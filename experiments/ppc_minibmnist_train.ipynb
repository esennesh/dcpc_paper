{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0592ca9e-6e32-4059-af50-4e49082fa72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/ppc_experiments\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94520ed3-45be-4735-a0f2-b8f380838c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import pyro\n",
    "import torch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "import trainer.trainer as module_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac4be4-19eb-4713-a88d-9bec118c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75ea7b9-6fe5-4f8a-a825-3572e421242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4889350c-1457-4dee-9e93-fab34f951a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    logger = config.get_logger('train')\n",
    "\n",
    "    # setup data_loader instances\n",
    "    data_loader = config.init_obj('data_loader', module_data)\n",
    "    valid_data_loader = data_loader.split_validation()\n",
    "\n",
    "    # build model architecture, then print to console\n",
    "    model = config.init_obj('arch', module_arch)\n",
    "    logger.info(model)\n",
    "\n",
    "    # get function handles of metrics\n",
    "    metrics = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "    # build optimizer.\n",
    "    optimizer = config.init_obj('optimizer', pyro.optim)\n",
    "\n",
    "    # build trainer\n",
    "    # kwargs = config['trainer'].pop('args')\n",
    "    trainer = config.init_obj('trainer', module_trainer, model, metrics, optimizer,\n",
    "                              config=config, data_loader=data_loader,\n",
    "                              valid_data_loader=valid_data_loader,\n",
    "                              lr_scheduler=None)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1445d1-45bb-43f9-893d-7a2b2bad1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BouncingMnistPpc(\n",
      "  (decoder): DigitsDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=200, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=200, out_features=400, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=400, out_features=784, bias=True)\n",
      "      (5): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (digit_features): DigitFeatures()\n",
      "  (digit_positions): DigitPositions()\n",
      "  (graph): PpcGraphicalModel()\n",
      ")\n",
      "Trainable parameters: 396984\n",
      "Initialize particles: train batch 0\n",
      "Initialize particles: train batch 1\n",
      "Initialize particles: train batch 2\n",
      "Initialize particles: train batch 3\n",
      "Initialize particles: train batch 4\n",
      "Initialize particles: train batch 5\n",
      "Initialize particles: train batch 6\n",
      "Initialize particles: train batch 7\n",
      "Initialize particles: train batch 8\n",
      "Initialize particles: train batch 9\n",
      "Initialize particles: train batch 10\n",
      "Initialize particles: train batch 11\n",
      "Initialize particles: train batch 12\n",
      "Initialize particles: train batch 13\n",
      "Initialize particles: train batch 14\n",
      "Initialize particles: train batch 15\n",
      "Initialize particles: train batch 16\n",
      "Initialize particles: train batch 17\n",
      "Initialize particles: train batch 18\n",
      "Initialize particles: train batch 19\n",
      "Initialize particles: valid batch 0\n",
      "Initialize particles: valid batch 1\n",
      "Initialize particles: valid batch 2\n",
      "Train Epoch: 1 [0/900 (0%)] Loss: -195256.359375\n",
      "Train Epoch: 1 [270/900 (30%)] Loss: -195566.375000\n",
      "Train Epoch: 1 [540/900 (60%)] Loss: -195651.453125\n",
      "Train Epoch: 1 [810/900 (90%)] Loss: -196860.312500\n",
      "    epoch          : 1\n",
      "    loss           : -195216.50625\n",
      "    ess            : 9.244865655899048\n",
      "    log_marginal   : 195216.62265625\n",
      "    val_loss       : -196529.390625\n",
      "    val_ess        : 8.836113611857096\n",
      "    val_log_marginal: 196529.61458333334\n",
      "Train Epoch: 2 [0/900 (0%)] Loss: -197162.562500\n",
      "Train Epoch: 2 [270/900 (30%)] Loss: -194634.531250\n",
      "Train Epoch: 2 [540/900 (60%)] Loss: -195258.375000\n",
      "Train Epoch: 2 [810/900 (90%)] Loss: -198492.078125\n",
      "    epoch          : 2\n",
      "    loss           : -197796.190625\n",
      "    ess            : 8.990750360488892\n",
      "    log_marginal   : 197796.3078125\n",
      "    val_loss       : -197668.61979166666\n",
      "    val_ess        : 8.9756072362264\n",
      "    val_log_marginal: 197668.72395833334\n",
      "Train Epoch: 3 [0/900 (0%)] Loss: -202137.359375\n",
      "Train Epoch: 3 [270/900 (30%)] Loss: -198372.468750\n",
      "Train Epoch: 3 [540/900 (60%)] Loss: -199650.921875\n",
      "Train Epoch: 3 [810/900 (90%)] Loss: -198908.781250\n",
      "    epoch          : 3\n",
      "    loss           : -199811.61640625\n",
      "    ess            : 8.881428003311157\n",
      "    log_marginal   : 199811.7421875\n",
      "    val_loss       : -199923.65104166666\n",
      "    val_ess        : 9.051721890767416\n",
      "    val_log_marginal: 199923.72916666666\n",
      "Train Epoch: 4 [0/900 (0%)] Loss: -200118.734375\n",
      "Train Epoch: 4 [270/900 (30%)] Loss: -201957.265625\n",
      "Train Epoch: 4 [540/900 (60%)] Loss: -202163.984375\n",
      "Train Epoch: 4 [810/900 (90%)] Loss: -199297.531250\n",
      "    epoch          : 4\n",
      "    loss           : -201552.51484375\n",
      "    ess            : 8.765996265411378\n",
      "    log_marginal   : 201552.665625\n",
      "    val_loss       : -203024.88020833334\n",
      "    val_ess        : 8.64993953704834\n",
      "    val_log_marginal: 203025.01041666666\n",
      "Train Epoch: 5 [0/900 (0%)] Loss: -203453.312500\n",
      "Train Epoch: 5 [270/900 (30%)] Loss: -201951.718750\n",
      "Train Epoch: 5 [540/900 (60%)] Loss: -202783.250000\n",
      "Train Epoch: 5 [810/900 (90%)] Loss: -202545.781250\n",
      "    epoch          : 5\n",
      "    loss           : -203273.88984375\n",
      "    ess            : 8.701665878295898\n",
      "    log_marginal   : 203274.0265625\n",
      "    val_loss       : -204978.234375\n",
      "    val_ess        : 8.05926767985026\n",
      "    val_log_marginal: 204978.47395833334\n",
      "Train Epoch: 6 [0/900 (0%)] Loss: -205986.468750\n",
      "Train Epoch: 6 [270/900 (30%)] Loss: -204449.156250\n",
      "Train Epoch: 6 [540/900 (60%)] Loss: -205513.828125\n",
      "Train Epoch: 6 [810/900 (90%)] Loss: -207058.312500\n",
      "    epoch          : 6\n",
      "    loss           : -205145.19765625\n",
      "    ess            : 8.534713673591614\n",
      "    log_marginal   : 205145.3703125\n",
      "    val_loss       : -206384.26041666666\n",
      "    val_ess        : 8.970964749654135\n",
      "    val_log_marginal: 206384.41145833334\n",
      "Train Epoch: 7 [0/900 (0%)] Loss: -209039.656250\n",
      "Train Epoch: 7 [270/900 (30%)] Loss: -206304.093750\n",
      "Train Epoch: 7 [540/900 (60%)] Loss: -206988.109375\n",
      "Train Epoch: 7 [810/900 (90%)] Loss: -208108.265625\n",
      "    epoch          : 7\n",
      "    loss           : -206980.59921875\n",
      "    ess            : 8.322163367271424\n",
      "    log_marginal   : 206980.81640625\n",
      "    val_loss       : -207291.44791666666\n",
      "    val_ess        : 8.58027172088623\n",
      "    val_log_marginal: 207291.57291666666\n",
      "Train Epoch: 8 [0/900 (0%)] Loss: -206854.671875\n",
      "Train Epoch: 8 [270/900 (30%)] Loss: -206703.937500\n",
      "Train Epoch: 8 [540/900 (60%)] Loss: -209332.265625\n",
      "Train Epoch: 8 [810/900 (90%)] Loss: -209887.265625\n",
      "    epoch          : 8\n",
      "    loss           : -208334.7890625\n",
      "    ess            : 8.29697563648224\n",
      "    log_marginal   : 208334.9953125\n",
      "    val_loss       : -209007.77604166666\n",
      "    val_ess        : 8.27228037516276\n",
      "    val_log_marginal: 209008.015625\n",
      "Train Epoch: 9 [0/900 (0%)] Loss: -207713.093750\n",
      "Train Epoch: 9 [270/900 (30%)] Loss: -208557.250000\n",
      "Train Epoch: 9 [540/900 (60%)] Loss: -208032.203125\n",
      "Train Epoch: 9 [810/900 (90%)] Loss: -207841.109375\n",
      "    epoch          : 9\n",
      "    loss           : -209162.0890625\n",
      "    ess            : 8.278227138519288\n",
      "    log_marginal   : 209162.30625\n",
      "    val_loss       : -209932.5625\n",
      "    val_ess        : 8.039939562479654\n",
      "    val_log_marginal: 209932.81770833334\n",
      "Train Epoch: 10 [0/900 (0%)] Loss: -208763.359375\n",
      "Train Epoch: 10 [270/900 (30%)] Loss: -210628.000000\n",
      "Train Epoch: 10 [540/900 (60%)] Loss: -208330.671875\n",
      "Train Epoch: 10 [810/900 (90%)] Loss: -209695.265625\n",
      "    epoch          : 10\n",
      "    loss           : -209746.3359375\n",
      "    ess            : 8.072433352470398\n",
      "    log_marginal   : 209746.628125\n",
      "    val_loss       : -209912.640625\n",
      "    val_ess        : 8.151360988616943\n",
      "    val_log_marginal: 209912.92708333334\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch10.pth ...\n",
      "Train Epoch: 11 [0/900 (0%)] Loss: -209876.296875\n",
      "Train Epoch: 11 [270/900 (30%)] Loss: -210134.359375\n",
      "Train Epoch: 11 [540/900 (60%)] Loss: -210811.609375\n",
      "Train Epoch: 11 [810/900 (90%)] Loss: -210338.671875\n",
      "    epoch          : 11\n",
      "    loss           : -210279.8984375\n",
      "    ess            : 7.937832760810852\n",
      "    log_marginal   : 210280.1734375\n",
      "    val_loss       : -209732.69270833334\n",
      "    val_ess        : 7.530331452687581\n",
      "    val_log_marginal: 209733.015625\n",
      "Train Epoch: 12 [0/900 (0%)] Loss: -210243.078125\n",
      "Train Epoch: 12 [270/900 (30%)] Loss: -210810.468750\n",
      "Train Epoch: 12 [540/900 (60%)] Loss: -210682.656250\n",
      "Train Epoch: 12 [810/900 (90%)] Loss: -211745.140625\n",
      "    epoch          : 12\n",
      "    loss           : -210791.04765625\n",
      "    ess            : 7.638281774520874\n",
      "    log_marginal   : 210791.39609375\n",
      "    val_loss       : -209245.546875\n",
      "    val_ess        : 7.519031842549642\n",
      "    val_log_marginal: 209245.96875\n",
      "Train Epoch: 13 [0/900 (0%)] Loss: -211085.390625\n",
      "Train Epoch: 13 [270/900 (30%)] Loss: -208762.921875\n",
      "Train Epoch: 13 [540/900 (60%)] Loss: -210758.031250\n",
      "Train Epoch: 13 [810/900 (90%)] Loss: -213029.312500\n",
      "    epoch          : 13\n",
      "    loss           : -211278.01953125\n",
      "    ess            : 7.672930216789245\n",
      "    log_marginal   : 211278.35625\n",
      "    val_loss       : -211499.63020833334\n",
      "    val_ess        : 7.821587562561035\n",
      "    val_log_marginal: 211499.96875\n",
      "Train Epoch: 14 [0/900 (0%)] Loss: -210730.296875\n",
      "Train Epoch: 14 [270/900 (30%)] Loss: -211876.562500\n",
      "Train Epoch: 14 [540/900 (60%)] Loss: -211310.531250\n",
      "Train Epoch: 14 [810/900 (90%)] Loss: -210371.187500\n",
      "    epoch          : 14\n",
      "    loss           : -211739.8015625\n",
      "    ess            : 7.643706870079041\n",
      "    log_marginal   : 211740.140625\n",
      "    val_loss       : -212142.00520833334\n",
      "    val_ess        : 7.538074493408203\n",
      "    val_log_marginal: 212142.359375\n",
      "Train Epoch: 15 [0/900 (0%)] Loss: -211213.156250\n",
      "Train Epoch: 15 [270/900 (30%)] Loss: -210371.031250\n",
      "Train Epoch: 15 [540/900 (60%)] Loss: -213638.421875\n",
      "Train Epoch: 15 [810/900 (90%)] Loss: -212999.406250\n",
      "    epoch          : 15\n",
      "    loss           : -212147.30625\n",
      "    ess            : 7.340670943260193\n",
      "    log_marginal   : 212147.73203125\n",
      "    val_loss       : -212300.11458333334\n",
      "    val_ess        : 7.070817629496257\n",
      "    val_log_marginal: 212300.609375\n",
      "Train Epoch: 16 [0/900 (0%)] Loss: -214193.937500\n",
      "Train Epoch: 16 [270/900 (30%)] Loss: -211731.609375\n",
      "Train Epoch: 16 [540/900 (60%)] Loss: -214300.343750\n",
      "Train Epoch: 16 [810/900 (90%)] Loss: -212109.359375\n",
      "    epoch          : 16\n",
      "    loss           : -212483.30390625\n",
      "    ess            : 7.493937993049622\n",
      "    log_marginal   : 212483.68515625\n",
      "    val_loss       : -211161.58333333334\n",
      "    val_ess        : 7.2339935302734375\n",
      "    val_log_marginal: 211162.0\n",
      "Train Epoch: 17 [0/900 (0%)] Loss: -213737.406250\n",
      "Train Epoch: 17 [270/900 (30%)] Loss: -212299.359375\n",
      "Train Epoch: 17 [540/900 (60%)] Loss: -213646.828125\n",
      "Train Epoch: 17 [810/900 (90%)] Loss: -214519.812500\n",
      "    epoch          : 17\n",
      "    loss           : -212734.990625\n",
      "    ess            : 7.48877317905426\n",
      "    log_marginal   : 212735.33828125\n",
      "    val_loss       : -213034.078125\n",
      "    val_ess        : 7.881340503692627\n",
      "    val_log_marginal: 213034.34895833334\n",
      "Train Epoch: 18 [0/900 (0%)] Loss: -214454.921875\n",
      "Train Epoch: 18 [270/900 (30%)] Loss: -213305.656250\n",
      "Train Epoch: 18 [540/900 (60%)] Loss: -213314.937500\n",
      "Train Epoch: 18 [810/900 (90%)] Loss: -213354.953125\n",
      "    epoch          : 18\n",
      "    loss           : -212915.1296875\n",
      "    ess            : 7.486549925804138\n",
      "    log_marginal   : 212915.534375\n",
      "    val_loss       : -213090.27604166666\n",
      "    val_ess        : 7.268830140431722\n",
      "    val_log_marginal: 213090.72916666666\n",
      "Train Epoch: 19 [0/900 (0%)] Loss: -212985.609375\n",
      "Train Epoch: 19 [270/900 (30%)] Loss: -213077.937500\n",
      "Train Epoch: 19 [540/900 (60%)] Loss: -212316.718750\n",
      "Train Epoch: 19 [810/900 (90%)] Loss: -211820.312500\n",
      "    epoch          : 19\n",
      "    loss           : -213040.03984375\n",
      "    ess            : 7.506126046180725\n",
      "    log_marginal   : 213040.43828125\n",
      "    val_loss       : -211891.078125\n",
      "    val_ess        : 7.078898906707764\n",
      "    val_log_marginal: 211891.71875\n",
      "Train Epoch: 20 [0/900 (0%)] Loss: -214801.250000\n",
      "Train Epoch: 20 [270/900 (30%)] Loss: -215611.718750\n",
      "Train Epoch: 20 [540/900 (60%)] Loss: -212837.453125\n",
      "Train Epoch: 20 [810/900 (90%)] Loss: -214887.359375\n",
      "    epoch          : 20\n",
      "    loss           : -213132.89921875\n",
      "    ess            : 7.5238113641738895\n",
      "    log_marginal   : 213133.27109375\n",
      "    val_loss       : -212968.86458333334\n",
      "    val_ess        : 6.742594083150228\n",
      "    val_log_marginal: 212969.5625\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch20.pth ...\n",
      "Train Epoch: 21 [0/900 (0%)] Loss: -214726.921875\n",
      "Train Epoch: 21 [270/900 (30%)] Loss: -215164.671875\n",
      "Train Epoch: 21 [540/900 (60%)] Loss: -213191.921875\n",
      "Train Epoch: 21 [810/900 (90%)] Loss: -213022.046875\n",
      "    epoch          : 21\n",
      "    loss           : -213199.9859375\n",
      "    ess            : 7.3987620115280155\n",
      "    log_marginal   : 213200.3671875\n",
      "    val_loss       : -212762.29166666666\n",
      "    val_ess        : 7.626288890838623\n",
      "    val_log_marginal: 212762.61979166666\n",
      "Train Epoch: 22 [0/900 (0%)] Loss: -211935.296875\n",
      "Train Epoch: 22 [270/900 (30%)] Loss: -214331.203125\n",
      "Train Epoch: 22 [540/900 (60%)] Loss: -214668.203125\n",
      "Train Epoch: 22 [810/900 (90%)] Loss: -211582.984375\n",
      "    epoch          : 22\n",
      "    loss           : -213243.17734375\n",
      "    ess            : 7.437023544311524\n",
      "    log_marginal   : 213243.56328125\n",
      "    val_loss       : -214535.140625\n",
      "    val_ess        : 7.332992076873779\n",
      "    val_log_marginal: 214535.65104166666\n",
      "Train Epoch: 23 [0/900 (0%)] Loss: -212089.828125\n",
      "Train Epoch: 23 [270/900 (30%)] Loss: -214461.984375\n",
      "Train Epoch: 23 [540/900 (60%)] Loss: -213387.078125\n",
      "Train Epoch: 23 [810/900 (90%)] Loss: -211508.421875\n",
      "    epoch          : 23\n",
      "    loss           : -213280.56640625\n",
      "    ess            : 7.367288184165955\n",
      "    log_marginal   : 213280.97421875\n",
      "    val_loss       : -213471.58333333334\n",
      "    val_ess        : 7.539556980133057\n",
      "    val_log_marginal: 213471.953125\n",
      "Train Epoch: 24 [0/900 (0%)] Loss: -214134.031250\n",
      "Train Epoch: 24 [270/900 (30%)] Loss: -213400.781250\n",
      "Train Epoch: 24 [540/900 (60%)] Loss: -212677.890625\n",
      "Train Epoch: 24 [810/900 (90%)] Loss: -214021.515625\n",
      "    epoch          : 24\n",
      "    loss           : -213311.940625\n",
      "    ess            : 7.411446547508239\n",
      "    log_marginal   : 213312.346875\n",
      "    val_loss       : -213682.17708333334\n",
      "    val_ess        : 6.917892615000407\n",
      "    val_log_marginal: 213682.76041666666\n",
      "Train Epoch: 25 [0/900 (0%)] Loss: -212299.000000\n",
      "Train Epoch: 25 [270/900 (30%)] Loss: -212695.562500\n",
      "Train Epoch: 25 [540/900 (60%)] Loss: -212946.031250\n",
      "Train Epoch: 25 [810/900 (90%)] Loss: -213776.203125\n",
      "    epoch          : 25\n",
      "    loss           : -213342.88828125\n",
      "    ess            : 7.582149338722229\n",
      "    log_marginal   : 213343.23125\n",
      "    val_loss       : -213394.13541666666\n",
      "    val_ess        : 7.323108832041423\n",
      "    val_log_marginal: 213394.44791666666\n",
      "Train Epoch: 26 [0/900 (0%)] Loss: -213640.187500\n",
      "Train Epoch: 26 [270/900 (30%)] Loss: -213898.734375\n",
      "Train Epoch: 26 [540/900 (60%)] Loss: -213412.953125\n",
      "Train Epoch: 26 [810/900 (90%)] Loss: -212746.671875\n",
      "    epoch          : 26\n",
      "    loss           : -213365.05\n",
      "    ess            : 7.429479694366455\n",
      "    log_marginal   : 213365.428125\n",
      "    val_loss       : -213273.08333333334\n",
      "    val_ess        : 7.420183022816976\n",
      "    val_log_marginal: 213273.44270833334\n",
      "Train Epoch: 27 [0/900 (0%)] Loss: -216074.140625\n",
      "Train Epoch: 27 [270/900 (30%)] Loss: -213078.921875\n",
      "Train Epoch: 27 [540/900 (60%)] Loss: -211526.890625\n",
      "Train Epoch: 27 [810/900 (90%)] Loss: -212925.265625\n",
      "    epoch          : 27\n",
      "    loss           : -213389.7671875\n",
      "    ess            : 7.523171281814575\n",
      "    log_marginal   : 213390.13828125\n",
      "    val_loss       : -212161.18229166666\n",
      "    val_ess        : 7.383152802785237\n",
      "    val_log_marginal: 212161.58333333334\n",
      "Train Epoch: 28 [0/900 (0%)] Loss: -214309.875000\n",
      "Train Epoch: 28 [270/900 (30%)] Loss: -213930.609375\n",
      "Train Epoch: 28 [540/900 (60%)] Loss: -213121.515625\n",
      "Train Epoch: 28 [810/900 (90%)] Loss: -213462.296875\n",
      "    epoch          : 28\n",
      "    loss           : -213408.14453125\n",
      "    ess            : 7.540860247612\n",
      "    log_marginal   : 213408.4984375\n",
      "    val_loss       : -213274.65625\n",
      "    val_ess        : 7.754220326741536\n",
      "    val_log_marginal: 213275.01041666666\n",
      "Train Epoch: 29 [0/900 (0%)] Loss: -213281.531250\n",
      "Train Epoch: 29 [270/900 (30%)] Loss: -214016.953125\n",
      "Train Epoch: 29 [540/900 (60%)] Loss: -213467.531250\n",
      "Train Epoch: 29 [810/900 (90%)] Loss: -213892.078125\n",
      "    epoch          : 29\n",
      "    loss           : -213429.57890625\n",
      "    ess            : 7.4479368925094604\n",
      "    log_marginal   : 213429.96484375\n",
      "    val_loss       : -212204.47916666666\n",
      "    val_ess        : 7.029043992360433\n",
      "    val_log_marginal: 212204.88541666666\n",
      "Train Epoch: 30 [0/900 (0%)] Loss: -214890.734375\n",
      "Train Epoch: 30 [270/900 (30%)] Loss: -212934.265625\n",
      "Train Epoch: 30 [540/900 (60%)] Loss: -213167.468750\n",
      "Train Epoch: 30 [810/900 (90%)] Loss: -214314.140625\n",
      "    epoch          : 30\n",
      "    loss           : -213448.09921875\n",
      "    ess            : 7.58298511505127\n",
      "    log_marginal   : 213448.43671875\n",
      "    val_loss       : -212349.70833333334\n",
      "    val_ess        : 7.6121954917907715\n",
      "    val_log_marginal: 212350.19270833334\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch30.pth ...\n",
      "Train Epoch: 31 [0/900 (0%)] Loss: -211689.046875\n",
      "Train Epoch: 31 [270/900 (30%)] Loss: -214078.359375\n",
      "Train Epoch: 31 [540/900 (60%)] Loss: -213284.671875\n",
      "Train Epoch: 31 [810/900 (90%)] Loss: -214259.843750\n",
      "    epoch          : 31\n",
      "    loss           : -213465.15078125\n",
      "    ess            : 7.461648035049438\n",
      "    log_marginal   : 213465.51796875\n",
      "    val_loss       : -214095.79166666666\n",
      "    val_ess        : 7.67264986038208\n",
      "    val_log_marginal: 214096.0625\n",
      "Train Epoch: 32 [0/900 (0%)] Loss: -214910.921875\n",
      "Train Epoch: 32 [270/900 (30%)] Loss: -215277.781250\n",
      "Train Epoch: 32 [540/900 (60%)] Loss: -215601.296875\n",
      "Train Epoch: 32 [810/900 (90%)] Loss: -214438.734375\n",
      "    epoch          : 32\n",
      "    loss           : -213486.02421875\n",
      "    ess            : 7.307824563980103\n",
      "    log_marginal   : 213486.42890625\n",
      "    val_loss       : -213803.09895833334\n",
      "    val_ess        : 6.6044314702351885\n",
      "    val_log_marginal: 213803.765625\n",
      "Train Epoch: 33 [0/900 (0%)] Loss: -215310.875000\n",
      "Train Epoch: 33 [270/900 (30%)] Loss: -213673.093750\n",
      "Train Epoch: 33 [540/900 (60%)] Loss: -214016.625000\n",
      "Train Epoch: 33 [810/900 (90%)] Loss: -213444.250000\n",
      "    epoch          : 33\n",
      "    loss           : -213503.146875\n",
      "    ess            : 7.6083533525466915\n",
      "    log_marginal   : 213503.46875\n",
      "    val_loss       : -213692.1875\n",
      "    val_ess        : 7.154205481211345\n",
      "    val_log_marginal: 213692.52604166666\n",
      "Train Epoch: 34 [0/900 (0%)] Loss: -213613.843750\n",
      "Train Epoch: 34 [270/900 (30%)] Loss: -212939.734375\n",
      "Train Epoch: 34 [540/900 (60%)] Loss: -212251.031250\n",
      "Train Epoch: 34 [810/900 (90%)] Loss: -213401.718750\n",
      "    epoch          : 34\n",
      "    loss           : -213518.53828125\n",
      "    ess            : 7.546372270584106\n",
      "    log_marginal   : 213518.8703125\n",
      "    val_loss       : -211353.57291666666\n",
      "    val_ess        : 6.895437558492024\n",
      "    val_log_marginal: 211353.99479166666\n",
      "Train Epoch: 35 [0/900 (0%)] Loss: -214656.187500\n",
      "Train Epoch: 35 [270/900 (30%)] Loss: -212842.406250\n",
      "Train Epoch: 35 [540/900 (60%)] Loss: -213284.921875\n",
      "Train Epoch: 35 [810/900 (90%)] Loss: -214443.390625\n",
      "    epoch          : 35\n",
      "    loss           : -213537.2484375\n",
      "    ess            : 7.609598183631897\n",
      "    log_marginal   : 213537.58046875\n",
      "    val_loss       : -212163.15104166666\n",
      "    val_ess        : 7.587088743845622\n",
      "    val_log_marginal: 212163.46354166666\n",
      "Train Epoch: 36 [0/900 (0%)] Loss: -212304.500000\n",
      "Train Epoch: 36 [270/900 (30%)] Loss: -213450.718750\n",
      "Train Epoch: 36 [540/900 (60%)] Loss: -212859.765625\n",
      "Train Epoch: 36 [810/900 (90%)] Loss: -213071.234375\n",
      "    epoch          : 36\n",
      "    loss           : -213556.81171875\n",
      "    ess            : 7.509431600570679\n",
      "    log_marginal   : 213557.16484375\n",
      "    val_loss       : -213397.390625\n",
      "    val_ess        : 7.528435389200847\n",
      "    val_log_marginal: 213397.69270833334\n",
      "Train Epoch: 37 [0/900 (0%)] Loss: -215710.000000\n",
      "Train Epoch: 37 [270/900 (30%)] Loss: -215224.515625\n",
      "Train Epoch: 37 [540/900 (60%)] Loss: -213825.875000\n",
      "Train Epoch: 37 [810/900 (90%)] Loss: -213869.312500\n",
      "    epoch          : 37\n",
      "    loss           : -213570.41171875\n",
      "    ess            : 7.597271037101746\n",
      "    log_marginal   : 213570.74609375\n",
      "    val_loss       : -213404.02083333334\n",
      "    val_ess        : 7.5974799791971845\n",
      "    val_log_marginal: 213404.36979166666\n",
      "Train Epoch: 38 [0/900 (0%)] Loss: -212799.734375\n",
      "Train Epoch: 38 [270/900 (30%)] Loss: -213750.156250\n",
      "Train Epoch: 38 [540/900 (60%)] Loss: -213805.359375\n",
      "Train Epoch: 38 [810/900 (90%)] Loss: -213258.937500\n",
      "    epoch          : 38\n",
      "    loss           : -213584.51484375\n",
      "    ess            : 7.567050790786743\n",
      "    log_marginal   : 213584.8453125\n",
      "    val_loss       : -213608.46875\n",
      "    val_ess        : 7.83371114730835\n",
      "    val_log_marginal: 213608.796875\n",
      "Train Epoch: 39 [0/900 (0%)] Loss: -213099.890625\n",
      "Train Epoch: 39 [270/900 (30%)] Loss: -213087.875000\n",
      "Train Epoch: 39 [540/900 (60%)] Loss: -214422.531250\n",
      "Train Epoch: 39 [810/900 (90%)] Loss: -212677.343750\n",
      "    epoch          : 39\n",
      "    loss           : -213601.5046875\n",
      "    ess            : 7.502501749992371\n",
      "    log_marginal   : 213601.8765625\n",
      "    val_loss       : -212186.32291666666\n",
      "    val_ess        : 8.116505781809488\n",
      "    val_log_marginal: 212186.515625\n",
      "Train Epoch: 40 [0/900 (0%)] Loss: -212976.109375\n",
      "Train Epoch: 40 [270/900 (30%)] Loss: -214482.609375\n",
      "Train Epoch: 40 [540/900 (60%)] Loss: -212401.078125\n",
      "Train Epoch: 40 [810/900 (90%)] Loss: -215299.578125\n",
      "    epoch          : 40\n",
      "    loss           : -213618.4296875\n",
      "    ess            : 7.662742972373962\n",
      "    log_marginal   : 213618.746875\n",
      "    val_loss       : -212181.25\n",
      "    val_ess        : 8.031192302703857\n",
      "    val_log_marginal: 212181.515625\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch40.pth ...\n",
      "Train Epoch: 41 [0/900 (0%)] Loss: -213838.296875\n",
      "Train Epoch: 41 [270/900 (30%)] Loss: -212785.875000\n",
      "Train Epoch: 41 [540/900 (60%)] Loss: -213023.812500\n",
      "Train Epoch: 41 [810/900 (90%)] Loss: -214463.359375\n",
      "    epoch          : 41\n",
      "    loss           : -213633.10390625\n",
      "    ess            : 7.530860590934753\n",
      "    log_marginal   : 213633.45546875\n",
      "    val_loss       : -212222.80729166666\n",
      "    val_ess        : 7.5492197672526045\n",
      "    val_log_marginal: 212223.13541666666\n",
      "Train Epoch: 42 [0/900 (0%)] Loss: -213372.359375\n",
      "Train Epoch: 42 [270/900 (30%)] Loss: -214845.468750\n",
      "Train Epoch: 42 [540/900 (60%)] Loss: -212866.671875\n",
      "Train Epoch: 42 [810/900 (90%)] Loss: -214494.656250\n",
      "    epoch          : 42\n",
      "    loss           : -213645.3671875\n",
      "    ess            : 7.629193234443664\n",
      "    log_marginal   : 213645.696875\n",
      "    val_loss       : -213389.76041666666\n",
      "    val_ess        : 7.784323215484619\n",
      "    val_log_marginal: 213389.97916666666\n",
      "Train Epoch: 43 [0/900 (0%)] Loss: -214769.234375\n",
      "Train Epoch: 43 [270/900 (30%)] Loss: -214026.390625\n",
      "Train Epoch: 43 [540/900 (60%)] Loss: -212307.531250\n",
      "Train Epoch: 43 [810/900 (90%)] Loss: -212903.234375\n",
      "    epoch          : 43\n",
      "    loss           : -213657.80546875\n",
      "    ess            : 7.314575982093811\n",
      "    log_marginal   : 213658.2203125\n",
      "    val_loss       : -213522.68229166666\n",
      "    val_ess        : 7.285384178161621\n",
      "    val_log_marginal: 213523.06770833334\n",
      "Train Epoch: 44 [0/900 (0%)] Loss: -213891.500000\n",
      "Train Epoch: 44 [270/900 (30%)] Loss: -213774.390625\n",
      "Train Epoch: 44 [540/900 (60%)] Loss: -212850.468750\n",
      "Train Epoch: 44 [810/900 (90%)] Loss: -212784.453125\n",
      "    epoch          : 44\n",
      "    loss           : -213667.41640625\n",
      "    ess            : 7.442004370689392\n",
      "    log_marginal   : 213667.79765625\n",
      "    val_loss       : -212988.734375\n",
      "    val_ess        : 7.504257043202718\n",
      "    val_log_marginal: 212989.03125\n",
      "Train Epoch: 45 [0/900 (0%)] Loss: -212741.562500\n",
      "Train Epoch: 45 [270/900 (30%)] Loss: -213016.531250\n",
      "Train Epoch: 45 [540/900 (60%)] Loss: -212571.359375\n",
      "Train Epoch: 45 [810/900 (90%)] Loss: -213632.406250\n",
      "    epoch          : 45\n",
      "    loss           : -213685.1453125\n",
      "    ess            : 7.551773548126221\n",
      "    log_marginal   : 213685.51171875\n",
      "    val_loss       : -213165.86979166666\n",
      "    val_ess        : 7.396690686543782\n",
      "    val_log_marginal: 213166.25520833334\n",
      "Train Epoch: 46 [0/900 (0%)] Loss: -214172.875000\n",
      "Train Epoch: 46 [270/900 (30%)] Loss: -214657.890625\n",
      "Train Epoch: 46 [540/900 (60%)] Loss: -212604.468750\n",
      "Train Epoch: 46 [810/900 (90%)] Loss: -213180.953125\n",
      "    epoch          : 46\n",
      "    loss           : -213694.84453125\n",
      "    ess            : 7.505396986007691\n",
      "    log_marginal   : 213695.18671875\n",
      "    val_loss       : -214224.9375\n",
      "    val_ess        : 7.611259460449219\n",
      "    val_log_marginal: 214225.203125\n",
      "Train Epoch: 47 [0/900 (0%)] Loss: -211813.515625\n",
      "Train Epoch: 47 [270/900 (30%)] Loss: -211728.875000\n",
      "Train Epoch: 47 [540/900 (60%)] Loss: -213026.500000\n",
      "Train Epoch: 47 [810/900 (90%)] Loss: -213591.515625\n",
      "    epoch          : 47\n",
      "    loss           : -213703.5\n",
      "    ess            : 7.567963361740112\n",
      "    log_marginal   : 213703.82578125\n",
      "    val_loss       : -212673.63020833334\n",
      "    val_ess        : 7.234211126963298\n",
      "    val_log_marginal: 212674.171875\n",
      "Train Epoch: 48 [0/900 (0%)] Loss: -214777.656250\n",
      "Train Epoch: 48 [270/900 (30%)] Loss: -211358.828125\n",
      "Train Epoch: 48 [540/900 (60%)] Loss: -212993.656250\n",
      "Train Epoch: 48 [810/900 (90%)] Loss: -213769.359375\n",
      "    epoch          : 48\n",
      "    loss           : -213711.371875\n",
      "    ess            : 7.532149815559388\n",
      "    log_marginal   : 213711.725\n",
      "    val_loss       : -214887.265625\n",
      "    val_ess        : 7.901543140411377\n",
      "    val_log_marginal: 214887.56770833334\n",
      "Train Epoch: 49 [0/900 (0%)] Loss: -213188.609375\n",
      "Train Epoch: 49 [270/900 (30%)] Loss: -214611.453125\n",
      "Train Epoch: 49 [540/900 (60%)] Loss: -214066.250000\n",
      "Train Epoch: 49 [810/900 (90%)] Loss: -217137.203125\n",
      "    epoch          : 49\n",
      "    loss           : -213718.8828125\n",
      "    ess            : 7.412903046607971\n",
      "    log_marginal   : 213719.26015625\n",
      "    val_loss       : -213782.13020833334\n",
      "    val_ess        : 8.030219713846842\n",
      "    val_log_marginal: 213782.38020833334\n",
      "Train Epoch: 50 [0/900 (0%)] Loss: -213604.687500\n",
      "Train Epoch: 50 [270/900 (30%)] Loss: -214552.203125\n",
      "Train Epoch: 50 [540/900 (60%)] Loss: -215692.734375\n",
      "Train Epoch: 50 [810/900 (90%)] Loss: -214909.296875\n",
      "    epoch          : 50\n",
      "    loss           : -213729.9109375\n",
      "    ess            : 7.512089943885803\n",
      "    log_marginal   : 213730.25625\n",
      "    val_loss       : -212771.71354166666\n",
      "    val_ess        : 7.840208689371745\n",
      "    val_log_marginal: 212772.0\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch50.pth ...\n",
      "Train Epoch: 51 [0/900 (0%)] Loss: -214179.203125\n",
      "Train Epoch: 51 [270/900 (30%)] Loss: -212650.718750\n",
      "Train Epoch: 51 [540/900 (60%)] Loss: -214503.046875\n",
      "Train Epoch: 51 [810/900 (90%)] Loss: -214692.453125\n",
      "    epoch          : 51\n",
      "    loss           : -213740.50703125\n",
      "    ess            : 7.521561622619629\n",
      "    log_marginal   : 213740.8859375\n",
      "    val_loss       : -214150.57291666666\n",
      "    val_ess        : 6.65818977355957\n",
      "    val_log_marginal: 214151.16145833334\n",
      "Train Epoch: 52 [0/900 (0%)] Loss: -212749.937500\n",
      "Train Epoch: 52 [270/900 (30%)] Loss: -215679.500000\n",
      "Train Epoch: 52 [540/900 (60%)] Loss: -214297.265625\n",
      "Train Epoch: 52 [810/900 (90%)] Loss: -213513.625000\n",
      "    epoch          : 52\n",
      "    loss           : -213749.309375\n",
      "    ess            : 7.481020760536194\n",
      "    log_marginal   : 213749.696875\n",
      "    val_loss       : -214379.30208333334\n",
      "    val_ess        : 7.386109828948975\n",
      "    val_log_marginal: 214379.61458333334\n",
      "Train Epoch: 53 [0/900 (0%)] Loss: -213978.718750\n",
      "Train Epoch: 53 [270/900 (30%)] Loss: -214567.093750\n",
      "Train Epoch: 53 [540/900 (60%)] Loss: -213712.812500\n",
      "Train Epoch: 53 [810/900 (90%)] Loss: -212394.000000\n",
      "    epoch          : 53\n",
      "    loss           : -213761.11640625\n",
      "    ess            : 7.5773200511932375\n",
      "    log_marginal   : 213761.45625\n",
      "    val_loss       : -212854.24479166666\n",
      "    val_ess        : 8.1344895362854\n",
      "    val_log_marginal: 212854.45833333334\n",
      "Train Epoch: 54 [0/900 (0%)] Loss: -215546.140625\n",
      "Train Epoch: 54 [270/900 (30%)] Loss: -212835.343750\n",
      "Train Epoch: 54 [540/900 (60%)] Loss: -213521.109375\n",
      "Train Epoch: 54 [810/900 (90%)] Loss: -215133.734375\n",
      "    epoch          : 54\n",
      "    loss           : -213766.60546875\n",
      "    ess            : 7.5689407110214235\n",
      "    log_marginal   : 213766.93984375\n",
      "    val_loss       : -212809.11458333334\n",
      "    val_ess        : 7.504385948181152\n",
      "    val_log_marginal: 212809.40625\n",
      "Train Epoch: 55 [0/900 (0%)] Loss: -214432.953125\n",
      "Train Epoch: 55 [270/900 (30%)] Loss: -215831.000000\n",
      "Train Epoch: 55 [540/900 (60%)] Loss: -210980.453125\n",
      "Train Epoch: 55 [810/900 (90%)] Loss: -213103.890625\n",
      "    epoch          : 55\n",
      "    loss           : -213777.71328125\n",
      "    ess            : 7.544644498825074\n",
      "    log_marginal   : 213778.028125\n",
      "    val_loss       : -213107.04166666666\n",
      "    val_ess        : 7.628720124562581\n",
      "    val_log_marginal: 213107.28125\n",
      "Train Epoch: 56 [0/900 (0%)] Loss: -214496.187500\n",
      "Train Epoch: 56 [270/900 (30%)] Loss: -213716.468750\n",
      "Train Epoch: 56 [540/900 (60%)] Loss: -213588.390625\n",
      "Train Epoch: 56 [810/900 (90%)] Loss: -212955.234375\n",
      "    epoch          : 56\n",
      "    loss           : -213794.49375\n",
      "    ess            : 7.473038935661316\n",
      "    log_marginal   : 213794.8578125\n",
      "    val_loss       : -214050.26041666666\n",
      "    val_ess        : 7.579578558603923\n",
      "    val_log_marginal: 214050.65104166666\n",
      "Train Epoch: 57 [0/900 (0%)] Loss: -213179.140625\n",
      "Train Epoch: 57 [270/900 (30%)] Loss: -213558.984375\n",
      "Train Epoch: 57 [540/900 (60%)] Loss: -214345.406250\n",
      "Train Epoch: 57 [810/900 (90%)] Loss: -216428.203125\n",
      "    epoch          : 57\n",
      "    loss           : -213800.228125\n",
      "    ess            : 7.545406913757324\n",
      "    log_marginal   : 213800.5875\n",
      "    val_loss       : -212911.58854166666\n",
      "    val_ess        : 7.872942765553792\n",
      "    val_log_marginal: 212911.84895833334\n",
      "Train Epoch: 58 [0/900 (0%)] Loss: -213575.875000\n",
      "Train Epoch: 58 [270/900 (30%)] Loss: -214666.921875\n",
      "Train Epoch: 58 [540/900 (60%)] Loss: -214382.468750\n",
      "Train Epoch: 58 [810/900 (90%)] Loss: -212652.953125\n",
      "    epoch          : 58\n",
      "    loss           : -213813.3234375\n",
      "    ess            : 7.501309037208557\n",
      "    log_marginal   : 213813.66484375\n",
      "    val_loss       : -214178.52604166666\n",
      "    val_ess        : 7.815796375274658\n",
      "    val_log_marginal: 214178.80729166666\n",
      "Train Epoch: 59 [0/900 (0%)] Loss: -213729.656250\n",
      "Train Epoch: 59 [270/900 (30%)] Loss: -213481.890625\n",
      "Train Epoch: 59 [540/900 (60%)] Loss: -213670.937500\n",
      "Train Epoch: 59 [810/900 (90%)] Loss: -215354.890625\n",
      "    epoch          : 59\n",
      "    loss           : -213823.91484375\n",
      "    ess            : 7.578849029541016\n",
      "    log_marginal   : 213824.271875\n",
      "    val_loss       : -213814.41145833334\n",
      "    val_ess        : 7.631254990895589\n",
      "    val_log_marginal: 213814.74479166666\n",
      "Train Epoch: 60 [0/900 (0%)] Loss: -214457.234375\n",
      "Train Epoch: 60 [270/900 (30%)] Loss: -213793.250000\n",
      "Train Epoch: 60 [540/900 (60%)] Loss: -212251.203125\n",
      "Train Epoch: 60 [810/900 (90%)] Loss: -213751.953125\n",
      "    epoch          : 60\n",
      "    loss           : -213830.31484375\n",
      "    ess            : 7.646200513839721\n",
      "    log_marginal   : 213830.63515625\n",
      "    val_loss       : -213113.83854166666\n",
      "    val_ess        : 7.338529586791992\n",
      "    val_log_marginal: 213114.14583333334\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch60.pth ...\n",
      "Train Epoch: 61 [0/900 (0%)] Loss: -215400.671875\n",
      "Train Epoch: 61 [270/900 (30%)] Loss: -211922.078125\n",
      "Train Epoch: 61 [540/900 (60%)] Loss: -211629.625000\n",
      "Train Epoch: 61 [810/900 (90%)] Loss: -214605.875000\n",
      "    epoch          : 61\n",
      "    loss           : -213838.97421875\n",
      "    ess            : 7.625341129302979\n",
      "    log_marginal   : 213839.31328125\n",
      "    val_loss       : -214037.96354166666\n",
      "    val_ess        : 7.527523835500081\n",
      "    val_log_marginal: 214038.27083333334\n",
      "Train Epoch: 62 [0/900 (0%)] Loss: -214140.828125\n",
      "Train Epoch: 62 [270/900 (30%)] Loss: -213747.078125\n",
      "Train Epoch: 62 [540/900 (60%)] Loss: -214107.000000\n",
      "Train Epoch: 62 [810/900 (90%)] Loss: -214305.781250\n",
      "    epoch          : 62\n",
      "    loss           : -213847.0140625\n",
      "    ess            : 7.538983345031738\n",
      "    log_marginal   : 213847.35625\n",
      "    val_loss       : -214182.97916666666\n",
      "    val_ess        : 7.20114278793335\n",
      "    val_log_marginal: 214183.33333333334\n",
      "Train Epoch: 63 [0/900 (0%)] Loss: -214342.390625\n",
      "Train Epoch: 63 [270/900 (30%)] Loss: -211819.203125\n",
      "Train Epoch: 63 [540/900 (60%)] Loss: -214785.671875\n",
      "Train Epoch: 63 [810/900 (90%)] Loss: -212350.812500\n",
      "    epoch          : 63\n",
      "    loss           : -213861.728125\n",
      "    ess            : 7.552109956741333\n",
      "    log_marginal   : 213862.08671875\n",
      "    val_loss       : -212902.42708333334\n",
      "    val_ess        : 7.829143047332764\n",
      "    val_log_marginal: 212902.73958333334\n",
      "Train Epoch: 64 [0/900 (0%)] Loss: -213407.390625\n",
      "Train Epoch: 64 [270/900 (30%)] Loss: -212712.000000\n",
      "Train Epoch: 64 [540/900 (60%)] Loss: -213652.156250\n",
      "Train Epoch: 64 [810/900 (90%)] Loss: -215684.953125\n",
      "    epoch          : 64\n",
      "    loss           : -213868.86640625\n",
      "    ess            : 7.577442359924317\n",
      "    log_marginal   : 213869.19453125\n",
      "    val_loss       : -212894.52083333334\n",
      "    val_ess        : 7.760678132375081\n",
      "    val_log_marginal: 212894.78645833334\n",
      "Train Epoch: 65 [0/900 (0%)] Loss: -215345.312500\n",
      "Train Epoch: 65 [270/900 (30%)] Loss: -212726.984375\n",
      "Train Epoch: 65 [540/900 (60%)] Loss: -213454.187500\n",
      "Train Epoch: 65 [810/900 (90%)] Loss: -216559.234375\n",
      "    epoch          : 65\n",
      "    loss           : -213881.24609375\n",
      "    ess            : 7.5931734323501585\n",
      "    log_marginal   : 213881.575\n",
      "    val_loss       : -212231.609375\n",
      "    val_ess        : 7.7704644203186035\n",
      "    val_log_marginal: 212231.875\n",
      "Train Epoch: 66 [0/900 (0%)] Loss: -214630.828125\n",
      "Train Epoch: 66 [270/900 (30%)] Loss: -212713.687500\n",
      "Train Epoch: 66 [540/900 (60%)] Loss: -212602.578125\n",
      "Train Epoch: 66 [810/900 (90%)] Loss: -214169.953125\n",
      "    epoch          : 66\n",
      "    loss           : -213886.71171875\n",
      "    ess            : 7.662577891349793\n",
      "    log_marginal   : 213887.06328125\n",
      "    val_loss       : -212748.42708333334\n",
      "    val_ess        : 7.5584259033203125\n",
      "    val_log_marginal: 212748.83333333334\n",
      "Train Epoch: 67 [0/900 (0%)] Loss: -215472.500000\n",
      "Train Epoch: 67 [270/900 (30%)] Loss: -214932.312500\n",
      "Train Epoch: 67 [540/900 (60%)] Loss: -214266.890625\n",
      "Train Epoch: 67 [810/900 (90%)] Loss: -213934.390625\n",
      "    epoch          : 67\n",
      "    loss           : -213896.5046875\n",
      "    ess            : 7.5157088279724125\n",
      "    log_marginal   : 213896.8765625\n",
      "    val_loss       : -213840.1875\n",
      "    val_ess        : 7.697085380554199\n",
      "    val_log_marginal: 213840.453125\n",
      "Train Epoch: 68 [0/900 (0%)] Loss: -213884.265625\n",
      "Train Epoch: 68 [270/900 (30%)] Loss: -212820.390625\n",
      "Train Epoch: 68 [540/900 (60%)] Loss: -213577.828125\n",
      "Train Epoch: 68 [810/900 (90%)] Loss: -214644.031250\n",
      "    epoch          : 68\n",
      "    loss           : -213905.0734375\n",
      "    ess            : 7.544452667236328\n",
      "    log_marginal   : 213905.44140625\n",
      "    val_loss       : -213618.484375\n",
      "    val_ess        : 7.405073324839274\n",
      "    val_log_marginal: 213618.86458333334\n",
      "Train Epoch: 69 [0/900 (0%)] Loss: -213927.781250\n",
      "Train Epoch: 69 [270/900 (30%)] Loss: -212819.921875\n",
      "Train Epoch: 69 [540/900 (60%)] Loss: -214181.500000\n",
      "Train Epoch: 69 [810/900 (90%)] Loss: -214442.656250\n",
      "    epoch          : 69\n",
      "    loss           : -213911.96796875\n",
      "    ess            : 7.521486377716064\n",
      "    log_marginal   : 213912.31953125\n",
      "    val_loss       : -214214.61458333334\n",
      "    val_ess        : 7.475560983022054\n",
      "    val_log_marginal: 214214.921875\n",
      "Train Epoch: 70 [0/900 (0%)] Loss: -211948.468750\n",
      "Train Epoch: 70 [270/900 (30%)] Loss: -213267.250000\n",
      "Train Epoch: 70 [540/900 (60%)] Loss: -215258.031250\n",
      "Train Epoch: 70 [810/900 (90%)] Loss: -213666.390625\n",
      "    epoch          : 70\n",
      "    loss           : -213916.9140625\n",
      "    ess            : 7.69520103931427\n",
      "    log_marginal   : 213917.25859375\n",
      "    val_loss       : -212649.35416666666\n",
      "    val_ess        : 7.117008050282796\n",
      "    val_log_marginal: 212649.86979166666\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [0/900 (0%)] Loss: -212719.046875\n",
      "Train Epoch: 71 [270/900 (30%)] Loss: -214482.609375\n",
      "Train Epoch: 71 [540/900 (60%)] Loss: -214378.843750\n",
      "Train Epoch: 71 [810/900 (90%)] Loss: -211961.578125\n",
      "    epoch          : 71\n",
      "    loss           : -213925.66484375\n",
      "    ess            : 7.562091875076294\n",
      "    log_marginal   : 213926.0265625\n",
      "    val_loss       : -213982.27083333334\n",
      "    val_ess        : 7.682104746500651\n",
      "    val_log_marginal: 213982.64583333334\n",
      "Train Epoch: 72 [0/900 (0%)] Loss: -215618.578125\n",
      "Train Epoch: 72 [270/900 (30%)] Loss: -212652.156250\n",
      "Train Epoch: 72 [540/900 (60%)] Loss: -214673.250000\n",
      "Train Epoch: 72 [810/900 (90%)] Loss: -215048.875000\n",
      "    epoch          : 72\n",
      "    loss           : -213931.2171875\n",
      "    ess            : 7.463869166374207\n",
      "    log_marginal   : 213931.58203125\n",
      "    val_loss       : -213595.640625\n",
      "    val_ess        : 7.485071341196696\n",
      "    val_log_marginal: 213595.93229166666\n",
      "Train Epoch: 73 [0/900 (0%)] Loss: -214248.875000\n",
      "Train Epoch: 73 [270/900 (30%)] Loss: -214587.828125\n",
      "Train Epoch: 73 [540/900 (60%)] Loss: -214249.359375\n",
      "Train Epoch: 73 [810/900 (90%)] Loss: -213689.296875\n",
      "    epoch          : 73\n",
      "    loss           : -213931.33515625\n",
      "    ess            : 7.578221249580383\n",
      "    log_marginal   : 213931.66640625\n",
      "    val_loss       : -213860.21354166666\n",
      "    val_ess        : 7.630895773569743\n",
      "    val_log_marginal: 213860.48958333334\n",
      "Train Epoch: 74 [0/900 (0%)] Loss: -212997.765625\n",
      "Train Epoch: 74 [270/900 (30%)] Loss: -212887.937500\n",
      "Train Epoch: 74 [540/900 (60%)] Loss: -213256.875000\n",
      "Train Epoch: 74 [810/900 (90%)] Loss: -214457.656250\n",
      "    epoch          : 74\n",
      "    loss           : -213940.2125\n",
      "    ess            : 7.546737265586853\n",
      "    log_marginal   : 213940.56015625\n",
      "    val_loss       : -214223.36979166666\n",
      "    val_ess        : 7.941910584767659\n",
      "    val_log_marginal: 214223.609375\n",
      "Train Epoch: 75 [0/900 (0%)] Loss: -214072.781250\n",
      "Train Epoch: 75 [270/900 (30%)] Loss: -212272.578125\n",
      "Train Epoch: 75 [540/900 (60%)] Loss: -215517.343750\n",
      "Train Epoch: 75 [810/900 (90%)] Loss: -213045.812500\n",
      "    epoch          : 75\n",
      "    loss           : -213952.08828125\n",
      "    ess            : 7.538044142723083\n",
      "    log_marginal   : 213952.4234375\n",
      "    val_loss       : -213498.1875\n",
      "    val_ess        : 7.206523895263672\n",
      "    val_log_marginal: 213498.78125\n",
      "Train Epoch: 76 [0/900 (0%)] Loss: -214821.078125\n",
      "Train Epoch: 76 [270/900 (30%)] Loss: -213112.828125\n",
      "Train Epoch: 76 [540/900 (60%)] Loss: -211424.781250\n",
      "Train Epoch: 76 [810/900 (90%)] Loss: -212130.453125\n",
      "    epoch          : 76\n",
      "    loss           : -213964.81796875\n",
      "    ess            : 7.562155771255493\n",
      "    log_marginal   : 213965.16015625\n",
      "    val_loss       : -214063.90104166666\n",
      "    val_ess        : 8.031436443328857\n",
      "    val_log_marginal: 214064.140625\n",
      "Train Epoch: 77 [0/900 (0%)] Loss: -215200.656250\n",
      "Train Epoch: 77 [270/900 (30%)] Loss: -213416.406250\n",
      "Train Epoch: 77 [540/900 (60%)] Loss: -214053.984375\n",
      "Train Epoch: 77 [810/900 (90%)] Loss: -214085.500000\n",
      "    epoch          : 77\n",
      "    loss           : -213973.68671875\n",
      "    ess            : 7.456026935577393\n",
      "    log_marginal   : 213974.06171875\n",
      "    val_loss       : -212697.00520833334\n",
      "    val_ess        : 7.56416114171346\n",
      "    val_log_marginal: 212697.28125\n",
      "Train Epoch: 78 [0/900 (0%)] Loss: -214758.828125\n",
      "Train Epoch: 78 [270/900 (30%)] Loss: -214463.875000\n",
      "Train Epoch: 78 [540/900 (60%)] Loss: -214316.687500\n",
      "Train Epoch: 78 [810/900 (90%)] Loss: -214043.984375\n",
      "    epoch          : 78\n",
      "    loss           : -213983.8015625\n",
      "    ess            : 7.348576712608337\n",
      "    log_marginal   : 213984.209375\n",
      "    val_loss       : -213473.65625\n",
      "    val_ess        : 7.627793312072754\n",
      "    val_log_marginal: 213473.97395833334\n",
      "Train Epoch: 79 [0/900 (0%)] Loss: -212937.937500\n",
      "Train Epoch: 79 [270/900 (30%)] Loss: -214492.671875\n",
      "Train Epoch: 79 [540/900 (60%)] Loss: -214930.250000\n",
      "Train Epoch: 79 [810/900 (90%)] Loss: -214536.515625\n",
      "    epoch          : 79\n",
      "    loss           : -213987.9140625\n",
      "    ess            : 7.5503969430923465\n",
      "    log_marginal   : 213988.25703125\n",
      "    val_loss       : -214132.72395833334\n",
      "    val_ess        : 7.759392261505127\n",
      "    val_log_marginal: 214133.04166666666\n",
      "Train Epoch: 80 [0/900 (0%)] Loss: -215077.515625\n",
      "Train Epoch: 80 [270/900 (30%)] Loss: -214515.531250\n",
      "Train Epoch: 80 [540/900 (60%)] Loss: -212835.390625\n",
      "Train Epoch: 80 [810/900 (90%)] Loss: -213796.671875\n",
      "    epoch          : 80\n",
      "    loss           : -213994.834375\n",
      "    ess            : 7.700216817855835\n",
      "    log_marginal   : 213995.1546875\n",
      "    val_loss       : -212729.51041666666\n",
      "    val_ess        : 7.145796616872151\n",
      "    val_log_marginal: 212729.86458333334\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch80.pth ...\n",
      "Train Epoch: 81 [0/900 (0%)] Loss: -212927.890625\n",
      "Train Epoch: 81 [270/900 (30%)] Loss: -214409.046875\n",
      "Train Epoch: 81 [540/900 (60%)] Loss: -215474.734375\n",
      "Train Epoch: 81 [810/900 (90%)] Loss: -213061.625000\n",
      "    epoch          : 81\n",
      "    loss           : -214005.23125\n",
      "    ess            : 7.683176565170288\n",
      "    log_marginal   : 214005.54765625\n",
      "    val_loss       : -213789.375\n",
      "    val_ess        : 7.635962009429932\n",
      "    val_log_marginal: 213789.765625\n",
      "Train Epoch: 82 [0/900 (0%)] Loss: -213358.140625\n",
      "Train Epoch: 82 [270/900 (30%)] Loss: -215256.843750\n",
      "Train Epoch: 82 [540/900 (60%)] Loss: -214022.109375\n",
      "Train Epoch: 82 [810/900 (90%)] Loss: -212979.734375\n",
      "    epoch          : 82\n",
      "    loss           : -214015.25703125\n",
      "    ess            : 7.679424214363098\n",
      "    log_marginal   : 214015.57109375\n",
      "    val_loss       : -214044.06770833334\n",
      "    val_ess        : 7.608641783396403\n",
      "    val_log_marginal: 214044.359375\n",
      "Train Epoch: 83 [0/900 (0%)] Loss: -214395.359375\n",
      "Train Epoch: 83 [270/900 (30%)] Loss: -214290.921875\n",
      "Train Epoch: 83 [540/900 (60%)] Loss: -211658.828125\n",
      "Train Epoch: 83 [810/900 (90%)] Loss: -213714.000000\n",
      "    epoch          : 83\n",
      "    loss           : -214017.8546875\n",
      "    ess            : 7.59918258190155\n",
      "    log_marginal   : 214018.19765625\n",
      "    val_loss       : -214551.84375\n",
      "    val_ess        : 7.062396049499512\n",
      "    val_log_marginal: 214552.36458333334\n",
      "Train Epoch: 84 [0/900 (0%)] Loss: -213070.296875\n",
      "Train Epoch: 84 [270/900 (30%)] Loss: -213363.140625\n",
      "Train Epoch: 84 [540/900 (60%)] Loss: -213893.156250\n",
      "Train Epoch: 84 [810/900 (90%)] Loss: -213238.312500\n",
      "    epoch          : 84\n",
      "    loss           : -214028.3109375\n",
      "    ess            : 7.4487447261810305\n",
      "    log_marginal   : 214028.68046875\n",
      "    val_loss       : -213612.33854166666\n",
      "    val_ess        : 7.733758290608724\n",
      "    val_log_marginal: 213612.671875\n",
      "Train Epoch: 85 [0/900 (0%)] Loss: -215168.156250\n",
      "Train Epoch: 85 [270/900 (30%)] Loss: -213955.046875\n",
      "Train Epoch: 85 [540/900 (60%)] Loss: -213724.250000\n",
      "Train Epoch: 85 [810/900 (90%)] Loss: -214912.953125\n",
      "    epoch          : 85\n",
      "    loss           : -214031.37109375\n",
      "    ess            : 7.457820177078247\n",
      "    log_marginal   : 214031.7421875\n",
      "    val_loss       : -213284.80208333334\n",
      "    val_ess        : 7.577939510345459\n",
      "    val_log_marginal: 213285.15625\n",
      "Train Epoch: 86 [0/900 (0%)] Loss: -215368.609375\n",
      "Train Epoch: 86 [270/900 (30%)] Loss: -213263.453125\n",
      "Train Epoch: 86 [540/900 (60%)] Loss: -212981.984375\n",
      "Train Epoch: 86 [810/900 (90%)] Loss: -213271.875000\n",
      "    epoch          : 86\n",
      "    loss           : -214039.83515625\n",
      "    ess            : 7.704236960411071\n",
      "    log_marginal   : 214040.1453125\n",
      "    val_loss       : -212724.39583333334\n",
      "    val_ess        : 7.1219706535339355\n",
      "    val_log_marginal: 212724.75\n",
      "Train Epoch: 87 [0/900 (0%)] Loss: -213198.765625\n",
      "Train Epoch: 87 [270/900 (30%)] Loss: -213530.656250\n",
      "Train Epoch: 87 [540/900 (60%)] Loss: -216523.578125\n",
      "Train Epoch: 87 [810/900 (90%)] Loss: -214421.843750\n",
      "    epoch          : 87\n",
      "    loss           : -214043.2046875\n",
      "    ess            : 7.477463173866272\n",
      "    log_marginal   : 214043.56171875\n",
      "    val_loss       : -214226.203125\n",
      "    val_ess        : 7.405285676320394\n",
      "    val_log_marginal: 214226.54166666666\n",
      "Train Epoch: 88 [0/900 (0%)] Loss: -213854.984375\n",
      "Train Epoch: 88 [270/900 (30%)] Loss: -214274.109375\n",
      "Train Epoch: 88 [540/900 (60%)] Loss: -214154.781250\n",
      "Train Epoch: 88 [810/900 (90%)] Loss: -215096.406250\n",
      "    epoch          : 88\n",
      "    loss           : -214048.8203125\n",
      "    ess            : 7.8579174995422365\n",
      "    log_marginal   : 214049.11015625\n",
      "    val_loss       : -213665.46354166666\n",
      "    val_ess        : 7.305710315704346\n",
      "    val_log_marginal: 213665.81770833334\n",
      "Train Epoch: 89 [0/900 (0%)] Loss: -214907.109375\n",
      "Train Epoch: 89 [270/900 (30%)] Loss: -214927.046875\n",
      "Train Epoch: 89 [540/900 (60%)] Loss: -213046.890625\n",
      "Train Epoch: 89 [810/900 (90%)] Loss: -214187.359375\n",
      "    epoch          : 89\n",
      "    loss           : -214055.4234375\n",
      "    ess            : 7.685889101028442\n",
      "    log_marginal   : 214055.734375\n",
      "    val_loss       : -213478.50520833334\n",
      "    val_ess        : 7.787055969238281\n",
      "    val_log_marginal: 213478.734375\n",
      "Train Epoch: 90 [0/900 (0%)] Loss: -214920.953125\n",
      "Train Epoch: 90 [270/900 (30%)] Loss: -217088.578125\n",
      "Train Epoch: 90 [540/900 (60%)] Loss: -215547.875000\n",
      "Train Epoch: 90 [810/900 (90%)] Loss: -214763.531250\n",
      "    epoch          : 90\n",
      "    loss           : -214064.5453125\n",
      "    ess            : 7.708040022850037\n",
      "    log_marginal   : 214064.853125\n",
      "    val_loss       : -213292.89583333334\n",
      "    val_ess        : 7.337109088897705\n",
      "    val_log_marginal: 213293.44270833334\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch90.pth ...\n",
      "Train Epoch: 91 [0/900 (0%)] Loss: -213940.500000\n",
      "Train Epoch: 91 [270/900 (30%)] Loss: -215127.984375\n",
      "Train Epoch: 91 [540/900 (60%)] Loss: -215074.890625\n",
      "Train Epoch: 91 [810/900 (90%)] Loss: -212394.828125\n",
      "    epoch          : 91\n",
      "    loss           : -214067.48203125\n",
      "    ess            : 7.572081613540649\n",
      "    log_marginal   : 214067.81484375\n",
      "    val_loss       : -213970.66666666666\n",
      "    val_ess        : 7.030683676401774\n",
      "    val_log_marginal: 213971.19270833334\n",
      "Train Epoch: 92 [0/900 (0%)] Loss: -214925.921875\n",
      "Train Epoch: 92 [270/900 (30%)] Loss: -214234.000000\n",
      "Train Epoch: 92 [540/900 (60%)] Loss: -212849.984375\n",
      "Train Epoch: 92 [810/900 (90%)] Loss: -214797.921875\n",
      "    epoch          : 92\n",
      "    loss           : -214075.78671875\n",
      "    ess            : 7.629792380332947\n",
      "    log_marginal   : 214076.11484375\n",
      "    val_loss       : -214498.19791666666\n",
      "    val_ess        : 7.751222451527913\n",
      "    val_log_marginal: 214498.52604166666\n",
      "Train Epoch: 93 [0/900 (0%)] Loss: -213877.937500\n",
      "Train Epoch: 93 [270/900 (30%)] Loss: -214614.390625\n",
      "Train Epoch: 93 [540/900 (60%)] Loss: -216209.296875\n",
      "Train Epoch: 93 [810/900 (90%)] Loss: -213879.312500\n",
      "    epoch          : 93\n",
      "    loss           : -214080.06875\n",
      "    ess            : 7.625409555435181\n",
      "    log_marginal   : 214080.40234375\n",
      "    val_loss       : -213097.61458333334\n",
      "    val_ess        : 7.244280656178792\n",
      "    val_log_marginal: 213098.046875\n",
      "Train Epoch: 94 [0/900 (0%)] Loss: -213281.656250\n",
      "Train Epoch: 94 [270/900 (30%)] Loss: -214043.734375\n",
      "Train Epoch: 94 [540/900 (60%)] Loss: -216568.890625\n",
      "Train Epoch: 94 [810/900 (90%)] Loss: -212724.921875\n",
      "    epoch          : 94\n",
      "    loss           : -214084.0328125\n",
      "    ess            : 7.664706468582153\n",
      "    log_marginal   : 214084.3640625\n",
      "    val_loss       : -213822.83854166666\n",
      "    val_ess        : 7.486149946848552\n",
      "    val_log_marginal: 213823.17708333334\n",
      "Train Epoch: 95 [0/900 (0%)] Loss: -214236.671875\n",
      "Train Epoch: 95 [270/900 (30%)] Loss: -214089.406250\n",
      "Train Epoch: 95 [540/900 (60%)] Loss: -213546.093750\n",
      "Train Epoch: 95 [810/900 (90%)] Loss: -213886.156250\n",
      "    epoch          : 95\n",
      "    loss           : -214093.034375\n",
      "    ess            : 7.5791298151016235\n",
      "    log_marginal   : 214093.40703125\n",
      "    val_loss       : -214132.19270833334\n",
      "    val_ess        : 7.645144144694011\n",
      "    val_log_marginal: 214132.50520833334\n",
      "Train Epoch: 96 [0/900 (0%)] Loss: -214225.765625\n",
      "Train Epoch: 96 [270/900 (30%)] Loss: -213246.562500\n",
      "Train Epoch: 96 [540/900 (60%)] Loss: -213031.000000\n",
      "Train Epoch: 96 [810/900 (90%)] Loss: -215630.109375\n",
      "    epoch          : 96\n",
      "    loss           : -214099.2390625\n",
      "    ess            : 7.570619678497314\n",
      "    log_marginal   : 214099.60546875\n",
      "    val_loss       : -213149.83854166666\n",
      "    val_ess        : 7.667672952016194\n",
      "    val_log_marginal: 213150.10416666666\n",
      "Train Epoch: 97 [0/900 (0%)] Loss: -215405.500000\n",
      "Train Epoch: 97 [270/900 (30%)] Loss: -215245.156250\n",
      "Train Epoch: 97 [540/900 (60%)] Loss: -212594.953125\n",
      "Train Epoch: 97 [810/900 (90%)] Loss: -213893.812500\n",
      "    epoch          : 97\n",
      "    loss           : -214107.38359375\n",
      "    ess            : 7.663113617897034\n",
      "    log_marginal   : 214107.709375\n",
      "    val_loss       : -213654.875\n",
      "    val_ess        : 7.668266932169597\n",
      "    val_log_marginal: 213655.171875\n",
      "Train Epoch: 98 [0/900 (0%)] Loss: -213910.921875\n",
      "Train Epoch: 98 [270/900 (30%)] Loss: -212317.671875\n",
      "Train Epoch: 98 [540/900 (60%)] Loss: -213444.625000\n",
      "Train Epoch: 98 [810/900 (90%)] Loss: -215072.046875\n",
      "    epoch          : 98\n",
      "    loss           : -214112.99453125\n",
      "    ess            : 7.762027454376221\n",
      "    log_marginal   : 214113.30859375\n",
      "    val_loss       : -213597.30208333334\n",
      "    val_ess        : 7.321897824605306\n",
      "    val_log_marginal: 213597.61458333334\n",
      "Train Epoch: 99 [0/900 (0%)] Loss: -213164.156250\n",
      "Train Epoch: 99 [270/900 (30%)] Loss: -213993.609375\n",
      "Train Epoch: 99 [540/900 (60%)] Loss: -213932.984375\n",
      "Train Epoch: 99 [810/900 (90%)] Loss: -214448.937500\n",
      "    epoch          : 99\n",
      "    loss           : -214120.871875\n",
      "    ess            : 7.565671133995056\n",
      "    log_marginal   : 214121.23671875\n",
      "    val_loss       : -214810.63541666666\n",
      "    val_ess        : 7.644737243652344\n",
      "    val_log_marginal: 214810.99479166666\n",
      "Train Epoch: 100 [0/900 (0%)] Loss: -214331.781250\n",
      "Train Epoch: 100 [270/900 (30%)] Loss: -215286.109375\n",
      "Train Epoch: 100 [540/900 (60%)] Loss: -211783.187500\n",
      "Train Epoch: 100 [810/900 (90%)] Loss: -214227.203125\n",
      "    epoch          : 100\n",
      "    loss           : -214130.74921875\n",
      "    ess            : 7.503478050231934\n",
      "    log_marginal   : 214131.1234375\n",
      "    val_loss       : -213426.96354166666\n",
      "    val_ess        : 7.513208230336507\n",
      "    val_log_marginal: 213427.328125\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [0/900 (0%)] Loss: -214455.531250\n",
      "Train Epoch: 101 [270/900 (30%)] Loss: -215240.953125\n",
      "Train Epoch: 101 [540/900 (60%)] Loss: -214930.140625\n",
      "Train Epoch: 101 [810/900 (90%)] Loss: -213405.953125\n",
      "    epoch          : 101\n",
      "    loss           : -214139.478125\n",
      "    ess            : 7.630496311187744\n",
      "    log_marginal   : 214139.80703125\n",
      "    val_loss       : -215291.828125\n",
      "    val_ess        : 7.5480499267578125\n",
      "    val_log_marginal: 215292.11458333334\n",
      "Train Epoch: 102 [0/900 (0%)] Loss: -213717.984375\n",
      "Train Epoch: 102 [270/900 (30%)] Loss: -213840.609375\n",
      "Train Epoch: 102 [540/900 (60%)] Loss: -212996.687500\n",
      "Train Epoch: 102 [810/900 (90%)] Loss: -216419.718750\n",
      "    epoch          : 102\n",
      "    loss           : -214147.340625\n",
      "    ess            : 7.574316310882568\n",
      "    log_marginal   : 214147.70859375\n",
      "    val_loss       : -213212.265625\n",
      "    val_ess        : 7.699339548746745\n",
      "    val_log_marginal: 213212.58333333334\n",
      "Train Epoch: 103 [0/900 (0%)] Loss: -215715.937500\n",
      "Train Epoch: 103 [270/900 (30%)] Loss: -213474.625000\n",
      "Train Epoch: 103 [540/900 (60%)] Loss: -214547.609375\n",
      "Train Epoch: 103 [810/900 (90%)] Loss: -215316.843750\n",
      "    epoch          : 103\n",
      "    loss           : -214156.0953125\n",
      "    ess            : 7.645467901229859\n",
      "    log_marginal   : 214156.425\n",
      "    val_loss       : -213275.11979166666\n",
      "    val_ess        : 7.616532961527507\n",
      "    val_log_marginal: 213275.44791666666\n",
      "Train Epoch: 104 [0/900 (0%)] Loss: -214610.359375\n",
      "Train Epoch: 104 [270/900 (30%)] Loss: -215219.359375\n",
      "Train Epoch: 104 [540/900 (60%)] Loss: -213643.187500\n",
      "Train Epoch: 104 [810/900 (90%)] Loss: -215044.312500\n",
      "    epoch          : 104\n",
      "    loss           : -214159.93984375\n",
      "    ess            : 7.6672313690185545\n",
      "    log_marginal   : 214160.27109375\n",
      "    val_loss       : -214030.52083333334\n",
      "    val_ess        : 7.359177271525065\n",
      "    val_log_marginal: 214030.90104166666\n",
      "Train Epoch: 105 [0/900 (0%)] Loss: -212988.156250\n",
      "Train Epoch: 105 [270/900 (30%)] Loss: -213039.718750\n",
      "Train Epoch: 105 [540/900 (60%)] Loss: -213802.843750\n",
      "Train Epoch: 105 [810/900 (90%)] Loss: -215719.453125\n",
      "    epoch          : 105\n",
      "    loss           : -214166.9578125\n",
      "    ess            : 7.598829913139343\n",
      "    log_marginal   : 214167.328125\n",
      "    val_loss       : -213249.75520833334\n",
      "    val_ess        : 7.428508122762044\n",
      "    val_log_marginal: 213250.08854166666\n",
      "Train Epoch: 106 [0/900 (0%)] Loss: -214419.031250\n",
      "Train Epoch: 106 [270/900 (30%)] Loss: -214196.562500\n",
      "Train Epoch: 106 [540/900 (60%)] Loss: -214129.312500\n",
      "Train Epoch: 106 [810/900 (90%)] Loss: -213974.515625\n",
      "    epoch          : 106\n",
      "    loss           : -214175.17421875\n",
      "    ess            : 7.738267040252685\n",
      "    log_marginal   : 214175.46484375\n",
      "    val_loss       : -212465.203125\n",
      "    val_ess        : 7.74760627746582\n",
      "    val_log_marginal: 212465.44791666666\n",
      "Train Epoch: 107 [0/900 (0%)] Loss: -212066.406250\n",
      "Train Epoch: 107 [270/900 (30%)] Loss: -213502.875000\n",
      "Train Epoch: 107 [540/900 (60%)] Loss: -215280.468750\n",
      "Train Epoch: 107 [810/900 (90%)] Loss: -215503.265625\n",
      "    epoch          : 107\n",
      "    loss           : -214175.66640625\n",
      "    ess            : 7.695526146888733\n",
      "    log_marginal   : 214176.003125\n",
      "    val_loss       : -212725.90104166666\n",
      "    val_ess        : 7.265620708465576\n",
      "    val_log_marginal: 212726.29166666666\n",
      "Train Epoch: 108 [0/900 (0%)] Loss: -213855.765625\n",
      "Train Epoch: 108 [270/900 (30%)] Loss: -214260.781250\n",
      "Train Epoch: 108 [540/900 (60%)] Loss: -214758.921875\n",
      "Train Epoch: 108 [810/900 (90%)] Loss: -215355.187500\n",
      "    epoch          : 108\n",
      "    loss           : -214182.2640625\n",
      "    ess            : 7.5014231443405155\n",
      "    log_marginal   : 214182.61484375\n",
      "    val_loss       : -214440.31770833334\n",
      "    val_ess        : 7.42547607421875\n",
      "    val_log_marginal: 214440.78125\n",
      "Train Epoch: 109 [0/900 (0%)] Loss: -215295.187500\n",
      "Train Epoch: 109 [270/900 (30%)] Loss: -213525.500000\n",
      "Train Epoch: 109 [540/900 (60%)] Loss: -215102.140625\n",
      "Train Epoch: 109 [810/900 (90%)] Loss: -213567.296875\n",
      "    epoch          : 109\n",
      "    loss           : -214191.78671875\n",
      "    ess            : 7.74687819480896\n",
      "    log_marginal   : 214192.10625\n",
      "    val_loss       : -214130.68229166666\n",
      "    val_ess        : 7.866960525512695\n",
      "    val_log_marginal: 214131.08333333334\n",
      "Train Epoch: 110 [0/900 (0%)] Loss: -213431.359375\n",
      "Train Epoch: 110 [270/900 (30%)] Loss: -215887.093750\n",
      "Train Epoch: 110 [540/900 (60%)] Loss: -214521.718750\n",
      "Train Epoch: 110 [810/900 (90%)] Loss: -215659.765625\n",
      "    epoch          : 110\n",
      "    loss           : -214197.40703125\n",
      "    ess            : 7.696062541007995\n",
      "    log_marginal   : 214197.71796875\n",
      "    val_loss       : -214581.890625\n",
      "    val_ess        : 7.526234149932861\n",
      "    val_log_marginal: 214582.17708333334\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch110.pth ...\n",
      "Train Epoch: 111 [0/900 (0%)] Loss: -213403.921875\n",
      "Train Epoch: 111 [270/900 (30%)] Loss: -214566.562500\n",
      "Train Epoch: 111 [540/900 (60%)] Loss: -214263.468750\n",
      "Train Epoch: 111 [810/900 (90%)] Loss: -214166.921875\n",
      "    epoch          : 111\n",
      "    loss           : -214192.70234375\n",
      "    ess            : 7.68262734413147\n",
      "    log_marginal   : 214193.0328125\n",
      "    val_loss       : -214222.21875\n",
      "    val_ess        : 7.435145854949951\n",
      "    val_log_marginal: 214222.67708333334\n",
      "Train Epoch: 112 [0/900 (0%)] Loss: -214171.671875\n",
      "Train Epoch: 112 [270/900 (30%)] Loss: -211831.765625\n",
      "Train Epoch: 112 [540/900 (60%)] Loss: -213027.390625\n",
      "Train Epoch: 112 [810/900 (90%)] Loss: -215449.671875\n",
      "    epoch          : 112\n",
      "    loss           : -214202.26796875\n",
      "    ess            : 7.76263952255249\n",
      "    log_marginal   : 214202.58515625\n",
      "    val_loss       : -213539.96354166666\n",
      "    val_ess        : 7.516910711924235\n",
      "    val_log_marginal: 213540.31770833334\n",
      "Train Epoch: 113 [0/900 (0%)] Loss: -213700.312500\n",
      "Train Epoch: 113 [270/900 (30%)] Loss: -213685.656250\n",
      "Train Epoch: 113 [540/900 (60%)] Loss: -214042.203125\n",
      "Train Epoch: 113 [810/900 (90%)] Loss: -214855.343750\n",
      "    epoch          : 113\n",
      "    loss           : -214207.15625\n",
      "    ess            : 7.61912784576416\n",
      "    log_marginal   : 214207.515625\n",
      "    val_loss       : -212700.28645833334\n",
      "    val_ess        : 7.226622899373372\n",
      "    val_log_marginal: 212700.65104166666\n",
      "Train Epoch: 114 [0/900 (0%)] Loss: -213771.625000\n",
      "Train Epoch: 114 [270/900 (30%)] Loss: -215418.828125\n",
      "Train Epoch: 114 [540/900 (60%)] Loss: -214044.078125\n",
      "Train Epoch: 114 [810/900 (90%)] Loss: -215129.031250\n",
      "    epoch          : 114\n",
      "    loss           : -214216.0875\n",
      "    ess            : 7.582056927680969\n",
      "    log_marginal   : 214216.41953125\n",
      "    val_loss       : -213315.36979166666\n",
      "    val_ess        : 7.517857074737549\n",
      "    val_log_marginal: 213315.71875\n",
      "Train Epoch: 115 [0/900 (0%)] Loss: -215782.515625\n",
      "Train Epoch: 115 [270/900 (30%)] Loss: -213967.406250\n",
      "Train Epoch: 115 [540/900 (60%)] Loss: -213584.984375\n",
      "Train Epoch: 115 [810/900 (90%)] Loss: -213850.781250\n",
      "    epoch          : 115\n",
      "    loss           : -214223.59609375\n",
      "    ess            : 7.530340385437012\n",
      "    log_marginal   : 214223.9828125\n",
      "    val_loss       : -213863.24479166666\n",
      "    val_ess        : 7.86747678120931\n",
      "    val_log_marginal: 213863.52083333334\n",
      "Train Epoch: 116 [0/900 (0%)] Loss: -212975.656250\n",
      "Train Epoch: 116 [270/900 (30%)] Loss: -213618.781250\n",
      "Train Epoch: 116 [540/900 (60%)] Loss: -214412.078125\n",
      "Train Epoch: 116 [810/900 (90%)] Loss: -214797.343750\n",
      "    epoch          : 116\n",
      "    loss           : -214236.28984375\n",
      "    ess            : 7.792009449005127\n",
      "    log_marginal   : 214236.60078125\n",
      "    val_loss       : -214769.02604166666\n",
      "    val_ess        : 7.509720166524251\n",
      "    val_log_marginal: 214769.34375\n",
      "Train Epoch: 117 [0/900 (0%)] Loss: -212702.765625\n",
      "Train Epoch: 117 [270/900 (30%)] Loss: -212633.515625\n",
      "Train Epoch: 117 [540/900 (60%)] Loss: -215522.890625\n",
      "Train Epoch: 117 [810/900 (90%)] Loss: -214445.843750\n",
      "    epoch          : 117\n",
      "    loss           : -214244.925\n",
      "    ess            : 7.638697147369385\n",
      "    log_marginal   : 214245.2671875\n",
      "    val_loss       : -214442.21354166666\n",
      "    val_ess        : 7.436882336934407\n",
      "    val_log_marginal: 214442.55208333334\n",
      "Train Epoch: 118 [0/900 (0%)] Loss: -214805.093750\n",
      "Train Epoch: 118 [270/900 (30%)] Loss: -211917.875000\n",
      "Train Epoch: 118 [540/900 (60%)] Loss: -214724.953125\n",
      "Train Epoch: 118 [810/900 (90%)] Loss: -214563.046875\n",
      "    epoch          : 118\n",
      "    loss           : -214253.78828125\n",
      "    ess            : 7.757883906364441\n",
      "    log_marginal   : 214254.0796875\n",
      "    val_loss       : -214581.015625\n",
      "    val_ess        : 6.9380442301432295\n",
      "    val_log_marginal: 214581.43229166666\n",
      "Train Epoch: 119 [0/900 (0%)] Loss: -215185.781250\n",
      "Train Epoch: 119 [270/900 (30%)] Loss: -212899.031250\n",
      "Train Epoch: 119 [540/900 (60%)] Loss: -216179.734375\n",
      "Train Epoch: 119 [810/900 (90%)] Loss: -214428.343750\n",
      "    epoch          : 119\n",
      "    loss           : -214259.7203125\n",
      "    ess            : 7.638240385055542\n",
      "    log_marginal   : 214260.06640625\n",
      "    val_loss       : -214187.69791666666\n",
      "    val_ess        : 7.990377744038899\n",
      "    val_log_marginal: 214187.92708333334\n",
      "Train Epoch: 120 [0/900 (0%)] Loss: -214555.718750\n",
      "Train Epoch: 120 [270/900 (30%)] Loss: -215282.890625\n",
      "Train Epoch: 120 [540/900 (60%)] Loss: -214507.531250\n",
      "Train Epoch: 120 [810/900 (90%)] Loss: -213267.000000\n",
      "    epoch          : 120\n",
      "    loss           : -214266.9765625\n",
      "    ess            : 7.651251196861267\n",
      "    log_marginal   : 214267.284375\n",
      "    val_loss       : -213868.97395833334\n",
      "    val_ess        : 8.449941953023275\n",
      "    val_log_marginal: 213869.13541666666\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch120.pth ...\n",
      "Train Epoch: 121 [0/900 (0%)] Loss: -215635.500000\n",
      "Train Epoch: 121 [270/900 (30%)] Loss: -211792.781250\n",
      "Train Epoch: 121 [540/900 (60%)] Loss: -216291.187500\n",
      "Train Epoch: 121 [810/900 (90%)] Loss: -214571.187500\n",
      "    epoch          : 121\n",
      "    loss           : -214267.36953125\n",
      "    ess            : 7.551440334320068\n",
      "    log_marginal   : 214267.725\n",
      "    val_loss       : -214883.25520833334\n",
      "    val_ess        : 7.576964060465495\n",
      "    val_log_marginal: 214883.58333333334\n",
      "Train Epoch: 122 [0/900 (0%)] Loss: -214499.781250\n",
      "Train Epoch: 122 [270/900 (30%)] Loss: -214263.687500\n",
      "Train Epoch: 122 [540/900 (60%)] Loss: -214458.265625\n",
      "Train Epoch: 122 [810/900 (90%)] Loss: -215050.296875\n",
      "    epoch          : 122\n",
      "    loss           : -214273.57109375\n",
      "    ess            : 7.675595235824585\n",
      "    log_marginal   : 214273.8859375\n",
      "    val_loss       : -213312.25520833334\n",
      "    val_ess        : 7.100573698679606\n",
      "    val_log_marginal: 213312.6875\n",
      "Train Epoch: 123 [0/900 (0%)] Loss: -212309.812500\n",
      "Train Epoch: 123 [270/900 (30%)] Loss: -213319.296875\n",
      "Train Epoch: 123 [540/900 (60%)] Loss: -214528.359375\n",
      "Train Epoch: 123 [810/900 (90%)] Loss: -212680.156250\n",
      "    epoch          : 123\n",
      "    loss           : -214281.40859375\n",
      "    ess            : 7.701449894905091\n",
      "    log_marginal   : 214281.728125\n",
      "    val_loss       : -214834.40104166666\n",
      "    val_ess        : 7.473616600036621\n",
      "    val_log_marginal: 214834.72916666666\n",
      "Train Epoch: 124 [0/900 (0%)] Loss: -213000.031250\n",
      "Train Epoch: 124 [270/900 (30%)] Loss: -215409.843750\n",
      "Train Epoch: 124 [540/900 (60%)] Loss: -214924.312500\n",
      "Train Epoch: 124 [810/900 (90%)] Loss: -215356.578125\n",
      "    epoch          : 124\n",
      "    loss           : -214288.82890625\n",
      "    ess            : 7.725595760345459\n",
      "    log_marginal   : 214289.14609375\n",
      "    val_loss       : -213658.83333333334\n",
      "    val_ess        : 7.267402807871501\n",
      "    val_log_marginal: 213659.203125\n",
      "Train Epoch: 125 [0/900 (0%)] Loss: -216542.156250\n",
      "Train Epoch: 125 [270/900 (30%)] Loss: -212293.093750\n",
      "Train Epoch: 125 [540/900 (60%)] Loss: -215596.265625\n",
      "Train Epoch: 125 [810/900 (90%)] Loss: -213819.625000\n",
      "    epoch          : 125\n",
      "    loss           : -214292.78203125\n",
      "    ess            : 7.52178909778595\n",
      "    log_marginal   : 214293.13046875\n",
      "    val_loss       : -213693.140625\n",
      "    val_ess        : 7.787038644154866\n",
      "    val_log_marginal: 213693.41666666666\n",
      "Train Epoch: 126 [0/900 (0%)] Loss: -213913.234375\n",
      "Train Epoch: 126 [270/900 (30%)] Loss: -216093.937500\n",
      "Train Epoch: 126 [540/900 (60%)] Loss: -215440.828125\n",
      "Train Epoch: 126 [810/900 (90%)] Loss: -215574.234375\n",
      "    epoch          : 126\n",
      "    loss           : -214295.91875\n",
      "    ess            : 7.633781003952026\n",
      "    log_marginal   : 214296.2296875\n",
      "    val_loss       : -214144.48958333334\n",
      "    val_ess        : 7.5663119951883955\n",
      "    val_log_marginal: 214144.78645833334\n",
      "Train Epoch: 127 [0/900 (0%)] Loss: -212983.828125\n",
      "Train Epoch: 127 [270/900 (30%)] Loss: -214679.765625\n",
      "Train Epoch: 127 [540/900 (60%)] Loss: -213851.875000\n",
      "Train Epoch: 127 [810/900 (90%)] Loss: -213175.765625\n",
      "    epoch          : 127\n",
      "    loss           : -214300.7515625\n",
      "    ess            : 7.541728401184082\n",
      "    log_marginal   : 214301.103125\n",
      "    val_loss       : -213458.91145833334\n",
      "    val_ess        : 7.471093495686849\n",
      "    val_log_marginal: 213459.25\n",
      "Train Epoch: 128 [0/900 (0%)] Loss: -215315.625000\n",
      "Train Epoch: 128 [270/900 (30%)] Loss: -213390.250000\n",
      "Train Epoch: 128 [540/900 (60%)] Loss: -213912.421875\n",
      "Train Epoch: 128 [810/900 (90%)] Loss: -215210.359375\n",
      "    epoch          : 128\n",
      "    loss           : -214301.68125\n",
      "    ess            : 7.648366475105286\n",
      "    log_marginal   : 214302.02578125\n",
      "    val_loss       : -212568.67708333334\n",
      "    val_ess        : 7.397067546844482\n",
      "    val_log_marginal: 212569.04166666666\n",
      "Train Epoch: 129 [0/900 (0%)] Loss: -215878.078125\n",
      "Train Epoch: 129 [270/900 (30%)] Loss: -214377.843750\n",
      "Train Epoch: 129 [540/900 (60%)] Loss: -214502.671875\n",
      "Train Epoch: 129 [810/900 (90%)] Loss: -214481.718750\n",
      "    epoch          : 129\n",
      "    loss           : -214312.175\n",
      "    ess            : 7.71507773399353\n",
      "    log_marginal   : 214312.471875\n",
      "    val_loss       : -213579.98958333334\n",
      "    val_ess        : 7.9793141682942705\n",
      "    val_log_marginal: 213580.27083333334\n",
      "Train Epoch: 130 [0/900 (0%)] Loss: -211868.875000\n",
      "Train Epoch: 130 [270/900 (30%)] Loss: -213885.828125\n",
      "Train Epoch: 130 [540/900 (60%)] Loss: -214652.312500\n",
      "Train Epoch: 130 [810/900 (90%)] Loss: -213583.265625\n",
      "    epoch          : 130\n",
      "    loss           : -214323.3671875\n",
      "    ess            : 7.698133778572083\n",
      "    log_marginal   : 214323.671875\n",
      "    val_loss       : -214392.60416666666\n",
      "    val_ess        : 7.468428770701091\n",
      "    val_log_marginal: 214393.08333333334\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch130.pth ...\n",
      "Train Epoch: 131 [0/900 (0%)] Loss: -214938.359375\n",
      "Train Epoch: 131 [270/900 (30%)] Loss: -213547.421875\n",
      "Train Epoch: 131 [540/900 (60%)] Loss: -213600.343750\n",
      "Train Epoch: 131 [810/900 (90%)] Loss: -213585.421875\n",
      "    epoch          : 131\n",
      "    loss           : -214331.4265625\n",
      "    ess            : 7.8280720710754395\n",
      "    log_marginal   : 214331.73359375\n",
      "    val_loss       : -212982.06770833334\n",
      "    val_ess        : 7.53277047475179\n",
      "    val_log_marginal: 212982.4375\n",
      "Train Epoch: 132 [0/900 (0%)] Loss: -216416.109375\n",
      "Train Epoch: 132 [270/900 (30%)] Loss: -213992.343750\n",
      "Train Epoch: 132 [540/900 (60%)] Loss: -212932.531250\n",
      "Train Epoch: 132 [810/900 (90%)] Loss: -214117.812500\n",
      "    epoch          : 132\n",
      "    loss           : -214333.846875\n",
      "    ess            : 7.601157999038696\n",
      "    log_marginal   : 214334.19140625\n",
      "    val_loss       : -215249.74479166666\n",
      "    val_ess        : 8.139492193857828\n",
      "    val_log_marginal: 215249.94270833334\n",
      "Train Epoch: 133 [0/900 (0%)] Loss: -214798.296875\n",
      "Train Epoch: 133 [270/900 (30%)] Loss: -214509.031250\n",
      "Train Epoch: 133 [540/900 (60%)] Loss: -214589.093750\n",
      "Train Epoch: 133 [810/900 (90%)] Loss: -214218.781250\n",
      "    epoch          : 133\n",
      "    loss           : -214343.04921875\n",
      "    ess            : 7.556400012969971\n",
      "    log_marginal   : 214343.3921875\n",
      "    val_loss       : -214388.765625\n",
      "    val_ess        : 7.394101460774739\n",
      "    val_log_marginal: 214389.21354166666\n",
      "Train Epoch: 134 [0/900 (0%)] Loss: -214922.781250\n",
      "Train Epoch: 134 [270/900 (30%)] Loss: -216175.468750\n",
      "Train Epoch: 134 [540/900 (60%)] Loss: -214976.531250\n",
      "Train Epoch: 134 [810/900 (90%)] Loss: -215573.421875\n",
      "    epoch          : 134\n",
      "    loss           : -214349.31640625\n",
      "    ess            : 7.663607668876648\n",
      "    log_marginal   : 214349.6296875\n",
      "    val_loss       : -213496.51041666666\n",
      "    val_ess        : 7.806800365447998\n",
      "    val_log_marginal: 213496.796875\n",
      "Train Epoch: 135 [0/900 (0%)] Loss: -214353.000000\n",
      "Train Epoch: 135 [270/900 (30%)] Loss: -213965.875000\n",
      "Train Epoch: 135 [540/900 (60%)] Loss: -213595.140625\n",
      "Train Epoch: 135 [810/900 (90%)] Loss: -213585.109375\n",
      "    epoch          : 135\n",
      "    loss           : -214352.01171875\n",
      "    ess            : 7.69086902141571\n",
      "    log_marginal   : 214352.30078125\n",
      "    val_loss       : -215005.33854166666\n",
      "    val_ess        : 7.658182303110759\n",
      "    val_log_marginal: 215005.70833333334\n",
      "Train Epoch: 136 [0/900 (0%)] Loss: -213408.515625\n",
      "Train Epoch: 136 [270/900 (30%)] Loss: -215052.343750\n",
      "Train Epoch: 136 [540/900 (60%)] Loss: -214922.390625\n",
      "Train Epoch: 136 [810/900 (90%)] Loss: -215749.078125\n",
      "    epoch          : 136\n",
      "    loss           : -214358.2234375\n",
      "    ess            : 7.590164828300476\n",
      "    log_marginal   : 214358.57421875\n",
      "    val_loss       : -214173.578125\n",
      "    val_ess        : 7.395020484924316\n",
      "    val_log_marginal: 214173.90104166666\n",
      "Train Epoch: 137 [0/900 (0%)] Loss: -214498.828125\n",
      "Train Epoch: 137 [270/900 (30%)] Loss: -213408.843750\n",
      "Train Epoch: 137 [540/900 (60%)] Loss: -215968.156250\n",
      "Train Epoch: 137 [810/900 (90%)] Loss: -215306.359375\n",
      "    epoch          : 137\n",
      "    loss           : -214360.71328125\n",
      "    ess            : 7.637743210792541\n",
      "    log_marginal   : 214361.04765625\n",
      "    val_loss       : -214085.46875\n",
      "    val_ess        : 7.956641515096028\n",
      "    val_log_marginal: 214085.86979166666\n",
      "Train Epoch: 138 [0/900 (0%)] Loss: -212938.468750\n",
      "Train Epoch: 138 [270/900 (30%)] Loss: -214318.203125\n",
      "Train Epoch: 138 [540/900 (60%)] Loss: -215643.140625\n",
      "Train Epoch: 138 [810/900 (90%)] Loss: -213575.000000\n",
      "    epoch          : 138\n",
      "    loss           : -214367.596875\n",
      "    ess            : 7.580141854286194\n",
      "    log_marginal   : 214367.96640625\n",
      "    val_loss       : -214216.69270833334\n",
      "    val_ess        : 7.717916170756022\n",
      "    val_log_marginal: 214217.046875\n",
      "Train Epoch: 139 [0/900 (0%)] Loss: -214922.531250\n",
      "Train Epoch: 139 [270/900 (30%)] Loss: -215118.296875\n",
      "Train Epoch: 139 [540/900 (60%)] Loss: -214928.953125\n",
      "Train Epoch: 139 [810/900 (90%)] Loss: -214677.453125\n",
      "    epoch          : 139\n",
      "    loss           : -214369.2453125\n",
      "    ess            : 7.772417902946472\n",
      "    log_marginal   : 214369.5703125\n",
      "    val_loss       : -212332.30208333334\n",
      "    val_ess        : 7.7794121106465655\n",
      "    val_log_marginal: 212332.5625\n",
      "Train Epoch: 140 [0/900 (0%)] Loss: -213537.890625\n",
      "Train Epoch: 140 [270/900 (30%)] Loss: -213546.921875\n",
      "Train Epoch: 140 [540/900 (60%)] Loss: -214958.734375\n",
      "Train Epoch: 140 [810/900 (90%)] Loss: -212752.421875\n",
      "    epoch          : 140\n",
      "    loss           : -214379.9578125\n",
      "    ess            : 7.686829280853272\n",
      "    log_marginal   : 214380.3\n",
      "    val_loss       : -213471.35416666666\n",
      "    val_ess        : 7.281359990437825\n",
      "    val_log_marginal: 213471.80729166666\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch140.pth ...\n",
      "Train Epoch: 141 [0/900 (0%)] Loss: -213631.609375\n",
      "Train Epoch: 141 [270/900 (30%)] Loss: -213875.109375\n",
      "Train Epoch: 141 [540/900 (60%)] Loss: -212121.250000\n",
      "Train Epoch: 141 [810/900 (90%)] Loss: -215079.296875\n",
      "    epoch          : 141\n",
      "    loss           : -214383.80078125\n",
      "    ess            : 7.785597944259644\n",
      "    log_marginal   : 214384.0953125\n",
      "    val_loss       : -215546.078125\n",
      "    val_ess        : 7.222860336303711\n",
      "    val_log_marginal: 215546.47916666666\n",
      "Train Epoch: 142 [0/900 (0%)] Loss: -214184.234375\n",
      "Train Epoch: 142 [270/900 (30%)] Loss: -212405.140625\n",
      "Train Epoch: 142 [540/900 (60%)] Loss: -217396.781250\n",
      "Train Epoch: 142 [810/900 (90%)] Loss: -214567.578125\n",
      "    epoch          : 142\n",
      "    loss           : -214385.34375\n",
      "    ess            : 7.673137545585632\n",
      "    log_marginal   : 214385.66953125\n",
      "    val_loss       : -214087.140625\n",
      "    val_ess        : 7.640596707661946\n",
      "    val_log_marginal: 214087.64583333334\n",
      "Train Epoch: 143 [0/900 (0%)] Loss: -211780.984375\n",
      "Train Epoch: 143 [270/900 (30%)] Loss: -212470.343750\n",
      "Train Epoch: 143 [540/900 (60%)] Loss: -214735.156250\n",
      "Train Epoch: 143 [810/900 (90%)] Loss: -215642.078125\n",
      "    epoch          : 143\n",
      "    loss           : -214393.69921875\n",
      "    ess            : 7.630691480636597\n",
      "    log_marginal   : 214394.028125\n",
      "    val_loss       : -213892.140625\n",
      "    val_ess        : 7.321376323699951\n",
      "    val_log_marginal: 213892.52083333334\n",
      "Train Epoch: 144 [0/900 (0%)] Loss: -214723.468750\n",
      "Train Epoch: 144 [270/900 (30%)] Loss: -211646.203125\n",
      "Train Epoch: 144 [540/900 (60%)] Loss: -215317.812500\n",
      "Train Epoch: 144 [810/900 (90%)] Loss: -212374.828125\n",
      "    epoch          : 144\n",
      "    loss           : -214406.35078125\n",
      "    ess            : 7.691435527801514\n",
      "    log_marginal   : 214406.68125\n",
      "    val_loss       : -215037.86979166666\n",
      "    val_ess        : 7.807871182759603\n",
      "    val_log_marginal: 215038.31770833334\n",
      "Train Epoch: 145 [0/900 (0%)] Loss: -213440.156250\n",
      "Train Epoch: 145 [270/900 (30%)] Loss: -212896.250000\n",
      "Train Epoch: 145 [540/900 (60%)] Loss: -213949.734375\n",
      "Train Epoch: 145 [810/900 (90%)] Loss: -213434.500000\n",
      "    epoch          : 145\n",
      "    loss           : -214411.36484375\n",
      "    ess            : 7.75055763721466\n",
      "    log_marginal   : 214411.6609375\n",
      "    val_loss       : -213176.50520833334\n",
      "    val_ess        : 7.365526040395101\n",
      "    val_log_marginal: 213176.828125\n",
      "Train Epoch: 146 [0/900 (0%)] Loss: -215966.109375\n",
      "Train Epoch: 146 [270/900 (30%)] Loss: -214425.921875\n",
      "Train Epoch: 146 [540/900 (60%)] Loss: -214942.265625\n",
      "Train Epoch: 146 [810/900 (90%)] Loss: -214674.187500\n",
      "    epoch          : 146\n",
      "    loss           : -214419.0640625\n",
      "    ess            : 7.7572307109832765\n",
      "    log_marginal   : 214419.38046875\n",
      "    val_loss       : -215186.93229166666\n",
      "    val_ess        : 7.8195648193359375\n",
      "    val_log_marginal: 215187.171875\n",
      "Train Epoch: 147 [0/900 (0%)] Loss: -214411.812500\n",
      "Train Epoch: 147 [270/900 (30%)] Loss: -214913.296875\n",
      "Train Epoch: 147 [540/900 (60%)] Loss: -216733.812500\n",
      "Train Epoch: 147 [810/900 (90%)] Loss: -215630.890625\n",
      "    epoch          : 147\n",
      "    loss           : -214423.31328125\n",
      "    ess            : 7.604985928535461\n",
      "    log_marginal   : 214423.6875\n",
      "    val_loss       : -212951.43229166666\n",
      "    val_ess        : 7.217250982920329\n",
      "    val_log_marginal: 212951.83854166666\n",
      "Train Epoch: 148 [0/900 (0%)] Loss: -214167.625000\n",
      "Train Epoch: 148 [270/900 (30%)] Loss: -214071.500000\n",
      "Train Epoch: 148 [540/900 (60%)] Loss: -215538.000000\n",
      "Train Epoch: 148 [810/900 (90%)] Loss: -214350.453125\n",
      "    epoch          : 148\n",
      "    loss           : -214427.11953125\n",
      "    ess            : 7.724193978309631\n",
      "    log_marginal   : 214427.446875\n",
      "    val_loss       : -214487.68229166666\n",
      "    val_ess        : 8.21998643875122\n",
      "    val_log_marginal: 214488.00520833334\n",
      "Train Epoch: 149 [0/900 (0%)] Loss: -211054.531250\n",
      "Train Epoch: 149 [270/900 (30%)] Loss: -215840.781250\n",
      "Train Epoch: 149 [540/900 (60%)] Loss: -214313.468750\n",
      "Train Epoch: 149 [810/900 (90%)] Loss: -215806.203125\n",
      "    epoch          : 149\n",
      "    loss           : -214441.6703125\n",
      "    ess            : 7.703202891349792\n",
      "    log_marginal   : 214441.996875\n",
      "    val_loss       : -213730.72395833334\n",
      "    val_ess        : 7.139682451883952\n",
      "    val_log_marginal: 213731.11458333334\n",
      "Train Epoch: 150 [0/900 (0%)] Loss: -213386.781250\n",
      "Train Epoch: 150 [270/900 (30%)] Loss: -216064.187500\n",
      "Train Epoch: 150 [540/900 (60%)] Loss: -215587.531250\n",
      "Train Epoch: 150 [810/900 (90%)] Loss: -213275.609375\n",
      "    epoch          : 150\n",
      "    loss           : -214446.56015625\n",
      "    ess            : 7.644520401954651\n",
      "    log_marginal   : 214446.86796875\n",
      "    val_loss       : -215087.609375\n",
      "    val_ess        : 7.22141170501709\n",
      "    val_log_marginal: 215088.02604166666\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch150.pth ...\n",
      "Train Epoch: 151 [0/900 (0%)] Loss: -215363.562500\n",
      "Train Epoch: 151 [270/900 (30%)] Loss: -216812.140625\n",
      "Train Epoch: 151 [540/900 (60%)] Loss: -214597.875000\n",
      "Train Epoch: 151 [810/900 (90%)] Loss: -215039.296875\n",
      "    epoch          : 151\n",
      "    loss           : -214454.95703125\n",
      "    ess            : 7.739151430130005\n",
      "    log_marginal   : 214455.2640625\n",
      "    val_loss       : -214055.765625\n",
      "    val_ess        : 7.8285441398620605\n",
      "    val_log_marginal: 214056.07291666666\n",
      "Train Epoch: 152 [0/900 (0%)] Loss: -215344.828125\n",
      "Train Epoch: 152 [270/900 (30%)] Loss: -215022.203125\n",
      "Train Epoch: 152 [540/900 (60%)] Loss: -215148.187500\n",
      "Train Epoch: 152 [810/900 (90%)] Loss: -215579.421875\n",
      "    epoch          : 152\n",
      "    loss           : -214460.30625\n",
      "    ess            : 7.685211277008056\n",
      "    log_marginal   : 214460.64375\n",
      "    val_loss       : -213792.40104166666\n",
      "    val_ess        : 7.258214155832927\n",
      "    val_log_marginal: 213792.859375\n",
      "Train Epoch: 153 [0/900 (0%)] Loss: -213865.468750\n",
      "Train Epoch: 153 [270/900 (30%)] Loss: -213823.468750\n",
      "Train Epoch: 153 [540/900 (60%)] Loss: -215745.359375\n",
      "Train Epoch: 153 [810/900 (90%)] Loss: -214183.828125\n",
      "    epoch          : 153\n",
      "    loss           : -214466.99765625\n",
      "    ess            : 7.771321868896484\n",
      "    log_marginal   : 214467.28125\n",
      "    val_loss       : -213751.015625\n",
      "    val_ess        : 7.37069304784139\n",
      "    val_log_marginal: 213751.40104166666\n",
      "Train Epoch: 154 [0/900 (0%)] Loss: -216549.953125\n",
      "Train Epoch: 154 [270/900 (30%)] Loss: -214294.390625\n",
      "Train Epoch: 154 [540/900 (60%)] Loss: -215297.406250\n",
      "Train Epoch: 154 [810/900 (90%)] Loss: -213668.531250\n",
      "    epoch          : 154\n",
      "    loss           : -214472.975\n",
      "    ess            : 7.641787314414978\n",
      "    log_marginal   : 214473.31171875\n",
      "    val_loss       : -215214.35416666666\n",
      "    val_ess        : 7.757184028625488\n",
      "    val_log_marginal: 215214.61979166666\n",
      "Train Epoch: 155 [0/900 (0%)] Loss: -213996.093750\n",
      "Train Epoch: 155 [270/900 (30%)] Loss: -214464.000000\n",
      "Train Epoch: 155 [540/900 (60%)] Loss: -213575.812500\n",
      "Train Epoch: 155 [810/900 (90%)] Loss: -215949.140625\n",
      "    epoch          : 155\n",
      "    loss           : -214481.1171875\n",
      "    ess            : 7.596113085746765\n",
      "    log_marginal   : 214481.47421875\n",
      "    val_loss       : -214002.41145833334\n",
      "    val_ess        : 6.7753885587056475\n",
      "    val_log_marginal: 214002.93229166666\n",
      "Train Epoch: 156 [0/900 (0%)] Loss: -214132.078125\n",
      "Train Epoch: 156 [270/900 (30%)] Loss: -215999.468750\n",
      "Train Epoch: 156 [540/900 (60%)] Loss: -214507.921875\n",
      "Train Epoch: 156 [810/900 (90%)] Loss: -213502.515625\n",
      "    epoch          : 156\n",
      "    loss           : -214490.40390625\n",
      "    ess            : 7.712789058685303\n",
      "    log_marginal   : 214490.7171875\n",
      "    val_loss       : -215163.31770833334\n",
      "    val_ess        : 8.33934243520101\n",
      "    val_log_marginal: 215163.54166666666\n",
      "Train Epoch: 157 [0/900 (0%)] Loss: -213679.828125\n",
      "Train Epoch: 157 [270/900 (30%)] Loss: -213789.812500\n",
      "Train Epoch: 157 [540/900 (60%)] Loss: -214168.421875\n",
      "Train Epoch: 157 [810/900 (90%)] Loss: -214552.109375\n",
      "    epoch          : 157\n",
      "    loss           : -214493.24609375\n",
      "    ess            : 7.715305519104004\n",
      "    log_marginal   : 214493.56953125\n",
      "    val_loss       : -214655.515625\n",
      "    val_ess        : 7.617442766825358\n",
      "    val_log_marginal: 214655.91145833334\n",
      "Train Epoch: 158 [0/900 (0%)] Loss: -214595.078125\n",
      "Train Epoch: 158 [270/900 (30%)] Loss: -214918.625000\n",
      "Train Epoch: 158 [540/900 (60%)] Loss: -215325.156250\n",
      "Train Epoch: 158 [810/900 (90%)] Loss: -212002.531250\n",
      "    epoch          : 158\n",
      "    loss           : -214495.8125\n",
      "    ess            : 7.537033009529114\n",
      "    log_marginal   : 214496.1984375\n",
      "    val_loss       : -214548.13020833334\n",
      "    val_ess        : 7.650458812713623\n",
      "    val_log_marginal: 214548.47916666666\n",
      "Train Epoch: 159 [0/900 (0%)] Loss: -214781.156250\n",
      "Train Epoch: 159 [270/900 (30%)] Loss: -216888.781250\n",
      "Train Epoch: 159 [540/900 (60%)] Loss: -215961.671875\n",
      "Train Epoch: 159 [810/900 (90%)] Loss: -214717.093750\n",
      "    epoch          : 159\n",
      "    loss           : -214503.11796875\n",
      "    ess            : 7.637983012199402\n",
      "    log_marginal   : 214503.45234375\n",
      "    val_loss       : -214263.984375\n",
      "    val_ess        : 7.290012836456299\n",
      "    val_log_marginal: 214264.35416666666\n",
      "Train Epoch: 160 [0/900 (0%)] Loss: -216168.000000\n",
      "Train Epoch: 160 [270/900 (30%)] Loss: -213047.406250\n",
      "Train Epoch: 160 [540/900 (60%)] Loss: -214298.890625\n",
      "Train Epoch: 160 [810/900 (90%)] Loss: -212840.234375\n",
      "    epoch          : 160\n",
      "    loss           : -214512.634375\n",
      "    ess            : 7.709612584114074\n",
      "    log_marginal   : 214512.94921875\n",
      "    val_loss       : -214837.15104166666\n",
      "    val_ess        : 8.036251386006674\n",
      "    val_log_marginal: 214837.4375\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch160.pth ...\n",
      "Train Epoch: 161 [0/900 (0%)] Loss: -214141.765625\n",
      "Train Epoch: 161 [270/900 (30%)] Loss: -216234.000000\n",
      "Train Epoch: 161 [540/900 (60%)] Loss: -216214.250000\n",
      "Train Epoch: 161 [810/900 (90%)] Loss: -214421.718750\n",
      "    epoch          : 161\n",
      "    loss           : -214516.825\n",
      "    ess            : 7.56781644821167\n",
      "    log_marginal   : 214517.24609375\n",
      "    val_loss       : -214810.80729166666\n",
      "    val_ess        : 7.812553882598877\n",
      "    val_log_marginal: 214811.078125\n",
      "Train Epoch: 162 [0/900 (0%)] Loss: -212642.468750\n",
      "Train Epoch: 162 [270/900 (30%)] Loss: -215491.984375\n",
      "Train Epoch: 162 [540/900 (60%)] Loss: -212456.625000\n",
      "Train Epoch: 162 [810/900 (90%)] Loss: -213106.500000\n",
      "    epoch          : 162\n",
      "    loss           : -214521.91171875\n",
      "    ess            : 7.579550719261169\n",
      "    log_marginal   : 214522.27578125\n",
      "    val_loss       : -213515.47395833334\n",
      "    val_ess        : 7.487680117289226\n",
      "    val_log_marginal: 213515.8125\n",
      "Train Epoch: 163 [0/900 (0%)] Loss: -213833.687500\n",
      "Train Epoch: 163 [270/900 (30%)] Loss: -213961.046875\n",
      "Train Epoch: 163 [540/900 (60%)] Loss: -213907.875000\n",
      "Train Epoch: 163 [810/900 (90%)] Loss: -214126.250000\n",
      "    epoch          : 163\n",
      "    loss           : -214530.86328125\n",
      "    ess            : 7.6092512845993046\n",
      "    log_marginal   : 214531.22265625\n",
      "    val_loss       : -213082.59375\n",
      "    val_ess        : 7.124936580657959\n",
      "    val_log_marginal: 213083.06770833334\n",
      "Train Epoch: 164 [0/900 (0%)] Loss: -214697.828125\n",
      "Train Epoch: 164 [270/900 (30%)] Loss: -213332.718750\n",
      "Train Epoch: 164 [540/900 (60%)] Loss: -214137.296875\n",
      "Train Epoch: 164 [810/900 (90%)] Loss: -213274.453125\n",
      "    epoch          : 164\n",
      "    loss           : -214537.25234375\n",
      "    ess            : 7.551635670661926\n",
      "    log_marginal   : 214537.60859375\n",
      "    val_loss       : -214189.18229166666\n",
      "    val_ess        : 8.031867504119873\n",
      "    val_log_marginal: 214189.46875\n",
      "Train Epoch: 165 [0/900 (0%)] Loss: -214818.812500\n",
      "Train Epoch: 165 [270/900 (30%)] Loss: -213992.312500\n",
      "Train Epoch: 165 [540/900 (60%)] Loss: -215464.140625\n",
      "Train Epoch: 165 [810/900 (90%)] Loss: -214956.718750\n",
      "    epoch          : 165\n",
      "    loss           : -214544.45546875\n",
      "    ess            : 7.602216386795044\n",
      "    log_marginal   : 214544.82265625\n",
      "    val_loss       : -214290.29166666666\n",
      "    val_ess        : 7.576228936513265\n",
      "    val_log_marginal: 214290.61458333334\n",
      "Train Epoch: 166 [0/900 (0%)] Loss: -216751.828125\n",
      "Train Epoch: 166 [270/900 (30%)] Loss: -214108.953125\n",
      "Train Epoch: 166 [540/900 (60%)] Loss: -213792.828125\n",
      "Train Epoch: 166 [810/900 (90%)] Loss: -212570.156250\n",
      "    epoch          : 166\n",
      "    loss           : -214551.7890625\n",
      "    ess            : 7.673374772071838\n",
      "    log_marginal   : 214552.1125\n",
      "    val_loss       : -214751.28645833334\n",
      "    val_ess        : 7.689311345418294\n",
      "    val_log_marginal: 214751.55729166666\n",
      "Train Epoch: 167 [0/900 (0%)] Loss: -212693.875000\n",
      "Train Epoch: 167 [270/900 (30%)] Loss: -214413.390625\n",
      "Train Epoch: 167 [540/900 (60%)] Loss: -212858.421875\n",
      "Train Epoch: 167 [810/900 (90%)] Loss: -214990.343750\n",
      "    epoch          : 167\n",
      "    loss           : -214555.79140625\n",
      "    ess            : 7.598343110084533\n",
      "    log_marginal   : 214556.1484375\n",
      "    val_loss       : -214179.99479166666\n",
      "    val_ess        : 7.655475934346517\n",
      "    val_log_marginal: 214180.234375\n",
      "Train Epoch: 168 [0/900 (0%)] Loss: -212804.953125\n",
      "Train Epoch: 168 [270/900 (30%)] Loss: -212800.578125\n",
      "Train Epoch: 168 [540/900 (60%)] Loss: -215626.250000\n",
      "Train Epoch: 168 [810/900 (90%)] Loss: -214487.390625\n",
      "    epoch          : 168\n",
      "    loss           : -214562.29375\n",
      "    ess            : 7.759182429313659\n",
      "    log_marginal   : 214562.6453125\n",
      "    val_loss       : -213509.11458333334\n",
      "    val_ess        : 7.617212613423665\n",
      "    val_log_marginal: 213509.45833333334\n",
      "Train Epoch: 169 [0/900 (0%)] Loss: -214469.406250\n",
      "Train Epoch: 169 [270/900 (30%)] Loss: -214379.500000\n",
      "Train Epoch: 169 [540/900 (60%)] Loss: -213364.843750\n",
      "Train Epoch: 169 [810/900 (90%)] Loss: -214298.953125\n",
      "    epoch          : 169\n",
      "    loss           : -214572.109375\n",
      "    ess            : 7.784754419326783\n",
      "    log_marginal   : 214572.4125\n",
      "    val_loss       : -214077.8125\n",
      "    val_ess        : 7.64836851755778\n",
      "    val_log_marginal: 214078.1875\n",
      "Train Epoch: 170 [0/900 (0%)] Loss: -214238.093750\n",
      "Train Epoch: 170 [270/900 (30%)] Loss: -214178.187500\n",
      "Train Epoch: 170 [540/900 (60%)] Loss: -215525.156250\n",
      "Train Epoch: 170 [810/900 (90%)] Loss: -214088.718750\n",
      "    epoch          : 170\n",
      "    loss           : -214575.5640625\n",
      "    ess            : 7.630549335479737\n",
      "    log_marginal   : 214575.884375\n",
      "    val_loss       : -213115.44791666666\n",
      "    val_ess        : 7.316916306813558\n",
      "    val_log_marginal: 213115.796875\n",
      "Saving checkpoint: saved/models/MiniBouncingMnist_Ppc/0402_162552/checkpoint-epoch170.pth ...\n",
      "Train Epoch: 171 [0/900 (0%)] Loss: -214959.812500\n",
      "Train Epoch: 171 [270/900 (30%)] Loss: -213663.671875\n",
      "Train Epoch: 171 [540/900 (60%)] Loss: -211456.359375\n",
      "Train Epoch: 171 [810/900 (90%)] Loss: -214420.453125\n",
      "    epoch          : 171\n",
      "    loss           : -214583.915625\n",
      "    ess            : 7.700876784324646\n",
      "    log_marginal   : 214584.2375\n",
      "    val_loss       : -215369.296875\n",
      "    val_ess        : 7.805226008097331\n",
      "    val_log_marginal: 215369.58333333334\n",
      "Train Epoch: 172 [0/900 (0%)] Loss: -213673.187500\n",
      "Train Epoch: 172 [270/900 (30%)] Loss: -214197.500000\n",
      "Train Epoch: 172 [540/900 (60%)] Loss: -215430.765625\n",
      "Train Epoch: 172 [810/900 (90%)] Loss: -215746.812500\n",
      "    epoch          : 172\n",
      "    loss           : -214590.44921875\n",
      "    ess            : 7.691044116020203\n",
      "    log_marginal   : 214590.79375\n",
      "    val_loss       : -214097.19270833334\n",
      "    val_ess        : 7.6301163037618\n",
      "    val_log_marginal: 214097.48958333334\n",
      "Train Epoch: 173 [0/900 (0%)] Loss: -214984.078125\n",
      "Train Epoch: 173 [270/900 (30%)] Loss: -212446.671875\n",
      "Train Epoch: 173 [540/900 (60%)] Loss: -214431.687500\n",
      "Train Epoch: 173 [810/900 (90%)] Loss: -213815.187500\n",
      "    epoch          : 173\n",
      "    loss           : -214598.7875\n",
      "    ess            : 7.636913919448853\n",
      "    log_marginal   : 214599.1515625\n",
      "    val_loss       : -214407.24479166666\n",
      "    val_ess        : 7.203978856404622\n",
      "    val_log_marginal: 214407.65104166666\n",
      "Train Epoch: 174 [0/900 (0%)] Loss: -215438.234375\n",
      "Train Epoch: 174 [270/900 (30%)] Loss: -214090.562500\n",
      "Train Epoch: 174 [540/900 (60%)] Loss: -212603.812500\n",
      "Train Epoch: 174 [810/900 (90%)] Loss: -217060.953125\n",
      "    epoch          : 174\n",
      "    loss           : -214605.65625\n",
      "    ess            : 7.7200836658477785\n",
      "    log_marginal   : 214605.97578125\n",
      "    val_loss       : -214082.13020833334\n",
      "    val_ess        : 7.599996089935303\n",
      "    val_log_marginal: 214082.71875\n",
      "Train Epoch: 175 [0/900 (0%)] Loss: -215086.203125\n",
      "Train Epoch: 175 [270/900 (30%)] Loss: -213524.031250\n",
      "Train Epoch: 175 [540/900 (60%)] Loss: -212900.421875\n",
      "Train Epoch: 175 [810/900 (90%)] Loss: -213750.765625\n",
      "    epoch          : 175\n",
      "    loss           : -214611.934375\n",
      "    ess            : 7.804958939552307\n",
      "    log_marginal   : 214612.26875\n",
      "    val_loss       : -213029.47916666666\n",
      "    val_ess        : 7.673234303792317\n",
      "    val_log_marginal: 213029.77604166666\n",
      "Train Epoch: 176 [0/900 (0%)] Loss: -216066.312500\n",
      "Train Epoch: 176 [270/900 (30%)] Loss: -213472.984375\n",
      "Train Epoch: 176 [540/900 (60%)] Loss: -214760.421875\n",
      "Train Epoch: 176 [810/900 (90%)] Loss: -214659.203125\n",
      "    epoch          : 176\n",
      "    loss           : -214620.36875\n",
      "    ess            : 7.806907796859742\n",
      "    log_marginal   : 214620.671875\n",
      "    val_loss       : -215514.38020833334\n",
      "    val_ess        : 7.7165633837382\n",
      "    val_log_marginal: 215514.65625\n",
      "Train Epoch: 177 [0/900 (0%)] Loss: -211576.078125\n",
      "Train Epoch: 177 [270/900 (30%)] Loss: -214708.296875\n",
      "Train Epoch: 177 [540/900 (60%)] Loss: -214631.734375\n",
      "Train Epoch: 177 [810/900 (90%)] Loss: -216111.531250\n",
      "    epoch          : 177\n",
      "    loss           : -214620.0828125\n",
      "    ess            : 7.6646729707717896\n",
      "    log_marginal   : 214620.403125\n",
      "    val_loss       : -214022.65625\n",
      "    val_ess        : 7.6028720537821455\n",
      "    val_log_marginal: 214023.02604166666\n",
      "Train Epoch: 178 [0/900 (0%)] Loss: -214165.515625\n",
      "Train Epoch: 178 [270/900 (30%)] Loss: -214026.781250\n",
      "Train Epoch: 178 [540/900 (60%)] Loss: -215704.765625\n",
      "Train Epoch: 178 [810/900 (90%)] Loss: -215263.890625\n",
      "    epoch          : 178\n",
      "    loss           : -214628.31875\n",
      "    ess            : 7.809907698631287\n",
      "    log_marginal   : 214628.64140625\n",
      "    val_loss       : -214509.19791666666\n",
      "    val_ess        : 7.389561176300049\n",
      "    val_log_marginal: 214509.63020833334\n",
      "Train Epoch: 179 [0/900 (0%)] Loss: -212490.734375\n",
      "Train Epoch: 179 [270/900 (30%)] Loss: -215353.406250\n"
     ]
    }
   ],
   "source": [
    "from utils import read_json\n",
    "\n",
    "config = read_json(\"experiments/ppc_minibmnist_config.json\")\n",
    "config = ConfigParser(config)\n",
    "trainer = main(config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5b900-0121-4cf6-91b6-2c9b0b12716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained.model.eval()\n",
    "trained.model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b487d4-288a-40d7-8f4d-c79e2e15385e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ppc] *",
   "language": "python",
   "name": "conda-env-ppc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
