{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ef93e3-8eb5-4883-8265-5fbe97d06e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/shai_hulud/ppc_experiments\n",
      "env: TORCH_CUDNN_SDPA_ENABLED=1\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%env TORCH_CUDNN_SDPA_ENABLED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94520ed3-45be-4735-a0f2-b8f380838c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import pyro\n",
    "import torch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "import trainer.trainer as module_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac4be4-19eb-4713-a88d-9bec118c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75ea7b9-6fe5-4f8a-a825-3572e421242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1445d1-45bb-43f9-893d-7a2b2bad1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "\n",
    "config = read_json(\"experiments/ppc_flowers_config.json\")\n",
    "config = ConfigParser(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca35026-5f64-47f8-98c7-a5e228013d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiffusionPpc(\n",
      "  (diffusion): DiffusionStep(\n",
      "    (unet): ScoreNetwork0(\n",
      "      (_convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LogSigmoid()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): LogSigmoid()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): LogSigmoid()\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): LogSigmoid()\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): LogSigmoid()\n",
      "        )\n",
      "      )\n",
      "      (_tconvs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "          (1): LogSigmoid()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "          (1): LogSigmoid()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "          (1): LogSigmoid()\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): ConvTranspose2d(128, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "          (1): LogSigmoid()\n",
      "        )\n",
      "        (4): Sequential(\n",
      "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LogSigmoid()\n",
      "          (2): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (prior): DiffusionPrior()\n",
      "  (graph): PpcGraphicalModel()\n",
      ")\n",
      "Trainable parameters: 2362563\n",
      "Initialize particles: train batch 0\n",
      "Initialize particles: train batch 1\n",
      "Initialize particles: train batch 2\n",
      "Initialize particles: train batch 3\n",
      "Initialize particles: train batch 4\n",
      "Initialize particles: train batch 5\n",
      "Initialize particles: train batch 6\n",
      "Initialize particles: train batch 7\n",
      "Initialize particles: train batch 8\n",
      "Initialize particles: train batch 9\n",
      "Initialize particles: train batch 10\n",
      "Initialize particles: train batch 11\n",
      "Initialize particles: train batch 12\n",
      "Initialize particles: train batch 13\n",
      "Initialize particles: train batch 14\n",
      "Initialize particles: train batch 15\n",
      "Initialize particles: train batch 16\n",
      "Initialize particles: train batch 17\n",
      "Initialize particles: train batch 18\n",
      "Initialize particles: train batch 19\n",
      "Initialize particles: train batch 20\n",
      "Initialize particles: train batch 21\n",
      "Initialize particles: train batch 22\n",
      "Initialize particles: train batch 23\n",
      "Initialize particles: train batch 24\n",
      "Initialize particles: train batch 25\n",
      "Initialize particles: train batch 26\n",
      "Initialize particles: train batch 27\n",
      "Initialize particles: train batch 28\n",
      "Initialize particles: train batch 29\n",
      "Initialize particles: train batch 30\n",
      "Initialize particles: train batch 31\n",
      "Initialize particles: train batch 32\n",
      "Initialize particles: train batch 33\n",
      "Initialize particles: train batch 34\n",
      "Initialize particles: train batch 35\n",
      "Initialize particles: train batch 36\n",
      "Initialize particles: train batch 37\n",
      "Initialize particles: train batch 38\n",
      "Initialize particles: train batch 39\n",
      "Initialize particles: train batch 40\n",
      "Initialize particles: train batch 41\n",
      "Initialize particles: train batch 42\n",
      "Initialize particles: train batch 43\n",
      "Initialize particles: train batch 44\n",
      "Initialize particles: train batch 45\n",
      "Initialize particles: train batch 46\n",
      "Initialize particles: train batch 47\n",
      "Initialize particles: train batch 48\n",
      "Initialize particles: train batch 49\n",
      "Initialize particles: train batch 50\n",
      "Initialize particles: train batch 51\n",
      "Initialize particles: train batch 52\n",
      "Initialize particles: train batch 53\n",
      "Initialize particles: train batch 54\n",
      "Initialize particles: train batch 55\n",
      "Initialize particles: train batch 56\n",
      "Initialize particles: train batch 57\n",
      "Initialize particles: train batch 58\n",
      "Initialize particles: train batch 59\n",
      "Initialize particles: train batch 60\n",
      "Initialize particles: train batch 61\n",
      "Initialize particles: train batch 62\n",
      "Initialize particles: train batch 63\n",
      "Initialize particles: train batch 64\n",
      "Initialize particles: train batch 65\n",
      "Initialize particles: train batch 66\n",
      "Initialize particles: train batch 67\n",
      "Initialize particles: train batch 68\n",
      "Initialize particles: train batch 69\n",
      "Initialize particles: train batch 70\n",
      "Initialize particles: train batch 71\n",
      "Initialize particles: train batch 72\n",
      "Initialize particles: train batch 73\n",
      "Initialize particles: train batch 74\n",
      "Initialize particles: train batch 75\n",
      "Initialize particles: train batch 76\n",
      "Initialize particles: train batch 77\n",
      "Initialize particles: train batch 78\n",
      "Initialize particles: train batch 79\n",
      "Initialize particles: train batch 80\n",
      "Initialize particles: train batch 81\n",
      "Initialize particles: train batch 82\n",
      "Initialize particles: train batch 83\n",
      "Initialize particles: train batch 84\n",
      "Initialize particles: train batch 85\n",
      "Initialize particles: train batch 86\n",
      "Initialize particles: train batch 87\n",
      "Initialize particles: train batch 88\n",
      "Initialize particles: train batch 89\n",
      "Initialize particles: train batch 90\n",
      "Initialize particles: train batch 91\n",
      "Initialize particles: train batch 92\n",
      "Initialize particles: train batch 93\n",
      "Initialize particles: train batch 94\n",
      "Initialize particles: train batch 95\n",
      "Initialize particles: train batch 96\n",
      "Initialize particles: train batch 97\n",
      "Initialize particles: train batch 98\n",
      "Initialize particles: train batch 99\n",
      "Initialize particles: train batch 100\n",
      "Initialize particles: train batch 101\n",
      "Initialize particles: train batch 102\n",
      "Initialize particles: train batch 103\n",
      "Initialize particles: train batch 104\n",
      "Initialize particles: train batch 105\n",
      "Initialize particles: train batch 106\n",
      "Initialize particles: train batch 107\n",
      "Initialize particles: train batch 108\n",
      "Initialize particles: train batch 109\n",
      "Initialize particles: train batch 110\n",
      "Initialize particles: train batch 111\n",
      "Initialize particles: train batch 112\n",
      "Initialize particles: train batch 113\n",
      "Initialize particles: train batch 114\n",
      "Initialize particles: valid batch 0\n",
      "Initialize particles: valid batch 1\n",
      "Initialize particles: valid batch 2\n",
      "Initialize particles: valid batch 3\n",
      "Initialize particles: valid batch 4\n",
      "Initialize particles: valid batch 5\n",
      "Initialize particles: valid batch 6\n",
      "Initialize particles: valid batch 7\n",
      "Initialize particles: valid batch 8\n",
      "Initialize particles: valid batch 9\n",
      "Initialize particles: valid batch 10\n",
      "Initialize particles: valid batch 11\n",
      "Initialize particles: valid batch 12\n"
     ]
    }
   ],
   "source": [
    "logger = config.get_logger('train')\n",
    "\n",
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()\n",
    "\n",
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)\n",
    "logger.info(model)\n",
    "\n",
    "# get function handles of metrics\n",
    "metrics = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# build optimizer.\n",
    "if \"lr_scheduler\" in config:\n",
    "    lr_scheduler = getattr(pyro.optim, config[\"lr_scheduler\"][\"type\"])\n",
    "    lr_scheduler = optimizer = lr_scheduler({\n",
    "        \"optimizer\": getattr(torch.optim, config[\"optimizer\"][\"type\"]),\n",
    "        \"optim_args\": config[\"optimizer\"][\"args\"][\"optim_args\"],\n",
    "        **config[\"lr_scheduler\"][\"args\"]\n",
    "    })\n",
    "else:\n",
    "    optimizer = config.init_obj('optimizer', pyro.optim)\n",
    "    lr_scheduler = None\n",
    "\n",
    "# build trainer\n",
    "# kwargs = config['trainer'].pop('args')\n",
    "trainer = config.init_obj('trainer', module_trainer, model, metrics, optimizer,\n",
    "                          config=config, data_loader=data_loader,\n",
    "                          valid_data_loader=valid_data_loader,\n",
    "                          lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5cdd31-7fae-4e6f-8fe2-ef5c023919de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved/log/FlowersDiffusion_Ppc/0502_011314\n"
     ]
    }
   ],
   "source": [
    "logger.info(trainer.config.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9820b982-1a39-4bde-850e-1a1d9a92557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/918 (0%)] Loss: 75280016.000000\n",
      "Train Epoch: 1 [16/918 (2%)] Loss: 65736224.000000\n",
      "Train Epoch: 1 [32/918 (3%)] Loss: 68942752.000000\n",
      "Train Epoch: 1 [48/918 (5%)] Loss: 66970356.000000\n",
      "Train Epoch: 1 [64/918 (7%)] Loss: 76079696.000000\n",
      "Train Epoch: 1 [80/918 (9%)] Loss: 69918080.000000\n",
      "Train Epoch: 1 [96/918 (10%)] Loss: 62746536.000000\n",
      "Train Epoch: 1 [112/918 (12%)] Loss: 56976864.000000\n",
      "Train Epoch: 1 [128/918 (14%)] Loss: 75223232.000000\n",
      "Train Epoch: 1 [144/918 (16%)] Loss: 67858048.000000\n",
      "Train Epoch: 1 [160/918 (17%)] Loss: 59077404.000000\n",
      "Train Epoch: 1 [176/918 (19%)] Loss: 69545896.000000\n",
      "Train Epoch: 1 [192/918 (21%)] Loss: 55390720.000000\n",
      "Train Epoch: 1 [208/918 (23%)] Loss: 61662688.000000\n",
      "Train Epoch: 1 [224/918 (24%)] Loss: 76061824.000000\n",
      "Train Epoch: 1 [240/918 (26%)] Loss: 58553076.000000\n",
      "Train Epoch: 1 [256/918 (28%)] Loss: 63761920.000000\n",
      "Train Epoch: 1 [272/918 (30%)] Loss: 66139144.000000\n",
      "Train Epoch: 1 [288/918 (31%)] Loss: 58706080.000000\n",
      "Train Epoch: 1 [304/918 (33%)] Loss: 63007148.000000\n",
      "Train Epoch: 1 [320/918 (35%)] Loss: 47727224.000000\n",
      "Train Epoch: 1 [336/918 (37%)] Loss: 56003648.000000\n",
      "Train Epoch: 1 [352/918 (38%)] Loss: 70390496.000000\n",
      "Train Epoch: 1 [368/918 (40%)] Loss: 63945204.000000\n",
      "Train Epoch: 1 [384/918 (42%)] Loss: 61233056.000000\n",
      "Train Epoch: 1 [400/918 (44%)] Loss: 58343784.000000\n",
      "Train Epoch: 1 [416/918 (45%)] Loss: 65548748.000000\n",
      "Train Epoch: 1 [432/918 (47%)] Loss: 65249512.000000\n",
      "Train Epoch: 1 [448/918 (49%)] Loss: 57409844.000000\n",
      "Train Epoch: 1 [464/918 (51%)] Loss: 60690144.000000\n",
      "Train Epoch: 1 [480/918 (52%)] Loss: 55005004.000000\n",
      "Train Epoch: 1 [496/918 (54%)] Loss: 60794880.000000\n",
      "Train Epoch: 1 [512/918 (56%)] Loss: 59426892.000000\n",
      "Train Epoch: 1 [528/918 (58%)] Loss: 59293088.000000\n",
      "Train Epoch: 1 [544/918 (59%)] Loss: 58144532.000000\n",
      "Train Epoch: 1 [560/918 (61%)] Loss: 61836808.000000\n",
      "Train Epoch: 1 [576/918 (63%)] Loss: 56372620.000000\n",
      "Train Epoch: 1 [592/918 (64%)] Loss: 49086156.000000\n",
      "Train Epoch: 1 [608/918 (66%)] Loss: 58282016.000000\n",
      "Train Epoch: 1 [624/918 (68%)] Loss: 62910412.000000\n",
      "Train Epoch: 1 [640/918 (70%)] Loss: 62763372.000000\n",
      "Train Epoch: 1 [656/918 (71%)] Loss: 62948148.000000\n",
      "Train Epoch: 1 [672/918 (73%)] Loss: 60721396.000000\n",
      "Train Epoch: 1 [688/918 (75%)] Loss: 61080360.000000\n",
      "Train Epoch: 1 [704/918 (77%)] Loss: 60940020.000000\n",
      "Train Epoch: 1 [720/918 (78%)] Loss: 65537896.000000\n",
      "Train Epoch: 1 [736/918 (80%)] Loss: 49733504.000000\n",
      "Train Epoch: 1 [752/918 (82%)] Loss: 52915816.000000\n",
      "Train Epoch: 1 [768/918 (84%)] Loss: 62596680.000000\n",
      "Train Epoch: 1 [784/918 (85%)] Loss: 54088116.000000\n",
      "Train Epoch: 1 [800/918 (87%)] Loss: 58402444.000000\n",
      "Train Epoch: 1 [816/918 (89%)] Loss: 58996864.000000\n",
      "Train Epoch: 1 [832/918 (91%)] Loss: 69635544.000000\n",
      "Train Epoch: 1 [848/918 (92%)] Loss: 51443576.000000\n",
      "Train Epoch: 1 [864/918 (94%)] Loss: 62366336.000000\n",
      "Train Epoch: 1 [880/918 (96%)] Loss: 53774016.000000\n",
      "Train Epoch: 1 [896/918 (98%)] Loss: 56208244.000000\n",
      "Train Epoch: 1 [912/918 (99%)] Loss: 54491664.000000\n",
      "    epoch          : 1\n",
      "    loss           : 63886066.747826084\n",
      "    ess            : 2.4758910469386888\n",
      "    log_marginal   : -63886064.48695652\n",
      "    val_loss       : 62639128.0\n",
      "    val_ess        : 3.5768340550936184\n",
      "    val_log_marginal: -62639125.84615385\n",
      "Train Epoch: 2 [0/918 (0%)] Loss: 66931956.000000\n",
      "Train Epoch: 2 [16/918 (2%)] Loss: 49288940.000000\n",
      "Train Epoch: 2 [32/918 (3%)] Loss: 59490484.000000\n",
      "Train Epoch: 2 [48/918 (5%)] Loss: 68202496.000000\n",
      "Train Epoch: 2 [64/918 (7%)] Loss: 61048948.000000\n",
      "Train Epoch: 2 [80/918 (9%)] Loss: 74928984.000000\n",
      "Train Epoch: 2 [96/918 (10%)] Loss: 69110264.000000\n",
      "Train Epoch: 2 [112/918 (12%)] Loss: 64728732.000000\n",
      "Train Epoch: 2 [128/918 (14%)] Loss: 65779884.000000\n",
      "Train Epoch: 2 [144/918 (16%)] Loss: 54191924.000000\n",
      "Train Epoch: 2 [160/918 (17%)] Loss: 62153064.000000\n",
      "Train Epoch: 2 [176/918 (19%)] Loss: 62816460.000000\n",
      "Train Epoch: 2 [192/918 (21%)] Loss: 51977720.000000\n",
      "Train Epoch: 2 [208/918 (23%)] Loss: 54241396.000000\n",
      "Train Epoch: 2 [224/918 (24%)] Loss: 65413376.000000\n",
      "Train Epoch: 2 [240/918 (26%)] Loss: 62896396.000000\n",
      "Train Epoch: 2 [256/918 (28%)] Loss: 54073460.000000\n",
      "Train Epoch: 2 [272/918 (30%)] Loss: 54974540.000000\n",
      "Train Epoch: 2 [288/918 (31%)] Loss: 64062516.000000\n",
      "Train Epoch: 2 [304/918 (33%)] Loss: 68297888.000000\n",
      "Train Epoch: 2 [320/918 (35%)] Loss: 44884752.000000\n",
      "Train Epoch: 2 [336/918 (37%)] Loss: 41903976.000000\n",
      "Train Epoch: 2 [352/918 (38%)] Loss: 54312028.000000\n",
      "Train Epoch: 2 [368/918 (40%)] Loss: 56988012.000000\n",
      "Train Epoch: 2 [384/918 (42%)] Loss: 61804256.000000\n",
      "Train Epoch: 2 [400/918 (44%)] Loss: 63502300.000000\n",
      "Train Epoch: 2 [416/918 (45%)] Loss: 67524752.000000\n",
      "Train Epoch: 2 [432/918 (47%)] Loss: 54893388.000000\n",
      "Train Epoch: 2 [448/918 (49%)] Loss: 66627484.000000\n",
      "Train Epoch: 2 [464/918 (51%)] Loss: 56287116.000000\n",
      "Train Epoch: 2 [480/918 (52%)] Loss: 60741260.000000\n",
      "Train Epoch: 2 [496/918 (54%)] Loss: 70425408.000000\n",
      "Train Epoch: 2 [512/918 (56%)] Loss: 47648192.000000\n",
      "Train Epoch: 2 [528/918 (58%)] Loss: 49836748.000000\n",
      "Train Epoch: 2 [544/918 (59%)] Loss: 54211484.000000\n",
      "Train Epoch: 2 [560/918 (61%)] Loss: 54353908.000000\n",
      "Train Epoch: 2 [576/918 (63%)] Loss: 67298264.000000\n",
      "Train Epoch: 2 [592/918 (64%)] Loss: 55127156.000000\n",
      "Train Epoch: 2 [608/918 (66%)] Loss: 53271884.000000\n",
      "Train Epoch: 2 [624/918 (68%)] Loss: 46092512.000000\n",
      "Train Epoch: 2 [640/918 (70%)] Loss: 44765816.000000\n",
      "Train Epoch: 2 [656/918 (71%)] Loss: 60900584.000000\n",
      "Train Epoch: 2 [672/918 (73%)] Loss: 49583984.000000\n",
      "Train Epoch: 2 [688/918 (75%)] Loss: 50279464.000000\n",
      "Train Epoch: 2 [704/918 (77%)] Loss: 58815676.000000\n",
      "Train Epoch: 2 [720/918 (78%)] Loss: 51930520.000000\n",
      "Train Epoch: 2 [736/918 (80%)] Loss: 58870004.000000\n",
      "Train Epoch: 2 [752/918 (82%)] Loss: 64378112.000000\n",
      "Train Epoch: 2 [768/918 (84%)] Loss: 50656720.000000\n",
      "Train Epoch: 2 [784/918 (85%)] Loss: 53526992.000000\n",
      "Train Epoch: 2 [800/918 (87%)] Loss: 54624552.000000\n",
      "Train Epoch: 2 [816/918 (89%)] Loss: 61086816.000000\n",
      "Train Epoch: 2 [832/918 (91%)] Loss: 57577408.000000\n",
      "Train Epoch: 2 [848/918 (92%)] Loss: 54707840.000000\n",
      "Train Epoch: 2 [864/918 (94%)] Loss: 58031348.000000\n",
      "Train Epoch: 2 [880/918 (96%)] Loss: 50973676.000000\n",
      "Train Epoch: 2 [896/918 (98%)] Loss: 54130408.000000\n",
      "Train Epoch: 2 [912/918 (99%)] Loss: 56875876.000000\n",
      "    epoch          : 2\n",
      "    loss           : 57436416.8\n",
      "    ess            : 4.7479864700980805\n",
      "    log_marginal   : -57436415.16521739\n",
      "    val_loss       : 57618113.23076923\n",
      "    val_ess        : 7.356190754817082\n",
      "    val_log_marginal: -57618111.692307696\n",
      "Train Epoch: 3 [0/918 (0%)] Loss: 56635304.000000\n",
      "Train Epoch: 3 [16/918 (2%)] Loss: 63227968.000000\n",
      "Train Epoch: 3 [32/918 (3%)] Loss: 48743916.000000\n",
      "Train Epoch: 3 [48/918 (5%)] Loss: 60666956.000000\n",
      "Train Epoch: 3 [64/918 (7%)] Loss: 58721676.000000\n",
      "Train Epoch: 3 [80/918 (9%)] Loss: 70031872.000000\n",
      "Train Epoch: 3 [96/918 (10%)] Loss: 60748788.000000\n",
      "Train Epoch: 3 [112/918 (12%)] Loss: 48406132.000000\n",
      "Train Epoch: 3 [128/918 (14%)] Loss: 36603724.000000\n",
      "Train Epoch: 3 [144/918 (16%)] Loss: 54356012.000000\n",
      "Train Epoch: 3 [160/918 (17%)] Loss: 55851732.000000\n",
      "Train Epoch: 3 [176/918 (19%)] Loss: 51944820.000000\n",
      "Train Epoch: 3 [192/918 (21%)] Loss: 57163612.000000\n",
      "Train Epoch: 3 [208/918 (23%)] Loss: 59828456.000000\n",
      "Train Epoch: 3 [224/918 (24%)] Loss: 58389196.000000\n",
      "Train Epoch: 3 [240/918 (26%)] Loss: 56977384.000000\n",
      "Train Epoch: 3 [256/918 (28%)] Loss: 55426716.000000\n",
      "Train Epoch: 3 [272/918 (30%)] Loss: 50966676.000000\n",
      "Train Epoch: 3 [288/918 (31%)] Loss: 55944928.000000\n",
      "Train Epoch: 3 [304/918 (33%)] Loss: 47704120.000000\n",
      "Train Epoch: 3 [320/918 (35%)] Loss: 51324084.000000\n",
      "Train Epoch: 3 [336/918 (37%)] Loss: 44979560.000000\n",
      "Train Epoch: 3 [352/918 (38%)] Loss: 52868524.000000\n",
      "Train Epoch: 3 [368/918 (40%)] Loss: 45584016.000000\n",
      "Train Epoch: 3 [384/918 (42%)] Loss: 56830048.000000\n",
      "Train Epoch: 3 [400/918 (44%)] Loss: 53985696.000000\n",
      "Train Epoch: 3 [416/918 (45%)] Loss: 61824448.000000\n",
      "Train Epoch: 3 [432/918 (47%)] Loss: 57749580.000000\n",
      "Train Epoch: 3 [448/918 (49%)] Loss: 60670368.000000\n",
      "Train Epoch: 3 [464/918 (51%)] Loss: 54058848.000000\n",
      "Train Epoch: 3 [480/918 (52%)] Loss: 47452488.000000\n",
      "Train Epoch: 3 [496/918 (54%)] Loss: 63255924.000000\n",
      "Train Epoch: 3 [512/918 (56%)] Loss: 51136620.000000\n",
      "Train Epoch: 3 [528/918 (58%)] Loss: 54081420.000000\n",
      "Train Epoch: 3 [544/918 (59%)] Loss: 60026420.000000\n",
      "Train Epoch: 3 [560/918 (61%)] Loss: 46196520.000000\n",
      "Train Epoch: 3 [576/918 (63%)] Loss: 50209008.000000\n",
      "Train Epoch: 3 [592/918 (64%)] Loss: 48281248.000000\n",
      "Train Epoch: 3 [608/918 (66%)] Loss: 60196532.000000\n",
      "Train Epoch: 3 [624/918 (68%)] Loss: 51473304.000000\n",
      "Train Epoch: 3 [640/918 (70%)] Loss: 44895084.000000\n",
      "Train Epoch: 3 [656/918 (71%)] Loss: 58976564.000000\n",
      "Train Epoch: 3 [672/918 (73%)] Loss: 45897684.000000\n",
      "Train Epoch: 3 [688/918 (75%)] Loss: 63535924.000000\n",
      "Train Epoch: 3 [704/918 (77%)] Loss: 42948104.000000\n",
      "Train Epoch: 3 [720/918 (78%)] Loss: 53837216.000000\n",
      "Train Epoch: 3 [736/918 (80%)] Loss: 50327632.000000\n",
      "Train Epoch: 3 [752/918 (82%)] Loss: 51722636.000000\n",
      "Train Epoch: 3 [768/918 (84%)] Loss: 41862940.000000\n",
      "Train Epoch: 3 [784/918 (85%)] Loss: 48692220.000000\n",
      "Train Epoch: 3 [800/918 (87%)] Loss: 52410988.000000\n",
      "Train Epoch: 3 [816/918 (89%)] Loss: 56338664.000000\n",
      "Train Epoch: 3 [832/918 (91%)] Loss: 50102528.000000\n",
      "Train Epoch: 3 [848/918 (92%)] Loss: 44050364.000000\n",
      "Train Epoch: 3 [864/918 (94%)] Loss: 62421748.000000\n",
      "Train Epoch: 3 [880/918 (96%)] Loss: 48514752.000000\n",
      "Train Epoch: 3 [896/918 (98%)] Loss: 55680444.000000\n",
      "Train Epoch: 3 [912/918 (99%)] Loss: 55862780.000000\n",
      "    epoch          : 3\n",
      "    loss           : 52755137.73913044\n",
      "    ess            : 6.534591430166493\n",
      "    log_marginal   : -52755135.82608695\n",
      "    val_loss       : 53510175.384615384\n",
      "    val_ess        : 8.043346515068642\n",
      "    val_log_marginal: -53510173.84615385\n",
      "Train Epoch: 4 [0/918 (0%)] Loss: 47788412.000000\n",
      "Train Epoch: 4 [16/918 (2%)] Loss: 50538412.000000\n",
      "Train Epoch: 4 [32/918 (3%)] Loss: 44389436.000000\n",
      "Train Epoch: 4 [48/918 (5%)] Loss: 57664588.000000\n",
      "Train Epoch: 4 [64/918 (7%)] Loss: 46552108.000000\n",
      "Train Epoch: 4 [80/918 (9%)] Loss: 50120656.000000\n",
      "Train Epoch: 4 [96/918 (10%)] Loss: 51294196.000000\n",
      "Train Epoch: 4 [112/918 (12%)] Loss: 39459836.000000\n",
      "Train Epoch: 4 [128/918 (14%)] Loss: 57500428.000000\n",
      "Train Epoch: 4 [144/918 (16%)] Loss: 52959676.000000\n",
      "Train Epoch: 4 [160/918 (17%)] Loss: 53273392.000000\n",
      "Train Epoch: 4 [176/918 (19%)] Loss: 51825708.000000\n",
      "Train Epoch: 4 [192/918 (21%)] Loss: 43510832.000000\n",
      "Train Epoch: 4 [208/918 (23%)] Loss: 43871952.000000\n",
      "Train Epoch: 4 [224/918 (24%)] Loss: 54106216.000000\n",
      "Train Epoch: 4 [240/918 (26%)] Loss: 55118376.000000\n",
      "Train Epoch: 4 [256/918 (28%)] Loss: 52924736.000000\n",
      "Train Epoch: 4 [272/918 (30%)] Loss: 47795468.000000\n",
      "Train Epoch: 4 [288/918 (31%)] Loss: 44233500.000000\n",
      "Train Epoch: 4 [304/918 (33%)] Loss: 44312096.000000\n",
      "Train Epoch: 4 [320/918 (35%)] Loss: 42284512.000000\n",
      "Train Epoch: 4 [336/918 (37%)] Loss: 46366540.000000\n",
      "Train Epoch: 4 [352/918 (38%)] Loss: 46290612.000000\n",
      "Train Epoch: 4 [368/918 (40%)] Loss: 54103996.000000\n",
      "Train Epoch: 4 [384/918 (42%)] Loss: 45824156.000000\n",
      "Train Epoch: 4 [400/918 (44%)] Loss: 42977896.000000\n",
      "Train Epoch: 4 [416/918 (45%)] Loss: 50808764.000000\n",
      "Train Epoch: 4 [432/918 (47%)] Loss: 55680564.000000\n",
      "Train Epoch: 4 [448/918 (49%)] Loss: 39907176.000000\n",
      "Train Epoch: 4 [464/918 (51%)] Loss: 71263320.000000\n",
      "Train Epoch: 4 [480/918 (52%)] Loss: 46407724.000000\n",
      "Train Epoch: 4 [496/918 (54%)] Loss: 48155904.000000\n",
      "Train Epoch: 4 [512/918 (56%)] Loss: 41447724.000000\n",
      "Train Epoch: 4 [528/918 (58%)] Loss: 55002888.000000\n",
      "Train Epoch: 4 [544/918 (59%)] Loss: 55217532.000000\n",
      "Train Epoch: 4 [560/918 (61%)] Loss: 57806600.000000\n",
      "Train Epoch: 4 [576/918 (63%)] Loss: 44499216.000000\n",
      "Train Epoch: 4 [592/918 (64%)] Loss: 50891120.000000\n",
      "Train Epoch: 4 [608/918 (66%)] Loss: 45544384.000000\n",
      "Train Epoch: 4 [624/918 (68%)] Loss: 50931124.000000\n",
      "Train Epoch: 4 [640/918 (70%)] Loss: 44063740.000000\n",
      "Train Epoch: 4 [656/918 (71%)] Loss: 58081228.000000\n",
      "Train Epoch: 4 [672/918 (73%)] Loss: 54107060.000000\n",
      "Train Epoch: 4 [688/918 (75%)] Loss: 56840332.000000\n",
      "Train Epoch: 4 [704/918 (77%)] Loss: 48048064.000000\n",
      "Train Epoch: 4 [720/918 (78%)] Loss: 50627552.000000\n",
      "Train Epoch: 4 [736/918 (80%)] Loss: 47921840.000000\n",
      "Train Epoch: 4 [752/918 (82%)] Loss: 49137888.000000\n",
      "Train Epoch: 4 [768/918 (84%)] Loss: 47501120.000000\n",
      "Train Epoch: 4 [784/918 (85%)] Loss: 47104284.000000\n",
      "Train Epoch: 4 [800/918 (87%)] Loss: 51095420.000000\n",
      "Train Epoch: 4 [816/918 (89%)] Loss: 52984144.000000\n",
      "Train Epoch: 4 [832/918 (91%)] Loss: 41117384.000000\n",
      "Train Epoch: 4 [848/918 (92%)] Loss: 51794140.000000\n",
      "Train Epoch: 4 [864/918 (94%)] Loss: 52737076.000000\n",
      "Train Epoch: 4 [880/918 (96%)] Loss: 51251696.000000\n",
      "Train Epoch: 4 [896/918 (98%)] Loss: 55977448.000000\n",
      "Train Epoch: 4 [912/918 (99%)] Loss: 43890536.000000\n",
      "    epoch          : 4\n",
      "    loss           : 48810138.88695652\n",
      "    ess            : 8.60696031736291\n",
      "    log_marginal   : -48810137.14782609\n",
      "    val_loss       : 50563503.384615384\n",
      "    val_ess        : 11.650914265559269\n",
      "    val_log_marginal: -50563501.84615385\n",
      "Train Epoch: 5 [0/918 (0%)] Loss: 48762896.000000\n",
      "Train Epoch: 5 [16/918 (2%)] Loss: 52480624.000000\n",
      "Train Epoch: 5 [32/918 (3%)] Loss: 44038508.000000\n",
      "Train Epoch: 5 [48/918 (5%)] Loss: 46342704.000000\n",
      "Train Epoch: 5 [64/918 (7%)] Loss: 39256280.000000\n",
      "Train Epoch: 5 [80/918 (9%)] Loss: 51947456.000000\n",
      "Train Epoch: 5 [96/918 (10%)] Loss: 58131380.000000\n",
      "Train Epoch: 5 [112/918 (12%)] Loss: 45403788.000000\n",
      "Train Epoch: 5 [128/918 (14%)] Loss: 44268572.000000\n",
      "Train Epoch: 5 [144/918 (16%)] Loss: 31893248.000000\n",
      "Train Epoch: 5 [160/918 (17%)] Loss: 50512832.000000\n",
      "Train Epoch: 5 [176/918 (19%)] Loss: 56646952.000000\n",
      "Train Epoch: 5 [192/918 (21%)] Loss: 49461512.000000\n",
      "Train Epoch: 5 [208/918 (23%)] Loss: 53176296.000000\n",
      "Train Epoch: 5 [224/918 (24%)] Loss: 45074988.000000\n",
      "Train Epoch: 5 [240/918 (26%)] Loss: 43118848.000000\n",
      "Train Epoch: 5 [256/918 (28%)] Loss: 40601036.000000\n",
      "Train Epoch: 5 [272/918 (30%)] Loss: 47782892.000000\n",
      "Train Epoch: 5 [288/918 (31%)] Loss: 52812748.000000\n",
      "Train Epoch: 5 [304/918 (33%)] Loss: 47390592.000000\n",
      "Train Epoch: 5 [320/918 (35%)] Loss: 46327372.000000\n",
      "Train Epoch: 5 [336/918 (37%)] Loss: 38687900.000000\n",
      "Train Epoch: 5 [352/918 (38%)] Loss: 48467980.000000\n",
      "Train Epoch: 5 [368/918 (40%)] Loss: 54084148.000000\n",
      "Train Epoch: 5 [384/918 (42%)] Loss: 55058548.000000\n",
      "Train Epoch: 5 [400/918 (44%)] Loss: 54768564.000000\n",
      "Train Epoch: 5 [416/918 (45%)] Loss: 54765404.000000\n",
      "Train Epoch: 5 [432/918 (47%)] Loss: 40931864.000000\n",
      "Train Epoch: 5 [448/918 (49%)] Loss: 53979316.000000\n",
      "Train Epoch: 5 [464/918 (51%)] Loss: 44216524.000000\n",
      "Train Epoch: 5 [480/918 (52%)] Loss: 39580488.000000\n",
      "Train Epoch: 5 [496/918 (54%)] Loss: 46814224.000000\n",
      "Train Epoch: 5 [512/918 (56%)] Loss: 44837192.000000\n",
      "Train Epoch: 5 [528/918 (58%)] Loss: 42630888.000000\n",
      "Train Epoch: 5 [544/918 (59%)] Loss: 43725064.000000\n",
      "Train Epoch: 5 [560/918 (61%)] Loss: 49413584.000000\n",
      "Train Epoch: 5 [576/918 (63%)] Loss: 44978136.000000\n",
      "Train Epoch: 5 [592/918 (64%)] Loss: 49896440.000000\n",
      "Train Epoch: 5 [608/918 (66%)] Loss: 43024724.000000\n",
      "Train Epoch: 5 [624/918 (68%)] Loss: 37616892.000000\n",
      "Train Epoch: 5 [640/918 (70%)] Loss: 50055808.000000\n",
      "Train Epoch: 5 [656/918 (71%)] Loss: 43649064.000000\n",
      "Train Epoch: 5 [672/918 (73%)] Loss: 69100192.000000\n",
      "Train Epoch: 5 [688/918 (75%)] Loss: 47434228.000000\n",
      "Train Epoch: 5 [704/918 (77%)] Loss: 43127148.000000\n",
      "Train Epoch: 5 [720/918 (78%)] Loss: 43356124.000000\n",
      "Train Epoch: 5 [736/918 (80%)] Loss: 45506848.000000\n",
      "Train Epoch: 5 [752/918 (82%)] Loss: 41685064.000000\n",
      "Train Epoch: 5 [768/918 (84%)] Loss: 48322272.000000\n",
      "Train Epoch: 5 [784/918 (85%)] Loss: 48894280.000000\n",
      "Train Epoch: 5 [800/918 (87%)] Loss: 36177452.000000\n",
      "Train Epoch: 5 [816/918 (89%)] Loss: 45764656.000000\n",
      "Train Epoch: 5 [832/918 (91%)] Loss: 45116448.000000\n",
      "Train Epoch: 5 [848/918 (92%)] Loss: 41048588.000000\n",
      "Train Epoch: 5 [864/918 (94%)] Loss: 40934768.000000\n",
      "Train Epoch: 5 [880/918 (96%)] Loss: 47564136.000000\n",
      "Train Epoch: 5 [896/918 (98%)] Loss: 37929288.000000\n",
      "Train Epoch: 5 [912/918 (99%)] Loss: 49429808.000000\n",
      "    epoch          : 5\n",
      "    loss           : 46136950.36521739\n",
      "    ess            : 10.8596361440161\n",
      "    log_marginal   : -46136948.59130435\n",
      "    val_loss       : 49080596.615384616\n",
      "    val_ess        : 10.791969446035532\n",
      "    val_log_marginal: -49080592.92307692\n",
      "Train Epoch: 6 [0/918 (0%)] Loss: 46738336.000000\n",
      "Train Epoch: 6 [16/918 (2%)] Loss: 42561896.000000\n",
      "Train Epoch: 6 [32/918 (3%)] Loss: 52593584.000000\n",
      "Train Epoch: 6 [48/918 (5%)] Loss: 37639496.000000\n",
      "Train Epoch: 6 [64/918 (7%)] Loss: 41364400.000000\n",
      "Train Epoch: 6 [80/918 (9%)] Loss: 42502944.000000\n",
      "Train Epoch: 6 [96/918 (10%)] Loss: 47769792.000000\n",
      "Train Epoch: 6 [112/918 (12%)] Loss: 47883884.000000\n",
      "Train Epoch: 6 [128/918 (14%)] Loss: 46675232.000000\n",
      "Train Epoch: 6 [144/918 (16%)] Loss: 49490444.000000\n",
      "Train Epoch: 6 [160/918 (17%)] Loss: 49919984.000000\n",
      "Train Epoch: 6 [176/918 (19%)] Loss: 52327032.000000\n",
      "Train Epoch: 6 [192/918 (21%)] Loss: 50064496.000000\n",
      "Train Epoch: 6 [208/918 (23%)] Loss: 44567880.000000\n",
      "Train Epoch: 6 [224/918 (24%)] Loss: 40568272.000000\n",
      "Train Epoch: 6 [240/918 (26%)] Loss: 48978652.000000\n",
      "Train Epoch: 6 [256/918 (28%)] Loss: 36501776.000000\n",
      "Train Epoch: 6 [272/918 (30%)] Loss: 45008696.000000\n",
      "Train Epoch: 6 [288/918 (31%)] Loss: 40690208.000000\n",
      "Train Epoch: 6 [304/918 (33%)] Loss: 53999208.000000\n",
      "Train Epoch: 6 [320/918 (35%)] Loss: 46592200.000000\n",
      "Train Epoch: 6 [336/918 (37%)] Loss: 48507308.000000\n",
      "Train Epoch: 6 [352/918 (38%)] Loss: 45493232.000000\n",
      "Train Epoch: 6 [368/918 (40%)] Loss: 44639952.000000\n",
      "Train Epoch: 6 [384/918 (42%)] Loss: 38533012.000000\n",
      "Train Epoch: 6 [400/918 (44%)] Loss: 45011232.000000\n",
      "Train Epoch: 6 [416/918 (45%)] Loss: 42288488.000000\n",
      "Train Epoch: 6 [432/918 (47%)] Loss: 45881216.000000\n",
      "Train Epoch: 6 [448/918 (49%)] Loss: 44396168.000000\n",
      "Train Epoch: 6 [464/918 (51%)] Loss: 43908988.000000\n",
      "Train Epoch: 6 [480/918 (52%)] Loss: 47403816.000000\n",
      "Train Epoch: 6 [496/918 (54%)] Loss: 40152304.000000\n",
      "Train Epoch: 6 [512/918 (56%)] Loss: 51318708.000000\n",
      "Train Epoch: 6 [528/918 (58%)] Loss: 46902232.000000\n",
      "Train Epoch: 6 [544/918 (59%)] Loss: 41816188.000000\n",
      "Train Epoch: 6 [560/918 (61%)] Loss: 44870312.000000\n",
      "Train Epoch: 6 [576/918 (63%)] Loss: 39195156.000000\n",
      "Train Epoch: 6 [592/918 (64%)] Loss: 46531052.000000\n",
      "Train Epoch: 6 [608/918 (66%)] Loss: 52255712.000000\n",
      "Train Epoch: 6 [624/918 (68%)] Loss: 57943860.000000\n",
      "Train Epoch: 6 [640/918 (70%)] Loss: 42778940.000000\n",
      "Train Epoch: 6 [656/918 (71%)] Loss: 35337088.000000\n",
      "Train Epoch: 6 [672/918 (73%)] Loss: 44547452.000000\n",
      "Train Epoch: 6 [688/918 (75%)] Loss: 47300844.000000\n",
      "Train Epoch: 6 [704/918 (77%)] Loss: 44244956.000000\n",
      "Train Epoch: 6 [720/918 (78%)] Loss: 40765192.000000\n",
      "Train Epoch: 6 [736/918 (80%)] Loss: 40071056.000000\n",
      "Train Epoch: 6 [752/918 (82%)] Loss: 46949124.000000\n",
      "Train Epoch: 6 [768/918 (84%)] Loss: 49817328.000000\n",
      "Train Epoch: 6 [784/918 (85%)] Loss: 47562428.000000\n",
      "Train Epoch: 6 [800/918 (87%)] Loss: 50974752.000000\n",
      "Train Epoch: 6 [816/918 (89%)] Loss: 37289404.000000\n",
      "Train Epoch: 6 [832/918 (91%)] Loss: 43580496.000000\n",
      "Train Epoch: 6 [848/918 (92%)] Loss: 45143232.000000\n",
      "Train Epoch: 6 [864/918 (94%)] Loss: 48525960.000000\n",
      "Train Epoch: 6 [880/918 (96%)] Loss: 42387168.000000\n",
      "Train Epoch: 6 [896/918 (98%)] Loss: 45495580.000000\n",
      "Train Epoch: 6 [912/918 (99%)] Loss: 40113136.000000\n",
      "    epoch          : 6\n",
      "    loss           : 44415153.91304348\n",
      "    ess            : 12.614346474149952\n",
      "    log_marginal   : -44415152.20869565\n",
      "    val_loss       : 47858848.461538464\n",
      "    val_ess        : 12.509858828324537\n",
      "    val_log_marginal: -47858846.461538464\n",
      "Train Epoch: 7 [0/918 (0%)] Loss: 43008172.000000\n",
      "Train Epoch: 7 [16/918 (2%)] Loss: 44719208.000000\n",
      "Train Epoch: 7 [32/918 (3%)] Loss: 53930012.000000\n",
      "Train Epoch: 7 [48/918 (5%)] Loss: 42370940.000000\n",
      "Train Epoch: 7 [64/918 (7%)] Loss: 40907232.000000\n",
      "Train Epoch: 7 [80/918 (9%)] Loss: 46290848.000000\n",
      "Train Epoch: 7 [96/918 (10%)] Loss: 41940424.000000\n",
      "Train Epoch: 7 [112/918 (12%)] Loss: 43475996.000000\n",
      "Train Epoch: 7 [128/918 (14%)] Loss: 36030056.000000\n",
      "Train Epoch: 7 [144/918 (16%)] Loss: 41562876.000000\n",
      "Train Epoch: 7 [160/918 (17%)] Loss: 45084668.000000\n",
      "Train Epoch: 7 [176/918 (19%)] Loss: 57170356.000000\n",
      "Train Epoch: 7 [192/918 (21%)] Loss: 37605692.000000\n",
      "Train Epoch: 7 [208/918 (23%)] Loss: 47770552.000000\n",
      "Train Epoch: 7 [224/918 (24%)] Loss: 46801884.000000\n",
      "Train Epoch: 7 [240/918 (26%)] Loss: 40992404.000000\n",
      "Train Epoch: 7 [256/918 (28%)] Loss: 41400704.000000\n",
      "Train Epoch: 7 [272/918 (30%)] Loss: 44939704.000000\n",
      "Train Epoch: 7 [288/918 (31%)] Loss: 41548332.000000\n",
      "Train Epoch: 7 [304/918 (33%)] Loss: 39005636.000000\n",
      "Train Epoch: 7 [320/918 (35%)] Loss: 51656624.000000\n",
      "Train Epoch: 7 [336/918 (37%)] Loss: 34386992.000000\n",
      "Train Epoch: 7 [352/918 (38%)] Loss: 49089388.000000\n",
      "Train Epoch: 7 [368/918 (40%)] Loss: 44293932.000000\n",
      "Train Epoch: 7 [384/918 (42%)] Loss: 47203096.000000\n",
      "Train Epoch: 7 [400/918 (44%)] Loss: 35062248.000000\n",
      "Train Epoch: 7 [416/918 (45%)] Loss: 36166848.000000\n",
      "Train Epoch: 7 [432/918 (47%)] Loss: 34593852.000000\n",
      "Train Epoch: 7 [448/918 (49%)] Loss: 45431148.000000\n",
      "Train Epoch: 7 [464/918 (51%)] Loss: 43556576.000000\n",
      "Train Epoch: 7 [480/918 (52%)] Loss: 49890076.000000\n",
      "Train Epoch: 7 [496/918 (54%)] Loss: 47493280.000000\n",
      "Train Epoch: 7 [512/918 (56%)] Loss: 49050448.000000\n",
      "Train Epoch: 7 [528/918 (58%)] Loss: 47248764.000000\n",
      "Train Epoch: 7 [544/918 (59%)] Loss: 41006716.000000\n",
      "Train Epoch: 7 [560/918 (61%)] Loss: 40759712.000000\n",
      "Train Epoch: 7 [576/918 (63%)] Loss: 33751840.000000\n",
      "Train Epoch: 7 [592/918 (64%)] Loss: 36924880.000000\n",
      "Train Epoch: 7 [608/918 (66%)] Loss: 49237928.000000\n",
      "Train Epoch: 7 [624/918 (68%)] Loss: 45986844.000000\n",
      "Train Epoch: 7 [640/918 (70%)] Loss: 35841680.000000\n",
      "Train Epoch: 7 [656/918 (71%)] Loss: 39550536.000000\n",
      "Train Epoch: 7 [672/918 (73%)] Loss: 52079120.000000\n",
      "Train Epoch: 7 [688/918 (75%)] Loss: 41355676.000000\n",
      "Train Epoch: 7 [704/918 (77%)] Loss: 44915348.000000\n",
      "Train Epoch: 7 [720/918 (78%)] Loss: 47181500.000000\n",
      "Train Epoch: 7 [736/918 (80%)] Loss: 41346824.000000\n",
      "Train Epoch: 7 [752/918 (82%)] Loss: 44012204.000000\n",
      "Train Epoch: 7 [768/918 (84%)] Loss: 43127600.000000\n",
      "Train Epoch: 7 [784/918 (85%)] Loss: 41135068.000000\n",
      "Train Epoch: 7 [800/918 (87%)] Loss: 43542088.000000\n",
      "Train Epoch: 7 [816/918 (89%)] Loss: 31501242.000000\n",
      "Train Epoch: 7 [832/918 (91%)] Loss: 51626296.000000\n",
      "Train Epoch: 7 [848/918 (92%)] Loss: 39852080.000000\n",
      "Train Epoch: 7 [864/918 (94%)] Loss: 33774992.000000\n",
      "Train Epoch: 7 [880/918 (96%)] Loss: 49123580.000000\n",
      "Train Epoch: 7 [896/918 (98%)] Loss: 39198600.000000\n",
      "Train Epoch: 7 [912/918 (99%)] Loss: 41877528.000000\n",
      "    epoch          : 7\n",
      "    loss           : 43291289.79130435\n",
      "    ess            : 13.897455648753954\n",
      "    log_marginal   : -43291288.104347825\n",
      "    val_loss       : 47042764.615384616\n",
      "    val_ess        : 13.086659027979923\n",
      "    val_log_marginal: -47042763.384615384\n",
      "Train Epoch: 8 [0/918 (0%)] Loss: 37490172.000000\n",
      "Train Epoch: 8 [16/918 (2%)] Loss: 48277260.000000\n",
      "Train Epoch: 8 [32/918 (3%)] Loss: 40467772.000000\n",
      "Train Epoch: 8 [48/918 (5%)] Loss: 50696312.000000\n",
      "Train Epoch: 8 [64/918 (7%)] Loss: 44638132.000000\n",
      "Train Epoch: 8 [80/918 (9%)] Loss: 47593644.000000\n",
      "Train Epoch: 8 [96/918 (10%)] Loss: 41494848.000000\n",
      "Train Epoch: 8 [112/918 (12%)] Loss: 44308960.000000\n",
      "Train Epoch: 8 [128/918 (14%)] Loss: 43363252.000000\n",
      "Train Epoch: 8 [144/918 (16%)] Loss: 41707232.000000\n",
      "Train Epoch: 8 [160/918 (17%)] Loss: 43892048.000000\n",
      "Train Epoch: 8 [176/918 (19%)] Loss: 36369536.000000\n",
      "Train Epoch: 8 [192/918 (21%)] Loss: 41472204.000000\n",
      "Train Epoch: 8 [208/918 (23%)] Loss: 36956736.000000\n",
      "Train Epoch: 8 [224/918 (24%)] Loss: 45353912.000000\n",
      "Train Epoch: 8 [240/918 (26%)] Loss: 41144848.000000\n",
      "Train Epoch: 8 [256/918 (28%)] Loss: 40706764.000000\n",
      "Train Epoch: 8 [272/918 (30%)] Loss: 36921168.000000\n",
      "Train Epoch: 8 [288/918 (31%)] Loss: 50496056.000000\n",
      "Train Epoch: 8 [304/918 (33%)] Loss: 46345568.000000\n",
      "Train Epoch: 8 [320/918 (35%)] Loss: 48252408.000000\n",
      "Train Epoch: 8 [336/918 (37%)] Loss: 37599804.000000\n",
      "Train Epoch: 8 [352/918 (38%)] Loss: 43449448.000000\n",
      "Train Epoch: 8 [368/918 (40%)] Loss: 48041080.000000\n",
      "Train Epoch: 8 [384/918 (42%)] Loss: 46344468.000000\n",
      "Train Epoch: 8 [400/918 (44%)] Loss: 42765020.000000\n",
      "Train Epoch: 8 [416/918 (45%)] Loss: 47321120.000000\n",
      "Train Epoch: 8 [432/918 (47%)] Loss: 36383920.000000\n",
      "Train Epoch: 8 [448/918 (49%)] Loss: 39123968.000000\n",
      "Train Epoch: 8 [464/918 (51%)] Loss: 41043868.000000\n",
      "Train Epoch: 8 [480/918 (52%)] Loss: 34516040.000000\n",
      "Train Epoch: 8 [496/918 (54%)] Loss: 41637128.000000\n",
      "Train Epoch: 8 [512/918 (56%)] Loss: 45258336.000000\n",
      "Train Epoch: 8 [528/918 (58%)] Loss: 39775912.000000\n",
      "Train Epoch: 8 [544/918 (59%)] Loss: 49265836.000000\n",
      "Train Epoch: 8 [560/918 (61%)] Loss: 42643156.000000\n",
      "Train Epoch: 8 [576/918 (63%)] Loss: 47880940.000000\n",
      "Train Epoch: 8 [592/918 (64%)] Loss: 36796872.000000\n",
      "Train Epoch: 8 [608/918 (66%)] Loss: 43134272.000000\n",
      "Train Epoch: 8 [624/918 (68%)] Loss: 37457976.000000\n",
      "Train Epoch: 8 [640/918 (70%)] Loss: 51270392.000000\n",
      "Train Epoch: 8 [656/918 (71%)] Loss: 37940508.000000\n",
      "Train Epoch: 8 [672/918 (73%)] Loss: 45575712.000000\n",
      "Train Epoch: 8 [688/918 (75%)] Loss: 39681672.000000\n",
      "Train Epoch: 8 [704/918 (77%)] Loss: 33210966.000000\n",
      "Train Epoch: 8 [720/918 (78%)] Loss: 45309856.000000\n",
      "Train Epoch: 8 [736/918 (80%)] Loss: 44574656.000000\n",
      "Train Epoch: 8 [752/918 (82%)] Loss: 42561352.000000\n",
      "Train Epoch: 8 [768/918 (84%)] Loss: 39903996.000000\n",
      "Train Epoch: 8 [784/918 (85%)] Loss: 43179536.000000\n",
      "Train Epoch: 8 [800/918 (87%)] Loss: 43291132.000000\n",
      "Train Epoch: 8 [816/918 (89%)] Loss: 38249608.000000\n",
      "Train Epoch: 8 [832/918 (91%)] Loss: 36988944.000000\n",
      "Train Epoch: 8 [848/918 (92%)] Loss: 41832384.000000\n",
      "Train Epoch: 8 [864/918 (94%)] Loss: 52315900.000000\n",
      "Train Epoch: 8 [880/918 (96%)] Loss: 41953192.000000\n",
      "Train Epoch: 8 [896/918 (98%)] Loss: 44390504.000000\n",
      "Train Epoch: 8 [912/918 (99%)] Loss: 43434068.000000\n",
      "    epoch          : 8\n",
      "    loss           : 42476337.026086956\n",
      "    ess            : 13.664420198357623\n",
      "    log_marginal   : -42476335.39130435\n",
      "    val_loss       : 46964233.538461536\n",
      "    val_ess        : 13.258447977212759\n",
      "    val_log_marginal: -46964232.615384616\n",
      "Train Epoch: 9 [0/918 (0%)] Loss: 41456808.000000\n",
      "Train Epoch: 9 [16/918 (2%)] Loss: 33068854.000000\n",
      "Train Epoch: 9 [32/918 (3%)] Loss: 44982796.000000\n",
      "Train Epoch: 9 [48/918 (5%)] Loss: 36212180.000000\n",
      "Train Epoch: 9 [64/918 (7%)] Loss: 41236092.000000\n",
      "Train Epoch: 9 [80/918 (9%)] Loss: 39584912.000000\n",
      "Train Epoch: 9 [96/918 (10%)] Loss: 47569648.000000\n",
      "Train Epoch: 9 [112/918 (12%)] Loss: 33384848.000000\n",
      "Train Epoch: 9 [128/918 (14%)] Loss: 43209320.000000\n",
      "Train Epoch: 9 [144/918 (16%)] Loss: 48362016.000000\n",
      "Train Epoch: 9 [160/918 (17%)] Loss: 39010876.000000\n",
      "Train Epoch: 9 [176/918 (19%)] Loss: 39510368.000000\n",
      "Train Epoch: 9 [192/918 (21%)] Loss: 41570476.000000\n",
      "Train Epoch: 9 [208/918 (23%)] Loss: 43561896.000000\n",
      "Train Epoch: 9 [224/918 (24%)] Loss: 41101484.000000\n",
      "Train Epoch: 9 [240/918 (26%)] Loss: 41705032.000000\n",
      "Train Epoch: 9 [256/918 (28%)] Loss: 55398092.000000\n",
      "Train Epoch: 9 [272/918 (30%)] Loss: 46252460.000000\n",
      "Train Epoch: 9 [288/918 (31%)] Loss: 58596244.000000\n",
      "Train Epoch: 9 [304/918 (33%)] Loss: 50862000.000000\n",
      "Train Epoch: 9 [320/918 (35%)] Loss: 35945152.000000\n",
      "Train Epoch: 9 [336/918 (37%)] Loss: 42280168.000000\n",
      "Train Epoch: 9 [352/918 (38%)] Loss: 39804328.000000\n",
      "Train Epoch: 9 [368/918 (40%)] Loss: 35961516.000000\n",
      "Train Epoch: 9 [384/918 (42%)] Loss: 46357996.000000\n",
      "Train Epoch: 9 [400/918 (44%)] Loss: 42863568.000000\n",
      "Train Epoch: 9 [416/918 (45%)] Loss: 37905632.000000\n",
      "Train Epoch: 9 [432/918 (47%)] Loss: 47121096.000000\n",
      "Train Epoch: 9 [448/918 (49%)] Loss: 30579696.000000\n",
      "Train Epoch: 9 [464/918 (51%)] Loss: 43336912.000000\n",
      "Train Epoch: 9 [480/918 (52%)] Loss: 49485368.000000\n",
      "Train Epoch: 9 [496/918 (54%)] Loss: 50899188.000000\n",
      "Train Epoch: 9 [512/918 (56%)] Loss: 36586504.000000\n",
      "Train Epoch: 9 [528/918 (58%)] Loss: 43491920.000000\n",
      "Train Epoch: 9 [544/918 (59%)] Loss: 31337376.000000\n",
      "Train Epoch: 9 [560/918 (61%)] Loss: 31306278.000000\n",
      "Train Epoch: 9 [576/918 (63%)] Loss: 43609920.000000\n",
      "Train Epoch: 9 [592/918 (64%)] Loss: 33644236.000000\n",
      "Train Epoch: 9 [608/918 (66%)] Loss: 34420052.000000\n",
      "Train Epoch: 9 [624/918 (68%)] Loss: 37427636.000000\n",
      "Train Epoch: 9 [640/918 (70%)] Loss: 41310700.000000\n",
      "Train Epoch: 9 [656/918 (71%)] Loss: 39530060.000000\n",
      "Train Epoch: 9 [672/918 (73%)] Loss: 38707420.000000\n",
      "Train Epoch: 9 [688/918 (75%)] Loss: 39545696.000000\n",
      "Train Epoch: 9 [704/918 (77%)] Loss: 31046682.000000\n",
      "Train Epoch: 9 [720/918 (78%)] Loss: 37732812.000000\n",
      "Train Epoch: 9 [736/918 (80%)] Loss: 42103980.000000\n",
      "Train Epoch: 9 [752/918 (82%)] Loss: 40859904.000000\n",
      "Train Epoch: 9 [768/918 (84%)] Loss: 48168940.000000\n",
      "Train Epoch: 9 [784/918 (85%)] Loss: 38984360.000000\n",
      "Train Epoch: 9 [800/918 (87%)] Loss: 41964528.000000\n",
      "Train Epoch: 9 [816/918 (89%)] Loss: 40130140.000000\n",
      "Train Epoch: 9 [832/918 (91%)] Loss: 36405872.000000\n",
      "Train Epoch: 9 [848/918 (92%)] Loss: 42904756.000000\n",
      "Train Epoch: 9 [864/918 (94%)] Loss: 38840788.000000\n",
      "Train Epoch: 9 [880/918 (96%)] Loss: 38400840.000000\n",
      "Train Epoch: 9 [896/918 (98%)] Loss: 45532640.000000\n",
      "Train Epoch: 9 [912/918 (99%)] Loss: 49608188.000000\n",
      "    epoch          : 9\n",
      "    loss           : 41956066.43478261\n",
      "    ess            : 14.072232217374056\n",
      "    log_marginal   : -41956064.95652174\n",
      "    val_loss       : 46437004.92307692\n",
      "    val_ess        : 15.086693103496845\n",
      "    val_log_marginal: -46437003.07692308\n",
      "Train Epoch: 10 [0/918 (0%)] Loss: 44115536.000000\n",
      "Train Epoch: 10 [16/918 (2%)] Loss: 38596188.000000\n",
      "Train Epoch: 10 [32/918 (3%)] Loss: 48347704.000000\n",
      "Train Epoch: 10 [48/918 (5%)] Loss: 43398004.000000\n",
      "Train Epoch: 10 [64/918 (7%)] Loss: 33622892.000000\n",
      "Train Epoch: 10 [80/918 (9%)] Loss: 39241040.000000\n",
      "Train Epoch: 10 [96/918 (10%)] Loss: 38101716.000000\n",
      "Train Epoch: 10 [112/918 (12%)] Loss: 45814092.000000\n",
      "Train Epoch: 10 [128/918 (14%)] Loss: 40577536.000000\n",
      "Train Epoch: 10 [144/918 (16%)] Loss: 37144360.000000\n",
      "Train Epoch: 10 [160/918 (17%)] Loss: 36783840.000000\n",
      "Train Epoch: 10 [176/918 (19%)] Loss: 44291228.000000\n",
      "Train Epoch: 10 [192/918 (21%)] Loss: 40890408.000000\n",
      "Train Epoch: 10 [208/918 (23%)] Loss: 45341248.000000\n",
      "Train Epoch: 10 [224/918 (24%)] Loss: 48761484.000000\n",
      "Train Epoch: 10 [240/918 (26%)] Loss: 47979136.000000\n",
      "Train Epoch: 10 [256/918 (28%)] Loss: 36132424.000000\n",
      "Train Epoch: 10 [272/918 (30%)] Loss: 42097256.000000\n",
      "Train Epoch: 10 [288/918 (31%)] Loss: 41445024.000000\n",
      "Train Epoch: 10 [304/918 (33%)] Loss: 43119508.000000\n",
      "Train Epoch: 10 [320/918 (35%)] Loss: 40086580.000000\n",
      "Train Epoch: 10 [336/918 (37%)] Loss: 42665820.000000\n",
      "Train Epoch: 10 [352/918 (38%)] Loss: 29431654.000000\n",
      "Train Epoch: 10 [368/918 (40%)] Loss: 35655488.000000\n",
      "Train Epoch: 10 [384/918 (42%)] Loss: 46666216.000000\n",
      "Train Epoch: 10 [400/918 (44%)] Loss: 41934036.000000\n",
      "Train Epoch: 10 [416/918 (45%)] Loss: 29944870.000000\n",
      "Train Epoch: 10 [432/918 (47%)] Loss: 44560780.000000\n",
      "Train Epoch: 10 [448/918 (49%)] Loss: 42253728.000000\n",
      "Train Epoch: 10 [464/918 (51%)] Loss: 43113440.000000\n",
      "Train Epoch: 10 [480/918 (52%)] Loss: 52646368.000000\n",
      "Train Epoch: 10 [496/918 (54%)] Loss: 41074368.000000\n",
      "Train Epoch: 10 [512/918 (56%)] Loss: 44618828.000000\n",
      "Train Epoch: 10 [528/918 (58%)] Loss: 41916660.000000\n",
      "Train Epoch: 10 [544/918 (59%)] Loss: 39074888.000000\n",
      "Train Epoch: 10 [560/918 (61%)] Loss: 47552952.000000\n",
      "Train Epoch: 10 [576/918 (63%)] Loss: 52854860.000000\n",
      "Train Epoch: 10 [592/918 (64%)] Loss: 42789328.000000\n",
      "Train Epoch: 10 [608/918 (66%)] Loss: 41168544.000000\n",
      "Train Epoch: 10 [624/918 (68%)] Loss: 39383076.000000\n",
      "Train Epoch: 10 [640/918 (70%)] Loss: 41297932.000000\n",
      "Train Epoch: 10 [656/918 (71%)] Loss: 38258300.000000\n",
      "Train Epoch: 10 [672/918 (73%)] Loss: 47505068.000000\n",
      "Train Epoch: 10 [688/918 (75%)] Loss: 39953136.000000\n",
      "Train Epoch: 10 [704/918 (77%)] Loss: 40120744.000000\n",
      "Train Epoch: 10 [720/918 (78%)] Loss: 39754156.000000\n",
      "Train Epoch: 10 [736/918 (80%)] Loss: 35628896.000000\n",
      "Train Epoch: 10 [752/918 (82%)] Loss: 34954768.000000\n",
      "Train Epoch: 10 [768/918 (84%)] Loss: 39438864.000000\n",
      "Train Epoch: 10 [784/918 (85%)] Loss: 37147304.000000\n",
      "Train Epoch: 10 [800/918 (87%)] Loss: 48605484.000000\n",
      "Train Epoch: 10 [816/918 (89%)] Loss: 44653712.000000\n",
      "Train Epoch: 10 [832/918 (91%)] Loss: 31119482.000000\n",
      "Train Epoch: 10 [848/918 (92%)] Loss: 51249164.000000\n",
      "Train Epoch: 10 [864/918 (94%)] Loss: 41116176.000000\n",
      "Train Epoch: 10 [880/918 (96%)] Loss: 37880988.000000\n",
      "Train Epoch: 10 [896/918 (98%)] Loss: 35911880.000000\n",
      "Train Epoch: 10 [912/918 (99%)] Loss: 33206508.000000\n",
      "    epoch          : 10\n",
      "    loss           : 41528588.556521736\n",
      "    ess            : 14.201224928316863\n",
      "    log_marginal   : -41528586.71304348\n",
      "    val_loss       : 45882722.15384615\n",
      "    val_ess        : 14.117392650017372\n",
      "    val_log_marginal: -45882720.615384616\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [0/918 (0%)] Loss: 39865248.000000\n",
      "Train Epoch: 11 [16/918 (2%)] Loss: 35690992.000000\n",
      "Train Epoch: 11 [32/918 (3%)] Loss: 40801212.000000\n",
      "Train Epoch: 11 [48/918 (5%)] Loss: 35980624.000000\n",
      "Train Epoch: 11 [64/918 (7%)] Loss: 37271264.000000\n",
      "Train Epoch: 11 [80/918 (9%)] Loss: 40626968.000000\n",
      "Train Epoch: 11 [96/918 (10%)] Loss: 42776584.000000\n",
      "Train Epoch: 11 [112/918 (12%)] Loss: 41454600.000000\n",
      "Train Epoch: 11 [128/918 (14%)] Loss: 43245344.000000\n",
      "Train Epoch: 11 [144/918 (16%)] Loss: 41947264.000000\n",
      "Train Epoch: 11 [160/918 (17%)] Loss: 44133308.000000\n",
      "Train Epoch: 11 [176/918 (19%)] Loss: 46076096.000000\n",
      "Train Epoch: 11 [192/918 (21%)] Loss: 39430812.000000\n",
      "Train Epoch: 11 [208/918 (23%)] Loss: 48748548.000000\n",
      "Train Epoch: 11 [224/918 (24%)] Loss: 40285984.000000\n",
      "Train Epoch: 11 [240/918 (26%)] Loss: 46553560.000000\n",
      "Train Epoch: 11 [256/918 (28%)] Loss: 37882044.000000\n",
      "Train Epoch: 11 [272/918 (30%)] Loss: 37765548.000000\n",
      "Train Epoch: 11 [288/918 (31%)] Loss: 40803900.000000\n",
      "Train Epoch: 11 [304/918 (33%)] Loss: 44467792.000000\n",
      "Train Epoch: 11 [320/918 (35%)] Loss: 33324654.000000\n",
      "Train Epoch: 11 [336/918 (37%)] Loss: 28423678.000000\n",
      "Train Epoch: 11 [352/918 (38%)] Loss: 47977120.000000\n",
      "Train Epoch: 11 [368/918 (40%)] Loss: 42698144.000000\n",
      "Train Epoch: 11 [384/918 (42%)] Loss: 48198380.000000\n",
      "Train Epoch: 11 [400/918 (44%)] Loss: 41778768.000000\n",
      "Train Epoch: 11 [416/918 (45%)] Loss: 41496436.000000\n",
      "Train Epoch: 11 [432/918 (47%)] Loss: 47859148.000000\n",
      "Train Epoch: 11 [448/918 (49%)] Loss: 39119292.000000\n",
      "Train Epoch: 11 [464/918 (51%)] Loss: 42573948.000000\n",
      "Train Epoch: 11 [480/918 (52%)] Loss: 44530396.000000\n",
      "Train Epoch: 11 [496/918 (54%)] Loss: 41288224.000000\n",
      "Train Epoch: 11 [512/918 (56%)] Loss: 34625500.000000\n",
      "Train Epoch: 11 [528/918 (58%)] Loss: 34654464.000000\n",
      "Train Epoch: 11 [544/918 (59%)] Loss: 44501032.000000\n",
      "Train Epoch: 11 [560/918 (61%)] Loss: 36569468.000000\n",
      "Train Epoch: 11 [576/918 (63%)] Loss: 40830364.000000\n",
      "Train Epoch: 11 [592/918 (64%)] Loss: 33737372.000000\n",
      "Train Epoch: 11 [608/918 (66%)] Loss: 34566420.000000\n",
      "Train Epoch: 11 [624/918 (68%)] Loss: 45300888.000000\n",
      "Train Epoch: 11 [640/918 (70%)] Loss: 42715264.000000\n",
      "Train Epoch: 11 [656/918 (71%)] Loss: 37612856.000000\n",
      "Train Epoch: 11 [672/918 (73%)] Loss: 40019576.000000\n",
      "Train Epoch: 11 [688/918 (75%)] Loss: 40630440.000000\n",
      "Train Epoch: 11 [704/918 (77%)] Loss: 40069288.000000\n",
      "Train Epoch: 11 [720/918 (78%)] Loss: 43848916.000000\n",
      "Train Epoch: 11 [736/918 (80%)] Loss: 37349904.000000\n",
      "Train Epoch: 11 [752/918 (82%)] Loss: 44389384.000000\n",
      "Train Epoch: 11 [768/918 (84%)] Loss: 42530004.000000\n",
      "Train Epoch: 11 [784/918 (85%)] Loss: 38521084.000000\n",
      "Train Epoch: 11 [800/918 (87%)] Loss: 41329868.000000\n",
      "Train Epoch: 11 [816/918 (89%)] Loss: 39253000.000000\n",
      "Train Epoch: 11 [832/918 (91%)] Loss: 40163232.000000\n",
      "Train Epoch: 11 [848/918 (92%)] Loss: 44167688.000000\n",
      "Train Epoch: 11 [864/918 (94%)] Loss: 42923720.000000\n",
      "Train Epoch: 11 [880/918 (96%)] Loss: 42378956.000000\n",
      "Train Epoch: 11 [896/918 (98%)] Loss: 35410444.000000\n",
      "Train Epoch: 11 [912/918 (99%)] Loss: 23819656.000000\n",
      "    epoch          : 11\n",
      "    loss           : 41125654.26086956\n",
      "    ess            : 15.751578977833624\n",
      "    log_marginal   : -41125652.539130434\n",
      "    val_loss       : 45665321.84615385\n",
      "    val_ess        : 13.49167026923253\n",
      "    val_log_marginal: -45665320.92307692\n",
      "Train Epoch: 12 [0/918 (0%)] Loss: 47789004.000000\n",
      "Train Epoch: 12 [16/918 (2%)] Loss: 32362388.000000\n",
      "Train Epoch: 12 [32/918 (3%)] Loss: 41124640.000000\n",
      "Train Epoch: 12 [48/918 (5%)] Loss: 43470844.000000\n",
      "Train Epoch: 12 [64/918 (7%)] Loss: 41427240.000000\n",
      "Train Epoch: 12 [80/918 (9%)] Loss: 32739738.000000\n",
      "Train Epoch: 12 [96/918 (10%)] Loss: 45302936.000000\n",
      "Train Epoch: 12 [112/918 (12%)] Loss: 42544176.000000\n",
      "Train Epoch: 12 [128/918 (14%)] Loss: 36305288.000000\n",
      "Train Epoch: 12 [144/918 (16%)] Loss: 39955392.000000\n",
      "Train Epoch: 12 [160/918 (17%)] Loss: 38772220.000000\n",
      "Train Epoch: 12 [176/918 (19%)] Loss: 39639840.000000\n",
      "Train Epoch: 12 [192/918 (21%)] Loss: 40837052.000000\n",
      "Train Epoch: 12 [208/918 (23%)] Loss: 36689552.000000\n",
      "Train Epoch: 12 [224/918 (24%)] Loss: 43513920.000000\n",
      "Train Epoch: 12 [240/918 (26%)] Loss: 33503046.000000\n",
      "Train Epoch: 12 [256/918 (28%)] Loss: 31525968.000000\n",
      "Train Epoch: 12 [272/918 (30%)] Loss: 34540916.000000\n",
      "Train Epoch: 12 [288/918 (31%)] Loss: 42521900.000000\n",
      "Train Epoch: 12 [304/918 (33%)] Loss: 44550272.000000\n",
      "Train Epoch: 12 [320/918 (35%)] Loss: 40722828.000000\n",
      "Train Epoch: 12 [336/918 (37%)] Loss: 41222256.000000\n",
      "Train Epoch: 12 [352/918 (38%)] Loss: 34148556.000000\n",
      "Train Epoch: 12 [368/918 (40%)] Loss: 46767768.000000\n",
      "Train Epoch: 12 [384/918 (42%)] Loss: 41647820.000000\n",
      "Train Epoch: 12 [400/918 (44%)] Loss: 41114476.000000\n",
      "Train Epoch: 12 [416/918 (45%)] Loss: 41212008.000000\n",
      "Train Epoch: 12 [432/918 (47%)] Loss: 43074064.000000\n",
      "Train Epoch: 12 [448/918 (49%)] Loss: 39461736.000000\n",
      "Train Epoch: 12 [464/918 (51%)] Loss: 36956136.000000\n",
      "Train Epoch: 12 [480/918 (52%)] Loss: 45071744.000000\n",
      "Train Epoch: 12 [496/918 (54%)] Loss: 41957248.000000\n",
      "Train Epoch: 12 [512/918 (56%)] Loss: 37599900.000000\n",
      "Train Epoch: 12 [528/918 (58%)] Loss: 35859820.000000\n",
      "Train Epoch: 12 [544/918 (59%)] Loss: 44131828.000000\n",
      "Train Epoch: 12 [560/918 (61%)] Loss: 52120020.000000\n",
      "Train Epoch: 12 [576/918 (63%)] Loss: 45329932.000000\n",
      "Train Epoch: 12 [592/918 (64%)] Loss: 41321900.000000\n",
      "Train Epoch: 12 [608/918 (66%)] Loss: 38055420.000000\n",
      "Train Epoch: 12 [624/918 (68%)] Loss: 41736208.000000\n",
      "Train Epoch: 12 [640/918 (70%)] Loss: 43090656.000000\n",
      "Train Epoch: 12 [656/918 (71%)] Loss: 31383270.000000\n",
      "Train Epoch: 12 [672/918 (73%)] Loss: 37966848.000000\n",
      "Train Epoch: 12 [688/918 (75%)] Loss: 48273388.000000\n",
      "Train Epoch: 12 [704/918 (77%)] Loss: 41184812.000000\n",
      "Train Epoch: 12 [720/918 (78%)] Loss: 35800720.000000\n",
      "Train Epoch: 12 [736/918 (80%)] Loss: 36670980.000000\n",
      "Train Epoch: 12 [752/918 (82%)] Loss: 40248392.000000\n",
      "Train Epoch: 12 [768/918 (84%)] Loss: 41556360.000000\n",
      "Train Epoch: 12 [784/918 (85%)] Loss: 43140464.000000\n",
      "Train Epoch: 12 [800/918 (87%)] Loss: 39893744.000000\n",
      "Train Epoch: 12 [816/918 (89%)] Loss: 35347080.000000\n",
      "Train Epoch: 12 [832/918 (91%)] Loss: 40402128.000000\n",
      "Train Epoch: 12 [848/918 (92%)] Loss: 36217660.000000\n",
      "Train Epoch: 12 [864/918 (94%)] Loss: 36762748.000000\n",
      "Train Epoch: 12 [880/918 (96%)] Loss: 43187856.000000\n",
      "Train Epoch: 12 [896/918 (98%)] Loss: 46245452.000000\n",
      "Train Epoch: 12 [912/918 (99%)] Loss: 41562736.000000\n",
      "    epoch          : 12\n",
      "    loss           : 40997935.895652175\n",
      "    ess            : 14.647876191139222\n",
      "    log_marginal   : -40997934.069565214\n",
      "    val_loss       : 45917436.0\n",
      "    val_ess        : 11.368769498971792\n",
      "    val_log_marginal: -45917434.0\n",
      "Train Epoch: 13 [0/918 (0%)] Loss: 46180704.000000\n",
      "Train Epoch: 13 [16/918 (2%)] Loss: 37025144.000000\n",
      "Train Epoch: 13 [32/918 (3%)] Loss: 40533384.000000\n",
      "Train Epoch: 13 [48/918 (5%)] Loss: 49501248.000000\n",
      "Train Epoch: 13 [64/918 (7%)] Loss: 39556488.000000\n",
      "Train Epoch: 13 [80/918 (9%)] Loss: 39943400.000000\n",
      "Train Epoch: 13 [96/918 (10%)] Loss: 38468668.000000\n",
      "Train Epoch: 13 [112/918 (12%)] Loss: 36610528.000000\n",
      "Train Epoch: 13 [128/918 (14%)] Loss: 38872200.000000\n",
      "Train Epoch: 13 [144/918 (16%)] Loss: 38904488.000000\n",
      "Train Epoch: 13 [160/918 (17%)] Loss: 53590652.000000\n",
      "Train Epoch: 13 [176/918 (19%)] Loss: 42336796.000000\n",
      "Train Epoch: 13 [192/918 (21%)] Loss: 48963284.000000\n",
      "Train Epoch: 13 [208/918 (23%)] Loss: 45176688.000000\n",
      "Train Epoch: 13 [224/918 (24%)] Loss: 39870044.000000\n",
      "Train Epoch: 13 [240/918 (26%)] Loss: 45262060.000000\n",
      "Train Epoch: 13 [256/918 (28%)] Loss: 41548960.000000\n",
      "Train Epoch: 13 [272/918 (30%)] Loss: 38794716.000000\n",
      "Train Epoch: 13 [288/918 (31%)] Loss: 48061464.000000\n",
      "Train Epoch: 13 [304/918 (33%)] Loss: 36916212.000000\n",
      "Train Epoch: 13 [320/918 (35%)] Loss: 41707856.000000\n",
      "Train Epoch: 13 [336/918 (37%)] Loss: 35695856.000000\n",
      "Train Epoch: 13 [352/918 (38%)] Loss: 35527952.000000\n",
      "Train Epoch: 13 [368/918 (40%)] Loss: 43892464.000000\n",
      "Train Epoch: 13 [384/918 (42%)] Loss: 41494640.000000\n",
      "Train Epoch: 13 [400/918 (44%)] Loss: 48248588.000000\n",
      "Train Epoch: 13 [416/918 (45%)] Loss: 34134908.000000\n",
      "Train Epoch: 13 [432/918 (47%)] Loss: 35680076.000000\n",
      "Train Epoch: 13 [448/918 (49%)] Loss: 39545152.000000\n",
      "Train Epoch: 13 [464/918 (51%)] Loss: 37705640.000000\n",
      "Train Epoch: 13 [480/918 (52%)] Loss: 43894880.000000\n",
      "Train Epoch: 13 [496/918 (54%)] Loss: 42819904.000000\n",
      "Train Epoch: 13 [512/918 (56%)] Loss: 48177528.000000\n",
      "Train Epoch: 13 [528/918 (58%)] Loss: 37204908.000000\n",
      "Train Epoch: 13 [544/918 (59%)] Loss: 44385840.000000\n",
      "Train Epoch: 13 [560/918 (61%)] Loss: 55456796.000000\n",
      "Train Epoch: 13 [576/918 (63%)] Loss: 36334976.000000\n",
      "Train Epoch: 13 [592/918 (64%)] Loss: 38456456.000000\n",
      "Train Epoch: 13 [608/918 (66%)] Loss: 35879776.000000\n",
      "Train Epoch: 13 [624/918 (68%)] Loss: 36841872.000000\n",
      "Train Epoch: 13 [640/918 (70%)] Loss: 33799144.000000\n",
      "Train Epoch: 13 [656/918 (71%)] Loss: 36787144.000000\n",
      "Train Epoch: 13 [672/918 (73%)] Loss: 45315564.000000\n",
      "Train Epoch: 13 [688/918 (75%)] Loss: 33373760.000000\n",
      "Train Epoch: 13 [704/918 (77%)] Loss: 38374300.000000\n",
      "Train Epoch: 13 [720/918 (78%)] Loss: 35635752.000000\n",
      "Train Epoch: 13 [736/918 (80%)] Loss: 39762576.000000\n",
      "Train Epoch: 13 [752/918 (82%)] Loss: 35051392.000000\n",
      "Train Epoch: 13 [768/918 (84%)] Loss: 41730824.000000\n",
      "Train Epoch: 13 [784/918 (85%)] Loss: 41512220.000000\n",
      "Train Epoch: 13 [800/918 (87%)] Loss: 34859824.000000\n",
      "Train Epoch: 13 [816/918 (89%)] Loss: 37388936.000000\n",
      "Train Epoch: 13 [832/918 (91%)] Loss: 40255996.000000\n",
      "Train Epoch: 13 [848/918 (92%)] Loss: 38830688.000000\n",
      "Train Epoch: 13 [864/918 (94%)] Loss: 38583752.000000\n",
      "Train Epoch: 13 [880/918 (96%)] Loss: 50992168.000000\n",
      "Train Epoch: 13 [896/918 (98%)] Loss: 34904572.000000\n",
      "Train Epoch: 13 [912/918 (99%)] Loss: 40997660.000000\n",
      "    epoch          : 13\n",
      "    loss           : 40694404.45217391\n",
      "    ess            : 15.075107784893202\n",
      "    log_marginal   : -40694402.36521739\n",
      "    val_loss       : 45701326.461538464\n",
      "    val_ess        : 13.773814824911264\n",
      "    val_log_marginal: -45701325.23076923\n",
      "Train Epoch: 14 [0/918 (0%)] Loss: 38439504.000000\n",
      "Train Epoch: 14 [16/918 (2%)] Loss: 34973052.000000\n",
      "Train Epoch: 14 [32/918 (3%)] Loss: 39650044.000000\n",
      "Train Epoch: 14 [48/918 (5%)] Loss: 39079664.000000\n",
      "Train Epoch: 14 [64/918 (7%)] Loss: 46093408.000000\n",
      "Train Epoch: 14 [80/918 (9%)] Loss: 34054368.000000\n",
      "Train Epoch: 14 [96/918 (10%)] Loss: 35737928.000000\n",
      "Train Epoch: 14 [112/918 (12%)] Loss: 52548184.000000\n",
      "Train Epoch: 14 [128/918 (14%)] Loss: 45860100.000000\n",
      "Train Epoch: 14 [144/918 (16%)] Loss: 44507128.000000\n",
      "Train Epoch: 14 [160/918 (17%)] Loss: 38010624.000000\n",
      "Train Epoch: 14 [176/918 (19%)] Loss: 42422992.000000\n",
      "Train Epoch: 14 [192/918 (21%)] Loss: 34118580.000000\n",
      "Train Epoch: 14 [208/918 (23%)] Loss: 46063476.000000\n",
      "Train Epoch: 14 [224/918 (24%)] Loss: 35029164.000000\n",
      "Train Epoch: 14 [240/918 (26%)] Loss: 56845868.000000\n",
      "Train Epoch: 14 [256/918 (28%)] Loss: 46876332.000000\n",
      "Train Epoch: 14 [272/918 (30%)] Loss: 37503964.000000\n",
      "Train Epoch: 14 [288/918 (31%)] Loss: 36311068.000000\n",
      "Train Epoch: 14 [304/918 (33%)] Loss: 50941788.000000\n",
      "Train Epoch: 14 [320/918 (35%)] Loss: 47886060.000000\n",
      "Train Epoch: 14 [336/918 (37%)] Loss: 39299632.000000\n",
      "Train Epoch: 14 [352/918 (38%)] Loss: 47393436.000000\n",
      "Train Epoch: 14 [368/918 (40%)] Loss: 40873576.000000\n",
      "Train Epoch: 14 [384/918 (42%)] Loss: 42164656.000000\n",
      "Train Epoch: 14 [400/918 (44%)] Loss: 42007740.000000\n",
      "Train Epoch: 14 [416/918 (45%)] Loss: 39159660.000000\n",
      "Train Epoch: 14 [432/918 (47%)] Loss: 40982728.000000\n",
      "Train Epoch: 14 [448/918 (49%)] Loss: 44738688.000000\n",
      "Train Epoch: 14 [464/918 (51%)] Loss: 36374656.000000\n",
      "Train Epoch: 14 [480/918 (52%)] Loss: 41792296.000000\n",
      "Train Epoch: 14 [496/918 (54%)] Loss: 43477212.000000\n",
      "Train Epoch: 14 [512/918 (56%)] Loss: 38499900.000000\n",
      "Train Epoch: 14 [528/918 (58%)] Loss: 43096944.000000\n",
      "Train Epoch: 14 [544/918 (59%)] Loss: 45872928.000000\n",
      "Train Epoch: 14 [560/918 (61%)] Loss: 44392060.000000\n",
      "Train Epoch: 14 [576/918 (63%)] Loss: 51609132.000000\n",
      "Train Epoch: 14 [592/918 (64%)] Loss: 46259356.000000\n",
      "Train Epoch: 14 [608/918 (66%)] Loss: 38962664.000000\n",
      "Train Epoch: 14 [624/918 (68%)] Loss: 39244028.000000\n",
      "Train Epoch: 14 [640/918 (70%)] Loss: 37347292.000000\n",
      "Train Epoch: 14 [656/918 (71%)] Loss: 37038992.000000\n",
      "Train Epoch: 14 [672/918 (73%)] Loss: 40150344.000000\n",
      "Train Epoch: 14 [688/918 (75%)] Loss: 36340720.000000\n",
      "Train Epoch: 14 [704/918 (77%)] Loss: 38155936.000000\n",
      "Train Epoch: 14 [720/918 (78%)] Loss: 43796896.000000\n",
      "Train Epoch: 14 [736/918 (80%)] Loss: 38228816.000000\n",
      "Train Epoch: 14 [752/918 (82%)] Loss: 35247296.000000\n",
      "Train Epoch: 14 [768/918 (84%)] Loss: 43455752.000000\n",
      "Train Epoch: 14 [784/918 (85%)] Loss: 33043406.000000\n",
      "Train Epoch: 14 [800/918 (87%)] Loss: 46823468.000000\n",
      "Train Epoch: 14 [816/918 (89%)] Loss: 43570984.000000\n",
      "Train Epoch: 14 [832/918 (91%)] Loss: 39578592.000000\n",
      "Train Epoch: 14 [848/918 (92%)] Loss: 46887340.000000\n",
      "Train Epoch: 14 [864/918 (94%)] Loss: 42784840.000000\n",
      "Train Epoch: 14 [880/918 (96%)] Loss: 36384412.000000\n",
      "Train Epoch: 14 [896/918 (98%)] Loss: 38427848.000000\n",
      "Train Epoch: 14 [912/918 (99%)] Loss: 33349220.000000\n",
      "    epoch          : 14\n",
      "    loss           : 40578247.11304348\n",
      "    ess            : 15.904621082803477\n",
      "    log_marginal   : -40578245.51304348\n",
      "    val_loss       : 45727255.07692308\n",
      "    val_ess        : 14.976337322821983\n",
      "    val_log_marginal: -45727253.23076923\n",
      "Train Epoch: 15 [0/918 (0%)] Loss: 42830164.000000\n",
      "Train Epoch: 15 [16/918 (2%)] Loss: 40659436.000000\n",
      "Train Epoch: 15 [32/918 (3%)] Loss: 37486024.000000\n",
      "Train Epoch: 15 [48/918 (5%)] Loss: 35863040.000000\n",
      "Train Epoch: 15 [64/918 (7%)] Loss: 39669228.000000\n",
      "Train Epoch: 15 [80/918 (9%)] Loss: 38912552.000000\n",
      "Train Epoch: 15 [96/918 (10%)] Loss: 34761884.000000\n",
      "Train Epoch: 15 [112/918 (12%)] Loss: 42072880.000000\n",
      "Train Epoch: 15 [128/918 (14%)] Loss: 34648212.000000\n",
      "Train Epoch: 15 [144/918 (16%)] Loss: 37734652.000000\n",
      "Train Epoch: 15 [160/918 (17%)] Loss: 45680764.000000\n",
      "Train Epoch: 15 [176/918 (19%)] Loss: 35215856.000000\n",
      "Train Epoch: 15 [192/918 (21%)] Loss: 39270368.000000\n",
      "Train Epoch: 15 [208/918 (23%)] Loss: 30178762.000000\n",
      "Train Epoch: 15 [224/918 (24%)] Loss: 36758592.000000\n",
      "Train Epoch: 15 [240/918 (26%)] Loss: 36435616.000000\n",
      "Train Epoch: 15 [256/918 (28%)] Loss: 28806660.000000\n",
      "Train Epoch: 15 [272/918 (30%)] Loss: 31430752.000000\n",
      "Train Epoch: 15 [288/918 (31%)] Loss: 41309040.000000\n",
      "Train Epoch: 15 [304/918 (33%)] Loss: 36862332.000000\n",
      "Train Epoch: 15 [320/918 (35%)] Loss: 43655024.000000\n",
      "Train Epoch: 15 [336/918 (37%)] Loss: 43015868.000000\n",
      "Train Epoch: 15 [352/918 (38%)] Loss: 40202768.000000\n",
      "Train Epoch: 15 [368/918 (40%)] Loss: 41880700.000000\n",
      "Train Epoch: 15 [384/918 (42%)] Loss: 37345640.000000\n",
      "Train Epoch: 15 [400/918 (44%)] Loss: 47730220.000000\n",
      "Train Epoch: 15 [416/918 (45%)] Loss: 42725708.000000\n",
      "Train Epoch: 15 [432/918 (47%)] Loss: 52149708.000000\n",
      "Train Epoch: 15 [448/918 (49%)] Loss: 35438504.000000\n",
      "Train Epoch: 15 [464/918 (51%)] Loss: 45783260.000000\n",
      "Train Epoch: 15 [480/918 (52%)] Loss: 43500460.000000\n",
      "Train Epoch: 15 [496/918 (54%)] Loss: 35558836.000000\n",
      "Train Epoch: 15 [512/918 (56%)] Loss: 45593112.000000\n",
      "Train Epoch: 15 [528/918 (58%)] Loss: 40391688.000000\n",
      "Train Epoch: 15 [544/918 (59%)] Loss: 54855912.000000\n",
      "Train Epoch: 15 [560/918 (61%)] Loss: 44564508.000000\n",
      "Train Epoch: 15 [576/918 (63%)] Loss: 39476796.000000\n",
      "Train Epoch: 15 [592/918 (64%)] Loss: 34890492.000000\n",
      "Train Epoch: 15 [608/918 (66%)] Loss: 38426264.000000\n",
      "Train Epoch: 15 [624/918 (68%)] Loss: 30669968.000000\n",
      "Train Epoch: 15 [640/918 (70%)] Loss: 37077552.000000\n",
      "Train Epoch: 15 [656/918 (71%)] Loss: 39379804.000000\n",
      "Train Epoch: 15 [672/918 (73%)] Loss: 34591808.000000\n",
      "Train Epoch: 15 [688/918 (75%)] Loss: 40275756.000000\n",
      "Train Epoch: 15 [704/918 (77%)] Loss: 33755360.000000\n",
      "Train Epoch: 15 [720/918 (78%)] Loss: 38407484.000000\n",
      "Train Epoch: 15 [736/918 (80%)] Loss: 41307260.000000\n",
      "Train Epoch: 15 [752/918 (82%)] Loss: 40101152.000000\n",
      "Train Epoch: 15 [768/918 (84%)] Loss: 46255360.000000\n",
      "Train Epoch: 15 [784/918 (85%)] Loss: 44217100.000000\n",
      "Train Epoch: 15 [800/918 (87%)] Loss: 41342880.000000\n",
      "Train Epoch: 15 [816/918 (89%)] Loss: 44592064.000000\n",
      "Train Epoch: 15 [832/918 (91%)] Loss: 33721772.000000\n",
      "Train Epoch: 15 [848/918 (92%)] Loss: 38739280.000000\n",
      "Train Epoch: 15 [864/918 (94%)] Loss: 41542048.000000\n",
      "Train Epoch: 15 [880/918 (96%)] Loss: 45028208.000000\n",
      "Train Epoch: 15 [896/918 (98%)] Loss: 45415160.000000\n",
      "Train Epoch: 15 [912/918 (99%)] Loss: 34664884.000000\n",
      "    epoch          : 15\n",
      "    loss           : 40328154.36521739\n",
      "    ess            : 15.353927097113235\n",
      "    log_marginal   : -40328151.94782609\n",
      "    val_loss       : 45426736.76923077\n",
      "    val_ess        : 13.086659027979923\n",
      "    val_log_marginal: -45426735.23076923\n",
      "Train Epoch: 16 [0/918 (0%)] Loss: 31142480.000000\n",
      "Train Epoch: 16 [16/918 (2%)] Loss: 30336934.000000\n",
      "Train Epoch: 16 [32/918 (3%)] Loss: 29100582.000000\n",
      "Train Epoch: 16 [48/918 (5%)] Loss: 37431828.000000\n",
      "Train Epoch: 16 [64/918 (7%)] Loss: 33178452.000000\n",
      "Train Epoch: 16 [80/918 (9%)] Loss: 36842204.000000\n",
      "Train Epoch: 16 [96/918 (10%)] Loss: 42658688.000000\n",
      "Train Epoch: 16 [112/918 (12%)] Loss: 35690624.000000\n",
      "Train Epoch: 16 [128/918 (14%)] Loss: 36063580.000000\n",
      "Train Epoch: 16 [144/918 (16%)] Loss: 45827248.000000\n",
      "Train Epoch: 16 [160/918 (17%)] Loss: 38763948.000000\n",
      "Train Epoch: 16 [176/918 (19%)] Loss: 41156704.000000\n",
      "Train Epoch: 16 [192/918 (21%)] Loss: 41472896.000000\n",
      "Train Epoch: 16 [208/918 (23%)] Loss: 48014380.000000\n",
      "Train Epoch: 16 [224/918 (24%)] Loss: 38096360.000000\n",
      "Train Epoch: 16 [240/918 (26%)] Loss: 43867856.000000\n",
      "Train Epoch: 16 [256/918 (28%)] Loss: 40422396.000000\n",
      "Train Epoch: 16 [272/918 (30%)] Loss: 33929256.000000\n",
      "Train Epoch: 16 [288/918 (31%)] Loss: 47141144.000000\n",
      "Train Epoch: 16 [304/918 (33%)] Loss: 37426212.000000\n",
      "Train Epoch: 16 [320/918 (35%)] Loss: 39380688.000000\n",
      "Train Epoch: 16 [336/918 (37%)] Loss: 45543792.000000\n",
      "Train Epoch: 16 [352/918 (38%)] Loss: 49405232.000000\n",
      "Train Epoch: 16 [368/918 (40%)] Loss: 40175888.000000\n",
      "Train Epoch: 16 [384/918 (42%)] Loss: 39696796.000000\n",
      "Train Epoch: 16 [400/918 (44%)] Loss: 38050364.000000\n",
      "Train Epoch: 16 [416/918 (45%)] Loss: 43595252.000000\n",
      "Train Epoch: 16 [432/918 (47%)] Loss: 45308556.000000\n",
      "Train Epoch: 16 [448/918 (49%)] Loss: 41508960.000000\n",
      "Train Epoch: 16 [464/918 (51%)] Loss: 39113936.000000\n",
      "Train Epoch: 16 [480/918 (52%)] Loss: 44334568.000000\n",
      "Train Epoch: 16 [496/918 (54%)] Loss: 36676748.000000\n",
      "Train Epoch: 16 [512/918 (56%)] Loss: 30727418.000000\n",
      "Train Epoch: 16 [528/918 (58%)] Loss: 39912872.000000\n",
      "Train Epoch: 16 [544/918 (59%)] Loss: 39627344.000000\n",
      "Train Epoch: 16 [560/918 (61%)] Loss: 41537888.000000\n",
      "Train Epoch: 16 [576/918 (63%)] Loss: 42162252.000000\n",
      "Train Epoch: 16 [592/918 (64%)] Loss: 35566688.000000\n",
      "Train Epoch: 16 [608/918 (66%)] Loss: 38185596.000000\n",
      "Train Epoch: 16 [624/918 (68%)] Loss: 43196960.000000\n",
      "Train Epoch: 16 [640/918 (70%)] Loss: 33768956.000000\n",
      "Train Epoch: 16 [656/918 (71%)] Loss: 40774544.000000\n",
      "Train Epoch: 16 [672/918 (73%)] Loss: 38084180.000000\n",
      "Train Epoch: 16 [688/918 (75%)] Loss: 33586988.000000\n",
      "Train Epoch: 16 [704/918 (77%)] Loss: 33910364.000000\n",
      "Train Epoch: 16 [720/918 (78%)] Loss: 45112912.000000\n",
      "Train Epoch: 16 [736/918 (80%)] Loss: 38093352.000000\n",
      "Train Epoch: 16 [752/918 (82%)] Loss: 44304220.000000\n",
      "Train Epoch: 16 [768/918 (84%)] Loss: 35315592.000000\n",
      "Train Epoch: 16 [784/918 (85%)] Loss: 39642820.000000\n",
      "Train Epoch: 16 [800/918 (87%)] Loss: 34656904.000000\n",
      "Train Epoch: 16 [816/918 (89%)] Loss: 38206024.000000\n",
      "Train Epoch: 16 [832/918 (91%)] Loss: 33951584.000000\n",
      "Train Epoch: 16 [848/918 (92%)] Loss: 44664872.000000\n",
      "Train Epoch: 16 [864/918 (94%)] Loss: 45934956.000000\n",
      "Train Epoch: 16 [880/918 (96%)] Loss: 46944828.000000\n",
      "Train Epoch: 16 [896/918 (98%)] Loss: 48548784.000000\n",
      "Train Epoch: 16 [912/918 (99%)] Loss: 34642032.000000\n",
      "    epoch          : 16\n",
      "    loss           : 40189180.973913044\n",
      "    ess            : 15.94346028825511\n",
      "    log_marginal   : -40189179.73913044\n",
      "    val_loss       : 45457500.92307692\n",
      "    val_ess        : 13.945603737464317\n",
      "    val_log_marginal: -45457498.76923077\n",
      "Train Epoch: 17 [0/918 (0%)] Loss: 36249300.000000\n",
      "Train Epoch: 17 [16/918 (2%)] Loss: 42440416.000000\n",
      "Train Epoch: 17 [32/918 (3%)] Loss: 54219868.000000\n",
      "Train Epoch: 17 [48/918 (5%)] Loss: 39036648.000000\n",
      "Train Epoch: 17 [64/918 (7%)] Loss: 38696232.000000\n",
      "Train Epoch: 17 [80/918 (9%)] Loss: 38715168.000000\n",
      "Train Epoch: 17 [96/918 (10%)] Loss: 37746076.000000\n",
      "Train Epoch: 17 [112/918 (12%)] Loss: 40313544.000000\n",
      "Train Epoch: 17 [128/918 (14%)] Loss: 28012710.000000\n",
      "Train Epoch: 17 [144/918 (16%)] Loss: 33117126.000000\n",
      "Train Epoch: 17 [160/918 (17%)] Loss: 37519104.000000\n",
      "Train Epoch: 17 [176/918 (19%)] Loss: 42534816.000000\n",
      "Train Epoch: 17 [192/918 (21%)] Loss: 43720496.000000\n",
      "Train Epoch: 17 [208/918 (23%)] Loss: 33418670.000000\n",
      "Train Epoch: 17 [224/918 (24%)] Loss: 46109848.000000\n",
      "Train Epoch: 17 [240/918 (26%)] Loss: 40345576.000000\n",
      "Train Epoch: 17 [256/918 (28%)] Loss: 33492558.000000\n",
      "Train Epoch: 17 [272/918 (30%)] Loss: 39796208.000000\n",
      "Train Epoch: 17 [288/918 (31%)] Loss: 32326036.000000\n",
      "Train Epoch: 17 [304/918 (33%)] Loss: 40124736.000000\n",
      "Train Epoch: 17 [320/918 (35%)] Loss: 30528986.000000\n",
      "Train Epoch: 17 [336/918 (37%)] Loss: 40063056.000000\n",
      "Train Epoch: 17 [352/918 (38%)] Loss: 44776464.000000\n",
      "Train Epoch: 17 [368/918 (40%)] Loss: 34516916.000000\n",
      "Train Epoch: 17 [384/918 (42%)] Loss: 46498448.000000\n",
      "Train Epoch: 17 [400/918 (44%)] Loss: 34518344.000000\n",
      "Train Epoch: 17 [416/918 (45%)] Loss: 42709276.000000\n",
      "Train Epoch: 17 [432/918 (47%)] Loss: 37212668.000000\n",
      "Train Epoch: 17 [448/918 (49%)] Loss: 37334968.000000\n",
      "Train Epoch: 17 [464/918 (51%)] Loss: 46273112.000000\n",
      "Train Epoch: 17 [480/918 (52%)] Loss: 40659696.000000\n",
      "Train Epoch: 17 [496/918 (54%)] Loss: 47340116.000000\n",
      "Train Epoch: 17 [512/918 (56%)] Loss: 31272528.000000\n",
      "Train Epoch: 17 [528/918 (58%)] Loss: 34789976.000000\n",
      "Train Epoch: 17 [544/918 (59%)] Loss: 45638348.000000\n",
      "Train Epoch: 17 [560/918 (61%)] Loss: 46485144.000000\n",
      "Train Epoch: 17 [576/918 (63%)] Loss: 45763164.000000\n",
      "Train Epoch: 17 [592/918 (64%)] Loss: 38608448.000000\n",
      "Train Epoch: 17 [608/918 (66%)] Loss: 50293904.000000\n",
      "Train Epoch: 17 [624/918 (68%)] Loss: 39831488.000000\n",
      "Train Epoch: 17 [640/918 (70%)] Loss: 40238376.000000\n",
      "Train Epoch: 17 [656/918 (71%)] Loss: 39763488.000000\n",
      "Train Epoch: 17 [672/918 (73%)] Loss: 34642624.000000\n",
      "Train Epoch: 17 [688/918 (75%)] Loss: 38901120.000000\n",
      "Train Epoch: 17 [704/918 (77%)] Loss: 38233084.000000\n",
      "Train Epoch: 17 [720/918 (78%)] Loss: 40559728.000000\n",
      "Train Epoch: 17 [736/918 (80%)] Loss: 39620956.000000\n",
      "Train Epoch: 17 [752/918 (82%)] Loss: 33232558.000000\n",
      "Train Epoch: 17 [768/918 (84%)] Loss: 43748400.000000\n",
      "Train Epoch: 17 [784/918 (85%)] Loss: 43074812.000000\n",
      "Train Epoch: 17 [800/918 (87%)] Loss: 37950984.000000\n",
      "Train Epoch: 17 [816/918 (89%)] Loss: 52730284.000000\n",
      "Train Epoch: 17 [832/918 (91%)] Loss: 38130008.000000\n",
      "Train Epoch: 17 [848/918 (92%)] Loss: 32524346.000000\n",
      "Train Epoch: 17 [864/918 (94%)] Loss: 35318440.000000\n",
      "Train Epoch: 17 [880/918 (96%)] Loss: 42610940.000000\n",
      "Train Epoch: 17 [896/918 (98%)] Loss: 40862044.000000\n",
      "Train Epoch: 17 [912/918 (99%)] Loss: 37822072.000000\n",
      "    epoch          : 17\n",
      "    loss           : 40066096.15652174\n",
      "    ess            : 15.840831858178843\n",
      "    log_marginal   : -40066094.20869565\n",
      "    val_loss       : 44880492.307692304\n",
      "    val_ess        : 14.9763373870116\n",
      "    val_log_marginal: -44880491.07692308\n",
      "Train Epoch: 18 [0/918 (0%)] Loss: 39167744.000000\n",
      "Train Epoch: 18 [16/918 (2%)] Loss: 40830348.000000\n",
      "Train Epoch: 18 [32/918 (3%)] Loss: 43064640.000000\n",
      "Train Epoch: 18 [48/918 (5%)] Loss: 33646560.000000\n",
      "Train Epoch: 18 [64/918 (7%)] Loss: 33841836.000000\n",
      "Train Epoch: 18 [80/918 (9%)] Loss: 41520200.000000\n",
      "Train Epoch: 18 [96/918 (10%)] Loss: 59089824.000000\n",
      "Train Epoch: 18 [112/918 (12%)] Loss: 42124124.000000\n",
      "Train Epoch: 18 [128/918 (14%)] Loss: 38189864.000000\n",
      "Train Epoch: 18 [144/918 (16%)] Loss: 40301032.000000\n",
      "Train Epoch: 18 [160/918 (17%)] Loss: 55711072.000000\n",
      "Train Epoch: 18 [176/918 (19%)] Loss: 44143732.000000\n",
      "Train Epoch: 18 [192/918 (21%)] Loss: 42260848.000000\n",
      "Train Epoch: 18 [208/918 (23%)] Loss: 40282032.000000\n",
      "Train Epoch: 18 [224/918 (24%)] Loss: 40923004.000000\n",
      "Train Epoch: 18 [240/918 (26%)] Loss: 39503100.000000\n",
      "Train Epoch: 18 [256/918 (28%)] Loss: 48571372.000000\n",
      "Train Epoch: 18 [272/918 (30%)] Loss: 44500540.000000\n",
      "Train Epoch: 18 [288/918 (31%)] Loss: 53031708.000000\n",
      "Train Epoch: 18 [304/918 (33%)] Loss: 40215344.000000\n",
      "Train Epoch: 18 [320/918 (35%)] Loss: 46738384.000000\n",
      "Train Epoch: 18 [336/918 (37%)] Loss: 35703176.000000\n",
      "Train Epoch: 18 [352/918 (38%)] Loss: 34435868.000000\n",
      "Train Epoch: 18 [368/918 (40%)] Loss: 33303386.000000\n",
      "Train Epoch: 18 [384/918 (42%)] Loss: 38116720.000000\n",
      "Train Epoch: 18 [400/918 (44%)] Loss: 34375796.000000\n",
      "Train Epoch: 18 [416/918 (45%)] Loss: 48387192.000000\n",
      "Train Epoch: 18 [432/918 (47%)] Loss: 55164456.000000\n",
      "Train Epoch: 18 [448/918 (49%)] Loss: 33477806.000000\n",
      "Train Epoch: 18 [464/918 (51%)] Loss: 32251722.000000\n",
      "Train Epoch: 18 [480/918 (52%)] Loss: 36156624.000000\n",
      "Train Epoch: 18 [496/918 (54%)] Loss: 38722132.000000\n",
      "Train Epoch: 18 [512/918 (56%)] Loss: 39870960.000000\n",
      "Train Epoch: 18 [528/918 (58%)] Loss: 41080208.000000\n",
      "Train Epoch: 18 [544/918 (59%)] Loss: 50501360.000000\n",
      "Train Epoch: 18 [560/918 (61%)] Loss: 43269052.000000\n",
      "Train Epoch: 18 [576/918 (63%)] Loss: 41844320.000000\n",
      "Train Epoch: 18 [592/918 (64%)] Loss: 33498702.000000\n",
      "Train Epoch: 18 [608/918 (66%)] Loss: 37516936.000000\n",
      "Train Epoch: 18 [624/918 (68%)] Loss: 35084348.000000\n",
      "Train Epoch: 18 [640/918 (70%)] Loss: 43663424.000000\n",
      "Train Epoch: 18 [656/918 (71%)] Loss: 40586368.000000\n",
      "Train Epoch: 18 [672/918 (73%)] Loss: 41688788.000000\n",
      "Train Epoch: 18 [688/918 (75%)] Loss: 38712796.000000\n",
      "Train Epoch: 18 [704/918 (77%)] Loss: 38623628.000000\n",
      "Train Epoch: 18 [720/918 (78%)] Loss: 46748028.000000\n",
      "Train Epoch: 18 [736/918 (80%)] Loss: 47181724.000000\n",
      "Train Epoch: 18 [752/918 (82%)] Loss: 34406300.000000\n",
      "Train Epoch: 18 [768/918 (84%)] Loss: 35091472.000000\n",
      "Train Epoch: 18 [784/918 (85%)] Loss: 34859848.000000\n",
      "Train Epoch: 18 [800/918 (87%)] Loss: 37302844.000000\n",
      "Train Epoch: 18 [816/918 (89%)] Loss: 41752908.000000\n",
      "Train Epoch: 18 [832/918 (91%)] Loss: 34909544.000000\n",
      "Train Epoch: 18 [848/918 (92%)] Loss: 44129060.000000\n",
      "Train Epoch: 18 [864/918 (94%)] Loss: 38192556.000000\n",
      "Train Epoch: 18 [880/918 (96%)] Loss: 43952172.000000\n",
      "Train Epoch: 18 [896/918 (98%)] Loss: 33191902.000000\n",
      "Train Epoch: 18 [912/918 (99%)] Loss: 37327340.000000\n",
      "    epoch          : 18\n",
      "    loss           : 39826237.182608694\n",
      "    ess            : 16.76602894741556\n",
      "    log_marginal   : -39826235.39130435\n",
      "    val_loss       : 45607956.615384616\n",
      "    val_ess        : 13.60202575646914\n",
      "    val_log_marginal: -45607954.307692304\n",
      "Train Epoch: 19 [0/918 (0%)] Loss: 36222452.000000\n",
      "Train Epoch: 19 [16/918 (2%)] Loss: 45016476.000000\n",
      "Train Epoch: 19 [32/918 (3%)] Loss: 36502272.000000\n",
      "Train Epoch: 19 [48/918 (5%)] Loss: 37526420.000000\n",
      "Train Epoch: 19 [64/918 (7%)] Loss: 39190760.000000\n",
      "Train Epoch: 19 [80/918 (9%)] Loss: 38049628.000000\n",
      "Train Epoch: 19 [96/918 (10%)] Loss: 50178140.000000\n",
      "Train Epoch: 19 [112/918 (12%)] Loss: 34264120.000000\n",
      "Train Epoch: 19 [128/918 (14%)] Loss: 35952648.000000\n",
      "Train Epoch: 19 [144/918 (16%)] Loss: 31397038.000000\n",
      "Train Epoch: 19 [160/918 (17%)] Loss: 37702560.000000\n",
      "Train Epoch: 19 [176/918 (19%)] Loss: 43898708.000000\n",
      "Train Epoch: 19 [192/918 (21%)] Loss: 37853308.000000\n",
      "Train Epoch: 19 [208/918 (23%)] Loss: 33320836.000000\n",
      "Train Epoch: 19 [224/918 (24%)] Loss: 39638120.000000\n",
      "Train Epoch: 19 [240/918 (26%)] Loss: 40481288.000000\n",
      "Train Epoch: 19 [256/918 (28%)] Loss: 37531176.000000\n",
      "Train Epoch: 19 [272/918 (30%)] Loss: 36194504.000000\n",
      "Train Epoch: 19 [288/918 (31%)] Loss: 47735404.000000\n",
      "Train Epoch: 19 [304/918 (33%)] Loss: 39399756.000000\n",
      "Train Epoch: 19 [320/918 (35%)] Loss: 34994664.000000\n",
      "Train Epoch: 19 [336/918 (37%)] Loss: 31445370.000000\n",
      "Train Epoch: 19 [352/918 (38%)] Loss: 29688340.000000\n",
      "Train Epoch: 19 [368/918 (40%)] Loss: 39319084.000000\n",
      "Train Epoch: 19 [384/918 (42%)] Loss: 40107284.000000\n",
      "Train Epoch: 19 [400/918 (44%)] Loss: 37625320.000000\n",
      "Train Epoch: 19 [416/918 (45%)] Loss: 36297916.000000\n",
      "Train Epoch: 19 [432/918 (47%)] Loss: 35772572.000000\n",
      "Train Epoch: 19 [448/918 (49%)] Loss: 45064416.000000\n",
      "Train Epoch: 19 [464/918 (51%)] Loss: 40972288.000000\n",
      "Train Epoch: 19 [480/918 (52%)] Loss: 42853928.000000\n",
      "Train Epoch: 19 [496/918 (54%)] Loss: 41932072.000000\n",
      "Train Epoch: 19 [512/918 (56%)] Loss: 34432480.000000\n",
      "Train Epoch: 19 [528/918 (58%)] Loss: 35472744.000000\n",
      "Train Epoch: 19 [544/918 (59%)] Loss: 39139196.000000\n",
      "Train Epoch: 19 [560/918 (61%)] Loss: 42631476.000000\n",
      "Train Epoch: 19 [576/918 (63%)] Loss: 38068520.000000\n",
      "Train Epoch: 19 [592/918 (64%)] Loss: 48277200.000000\n",
      "Train Epoch: 19 [608/918 (66%)] Loss: 41965544.000000\n",
      "Train Epoch: 19 [624/918 (68%)] Loss: 33633532.000000\n",
      "Train Epoch: 19 [640/918 (70%)] Loss: 41123540.000000\n",
      "Train Epoch: 19 [656/918 (71%)] Loss: 41466996.000000\n",
      "Train Epoch: 19 [672/918 (73%)] Loss: 38226608.000000\n",
      "Train Epoch: 19 [688/918 (75%)] Loss: 39829800.000000\n",
      "Train Epoch: 19 [704/918 (77%)] Loss: 49101132.000000\n",
      "Train Epoch: 19 [720/918 (78%)] Loss: 38987084.000000\n",
      "Train Epoch: 19 [736/918 (80%)] Loss: 39534864.000000\n",
      "Train Epoch: 19 [752/918 (82%)] Loss: 49595192.000000\n",
      "Train Epoch: 19 [768/918 (84%)] Loss: 36618600.000000\n",
      "Train Epoch: 19 [784/918 (85%)] Loss: 40724736.000000\n",
      "Train Epoch: 19 [800/918 (87%)] Loss: 35968696.000000\n",
      "Train Epoch: 19 [816/918 (89%)] Loss: 43878112.000000\n",
      "Train Epoch: 19 [832/918 (91%)] Loss: 26646264.000000\n",
      "Train Epoch: 19 [848/918 (92%)] Loss: 36636764.000000\n",
      "Train Epoch: 19 [864/918 (94%)] Loss: 35258780.000000\n",
      "Train Epoch: 19 [880/918 (96%)] Loss: 52747648.000000\n",
      "Train Epoch: 19 [896/918 (98%)] Loss: 44970072.000000\n",
      "Train Epoch: 19 [912/918 (99%)] Loss: 42181388.000000\n",
      "    epoch          : 19\n",
      "    loss           : 39599690.50434782\n",
      "    ess            : 16.474734650487484\n",
      "    log_marginal   : -39599688.73043478\n",
      "    val_loss       : 44623338.461538464\n",
      "    val_ess        : 15.51218186891996\n",
      "    val_log_marginal: -44623336.0\n",
      "Train Epoch: 20 [0/918 (0%)] Loss: 34445832.000000\n",
      "Train Epoch: 20 [16/918 (2%)] Loss: 33964720.000000\n",
      "Train Epoch: 20 [32/918 (3%)] Loss: 46061624.000000\n",
      "Train Epoch: 20 [48/918 (5%)] Loss: 45894164.000000\n",
      "Train Epoch: 20 [64/918 (7%)] Loss: 43803156.000000\n",
      "Train Epoch: 20 [80/918 (9%)] Loss: 42920456.000000\n",
      "Train Epoch: 20 [96/918 (10%)] Loss: 40243164.000000\n",
      "Train Epoch: 20 [112/918 (12%)] Loss: 37523028.000000\n",
      "Train Epoch: 20 [128/918 (14%)] Loss: 43751976.000000\n",
      "Train Epoch: 20 [144/918 (16%)] Loss: 39215996.000000\n",
      "Train Epoch: 20 [160/918 (17%)] Loss: 44210516.000000\n",
      "Train Epoch: 20 [176/918 (19%)] Loss: 36605632.000000\n",
      "Train Epoch: 20 [192/918 (21%)] Loss: 40504128.000000\n",
      "Train Epoch: 20 [208/918 (23%)] Loss: 36001176.000000\n",
      "Train Epoch: 20 [224/918 (24%)] Loss: 39282600.000000\n",
      "Train Epoch: 20 [240/918 (26%)] Loss: 43721052.000000\n",
      "Train Epoch: 20 [256/918 (28%)] Loss: 39774920.000000\n",
      "Train Epoch: 20 [272/918 (30%)] Loss: 36892768.000000\n",
      "Train Epoch: 20 [288/918 (31%)] Loss: 40097128.000000\n",
      "Train Epoch: 20 [304/918 (33%)] Loss: 38562576.000000\n",
      "Train Epoch: 20 [320/918 (35%)] Loss: 41263760.000000\n",
      "Train Epoch: 20 [336/918 (37%)] Loss: 51992096.000000\n",
      "Train Epoch: 20 [352/918 (38%)] Loss: 32771540.000000\n",
      "Train Epoch: 20 [368/918 (40%)] Loss: 44697448.000000\n",
      "Train Epoch: 20 [384/918 (42%)] Loss: 34109224.000000\n",
      "Train Epoch: 20 [400/918 (44%)] Loss: 34592784.000000\n",
      "Train Epoch: 20 [416/918 (45%)] Loss: 35156440.000000\n",
      "Train Epoch: 20 [432/918 (47%)] Loss: 38901932.000000\n",
      "Train Epoch: 20 [448/918 (49%)] Loss: 36766784.000000\n",
      "Train Epoch: 20 [464/918 (51%)] Loss: 33117722.000000\n",
      "Train Epoch: 20 [480/918 (52%)] Loss: 35503872.000000\n",
      "Train Epoch: 20 [496/918 (54%)] Loss: 39623792.000000\n",
      "Train Epoch: 20 [512/918 (56%)] Loss: 34878824.000000\n",
      "Train Epoch: 20 [528/918 (58%)] Loss: 30258464.000000\n",
      "Train Epoch: 20 [544/918 (59%)] Loss: 46563564.000000\n",
      "Train Epoch: 20 [560/918 (61%)] Loss: 40402764.000000\n",
      "Train Epoch: 20 [576/918 (63%)] Loss: 33308672.000000\n",
      "Train Epoch: 20 [592/918 (64%)] Loss: 35664904.000000\n",
      "Train Epoch: 20 [608/918 (66%)] Loss: 41819332.000000\n",
      "Train Epoch: 20 [624/918 (68%)] Loss: 36606656.000000\n",
      "Train Epoch: 20 [640/918 (70%)] Loss: 38557908.000000\n",
      "Train Epoch: 20 [656/918 (71%)] Loss: 42271180.000000\n",
      "Train Epoch: 20 [672/918 (73%)] Loss: 35807476.000000\n",
      "Train Epoch: 20 [688/918 (75%)] Loss: 30610534.000000\n",
      "Train Epoch: 20 [704/918 (77%)] Loss: 32160506.000000\n",
      "Train Epoch: 20 [720/918 (78%)] Loss: 37958972.000000\n",
      "Train Epoch: 20 [736/918 (80%)] Loss: 34828604.000000\n",
      "Train Epoch: 20 [752/918 (82%)] Loss: 40886928.000000\n",
      "Train Epoch: 20 [768/918 (84%)] Loss: 47278092.000000\n",
      "Train Epoch: 20 [784/918 (85%)] Loss: 37700784.000000\n",
      "Train Epoch: 20 [800/918 (87%)] Loss: 39306460.000000\n",
      "Train Epoch: 20 [816/918 (89%)] Loss: 37502960.000000\n",
      "Train Epoch: 20 [832/918 (91%)] Loss: 39157704.000000\n",
      "Train Epoch: 20 [848/918 (92%)] Loss: 42455488.000000\n",
      "Train Epoch: 20 [864/918 (94%)] Loss: 33545942.000000\n",
      "Train Epoch: 20 [880/918 (96%)] Loss: 36196784.000000\n",
      "Train Epoch: 20 [896/918 (98%)] Loss: 38380432.000000\n",
      "Train Epoch: 20 [912/918 (99%)] Loss: 39560884.000000\n",
      "    epoch          : 20\n",
      "    loss           : 39352068.313043475\n",
      "    ess            : 16.377636605760326\n",
      "    log_marginal   : -39352066.817391306\n",
      "    val_loss       : 45033600.15384615\n",
      "    val_ess        : 17.037804676936222\n",
      "    val_log_marginal: -45033598.461538464\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch20.pth ...\n",
      "Train Epoch: 21 [0/918 (0%)] Loss: 41447772.000000\n",
      "Train Epoch: 21 [16/918 (2%)] Loss: 33174794.000000\n",
      "Train Epoch: 21 [32/918 (3%)] Loss: 43423624.000000\n",
      "Train Epoch: 21 [48/918 (5%)] Loss: 41972456.000000\n",
      "Train Epoch: 21 [64/918 (7%)] Loss: 42067776.000000\n",
      "Train Epoch: 21 [80/918 (9%)] Loss: 34523632.000000\n",
      "Train Epoch: 21 [96/918 (10%)] Loss: 33073374.000000\n",
      "Train Epoch: 21 [112/918 (12%)] Loss: 35303900.000000\n",
      "Train Epoch: 21 [128/918 (14%)] Loss: 34032020.000000\n",
      "Train Epoch: 21 [144/918 (16%)] Loss: 32231424.000000\n",
      "Train Epoch: 21 [160/918 (17%)] Loss: 44559004.000000\n",
      "Train Epoch: 21 [176/918 (19%)] Loss: 47318960.000000\n",
      "Train Epoch: 21 [192/918 (21%)] Loss: 44798136.000000\n",
      "Train Epoch: 21 [208/918 (23%)] Loss: 38670164.000000\n",
      "Train Epoch: 21 [224/918 (24%)] Loss: 38660108.000000\n",
      "Train Epoch: 21 [240/918 (26%)] Loss: 44957740.000000\n",
      "Train Epoch: 21 [256/918 (28%)] Loss: 45764616.000000\n",
      "Train Epoch: 21 [272/918 (30%)] Loss: 39469608.000000\n",
      "Train Epoch: 21 [288/918 (31%)] Loss: 44359968.000000\n",
      "Train Epoch: 21 [304/918 (33%)] Loss: 32157690.000000\n",
      "Train Epoch: 21 [320/918 (35%)] Loss: 43191784.000000\n",
      "Train Epoch: 21 [336/918 (37%)] Loss: 40337456.000000\n",
      "Train Epoch: 21 [352/918 (38%)] Loss: 35184960.000000\n",
      "Train Epoch: 21 [368/918 (40%)] Loss: 34263820.000000\n",
      "Train Epoch: 21 [384/918 (42%)] Loss: 42270908.000000\n",
      "Train Epoch: 21 [400/918 (44%)] Loss: 45426528.000000\n",
      "Train Epoch: 21 [416/918 (45%)] Loss: 40250176.000000\n",
      "Train Epoch: 21 [432/918 (47%)] Loss: 37319840.000000\n",
      "Train Epoch: 21 [448/918 (49%)] Loss: 51135592.000000\n",
      "Train Epoch: 21 [464/918 (51%)] Loss: 32732768.000000\n",
      "Train Epoch: 21 [480/918 (52%)] Loss: 38747052.000000\n",
      "Train Epoch: 21 [496/918 (54%)] Loss: 40093168.000000\n",
      "Train Epoch: 21 [512/918 (56%)] Loss: 42018888.000000\n",
      "Train Epoch: 21 [528/918 (58%)] Loss: 31451706.000000\n",
      "Train Epoch: 21 [544/918 (59%)] Loss: 42962496.000000\n",
      "Train Epoch: 21 [560/918 (61%)] Loss: 35313244.000000\n",
      "Train Epoch: 21 [576/918 (63%)] Loss: 39293800.000000\n",
      "Train Epoch: 21 [592/918 (64%)] Loss: 36903840.000000\n",
      "Train Epoch: 21 [608/918 (66%)] Loss: 44858696.000000\n",
      "Train Epoch: 21 [624/918 (68%)] Loss: 39397696.000000\n",
      "Train Epoch: 21 [640/918 (70%)] Loss: 58306268.000000\n",
      "Train Epoch: 21 [656/918 (71%)] Loss: 39657852.000000\n",
      "Train Epoch: 21 [672/918 (73%)] Loss: 43271040.000000\n",
      "Train Epoch: 21 [688/918 (75%)] Loss: 39711648.000000\n",
      "Train Epoch: 21 [704/918 (77%)] Loss: 45677232.000000\n",
      "Train Epoch: 21 [720/918 (78%)] Loss: 33294586.000000\n",
      "Train Epoch: 21 [736/918 (80%)] Loss: 38253640.000000\n",
      "Train Epoch: 21 [752/918 (82%)] Loss: 37434696.000000\n",
      "Train Epoch: 21 [768/918 (84%)] Loss: 42722876.000000\n",
      "Train Epoch: 21 [784/918 (85%)] Loss: 51962124.000000\n",
      "Train Epoch: 21 [800/918 (87%)] Loss: 39004916.000000\n",
      "Train Epoch: 21 [816/918 (89%)] Loss: 39019636.000000\n",
      "Train Epoch: 21 [832/918 (91%)] Loss: 36616736.000000\n",
      "Train Epoch: 21 [848/918 (92%)] Loss: 42372144.000000\n",
      "Train Epoch: 21 [864/918 (94%)] Loss: 44949056.000000\n",
      "Train Epoch: 21 [880/918 (96%)] Loss: 35116492.000000\n",
      "Train Epoch: 21 [896/918 (98%)] Loss: 28230906.000000\n",
      "Train Epoch: 21 [912/918 (99%)] Loss: 34598268.000000\n",
      "    epoch          : 21\n",
      "    loss           : 39106593.33913043\n",
      "    ess            : 16.829818235272946\n",
      "    log_marginal   : -39106591.860869564\n",
      "    val_loss       : 43981524.0\n",
      "    val_ess        : 13.77381471487192\n",
      "    val_log_marginal: -43981521.23076923\n",
      "Train Epoch: 22 [0/918 (0%)] Loss: 35139432.000000\n",
      "Train Epoch: 22 [16/918 (2%)] Loss: 38805352.000000\n",
      "Train Epoch: 22 [32/918 (3%)] Loss: 39706672.000000\n",
      "Train Epoch: 22 [48/918 (5%)] Loss: 44638560.000000\n",
      "Train Epoch: 22 [64/918 (7%)] Loss: 38334988.000000\n",
      "Train Epoch: 22 [80/918 (9%)] Loss: 30612224.000000\n",
      "Train Epoch: 22 [96/918 (10%)] Loss: 41872200.000000\n",
      "Train Epoch: 22 [112/918 (12%)] Loss: 36983912.000000\n",
      "Train Epoch: 22 [128/918 (14%)] Loss: 38481992.000000\n",
      "Train Epoch: 22 [144/918 (16%)] Loss: 29570182.000000\n",
      "Train Epoch: 22 [160/918 (17%)] Loss: 39383196.000000\n",
      "Train Epoch: 22 [176/918 (19%)] Loss: 37267884.000000\n",
      "Train Epoch: 22 [192/918 (21%)] Loss: 39819112.000000\n",
      "Train Epoch: 22 [208/918 (23%)] Loss: 33310838.000000\n",
      "Train Epoch: 22 [224/918 (24%)] Loss: 50637536.000000\n",
      "Train Epoch: 22 [240/918 (26%)] Loss: 46566364.000000\n",
      "Train Epoch: 22 [256/918 (28%)] Loss: 42933728.000000\n",
      "Train Epoch: 22 [272/918 (30%)] Loss: 42069364.000000\n",
      "Train Epoch: 22 [288/918 (31%)] Loss: 35874568.000000\n",
      "Train Epoch: 22 [304/918 (33%)] Loss: 43043744.000000\n",
      "Train Epoch: 22 [320/918 (35%)] Loss: 41949752.000000\n",
      "Train Epoch: 22 [336/918 (37%)] Loss: 40317792.000000\n",
      "Train Epoch: 22 [352/918 (38%)] Loss: 38498620.000000\n",
      "Train Epoch: 22 [368/918 (40%)] Loss: 39232572.000000\n",
      "Train Epoch: 22 [384/918 (42%)] Loss: 38559496.000000\n",
      "Train Epoch: 22 [400/918 (44%)] Loss: 46277984.000000\n",
      "Train Epoch: 22 [416/918 (45%)] Loss: 36238444.000000\n",
      "Train Epoch: 22 [432/918 (47%)] Loss: 38362620.000000\n",
      "Train Epoch: 22 [448/918 (49%)] Loss: 34083040.000000\n",
      "Train Epoch: 22 [464/918 (51%)] Loss: 41959640.000000\n",
      "Train Epoch: 22 [480/918 (52%)] Loss: 44104392.000000\n",
      "Train Epoch: 22 [496/918 (54%)] Loss: 38685296.000000\n",
      "Train Epoch: 22 [512/918 (56%)] Loss: 38720668.000000\n",
      "Train Epoch: 22 [528/918 (58%)] Loss: 32787936.000000\n",
      "Train Epoch: 22 [544/918 (59%)] Loss: 33528426.000000\n",
      "Train Epoch: 22 [560/918 (61%)] Loss: 36103708.000000\n",
      "Train Epoch: 22 [576/918 (63%)] Loss: 47684736.000000\n",
      "Train Epoch: 22 [592/918 (64%)] Loss: 37153172.000000\n",
      "Train Epoch: 22 [608/918 (66%)] Loss: 42617788.000000\n",
      "Train Epoch: 22 [624/918 (68%)] Loss: 38725440.000000\n",
      "Train Epoch: 22 [640/918 (70%)] Loss: 35378736.000000\n",
      "Train Epoch: 22 [656/918 (71%)] Loss: 31594334.000000\n",
      "Train Epoch: 22 [672/918 (73%)] Loss: 44722456.000000\n",
      "Train Epoch: 22 [688/918 (75%)] Loss: 36353420.000000\n",
      "Train Epoch: 22 [704/918 (77%)] Loss: 32162784.000000\n",
      "Train Epoch: 22 [720/918 (78%)] Loss: 38925344.000000\n",
      "Train Epoch: 22 [736/918 (80%)] Loss: 33174132.000000\n",
      "Train Epoch: 22 [752/918 (82%)] Loss: 47383000.000000\n",
      "Train Epoch: 22 [768/918 (84%)] Loss: 29153050.000000\n",
      "Train Epoch: 22 [784/918 (85%)] Loss: 42525356.000000\n",
      "Train Epoch: 22 [800/918 (87%)] Loss: 33227040.000000\n",
      "Train Epoch: 22 [816/918 (89%)] Loss: 32918496.000000\n",
      "Train Epoch: 22 [832/918 (91%)] Loss: 36969236.000000\n",
      "Train Epoch: 22 [848/918 (92%)] Loss: 43015144.000000\n",
      "Train Epoch: 22 [864/918 (94%)] Loss: 36951788.000000\n",
      "Train Epoch: 22 [880/918 (96%)] Loss: 32491354.000000\n",
      "Train Epoch: 22 [896/918 (98%)] Loss: 40230204.000000\n",
      "Train Epoch: 22 [912/918 (99%)] Loss: 48719600.000000\n",
      "    epoch          : 22\n",
      "    loss           : 38840779.94782609\n",
      "    ess            : 17.692640266211136\n",
      "    log_marginal   : -38840778.48695652\n",
      "    val_loss       : 43454467.384615384\n",
      "    val_ess        : 18.068538262293888\n",
      "    val_log_marginal: -43454465.384615384\n",
      "Train Epoch: 23 [0/918 (0%)] Loss: 41446688.000000\n",
      "Train Epoch: 23 [16/918 (2%)] Loss: 31606756.000000\n",
      "Train Epoch: 23 [32/918 (3%)] Loss: 36141132.000000\n",
      "Train Epoch: 23 [48/918 (5%)] Loss: 40618152.000000\n",
      "Train Epoch: 23 [64/918 (7%)] Loss: 36593908.000000\n",
      "Train Epoch: 23 [80/918 (9%)] Loss: 35788628.000000\n",
      "Train Epoch: 23 [96/918 (10%)] Loss: 36955760.000000\n",
      "Train Epoch: 23 [112/918 (12%)] Loss: 35478544.000000\n",
      "Train Epoch: 23 [128/918 (14%)] Loss: 44725552.000000\n",
      "Train Epoch: 23 [144/918 (16%)] Loss: 31794798.000000\n",
      "Train Epoch: 23 [160/918 (17%)] Loss: 48531516.000000\n",
      "Train Epoch: 23 [176/918 (19%)] Loss: 38357280.000000\n",
      "Train Epoch: 23 [192/918 (21%)] Loss: 33122704.000000\n",
      "Train Epoch: 23 [208/918 (23%)] Loss: 54231708.000000\n",
      "Train Epoch: 23 [224/918 (24%)] Loss: 31472198.000000\n",
      "Train Epoch: 23 [240/918 (26%)] Loss: 38883976.000000\n",
      "Train Epoch: 23 [256/918 (28%)] Loss: 30059290.000000\n",
      "Train Epoch: 23 [272/918 (30%)] Loss: 27676474.000000\n",
      "Train Epoch: 23 [288/918 (31%)] Loss: 39963212.000000\n",
      "Train Epoch: 23 [304/918 (33%)] Loss: 37250136.000000\n",
      "Train Epoch: 23 [320/918 (35%)] Loss: 36969456.000000\n",
      "Train Epoch: 23 [336/918 (37%)] Loss: 30091290.000000\n",
      "Train Epoch: 23 [352/918 (38%)] Loss: 38392956.000000\n",
      "Train Epoch: 23 [368/918 (40%)] Loss: 36953960.000000\n",
      "Train Epoch: 23 [384/918 (42%)] Loss: 43536704.000000\n",
      "Train Epoch: 23 [400/918 (44%)] Loss: 36113008.000000\n",
      "Train Epoch: 23 [416/918 (45%)] Loss: 37130740.000000\n",
      "Train Epoch: 23 [432/918 (47%)] Loss: 33348154.000000\n",
      "Train Epoch: 23 [448/918 (49%)] Loss: 32577006.000000\n",
      "Train Epoch: 23 [464/918 (51%)] Loss: 32406214.000000\n",
      "Train Epoch: 23 [480/918 (52%)] Loss: 29292014.000000\n",
      "Train Epoch: 23 [496/918 (54%)] Loss: 36956236.000000\n",
      "Train Epoch: 23 [512/918 (56%)] Loss: 39325116.000000\n",
      "Train Epoch: 23 [528/918 (58%)] Loss: 39186544.000000\n",
      "Train Epoch: 23 [544/918 (59%)] Loss: 37695764.000000\n",
      "Train Epoch: 23 [560/918 (61%)] Loss: 31581296.000000\n",
      "Train Epoch: 23 [576/918 (63%)] Loss: 42624680.000000\n",
      "Train Epoch: 23 [592/918 (64%)] Loss: 31760170.000000\n",
      "Train Epoch: 23 [608/918 (66%)] Loss: 35263624.000000\n",
      "Train Epoch: 23 [624/918 (68%)] Loss: 40945512.000000\n",
      "Train Epoch: 23 [640/918 (70%)] Loss: 34266204.000000\n",
      "Train Epoch: 23 [656/918 (71%)] Loss: 38798896.000000\n",
      "Train Epoch: 23 [672/918 (73%)] Loss: 43772808.000000\n",
      "Train Epoch: 23 [688/918 (75%)] Loss: 41111208.000000\n",
      "Train Epoch: 23 [704/918 (77%)] Loss: 51180268.000000\n",
      "Train Epoch: 23 [720/918 (78%)] Loss: 35845468.000000\n",
      "Train Epoch: 23 [736/918 (80%)] Loss: 40489748.000000\n",
      "Train Epoch: 23 [752/918 (82%)] Loss: 33996604.000000\n",
      "Train Epoch: 23 [768/918 (84%)] Loss: 35625740.000000\n",
      "Train Epoch: 23 [784/918 (85%)] Loss: 40526656.000000\n",
      "Train Epoch: 23 [800/918 (87%)] Loss: 42525920.000000\n",
      "Train Epoch: 23 [816/918 (89%)] Loss: 39297212.000000\n",
      "Train Epoch: 23 [832/918 (91%)] Loss: 36505920.000000\n",
      "Train Epoch: 23 [848/918 (92%)] Loss: 44833856.000000\n",
      "Train Epoch: 23 [864/918 (94%)] Loss: 31334756.000000\n",
      "Train Epoch: 23 [880/918 (96%)] Loss: 45892984.000000\n",
      "Train Epoch: 23 [896/918 (98%)] Loss: 27317460.000000\n",
      "Train Epoch: 23 [912/918 (99%)] Loss: 32468274.000000\n",
      "    epoch          : 23\n",
      "    loss           : 38395909.51304348\n",
      "    ess            : 17.69122606360394\n",
      "    log_marginal   : -38395907.80869565\n",
      "    val_loss       : 43394816.461538464\n",
      "    val_ess        : 18.432593969198372\n",
      "    val_log_marginal: -43394813.84615385\n",
      "Train Epoch: 24 [0/918 (0%)] Loss: 35910524.000000\n",
      "Train Epoch: 24 [16/918 (2%)] Loss: 34540208.000000\n",
      "Train Epoch: 24 [32/918 (3%)] Loss: 46125952.000000\n",
      "Train Epoch: 24 [48/918 (5%)] Loss: 39937792.000000\n",
      "Train Epoch: 24 [64/918 (7%)] Loss: 27560238.000000\n",
      "Train Epoch: 24 [80/918 (9%)] Loss: 42581984.000000\n",
      "Train Epoch: 24 [96/918 (10%)] Loss: 42260576.000000\n",
      "Train Epoch: 24 [112/918 (12%)] Loss: 32960692.000000\n",
      "Train Epoch: 24 [128/918 (14%)] Loss: 46479052.000000\n",
      "Train Epoch: 24 [144/918 (16%)] Loss: 30992678.000000\n",
      "Train Epoch: 24 [160/918 (17%)] Loss: 31838976.000000\n",
      "Train Epoch: 24 [176/918 (19%)] Loss: 59633148.000000\n",
      "Train Epoch: 24 [192/918 (21%)] Loss: 41252220.000000\n",
      "Train Epoch: 24 [208/918 (23%)] Loss: 32017850.000000\n",
      "Train Epoch: 24 [224/918 (24%)] Loss: 41877388.000000\n",
      "Train Epoch: 24 [240/918 (26%)] Loss: 38808776.000000\n",
      "Train Epoch: 24 [256/918 (28%)] Loss: 34569884.000000\n",
      "Train Epoch: 24 [272/918 (30%)] Loss: 42357184.000000\n",
      "Train Epoch: 24 [288/918 (31%)] Loss: 34934316.000000\n",
      "Train Epoch: 24 [304/918 (33%)] Loss: 28744480.000000\n",
      "Train Epoch: 24 [320/918 (35%)] Loss: 35137584.000000\n",
      "Train Epoch: 24 [336/918 (37%)] Loss: 34036476.000000\n",
      "Train Epoch: 24 [352/918 (38%)] Loss: 41667176.000000\n",
      "Train Epoch: 24 [368/918 (40%)] Loss: 41342400.000000\n",
      "Train Epoch: 24 [384/918 (42%)] Loss: 37362928.000000\n",
      "Train Epoch: 24 [400/918 (44%)] Loss: 39644720.000000\n",
      "Train Epoch: 24 [416/918 (45%)] Loss: 34263276.000000\n",
      "Train Epoch: 24 [432/918 (47%)] Loss: 40293540.000000\n",
      "Train Epoch: 24 [448/918 (49%)] Loss: 34272000.000000\n",
      "Train Epoch: 24 [464/918 (51%)] Loss: 33269332.000000\n",
      "Train Epoch: 24 [480/918 (52%)] Loss: 36900944.000000\n",
      "Train Epoch: 24 [496/918 (54%)] Loss: 44522124.000000\n",
      "Train Epoch: 24 [512/918 (56%)] Loss: 38033020.000000\n",
      "Train Epoch: 24 [528/918 (58%)] Loss: 37179052.000000\n",
      "Train Epoch: 24 [544/918 (59%)] Loss: 38885608.000000\n",
      "Train Epoch: 24 [560/918 (61%)] Loss: 28246342.000000\n",
      "Train Epoch: 24 [576/918 (63%)] Loss: 49052060.000000\n",
      "Train Epoch: 24 [592/918 (64%)] Loss: 29730544.000000\n",
      "Train Epoch: 24 [608/918 (66%)] Loss: 38524272.000000\n",
      "Train Epoch: 24 [624/918 (68%)] Loss: 40173020.000000\n",
      "Train Epoch: 24 [640/918 (70%)] Loss: 33480806.000000\n",
      "Train Epoch: 24 [656/918 (71%)] Loss: 45086768.000000\n",
      "Train Epoch: 24 [672/918 (73%)] Loss: 34988572.000000\n",
      "Train Epoch: 24 [688/918 (75%)] Loss: 44701184.000000\n",
      "Train Epoch: 24 [704/918 (77%)] Loss: 29240384.000000\n",
      "Train Epoch: 24 [720/918 (78%)] Loss: 39972636.000000\n",
      "Train Epoch: 24 [736/918 (80%)] Loss: 35754588.000000\n",
      "Train Epoch: 24 [752/918 (82%)] Loss: 29840582.000000\n",
      "Train Epoch: 24 [768/918 (84%)] Loss: 44136232.000000\n",
      "Train Epoch: 24 [784/918 (85%)] Loss: 39757776.000000\n",
      "Train Epoch: 24 [800/918 (87%)] Loss: 39971664.000000\n",
      "Train Epoch: 24 [816/918 (89%)] Loss: 33637132.000000\n",
      "Train Epoch: 24 [832/918 (91%)] Loss: 39462896.000000\n",
      "Train Epoch: 24 [848/918 (92%)] Loss: 42999200.000000\n",
      "Train Epoch: 24 [864/918 (94%)] Loss: 38796380.000000\n",
      "Train Epoch: 24 [880/918 (96%)] Loss: 34160720.000000\n",
      "Train Epoch: 24 [896/918 (98%)] Loss: 38269532.000000\n",
      "Train Epoch: 24 [912/918 (99%)] Loss: 38919624.000000\n",
      "    epoch          : 24\n",
      "    loss           : 37985345.443478264\n",
      "    ess            : 18.042193462537682\n",
      "    log_marginal   : -37985343.87826087\n",
      "    val_loss       : 42461155.07692308\n",
      "    val_ess        : 18.06853822561411\n",
      "    val_log_marginal: -42461153.538461536\n",
      "Train Epoch: 25 [0/918 (0%)] Loss: 26708118.000000\n",
      "Train Epoch: 25 [16/918 (2%)] Loss: 45354124.000000\n",
      "Train Epoch: 25 [32/918 (3%)] Loss: 43852464.000000\n",
      "Train Epoch: 25 [48/918 (5%)] Loss: 35900780.000000\n",
      "Train Epoch: 25 [64/918 (7%)] Loss: 47038424.000000\n",
      "Train Epoch: 25 [80/918 (9%)] Loss: 39075200.000000\n",
      "Train Epoch: 25 [96/918 (10%)] Loss: 38750668.000000\n",
      "Train Epoch: 25 [112/918 (12%)] Loss: 32461392.000000\n",
      "Train Epoch: 25 [128/918 (14%)] Loss: 39260828.000000\n",
      "Train Epoch: 25 [144/918 (16%)] Loss: 34099836.000000\n",
      "Train Epoch: 25 [160/918 (17%)] Loss: 35312308.000000\n",
      "Train Epoch: 25 [176/918 (19%)] Loss: 36288636.000000\n",
      "Train Epoch: 25 [192/918 (21%)] Loss: 34496756.000000\n",
      "Train Epoch: 25 [208/918 (23%)] Loss: 37271452.000000\n",
      "Train Epoch: 25 [224/918 (24%)] Loss: 38056476.000000\n",
      "Train Epoch: 25 [240/918 (26%)] Loss: 35973460.000000\n",
      "Train Epoch: 25 [256/918 (28%)] Loss: 38739560.000000\n",
      "Train Epoch: 25 [272/918 (30%)] Loss: 44043996.000000\n",
      "Train Epoch: 25 [288/918 (31%)] Loss: 39446908.000000\n",
      "Train Epoch: 25 [304/918 (33%)] Loss: 38719996.000000\n",
      "Train Epoch: 25 [320/918 (35%)] Loss: 35031116.000000\n",
      "Train Epoch: 25 [336/918 (37%)] Loss: 35871712.000000\n",
      "Train Epoch: 25 [352/918 (38%)] Loss: 34252532.000000\n",
      "Train Epoch: 25 [368/918 (40%)] Loss: 29116110.000000\n",
      "Train Epoch: 25 [384/918 (42%)] Loss: 39104992.000000\n",
      "Train Epoch: 25 [400/918 (44%)] Loss: 35287720.000000\n",
      "Train Epoch: 25 [416/918 (45%)] Loss: 38768892.000000\n",
      "Train Epoch: 25 [432/918 (47%)] Loss: 35671900.000000\n",
      "Train Epoch: 25 [448/918 (49%)] Loss: 34474464.000000\n",
      "Train Epoch: 25 [464/918 (51%)] Loss: 34015696.000000\n",
      "Train Epoch: 25 [480/918 (52%)] Loss: 39279452.000000\n",
      "Train Epoch: 25 [496/918 (54%)] Loss: 26930276.000000\n",
      "Train Epoch: 25 [512/918 (56%)] Loss: 33536550.000000\n",
      "Train Epoch: 25 [528/918 (58%)] Loss: 30801014.000000\n",
      "Train Epoch: 25 [544/918 (59%)] Loss: 41786796.000000\n",
      "Train Epoch: 25 [560/918 (61%)] Loss: 38677888.000000\n",
      "Train Epoch: 25 [576/918 (63%)] Loss: 37679292.000000\n",
      "Train Epoch: 25 [592/918 (64%)] Loss: 44255740.000000\n",
      "Train Epoch: 25 [608/918 (66%)] Loss: 43710248.000000\n",
      "Train Epoch: 25 [624/918 (68%)] Loss: 40877096.000000\n",
      "Train Epoch: 25 [640/918 (70%)] Loss: 38666620.000000\n",
      "Train Epoch: 25 [656/918 (71%)] Loss: 42635536.000000\n",
      "Train Epoch: 25 [672/918 (73%)] Loss: 43915568.000000\n",
      "Train Epoch: 25 [688/918 (75%)] Loss: 32941188.000000\n",
      "Train Epoch: 25 [704/918 (77%)] Loss: 34055528.000000\n",
      "Train Epoch: 25 [720/918 (78%)] Loss: 43349632.000000\n",
      "Train Epoch: 25 [736/918 (80%)] Loss: 46813620.000000\n",
      "Train Epoch: 25 [752/918 (82%)] Loss: 45816352.000000\n",
      "Train Epoch: 25 [768/918 (84%)] Loss: 41875024.000000\n",
      "Train Epoch: 25 [784/918 (85%)] Loss: 36684764.000000\n",
      "Train Epoch: 25 [800/918 (87%)] Loss: 42544164.000000\n",
      "Train Epoch: 25 [816/918 (89%)] Loss: 35049296.000000\n",
      "Train Epoch: 25 [832/918 (91%)] Loss: 40147708.000000\n",
      "Train Epoch: 25 [848/918 (92%)] Loss: 38788652.000000\n",
      "Train Epoch: 25 [864/918 (94%)] Loss: 29627988.000000\n",
      "Train Epoch: 25 [880/918 (96%)] Loss: 39672956.000000\n",
      "Train Epoch: 25 [896/918 (98%)] Loss: 29375840.000000\n",
      "Train Epoch: 25 [912/918 (99%)] Loss: 35070100.000000\n",
      "    epoch          : 25\n",
      "    loss           : 37324531.72173913\n",
      "    ess            : 19.03259398418924\n",
      "    log_marginal   : -37324530.48695652\n",
      "    val_loss       : 42225961.84615385\n",
      "    val_ess        : 19.958216410416824\n",
      "    val_log_marginal: -42225958.92307692\n",
      "Train Epoch: 26 [0/918 (0%)] Loss: 31097988.000000\n",
      "Train Epoch: 26 [16/918 (2%)] Loss: 36418124.000000\n",
      "Train Epoch: 26 [32/918 (3%)] Loss: 34580744.000000\n",
      "Train Epoch: 26 [48/918 (5%)] Loss: 37673788.000000\n",
      "Train Epoch: 26 [64/918 (7%)] Loss: 36299400.000000\n",
      "Train Epoch: 26 [80/918 (9%)] Loss: 35221968.000000\n",
      "Train Epoch: 26 [96/918 (10%)] Loss: 32039200.000000\n",
      "Train Epoch: 26 [112/918 (12%)] Loss: 32852902.000000\n",
      "Train Epoch: 26 [128/918 (14%)] Loss: 38221312.000000\n",
      "Train Epoch: 26 [144/918 (16%)] Loss: 37226748.000000\n",
      "Train Epoch: 26 [160/918 (17%)] Loss: 44974856.000000\n",
      "Train Epoch: 26 [176/918 (19%)] Loss: 38150544.000000\n",
      "Train Epoch: 26 [192/918 (21%)] Loss: 29405120.000000\n",
      "Train Epoch: 26 [208/918 (23%)] Loss: 34525160.000000\n",
      "Train Epoch: 26 [224/918 (24%)] Loss: 34889300.000000\n",
      "Train Epoch: 26 [240/918 (26%)] Loss: 40599552.000000\n",
      "Train Epoch: 26 [256/918 (28%)] Loss: 39140500.000000\n",
      "Train Epoch: 26 [272/918 (30%)] Loss: 33569564.000000\n",
      "Train Epoch: 26 [288/918 (31%)] Loss: 35734524.000000\n",
      "Train Epoch: 26 [304/918 (33%)] Loss: 31343002.000000\n",
      "Train Epoch: 26 [320/918 (35%)] Loss: 41407868.000000\n",
      "Train Epoch: 26 [336/918 (37%)] Loss: 42307792.000000\n",
      "Train Epoch: 26 [352/918 (38%)] Loss: 34098876.000000\n",
      "Train Epoch: 26 [368/918 (40%)] Loss: 40639176.000000\n",
      "Train Epoch: 26 [384/918 (42%)] Loss: 46375188.000000\n",
      "Train Epoch: 26 [400/918 (44%)] Loss: 32977268.000000\n",
      "Train Epoch: 26 [416/918 (45%)] Loss: 44142732.000000\n",
      "Train Epoch: 26 [432/918 (47%)] Loss: 37132544.000000\n",
      "Train Epoch: 26 [448/918 (49%)] Loss: 35186516.000000\n",
      "Train Epoch: 26 [464/918 (51%)] Loss: 34636540.000000\n",
      "Train Epoch: 26 [480/918 (52%)] Loss: 33091526.000000\n",
      "Train Epoch: 26 [496/918 (54%)] Loss: 37976248.000000\n",
      "Train Epoch: 26 [512/918 (56%)] Loss: 33913612.000000\n",
      "Train Epoch: 26 [528/918 (58%)] Loss: 35169000.000000\n",
      "Train Epoch: 26 [544/918 (59%)] Loss: 38518576.000000\n",
      "Train Epoch: 26 [560/918 (61%)] Loss: 33558352.000000\n",
      "Train Epoch: 26 [576/918 (63%)] Loss: 31508196.000000\n",
      "Train Epoch: 26 [592/918 (64%)] Loss: 38932168.000000\n",
      "Train Epoch: 26 [608/918 (66%)] Loss: 34157944.000000\n",
      "Train Epoch: 26 [624/918 (68%)] Loss: 39982708.000000\n",
      "Train Epoch: 26 [640/918 (70%)] Loss: 29800372.000000\n",
      "Train Epoch: 26 [656/918 (71%)] Loss: 38956704.000000\n",
      "Train Epoch: 26 [672/918 (73%)] Loss: 26858356.000000\n",
      "Train Epoch: 26 [688/918 (75%)] Loss: 35816712.000000\n",
      "Train Epoch: 26 [704/918 (77%)] Loss: 31246992.000000\n",
      "Train Epoch: 26 [720/918 (78%)] Loss: 28539118.000000\n",
      "Train Epoch: 26 [736/918 (80%)] Loss: 38400104.000000\n",
      "Train Epoch: 26 [752/918 (82%)] Loss: 45728016.000000\n",
      "Train Epoch: 26 [768/918 (84%)] Loss: 43022644.000000\n",
      "Train Epoch: 26 [784/918 (85%)] Loss: 33260262.000000\n",
      "Train Epoch: 26 [800/918 (87%)] Loss: 38870796.000000\n",
      "Train Epoch: 26 [816/918 (89%)] Loss: 46642584.000000\n",
      "Train Epoch: 26 [832/918 (91%)] Loss: 29790950.000000\n",
      "Train Epoch: 26 [848/918 (92%)] Loss: 38381996.000000\n",
      "Train Epoch: 26 [864/918 (94%)] Loss: 36332616.000000\n",
      "Train Epoch: 26 [880/918 (96%)] Loss: 31890542.000000\n",
      "Train Epoch: 26 [896/918 (98%)] Loss: 36748912.000000\n",
      "Train Epoch: 26 [912/918 (99%)] Loss: 35987684.000000\n",
      "    epoch          : 26\n",
      "    loss           : 36721361.11304348\n",
      "    ess            : 20.197771250683328\n",
      "    log_marginal   : -36721359.63478261\n",
      "    val_loss       : 42129444.615384616\n",
      "    val_ess        : 18.24032710148738\n",
      "    val_log_marginal: -42129442.76923077\n",
      "Train Epoch: 27 [0/918 (0%)] Loss: 26515932.000000\n",
      "Train Epoch: 27 [16/918 (2%)] Loss: 42356268.000000\n",
      "Train Epoch: 27 [32/918 (3%)] Loss: 31441210.000000\n",
      "Train Epoch: 27 [48/918 (5%)] Loss: 43446984.000000\n",
      "Train Epoch: 27 [64/918 (7%)] Loss: 36482220.000000\n",
      "Train Epoch: 27 [80/918 (9%)] Loss: 38532616.000000\n",
      "Train Epoch: 27 [96/918 (10%)] Loss: 35663168.000000\n",
      "Train Epoch: 27 [112/918 (12%)] Loss: 36701748.000000\n",
      "Train Epoch: 27 [128/918 (14%)] Loss: 54065100.000000\n",
      "Train Epoch: 27 [144/918 (16%)] Loss: 39529360.000000\n",
      "Train Epoch: 27 [160/918 (17%)] Loss: 34052168.000000\n",
      "Train Epoch: 27 [176/918 (19%)] Loss: 39799688.000000\n",
      "Train Epoch: 27 [192/918 (21%)] Loss: 36997084.000000\n",
      "Train Epoch: 27 [208/918 (23%)] Loss: 26917728.000000\n",
      "Train Epoch: 27 [224/918 (24%)] Loss: 33995948.000000\n",
      "Train Epoch: 27 [240/918 (26%)] Loss: 35523656.000000\n",
      "Train Epoch: 27 [256/918 (28%)] Loss: 43447040.000000\n",
      "Train Epoch: 27 [272/918 (30%)] Loss: 40785460.000000\n",
      "Train Epoch: 27 [288/918 (31%)] Loss: 35388572.000000\n",
      "Train Epoch: 27 [304/918 (33%)] Loss: 32618810.000000\n",
      "Train Epoch: 27 [320/918 (35%)] Loss: 42391464.000000\n",
      "Train Epoch: 27 [336/918 (37%)] Loss: 38720000.000000\n",
      "Train Epoch: 27 [352/918 (38%)] Loss: 41554172.000000\n",
      "Train Epoch: 27 [368/918 (40%)] Loss: 44844228.000000\n",
      "Train Epoch: 27 [384/918 (42%)] Loss: 31655124.000000\n",
      "Train Epoch: 27 [400/918 (44%)] Loss: 40306048.000000\n",
      "Train Epoch: 27 [416/918 (45%)] Loss: 35255488.000000\n",
      "Train Epoch: 27 [432/918 (47%)] Loss: 33297110.000000\n",
      "Train Epoch: 27 [448/918 (49%)] Loss: 31482292.000000\n",
      "Train Epoch: 27 [464/918 (51%)] Loss: 42871132.000000\n",
      "Train Epoch: 27 [480/918 (52%)] Loss: 44420052.000000\n",
      "Train Epoch: 27 [496/918 (54%)] Loss: 34438140.000000\n",
      "Train Epoch: 27 [512/918 (56%)] Loss: 35295868.000000\n",
      "Train Epoch: 27 [528/918 (58%)] Loss: 29682468.000000\n",
      "Train Epoch: 27 [544/918 (59%)] Loss: 40983816.000000\n",
      "Train Epoch: 27 [560/918 (61%)] Loss: 32637978.000000\n",
      "Train Epoch: 27 [576/918 (63%)] Loss: 35947520.000000\n",
      "Train Epoch: 27 [592/918 (64%)] Loss: 35319888.000000\n",
      "Train Epoch: 27 [608/918 (66%)] Loss: 40165832.000000\n",
      "Train Epoch: 27 [624/918 (68%)] Loss: 29341454.000000\n",
      "Train Epoch: 27 [640/918 (70%)] Loss: 29437172.000000\n",
      "Train Epoch: 27 [656/918 (71%)] Loss: 36364544.000000\n",
      "Train Epoch: 27 [672/918 (73%)] Loss: 37818076.000000\n",
      "Train Epoch: 27 [688/918 (75%)] Loss: 28690942.000000\n",
      "Train Epoch: 27 [704/918 (77%)] Loss: 36519368.000000\n",
      "Train Epoch: 27 [720/918 (78%)] Loss: 29360902.000000\n",
      "Train Epoch: 27 [736/918 (80%)] Loss: 30269902.000000\n",
      "Train Epoch: 27 [752/918 (82%)] Loss: 30487386.000000\n",
      "Train Epoch: 27 [768/918 (84%)] Loss: 37579004.000000\n",
      "Train Epoch: 27 [784/918 (85%)] Loss: 36689308.000000\n",
      "Train Epoch: 27 [800/918 (87%)] Loss: 29844070.000000\n",
      "Train Epoch: 27 [816/918 (89%)] Loss: 33738348.000000\n",
      "Train Epoch: 27 [832/918 (91%)] Loss: 30802522.000000\n",
      "Train Epoch: 27 [848/918 (92%)] Loss: 40699368.000000\n",
      "Train Epoch: 27 [864/918 (94%)] Loss: 47178872.000000\n",
      "Train Epoch: 27 [880/918 (96%)] Loss: 36330184.000000\n",
      "Train Epoch: 27 [896/918 (98%)] Loss: 32241766.000000\n",
      "Train Epoch: 27 [912/918 (99%)] Loss: 37562080.000000\n",
      "    epoch          : 27\n",
      "    loss           : 35738262.069565214\n",
      "    ess            : 20.820613334489906\n",
      "    log_marginal   : -35738260.59130435\n",
      "    val_loss       : 39867968.76923077\n",
      "    val_ess        : 19.271060686845047\n",
      "    val_log_marginal: -39867965.84615385\n",
      "Train Epoch: 28 [0/918 (0%)] Loss: 31571252.000000\n",
      "Train Epoch: 28 [16/918 (2%)] Loss: 32618570.000000\n",
      "Train Epoch: 28 [32/918 (3%)] Loss: 46977196.000000\n",
      "Train Epoch: 28 [48/918 (5%)] Loss: 30992826.000000\n",
      "Train Epoch: 28 [64/918 (7%)] Loss: 38061440.000000\n",
      "Train Epoch: 28 [80/918 (9%)] Loss: 39419112.000000\n",
      "Train Epoch: 28 [96/918 (10%)] Loss: 33564808.000000\n",
      "Train Epoch: 28 [112/918 (12%)] Loss: 36070384.000000\n",
      "Train Epoch: 28 [128/918 (14%)] Loss: 36279464.000000\n",
      "Train Epoch: 28 [144/918 (16%)] Loss: 37561260.000000\n",
      "Train Epoch: 28 [160/918 (17%)] Loss: 41053736.000000\n",
      "Train Epoch: 28 [176/918 (19%)] Loss: 37026396.000000\n",
      "Train Epoch: 28 [192/918 (21%)] Loss: 35436508.000000\n",
      "Train Epoch: 28 [208/918 (23%)] Loss: 38795696.000000\n",
      "Train Epoch: 28 [224/918 (24%)] Loss: 33659664.000000\n",
      "Train Epoch: 28 [240/918 (26%)] Loss: 36322704.000000\n",
      "Train Epoch: 28 [256/918 (28%)] Loss: 39099388.000000\n",
      "Train Epoch: 28 [272/918 (30%)] Loss: 37677352.000000\n",
      "Train Epoch: 28 [288/918 (31%)] Loss: 39294332.000000\n",
      "Train Epoch: 28 [304/918 (33%)] Loss: 35136056.000000\n",
      "Train Epoch: 28 [320/918 (35%)] Loss: 33649884.000000\n",
      "Train Epoch: 28 [336/918 (37%)] Loss: 36438172.000000\n",
      "Train Epoch: 28 [352/918 (38%)] Loss: 28783798.000000\n",
      "Train Epoch: 28 [368/918 (40%)] Loss: 35507932.000000\n",
      "Train Epoch: 28 [384/918 (42%)] Loss: 36558280.000000\n",
      "Train Epoch: 28 [400/918 (44%)] Loss: 36314652.000000\n",
      "Train Epoch: 28 [416/918 (45%)] Loss: 29816314.000000\n",
      "Train Epoch: 28 [432/918 (47%)] Loss: 35892540.000000\n",
      "Train Epoch: 28 [448/918 (49%)] Loss: 37923120.000000\n",
      "Train Epoch: 28 [464/918 (51%)] Loss: 35951848.000000\n",
      "Train Epoch: 28 [480/918 (52%)] Loss: 27752864.000000\n",
      "Train Epoch: 28 [496/918 (54%)] Loss: 33654236.000000\n",
      "Train Epoch: 28 [512/918 (56%)] Loss: 33726844.000000\n",
      "Train Epoch: 28 [528/918 (58%)] Loss: 32706644.000000\n",
      "Train Epoch: 28 [544/918 (59%)] Loss: 32054288.000000\n",
      "Train Epoch: 28 [560/918 (61%)] Loss: 39310400.000000\n",
      "Train Epoch: 28 [576/918 (63%)] Loss: 41773164.000000\n",
      "Train Epoch: 28 [592/918 (64%)] Loss: 23277766.000000\n",
      "Train Epoch: 28 [608/918 (66%)] Loss: 33990100.000000\n",
      "Train Epoch: 28 [624/918 (68%)] Loss: 38132416.000000\n",
      "Train Epoch: 28 [640/918 (70%)] Loss: 27954958.000000\n",
      "Train Epoch: 28 [656/918 (71%)] Loss: 36600084.000000\n",
      "Train Epoch: 28 [672/918 (73%)] Loss: 35284876.000000\n",
      "Train Epoch: 28 [688/918 (75%)] Loss: 31497344.000000\n",
      "Train Epoch: 28 [704/918 (77%)] Loss: 28754766.000000\n",
      "Train Epoch: 28 [720/918 (78%)] Loss: 31610484.000000\n",
      "Train Epoch: 28 [736/918 (80%)] Loss: 33038836.000000\n",
      "Train Epoch: 28 [752/918 (82%)] Loss: 32498228.000000\n",
      "Train Epoch: 28 [768/918 (84%)] Loss: 37256784.000000\n",
      "Train Epoch: 28 [784/918 (85%)] Loss: 35252224.000000\n",
      "Train Epoch: 28 [800/918 (87%)] Loss: 37294224.000000\n",
      "Train Epoch: 28 [816/918 (89%)] Loss: 35679048.000000\n",
      "Train Epoch: 28 [832/918 (91%)] Loss: 33157582.000000\n",
      "Train Epoch: 28 [848/918 (92%)] Loss: 35512308.000000\n",
      "Train Epoch: 28 [864/918 (94%)] Loss: 38462280.000000\n",
      "Train Epoch: 28 [880/918 (96%)] Loss: 34087400.000000\n",
      "Train Epoch: 28 [896/918 (98%)] Loss: 27563264.000000\n",
      "Train Epoch: 28 [912/918 (99%)] Loss: 30268370.000000\n",
      "    epoch          : 28\n",
      "    loss           : 34570520.104347825\n",
      "    ess            : 22.356631042646324\n",
      "    log_marginal   : -34570518.556521736\n",
      "    val_loss       : 38836403.84615385\n",
      "    val_ess        : 18.755693949185886\n",
      "    val_log_marginal: -38836401.23076923\n",
      "Train Epoch: 29 [0/918 (0%)] Loss: 40304220.000000\n",
      "Train Epoch: 29 [16/918 (2%)] Loss: 34539400.000000\n",
      "Train Epoch: 29 [32/918 (3%)] Loss: 28325872.000000\n",
      "Train Epoch: 29 [48/918 (5%)] Loss: 32785878.000000\n",
      "Train Epoch: 29 [64/918 (7%)] Loss: 25532888.000000\n",
      "Train Epoch: 29 [80/918 (9%)] Loss: 40784352.000000\n",
      "Train Epoch: 29 [96/918 (10%)] Loss: 39426428.000000\n",
      "Train Epoch: 29 [112/918 (12%)] Loss: 28769492.000000\n",
      "Train Epoch: 29 [128/918 (14%)] Loss: 27002486.000000\n",
      "Train Epoch: 29 [144/918 (16%)] Loss: 34111316.000000\n",
      "Train Epoch: 29 [160/918 (17%)] Loss: 32075150.000000\n",
      "Train Epoch: 29 [176/918 (19%)] Loss: 41505756.000000\n",
      "Train Epoch: 29 [192/918 (21%)] Loss: 41343084.000000\n",
      "Train Epoch: 29 [208/918 (23%)] Loss: 37812284.000000\n",
      "Train Epoch: 29 [224/918 (24%)] Loss: 33999644.000000\n",
      "Train Epoch: 29 [240/918 (26%)] Loss: 28943674.000000\n",
      "Train Epoch: 29 [256/918 (28%)] Loss: 32376094.000000\n",
      "Train Epoch: 29 [272/918 (30%)] Loss: 29926734.000000\n",
      "Train Epoch: 29 [288/918 (31%)] Loss: 31769504.000000\n",
      "Train Epoch: 29 [304/918 (33%)] Loss: 32886510.000000\n",
      "Train Epoch: 29 [320/918 (35%)] Loss: 31889914.000000\n",
      "Train Epoch: 29 [336/918 (37%)] Loss: 31673286.000000\n",
      "Train Epoch: 29 [352/918 (38%)] Loss: 32381466.000000\n",
      "Train Epoch: 29 [368/918 (40%)] Loss: 33099814.000000\n",
      "Train Epoch: 29 [384/918 (42%)] Loss: 36493992.000000\n",
      "Train Epoch: 29 [400/918 (44%)] Loss: 27697118.000000\n",
      "Train Epoch: 29 [416/918 (45%)] Loss: 29825846.000000\n",
      "Train Epoch: 29 [432/918 (47%)] Loss: 38186984.000000\n",
      "Train Epoch: 29 [448/918 (49%)] Loss: 34187340.000000\n",
      "Train Epoch: 29 [464/918 (51%)] Loss: 28422638.000000\n",
      "Train Epoch: 29 [480/918 (52%)] Loss: 31813620.000000\n",
      "Train Epoch: 29 [496/918 (54%)] Loss: 33576284.000000\n",
      "Train Epoch: 29 [512/918 (56%)] Loss: 27999706.000000\n",
      "Train Epoch: 29 [528/918 (58%)] Loss: 33444768.000000\n",
      "Train Epoch: 29 [544/918 (59%)] Loss: 37201448.000000\n",
      "Train Epoch: 29 [560/918 (61%)] Loss: 33898432.000000\n",
      "Train Epoch: 29 [576/918 (63%)] Loss: 33620988.000000\n",
      "Train Epoch: 29 [592/918 (64%)] Loss: 34090100.000000\n",
      "Train Epoch: 29 [608/918 (66%)] Loss: 30259238.000000\n",
      "Train Epoch: 29 [624/918 (68%)] Loss: 34933224.000000\n",
      "Train Epoch: 29 [640/918 (70%)] Loss: 34264564.000000\n",
      "Train Epoch: 29 [656/918 (71%)] Loss: 28798318.000000\n",
      "Train Epoch: 29 [672/918 (73%)] Loss: 30905696.000000\n",
      "Train Epoch: 29 [688/918 (75%)] Loss: 28646346.000000\n",
      "Train Epoch: 29 [704/918 (77%)] Loss: 31685178.000000\n",
      "Train Epoch: 29 [720/918 (78%)] Loss: 36420928.000000\n",
      "Train Epoch: 29 [736/918 (80%)] Loss: 30800890.000000\n",
      "Train Epoch: 29 [752/918 (82%)] Loss: 30942022.000000\n",
      "Train Epoch: 29 [768/918 (84%)] Loss: 29926160.000000\n",
      "Train Epoch: 29 [784/918 (85%)] Loss: 36293164.000000\n",
      "Train Epoch: 29 [800/918 (87%)] Loss: 28209376.000000\n",
      "Train Epoch: 29 [816/918 (89%)] Loss: 29814118.000000\n",
      "Train Epoch: 29 [832/918 (91%)] Loss: 31799374.000000\n",
      "Train Epoch: 29 [848/918 (92%)] Loss: 30179610.000000\n",
      "Train Epoch: 29 [864/918 (94%)] Loss: 27326222.000000\n",
      "Train Epoch: 29 [880/918 (96%)] Loss: 33576148.000000\n",
      "Train Epoch: 29 [896/918 (98%)] Loss: 29361204.000000\n",
      "Train Epoch: 29 [912/918 (99%)] Loss: 32561402.000000\n",
      "    epoch          : 29\n",
      "    loss           : 33128943.304347824\n",
      "    ess            : 23.87090784570445\n",
      "    log_marginal   : -33128941.860869564\n",
      "    val_loss       : 36699151.538461536\n",
      "    val_ess        : 21.050383421090935\n",
      "    val_log_marginal: -36699149.692307696\n",
      "Train Epoch: 30 [0/918 (0%)] Loss: 34324712.000000\n",
      "Train Epoch: 30 [16/918 (2%)] Loss: 33183894.000000\n",
      "Train Epoch: 30 [32/918 (3%)] Loss: 34063368.000000\n",
      "Train Epoch: 30 [48/918 (5%)] Loss: 30008102.000000\n",
      "Train Epoch: 30 [64/918 (7%)] Loss: 36642796.000000\n",
      "Train Epoch: 30 [80/918 (9%)] Loss: 31072864.000000\n",
      "Train Epoch: 30 [96/918 (10%)] Loss: 29110740.000000\n",
      "Train Epoch: 30 [112/918 (12%)] Loss: 35185396.000000\n",
      "Train Epoch: 30 [128/918 (14%)] Loss: 31342086.000000\n",
      "Train Epoch: 30 [144/918 (16%)] Loss: 35533468.000000\n",
      "Train Epoch: 30 [160/918 (17%)] Loss: 29328288.000000\n",
      "Train Epoch: 30 [176/918 (19%)] Loss: 29890186.000000\n",
      "Train Epoch: 30 [192/918 (21%)] Loss: 31130682.000000\n",
      "Train Epoch: 30 [208/918 (23%)] Loss: 29643552.000000\n",
      "Train Epoch: 30 [224/918 (24%)] Loss: 19949386.000000\n",
      "Train Epoch: 30 [240/918 (26%)] Loss: 29011930.000000\n",
      "Train Epoch: 30 [256/918 (28%)] Loss: 38892444.000000\n",
      "Train Epoch: 30 [272/918 (30%)] Loss: 35432072.000000\n",
      "Train Epoch: 30 [288/918 (31%)] Loss: 38874204.000000\n",
      "Train Epoch: 30 [304/918 (33%)] Loss: 32454938.000000\n",
      "Train Epoch: 30 [320/918 (35%)] Loss: 37020904.000000\n",
      "Train Epoch: 30 [336/918 (37%)] Loss: 32966384.000000\n",
      "Train Epoch: 30 [352/918 (38%)] Loss: 24546240.000000\n",
      "Train Epoch: 30 [368/918 (40%)] Loss: 32304352.000000\n",
      "Train Epoch: 30 [384/918 (42%)] Loss: 31633510.000000\n",
      "Train Epoch: 30 [400/918 (44%)] Loss: 32670720.000000\n",
      "Train Epoch: 30 [416/918 (45%)] Loss: 32762554.000000\n",
      "Train Epoch: 30 [432/918 (47%)] Loss: 27900842.000000\n",
      "Train Epoch: 30 [448/918 (49%)] Loss: 29905178.000000\n",
      "Train Epoch: 30 [464/918 (51%)] Loss: 28641050.000000\n",
      "Train Epoch: 30 [480/918 (52%)] Loss: 30852538.000000\n",
      "Train Epoch: 30 [496/918 (54%)] Loss: 32479728.000000\n",
      "Train Epoch: 30 [512/918 (56%)] Loss: 30504090.000000\n",
      "Train Epoch: 30 [528/918 (58%)] Loss: 30755386.000000\n",
      "Train Epoch: 30 [544/918 (59%)] Loss: 27618848.000000\n",
      "Train Epoch: 30 [560/918 (61%)] Loss: 34938388.000000\n",
      "Train Epoch: 30 [576/918 (63%)] Loss: 27574416.000000\n",
      "Train Epoch: 30 [592/918 (64%)] Loss: 27173606.000000\n",
      "Train Epoch: 30 [608/918 (66%)] Loss: 33984808.000000\n",
      "Train Epoch: 30 [624/918 (68%)] Loss: 26633296.000000\n",
      "Train Epoch: 30 [640/918 (70%)] Loss: 29938752.000000\n",
      "Train Epoch: 30 [656/918 (71%)] Loss: 31961966.000000\n",
      "Train Epoch: 30 [672/918 (73%)] Loss: 26152032.000000\n",
      "Train Epoch: 30 [688/918 (75%)] Loss: 28245242.000000\n",
      "Train Epoch: 30 [704/918 (77%)] Loss: 29036506.000000\n",
      "Train Epoch: 30 [720/918 (78%)] Loss: 31518222.000000\n",
      "Train Epoch: 30 [736/918 (80%)] Loss: 27030618.000000\n",
      "Train Epoch: 30 [752/918 (82%)] Loss: 28097446.000000\n",
      "Train Epoch: 30 [768/918 (84%)] Loss: 28609934.000000\n",
      "Train Epoch: 30 [784/918 (85%)] Loss: 34732224.000000\n",
      "Train Epoch: 30 [800/918 (87%)] Loss: 31478102.000000\n",
      "Train Epoch: 30 [816/918 (89%)] Loss: 26165964.000000\n",
      "Train Epoch: 30 [832/918 (91%)] Loss: 26387800.000000\n",
      "Train Epoch: 30 [848/918 (92%)] Loss: 42802176.000000\n",
      "Train Epoch: 30 [864/918 (94%)] Loss: 31556656.000000\n",
      "Train Epoch: 30 [880/918 (96%)] Loss: 31733734.000000\n",
      "Train Epoch: 30 [896/918 (98%)] Loss: 29004244.000000\n",
      "Train Epoch: 30 [912/918 (99%)] Loss: 26136428.000000\n",
      "    epoch          : 30\n",
      "    loss           : 31483055.304347824\n",
      "    ess            : 25.778726809957753\n",
      "    log_marginal   : -31483054.139130436\n",
      "    val_loss       : 34981463.23076923\n",
      "    val_ess        : 21.98327220403231\n",
      "    val_log_marginal: -34981462.15384615\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [0/918 (0%)] Loss: 32658948.000000\n",
      "Train Epoch: 31 [16/918 (2%)] Loss: 27845674.000000\n",
      "Train Epoch: 31 [32/918 (3%)] Loss: 38141308.000000\n",
      "Train Epoch: 31 [48/918 (5%)] Loss: 35378648.000000\n",
      "Train Epoch: 31 [64/918 (7%)] Loss: 31673882.000000\n",
      "Train Epoch: 31 [80/918 (9%)] Loss: 29599668.000000\n",
      "Train Epoch: 31 [96/918 (10%)] Loss: 31835466.000000\n",
      "Train Epoch: 31 [112/918 (12%)] Loss: 38801756.000000\n",
      "Train Epoch: 31 [128/918 (14%)] Loss: 28183846.000000\n",
      "Train Epoch: 31 [144/918 (16%)] Loss: 25153446.000000\n",
      "Train Epoch: 31 [160/918 (17%)] Loss: 27437534.000000\n",
      "Train Epoch: 31 [176/918 (19%)] Loss: 24785934.000000\n",
      "Train Epoch: 31 [192/918 (21%)] Loss: 30609038.000000\n",
      "Train Epoch: 31 [208/918 (23%)] Loss: 24235280.000000\n",
      "Train Epoch: 31 [224/918 (24%)] Loss: 32494158.000000\n",
      "Train Epoch: 31 [240/918 (26%)] Loss: 28029268.000000\n",
      "Train Epoch: 31 [256/918 (28%)] Loss: 28504806.000000\n",
      "Train Epoch: 31 [272/918 (30%)] Loss: 33497380.000000\n",
      "Train Epoch: 31 [288/918 (31%)] Loss: 28163360.000000\n",
      "Train Epoch: 31 [304/918 (33%)] Loss: 24368502.000000\n",
      "Train Epoch: 31 [320/918 (35%)] Loss: 29218778.000000\n",
      "Train Epoch: 31 [336/918 (37%)] Loss: 31673044.000000\n",
      "Train Epoch: 31 [352/918 (38%)] Loss: 30419834.000000\n",
      "Train Epoch: 31 [368/918 (40%)] Loss: 29342970.000000\n",
      "Train Epoch: 31 [384/918 (42%)] Loss: 32754900.000000\n",
      "Train Epoch: 31 [400/918 (44%)] Loss: 31546106.000000\n",
      "Train Epoch: 31 [416/918 (45%)] Loss: 26030776.000000\n",
      "Train Epoch: 31 [432/918 (47%)] Loss: 31668490.000000\n",
      "Train Epoch: 31 [448/918 (49%)] Loss: 25113944.000000\n",
      "Train Epoch: 31 [464/918 (51%)] Loss: 28891028.000000\n",
      "Train Epoch: 31 [480/918 (52%)] Loss: 32364784.000000\n",
      "Train Epoch: 31 [496/918 (54%)] Loss: 27840558.000000\n",
      "Train Epoch: 31 [512/918 (56%)] Loss: 28944198.000000\n",
      "Train Epoch: 31 [528/918 (58%)] Loss: 24865712.000000\n",
      "Train Epoch: 31 [544/918 (59%)] Loss: 27160678.000000\n",
      "Train Epoch: 31 [560/918 (61%)] Loss: 30376646.000000\n",
      "Train Epoch: 31 [576/918 (63%)] Loss: 25378910.000000\n",
      "Train Epoch: 31 [592/918 (64%)] Loss: 25895606.000000\n",
      "Train Epoch: 31 [608/918 (66%)] Loss: 30999584.000000\n",
      "Train Epoch: 31 [624/918 (68%)] Loss: 35916528.000000\n",
      "Train Epoch: 31 [640/918 (70%)] Loss: 31120020.000000\n",
      "Train Epoch: 31 [656/918 (71%)] Loss: 27422158.000000\n",
      "Train Epoch: 31 [672/918 (73%)] Loss: 23560056.000000\n",
      "Train Epoch: 31 [688/918 (75%)] Loss: 33594568.000000\n",
      "Train Epoch: 31 [704/918 (77%)] Loss: 29079200.000000\n",
      "Train Epoch: 31 [720/918 (78%)] Loss: 23769478.000000\n",
      "Train Epoch: 31 [736/918 (80%)] Loss: 35829132.000000\n",
      "Train Epoch: 31 [752/918 (82%)] Loss: 32280474.000000\n",
      "Train Epoch: 31 [768/918 (84%)] Loss: 29118618.000000\n",
      "Train Epoch: 31 [784/918 (85%)] Loss: 35862292.000000\n",
      "Train Epoch: 31 [800/918 (87%)] Loss: 27785988.000000\n",
      "Train Epoch: 31 [816/918 (89%)] Loss: 27557318.000000\n",
      "Train Epoch: 31 [832/918 (91%)] Loss: 28297552.000000\n",
      "Train Epoch: 31 [848/918 (92%)] Loss: 29116720.000000\n",
      "Train Epoch: 31 [864/918 (94%)] Loss: 27031296.000000\n",
      "Train Epoch: 31 [880/918 (96%)] Loss: 29753722.000000\n",
      "Train Epoch: 31 [896/918 (98%)] Loss: 31196006.000000\n",
      "Train Epoch: 31 [912/918 (99%)] Loss: 25854602.000000\n",
      "    epoch          : 31\n",
      "    loss           : 29450180.713043477\n",
      "    ess            : 28.845351973823878\n",
      "    log_marginal   : -29450179.47826087\n",
      "    val_loss       : 32228417.846153848\n",
      "    val_ess        : 23.467939376831055\n",
      "    val_log_marginal: -32228416.153846152\n",
      "Train Epoch: 32 [0/918 (0%)] Loss: 26532358.000000\n",
      "Train Epoch: 32 [16/918 (2%)] Loss: 21944622.000000\n",
      "Train Epoch: 32 [32/918 (3%)] Loss: 26844630.000000\n",
      "Train Epoch: 32 [48/918 (5%)] Loss: 31526100.000000\n",
      "Train Epoch: 32 [64/918 (7%)] Loss: 29227424.000000\n",
      "Train Epoch: 32 [80/918 (9%)] Loss: 29957716.000000\n",
      "Train Epoch: 32 [96/918 (10%)] Loss: 35604232.000000\n",
      "Train Epoch: 32 [112/918 (12%)] Loss: 29577434.000000\n",
      "Train Epoch: 32 [128/918 (14%)] Loss: 24033284.000000\n",
      "Train Epoch: 32 [144/918 (16%)] Loss: 24909146.000000\n",
      "Train Epoch: 32 [160/918 (17%)] Loss: 24558944.000000\n",
      "Train Epoch: 32 [176/918 (19%)] Loss: 25758618.000000\n",
      "Train Epoch: 32 [192/918 (21%)] Loss: 30915466.000000\n",
      "Train Epoch: 32 [208/918 (23%)] Loss: 25558332.000000\n",
      "Train Epoch: 32 [224/918 (24%)] Loss: 28076602.000000\n",
      "Train Epoch: 32 [240/918 (26%)] Loss: 25864774.000000\n",
      "Train Epoch: 32 [256/918 (28%)] Loss: 29765402.000000\n",
      "Train Epoch: 32 [272/918 (30%)] Loss: 25165468.000000\n",
      "Train Epoch: 32 [288/918 (31%)] Loss: 26942804.000000\n",
      "Train Epoch: 32 [304/918 (33%)] Loss: 26821510.000000\n",
      "Train Epoch: 32 [320/918 (35%)] Loss: 23550996.000000\n",
      "Train Epoch: 32 [336/918 (37%)] Loss: 27605370.000000\n",
      "Train Epoch: 32 [352/918 (38%)] Loss: 34553384.000000\n",
      "Train Epoch: 32 [368/918 (40%)] Loss: 23563882.000000\n",
      "Train Epoch: 32 [384/918 (42%)] Loss: 25249204.000000\n",
      "Train Epoch: 32 [400/918 (44%)] Loss: 27177248.000000\n",
      "Train Epoch: 32 [416/918 (45%)] Loss: 26533446.000000\n",
      "Train Epoch: 32 [432/918 (47%)] Loss: 30032020.000000\n",
      "Train Epoch: 32 [448/918 (49%)] Loss: 24962144.000000\n",
      "Train Epoch: 32 [464/918 (51%)] Loss: 21877328.000000\n",
      "Train Epoch: 32 [480/918 (52%)] Loss: 24837286.000000\n",
      "Train Epoch: 32 [496/918 (54%)] Loss: 25076568.000000\n",
      "Train Epoch: 32 [512/918 (56%)] Loss: 23430128.000000\n",
      "Train Epoch: 32 [528/918 (58%)] Loss: 28434878.000000\n",
      "Train Epoch: 32 [544/918 (59%)] Loss: 31340592.000000\n",
      "Train Epoch: 32 [560/918 (61%)] Loss: 23124390.000000\n",
      "Train Epoch: 32 [576/918 (63%)] Loss: 25094718.000000\n",
      "Train Epoch: 32 [592/918 (64%)] Loss: 23830870.000000\n",
      "Train Epoch: 32 [608/918 (66%)] Loss: 27769190.000000\n",
      "Train Epoch: 32 [624/918 (68%)] Loss: 26471072.000000\n",
      "Train Epoch: 32 [640/918 (70%)] Loss: 30258314.000000\n",
      "Train Epoch: 32 [656/918 (71%)] Loss: 29185246.000000\n",
      "Train Epoch: 32 [672/918 (73%)] Loss: 25024064.000000\n",
      "Train Epoch: 32 [688/918 (75%)] Loss: 32937168.000000\n",
      "Train Epoch: 32 [704/918 (77%)] Loss: 21724608.000000\n",
      "Train Epoch: 32 [720/918 (78%)] Loss: 29356846.000000\n",
      "Train Epoch: 32 [736/918 (80%)] Loss: 29598938.000000\n",
      "Train Epoch: 32 [752/918 (82%)] Loss: 31533486.000000\n",
      "Train Epoch: 32 [768/918 (84%)] Loss: 26762326.000000\n",
      "Train Epoch: 32 [784/918 (85%)] Loss: 26794726.000000\n",
      "Train Epoch: 32 [800/918 (87%)] Loss: 30737844.000000\n",
      "Train Epoch: 32 [816/918 (89%)] Loss: 24662774.000000\n",
      "Train Epoch: 32 [832/918 (91%)] Loss: 27209546.000000\n",
      "Train Epoch: 32 [848/918 (92%)] Loss: 30566656.000000\n",
      "Train Epoch: 32 [864/918 (94%)] Loss: 20463300.000000\n",
      "Train Epoch: 32 [880/918 (96%)] Loss: 25232288.000000\n",
      "Train Epoch: 32 [896/918 (98%)] Loss: 27807300.000000\n",
      "Train Epoch: 32 [912/918 (99%)] Loss: 23435936.000000\n",
      "    epoch          : 32\n",
      "    loss           : 27213564.817391306\n",
      "    ess            : 30.387086947067925\n",
      "    log_marginal   : -27213563.426086955\n",
      "    val_loss       : 29186993.692307692\n",
      "    val_ess        : 24.76488384833703\n",
      "    val_log_marginal: -29186992.46153846\n",
      "Train Epoch: 33 [0/918 (0%)] Loss: 21832196.000000\n",
      "Train Epoch: 33 [16/918 (2%)] Loss: 23997546.000000\n",
      "Train Epoch: 33 [32/918 (3%)] Loss: 24175002.000000\n",
      "Train Epoch: 33 [48/918 (5%)] Loss: 30197280.000000\n",
      "Train Epoch: 33 [64/918 (7%)] Loss: 26705344.000000\n",
      "Train Epoch: 33 [80/918 (9%)] Loss: 24625664.000000\n",
      "Train Epoch: 33 [96/918 (10%)] Loss: 26424540.000000\n",
      "Train Epoch: 33 [112/918 (12%)] Loss: 22117672.000000\n",
      "Train Epoch: 33 [128/918 (14%)] Loss: 21695264.000000\n",
      "Train Epoch: 33 [144/918 (16%)] Loss: 23961552.000000\n",
      "Train Epoch: 33 [160/918 (17%)] Loss: 23395264.000000\n",
      "Train Epoch: 33 [176/918 (19%)] Loss: 23684028.000000\n",
      "Train Epoch: 33 [192/918 (21%)] Loss: 21385588.000000\n",
      "Train Epoch: 33 [208/918 (23%)] Loss: 26301734.000000\n",
      "Train Epoch: 33 [224/918 (24%)] Loss: 29875398.000000\n",
      "Train Epoch: 33 [240/918 (26%)] Loss: 28468288.000000\n",
      "Train Epoch: 33 [256/918 (28%)] Loss: 27141882.000000\n",
      "Train Epoch: 33 [272/918 (30%)] Loss: 25159360.000000\n",
      "Train Epoch: 33 [288/918 (31%)] Loss: 31116442.000000\n",
      "Train Epoch: 33 [304/918 (33%)] Loss: 23251446.000000\n",
      "Train Epoch: 33 [320/918 (35%)] Loss: 25322650.000000\n",
      "Train Epoch: 33 [336/918 (37%)] Loss: 23318774.000000\n",
      "Train Epoch: 33 [352/918 (38%)] Loss: 27338608.000000\n",
      "Train Epoch: 33 [368/918 (40%)] Loss: 27707098.000000\n",
      "Train Epoch: 33 [384/918 (42%)] Loss: 26009006.000000\n",
      "Train Epoch: 33 [400/918 (44%)] Loss: 22187310.000000\n",
      "Train Epoch: 33 [416/918 (45%)] Loss: 27974694.000000\n",
      "Train Epoch: 33 [432/918 (47%)] Loss: 21549328.000000\n",
      "Train Epoch: 33 [448/918 (49%)] Loss: 26447246.000000\n",
      "Train Epoch: 33 [464/918 (51%)] Loss: 24418944.000000\n",
      "Train Epoch: 33 [480/918 (52%)] Loss: 30607350.000000\n",
      "Train Epoch: 33 [496/918 (54%)] Loss: 25406668.000000\n",
      "Train Epoch: 33 [512/918 (56%)] Loss: 23760826.000000\n",
      "Train Epoch: 33 [528/918 (58%)] Loss: 26009564.000000\n",
      "Train Epoch: 33 [544/918 (59%)] Loss: 24103792.000000\n",
      "Train Epoch: 33 [560/918 (61%)] Loss: 34148764.000000\n",
      "Train Epoch: 33 [576/918 (63%)] Loss: 29283022.000000\n",
      "Train Epoch: 33 [592/918 (64%)] Loss: 18241822.000000\n",
      "Train Epoch: 33 [608/918 (66%)] Loss: 23100942.000000\n",
      "Train Epoch: 33 [624/918 (68%)] Loss: 24826902.000000\n",
      "Train Epoch: 33 [640/918 (70%)] Loss: 23489964.000000\n",
      "Train Epoch: 33 [656/918 (71%)] Loss: 22445462.000000\n",
      "Train Epoch: 33 [672/918 (73%)] Loss: 19631734.000000\n",
      "Train Epoch: 33 [688/918 (75%)] Loss: 28995694.000000\n",
      "Train Epoch: 33 [704/918 (77%)] Loss: 25775626.000000\n",
      "Train Epoch: 33 [720/918 (78%)] Loss: 24397836.000000\n",
      "Train Epoch: 33 [736/918 (80%)] Loss: 23898640.000000\n",
      "Train Epoch: 33 [752/918 (82%)] Loss: 26421104.000000\n",
      "Train Epoch: 33 [768/918 (84%)] Loss: 24424214.000000\n",
      "Train Epoch: 33 [784/918 (85%)] Loss: 19285620.000000\n",
      "Train Epoch: 33 [800/918 (87%)] Loss: 24451132.000000\n",
      "Train Epoch: 33 [816/918 (89%)] Loss: 28999974.000000\n",
      "Train Epoch: 33 [832/918 (91%)] Loss: 23321150.000000\n",
      "Train Epoch: 33 [848/918 (92%)] Loss: 20503722.000000\n",
      "Train Epoch: 33 [864/918 (94%)] Loss: 22838682.000000\n",
      "Train Epoch: 33 [880/918 (96%)] Loss: 24745580.000000\n",
      "Train Epoch: 33 [896/918 (98%)] Loss: 24827948.000000\n",
      "Train Epoch: 33 [912/918 (99%)] Loss: 25186454.000000\n",
      "    epoch          : 33\n",
      "    loss           : 24938071.00869565\n",
      "    ess            : 29.56772684429003\n",
      "    log_marginal   : -24938070.19130435\n",
      "    val_loss       : 26125545.230769232\n",
      "    val_ess        : 24.810382843017578\n",
      "    val_log_marginal: -26125544.307692308\n",
      "Train Epoch: 34 [0/918 (0%)] Loss: 26135062.000000\n",
      "Train Epoch: 34 [16/918 (2%)] Loss: 29732992.000000\n",
      "Train Epoch: 34 [32/918 (3%)] Loss: 28393302.000000\n",
      "Train Epoch: 34 [48/918 (5%)] Loss: 25171628.000000\n",
      "Train Epoch: 34 [64/918 (7%)] Loss: 27057600.000000\n",
      "Train Epoch: 34 [80/918 (9%)] Loss: 23355946.000000\n",
      "Train Epoch: 34 [96/918 (10%)] Loss: 22115140.000000\n",
      "Train Epoch: 34 [112/918 (12%)] Loss: 19671200.000000\n",
      "Train Epoch: 34 [128/918 (14%)] Loss: 29128464.000000\n",
      "Train Epoch: 34 [144/918 (16%)] Loss: 29889440.000000\n",
      "Train Epoch: 34 [160/918 (17%)] Loss: 21417128.000000\n",
      "Train Epoch: 34 [176/918 (19%)] Loss: 23333198.000000\n",
      "Train Epoch: 34 [192/918 (21%)] Loss: 23570710.000000\n",
      "Train Epoch: 34 [208/918 (23%)] Loss: 24162438.000000\n",
      "Train Epoch: 34 [224/918 (24%)] Loss: 20574784.000000\n",
      "Train Epoch: 34 [240/918 (26%)] Loss: 17398852.000000\n",
      "Train Epoch: 34 [256/918 (28%)] Loss: 18321872.000000\n",
      "Train Epoch: 34 [272/918 (30%)] Loss: 22180832.000000\n",
      "Train Epoch: 34 [288/918 (31%)] Loss: 24824584.000000\n",
      "Train Epoch: 34 [304/918 (33%)] Loss: 20948468.000000\n",
      "Train Epoch: 34 [320/918 (35%)] Loss: 23206928.000000\n",
      "Train Epoch: 34 [336/918 (37%)] Loss: 25285304.000000\n",
      "Train Epoch: 34 [352/918 (38%)] Loss: 18417294.000000\n",
      "Train Epoch: 34 [368/918 (40%)] Loss: 23666908.000000\n",
      "Train Epoch: 34 [384/918 (42%)] Loss: 22423466.000000\n",
      "Train Epoch: 34 [400/918 (44%)] Loss: 23487632.000000\n",
      "Train Epoch: 34 [416/918 (45%)] Loss: 23677226.000000\n",
      "Train Epoch: 34 [432/918 (47%)] Loss: 20173624.000000\n",
      "Train Epoch: 34 [448/918 (49%)] Loss: 18998836.000000\n",
      "Train Epoch: 34 [464/918 (51%)] Loss: 27291748.000000\n",
      "Train Epoch: 34 [480/918 (52%)] Loss: 18544148.000000\n",
      "Train Epoch: 34 [496/918 (54%)] Loss: 17862836.000000\n",
      "Train Epoch: 34 [512/918 (56%)] Loss: 24478790.000000\n",
      "Train Epoch: 34 [528/918 (58%)] Loss: 21897942.000000\n",
      "Train Epoch: 34 [544/918 (59%)] Loss: 20131200.000000\n",
      "Train Epoch: 34 [560/918 (61%)] Loss: 26431074.000000\n",
      "Train Epoch: 34 [576/918 (63%)] Loss: 29567920.000000\n",
      "Train Epoch: 34 [592/918 (64%)] Loss: 21782374.000000\n",
      "Train Epoch: 34 [608/918 (66%)] Loss: 23130476.000000\n",
      "Train Epoch: 34 [624/918 (68%)] Loss: 23119280.000000\n",
      "Train Epoch: 34 [640/918 (70%)] Loss: 20246302.000000\n",
      "Train Epoch: 34 [656/918 (71%)] Loss: 18874574.000000\n",
      "Train Epoch: 34 [672/918 (73%)] Loss: 20566428.000000\n",
      "Train Epoch: 34 [688/918 (75%)] Loss: 20172434.000000\n",
      "Train Epoch: 34 [704/918 (77%)] Loss: 21543760.000000\n",
      "Train Epoch: 34 [720/918 (78%)] Loss: 20928282.000000\n",
      "Train Epoch: 34 [736/918 (80%)] Loss: 19461430.000000\n",
      "Train Epoch: 34 [752/918 (82%)] Loss: 23087878.000000\n",
      "Train Epoch: 34 [768/918 (84%)] Loss: 20929684.000000\n",
      "Train Epoch: 34 [784/918 (85%)] Loss: 22139904.000000\n",
      "Train Epoch: 34 [800/918 (87%)] Loss: 23757366.000000\n",
      "Train Epoch: 34 [816/918 (89%)] Loss: 20944110.000000\n",
      "Train Epoch: 34 [832/918 (91%)] Loss: 21241126.000000\n",
      "Train Epoch: 34 [848/918 (92%)] Loss: 19385284.000000\n",
      "Train Epoch: 34 [864/918 (94%)] Loss: 16811136.000000\n",
      "Train Epoch: 34 [880/918 (96%)] Loss: 19058062.000000\n",
      "Train Epoch: 34 [896/918 (98%)] Loss: 20132036.000000\n",
      "Train Epoch: 34 [912/918 (99%)] Loss: 15942953.000000\n",
      "    epoch          : 34\n",
      "    loss           : 22695573.2\n",
      "    ess            : 29.409733739106553\n",
      "    log_marginal   : -22695571.834782608\n",
      "    val_loss       : 23528782.846153848\n",
      "    val_ess        : 26.06637169764592\n",
      "    val_log_marginal: -23528782.53846154\n",
      "Train Epoch: 35 [0/918 (0%)] Loss: 24367224.000000\n",
      "Train Epoch: 35 [16/918 (2%)] Loss: 18445902.000000\n",
      "Train Epoch: 35 [32/918 (3%)] Loss: 19309312.000000\n",
      "Train Epoch: 35 [48/918 (5%)] Loss: 25735760.000000\n",
      "Train Epoch: 35 [64/918 (7%)] Loss: 21291784.000000\n",
      "Train Epoch: 35 [80/918 (9%)] Loss: 22270176.000000\n",
      "Train Epoch: 35 [96/918 (10%)] Loss: 27371982.000000\n",
      "Train Epoch: 35 [112/918 (12%)] Loss: 28384976.000000\n",
      "Train Epoch: 35 [128/918 (14%)] Loss: 29562970.000000\n",
      "Train Epoch: 35 [144/918 (16%)] Loss: 20265468.000000\n",
      "Train Epoch: 35 [160/918 (17%)] Loss: 21620044.000000\n",
      "Train Epoch: 35 [176/918 (19%)] Loss: 22782208.000000\n",
      "Train Epoch: 35 [192/918 (21%)] Loss: 18579636.000000\n",
      "Train Epoch: 35 [208/918 (23%)] Loss: 24316812.000000\n",
      "Train Epoch: 35 [224/918 (24%)] Loss: 20032296.000000\n",
      "Train Epoch: 35 [240/918 (26%)] Loss: 20439120.000000\n",
      "Train Epoch: 35 [256/918 (28%)] Loss: 17824576.000000\n",
      "Train Epoch: 35 [272/918 (30%)] Loss: 19927304.000000\n",
      "Train Epoch: 35 [288/918 (31%)] Loss: 24801936.000000\n",
      "Train Epoch: 35 [304/918 (33%)] Loss: 19567140.000000\n",
      "Train Epoch: 35 [320/918 (35%)] Loss: 21218406.000000\n",
      "Train Epoch: 35 [336/918 (37%)] Loss: 19685550.000000\n",
      "Train Epoch: 35 [352/918 (38%)] Loss: 15469208.000000\n",
      "Train Epoch: 35 [368/918 (40%)] Loss: 23611644.000000\n",
      "Train Epoch: 35 [384/918 (42%)] Loss: 18955238.000000\n",
      "Train Epoch: 35 [400/918 (44%)] Loss: 19342860.000000\n",
      "Train Epoch: 35 [416/918 (45%)] Loss: 17653038.000000\n",
      "Train Epoch: 35 [432/918 (47%)] Loss: 17313492.000000\n",
      "Train Epoch: 35 [448/918 (49%)] Loss: 19009160.000000\n",
      "Train Epoch: 35 [464/918 (51%)] Loss: 20153616.000000\n",
      "Train Epoch: 35 [480/918 (52%)] Loss: 19192682.000000\n",
      "Train Epoch: 35 [496/918 (54%)] Loss: 17426176.000000\n",
      "Train Epoch: 35 [512/918 (56%)] Loss: 26797174.000000\n",
      "Train Epoch: 35 [528/918 (58%)] Loss: 22416056.000000\n",
      "Train Epoch: 35 [544/918 (59%)] Loss: 17385784.000000\n",
      "Train Epoch: 35 [560/918 (61%)] Loss: 18818070.000000\n",
      "Train Epoch: 35 [576/918 (63%)] Loss: 20606974.000000\n",
      "Train Epoch: 35 [592/918 (64%)] Loss: 17756216.000000\n",
      "Train Epoch: 35 [608/918 (66%)] Loss: 24410358.000000\n",
      "Train Epoch: 35 [624/918 (68%)] Loss: 19222342.000000\n",
      "Train Epoch: 35 [640/918 (70%)] Loss: 21006222.000000\n",
      "Train Epoch: 35 [656/918 (71%)] Loss: 18577452.000000\n",
      "Train Epoch: 35 [672/918 (73%)] Loss: 18489166.000000\n",
      "Train Epoch: 35 [688/918 (75%)] Loss: 21528794.000000\n",
      "Train Epoch: 35 [704/918 (77%)] Loss: 24937998.000000\n",
      "Train Epoch: 35 [720/918 (78%)] Loss: 21603336.000000\n",
      "Train Epoch: 35 [736/918 (80%)] Loss: 25595628.000000\n",
      "Train Epoch: 35 [752/918 (82%)] Loss: 16359218.000000\n",
      "Train Epoch: 35 [768/918 (84%)] Loss: 20822774.000000\n",
      "Train Epoch: 35 [784/918 (85%)] Loss: 18651222.000000\n",
      "Train Epoch: 35 [800/918 (87%)] Loss: 14161357.000000\n",
      "Train Epoch: 35 [816/918 (89%)] Loss: 20831300.000000\n",
      "Train Epoch: 35 [832/918 (91%)] Loss: 19498496.000000\n",
      "Train Epoch: 35 [848/918 (92%)] Loss: 18712128.000000\n",
      "Train Epoch: 35 [864/918 (94%)] Loss: 18210368.000000\n",
      "Train Epoch: 35 [880/918 (96%)] Loss: 16689608.000000\n",
      "Train Epoch: 35 [896/918 (98%)] Loss: 17695684.000000\n",
      "Train Epoch: 35 [912/918 (99%)] Loss: 18355438.000000\n",
      "    epoch          : 35\n",
      "    loss           : 20696279.773913044\n",
      "    ess            : 26.500059567327085\n",
      "    log_marginal   : -20696278.25217391\n",
      "    val_loss       : 21242347.846153848\n",
      "    val_ess        : 27.011771202087402\n",
      "    val_log_marginal: -21242346.46153846\n",
      "Train Epoch: 36 [0/918 (0%)] Loss: 19043216.000000\n",
      "Train Epoch: 36 [16/918 (2%)] Loss: 17843034.000000\n",
      "Train Epoch: 36 [32/918 (3%)] Loss: 20334800.000000\n",
      "Train Epoch: 36 [48/918 (5%)] Loss: 15569264.000000\n",
      "Train Epoch: 36 [64/918 (7%)] Loss: 20451482.000000\n",
      "Train Epoch: 36 [80/918 (9%)] Loss: 19150852.000000\n",
      "Train Epoch: 36 [96/918 (10%)] Loss: 20208292.000000\n",
      "Train Epoch: 36 [112/918 (12%)] Loss: 20290006.000000\n",
      "Train Epoch: 36 [128/918 (14%)] Loss: 23614694.000000\n",
      "Train Epoch: 36 [144/918 (16%)] Loss: 19008350.000000\n",
      "Train Epoch: 36 [160/918 (17%)] Loss: 20993600.000000\n",
      "Train Epoch: 36 [176/918 (19%)] Loss: 20110512.000000\n",
      "Train Epoch: 36 [192/918 (21%)] Loss: 16427528.000000\n",
      "Train Epoch: 36 [208/918 (23%)] Loss: 18437454.000000\n",
      "Train Epoch: 36 [224/918 (24%)] Loss: 17819998.000000\n",
      "Train Epoch: 36 [240/918 (26%)] Loss: 19582660.000000\n",
      "Train Epoch: 36 [256/918 (28%)] Loss: 20790814.000000\n",
      "Train Epoch: 36 [272/918 (30%)] Loss: 20618774.000000\n",
      "Train Epoch: 36 [288/918 (31%)] Loss: 19792554.000000\n",
      "Train Epoch: 36 [304/918 (33%)] Loss: 20548136.000000\n",
      "Train Epoch: 36 [320/918 (35%)] Loss: 14772595.000000\n",
      "Train Epoch: 36 [336/918 (37%)] Loss: 16792848.000000\n",
      "Train Epoch: 36 [352/918 (38%)] Loss: 20852980.000000\n",
      "Train Epoch: 36 [368/918 (40%)] Loss: 20332260.000000\n",
      "Train Epoch: 36 [384/918 (42%)] Loss: 16733290.000000\n",
      "Train Epoch: 36 [400/918 (44%)] Loss: 16923072.000000\n",
      "Train Epoch: 36 [416/918 (45%)] Loss: 16383461.000000\n",
      "Train Epoch: 36 [432/918 (47%)] Loss: 22112862.000000\n",
      "Train Epoch: 36 [448/918 (49%)] Loss: 20588368.000000\n",
      "Train Epoch: 36 [464/918 (51%)] Loss: 20568180.000000\n",
      "Train Epoch: 36 [480/918 (52%)] Loss: 16004575.000000\n",
      "Train Epoch: 36 [496/918 (54%)] Loss: 20436928.000000\n",
      "Train Epoch: 36 [512/918 (56%)] Loss: 17783920.000000\n",
      "Train Epoch: 36 [528/918 (58%)] Loss: 18743456.000000\n",
      "Train Epoch: 36 [544/918 (59%)] Loss: 22217350.000000\n",
      "Train Epoch: 36 [560/918 (61%)] Loss: 17602342.000000\n",
      "Train Epoch: 36 [576/918 (63%)] Loss: 17715920.000000\n",
      "Train Epoch: 36 [592/918 (64%)] Loss: 16664659.000000\n",
      "Train Epoch: 36 [608/918 (66%)] Loss: 17903414.000000\n",
      "Train Epoch: 36 [624/918 (68%)] Loss: 16619845.000000\n",
      "Train Epoch: 36 [640/918 (70%)] Loss: 18191710.000000\n",
      "Train Epoch: 36 [656/918 (71%)] Loss: 20213886.000000\n",
      "Train Epoch: 36 [672/918 (73%)] Loss: 20991982.000000\n",
      "Train Epoch: 36 [688/918 (75%)] Loss: 19082626.000000\n",
      "Train Epoch: 36 [704/918 (77%)] Loss: 20105728.000000\n",
      "Train Epoch: 36 [720/918 (78%)] Loss: 21534212.000000\n",
      "Train Epoch: 36 [736/918 (80%)] Loss: 23493388.000000\n",
      "Train Epoch: 36 [752/918 (82%)] Loss: 19424924.000000\n",
      "Train Epoch: 36 [768/918 (84%)] Loss: 23910700.000000\n",
      "Train Epoch: 36 [784/918 (85%)] Loss: 17822152.000000\n",
      "Train Epoch: 36 [800/918 (87%)] Loss: 20973080.000000\n",
      "Train Epoch: 36 [816/918 (89%)] Loss: 19710868.000000\n",
      "Train Epoch: 36 [832/918 (91%)] Loss: 20248182.000000\n",
      "Train Epoch: 36 [848/918 (92%)] Loss: 21143384.000000\n",
      "Train Epoch: 36 [864/918 (94%)] Loss: 17075170.000000\n",
      "Train Epoch: 36 [880/918 (96%)] Loss: 16053440.000000\n",
      "Train Epoch: 36 [896/918 (98%)] Loss: 16848528.000000\n",
      "Train Epoch: 36 [912/918 (99%)] Loss: 18601876.000000\n",
      "    epoch          : 36\n",
      "    loss           : 18915818.11304348\n",
      "    ess            : 23.618435936388764\n",
      "    log_marginal   : -18915815.947826087\n",
      "    val_loss       : 19127908.615384616\n",
      "    val_ess        : 21.993480370594906\n",
      "    val_log_marginal: -19127908.076923076\n",
      "Train Epoch: 37 [0/918 (0%)] Loss: 13425061.000000\n",
      "Train Epoch: 37 [16/918 (2%)] Loss: 17731648.000000\n",
      "Train Epoch: 37 [32/918 (3%)] Loss: 15696976.000000\n",
      "Train Epoch: 37 [48/918 (5%)] Loss: 19123246.000000\n",
      "Train Epoch: 37 [64/918 (7%)] Loss: 16379792.000000\n",
      "Train Epoch: 37 [80/918 (9%)] Loss: 19836312.000000\n",
      "Train Epoch: 37 [96/918 (10%)] Loss: 20609798.000000\n",
      "Train Epoch: 37 [112/918 (12%)] Loss: 13595675.000000\n",
      "Train Epoch: 37 [128/918 (14%)] Loss: 15731559.000000\n",
      "Train Epoch: 37 [144/918 (16%)] Loss: 18095256.000000\n",
      "Train Epoch: 37 [160/918 (17%)] Loss: 16131194.000000\n",
      "Train Epoch: 37 [176/918 (19%)] Loss: 21364240.000000\n",
      "Train Epoch: 37 [192/918 (21%)] Loss: 20179380.000000\n",
      "Train Epoch: 37 [208/918 (23%)] Loss: 18826718.000000\n",
      "Train Epoch: 37 [224/918 (24%)] Loss: 22087220.000000\n",
      "Train Epoch: 37 [240/918 (26%)] Loss: 17525912.000000\n",
      "Train Epoch: 37 [256/918 (28%)] Loss: 17411604.000000\n",
      "Train Epoch: 37 [272/918 (30%)] Loss: 18369780.000000\n",
      "Train Epoch: 37 [288/918 (31%)] Loss: 18637508.000000\n",
      "Train Epoch: 37 [304/918 (33%)] Loss: 20942584.000000\n",
      "Train Epoch: 37 [320/918 (35%)] Loss: 16219626.000000\n",
      "Train Epoch: 37 [336/918 (37%)] Loss: 15155899.000000\n",
      "Train Epoch: 37 [352/918 (38%)] Loss: 13614362.000000\n",
      "Train Epoch: 37 [368/918 (40%)] Loss: 18196100.000000\n",
      "Train Epoch: 37 [384/918 (42%)] Loss: 16696784.000000\n",
      "Train Epoch: 37 [400/918 (44%)] Loss: 18133224.000000\n",
      "Train Epoch: 37 [416/918 (45%)] Loss: 16451472.000000\n",
      "Train Epoch: 37 [432/918 (47%)] Loss: 20697086.000000\n",
      "Train Epoch: 37 [448/918 (49%)] Loss: 17978276.000000\n",
      "Train Epoch: 37 [464/918 (51%)] Loss: 19072360.000000\n",
      "Train Epoch: 37 [480/918 (52%)] Loss: 18689006.000000\n",
      "Train Epoch: 37 [496/918 (54%)] Loss: 16667571.000000\n",
      "Train Epoch: 37 [512/918 (56%)] Loss: 16499594.000000\n",
      "Train Epoch: 37 [528/918 (58%)] Loss: 16166715.000000\n",
      "Train Epoch: 37 [544/918 (59%)] Loss: 17000974.000000\n",
      "Train Epoch: 37 [560/918 (61%)] Loss: 20060712.000000\n",
      "Train Epoch: 37 [576/918 (63%)] Loss: 18598694.000000\n",
      "Train Epoch: 37 [592/918 (64%)] Loss: 22441012.000000\n",
      "Train Epoch: 37 [608/918 (66%)] Loss: 19560104.000000\n",
      "Train Epoch: 37 [624/918 (68%)] Loss: 13211508.000000\n",
      "Train Epoch: 37 [640/918 (70%)] Loss: 13642360.000000\n",
      "Train Epoch: 37 [656/918 (71%)] Loss: 18658532.000000\n",
      "Train Epoch: 37 [672/918 (73%)] Loss: 16548024.000000\n",
      "Train Epoch: 37 [688/918 (75%)] Loss: 16869968.000000\n",
      "Train Epoch: 37 [704/918 (77%)] Loss: 15412701.000000\n",
      "Train Epoch: 37 [720/918 (78%)] Loss: 15906971.000000\n",
      "Train Epoch: 37 [736/918 (80%)] Loss: 18569744.000000\n",
      "Train Epoch: 37 [752/918 (82%)] Loss: 12765184.000000\n",
      "Train Epoch: 37 [768/918 (84%)] Loss: 17810384.000000\n",
      "Train Epoch: 37 [784/918 (85%)] Loss: 16322615.000000\n",
      "Train Epoch: 37 [800/918 (87%)] Loss: 14009415.000000\n",
      "Train Epoch: 37 [816/918 (89%)] Loss: 21316894.000000\n",
      "Train Epoch: 37 [832/918 (91%)] Loss: 20063578.000000\n",
      "Train Epoch: 37 [848/918 (92%)] Loss: 20471302.000000\n",
      "Train Epoch: 37 [864/918 (94%)] Loss: 16013648.000000\n",
      "Train Epoch: 37 [880/918 (96%)] Loss: 14252391.000000\n",
      "Train Epoch: 37 [896/918 (98%)] Loss: 18671112.000000\n",
      "Train Epoch: 37 [912/918 (99%)] Loss: 16967890.000000\n",
      "    epoch          : 37\n",
      "    loss           : 17565446.052173913\n",
      "    ess            : 20.829813841114873\n",
      "    log_marginal   : -17565444.95652174\n",
      "    val_loss       : 17730188.230769232\n",
      "    val_ess        : 19.151611236425545\n",
      "    val_log_marginal: -17730184.846153848\n",
      "Train Epoch: 38 [0/918 (0%)] Loss: 18682686.000000\n",
      "Train Epoch: 38 [16/918 (2%)] Loss: 15682096.000000\n",
      "Train Epoch: 38 [32/918 (3%)] Loss: 15027351.000000\n",
      "Train Epoch: 38 [48/918 (5%)] Loss: 17252244.000000\n",
      "Train Epoch: 38 [64/918 (7%)] Loss: 16847700.000000\n",
      "Train Epoch: 38 [80/918 (9%)] Loss: 17540804.000000\n",
      "Train Epoch: 38 [96/918 (10%)] Loss: 16859134.000000\n",
      "Train Epoch: 38 [112/918 (12%)] Loss: 17734564.000000\n",
      "Train Epoch: 38 [128/918 (14%)] Loss: 16793760.000000\n",
      "Train Epoch: 38 [144/918 (16%)] Loss: 17343734.000000\n",
      "Train Epoch: 38 [160/918 (17%)] Loss: 18028326.000000\n",
      "Train Epoch: 38 [176/918 (19%)] Loss: 14008344.000000\n",
      "Train Epoch: 38 [192/918 (21%)] Loss: 19290336.000000\n",
      "Train Epoch: 38 [208/918 (23%)] Loss: 19681768.000000\n",
      "Train Epoch: 38 [224/918 (24%)] Loss: 15712923.000000\n",
      "Train Epoch: 38 [240/918 (26%)] Loss: 17893584.000000\n",
      "Train Epoch: 38 [256/918 (28%)] Loss: 14827677.000000\n",
      "Train Epoch: 38 [272/918 (30%)] Loss: 17924416.000000\n",
      "Train Epoch: 38 [288/918 (31%)] Loss: 15533170.000000\n",
      "Train Epoch: 38 [304/918 (33%)] Loss: 14313085.000000\n",
      "Train Epoch: 38 [320/918 (35%)] Loss: 14163410.000000\n",
      "Train Epoch: 38 [336/918 (37%)] Loss: 14729319.000000\n",
      "Train Epoch: 38 [352/918 (38%)] Loss: 13461984.000000\n",
      "Train Epoch: 38 [368/918 (40%)] Loss: 15278781.000000\n",
      "Train Epoch: 38 [384/918 (42%)] Loss: 15467763.000000\n",
      "Train Epoch: 38 [400/918 (44%)] Loss: 17902734.000000\n",
      "Train Epoch: 38 [416/918 (45%)] Loss: 15281011.000000\n",
      "Train Epoch: 38 [432/918 (47%)] Loss: 14409739.000000\n",
      "Train Epoch: 38 [448/918 (49%)] Loss: 16270752.000000\n",
      "Train Epoch: 38 [464/918 (51%)] Loss: 24403582.000000\n",
      "Train Epoch: 38 [480/918 (52%)] Loss: 15878314.000000\n",
      "Train Epoch: 38 [496/918 (54%)] Loss: 18116622.000000\n",
      "Train Epoch: 38 [512/918 (56%)] Loss: 17367684.000000\n",
      "Train Epoch: 38 [528/918 (58%)] Loss: 17028462.000000\n",
      "Train Epoch: 38 [544/918 (59%)] Loss: 14561803.000000\n",
      "Train Epoch: 38 [560/918 (61%)] Loss: 13673480.000000\n",
      "Train Epoch: 38 [576/918 (63%)] Loss: 15388704.000000\n",
      "Train Epoch: 38 [592/918 (64%)] Loss: 19266950.000000\n",
      "Train Epoch: 38 [608/918 (66%)] Loss: 17280216.000000\n",
      "Train Epoch: 38 [624/918 (68%)] Loss: 15598341.000000\n",
      "Train Epoch: 38 [640/918 (70%)] Loss: 12635014.000000\n",
      "Train Epoch: 38 [656/918 (71%)] Loss: 18707278.000000\n",
      "Train Epoch: 38 [672/918 (73%)] Loss: 17595542.000000\n",
      "Train Epoch: 38 [688/918 (75%)] Loss: 17708486.000000\n",
      "Train Epoch: 38 [704/918 (77%)] Loss: 18331782.000000\n",
      "Train Epoch: 38 [720/918 (78%)] Loss: 18504516.000000\n",
      "Train Epoch: 38 [736/918 (80%)] Loss: 17555802.000000\n",
      "Train Epoch: 38 [752/918 (82%)] Loss: 13382867.000000\n",
      "Train Epoch: 38 [768/918 (84%)] Loss: 14706711.000000\n",
      "Train Epoch: 38 [784/918 (85%)] Loss: 17469466.000000\n",
      "Train Epoch: 38 [800/918 (87%)] Loss: 22250806.000000\n",
      "Train Epoch: 38 [816/918 (89%)] Loss: 16615773.000000\n",
      "Train Epoch: 38 [832/918 (91%)] Loss: 19793040.000000\n",
      "Train Epoch: 38 [848/918 (92%)] Loss: 14932691.000000\n",
      "Train Epoch: 38 [864/918 (94%)] Loss: 14927331.000000\n",
      "Train Epoch: 38 [880/918 (96%)] Loss: 15807613.000000\n",
      "Train Epoch: 38 [896/918 (98%)] Loss: 19817384.000000\n",
      "Train Epoch: 38 [912/918 (99%)] Loss: 13791451.000000\n",
      "    epoch          : 38\n",
      "    loss           : 16502507.113043478\n",
      "    ess            : 19.008021545410156\n",
      "    log_marginal   : -16502505.747826086\n",
      "    val_loss       : 17013050.153846152\n",
      "    val_ess        : 18.894488114577072\n",
      "    val_log_marginal: -17013048.923076924\n",
      "Train Epoch: 39 [0/918 (0%)] Loss: 20911570.000000\n",
      "Train Epoch: 39 [16/918 (2%)] Loss: 14732378.000000\n",
      "Train Epoch: 39 [32/918 (3%)] Loss: 12635267.000000\n",
      "Train Epoch: 39 [48/918 (5%)] Loss: 14703613.000000\n",
      "Train Epoch: 39 [64/918 (7%)] Loss: 16396682.000000\n",
      "Train Epoch: 39 [80/918 (9%)] Loss: 15003733.000000\n",
      "Train Epoch: 39 [96/918 (10%)] Loss: 20598294.000000\n",
      "Train Epoch: 39 [112/918 (12%)] Loss: 17280842.000000\n",
      "Train Epoch: 39 [128/918 (14%)] Loss: 17738448.000000\n",
      "Train Epoch: 39 [144/918 (16%)] Loss: 15684515.000000\n",
      "Train Epoch: 39 [160/918 (17%)] Loss: 16119466.000000\n",
      "Train Epoch: 39 [176/918 (19%)] Loss: 15766250.000000\n",
      "Train Epoch: 39 [192/918 (21%)] Loss: 21218478.000000\n",
      "Train Epoch: 39 [208/918 (23%)] Loss: 15126170.000000\n",
      "Train Epoch: 39 [224/918 (24%)] Loss: 16795342.000000\n",
      "Train Epoch: 39 [240/918 (26%)] Loss: 14346787.000000\n",
      "Train Epoch: 39 [256/918 (28%)] Loss: 14468877.000000\n",
      "Train Epoch: 39 [272/918 (30%)] Loss: 19784478.000000\n",
      "Train Epoch: 39 [288/918 (31%)] Loss: 15826506.000000\n",
      "Train Epoch: 39 [304/918 (33%)] Loss: 15533975.000000\n",
      "Train Epoch: 39 [320/918 (35%)] Loss: 16977462.000000\n",
      "Train Epoch: 39 [336/918 (37%)] Loss: 16429720.000000\n",
      "Train Epoch: 39 [352/918 (38%)] Loss: 19171952.000000\n",
      "Train Epoch: 39 [368/918 (40%)] Loss: 15032608.000000\n",
      "Train Epoch: 39 [384/918 (42%)] Loss: 12420526.000000\n",
      "Train Epoch: 39 [400/918 (44%)] Loss: 16880416.000000\n",
      "Train Epoch: 39 [416/918 (45%)] Loss: 18844830.000000\n",
      "Train Epoch: 39 [432/918 (47%)] Loss: 14876138.000000\n",
      "Train Epoch: 39 [448/918 (49%)] Loss: 17346596.000000\n",
      "Train Epoch: 39 [464/918 (51%)] Loss: 15098984.000000\n",
      "Train Epoch: 39 [480/918 (52%)] Loss: 14835264.000000\n",
      "Train Epoch: 39 [496/918 (54%)] Loss: 18721428.000000\n",
      "Train Epoch: 39 [512/918 (56%)] Loss: 20468148.000000\n",
      "Train Epoch: 39 [528/918 (58%)] Loss: 19510408.000000\n",
      "Train Epoch: 39 [544/918 (59%)] Loss: 15342613.000000\n",
      "Train Epoch: 39 [560/918 (61%)] Loss: 12851656.000000\n",
      "Train Epoch: 39 [576/918 (63%)] Loss: 16793974.000000\n",
      "Train Epoch: 39 [592/918 (64%)] Loss: 13842395.000000\n",
      "Train Epoch: 39 [608/918 (66%)] Loss: 17388360.000000\n",
      "Train Epoch: 39 [624/918 (68%)] Loss: 12862424.000000\n",
      "Train Epoch: 39 [640/918 (70%)] Loss: 17142238.000000\n",
      "Train Epoch: 39 [656/918 (71%)] Loss: 15611719.000000\n",
      "Train Epoch: 39 [672/918 (73%)] Loss: 10775981.000000\n",
      "Train Epoch: 39 [688/918 (75%)] Loss: 11055088.000000\n",
      "Train Epoch: 39 [704/918 (77%)] Loss: 15952989.000000\n",
      "Train Epoch: 39 [720/918 (78%)] Loss: 13411437.000000\n",
      "Train Epoch: 39 [736/918 (80%)] Loss: 16530349.000000\n",
      "Train Epoch: 39 [752/918 (82%)] Loss: 11967533.000000\n",
      "Train Epoch: 39 [768/918 (84%)] Loss: 14010687.000000\n",
      "Train Epoch: 39 [784/918 (85%)] Loss: 13712375.000000\n",
      "Train Epoch: 39 [800/918 (87%)] Loss: 12396416.000000\n",
      "Train Epoch: 39 [816/918 (89%)] Loss: 17973360.000000\n",
      "Train Epoch: 39 [832/918 (91%)] Loss: 18292160.000000\n",
      "Train Epoch: 39 [848/918 (92%)] Loss: 16041315.000000\n",
      "Train Epoch: 39 [864/918 (94%)] Loss: 16800572.000000\n",
      "Train Epoch: 39 [880/918 (96%)] Loss: 16597589.000000\n",
      "Train Epoch: 39 [896/918 (98%)] Loss: 12121387.000000\n",
      "Train Epoch: 39 [912/918 (99%)] Loss: 13939222.000000\n",
      "    epoch          : 39\n",
      "    loss           : 16021776.47826087\n",
      "    ess            : 16.552259210918262\n",
      "    log_marginal   : -16021775.043478262\n",
      "    val_loss       : 15945686.846153846\n",
      "    val_ess        : 16.293220666738655\n",
      "    val_log_marginal: -15945685.384615384\n",
      "Train Epoch: 40 [0/918 (0%)] Loss: 14222477.000000\n",
      "Train Epoch: 40 [16/918 (2%)] Loss: 13505178.000000\n",
      "Train Epoch: 40 [32/918 (3%)] Loss: 14466071.000000\n",
      "Train Epoch: 40 [48/918 (5%)] Loss: 16120640.000000\n",
      "Train Epoch: 40 [64/918 (7%)] Loss: 11151997.000000\n",
      "Train Epoch: 40 [80/918 (9%)] Loss: 13804362.000000\n",
      "Train Epoch: 40 [96/918 (10%)] Loss: 13461911.000000\n",
      "Train Epoch: 40 [112/918 (12%)] Loss: 10392239.000000\n",
      "Train Epoch: 40 [128/918 (14%)] Loss: 19301118.000000\n",
      "Train Epoch: 40 [144/918 (16%)] Loss: 12706333.000000\n",
      "Train Epoch: 40 [160/918 (17%)] Loss: 12734293.000000\n",
      "Train Epoch: 40 [176/918 (19%)] Loss: 14439533.000000\n",
      "Train Epoch: 40 [192/918 (21%)] Loss: 11589240.000000\n",
      "Train Epoch: 40 [208/918 (23%)] Loss: 15164522.000000\n",
      "Train Epoch: 40 [224/918 (24%)] Loss: 14887280.000000\n",
      "Train Epoch: 40 [240/918 (26%)] Loss: 14798621.000000\n",
      "Train Epoch: 40 [256/918 (28%)] Loss: 15581218.000000\n",
      "Train Epoch: 40 [272/918 (30%)] Loss: 17033408.000000\n",
      "Train Epoch: 40 [288/918 (31%)] Loss: 20014442.000000\n",
      "Train Epoch: 40 [304/918 (33%)] Loss: 15335992.000000\n",
      "Train Epoch: 40 [320/918 (35%)] Loss: 14754906.000000\n",
      "Train Epoch: 40 [336/918 (37%)] Loss: 16551427.000000\n",
      "Train Epoch: 40 [352/918 (38%)] Loss: 12650466.000000\n",
      "Train Epoch: 40 [368/918 (40%)] Loss: 12107754.000000\n",
      "Train Epoch: 40 [384/918 (42%)] Loss: 19645444.000000\n",
      "Train Epoch: 40 [400/918 (44%)] Loss: 16859780.000000\n",
      "Train Epoch: 40 [416/918 (45%)] Loss: 12628034.000000\n",
      "Train Epoch: 40 [432/918 (47%)] Loss: 16616101.000000\n",
      "Train Epoch: 40 [448/918 (49%)] Loss: 13239870.000000\n",
      "Train Epoch: 40 [464/918 (51%)] Loss: 18353780.000000\n",
      "Train Epoch: 40 [480/918 (52%)] Loss: 12431867.000000\n",
      "Train Epoch: 40 [496/918 (54%)] Loss: 16621226.000000\n",
      "Train Epoch: 40 [512/918 (56%)] Loss: 16840100.000000\n",
      "Train Epoch: 40 [528/918 (58%)] Loss: 17748816.000000\n",
      "Train Epoch: 40 [544/918 (59%)] Loss: 12832476.000000\n",
      "Train Epoch: 40 [560/918 (61%)] Loss: 17505424.000000\n",
      "Train Epoch: 40 [576/918 (63%)] Loss: 12547668.000000\n",
      "Train Epoch: 40 [592/918 (64%)] Loss: 11272336.000000\n",
      "Train Epoch: 40 [608/918 (66%)] Loss: 17305178.000000\n",
      "Train Epoch: 40 [624/918 (68%)] Loss: 13110144.000000\n",
      "Train Epoch: 40 [640/918 (70%)] Loss: 17878878.000000\n",
      "Train Epoch: 40 [656/918 (71%)] Loss: 13104567.000000\n",
      "Train Epoch: 40 [672/918 (73%)] Loss: 14398661.000000\n",
      "Train Epoch: 40 [688/918 (75%)] Loss: 24658918.000000\n",
      "Train Epoch: 40 [704/918 (77%)] Loss: 13327292.000000\n",
      "Train Epoch: 40 [720/918 (78%)] Loss: 16069879.000000\n",
      "Train Epoch: 40 [736/918 (80%)] Loss: 16086823.000000\n",
      "Train Epoch: 40 [752/918 (82%)] Loss: 13219999.000000\n",
      "Train Epoch: 40 [768/918 (84%)] Loss: 14150261.000000\n",
      "Train Epoch: 40 [784/918 (85%)] Loss: 15677405.000000\n",
      "Train Epoch: 40 [800/918 (87%)] Loss: 18050100.000000\n",
      "Train Epoch: 40 [816/918 (89%)] Loss: 12566396.000000\n",
      "Train Epoch: 40 [832/918 (91%)] Loss: 17755872.000000\n",
      "Train Epoch: 40 [848/918 (92%)] Loss: 19868986.000000\n",
      "Train Epoch: 40 [864/918 (94%)] Loss: 15002975.000000\n",
      "Train Epoch: 40 [880/918 (96%)] Loss: 11478320.000000\n",
      "Train Epoch: 40 [896/918 (98%)] Loss: 17731162.000000\n",
      "Train Epoch: 40 [912/918 (99%)] Loss: 12337916.000000\n",
      "    epoch          : 40\n",
      "    loss           : 15608287.956521738\n",
      "    ess            : 17.152140528222787\n",
      "    log_marginal   : -15608286.495652175\n",
      "    val_loss       : 15321512.23076923\n",
      "    val_ess        : 14.388894741351788\n",
      "    val_log_marginal: -15321511.461538462\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [0/918 (0%)] Loss: 17448126.000000\n",
      "Train Epoch: 41 [16/918 (2%)] Loss: 17050266.000000\n",
      "Train Epoch: 41 [32/918 (3%)] Loss: 12091430.000000\n",
      "Train Epoch: 41 [48/918 (5%)] Loss: 14142955.000000\n",
      "Train Epoch: 41 [64/918 (7%)] Loss: 14313939.000000\n",
      "Train Epoch: 41 [80/918 (9%)] Loss: 16948416.000000\n",
      "Train Epoch: 41 [96/918 (10%)] Loss: 18497184.000000\n",
      "Train Epoch: 41 [112/918 (12%)] Loss: 18124222.000000\n",
      "Train Epoch: 41 [128/918 (14%)] Loss: 15197048.000000\n",
      "Train Epoch: 41 [144/918 (16%)] Loss: 14518400.000000\n",
      "Train Epoch: 41 [160/918 (17%)] Loss: 13064830.000000\n",
      "Train Epoch: 41 [176/918 (19%)] Loss: 18554308.000000\n",
      "Train Epoch: 41 [192/918 (21%)] Loss: 18563830.000000\n",
      "Train Epoch: 41 [208/918 (23%)] Loss: 16030231.000000\n",
      "Train Epoch: 41 [224/918 (24%)] Loss: 16678202.000000\n",
      "Train Epoch: 41 [240/918 (26%)] Loss: 14664450.000000\n",
      "Train Epoch: 41 [256/918 (28%)] Loss: 14701933.000000\n",
      "Train Epoch: 41 [272/918 (30%)] Loss: 15190861.000000\n",
      "Train Epoch: 41 [288/918 (31%)] Loss: 14920925.000000\n",
      "Train Epoch: 41 [304/918 (33%)] Loss: 13823290.000000\n",
      "Train Epoch: 41 [320/918 (35%)] Loss: 31016614.000000\n",
      "Train Epoch: 41 [336/918 (37%)] Loss: 12058405.000000\n",
      "Train Epoch: 41 [352/918 (38%)] Loss: 15427139.000000\n",
      "Train Epoch: 41 [368/918 (40%)] Loss: 17063358.000000\n",
      "Train Epoch: 41 [384/918 (42%)] Loss: 20951018.000000\n",
      "Train Epoch: 41 [400/918 (44%)] Loss: 13940664.000000\n",
      "Train Epoch: 41 [416/918 (45%)] Loss: 16430543.000000\n",
      "Train Epoch: 41 [432/918 (47%)] Loss: 14665968.000000\n",
      "Train Epoch: 41 [448/918 (49%)] Loss: 15465735.000000\n",
      "Train Epoch: 41 [464/918 (51%)] Loss: 12280976.000000\n",
      "Train Epoch: 41 [480/918 (52%)] Loss: 16433456.000000\n",
      "Train Epoch: 41 [496/918 (54%)] Loss: 13317212.000000\n",
      "Train Epoch: 41 [512/918 (56%)] Loss: 20100086.000000\n",
      "Train Epoch: 41 [528/918 (58%)] Loss: 12227980.000000\n",
      "Train Epoch: 41 [544/918 (59%)] Loss: 11909110.000000\n",
      "Train Epoch: 41 [560/918 (61%)] Loss: 12692862.000000\n",
      "Train Epoch: 41 [576/918 (63%)] Loss: 14183843.000000\n",
      "Train Epoch: 41 [592/918 (64%)] Loss: 13408797.000000\n",
      "Train Epoch: 41 [608/918 (66%)] Loss: 15540333.000000\n",
      "Train Epoch: 41 [624/918 (68%)] Loss: 13155944.000000\n",
      "Train Epoch: 41 [640/918 (70%)] Loss: 16295715.000000\n",
      "Train Epoch: 41 [656/918 (71%)] Loss: 19203942.000000\n",
      "Train Epoch: 41 [672/918 (73%)] Loss: 14280157.000000\n",
      "Train Epoch: 41 [688/918 (75%)] Loss: 16812830.000000\n",
      "Train Epoch: 41 [704/918 (77%)] Loss: 15978683.000000\n",
      "Train Epoch: 41 [720/918 (78%)] Loss: 12799770.000000\n",
      "Train Epoch: 41 [736/918 (80%)] Loss: 14198880.000000\n",
      "Train Epoch: 41 [752/918 (82%)] Loss: 13857087.000000\n",
      "Train Epoch: 41 [768/918 (84%)] Loss: 15441496.000000\n",
      "Train Epoch: 41 [784/918 (85%)] Loss: 15103866.000000\n",
      "Train Epoch: 41 [800/918 (87%)] Loss: 11375911.000000\n",
      "Train Epoch: 41 [816/918 (89%)] Loss: 19377440.000000\n",
      "Train Epoch: 41 [832/918 (91%)] Loss: 18305900.000000\n",
      "Train Epoch: 41 [848/918 (92%)] Loss: 19845102.000000\n",
      "Train Epoch: 41 [864/918 (94%)] Loss: 11930261.000000\n",
      "Train Epoch: 41 [880/918 (96%)] Loss: 13510192.000000\n",
      "Train Epoch: 41 [896/918 (98%)] Loss: 13738034.000000\n",
      "Train Epoch: 41 [912/918 (99%)] Loss: 15555459.000000\n",
      "    epoch          : 41\n",
      "    loss           : 15333580.078260869\n",
      "    ess            : 15.069902030281398\n",
      "    log_marginal   : -15333578.513043478\n",
      "    val_loss       : 14954718.923076924\n",
      "    val_ess        : 10.576549823467548\n",
      "    val_log_marginal: -14954718.076923076\n",
      "Train Epoch: 42 [0/918 (0%)] Loss: 17796934.000000\n",
      "Train Epoch: 42 [16/918 (2%)] Loss: 13057724.000000\n",
      "Train Epoch: 42 [32/918 (3%)] Loss: 14080970.000000\n",
      "Train Epoch: 42 [48/918 (5%)] Loss: 15967264.000000\n",
      "Train Epoch: 42 [64/918 (7%)] Loss: 15093901.000000\n",
      "Train Epoch: 42 [80/918 (9%)] Loss: 10905845.000000\n",
      "Train Epoch: 42 [96/918 (10%)] Loss: 15779469.000000\n",
      "Train Epoch: 42 [112/918 (12%)] Loss: 14089443.000000\n",
      "Train Epoch: 42 [128/918 (14%)] Loss: 25590022.000000\n",
      "Train Epoch: 42 [144/918 (16%)] Loss: 9935924.000000\n",
      "Train Epoch: 42 [160/918 (17%)] Loss: 14008104.000000\n",
      "Train Epoch: 42 [176/918 (19%)] Loss: 15572483.000000\n",
      "Train Epoch: 42 [192/918 (21%)] Loss: 14234637.000000\n",
      "Train Epoch: 42 [208/918 (23%)] Loss: 11585466.000000\n",
      "Train Epoch: 42 [224/918 (24%)] Loss: 14337770.000000\n",
      "Train Epoch: 42 [240/918 (26%)] Loss: 18572550.000000\n",
      "Train Epoch: 42 [256/918 (28%)] Loss: 16486797.000000\n",
      "Train Epoch: 42 [272/918 (30%)] Loss: 17224854.000000\n",
      "Train Epoch: 42 [288/918 (31%)] Loss: 15630955.000000\n",
      "Train Epoch: 42 [304/918 (33%)] Loss: 15850355.000000\n",
      "Train Epoch: 42 [320/918 (35%)] Loss: 14321461.000000\n",
      "Train Epoch: 42 [336/918 (37%)] Loss: 13401749.000000\n",
      "Train Epoch: 42 [352/918 (38%)] Loss: 12892413.000000\n",
      "Train Epoch: 42 [368/918 (40%)] Loss: 11796917.000000\n",
      "Train Epoch: 42 [384/918 (42%)] Loss: 12299454.000000\n",
      "Train Epoch: 42 [400/918 (44%)] Loss: 13168227.000000\n",
      "Train Epoch: 42 [416/918 (45%)] Loss: 15930616.000000\n",
      "Train Epoch: 42 [432/918 (47%)] Loss: 27231898.000000\n",
      "Train Epoch: 42 [448/918 (49%)] Loss: 16686093.000000\n",
      "Train Epoch: 42 [464/918 (51%)] Loss: 14823111.000000\n",
      "Train Epoch: 42 [480/918 (52%)] Loss: 14848381.000000\n",
      "Train Epoch: 42 [496/918 (54%)] Loss: 13645605.000000\n",
      "Train Epoch: 42 [512/918 (56%)] Loss: 15238213.000000\n",
      "Train Epoch: 42 [528/918 (58%)] Loss: 14054231.000000\n",
      "Train Epoch: 42 [544/918 (59%)] Loss: 19506084.000000\n",
      "Train Epoch: 42 [560/918 (61%)] Loss: 11809948.000000\n",
      "Train Epoch: 42 [576/918 (63%)] Loss: 13783039.000000\n",
      "Train Epoch: 42 [592/918 (64%)] Loss: 16956660.000000\n",
      "Train Epoch: 42 [608/918 (66%)] Loss: 15714461.000000\n",
      "Train Epoch: 42 [624/918 (68%)] Loss: 13700893.000000\n",
      "Train Epoch: 42 [640/918 (70%)] Loss: 16838694.000000\n",
      "Train Epoch: 42 [656/918 (71%)] Loss: 17918432.000000\n",
      "Train Epoch: 42 [672/918 (73%)] Loss: 13222196.000000\n",
      "Train Epoch: 42 [688/918 (75%)] Loss: 12580027.000000\n",
      "Train Epoch: 42 [704/918 (77%)] Loss: 17235350.000000\n",
      "Train Epoch: 42 [720/918 (78%)] Loss: 14121591.000000\n",
      "Train Epoch: 42 [736/918 (80%)] Loss: 14628247.000000\n",
      "Train Epoch: 42 [752/918 (82%)] Loss: 10241835.000000\n",
      "Train Epoch: 42 [768/918 (84%)] Loss: 20892808.000000\n",
      "Train Epoch: 42 [784/918 (85%)] Loss: 16665671.000000\n",
      "Train Epoch: 42 [800/918 (87%)] Loss: 19186312.000000\n",
      "Train Epoch: 42 [816/918 (89%)] Loss: 20995808.000000\n",
      "Train Epoch: 42 [832/918 (91%)] Loss: 15291202.000000\n",
      "Train Epoch: 42 [848/918 (92%)] Loss: 13285762.000000\n",
      "Train Epoch: 42 [864/918 (94%)] Loss: 13653619.000000\n",
      "Train Epoch: 42 [880/918 (96%)] Loss: 18353998.000000\n",
      "Train Epoch: 42 [896/918 (98%)] Loss: 17002782.000000\n",
      "Train Epoch: 42 [912/918 (99%)] Loss: 15365208.000000\n",
      "    epoch          : 42\n",
      "    loss           : 14983953.426086957\n",
      "    ess            : 15.220745119841203\n",
      "    log_marginal   : -14983952.373913044\n",
      "    val_loss       : 14736888.076923076\n",
      "    val_ess        : 12.754467964172363\n",
      "    val_log_marginal: -14736885.153846154\n",
      "Train Epoch: 43 [0/918 (0%)] Loss: 12764672.000000\n",
      "Train Epoch: 43 [16/918 (2%)] Loss: 11301510.000000\n",
      "Train Epoch: 43 [32/918 (3%)] Loss: 15552506.000000\n",
      "Train Epoch: 43 [48/918 (5%)] Loss: 11974464.000000\n",
      "Train Epoch: 43 [64/918 (7%)] Loss: 22954544.000000\n",
      "Train Epoch: 43 [80/918 (9%)] Loss: 17727728.000000\n",
      "Train Epoch: 43 [96/918 (10%)] Loss: 19145740.000000\n",
      "Train Epoch: 43 [112/918 (12%)] Loss: 20323640.000000\n",
      "Train Epoch: 43 [128/918 (14%)] Loss: 11978559.000000\n",
      "Train Epoch: 43 [144/918 (16%)] Loss: 16291373.000000\n",
      "Train Epoch: 43 [160/918 (17%)] Loss: 16190135.000000\n",
      "Train Epoch: 43 [176/918 (19%)] Loss: 18798222.000000\n",
      "Train Epoch: 43 [192/918 (21%)] Loss: 28511626.000000\n",
      "Train Epoch: 43 [208/918 (23%)] Loss: 14590583.000000\n",
      "Train Epoch: 43 [224/918 (24%)] Loss: 12308583.000000\n",
      "Train Epoch: 43 [240/918 (26%)] Loss: 13704415.000000\n",
      "Train Epoch: 43 [256/918 (28%)] Loss: 14170407.000000\n",
      "Train Epoch: 43 [272/918 (30%)] Loss: 14328688.000000\n",
      "Train Epoch: 43 [288/918 (31%)] Loss: 16940072.000000\n",
      "Train Epoch: 43 [304/918 (33%)] Loss: 11559968.000000\n",
      "Train Epoch: 43 [320/918 (35%)] Loss: 12143489.000000\n",
      "Train Epoch: 43 [336/918 (37%)] Loss: 15667987.000000\n",
      "Train Epoch: 43 [352/918 (38%)] Loss: 12968062.000000\n",
      "Train Epoch: 43 [368/918 (40%)] Loss: 13517183.000000\n",
      "Train Epoch: 43 [384/918 (42%)] Loss: 12899571.000000\n",
      "Train Epoch: 43 [400/918 (44%)] Loss: 14694675.000000\n",
      "Train Epoch: 43 [416/918 (45%)] Loss: 18193486.000000\n",
      "Train Epoch: 43 [432/918 (47%)] Loss: 13825619.000000\n",
      "Train Epoch: 43 [448/918 (49%)] Loss: 10797053.000000\n",
      "Train Epoch: 43 [464/918 (51%)] Loss: 10414228.000000\n",
      "Train Epoch: 43 [480/918 (52%)] Loss: 13867528.000000\n",
      "Train Epoch: 43 [496/918 (54%)] Loss: 15588048.000000\n",
      "Train Epoch: 43 [512/918 (56%)] Loss: 11551421.000000\n",
      "Train Epoch: 43 [528/918 (58%)] Loss: 17702336.000000\n",
      "Train Epoch: 43 [544/918 (59%)] Loss: 13781335.000000\n",
      "Train Epoch: 43 [560/918 (61%)] Loss: 12078589.000000\n",
      "Train Epoch: 43 [576/918 (63%)] Loss: 18253686.000000\n",
      "Train Epoch: 43 [592/918 (64%)] Loss: 17916080.000000\n",
      "Train Epoch: 43 [608/918 (66%)] Loss: 12411608.000000\n",
      "Train Epoch: 43 [624/918 (68%)] Loss: 12160774.000000\n",
      "Train Epoch: 43 [640/918 (70%)] Loss: 15172191.000000\n",
      "Train Epoch: 43 [656/918 (71%)] Loss: 16218901.000000\n",
      "Train Epoch: 43 [672/918 (73%)] Loss: 12240963.000000\n",
      "Train Epoch: 43 [688/918 (75%)] Loss: 16763107.000000\n",
      "Train Epoch: 43 [704/918 (77%)] Loss: 19309196.000000\n",
      "Train Epoch: 43 [720/918 (78%)] Loss: 15016533.000000\n",
      "Train Epoch: 43 [736/918 (80%)] Loss: 10917000.000000\n",
      "Train Epoch: 43 [752/918 (82%)] Loss: 15954471.000000\n",
      "Train Epoch: 43 [768/918 (84%)] Loss: 17786574.000000\n",
      "Train Epoch: 43 [784/918 (85%)] Loss: 16668259.000000\n",
      "Train Epoch: 43 [800/918 (87%)] Loss: 9085777.000000\n",
      "Train Epoch: 43 [816/918 (89%)] Loss: 10972112.000000\n",
      "Train Epoch: 43 [832/918 (91%)] Loss: 13637747.000000\n",
      "Train Epoch: 43 [848/918 (92%)] Loss: 14213882.000000\n",
      "Train Epoch: 43 [864/918 (94%)] Loss: 15833096.000000\n",
      "Train Epoch: 43 [880/918 (96%)] Loss: 14817335.000000\n",
      "Train Epoch: 43 [896/918 (98%)] Loss: 11722760.000000\n",
      "Train Epoch: 43 [912/918 (99%)] Loss: 12653290.000000\n",
      "    epoch          : 43\n",
      "    loss           : 14806917.017391304\n",
      "    ess            : 14.605958770669025\n",
      "    log_marginal   : -14806915.44347826\n",
      "    val_loss       : 14848529.615384616\n",
      "    val_ess        : 12.251023842738224\n",
      "    val_log_marginal: -14848528.692307692\n",
      "Train Epoch: 44 [0/918 (0%)] Loss: 12725713.000000\n",
      "Train Epoch: 44 [16/918 (2%)] Loss: 17195992.000000\n",
      "Train Epoch: 44 [32/918 (3%)] Loss: 14323410.000000\n",
      "Train Epoch: 44 [48/918 (5%)] Loss: 10513971.000000\n",
      "Train Epoch: 44 [64/918 (7%)] Loss: 24743262.000000\n",
      "Train Epoch: 44 [80/918 (9%)] Loss: 13828851.000000\n",
      "Train Epoch: 44 [96/918 (10%)] Loss: 12164238.000000\n",
      "Train Epoch: 44 [112/918 (12%)] Loss: 16560003.000000\n",
      "Train Epoch: 44 [128/918 (14%)] Loss: 19422174.000000\n",
      "Train Epoch: 44 [144/918 (16%)] Loss: 14793133.000000\n",
      "Train Epoch: 44 [160/918 (17%)] Loss: 16420810.000000\n",
      "Train Epoch: 44 [176/918 (19%)] Loss: 13991661.000000\n",
      "Train Epoch: 44 [192/918 (21%)] Loss: 10071011.000000\n",
      "Train Epoch: 44 [208/918 (23%)] Loss: 26324826.000000\n",
      "Train Epoch: 44 [224/918 (24%)] Loss: 15138647.000000\n",
      "Train Epoch: 44 [240/918 (26%)] Loss: 13611920.000000\n",
      "Train Epoch: 44 [256/918 (28%)] Loss: 13769763.000000\n",
      "Train Epoch: 44 [272/918 (30%)] Loss: 11674752.000000\n",
      "Train Epoch: 44 [288/918 (31%)] Loss: 30962406.000000\n",
      "Train Epoch: 44 [304/918 (33%)] Loss: 16793326.000000\n",
      "Train Epoch: 44 [320/918 (35%)] Loss: 14205392.000000\n",
      "Train Epoch: 44 [336/918 (37%)] Loss: 12426131.000000\n",
      "Train Epoch: 44 [352/918 (38%)] Loss: 14658208.000000\n",
      "Train Epoch: 44 [368/918 (40%)] Loss: 15320447.000000\n",
      "Train Epoch: 44 [384/918 (42%)] Loss: 12919249.000000\n",
      "Train Epoch: 44 [400/918 (44%)] Loss: 12200954.000000\n",
      "Train Epoch: 44 [416/918 (45%)] Loss: 12566556.000000\n",
      "Train Epoch: 44 [432/918 (47%)] Loss: 11810343.000000\n",
      "Train Epoch: 44 [448/918 (49%)] Loss: 14570032.000000\n",
      "Train Epoch: 44 [464/918 (51%)] Loss: 14278765.000000\n",
      "Train Epoch: 44 [480/918 (52%)] Loss: 13211112.000000\n",
      "Train Epoch: 44 [496/918 (54%)] Loss: 15837389.000000\n",
      "Train Epoch: 44 [512/918 (56%)] Loss: 15374805.000000\n",
      "Train Epoch: 44 [528/918 (58%)] Loss: 18053960.000000\n",
      "Train Epoch: 44 [544/918 (59%)] Loss: 12684594.000000\n",
      "Train Epoch: 44 [560/918 (61%)] Loss: 11002135.000000\n",
      "Train Epoch: 44 [576/918 (63%)] Loss: 14361418.000000\n",
      "Train Epoch: 44 [592/918 (64%)] Loss: 17904168.000000\n",
      "Train Epoch: 44 [608/918 (66%)] Loss: 14196587.000000\n",
      "Train Epoch: 44 [624/918 (68%)] Loss: 11377459.000000\n",
      "Train Epoch: 44 [640/918 (70%)] Loss: 15729735.000000\n",
      "Train Epoch: 44 [656/918 (71%)] Loss: 14162243.000000\n",
      "Train Epoch: 44 [672/918 (73%)] Loss: 13025310.000000\n",
      "Train Epoch: 44 [688/918 (75%)] Loss: 14770512.000000\n",
      "Train Epoch: 44 [704/918 (77%)] Loss: 16051835.000000\n",
      "Train Epoch: 44 [720/918 (78%)] Loss: 14758179.000000\n",
      "Train Epoch: 44 [736/918 (80%)] Loss: 9987437.000000\n",
      "Train Epoch: 44 [752/918 (82%)] Loss: 14714199.000000\n",
      "Train Epoch: 44 [768/918 (84%)] Loss: 13878144.000000\n",
      "Train Epoch: 44 [784/918 (85%)] Loss: 11761647.000000\n",
      "Train Epoch: 44 [800/918 (87%)] Loss: 14154131.000000\n",
      "Train Epoch: 44 [816/918 (89%)] Loss: 14611141.000000\n",
      "Train Epoch: 44 [832/918 (91%)] Loss: 12111379.000000\n",
      "Train Epoch: 44 [848/918 (92%)] Loss: 11933199.000000\n",
      "Train Epoch: 44 [864/918 (94%)] Loss: 13904704.000000\n",
      "Train Epoch: 44 [880/918 (96%)] Loss: 13520263.000000\n",
      "Train Epoch: 44 [896/918 (98%)] Loss: 13901920.000000\n",
      "Train Epoch: 44 [912/918 (99%)] Loss: 18347112.000000\n",
      "    epoch          : 44\n",
      "    loss           : 14707460.826086957\n",
      "    ess            : 14.14317138713339\n",
      "    log_marginal   : -14707459.47826087\n",
      "    val_loss       : 14450534.846153846\n",
      "    val_ess        : 10.58120426764855\n",
      "    val_log_marginal: -14450533.461538462\n",
      "Train Epoch: 45 [0/918 (0%)] Loss: 12065562.000000\n",
      "Train Epoch: 45 [16/918 (2%)] Loss: 12479899.000000\n",
      "Train Epoch: 45 [32/918 (3%)] Loss: 13548789.000000\n",
      "Train Epoch: 45 [48/918 (5%)] Loss: 12735938.000000\n",
      "Train Epoch: 45 [64/918 (7%)] Loss: 13135235.000000\n",
      "Train Epoch: 45 [80/918 (9%)] Loss: 13479853.000000\n",
      "Train Epoch: 45 [96/918 (10%)] Loss: 14458195.000000\n",
      "Train Epoch: 45 [112/918 (12%)] Loss: 21512628.000000\n",
      "Train Epoch: 45 [128/918 (14%)] Loss: 16714426.000000\n",
      "Train Epoch: 45 [144/918 (16%)] Loss: 13664941.000000\n",
      "Train Epoch: 45 [160/918 (17%)] Loss: 12029280.000000\n",
      "Train Epoch: 45 [176/918 (19%)] Loss: 12469224.000000\n",
      "Train Epoch: 45 [192/918 (21%)] Loss: 10412247.000000\n",
      "Train Epoch: 45 [208/918 (23%)] Loss: 9265040.000000\n",
      "Train Epoch: 45 [224/918 (24%)] Loss: 13779991.000000\n",
      "Train Epoch: 45 [240/918 (26%)] Loss: 16032909.000000\n",
      "Train Epoch: 45 [256/918 (28%)] Loss: 16695933.000000\n",
      "Train Epoch: 45 [272/918 (30%)] Loss: 14370067.000000\n",
      "Train Epoch: 45 [288/918 (31%)] Loss: 12229995.000000\n",
      "Train Epoch: 45 [304/918 (33%)] Loss: 13464631.000000\n",
      "Train Epoch: 45 [320/918 (35%)] Loss: 14831816.000000\n",
      "Train Epoch: 45 [336/918 (37%)] Loss: 14477584.000000\n",
      "Train Epoch: 45 [352/918 (38%)] Loss: 11418357.000000\n",
      "Train Epoch: 45 [368/918 (40%)] Loss: 15895187.000000\n",
      "Train Epoch: 45 [384/918 (42%)] Loss: 10758827.000000\n",
      "Train Epoch: 45 [400/918 (44%)] Loss: 11237307.000000\n",
      "Train Epoch: 45 [416/918 (45%)] Loss: 14953189.000000\n",
      "Train Epoch: 45 [432/918 (47%)] Loss: 13577005.000000\n",
      "Train Epoch: 45 [448/918 (49%)] Loss: 17554870.000000\n",
      "Train Epoch: 45 [464/918 (51%)] Loss: 13816048.000000\n",
      "Train Epoch: 45 [480/918 (52%)] Loss: 15544581.000000\n",
      "Train Epoch: 45 [496/918 (54%)] Loss: 18232270.000000\n",
      "Train Epoch: 45 [512/918 (56%)] Loss: 15921679.000000\n",
      "Train Epoch: 45 [528/918 (58%)] Loss: 12404704.000000\n",
      "Train Epoch: 45 [544/918 (59%)] Loss: 14681267.000000\n",
      "Train Epoch: 45 [560/918 (61%)] Loss: 14467495.000000\n",
      "Train Epoch: 45 [576/918 (63%)] Loss: 15542192.000000\n",
      "Train Epoch: 45 [592/918 (64%)] Loss: 14670195.000000\n",
      "Train Epoch: 45 [608/918 (66%)] Loss: 12236775.000000\n",
      "Train Epoch: 45 [624/918 (68%)] Loss: 14117296.000000\n",
      "Train Epoch: 45 [640/918 (70%)] Loss: 13836359.000000\n",
      "Train Epoch: 45 [656/918 (71%)] Loss: 12228376.000000\n",
      "Train Epoch: 45 [672/918 (73%)] Loss: 12866971.000000\n",
      "Train Epoch: 45 [688/918 (75%)] Loss: 12700232.000000\n",
      "Train Epoch: 45 [704/918 (77%)] Loss: 19503202.000000\n",
      "Train Epoch: 45 [720/918 (78%)] Loss: 14668730.000000\n",
      "Train Epoch: 45 [736/918 (80%)] Loss: 17060216.000000\n",
      "Train Epoch: 45 [752/918 (82%)] Loss: 17285320.000000\n",
      "Train Epoch: 45 [768/918 (84%)] Loss: 13352383.000000\n",
      "Train Epoch: 45 [784/918 (85%)] Loss: 16505554.000000\n",
      "Train Epoch: 45 [800/918 (87%)] Loss: 10988475.000000\n",
      "Train Epoch: 45 [816/918 (89%)] Loss: 15311112.000000\n",
      "Train Epoch: 45 [832/918 (91%)] Loss: 13351264.000000\n",
      "Train Epoch: 45 [848/918 (92%)] Loss: 15385114.000000\n",
      "Train Epoch: 45 [864/918 (94%)] Loss: 16636888.000000\n",
      "Train Epoch: 45 [880/918 (96%)] Loss: 10114115.000000\n",
      "Train Epoch: 45 [896/918 (98%)] Loss: 13164687.000000\n",
      "Train Epoch: 45 [912/918 (99%)] Loss: 12959489.000000\n",
      "    epoch          : 45\n",
      "    loss           : 14613338.739130436\n",
      "    ess            : 14.482891101422517\n",
      "    log_marginal   : -14613336.869565217\n",
      "    val_loss       : 14754484.307692308\n",
      "    val_ess        : 11.620702230013334\n",
      "    val_log_marginal: -14754483.0\n",
      "Train Epoch: 46 [0/918 (0%)] Loss: 12577311.000000\n",
      "Train Epoch: 46 [16/918 (2%)] Loss: 11474000.000000\n",
      "Train Epoch: 46 [32/918 (3%)] Loss: 12495019.000000\n",
      "Train Epoch: 46 [48/918 (5%)] Loss: 12734552.000000\n",
      "Train Epoch: 46 [64/918 (7%)] Loss: 21406596.000000\n",
      "Train Epoch: 46 [80/918 (9%)] Loss: 21638126.000000\n",
      "Train Epoch: 46 [96/918 (10%)] Loss: 13166989.000000\n",
      "Train Epoch: 46 [112/918 (12%)] Loss: 10435130.000000\n",
      "Train Epoch: 46 [128/918 (14%)] Loss: 18150422.000000\n",
      "Train Epoch: 46 [144/918 (16%)] Loss: 13492805.000000\n",
      "Train Epoch: 46 [160/918 (17%)] Loss: 15006349.000000\n",
      "Train Epoch: 46 [176/918 (19%)] Loss: 17393744.000000\n",
      "Train Epoch: 46 [192/918 (21%)] Loss: 13060797.000000\n",
      "Train Epoch: 46 [208/918 (23%)] Loss: 14220074.000000\n",
      "Train Epoch: 46 [224/918 (24%)] Loss: 19107166.000000\n",
      "Train Epoch: 46 [240/918 (26%)] Loss: 18206334.000000\n",
      "Train Epoch: 46 [256/918 (28%)] Loss: 12116511.000000\n",
      "Train Epoch: 46 [272/918 (30%)] Loss: 13058485.000000\n",
      "Train Epoch: 46 [288/918 (31%)] Loss: 14775842.000000\n",
      "Train Epoch: 46 [304/918 (33%)] Loss: 13165648.000000\n",
      "Train Epoch: 46 [320/918 (35%)] Loss: 12407128.000000\n",
      "Train Epoch: 46 [336/918 (37%)] Loss: 13317461.000000\n",
      "Train Epoch: 46 [352/918 (38%)] Loss: 13351592.000000\n",
      "Train Epoch: 46 [368/918 (40%)] Loss: 18453660.000000\n",
      "Train Epoch: 46 [384/918 (42%)] Loss: 14685101.000000\n",
      "Train Epoch: 46 [400/918 (44%)] Loss: 13207880.000000\n",
      "Train Epoch: 46 [416/918 (45%)] Loss: 17316572.000000\n",
      "Train Epoch: 46 [432/918 (47%)] Loss: 13485539.000000\n",
      "Train Epoch: 46 [448/918 (49%)] Loss: 13991800.000000\n",
      "Train Epoch: 46 [464/918 (51%)] Loss: 12948088.000000\n",
      "Train Epoch: 46 [480/918 (52%)] Loss: 10328064.000000\n",
      "Train Epoch: 46 [496/918 (54%)] Loss: 16527946.000000\n",
      "Train Epoch: 46 [512/918 (56%)] Loss: 9877283.000000\n",
      "Train Epoch: 46 [528/918 (58%)] Loss: 17078118.000000\n",
      "Train Epoch: 46 [544/918 (59%)] Loss: 14535155.000000\n",
      "Train Epoch: 46 [560/918 (61%)] Loss: 13087923.000000\n",
      "Train Epoch: 46 [576/918 (63%)] Loss: 12615169.000000\n",
      "Train Epoch: 46 [592/918 (64%)] Loss: 14447381.000000\n",
      "Train Epoch: 46 [608/918 (66%)] Loss: 15928535.000000\n",
      "Train Epoch: 46 [624/918 (68%)] Loss: 12238571.000000\n",
      "Train Epoch: 46 [640/918 (70%)] Loss: 13172878.000000\n",
      "Train Epoch: 46 [656/918 (71%)] Loss: 12013356.000000\n",
      "Train Epoch: 46 [672/918 (73%)] Loss: 11951023.000000\n",
      "Train Epoch: 46 [688/918 (75%)] Loss: 14796954.000000\n",
      "Train Epoch: 46 [704/918 (77%)] Loss: 16478003.000000\n",
      "Train Epoch: 46 [720/918 (78%)] Loss: 18130750.000000\n",
      "Train Epoch: 46 [736/918 (80%)] Loss: 13859901.000000\n",
      "Train Epoch: 46 [752/918 (82%)] Loss: 17277534.000000\n",
      "Train Epoch: 46 [768/918 (84%)] Loss: 12954195.000000\n",
      "Train Epoch: 46 [784/918 (85%)] Loss: 14130787.000000\n",
      "Train Epoch: 46 [800/918 (87%)] Loss: 13603357.000000\n",
      "Train Epoch: 46 [816/918 (89%)] Loss: 13820026.000000\n",
      "Train Epoch: 46 [832/918 (91%)] Loss: 10740962.000000\n",
      "Train Epoch: 46 [848/918 (92%)] Loss: 12591792.000000\n",
      "Train Epoch: 46 [864/918 (94%)] Loss: 20657482.000000\n",
      "Train Epoch: 46 [880/918 (96%)] Loss: 11976506.000000\n",
      "Train Epoch: 46 [896/918 (98%)] Loss: 15150944.000000\n",
      "Train Epoch: 46 [912/918 (99%)] Loss: 15523335.000000\n",
      "    epoch          : 46\n",
      "    loss           : 14332332.930434782\n",
      "    ess            : 14.164273315927257\n",
      "    log_marginal   : -14332331.895652173\n",
      "    val_loss       : 13627742.384615384\n",
      "    val_ess        : 10.996432671180138\n",
      "    val_log_marginal: -13627741.384615384\n",
      "Train Epoch: 47 [0/918 (0%)] Loss: 14571221.000000\n",
      "Train Epoch: 47 [16/918 (2%)] Loss: 10521840.000000\n",
      "Train Epoch: 47 [32/918 (3%)] Loss: 20728004.000000\n",
      "Train Epoch: 47 [48/918 (5%)] Loss: 19032640.000000\n",
      "Train Epoch: 47 [64/918 (7%)] Loss: 10565031.000000\n",
      "Train Epoch: 47 [80/918 (9%)] Loss: 12226571.000000\n",
      "Train Epoch: 47 [96/918 (10%)] Loss: 9550411.000000\n",
      "Train Epoch: 47 [112/918 (12%)] Loss: 17169720.000000\n",
      "Train Epoch: 47 [128/918 (14%)] Loss: 12528243.000000\n",
      "Train Epoch: 47 [144/918 (16%)] Loss: 13924746.000000\n",
      "Train Epoch: 47 [160/918 (17%)] Loss: 12891219.000000\n",
      "Train Epoch: 47 [176/918 (19%)] Loss: 12663147.000000\n",
      "Train Epoch: 47 [192/918 (21%)] Loss: 15412775.000000\n",
      "Train Epoch: 47 [208/918 (23%)] Loss: 16062263.000000\n",
      "Train Epoch: 47 [224/918 (24%)] Loss: 12908363.000000\n",
      "Train Epoch: 47 [240/918 (26%)] Loss: 14208311.000000\n",
      "Train Epoch: 47 [256/918 (28%)] Loss: 22960248.000000\n",
      "Train Epoch: 47 [272/918 (30%)] Loss: 14106346.000000\n",
      "Train Epoch: 47 [288/918 (31%)] Loss: 15518797.000000\n",
      "Train Epoch: 47 [304/918 (33%)] Loss: 11483438.000000\n",
      "Train Epoch: 47 [320/918 (35%)] Loss: 16086632.000000\n",
      "Train Epoch: 47 [336/918 (37%)] Loss: 16711931.000000\n",
      "Train Epoch: 47 [352/918 (38%)] Loss: 15074122.000000\n",
      "Train Epoch: 47 [368/918 (40%)] Loss: 10409849.000000\n",
      "Train Epoch: 47 [384/918 (42%)] Loss: 13465795.000000\n",
      "Train Epoch: 47 [400/918 (44%)] Loss: 10554451.000000\n",
      "Train Epoch: 47 [416/918 (45%)] Loss: 12552284.000000\n",
      "Train Epoch: 47 [432/918 (47%)] Loss: 14868570.000000\n",
      "Train Epoch: 47 [448/918 (49%)] Loss: 14978451.000000\n",
      "Train Epoch: 47 [464/918 (51%)] Loss: 15769818.000000\n",
      "Train Epoch: 47 [480/918 (52%)] Loss: 12194379.000000\n",
      "Train Epoch: 47 [496/918 (54%)] Loss: 12780843.000000\n",
      "Train Epoch: 47 [512/918 (56%)] Loss: 17232998.000000\n",
      "Train Epoch: 47 [528/918 (58%)] Loss: 13347014.000000\n",
      "Train Epoch: 47 [544/918 (59%)] Loss: 12667306.000000\n",
      "Train Epoch: 47 [560/918 (61%)] Loss: 11297379.000000\n",
      "Train Epoch: 47 [576/918 (63%)] Loss: 15708605.000000\n",
      "Train Epoch: 47 [592/918 (64%)] Loss: 10242197.000000\n",
      "Train Epoch: 47 [608/918 (66%)] Loss: 14594047.000000\n",
      "Train Epoch: 47 [624/918 (68%)] Loss: 17568628.000000\n",
      "Train Epoch: 47 [640/918 (70%)] Loss: 10213305.000000\n",
      "Train Epoch: 47 [656/918 (71%)] Loss: 13502437.000000\n",
      "Train Epoch: 47 [672/918 (73%)] Loss: 14232144.000000\n",
      "Train Epoch: 47 [688/918 (75%)] Loss: 20332644.000000\n",
      "Train Epoch: 47 [704/918 (77%)] Loss: 13063640.000000\n",
      "Train Epoch: 47 [720/918 (78%)] Loss: 11446719.000000\n",
      "Train Epoch: 47 [736/918 (80%)] Loss: 15955773.000000\n",
      "Train Epoch: 47 [752/918 (82%)] Loss: 11901467.000000\n",
      "Train Epoch: 47 [768/918 (84%)] Loss: 15495549.000000\n",
      "Train Epoch: 47 [784/918 (85%)] Loss: 11159420.000000\n",
      "Train Epoch: 47 [800/918 (87%)] Loss: 12348295.000000\n",
      "Train Epoch: 47 [816/918 (89%)] Loss: 14989560.000000\n",
      "Train Epoch: 47 [832/918 (91%)] Loss: 12282685.000000\n",
      "Train Epoch: 47 [848/918 (92%)] Loss: 12044184.000000\n",
      "Train Epoch: 47 [864/918 (94%)] Loss: 11742030.000000\n",
      "Train Epoch: 47 [880/918 (96%)] Loss: 11968375.000000\n",
      "Train Epoch: 47 [896/918 (98%)] Loss: 15418291.000000\n",
      "Train Epoch: 47 [912/918 (99%)] Loss: 14365007.000000\n",
      "    epoch          : 47\n",
      "    loss           : 14365137.947826087\n",
      "    ess            : 13.489766680676004\n",
      "    log_marginal   : -14365136.32173913\n",
      "    val_loss       : 13972538.384615384\n",
      "    val_ess        : 8.875293254852295\n",
      "    val_log_marginal: -13972535.538461538\n",
      "Train Epoch: 48 [0/918 (0%)] Loss: 15316024.000000\n",
      "Train Epoch: 48 [16/918 (2%)] Loss: 10921861.000000\n",
      "Train Epoch: 48 [32/918 (3%)] Loss: 11711014.000000\n",
      "Train Epoch: 48 [48/918 (5%)] Loss: 14154680.000000\n",
      "Train Epoch: 48 [64/918 (7%)] Loss: 12284096.000000\n",
      "Train Epoch: 48 [80/918 (9%)] Loss: 14038643.000000\n",
      "Train Epoch: 48 [96/918 (10%)] Loss: 12370237.000000\n",
      "Train Epoch: 48 [112/918 (12%)] Loss: 19772148.000000\n",
      "Train Epoch: 48 [128/918 (14%)] Loss: 11688552.000000\n",
      "Train Epoch: 48 [144/918 (16%)] Loss: 11864701.000000\n",
      "Train Epoch: 48 [160/918 (17%)] Loss: 13750679.000000\n",
      "Train Epoch: 48 [176/918 (19%)] Loss: 10071074.000000\n",
      "Train Epoch: 48 [192/918 (21%)] Loss: 16621331.000000\n",
      "Train Epoch: 48 [208/918 (23%)] Loss: 10359600.000000\n",
      "Train Epoch: 48 [224/918 (24%)] Loss: 11472363.000000\n",
      "Train Epoch: 48 [240/918 (26%)] Loss: 16166757.000000\n",
      "Train Epoch: 48 [256/918 (28%)] Loss: 16080519.000000\n",
      "Train Epoch: 48 [272/918 (30%)] Loss: 12115012.000000\n",
      "Train Epoch: 48 [288/918 (31%)] Loss: 15779635.000000\n",
      "Train Epoch: 48 [304/918 (33%)] Loss: 9943524.000000\n",
      "Train Epoch: 48 [320/918 (35%)] Loss: 9718775.000000\n",
      "Train Epoch: 48 [336/918 (37%)] Loss: 12772780.000000\n",
      "Train Epoch: 48 [352/918 (38%)] Loss: 13699739.000000\n",
      "Train Epoch: 48 [368/918 (40%)] Loss: 13450768.000000\n",
      "Train Epoch: 48 [384/918 (42%)] Loss: 18565348.000000\n",
      "Train Epoch: 48 [400/918 (44%)] Loss: 16006104.000000\n",
      "Train Epoch: 48 [416/918 (45%)] Loss: 12527575.000000\n",
      "Train Epoch: 48 [432/918 (47%)] Loss: 16613195.000000\n",
      "Train Epoch: 48 [448/918 (49%)] Loss: 13443939.000000\n",
      "Train Epoch: 48 [464/918 (51%)] Loss: 14094344.000000\n",
      "Train Epoch: 48 [480/918 (52%)] Loss: 14260263.000000\n",
      "Train Epoch: 48 [496/918 (54%)] Loss: 11701060.000000\n",
      "Train Epoch: 48 [512/918 (56%)] Loss: 23938624.000000\n",
      "Train Epoch: 48 [528/918 (58%)] Loss: 10490384.000000\n",
      "Train Epoch: 48 [544/918 (59%)] Loss: 15330653.000000\n",
      "Train Epoch: 48 [560/918 (61%)] Loss: 12761179.000000\n",
      "Train Epoch: 48 [576/918 (63%)] Loss: 17660186.000000\n",
      "Train Epoch: 48 [592/918 (64%)] Loss: 23050524.000000\n",
      "Train Epoch: 48 [608/918 (66%)] Loss: 10676674.000000\n",
      "Train Epoch: 48 [624/918 (68%)] Loss: 10377306.000000\n",
      "Train Epoch: 48 [640/918 (70%)] Loss: 12638279.000000\n",
      "Train Epoch: 48 [656/918 (71%)] Loss: 12777421.000000\n",
      "Train Epoch: 48 [672/918 (73%)] Loss: 18458718.000000\n",
      "Train Epoch: 48 [688/918 (75%)] Loss: 17502084.000000\n",
      "Train Epoch: 48 [704/918 (77%)] Loss: 14439795.000000\n",
      "Train Epoch: 48 [720/918 (78%)] Loss: 15900818.000000\n",
      "Train Epoch: 48 [736/918 (80%)] Loss: 16041099.000000\n",
      "Train Epoch: 48 [752/918 (82%)] Loss: 12882043.000000\n",
      "Train Epoch: 48 [768/918 (84%)] Loss: 9533379.000000\n",
      "Train Epoch: 48 [784/918 (85%)] Loss: 15525906.000000\n",
      "Train Epoch: 48 [800/918 (87%)] Loss: 12571994.000000\n",
      "Train Epoch: 48 [816/918 (89%)] Loss: 12689939.000000\n",
      "Train Epoch: 48 [832/918 (91%)] Loss: 20283486.000000\n",
      "Train Epoch: 48 [848/918 (92%)] Loss: 14259597.000000\n",
      "Train Epoch: 48 [864/918 (94%)] Loss: 11672168.000000\n",
      "Train Epoch: 48 [880/918 (96%)] Loss: 16091079.000000\n",
      "Train Epoch: 48 [896/918 (98%)] Loss: 16291549.000000\n",
      "Train Epoch: 48 [912/918 (99%)] Loss: 14218401.000000\n",
      "    epoch          : 48\n",
      "    loss           : 14247867.27826087\n",
      "    ess            : 13.114315227840258\n",
      "    log_marginal   : -14247866.052173913\n",
      "    val_loss       : 13992212.923076924\n",
      "    val_ess        : 12.135860223036547\n",
      "    val_log_marginal: -13992211.76923077\n",
      "Train Epoch: 49 [0/918 (0%)] Loss: 11646551.000000\n",
      "Train Epoch: 49 [16/918 (2%)] Loss: 11996382.000000\n",
      "Train Epoch: 49 [32/918 (3%)] Loss: 12336530.000000\n",
      "Train Epoch: 49 [48/918 (5%)] Loss: 12968635.000000\n",
      "Train Epoch: 49 [64/918 (7%)] Loss: 13403400.000000\n",
      "Train Epoch: 49 [80/918 (9%)] Loss: 16802064.000000\n",
      "Train Epoch: 49 [96/918 (10%)] Loss: 11855114.000000\n",
      "Train Epoch: 49 [112/918 (12%)] Loss: 17331700.000000\n",
      "Train Epoch: 49 [128/918 (14%)] Loss: 15195375.000000\n",
      "Train Epoch: 49 [144/918 (16%)] Loss: 15590331.000000\n",
      "Train Epoch: 49 [160/918 (17%)] Loss: 15012586.000000\n",
      "Train Epoch: 49 [176/918 (19%)] Loss: 12239096.000000\n",
      "Train Epoch: 49 [192/918 (21%)] Loss: 14824669.000000\n",
      "Train Epoch: 49 [208/918 (23%)] Loss: 12881355.000000\n",
      "Train Epoch: 49 [224/918 (24%)] Loss: 18427332.000000\n",
      "Train Epoch: 49 [240/918 (26%)] Loss: 13310909.000000\n",
      "Train Epoch: 49 [256/918 (28%)] Loss: 18479518.000000\n",
      "Train Epoch: 49 [272/918 (30%)] Loss: 13381166.000000\n",
      "Train Epoch: 49 [288/918 (31%)] Loss: 13430506.000000\n",
      "Train Epoch: 49 [304/918 (33%)] Loss: 11780022.000000\n",
      "Train Epoch: 49 [320/918 (35%)] Loss: 11254003.000000\n",
      "Train Epoch: 49 [336/918 (37%)] Loss: 11386840.000000\n",
      "Train Epoch: 49 [352/918 (38%)] Loss: 15563149.000000\n",
      "Train Epoch: 49 [368/918 (40%)] Loss: 11406533.000000\n",
      "Train Epoch: 49 [384/918 (42%)] Loss: 10935872.000000\n",
      "Train Epoch: 49 [400/918 (44%)] Loss: 14381210.000000\n",
      "Train Epoch: 49 [416/918 (45%)] Loss: 17262574.000000\n",
      "Train Epoch: 49 [432/918 (47%)] Loss: 14406229.000000\n",
      "Train Epoch: 49 [448/918 (49%)] Loss: 14576391.000000\n",
      "Train Epoch: 49 [464/918 (51%)] Loss: 13909155.000000\n",
      "Train Epoch: 49 [480/918 (52%)] Loss: 14042589.000000\n",
      "Train Epoch: 49 [496/918 (54%)] Loss: 14448330.000000\n",
      "Train Epoch: 49 [512/918 (56%)] Loss: 10417706.000000\n",
      "Train Epoch: 49 [528/918 (58%)] Loss: 11708606.000000\n",
      "Train Epoch: 49 [544/918 (59%)] Loss: 18638368.000000\n",
      "Train Epoch: 49 [560/918 (61%)] Loss: 10409661.000000\n",
      "Train Epoch: 49 [576/918 (63%)] Loss: 14686995.000000\n",
      "Train Epoch: 49 [592/918 (64%)] Loss: 15386669.000000\n",
      "Train Epoch: 49 [608/918 (66%)] Loss: 24115884.000000\n",
      "Train Epoch: 49 [624/918 (68%)] Loss: 14415229.000000\n",
      "Train Epoch: 49 [640/918 (70%)] Loss: 20571798.000000\n",
      "Train Epoch: 49 [656/918 (71%)] Loss: 11979203.000000\n",
      "Train Epoch: 49 [672/918 (73%)] Loss: 13343715.000000\n",
      "Train Epoch: 49 [688/918 (75%)] Loss: 15602605.000000\n",
      "Train Epoch: 49 [704/918 (77%)] Loss: 13110966.000000\n",
      "Train Epoch: 49 [720/918 (78%)] Loss: 13012516.000000\n",
      "Train Epoch: 49 [736/918 (80%)] Loss: 14340659.000000\n",
      "Train Epoch: 49 [752/918 (82%)] Loss: 14028952.000000\n",
      "Train Epoch: 49 [768/918 (84%)] Loss: 17944836.000000\n",
      "Train Epoch: 49 [784/918 (85%)] Loss: 12551120.000000\n",
      "Train Epoch: 49 [800/918 (87%)] Loss: 14626053.000000\n",
      "Train Epoch: 49 [816/918 (89%)] Loss: 10564367.000000\n",
      "Train Epoch: 49 [832/918 (91%)] Loss: 10472295.000000\n",
      "Train Epoch: 49 [848/918 (92%)] Loss: 16353667.000000\n",
      "Train Epoch: 49 [864/918 (94%)] Loss: 15451877.000000\n",
      "Train Epoch: 49 [880/918 (96%)] Loss: 14345223.000000\n",
      "Train Epoch: 49 [896/918 (98%)] Loss: 14828359.000000\n",
      "Train Epoch: 49 [912/918 (99%)] Loss: 19610352.000000\n",
      "    epoch          : 49\n",
      "    loss           : 14235429.756521739\n",
      "    ess            : 14.000069340415623\n",
      "    log_marginal   : -14235427.634782609\n",
      "    val_loss       : 14209983.846153846\n",
      "    val_ess        : 10.924782404532799\n",
      "    val_log_marginal: -14209983.307692308\n",
      "Train Epoch: 50 [0/918 (0%)] Loss: 16484032.000000\n",
      "Train Epoch: 50 [16/918 (2%)] Loss: 12096473.000000\n",
      "Train Epoch: 50 [32/918 (3%)] Loss: 12662317.000000\n",
      "Train Epoch: 50 [48/918 (5%)] Loss: 12923550.000000\n",
      "Train Epoch: 50 [64/918 (7%)] Loss: 15844573.000000\n",
      "Train Epoch: 50 [80/918 (9%)] Loss: 10342327.000000\n",
      "Train Epoch: 50 [96/918 (10%)] Loss: 14840141.000000\n",
      "Train Epoch: 50 [112/918 (12%)] Loss: 14556880.000000\n",
      "Train Epoch: 50 [128/918 (14%)] Loss: 14645248.000000\n",
      "Train Epoch: 50 [144/918 (16%)] Loss: 12148063.000000\n",
      "Train Epoch: 50 [160/918 (17%)] Loss: 13636771.000000\n",
      "Train Epoch: 50 [176/918 (19%)] Loss: 14380323.000000\n",
      "Train Epoch: 50 [192/918 (21%)] Loss: 11827647.000000\n",
      "Train Epoch: 50 [208/918 (23%)] Loss: 17518254.000000\n",
      "Train Epoch: 50 [224/918 (24%)] Loss: 10865147.000000\n",
      "Train Epoch: 50 [240/918 (26%)] Loss: 22935470.000000\n",
      "Train Epoch: 50 [256/918 (28%)] Loss: 15199530.000000\n",
      "Train Epoch: 50 [272/918 (30%)] Loss: 14344363.000000\n",
      "Train Epoch: 50 [288/918 (31%)] Loss: 17162036.000000\n",
      "Train Epoch: 50 [304/918 (33%)] Loss: 12615628.000000\n",
      "Train Epoch: 50 [320/918 (35%)] Loss: 13062428.000000\n",
      "Train Epoch: 50 [336/918 (37%)] Loss: 13956808.000000\n",
      "Train Epoch: 50 [352/918 (38%)] Loss: 16207295.000000\n",
      "Train Epoch: 50 [368/918 (40%)] Loss: 14233221.000000\n",
      "Train Epoch: 50 [384/918 (42%)] Loss: 17942264.000000\n",
      "Train Epoch: 50 [400/918 (44%)] Loss: 11562112.000000\n",
      "Train Epoch: 50 [416/918 (45%)] Loss: 17067134.000000\n",
      "Train Epoch: 50 [432/918 (47%)] Loss: 17928710.000000\n",
      "Train Epoch: 50 [448/918 (49%)] Loss: 13548072.000000\n",
      "Train Epoch: 50 [464/918 (51%)] Loss: 16294400.000000\n",
      "Train Epoch: 50 [480/918 (52%)] Loss: 13697680.000000\n",
      "Train Epoch: 50 [496/918 (54%)] Loss: 12883495.000000\n",
      "Train Epoch: 50 [512/918 (56%)] Loss: 13495917.000000\n",
      "Train Epoch: 50 [528/918 (58%)] Loss: 11943994.000000\n",
      "Train Epoch: 50 [544/918 (59%)] Loss: 14119683.000000\n",
      "Train Epoch: 50 [560/918 (61%)] Loss: 14957591.000000\n",
      "Train Epoch: 50 [576/918 (63%)] Loss: 12647571.000000\n",
      "Train Epoch: 50 [592/918 (64%)] Loss: 15857968.000000\n",
      "Train Epoch: 50 [608/918 (66%)] Loss: 16030219.000000\n",
      "Train Epoch: 50 [624/918 (68%)] Loss: 16919038.000000\n",
      "Train Epoch: 50 [640/918 (70%)] Loss: 12815252.000000\n",
      "Train Epoch: 50 [656/918 (71%)] Loss: 13505616.000000\n",
      "Train Epoch: 50 [672/918 (73%)] Loss: 16103231.000000\n",
      "Train Epoch: 50 [688/918 (75%)] Loss: 16319808.000000\n",
      "Train Epoch: 50 [704/918 (77%)] Loss: 12113536.000000\n",
      "Train Epoch: 50 [720/918 (78%)] Loss: 12395349.000000\n",
      "Train Epoch: 50 [736/918 (80%)] Loss: 17805278.000000\n",
      "Train Epoch: 50 [752/918 (82%)] Loss: 13069604.000000\n",
      "Train Epoch: 50 [768/918 (84%)] Loss: 16079543.000000\n",
      "Train Epoch: 50 [784/918 (85%)] Loss: 18090062.000000\n",
      "Train Epoch: 50 [800/918 (87%)] Loss: 12705374.000000\n",
      "Train Epoch: 50 [816/918 (89%)] Loss: 13040408.000000\n",
      "Train Epoch: 50 [832/918 (91%)] Loss: 18577334.000000\n",
      "Train Epoch: 50 [848/918 (92%)] Loss: 12020174.000000\n",
      "Train Epoch: 50 [864/918 (94%)] Loss: 10616013.000000\n",
      "Train Epoch: 50 [880/918 (96%)] Loss: 13473799.000000\n",
      "Train Epoch: 50 [896/918 (98%)] Loss: 11296696.000000\n",
      "Train Epoch: 50 [912/918 (99%)] Loss: 17508864.000000\n",
      "    epoch          : 50\n",
      "    loss           : 14233814.104347827\n",
      "    ess            : 13.810496319895206\n",
      "    log_marginal   : -14233812.269565217\n",
      "    val_loss       : 13246324.076923076\n",
      "    val_ess        : 12.32176633981558\n",
      "    val_log_marginal: -13246323.076923076\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [0/918 (0%)] Loss: 12196274.000000\n",
      "Train Epoch: 51 [16/918 (2%)] Loss: 17676478.000000\n",
      "Train Epoch: 51 [32/918 (3%)] Loss: 11547615.000000\n",
      "Train Epoch: 51 [48/918 (5%)] Loss: 11525993.000000\n",
      "Train Epoch: 51 [64/918 (7%)] Loss: 18382080.000000\n",
      "Train Epoch: 51 [80/918 (9%)] Loss: 15908973.000000\n",
      "Train Epoch: 51 [96/918 (10%)] Loss: 14957227.000000\n",
      "Train Epoch: 51 [112/918 (12%)] Loss: 12390143.000000\n",
      "Train Epoch: 51 [128/918 (14%)] Loss: 20037028.000000\n",
      "Train Epoch: 51 [144/918 (16%)] Loss: 10071875.000000\n",
      "Train Epoch: 51 [160/918 (17%)] Loss: 13784493.000000\n",
      "Train Epoch: 51 [176/918 (19%)] Loss: 17701894.000000\n",
      "Train Epoch: 51 [192/918 (21%)] Loss: 12679267.000000\n",
      "Train Epoch: 51 [208/918 (23%)] Loss: 15706319.000000\n",
      "Train Epoch: 51 [224/918 (24%)] Loss: 14298624.000000\n",
      "Train Epoch: 51 [240/918 (26%)] Loss: 16285699.000000\n",
      "Train Epoch: 51 [256/918 (28%)] Loss: 12831620.000000\n",
      "Train Epoch: 51 [272/918 (30%)] Loss: 18458980.000000\n",
      "Train Epoch: 51 [288/918 (31%)] Loss: 14037458.000000\n",
      "Train Epoch: 51 [304/918 (33%)] Loss: 13262952.000000\n",
      "Train Epoch: 51 [320/918 (35%)] Loss: 19878262.000000\n",
      "Train Epoch: 51 [336/918 (37%)] Loss: 13081086.000000\n",
      "Train Epoch: 51 [352/918 (38%)] Loss: 11952317.000000\n",
      "Train Epoch: 51 [368/918 (40%)] Loss: 11742525.000000\n",
      "Train Epoch: 51 [384/918 (42%)] Loss: 12615654.000000\n",
      "Train Epoch: 51 [400/918 (44%)] Loss: 9651810.000000\n",
      "Train Epoch: 51 [416/918 (45%)] Loss: 14917839.000000\n",
      "Train Epoch: 51 [432/918 (47%)] Loss: 13530106.000000\n",
      "Train Epoch: 51 [448/918 (49%)] Loss: 12949304.000000\n",
      "Train Epoch: 51 [464/918 (51%)] Loss: 17602200.000000\n",
      "Train Epoch: 51 [480/918 (52%)] Loss: 12303882.000000\n",
      "Train Epoch: 51 [496/918 (54%)] Loss: 13487173.000000\n",
      "Train Epoch: 51 [512/918 (56%)] Loss: 13147238.000000\n",
      "Train Epoch: 51 [528/918 (58%)] Loss: 16083891.000000\n",
      "Train Epoch: 51 [544/918 (59%)] Loss: 20012388.000000\n",
      "Train Epoch: 51 [560/918 (61%)] Loss: 11897407.000000\n",
      "Train Epoch: 51 [576/918 (63%)] Loss: 15915234.000000\n",
      "Train Epoch: 51 [592/918 (64%)] Loss: 15163368.000000\n",
      "Train Epoch: 51 [608/918 (66%)] Loss: 11366488.000000\n",
      "Train Epoch: 51 [624/918 (68%)] Loss: 12327873.000000\n",
      "Train Epoch: 51 [640/918 (70%)] Loss: 11373178.000000\n",
      "Train Epoch: 51 [656/918 (71%)] Loss: 13305532.000000\n",
      "Train Epoch: 51 [672/918 (73%)] Loss: 14878595.000000\n",
      "Train Epoch: 51 [688/918 (75%)] Loss: 11509926.000000\n",
      "Train Epoch: 51 [704/918 (77%)] Loss: 16076935.000000\n",
      "Train Epoch: 51 [720/918 (78%)] Loss: 13960415.000000\n",
      "Train Epoch: 51 [736/918 (80%)] Loss: 22376236.000000\n",
      "Train Epoch: 51 [752/918 (82%)] Loss: 11599055.000000\n",
      "Train Epoch: 51 [768/918 (84%)] Loss: 16273869.000000\n",
      "Train Epoch: 51 [784/918 (85%)] Loss: 12118457.000000\n",
      "Train Epoch: 51 [800/918 (87%)] Loss: 13242975.000000\n",
      "Train Epoch: 51 [816/918 (89%)] Loss: 12267407.000000\n",
      "Train Epoch: 51 [832/918 (91%)] Loss: 13921389.000000\n",
      "Train Epoch: 51 [848/918 (92%)] Loss: 13066300.000000\n",
      "Train Epoch: 51 [864/918 (94%)] Loss: 12015507.000000\n",
      "Train Epoch: 51 [880/918 (96%)] Loss: 13893539.000000\n",
      "Train Epoch: 51 [896/918 (98%)] Loss: 12962899.000000\n",
      "Train Epoch: 51 [912/918 (99%)] Loss: 12766790.000000\n",
      "    epoch          : 51\n",
      "    loss           : 14062878.904347826\n",
      "    ess            : 13.615489632150402\n",
      "    log_marginal   : -14062877.539130434\n",
      "    val_loss       : 13875216.76923077\n",
      "    val_ess        : 9.883732667336098\n",
      "    val_log_marginal: -13875213.615384616\n",
      "Train Epoch: 52 [0/918 (0%)] Loss: 16416371.000000\n",
      "Train Epoch: 52 [16/918 (2%)] Loss: 20226622.000000\n",
      "Train Epoch: 52 [32/918 (3%)] Loss: 16922666.000000\n",
      "Train Epoch: 52 [48/918 (5%)] Loss: 13674317.000000\n",
      "Train Epoch: 52 [64/918 (7%)] Loss: 14884528.000000\n",
      "Train Epoch: 52 [80/918 (9%)] Loss: 11433075.000000\n",
      "Train Epoch: 52 [96/918 (10%)] Loss: 11347928.000000\n",
      "Train Epoch: 52 [112/918 (12%)] Loss: 15778029.000000\n",
      "Train Epoch: 52 [128/918 (14%)] Loss: 14144090.000000\n",
      "Train Epoch: 52 [144/918 (16%)] Loss: 12524207.000000\n",
      "Train Epoch: 52 [160/918 (17%)] Loss: 14562871.000000\n",
      "Train Epoch: 52 [176/918 (19%)] Loss: 10721763.000000\n",
      "Train Epoch: 52 [192/918 (21%)] Loss: 12363144.000000\n",
      "Train Epoch: 52 [208/918 (23%)] Loss: 13259345.000000\n",
      "Train Epoch: 52 [224/918 (24%)] Loss: 20099306.000000\n",
      "Train Epoch: 52 [240/918 (26%)] Loss: 14358752.000000\n",
      "Train Epoch: 52 [256/918 (28%)] Loss: 18620652.000000\n",
      "Train Epoch: 52 [272/918 (30%)] Loss: 19121070.000000\n",
      "Train Epoch: 52 [288/918 (31%)] Loss: 10051216.000000\n",
      "Train Epoch: 52 [304/918 (33%)] Loss: 16286858.000000\n",
      "Train Epoch: 52 [320/918 (35%)] Loss: 13003399.000000\n",
      "Train Epoch: 52 [336/918 (37%)] Loss: 8640732.000000\n",
      "Train Epoch: 52 [352/918 (38%)] Loss: 18968144.000000\n",
      "Train Epoch: 52 [368/918 (40%)] Loss: 12691243.000000\n",
      "Train Epoch: 52 [384/918 (42%)] Loss: 11511688.000000\n",
      "Train Epoch: 52 [400/918 (44%)] Loss: 12120434.000000\n",
      "Train Epoch: 52 [416/918 (45%)] Loss: 12670432.000000\n",
      "Train Epoch: 52 [432/918 (47%)] Loss: 18500344.000000\n",
      "Train Epoch: 52 [448/918 (49%)] Loss: 10047800.000000\n",
      "Train Epoch: 52 [464/918 (51%)] Loss: 18446246.000000\n",
      "Train Epoch: 52 [480/918 (52%)] Loss: 13517095.000000\n",
      "Train Epoch: 52 [496/918 (54%)] Loss: 11592380.000000\n",
      "Train Epoch: 52 [512/918 (56%)] Loss: 15197602.000000\n",
      "Train Epoch: 52 [528/918 (58%)] Loss: 10579981.000000\n",
      "Train Epoch: 52 [544/918 (59%)] Loss: 9295527.000000\n",
      "Train Epoch: 52 [560/918 (61%)] Loss: 15871469.000000\n",
      "Train Epoch: 52 [576/918 (63%)] Loss: 13050229.000000\n",
      "Train Epoch: 52 [592/918 (64%)] Loss: 14481776.000000\n",
      "Train Epoch: 52 [608/918 (66%)] Loss: 10939074.000000\n",
      "Train Epoch: 52 [624/918 (68%)] Loss: 17095012.000000\n",
      "Train Epoch: 52 [640/918 (70%)] Loss: 11237600.000000\n",
      "Train Epoch: 52 [656/918 (71%)] Loss: 17537264.000000\n",
      "Train Epoch: 52 [672/918 (73%)] Loss: 14060795.000000\n",
      "Train Epoch: 52 [688/918 (75%)] Loss: 14470533.000000\n",
      "Train Epoch: 52 [704/918 (77%)] Loss: 10789992.000000\n",
      "Train Epoch: 52 [720/918 (78%)] Loss: 18231024.000000\n",
      "Train Epoch: 52 [736/918 (80%)] Loss: 13228693.000000\n",
      "Train Epoch: 52 [752/918 (82%)] Loss: 10375045.000000\n",
      "Train Epoch: 52 [768/918 (84%)] Loss: 16431256.000000\n",
      "Train Epoch: 52 [784/918 (85%)] Loss: 11417944.000000\n",
      "Train Epoch: 52 [800/918 (87%)] Loss: 12644337.000000\n",
      "Train Epoch: 52 [816/918 (89%)] Loss: 18609894.000000\n",
      "Train Epoch: 52 [832/918 (91%)] Loss: 9523559.000000\n",
      "Train Epoch: 52 [848/918 (92%)] Loss: 17410328.000000\n",
      "Train Epoch: 52 [864/918 (94%)] Loss: 15027927.000000\n",
      "Train Epoch: 52 [880/918 (96%)] Loss: 14462960.000000\n",
      "Train Epoch: 52 [896/918 (98%)] Loss: 15005859.000000\n",
      "Train Epoch: 52 [912/918 (99%)] Loss: 12697421.000000\n",
      "    epoch          : 52\n",
      "    loss           : 13964537.060869565\n",
      "    ess            : 12.759026278620182\n",
      "    log_marginal   : -13964535.486956522\n",
      "    val_loss       : 13707027.384615384\n",
      "    val_ess        : 10.235767107743483\n",
      "    val_log_marginal: -13707026.076923076\n",
      "Train Epoch: 53 [0/918 (0%)] Loss: 13088367.000000\n",
      "Train Epoch: 53 [16/918 (2%)] Loss: 11467412.000000\n",
      "Train Epoch: 53 [32/918 (3%)] Loss: 11974883.000000\n",
      "Train Epoch: 53 [48/918 (5%)] Loss: 14573760.000000\n",
      "Train Epoch: 53 [64/918 (7%)] Loss: 12332088.000000\n",
      "Train Epoch: 53 [80/918 (9%)] Loss: 13458506.000000\n",
      "Train Epoch: 53 [96/918 (10%)] Loss: 19688528.000000\n",
      "Train Epoch: 53 [112/918 (12%)] Loss: 11952347.000000\n",
      "Train Epoch: 53 [128/918 (14%)] Loss: 10313915.000000\n",
      "Train Epoch: 53 [144/918 (16%)] Loss: 14398071.000000\n",
      "Train Epoch: 53 [160/918 (17%)] Loss: 12420495.000000\n",
      "Train Epoch: 53 [176/918 (19%)] Loss: 13900957.000000\n",
      "Train Epoch: 53 [192/918 (21%)] Loss: 15787200.000000\n",
      "Train Epoch: 53 [208/918 (23%)] Loss: 18132602.000000\n",
      "Train Epoch: 53 [224/918 (24%)] Loss: 13892845.000000\n",
      "Train Epoch: 53 [240/918 (26%)] Loss: 14682442.000000\n",
      "Train Epoch: 53 [256/918 (28%)] Loss: 18634536.000000\n",
      "Train Epoch: 53 [272/918 (30%)] Loss: 11390895.000000\n",
      "Train Epoch: 53 [288/918 (31%)] Loss: 15674664.000000\n",
      "Train Epoch: 53 [304/918 (33%)] Loss: 10423208.000000\n",
      "Train Epoch: 53 [320/918 (35%)] Loss: 18447400.000000\n",
      "Train Epoch: 53 [336/918 (37%)] Loss: 10691175.000000\n",
      "Train Epoch: 53 [352/918 (38%)] Loss: 10712380.000000\n",
      "Train Epoch: 53 [368/918 (40%)] Loss: 11077493.000000\n",
      "Train Epoch: 53 [384/918 (42%)] Loss: 16784750.000000\n",
      "Train Epoch: 53 [400/918 (44%)] Loss: 16979040.000000\n",
      "Train Epoch: 53 [416/918 (45%)] Loss: 15480943.000000\n",
      "Train Epoch: 53 [432/918 (47%)] Loss: 10384827.000000\n",
      "Train Epoch: 53 [448/918 (49%)] Loss: 13776042.000000\n",
      "Train Epoch: 53 [464/918 (51%)] Loss: 13010504.000000\n",
      "Train Epoch: 53 [480/918 (52%)] Loss: 14648845.000000\n",
      "Train Epoch: 53 [496/918 (54%)] Loss: 11067776.000000\n",
      "Train Epoch: 53 [512/918 (56%)] Loss: 21139366.000000\n",
      "Train Epoch: 53 [528/918 (58%)] Loss: 13529997.000000\n",
      "Train Epoch: 53 [544/918 (59%)] Loss: 12478887.000000\n",
      "Train Epoch: 53 [560/918 (61%)] Loss: 17806718.000000\n",
      "Train Epoch: 53 [576/918 (63%)] Loss: 17424980.000000\n",
      "Train Epoch: 53 [592/918 (64%)] Loss: 19164106.000000\n",
      "Train Epoch: 53 [608/918 (66%)] Loss: 13307885.000000\n",
      "Train Epoch: 53 [624/918 (68%)] Loss: 11435603.000000\n",
      "Train Epoch: 53 [640/918 (70%)] Loss: 15342088.000000\n",
      "Train Epoch: 53 [656/918 (71%)] Loss: 12720570.000000\n",
      "Train Epoch: 53 [672/918 (73%)] Loss: 20770790.000000\n",
      "Train Epoch: 53 [688/918 (75%)] Loss: 14143554.000000\n",
      "Train Epoch: 53 [704/918 (77%)] Loss: 14422752.000000\n",
      "Train Epoch: 53 [720/918 (78%)] Loss: 12561640.000000\n",
      "Train Epoch: 53 [736/918 (80%)] Loss: 12215260.000000\n",
      "Train Epoch: 53 [752/918 (82%)] Loss: 13879274.000000\n",
      "Train Epoch: 53 [768/918 (84%)] Loss: 14524157.000000\n",
      "Train Epoch: 53 [784/918 (85%)] Loss: 13360799.000000\n",
      "Train Epoch: 53 [800/918 (87%)] Loss: 10934929.000000\n",
      "Train Epoch: 53 [816/918 (89%)] Loss: 12931492.000000\n",
      "Train Epoch: 53 [832/918 (91%)] Loss: 9476236.000000\n",
      "Train Epoch: 53 [848/918 (92%)] Loss: 13612408.000000\n",
      "Train Epoch: 53 [864/918 (94%)] Loss: 13977149.000000\n",
      "Train Epoch: 53 [880/918 (96%)] Loss: 14830199.000000\n",
      "Train Epoch: 53 [896/918 (98%)] Loss: 16447434.000000\n",
      "Train Epoch: 53 [912/918 (99%)] Loss: 12428157.000000\n",
      "    epoch          : 53\n",
      "    loss           : 13895345.808695652\n",
      "    ess            : 13.565297148538672\n",
      "    log_marginal   : -13895344.286956523\n",
      "    val_loss       : 13333970.384615384\n",
      "    val_ess        : 13.213111657362719\n",
      "    val_log_marginal: -13333969.846153846\n",
      "Train Epoch: 54 [0/918 (0%)] Loss: 11996262.000000\n",
      "Train Epoch: 54 [16/918 (2%)] Loss: 15855923.000000\n",
      "Train Epoch: 54 [32/918 (3%)] Loss: 15855575.000000\n",
      "Train Epoch: 54 [48/918 (5%)] Loss: 14581440.000000\n",
      "Train Epoch: 54 [64/918 (7%)] Loss: 10726919.000000\n",
      "Train Epoch: 54 [80/918 (9%)] Loss: 10029360.000000\n",
      "Train Epoch: 54 [96/918 (10%)] Loss: 11282784.000000\n",
      "Train Epoch: 54 [112/918 (12%)] Loss: 13615378.000000\n",
      "Train Epoch: 54 [128/918 (14%)] Loss: 12541148.000000\n",
      "Train Epoch: 54 [144/918 (16%)] Loss: 17171302.000000\n",
      "Train Epoch: 54 [160/918 (17%)] Loss: 15076224.000000\n",
      "Train Epoch: 54 [176/918 (19%)] Loss: 9413978.000000\n",
      "Train Epoch: 54 [192/918 (21%)] Loss: 11957512.000000\n",
      "Train Epoch: 54 [208/918 (23%)] Loss: 10890256.000000\n",
      "Train Epoch: 54 [224/918 (24%)] Loss: 16772459.000000\n",
      "Train Epoch: 54 [240/918 (26%)] Loss: 13743101.000000\n",
      "Train Epoch: 54 [256/918 (28%)] Loss: 12309252.000000\n",
      "Train Epoch: 54 [272/918 (30%)] Loss: 12905047.000000\n",
      "Train Epoch: 54 [288/918 (31%)] Loss: 12252099.000000\n",
      "Train Epoch: 54 [304/918 (33%)] Loss: 10079204.000000\n",
      "Train Epoch: 54 [320/918 (35%)] Loss: 12169694.000000\n",
      "Train Epoch: 54 [336/918 (37%)] Loss: 12700748.000000\n",
      "Train Epoch: 54 [352/918 (38%)] Loss: 12343839.000000\n",
      "Train Epoch: 54 [368/918 (40%)] Loss: 12113383.000000\n",
      "Train Epoch: 54 [384/918 (42%)] Loss: 10713903.000000\n",
      "Train Epoch: 54 [400/918 (44%)] Loss: 20368176.000000\n",
      "Train Epoch: 54 [416/918 (45%)] Loss: 12885180.000000\n",
      "Train Epoch: 54 [432/918 (47%)] Loss: 17463770.000000\n",
      "Train Epoch: 54 [448/918 (49%)] Loss: 12676670.000000\n",
      "Train Epoch: 54 [464/918 (51%)] Loss: 11983414.000000\n",
      "Train Epoch: 54 [480/918 (52%)] Loss: 21793830.000000\n",
      "Train Epoch: 54 [496/918 (54%)] Loss: 11077693.000000\n",
      "Train Epoch: 54 [512/918 (56%)] Loss: 11535103.000000\n",
      "Train Epoch: 54 [528/918 (58%)] Loss: 13919171.000000\n",
      "Train Epoch: 54 [544/918 (59%)] Loss: 13258000.000000\n",
      "Train Epoch: 54 [560/918 (61%)] Loss: 12752036.000000\n",
      "Train Epoch: 54 [576/918 (63%)] Loss: 11933744.000000\n",
      "Train Epoch: 54 [592/918 (64%)] Loss: 14902960.000000\n",
      "Train Epoch: 54 [608/918 (66%)] Loss: 11021063.000000\n",
      "Train Epoch: 54 [624/918 (68%)] Loss: 12763069.000000\n",
      "Train Epoch: 54 [640/918 (70%)] Loss: 16985088.000000\n",
      "Train Epoch: 54 [656/918 (71%)] Loss: 10066047.000000\n",
      "Train Epoch: 54 [672/918 (73%)] Loss: 16833506.000000\n",
      "Train Epoch: 54 [688/918 (75%)] Loss: 14205600.000000\n",
      "Train Epoch: 54 [704/918 (77%)] Loss: 16135643.000000\n",
      "Train Epoch: 54 [720/918 (78%)] Loss: 17959926.000000\n",
      "Train Epoch: 54 [736/918 (80%)] Loss: 12045448.000000\n",
      "Train Epoch: 54 [752/918 (82%)] Loss: 12945694.000000\n",
      "Train Epoch: 54 [768/918 (84%)] Loss: 17469552.000000\n",
      "Train Epoch: 54 [784/918 (85%)] Loss: 13030192.000000\n",
      "Train Epoch: 54 [800/918 (87%)] Loss: 11251888.000000\n",
      "Train Epoch: 54 [816/918 (89%)] Loss: 15978063.000000\n",
      "Train Epoch: 54 [832/918 (91%)] Loss: 13029979.000000\n",
      "Train Epoch: 54 [848/918 (92%)] Loss: 19177892.000000\n",
      "Train Epoch: 54 [864/918 (94%)] Loss: 18491728.000000\n",
      "Train Epoch: 54 [880/918 (96%)] Loss: 10835871.000000\n",
      "Train Epoch: 54 [896/918 (98%)] Loss: 17908890.000000\n",
      "Train Epoch: 54 [912/918 (99%)] Loss: 13317252.000000\n",
      "    epoch          : 54\n",
      "    loss           : 14004243.947826087\n",
      "    ess            : 12.761813451932824\n",
      "    log_marginal   : -14004242.817391304\n",
      "    val_loss       : 13664523.076923076\n",
      "    val_ess        : 11.238474699167105\n",
      "    val_log_marginal: -13664521.615384616\n",
      "Train Epoch: 55 [0/918 (0%)] Loss: 12672507.000000\n",
      "Train Epoch: 55 [16/918 (2%)] Loss: 11039695.000000\n",
      "Train Epoch: 55 [32/918 (3%)] Loss: 15110099.000000\n",
      "Train Epoch: 55 [48/918 (5%)] Loss: 20692952.000000\n",
      "Train Epoch: 55 [64/918 (7%)] Loss: 14446602.000000\n",
      "Train Epoch: 55 [80/918 (9%)] Loss: 16002795.000000\n",
      "Train Epoch: 55 [96/918 (10%)] Loss: 14587031.000000\n",
      "Train Epoch: 55 [112/918 (12%)] Loss: 11815229.000000\n",
      "Train Epoch: 55 [128/918 (14%)] Loss: 11038711.000000\n",
      "Train Epoch: 55 [144/918 (16%)] Loss: 16272615.000000\n",
      "Train Epoch: 55 [160/918 (17%)] Loss: 12446768.000000\n",
      "Train Epoch: 55 [176/918 (19%)] Loss: 15452048.000000\n",
      "Train Epoch: 55 [192/918 (21%)] Loss: 10415431.000000\n",
      "Train Epoch: 55 [208/918 (23%)] Loss: 14302138.000000\n",
      "Train Epoch: 55 [224/918 (24%)] Loss: 19790320.000000\n",
      "Train Epoch: 55 [240/918 (26%)] Loss: 9997247.000000\n",
      "Train Epoch: 55 [256/918 (28%)] Loss: 14855903.000000\n",
      "Train Epoch: 55 [272/918 (30%)] Loss: 11449923.000000\n",
      "Train Epoch: 55 [288/918 (31%)] Loss: 10639128.000000\n",
      "Train Epoch: 55 [304/918 (33%)] Loss: 14662973.000000\n",
      "Train Epoch: 55 [320/918 (35%)] Loss: 14854535.000000\n",
      "Train Epoch: 55 [336/918 (37%)] Loss: 16430723.000000\n",
      "Train Epoch: 55 [352/918 (38%)] Loss: 14378339.000000\n",
      "Train Epoch: 55 [368/918 (40%)] Loss: 14630408.000000\n",
      "Train Epoch: 55 [384/918 (42%)] Loss: 12749146.000000\n",
      "Train Epoch: 55 [400/918 (44%)] Loss: 12587783.000000\n",
      "Train Epoch: 55 [416/918 (45%)] Loss: 12640990.000000\n",
      "Train Epoch: 55 [432/918 (47%)] Loss: 10579475.000000\n",
      "Train Epoch: 55 [448/918 (49%)] Loss: 10007471.000000\n",
      "Train Epoch: 55 [464/918 (51%)] Loss: 11857813.000000\n",
      "Train Epoch: 55 [480/918 (52%)] Loss: 12340653.000000\n",
      "Train Epoch: 55 [496/918 (54%)] Loss: 13004064.000000\n",
      "Train Epoch: 55 [512/918 (56%)] Loss: 13718951.000000\n",
      "Train Epoch: 55 [528/918 (58%)] Loss: 12289709.000000\n",
      "Train Epoch: 55 [544/918 (59%)] Loss: 14052099.000000\n",
      "Train Epoch: 55 [560/918 (61%)] Loss: 15958759.000000\n",
      "Train Epoch: 55 [576/918 (63%)] Loss: 13768786.000000\n",
      "Train Epoch: 55 [592/918 (64%)] Loss: 13122131.000000\n",
      "Train Epoch: 55 [608/918 (66%)] Loss: 12130292.000000\n",
      "Train Epoch: 55 [624/918 (68%)] Loss: 16012259.000000\n",
      "Train Epoch: 55 [640/918 (70%)] Loss: 15030954.000000\n",
      "Train Epoch: 55 [656/918 (71%)] Loss: 10695288.000000\n",
      "Train Epoch: 55 [672/918 (73%)] Loss: 15042893.000000\n",
      "Train Epoch: 55 [688/918 (75%)] Loss: 10588167.000000\n",
      "Train Epoch: 55 [704/918 (77%)] Loss: 14680992.000000\n",
      "Train Epoch: 55 [720/918 (78%)] Loss: 15066643.000000\n",
      "Train Epoch: 55 [736/918 (80%)] Loss: 14578087.000000\n",
      "Train Epoch: 55 [752/918 (82%)] Loss: 16213651.000000\n",
      "Train Epoch: 55 [768/918 (84%)] Loss: 14346855.000000\n",
      "Train Epoch: 55 [784/918 (85%)] Loss: 15395847.000000\n",
      "Train Epoch: 55 [800/918 (87%)] Loss: 14036899.000000\n",
      "Train Epoch: 55 [816/918 (89%)] Loss: 13160991.000000\n",
      "Train Epoch: 55 [832/918 (91%)] Loss: 11066491.000000\n",
      "Train Epoch: 55 [848/918 (92%)] Loss: 15120951.000000\n",
      "Train Epoch: 55 [864/918 (94%)] Loss: 9667635.000000\n",
      "Train Epoch: 55 [880/918 (96%)] Loss: 12260921.000000\n",
      "Train Epoch: 55 [896/918 (98%)] Loss: 17223232.000000\n",
      "Train Epoch: 55 [912/918 (99%)] Loss: 12605167.000000\n",
      "    epoch          : 55\n",
      "    loss           : 13983299.4\n",
      "    ess            : 13.288819930864417\n",
      "    log_marginal   : -13983298.043478262\n",
      "    val_loss       : 12977855.461538462\n",
      "    val_ess        : 10.697876875217144\n",
      "    val_log_marginal: -12977853.23076923\n",
      "Train Epoch: 56 [0/918 (0%)] Loss: 11566951.000000\n",
      "Train Epoch: 56 [16/918 (2%)] Loss: 10754759.000000\n",
      "Train Epoch: 56 [32/918 (3%)] Loss: 11248811.000000\n",
      "Train Epoch: 56 [48/918 (5%)] Loss: 12840475.000000\n",
      "Train Epoch: 56 [64/918 (7%)] Loss: 15466525.000000\n",
      "Train Epoch: 56 [80/918 (9%)] Loss: 11300179.000000\n",
      "Train Epoch: 56 [96/918 (10%)] Loss: 9597488.000000\n",
      "Train Epoch: 56 [112/918 (12%)] Loss: 11675020.000000\n",
      "Train Epoch: 56 [128/918 (14%)] Loss: 15425504.000000\n",
      "Train Epoch: 56 [144/918 (16%)] Loss: 14644071.000000\n",
      "Train Epoch: 56 [160/918 (17%)] Loss: 18035518.000000\n",
      "Train Epoch: 56 [176/918 (19%)] Loss: 12631652.000000\n",
      "Train Epoch: 56 [192/918 (21%)] Loss: 17315166.000000\n",
      "Train Epoch: 56 [208/918 (23%)] Loss: 14207517.000000\n",
      "Train Epoch: 56 [224/918 (24%)] Loss: 13335426.000000\n",
      "Train Epoch: 56 [240/918 (26%)] Loss: 10487102.000000\n",
      "Train Epoch: 56 [256/918 (28%)] Loss: 12698842.000000\n",
      "Train Epoch: 56 [272/918 (30%)] Loss: 18622920.000000\n",
      "Train Epoch: 56 [288/918 (31%)] Loss: 20484446.000000\n",
      "Train Epoch: 56 [304/918 (33%)] Loss: 13044611.000000\n",
      "Train Epoch: 56 [320/918 (35%)] Loss: 11300270.000000\n",
      "Train Epoch: 56 [336/918 (37%)] Loss: 14898683.000000\n",
      "Train Epoch: 56 [352/918 (38%)] Loss: 12288482.000000\n",
      "Train Epoch: 56 [368/918 (40%)] Loss: 18141768.000000\n",
      "Train Epoch: 56 [384/918 (42%)] Loss: 14947786.000000\n",
      "Train Epoch: 56 [400/918 (44%)] Loss: 15666992.000000\n",
      "Train Epoch: 56 [416/918 (45%)] Loss: 11830264.000000\n",
      "Train Epoch: 56 [432/918 (47%)] Loss: 12173042.000000\n",
      "Train Epoch: 56 [448/918 (49%)] Loss: 13026794.000000\n",
      "Train Epoch: 56 [464/918 (51%)] Loss: 15920999.000000\n",
      "Train Epoch: 56 [480/918 (52%)] Loss: 15027850.000000\n",
      "Train Epoch: 56 [496/918 (54%)] Loss: 12550546.000000\n",
      "Train Epoch: 56 [512/918 (56%)] Loss: 17279944.000000\n",
      "Train Epoch: 56 [528/918 (58%)] Loss: 12005590.000000\n",
      "Train Epoch: 56 [544/918 (59%)] Loss: 16002330.000000\n",
      "Train Epoch: 56 [560/918 (61%)] Loss: 16049907.000000\n",
      "Train Epoch: 56 [576/918 (63%)] Loss: 16797492.000000\n",
      "Train Epoch: 56 [592/918 (64%)] Loss: 11708173.000000\n",
      "Train Epoch: 56 [608/918 (66%)] Loss: 14662207.000000\n",
      "Train Epoch: 56 [624/918 (68%)] Loss: 14840423.000000\n",
      "Train Epoch: 56 [640/918 (70%)] Loss: 12833138.000000\n",
      "Train Epoch: 56 [656/918 (71%)] Loss: 11884176.000000\n",
      "Train Epoch: 56 [672/918 (73%)] Loss: 15680747.000000\n",
      "Train Epoch: 56 [688/918 (75%)] Loss: 14353210.000000\n",
      "Train Epoch: 56 [704/918 (77%)] Loss: 11353412.000000\n",
      "Train Epoch: 56 [720/918 (78%)] Loss: 16007058.000000\n",
      "Train Epoch: 56 [736/918 (80%)] Loss: 11936978.000000\n",
      "Train Epoch: 56 [752/918 (82%)] Loss: 12851848.000000\n",
      "Train Epoch: 56 [768/918 (84%)] Loss: 12123789.000000\n",
      "Train Epoch: 56 [784/918 (85%)] Loss: 10893564.000000\n",
      "Train Epoch: 56 [800/918 (87%)] Loss: 9358933.000000\n",
      "Train Epoch: 56 [816/918 (89%)] Loss: 17427924.000000\n",
      "Train Epoch: 56 [832/918 (91%)] Loss: 15841866.000000\n",
      "Train Epoch: 56 [848/918 (92%)] Loss: 14064147.000000\n",
      "Train Epoch: 56 [864/918 (94%)] Loss: 11412620.000000\n",
      "Train Epoch: 56 [880/918 (96%)] Loss: 15866512.000000\n",
      "Train Epoch: 56 [896/918 (98%)] Loss: 14283909.000000\n",
      "Train Epoch: 56 [912/918 (99%)] Loss: 13075574.000000\n",
      "    epoch          : 56\n",
      "    loss           : 13988621.15652174\n",
      "    ess            : 13.10657990704412\n",
      "    log_marginal   : -13988619.87826087\n",
      "    val_loss       : 13006276.846153846\n",
      "    val_ess        : 11.725452276376577\n",
      "    val_log_marginal: -13006275.76923077\n",
      "Train Epoch: 57 [0/918 (0%)] Loss: 13302583.000000\n",
      "Train Epoch: 57 [16/918 (2%)] Loss: 13914435.000000\n",
      "Train Epoch: 57 [32/918 (3%)] Loss: 15710269.000000\n",
      "Train Epoch: 57 [48/918 (5%)] Loss: 13953919.000000\n",
      "Train Epoch: 57 [64/918 (7%)] Loss: 16553709.000000\n",
      "Train Epoch: 57 [80/918 (9%)] Loss: 13676768.000000\n",
      "Train Epoch: 57 [96/918 (10%)] Loss: 13082996.000000\n",
      "Train Epoch: 57 [112/918 (12%)] Loss: 16894652.000000\n",
      "Train Epoch: 57 [128/918 (14%)] Loss: 12063595.000000\n",
      "Train Epoch: 57 [144/918 (16%)] Loss: 16305200.000000\n",
      "Train Epoch: 57 [160/918 (17%)] Loss: 13333592.000000\n",
      "Train Epoch: 57 [176/918 (19%)] Loss: 18188938.000000\n",
      "Train Epoch: 57 [192/918 (21%)] Loss: 14509955.000000\n",
      "Train Epoch: 57 [208/918 (23%)] Loss: 11700127.000000\n",
      "Train Epoch: 57 [224/918 (24%)] Loss: 14456344.000000\n",
      "Train Epoch: 57 [240/918 (26%)] Loss: 13337893.000000\n",
      "Train Epoch: 57 [256/918 (28%)] Loss: 13600010.000000\n",
      "Train Epoch: 57 [272/918 (30%)] Loss: 12735799.000000\n",
      "Train Epoch: 57 [288/918 (31%)] Loss: 11316592.000000\n",
      "Train Epoch: 57 [304/918 (33%)] Loss: 12884677.000000\n",
      "Train Epoch: 57 [320/918 (35%)] Loss: 15331691.000000\n",
      "Train Epoch: 57 [336/918 (37%)] Loss: 15000755.000000\n",
      "Train Epoch: 57 [352/918 (38%)] Loss: 14926272.000000\n",
      "Train Epoch: 57 [368/918 (40%)] Loss: 11906567.000000\n",
      "Train Epoch: 57 [384/918 (42%)] Loss: 14362061.000000\n",
      "Train Epoch: 57 [400/918 (44%)] Loss: 12358360.000000\n",
      "Train Epoch: 57 [416/918 (45%)] Loss: 13471853.000000\n",
      "Train Epoch: 57 [432/918 (47%)] Loss: 19149478.000000\n",
      "Train Epoch: 57 [448/918 (49%)] Loss: 12723725.000000\n",
      "Train Epoch: 57 [464/918 (51%)] Loss: 11307899.000000\n",
      "Train Epoch: 57 [480/918 (52%)] Loss: 11789463.000000\n",
      "Train Epoch: 57 [496/918 (54%)] Loss: 17722582.000000\n",
      "Train Epoch: 57 [512/918 (56%)] Loss: 18820292.000000\n",
      "Train Epoch: 57 [528/918 (58%)] Loss: 17001654.000000\n",
      "Train Epoch: 57 [544/918 (59%)] Loss: 10556025.000000\n",
      "Train Epoch: 57 [560/918 (61%)] Loss: 13261483.000000\n",
      "Train Epoch: 57 [576/918 (63%)] Loss: 12507301.000000\n",
      "Train Epoch: 57 [592/918 (64%)] Loss: 12328549.000000\n",
      "Train Epoch: 57 [608/918 (66%)] Loss: 12425214.000000\n",
      "Train Epoch: 57 [624/918 (68%)] Loss: 13734711.000000\n",
      "Train Epoch: 57 [640/918 (70%)] Loss: 11136202.000000\n",
      "Train Epoch: 57 [656/918 (71%)] Loss: 11867253.000000\n",
      "Train Epoch: 57 [672/918 (73%)] Loss: 23132144.000000\n",
      "Train Epoch: 57 [688/918 (75%)] Loss: 16863192.000000\n",
      "Train Epoch: 57 [704/918 (77%)] Loss: 14523613.000000\n",
      "Train Epoch: 57 [720/918 (78%)] Loss: 22141364.000000\n",
      "Train Epoch: 57 [736/918 (80%)] Loss: 13520567.000000\n",
      "Train Epoch: 57 [752/918 (82%)] Loss: 10427058.000000\n",
      "Train Epoch: 57 [768/918 (84%)] Loss: 14236701.000000\n",
      "Train Epoch: 57 [784/918 (85%)] Loss: 14162259.000000\n",
      "Train Epoch: 57 [800/918 (87%)] Loss: 11347299.000000\n",
      "Train Epoch: 57 [816/918 (89%)] Loss: 12077018.000000\n",
      "Train Epoch: 57 [832/918 (91%)] Loss: 13064539.000000\n",
      "Train Epoch: 57 [848/918 (92%)] Loss: 18334618.000000\n",
      "Train Epoch: 57 [864/918 (94%)] Loss: 14507887.000000\n",
      "Train Epoch: 57 [880/918 (96%)] Loss: 15217522.000000\n",
      "Train Epoch: 57 [896/918 (98%)] Loss: 11382569.000000\n",
      "Train Epoch: 57 [912/918 (99%)] Loss: 12528552.000000\n",
      "    epoch          : 57\n",
      "    loss           : 13973893.113043478\n",
      "    ess            : 13.146217746319978\n",
      "    log_marginal   : -13973891.313043479\n",
      "    val_loss       : 12700103.384615384\n",
      "    val_ess        : 12.719355179713322\n",
      "    val_log_marginal: -12700101.76923077\n",
      "Train Epoch: 58 [0/918 (0%)] Loss: 12226210.000000\n",
      "Train Epoch: 58 [16/918 (2%)] Loss: 11447291.000000\n",
      "Train Epoch: 58 [32/918 (3%)] Loss: 16269499.000000\n",
      "Train Epoch: 58 [48/918 (5%)] Loss: 8660847.000000\n",
      "Train Epoch: 58 [64/918 (7%)] Loss: 15050994.000000\n",
      "Train Epoch: 58 [80/918 (9%)] Loss: 15115192.000000\n",
      "Train Epoch: 58 [96/918 (10%)] Loss: 12217199.000000\n",
      "Train Epoch: 58 [112/918 (12%)] Loss: 16150207.000000\n",
      "Train Epoch: 58 [128/918 (14%)] Loss: 14955895.000000\n",
      "Train Epoch: 58 [144/918 (16%)] Loss: 9113477.000000\n",
      "Train Epoch: 58 [160/918 (17%)] Loss: 12294648.000000\n",
      "Train Epoch: 58 [176/918 (19%)] Loss: 13465083.000000\n",
      "Train Epoch: 58 [192/918 (21%)] Loss: 11819649.000000\n",
      "Train Epoch: 58 [208/918 (23%)] Loss: 11773625.000000\n",
      "Train Epoch: 58 [224/918 (24%)] Loss: 19100676.000000\n",
      "Train Epoch: 58 [240/918 (26%)] Loss: 15359856.000000\n",
      "Train Epoch: 58 [256/918 (28%)] Loss: 12609536.000000\n",
      "Train Epoch: 58 [272/918 (30%)] Loss: 10391237.000000\n",
      "Train Epoch: 58 [288/918 (31%)] Loss: 11548769.000000\n",
      "Train Epoch: 58 [304/918 (33%)] Loss: 16388821.000000\n",
      "Train Epoch: 58 [320/918 (35%)] Loss: 12757416.000000\n",
      "Train Epoch: 58 [336/918 (37%)] Loss: 11802470.000000\n",
      "Train Epoch: 58 [352/918 (38%)] Loss: 13025519.000000\n",
      "Train Epoch: 58 [368/918 (40%)] Loss: 13674503.000000\n",
      "Train Epoch: 58 [384/918 (42%)] Loss: 16419757.000000\n",
      "Train Epoch: 58 [400/918 (44%)] Loss: 11299132.000000\n",
      "Train Epoch: 58 [416/918 (45%)] Loss: 11977808.000000\n",
      "Train Epoch: 58 [432/918 (47%)] Loss: 12724549.000000\n",
      "Train Epoch: 58 [448/918 (49%)] Loss: 18055098.000000\n",
      "Train Epoch: 58 [464/918 (51%)] Loss: 14220933.000000\n",
      "Train Epoch: 58 [480/918 (52%)] Loss: 15609573.000000\n",
      "Train Epoch: 58 [496/918 (54%)] Loss: 15346581.000000\n",
      "Train Epoch: 58 [512/918 (56%)] Loss: 18029572.000000\n",
      "Train Epoch: 58 [528/918 (58%)] Loss: 19479638.000000\n",
      "Train Epoch: 58 [544/918 (59%)] Loss: 11285824.000000\n",
      "Train Epoch: 58 [560/918 (61%)] Loss: 16306915.000000\n",
      "Train Epoch: 58 [576/918 (63%)] Loss: 10509323.000000\n",
      "Train Epoch: 58 [592/918 (64%)] Loss: 10907723.000000\n",
      "Train Epoch: 58 [608/918 (66%)] Loss: 12364721.000000\n",
      "Train Epoch: 58 [624/918 (68%)] Loss: 13818250.000000\n",
      "Train Epoch: 58 [640/918 (70%)] Loss: 12621585.000000\n",
      "Train Epoch: 58 [656/918 (71%)] Loss: 11618766.000000\n",
      "Train Epoch: 58 [672/918 (73%)] Loss: 15618234.000000\n",
      "Train Epoch: 58 [688/918 (75%)] Loss: 17635152.000000\n",
      "Train Epoch: 58 [704/918 (77%)] Loss: 14919341.000000\n",
      "Train Epoch: 58 [720/918 (78%)] Loss: 15845519.000000\n",
      "Train Epoch: 58 [736/918 (80%)] Loss: 10830898.000000\n",
      "Train Epoch: 58 [752/918 (82%)] Loss: 12824615.000000\n",
      "Train Epoch: 58 [768/918 (84%)] Loss: 15443970.000000\n",
      "Train Epoch: 58 [784/918 (85%)] Loss: 14777226.000000\n",
      "Train Epoch: 58 [800/918 (87%)] Loss: 13622563.000000\n",
      "Train Epoch: 58 [816/918 (89%)] Loss: 13957392.000000\n",
      "Train Epoch: 58 [832/918 (91%)] Loss: 9391370.000000\n",
      "Train Epoch: 58 [848/918 (92%)] Loss: 14124279.000000\n",
      "Train Epoch: 58 [864/918 (94%)] Loss: 13668754.000000\n",
      "Train Epoch: 58 [880/918 (96%)] Loss: 7946750.500000\n",
      "Train Epoch: 58 [896/918 (98%)] Loss: 12220624.000000\n",
      "Train Epoch: 58 [912/918 (99%)] Loss: 8081622.000000\n",
      "    epoch          : 58\n",
      "    loss           : 13836032.334782608\n",
      "    ess            : 14.196067001508629\n",
      "    log_marginal   : -13836030.765217392\n",
      "    val_loss       : 13599622.23076923\n",
      "    val_ess        : 12.437586050767164\n",
      "    val_log_marginal: -13599621.384615384\n",
      "Train Epoch: 59 [0/918 (0%)] Loss: 11906392.000000\n",
      "Train Epoch: 59 [16/918 (2%)] Loss: 13450227.000000\n",
      "Train Epoch: 59 [32/918 (3%)] Loss: 11223263.000000\n",
      "Train Epoch: 59 [48/918 (5%)] Loss: 18667752.000000\n",
      "Train Epoch: 59 [64/918 (7%)] Loss: 16714858.000000\n",
      "Train Epoch: 59 [80/918 (9%)] Loss: 10164251.000000\n",
      "Train Epoch: 59 [96/918 (10%)] Loss: 17580170.000000\n",
      "Train Epoch: 59 [112/918 (12%)] Loss: 13910223.000000\n",
      "Train Epoch: 59 [128/918 (14%)] Loss: 16545365.000000\n",
      "Train Epoch: 59 [144/918 (16%)] Loss: 11418819.000000\n",
      "Train Epoch: 59 [160/918 (17%)] Loss: 14825131.000000\n",
      "Train Epoch: 59 [176/918 (19%)] Loss: 11701959.000000\n",
      "Train Epoch: 59 [192/918 (21%)] Loss: 10751410.000000\n",
      "Train Epoch: 59 [208/918 (23%)] Loss: 12394291.000000\n",
      "Train Epoch: 59 [224/918 (24%)] Loss: 13257954.000000\n",
      "Train Epoch: 59 [240/918 (26%)] Loss: 14952951.000000\n",
      "Train Epoch: 59 [256/918 (28%)] Loss: 13966235.000000\n",
      "Train Epoch: 59 [272/918 (30%)] Loss: 10417871.000000\n",
      "Train Epoch: 59 [288/918 (31%)] Loss: 14572352.000000\n",
      "Train Epoch: 59 [304/918 (33%)] Loss: 10951150.000000\n",
      "Train Epoch: 59 [320/918 (35%)] Loss: 13119747.000000\n",
      "Train Epoch: 59 [336/918 (37%)] Loss: 12052907.000000\n",
      "Train Epoch: 59 [352/918 (38%)] Loss: 13312182.000000\n",
      "Train Epoch: 59 [368/918 (40%)] Loss: 18866214.000000\n",
      "Train Epoch: 59 [384/918 (42%)] Loss: 15137458.000000\n",
      "Train Epoch: 59 [400/918 (44%)] Loss: 18060192.000000\n",
      "Train Epoch: 59 [416/918 (45%)] Loss: 13563331.000000\n",
      "Train Epoch: 59 [432/918 (47%)] Loss: 16457171.000000\n",
      "Train Epoch: 59 [448/918 (49%)] Loss: 12627175.000000\n",
      "Train Epoch: 59 [464/918 (51%)] Loss: 13591642.000000\n",
      "Train Epoch: 59 [480/918 (52%)] Loss: 13463917.000000\n",
      "Train Epoch: 59 [496/918 (54%)] Loss: 16934536.000000\n",
      "Train Epoch: 59 [512/918 (56%)] Loss: 13439685.000000\n",
      "Train Epoch: 59 [528/918 (58%)] Loss: 10555256.000000\n",
      "Train Epoch: 59 [544/918 (59%)] Loss: 15538378.000000\n",
      "Train Epoch: 59 [560/918 (61%)] Loss: 11190679.000000\n",
      "Train Epoch: 59 [576/918 (63%)] Loss: 12602333.000000\n",
      "Train Epoch: 59 [592/918 (64%)] Loss: 15127632.000000\n",
      "Train Epoch: 59 [608/918 (66%)] Loss: 11978379.000000\n",
      "Train Epoch: 59 [624/918 (68%)] Loss: 11903256.000000\n",
      "Train Epoch: 59 [640/918 (70%)] Loss: 12078566.000000\n",
      "Train Epoch: 59 [656/918 (71%)] Loss: 19274852.000000\n",
      "Train Epoch: 59 [672/918 (73%)] Loss: 16009767.000000\n",
      "Train Epoch: 59 [688/918 (75%)] Loss: 9939026.000000\n",
      "Train Epoch: 59 [704/918 (77%)] Loss: 18253376.000000\n",
      "Train Epoch: 59 [720/918 (78%)] Loss: 14178613.000000\n",
      "Train Epoch: 59 [736/918 (80%)] Loss: 14165123.000000\n",
      "Train Epoch: 59 [752/918 (82%)] Loss: 12588202.000000\n",
      "Train Epoch: 59 [768/918 (84%)] Loss: 11039967.000000\n",
      "Train Epoch: 59 [784/918 (85%)] Loss: 13374652.000000\n",
      "Train Epoch: 59 [800/918 (87%)] Loss: 16193600.000000\n",
      "Train Epoch: 59 [816/918 (89%)] Loss: 14688061.000000\n",
      "Train Epoch: 59 [832/918 (91%)] Loss: 14252627.000000\n",
      "Train Epoch: 59 [848/918 (92%)] Loss: 12982132.000000\n",
      "Train Epoch: 59 [864/918 (94%)] Loss: 13692663.000000\n",
      "Train Epoch: 59 [880/918 (96%)] Loss: 13629155.000000\n",
      "Train Epoch: 59 [896/918 (98%)] Loss: 17602078.000000\n",
      "Train Epoch: 59 [912/918 (99%)] Loss: 9694840.000000\n",
      "    epoch          : 59\n",
      "    loss           : 13883778.55652174\n",
      "    ess            : 13.154516164116238\n",
      "    log_marginal   : -13883776.773913043\n",
      "    val_loss       : 12321419.384615384\n",
      "    val_ess        : 12.317336339216967\n",
      "    val_log_marginal: -12321418.76923077\n",
      "Train Epoch: 60 [0/918 (0%)] Loss: 11273339.000000\n",
      "Train Epoch: 60 [16/918 (2%)] Loss: 13355826.000000\n",
      "Train Epoch: 60 [32/918 (3%)] Loss: 16685575.000000\n",
      "Train Epoch: 60 [48/918 (5%)] Loss: 13470896.000000\n",
      "Train Epoch: 60 [64/918 (7%)] Loss: 10215971.000000\n",
      "Train Epoch: 60 [80/918 (9%)] Loss: 15351034.000000\n",
      "Train Epoch: 60 [96/918 (10%)] Loss: 12677731.000000\n",
      "Train Epoch: 60 [112/918 (12%)] Loss: 12237914.000000\n",
      "Train Epoch: 60 [128/918 (14%)] Loss: 16325090.000000\n",
      "Train Epoch: 60 [144/918 (16%)] Loss: 10990025.000000\n",
      "Train Epoch: 60 [160/918 (17%)] Loss: 21177522.000000\n",
      "Train Epoch: 60 [176/918 (19%)] Loss: 12770091.000000\n",
      "Train Epoch: 60 [192/918 (21%)] Loss: 15257487.000000\n",
      "Train Epoch: 60 [208/918 (23%)] Loss: 14031499.000000\n",
      "Train Epoch: 60 [224/918 (24%)] Loss: 9501584.000000\n",
      "Train Epoch: 60 [240/918 (26%)] Loss: 14591891.000000\n",
      "Train Epoch: 60 [256/918 (28%)] Loss: 11051661.000000\n",
      "Train Epoch: 60 [272/918 (30%)] Loss: 14140421.000000\n",
      "Train Epoch: 60 [288/918 (31%)] Loss: 20183380.000000\n",
      "Train Epoch: 60 [304/918 (33%)] Loss: 11313052.000000\n",
      "Train Epoch: 60 [320/918 (35%)] Loss: 11045823.000000\n",
      "Train Epoch: 60 [336/918 (37%)] Loss: 15305623.000000\n",
      "Train Epoch: 60 [352/918 (38%)] Loss: 19901278.000000\n",
      "Train Epoch: 60 [368/918 (40%)] Loss: 17211512.000000\n",
      "Train Epoch: 60 [384/918 (42%)] Loss: 11213083.000000\n",
      "Train Epoch: 60 [400/918 (44%)] Loss: 14940290.000000\n",
      "Train Epoch: 60 [416/918 (45%)] Loss: 10275396.000000\n",
      "Train Epoch: 60 [432/918 (47%)] Loss: 12275776.000000\n",
      "Train Epoch: 60 [448/918 (49%)] Loss: 14581579.000000\n",
      "Train Epoch: 60 [464/918 (51%)] Loss: 17949146.000000\n",
      "Train Epoch: 60 [480/918 (52%)] Loss: 13595149.000000\n",
      "Train Epoch: 60 [496/918 (54%)] Loss: 11661086.000000\n",
      "Train Epoch: 60 [512/918 (56%)] Loss: 10511506.000000\n",
      "Train Epoch: 60 [528/918 (58%)] Loss: 15728931.000000\n",
      "Train Epoch: 60 [544/918 (59%)] Loss: 14047709.000000\n",
      "Train Epoch: 60 [560/918 (61%)] Loss: 12017323.000000\n",
      "Train Epoch: 60 [576/918 (63%)] Loss: 17122654.000000\n",
      "Train Epoch: 60 [592/918 (64%)] Loss: 16601613.000000\n",
      "Train Epoch: 60 [608/918 (66%)] Loss: 12570782.000000\n",
      "Train Epoch: 60 [624/918 (68%)] Loss: 10372863.000000\n",
      "Train Epoch: 60 [640/918 (70%)] Loss: 12915338.000000\n",
      "Train Epoch: 60 [656/918 (71%)] Loss: 14994397.000000\n",
      "Train Epoch: 60 [672/918 (73%)] Loss: 14200674.000000\n",
      "Train Epoch: 60 [688/918 (75%)] Loss: 14709203.000000\n",
      "Train Epoch: 60 [704/918 (77%)] Loss: 10052944.000000\n",
      "Train Epoch: 60 [720/918 (78%)] Loss: 14011571.000000\n",
      "Train Epoch: 60 [736/918 (80%)] Loss: 8688136.000000\n",
      "Train Epoch: 60 [752/918 (82%)] Loss: 13814989.000000\n",
      "Train Epoch: 60 [768/918 (84%)] Loss: 13680251.000000\n",
      "Train Epoch: 60 [784/918 (85%)] Loss: 13056636.000000\n",
      "Train Epoch: 60 [800/918 (87%)] Loss: 12725320.000000\n",
      "Train Epoch: 60 [816/918 (89%)] Loss: 14190968.000000\n",
      "Train Epoch: 60 [832/918 (91%)] Loss: 13335112.000000\n",
      "Train Epoch: 60 [848/918 (92%)] Loss: 14099205.000000\n",
      "Train Epoch: 60 [864/918 (94%)] Loss: 12276214.000000\n",
      "Train Epoch: 60 [880/918 (96%)] Loss: 12555450.000000\n",
      "Train Epoch: 60 [896/918 (98%)] Loss: 11594485.000000\n",
      "Train Epoch: 60 [912/918 (99%)] Loss: 17023090.000000\n",
      "    epoch          : 60\n",
      "    loss           : 13779950.104347827\n",
      "    ess            : 13.686031320820684\n",
      "    log_marginal   : -13779948.617391305\n",
      "    val_loss       : 13183969.461538462\n",
      "    val_ess        : 12.83147193835332\n",
      "    val_log_marginal: -13183968.384615384\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch60.pth ...\n",
      "Train Epoch: 61 [0/918 (0%)] Loss: 15010195.000000\n",
      "Train Epoch: 61 [16/918 (2%)] Loss: 20169002.000000\n",
      "Train Epoch: 61 [32/918 (3%)] Loss: 13625069.000000\n",
      "Train Epoch: 61 [48/918 (5%)] Loss: 11851107.000000\n",
      "Train Epoch: 61 [64/918 (7%)] Loss: 14568104.000000\n",
      "Train Epoch: 61 [80/918 (9%)] Loss: 14061968.000000\n",
      "Train Epoch: 61 [96/918 (10%)] Loss: 11900525.000000\n",
      "Train Epoch: 61 [112/918 (12%)] Loss: 9299656.000000\n",
      "Train Epoch: 61 [128/918 (14%)] Loss: 10548474.000000\n",
      "Train Epoch: 61 [144/918 (16%)] Loss: 16052749.000000\n",
      "Train Epoch: 61 [160/918 (17%)] Loss: 12209848.000000\n",
      "Train Epoch: 61 [176/918 (19%)] Loss: 15924253.000000\n",
      "Train Epoch: 61 [192/918 (21%)] Loss: 10828851.000000\n",
      "Train Epoch: 61 [208/918 (23%)] Loss: 13584368.000000\n",
      "Train Epoch: 61 [224/918 (24%)] Loss: 16606536.000000\n",
      "Train Epoch: 61 [240/918 (26%)] Loss: 12674012.000000\n",
      "Train Epoch: 61 [256/918 (28%)] Loss: 17099012.000000\n",
      "Train Epoch: 61 [272/918 (30%)] Loss: 15216239.000000\n",
      "Train Epoch: 61 [288/918 (31%)] Loss: 17142268.000000\n",
      "Train Epoch: 61 [304/918 (33%)] Loss: 14048647.000000\n",
      "Train Epoch: 61 [320/918 (35%)] Loss: 13528539.000000\n",
      "Train Epoch: 61 [336/918 (37%)] Loss: 11421006.000000\n",
      "Train Epoch: 61 [352/918 (38%)] Loss: 11758739.000000\n",
      "Train Epoch: 61 [368/918 (40%)] Loss: 15261165.000000\n",
      "Train Epoch: 61 [384/918 (42%)] Loss: 15817226.000000\n",
      "Train Epoch: 61 [400/918 (44%)] Loss: 16385408.000000\n",
      "Train Epoch: 61 [416/918 (45%)] Loss: 15545391.000000\n",
      "Train Epoch: 61 [432/918 (47%)] Loss: 13720637.000000\n",
      "Train Epoch: 61 [448/918 (49%)] Loss: 14524219.000000\n",
      "Train Epoch: 61 [464/918 (51%)] Loss: 13316488.000000\n",
      "Train Epoch: 61 [480/918 (52%)] Loss: 18212916.000000\n",
      "Train Epoch: 61 [496/918 (54%)] Loss: 12203020.000000\n",
      "Train Epoch: 61 [512/918 (56%)] Loss: 15560960.000000\n",
      "Train Epoch: 61 [528/918 (58%)] Loss: 14850218.000000\n",
      "Train Epoch: 61 [544/918 (59%)] Loss: 11786744.000000\n",
      "Train Epoch: 61 [560/918 (61%)] Loss: 15576154.000000\n",
      "Train Epoch: 61 [576/918 (63%)] Loss: 19929370.000000\n",
      "Train Epoch: 61 [592/918 (64%)] Loss: 13150158.000000\n",
      "Train Epoch: 61 [608/918 (66%)] Loss: 15157491.000000\n",
      "Train Epoch: 61 [624/918 (68%)] Loss: 13112061.000000\n",
      "Train Epoch: 61 [640/918 (70%)] Loss: 14218787.000000\n",
      "Train Epoch: 61 [656/918 (71%)] Loss: 16204751.000000\n",
      "Train Epoch: 61 [672/918 (73%)] Loss: 11853064.000000\n",
      "Train Epoch: 61 [688/918 (75%)] Loss: 11275588.000000\n",
      "Train Epoch: 61 [704/918 (77%)] Loss: 15165283.000000\n",
      "Train Epoch: 61 [720/918 (78%)] Loss: 12794491.000000\n",
      "Train Epoch: 61 [736/918 (80%)] Loss: 11635229.000000\n",
      "Train Epoch: 61 [752/918 (82%)] Loss: 10766891.000000\n",
      "Train Epoch: 61 [768/918 (84%)] Loss: 13277064.000000\n",
      "Train Epoch: 61 [784/918 (85%)] Loss: 14375554.000000\n",
      "Train Epoch: 61 [800/918 (87%)] Loss: 12407304.000000\n",
      "Train Epoch: 61 [816/918 (89%)] Loss: 14988546.000000\n",
      "Train Epoch: 61 [832/918 (91%)] Loss: 10131723.000000\n",
      "Train Epoch: 61 [848/918 (92%)] Loss: 11395394.000000\n",
      "Train Epoch: 61 [864/918 (94%)] Loss: 10706311.000000\n",
      "Train Epoch: 61 [880/918 (96%)] Loss: 15386755.000000\n",
      "Train Epoch: 61 [896/918 (98%)] Loss: 12690007.000000\n",
      "Train Epoch: 61 [912/918 (99%)] Loss: 14748884.000000\n",
      "    epoch          : 61\n",
      "    loss           : 13889721.469565218\n",
      "    ess            : 13.386359420030013\n",
      "    log_marginal   : -13889720.460869566\n",
      "    val_loss       : 12975974.692307692\n",
      "    val_ess        : 12.491794219383827\n",
      "    val_log_marginal: -12975973.23076923\n",
      "Train Epoch: 62 [0/918 (0%)] Loss: 10603715.000000\n",
      "Train Epoch: 62 [16/918 (2%)] Loss: 16169957.000000\n",
      "Train Epoch: 62 [32/918 (3%)] Loss: 11973087.000000\n",
      "Train Epoch: 62 [48/918 (5%)] Loss: 13080788.000000\n",
      "Train Epoch: 62 [64/918 (7%)] Loss: 15422423.000000\n",
      "Train Epoch: 62 [80/918 (9%)] Loss: 14152019.000000\n",
      "Train Epoch: 62 [96/918 (10%)] Loss: 12589443.000000\n",
      "Train Epoch: 62 [112/918 (12%)] Loss: 11414783.000000\n",
      "Train Epoch: 62 [128/918 (14%)] Loss: 11740803.000000\n",
      "Train Epoch: 62 [144/918 (16%)] Loss: 18975182.000000\n",
      "Train Epoch: 62 [160/918 (17%)] Loss: 13668711.000000\n",
      "Train Epoch: 62 [176/918 (19%)] Loss: 16008714.000000\n",
      "Train Epoch: 62 [192/918 (21%)] Loss: 16186837.000000\n",
      "Train Epoch: 62 [208/918 (23%)] Loss: 11840916.000000\n",
      "Train Epoch: 62 [224/918 (24%)] Loss: 14438293.000000\n",
      "Train Epoch: 62 [240/918 (26%)] Loss: 12376080.000000\n",
      "Train Epoch: 62 [256/918 (28%)] Loss: 12718147.000000\n",
      "Train Epoch: 62 [272/918 (30%)] Loss: 14989682.000000\n",
      "Train Epoch: 62 [288/918 (31%)] Loss: 15393992.000000\n",
      "Train Epoch: 62 [304/918 (33%)] Loss: 18200518.000000\n",
      "Train Epoch: 62 [320/918 (35%)] Loss: 13981002.000000\n",
      "Train Epoch: 62 [336/918 (37%)] Loss: 13416397.000000\n",
      "Train Epoch: 62 [352/918 (38%)] Loss: 15646594.000000\n",
      "Train Epoch: 62 [368/918 (40%)] Loss: 12290078.000000\n",
      "Train Epoch: 62 [384/918 (42%)] Loss: 12708452.000000\n",
      "Train Epoch: 62 [400/918 (44%)] Loss: 10419183.000000\n",
      "Train Epoch: 62 [416/918 (45%)] Loss: 12180022.000000\n",
      "Train Epoch: 62 [432/918 (47%)] Loss: 10978675.000000\n",
      "Train Epoch: 62 [448/918 (49%)] Loss: 12641263.000000\n",
      "Train Epoch: 62 [464/918 (51%)] Loss: 15456829.000000\n",
      "Train Epoch: 62 [480/918 (52%)] Loss: 15620480.000000\n",
      "Train Epoch: 62 [496/918 (54%)] Loss: 16091535.000000\n",
      "Train Epoch: 62 [512/918 (56%)] Loss: 16911400.000000\n",
      "Train Epoch: 62 [528/918 (58%)] Loss: 17008246.000000\n",
      "Train Epoch: 62 [544/918 (59%)] Loss: 17847850.000000\n",
      "Train Epoch: 62 [560/918 (61%)] Loss: 10395656.000000\n",
      "Train Epoch: 62 [576/918 (63%)] Loss: 13254171.000000\n",
      "Train Epoch: 62 [592/918 (64%)] Loss: 16479933.000000\n",
      "Train Epoch: 62 [608/918 (66%)] Loss: 16027181.000000\n",
      "Train Epoch: 62 [624/918 (68%)] Loss: 12271821.000000\n",
      "Train Epoch: 62 [640/918 (70%)] Loss: 24150296.000000\n",
      "Train Epoch: 62 [656/918 (71%)] Loss: 13041172.000000\n",
      "Train Epoch: 62 [672/918 (73%)] Loss: 12400776.000000\n",
      "Train Epoch: 62 [688/918 (75%)] Loss: 12433391.000000\n",
      "Train Epoch: 62 [704/918 (77%)] Loss: 11169954.000000\n",
      "Train Epoch: 62 [720/918 (78%)] Loss: 13179103.000000\n",
      "Train Epoch: 62 [736/918 (80%)] Loss: 15732746.000000\n",
      "Train Epoch: 62 [752/918 (82%)] Loss: 14049328.000000\n",
      "Train Epoch: 62 [768/918 (84%)] Loss: 13788253.000000\n",
      "Train Epoch: 62 [784/918 (85%)] Loss: 18754144.000000\n",
      "Train Epoch: 62 [800/918 (87%)] Loss: 10563077.000000\n",
      "Train Epoch: 62 [816/918 (89%)] Loss: 19495540.000000\n",
      "Train Epoch: 62 [832/918 (91%)] Loss: 15441997.000000\n",
      "Train Epoch: 62 [848/918 (92%)] Loss: 11773139.000000\n",
      "Train Epoch: 62 [864/918 (94%)] Loss: 10693861.000000\n",
      "Train Epoch: 62 [880/918 (96%)] Loss: 15457810.000000\n",
      "Train Epoch: 62 [896/918 (98%)] Loss: 10575223.000000\n",
      "Train Epoch: 62 [912/918 (99%)] Loss: 15768430.000000\n",
      "    epoch          : 62\n",
      "    loss           : 13877522.947826087\n",
      "    ess            : 13.329098500376162\n",
      "    log_marginal   : -13877521.382608695\n",
      "    val_loss       : 12462740.846153846\n",
      "    val_ess        : 10.497433735774113\n",
      "    val_log_marginal: -12462739.76923077\n",
      "Train Epoch: 63 [0/918 (0%)] Loss: 11412524.000000\n",
      "Train Epoch: 63 [16/918 (2%)] Loss: 13434029.000000\n",
      "Train Epoch: 63 [32/918 (3%)] Loss: 12322562.000000\n",
      "Train Epoch: 63 [48/918 (5%)] Loss: 11689696.000000\n",
      "Train Epoch: 63 [64/918 (7%)] Loss: 11919886.000000\n",
      "Train Epoch: 63 [80/918 (9%)] Loss: 16685496.000000\n",
      "Train Epoch: 63 [96/918 (10%)] Loss: 15897904.000000\n",
      "Train Epoch: 63 [112/918 (12%)] Loss: 11838757.000000\n",
      "Train Epoch: 63 [128/918 (14%)] Loss: 17341716.000000\n",
      "Train Epoch: 63 [144/918 (16%)] Loss: 11959043.000000\n",
      "Train Epoch: 63 [160/918 (17%)] Loss: 14673045.000000\n",
      "Train Epoch: 63 [176/918 (19%)] Loss: 9906747.000000\n",
      "Train Epoch: 63 [192/918 (21%)] Loss: 11774539.000000\n",
      "Train Epoch: 63 [208/918 (23%)] Loss: 12467219.000000\n",
      "Train Epoch: 63 [224/918 (24%)] Loss: 10860352.000000\n",
      "Train Epoch: 63 [240/918 (26%)] Loss: 17456956.000000\n",
      "Train Epoch: 63 [256/918 (28%)] Loss: 10231579.000000\n",
      "Train Epoch: 63 [272/918 (30%)] Loss: 13272911.000000\n",
      "Train Epoch: 63 [288/918 (31%)] Loss: 14944856.000000\n",
      "Train Epoch: 63 [304/918 (33%)] Loss: 13565773.000000\n",
      "Train Epoch: 63 [320/918 (35%)] Loss: 12843608.000000\n",
      "Train Epoch: 63 [336/918 (37%)] Loss: 19308206.000000\n",
      "Train Epoch: 63 [352/918 (38%)] Loss: 13501107.000000\n",
      "Train Epoch: 63 [368/918 (40%)] Loss: 14247527.000000\n",
      "Train Epoch: 63 [384/918 (42%)] Loss: 13998272.000000\n",
      "Train Epoch: 63 [400/918 (44%)] Loss: 12870908.000000\n",
      "Train Epoch: 63 [416/918 (45%)] Loss: 17092040.000000\n",
      "Train Epoch: 63 [432/918 (47%)] Loss: 13206591.000000\n",
      "Train Epoch: 63 [448/918 (49%)] Loss: 13159823.000000\n",
      "Train Epoch: 63 [464/918 (51%)] Loss: 14700208.000000\n",
      "Train Epoch: 63 [480/918 (52%)] Loss: 14460714.000000\n",
      "Train Epoch: 63 [496/918 (54%)] Loss: 14884530.000000\n",
      "Train Epoch: 63 [512/918 (56%)] Loss: 11144527.000000\n",
      "Train Epoch: 63 [528/918 (58%)] Loss: 13544608.000000\n",
      "Train Epoch: 63 [544/918 (59%)] Loss: 14973667.000000\n",
      "Train Epoch: 63 [560/918 (61%)] Loss: 15768010.000000\n",
      "Train Epoch: 63 [576/918 (63%)] Loss: 17713054.000000\n",
      "Train Epoch: 63 [592/918 (64%)] Loss: 17878432.000000\n",
      "Train Epoch: 63 [608/918 (66%)] Loss: 12702870.000000\n",
      "Train Epoch: 63 [624/918 (68%)] Loss: 13092590.000000\n",
      "Train Epoch: 63 [640/918 (70%)] Loss: 11353932.000000\n",
      "Train Epoch: 63 [656/918 (71%)] Loss: 14070792.000000\n",
      "Train Epoch: 63 [672/918 (73%)] Loss: 9625210.000000\n",
      "Train Epoch: 63 [688/918 (75%)] Loss: 13422250.000000\n",
      "Train Epoch: 63 [704/918 (77%)] Loss: 12709619.000000\n",
      "Train Epoch: 63 [720/918 (78%)] Loss: 16915526.000000\n",
      "Train Epoch: 63 [736/918 (80%)] Loss: 11173579.000000\n",
      "Train Epoch: 63 [752/918 (82%)] Loss: 12426613.000000\n",
      "Train Epoch: 63 [768/918 (84%)] Loss: 11036616.000000\n",
      "Train Epoch: 63 [784/918 (85%)] Loss: 16371151.000000\n",
      "Train Epoch: 63 [800/918 (87%)] Loss: 10720767.000000\n",
      "Train Epoch: 63 [816/918 (89%)] Loss: 11046859.000000\n",
      "Train Epoch: 63 [832/918 (91%)] Loss: 10432479.000000\n",
      "Train Epoch: 63 [848/918 (92%)] Loss: 16102135.000000\n",
      "Train Epoch: 63 [864/918 (94%)] Loss: 12640719.000000\n",
      "Train Epoch: 63 [880/918 (96%)] Loss: 12721102.000000\n",
      "Train Epoch: 63 [896/918 (98%)] Loss: 11852693.000000\n",
      "Train Epoch: 63 [912/918 (99%)] Loss: 13067959.000000\n",
      "    epoch          : 63\n",
      "    loss           : 13730485.391304348\n",
      "    ess            : 13.689359144542529\n",
      "    log_marginal   : -13730484.12173913\n",
      "    val_loss       : 12864517.653846154\n",
      "    val_ess        : 11.84986998484685\n",
      "    val_log_marginal: -12864517.538461538\n",
      "Train Epoch: 64 [0/918 (0%)] Loss: 14312503.000000\n",
      "Train Epoch: 64 [16/918 (2%)] Loss: 14963447.000000\n",
      "Train Epoch: 64 [32/918 (3%)] Loss: 15723274.000000\n",
      "Train Epoch: 64 [48/918 (5%)] Loss: 14351363.000000\n",
      "Train Epoch: 64 [64/918 (7%)] Loss: 11303715.000000\n",
      "Train Epoch: 64 [80/918 (9%)] Loss: 11578975.000000\n",
      "Train Epoch: 64 [96/918 (10%)] Loss: 16797172.000000\n",
      "Train Epoch: 64 [112/918 (12%)] Loss: 8983944.000000\n",
      "Train Epoch: 64 [128/918 (14%)] Loss: 13864752.000000\n",
      "Train Epoch: 64 [144/918 (16%)] Loss: 12995952.000000\n",
      "Train Epoch: 64 [160/918 (17%)] Loss: 12293779.000000\n",
      "Train Epoch: 64 [176/918 (19%)] Loss: 10839677.000000\n",
      "Train Epoch: 64 [192/918 (21%)] Loss: 11966102.000000\n",
      "Train Epoch: 64 [208/918 (23%)] Loss: 13633600.000000\n",
      "Train Epoch: 64 [224/918 (24%)] Loss: 12254962.000000\n",
      "Train Epoch: 64 [240/918 (26%)] Loss: 13906291.000000\n",
      "Train Epoch: 64 [256/918 (28%)] Loss: 12911384.000000\n",
      "Train Epoch: 64 [272/918 (30%)] Loss: 19840708.000000\n",
      "Train Epoch: 64 [288/918 (31%)] Loss: 11229201.000000\n",
      "Train Epoch: 64 [304/918 (33%)] Loss: 14493205.000000\n",
      "Train Epoch: 64 [320/918 (35%)] Loss: 14300640.000000\n",
      "Train Epoch: 64 [336/918 (37%)] Loss: 14294875.000000\n",
      "Train Epoch: 64 [352/918 (38%)] Loss: 15176243.000000\n",
      "Train Epoch: 64 [368/918 (40%)] Loss: 12156818.000000\n",
      "Train Epoch: 64 [384/918 (42%)] Loss: 14522704.000000\n",
      "Train Epoch: 64 [400/918 (44%)] Loss: 17183822.000000\n",
      "Train Epoch: 64 [416/918 (45%)] Loss: 14500389.000000\n",
      "Train Epoch: 64 [432/918 (47%)] Loss: 16100487.000000\n",
      "Train Epoch: 64 [448/918 (49%)] Loss: 11513820.000000\n",
      "Train Epoch: 64 [464/918 (51%)] Loss: 11662028.000000\n",
      "Train Epoch: 64 [480/918 (52%)] Loss: 12965280.000000\n",
      "Train Epoch: 64 [496/918 (54%)] Loss: 15932207.000000\n",
      "Train Epoch: 64 [512/918 (56%)] Loss: 13873589.000000\n",
      "Train Epoch: 64 [528/918 (58%)] Loss: 12499710.000000\n",
      "Train Epoch: 64 [544/918 (59%)] Loss: 14521679.000000\n",
      "Train Epoch: 64 [560/918 (61%)] Loss: 17464670.000000\n",
      "Train Epoch: 64 [576/918 (63%)] Loss: 16135923.000000\n",
      "Train Epoch: 64 [592/918 (64%)] Loss: 12310144.000000\n",
      "Train Epoch: 64 [608/918 (66%)] Loss: 11935903.000000\n",
      "Train Epoch: 64 [624/918 (68%)] Loss: 16028176.000000\n",
      "Train Epoch: 64 [640/918 (70%)] Loss: 12927776.000000\n",
      "Train Epoch: 64 [656/918 (71%)] Loss: 13892095.000000\n",
      "Train Epoch: 64 [672/918 (73%)] Loss: 13977747.000000\n",
      "Train Epoch: 64 [688/918 (75%)] Loss: 12752784.000000\n",
      "Train Epoch: 64 [704/918 (77%)] Loss: 14356064.000000\n",
      "Train Epoch: 64 [720/918 (78%)] Loss: 19643262.000000\n",
      "Train Epoch: 64 [736/918 (80%)] Loss: 16015661.000000\n",
      "Train Epoch: 64 [752/918 (82%)] Loss: 12179733.000000\n",
      "Train Epoch: 64 [768/918 (84%)] Loss: 11284214.000000\n",
      "Train Epoch: 64 [784/918 (85%)] Loss: 13637355.000000\n",
      "Train Epoch: 64 [800/918 (87%)] Loss: 14948656.000000\n",
      "Train Epoch: 64 [816/918 (89%)] Loss: 12840923.000000\n",
      "Train Epoch: 64 [832/918 (91%)] Loss: 11254824.000000\n",
      "Train Epoch: 64 [848/918 (92%)] Loss: 11103981.000000\n",
      "Train Epoch: 64 [864/918 (94%)] Loss: 13941266.000000\n",
      "Train Epoch: 64 [880/918 (96%)] Loss: 15193907.000000\n",
      "Train Epoch: 64 [896/918 (98%)] Loss: 15845175.000000\n",
      "Train Epoch: 64 [912/918 (99%)] Loss: 20440474.000000\n",
      "    epoch          : 64\n",
      "    loss           : 13729528.72173913\n",
      "    ess            : 12.92738297711248\n",
      "    log_marginal   : -13729526.965217391\n",
      "    val_loss       : 12702415.384615384\n",
      "    val_ess        : 13.93235965875479\n",
      "    val_log_marginal: -12702414.153846154\n",
      "Train Epoch: 65 [0/918 (0%)] Loss: 16196387.000000\n",
      "Train Epoch: 65 [16/918 (2%)] Loss: 13704730.000000\n",
      "Train Epoch: 65 [32/918 (3%)] Loss: 13255812.000000\n",
      "Train Epoch: 65 [48/918 (5%)] Loss: 14080394.000000\n",
      "Train Epoch: 65 [64/918 (7%)] Loss: 13317211.000000\n",
      "Train Epoch: 65 [80/918 (9%)] Loss: 13901611.000000\n",
      "Train Epoch: 65 [96/918 (10%)] Loss: 15710013.000000\n",
      "Train Epoch: 65 [112/918 (12%)] Loss: 16187405.000000\n",
      "Train Epoch: 65 [128/918 (14%)] Loss: 15879629.000000\n",
      "Train Epoch: 65 [144/918 (16%)] Loss: 10843954.000000\n",
      "Train Epoch: 65 [160/918 (17%)] Loss: 13922391.000000\n",
      "Train Epoch: 65 [176/918 (19%)] Loss: 11197672.000000\n",
      "Train Epoch: 65 [192/918 (21%)] Loss: 14755791.000000\n",
      "Train Epoch: 65 [208/918 (23%)] Loss: 11730841.000000\n",
      "Train Epoch: 65 [224/918 (24%)] Loss: 12999079.000000\n",
      "Train Epoch: 65 [240/918 (26%)] Loss: 20251070.000000\n",
      "Train Epoch: 65 [256/918 (28%)] Loss: 13487085.000000\n",
      "Train Epoch: 65 [272/918 (30%)] Loss: 13162766.000000\n",
      "Train Epoch: 65 [288/918 (31%)] Loss: 10920373.000000\n",
      "Train Epoch: 65 [304/918 (33%)] Loss: 16376669.000000\n",
      "Train Epoch: 65 [320/918 (35%)] Loss: 14339197.000000\n",
      "Train Epoch: 65 [336/918 (37%)] Loss: 12823840.000000\n",
      "Train Epoch: 65 [352/918 (38%)] Loss: 13954643.000000\n",
      "Train Epoch: 65 [368/918 (40%)] Loss: 13994770.000000\n",
      "Train Epoch: 65 [384/918 (42%)] Loss: 12753339.000000\n",
      "Train Epoch: 65 [400/918 (44%)] Loss: 15527080.000000\n",
      "Train Epoch: 65 [416/918 (45%)] Loss: 14651431.000000\n",
      "Train Epoch: 65 [432/918 (47%)] Loss: 11278351.000000\n",
      "Train Epoch: 65 [448/918 (49%)] Loss: 9885744.000000\n",
      "Train Epoch: 65 [464/918 (51%)] Loss: 12199019.000000\n",
      "Train Epoch: 65 [480/918 (52%)] Loss: 16005719.000000\n",
      "Train Epoch: 65 [496/918 (54%)] Loss: 13815360.000000\n",
      "Train Epoch: 65 [512/918 (56%)] Loss: 20920920.000000\n",
      "Train Epoch: 65 [528/918 (58%)] Loss: 12025332.000000\n",
      "Train Epoch: 65 [544/918 (59%)] Loss: 9737426.000000\n",
      "Train Epoch: 65 [560/918 (61%)] Loss: 14108323.000000\n",
      "Train Epoch: 65 [576/918 (63%)] Loss: 15803797.000000\n",
      "Train Epoch: 65 [592/918 (64%)] Loss: 16105864.000000\n",
      "Train Epoch: 65 [608/918 (66%)] Loss: 16872936.000000\n",
      "Train Epoch: 65 [624/918 (68%)] Loss: 13068117.000000\n",
      "Train Epoch: 65 [640/918 (70%)] Loss: 13162742.000000\n",
      "Train Epoch: 65 [656/918 (71%)] Loss: 12961894.000000\n",
      "Train Epoch: 65 [672/918 (73%)] Loss: 15991712.000000\n",
      "Train Epoch: 65 [688/918 (75%)] Loss: 17609546.000000\n",
      "Train Epoch: 65 [704/918 (77%)] Loss: 15552064.000000\n",
      "Train Epoch: 65 [720/918 (78%)] Loss: 10808896.000000\n",
      "Train Epoch: 65 [736/918 (80%)] Loss: 13906771.000000\n",
      "Train Epoch: 65 [752/918 (82%)] Loss: 12952789.000000\n",
      "Train Epoch: 65 [768/918 (84%)] Loss: 14730637.000000\n",
      "Train Epoch: 65 [784/918 (85%)] Loss: 11186923.000000\n",
      "Train Epoch: 65 [800/918 (87%)] Loss: 15005104.000000\n",
      "Train Epoch: 65 [816/918 (89%)] Loss: 10310919.000000\n",
      "Train Epoch: 65 [832/918 (91%)] Loss: 14944461.000000\n",
      "Train Epoch: 65 [848/918 (92%)] Loss: 9353651.000000\n",
      "Train Epoch: 65 [864/918 (94%)] Loss: 9883967.000000\n",
      "Train Epoch: 65 [880/918 (96%)] Loss: 17091990.000000\n",
      "Train Epoch: 65 [896/918 (98%)] Loss: 10629207.000000\n",
      "Train Epoch: 65 [912/918 (99%)] Loss: 10980298.000000\n",
      "    epoch          : 65\n",
      "    loss           : 13500069.513043478\n",
      "    ess            : 13.31159140130748\n",
      "    log_marginal   : -13500067.67826087\n",
      "    val_loss       : 12353513.307692308\n",
      "    val_ess        : 9.870913927371685\n",
      "    val_log_marginal: -12353511.384615384\n",
      "Train Epoch: 66 [0/918 (0%)] Loss: 17905082.000000\n",
      "Train Epoch: 66 [16/918 (2%)] Loss: 13419251.000000\n",
      "Train Epoch: 66 [32/918 (3%)] Loss: 11127317.000000\n",
      "Train Epoch: 66 [48/918 (5%)] Loss: 16186619.000000\n",
      "Train Epoch: 66 [64/918 (7%)] Loss: 12714805.000000\n",
      "Train Epoch: 66 [80/918 (9%)] Loss: 15700666.000000\n",
      "Train Epoch: 66 [96/918 (10%)] Loss: 9761856.000000\n",
      "Train Epoch: 66 [112/918 (12%)] Loss: 14301952.000000\n",
      "Train Epoch: 66 [128/918 (14%)] Loss: 18850798.000000\n",
      "Train Epoch: 66 [144/918 (16%)] Loss: 16050963.000000\n",
      "Train Epoch: 66 [160/918 (17%)] Loss: 10751012.000000\n",
      "Train Epoch: 66 [176/918 (19%)] Loss: 11398308.000000\n",
      "Train Epoch: 66 [192/918 (21%)] Loss: 14932448.000000\n",
      "Train Epoch: 66 [208/918 (23%)] Loss: 14578136.000000\n",
      "Train Epoch: 66 [224/918 (24%)] Loss: 10440623.000000\n",
      "Train Epoch: 66 [240/918 (26%)] Loss: 10801380.000000\n",
      "Train Epoch: 66 [256/918 (28%)] Loss: 12319157.000000\n",
      "Train Epoch: 66 [272/918 (30%)] Loss: 13020368.000000\n",
      "Train Epoch: 66 [288/918 (31%)] Loss: 16123087.000000\n",
      "Train Epoch: 66 [304/918 (33%)] Loss: 17343012.000000\n",
      "Train Epoch: 66 [320/918 (35%)] Loss: 11092470.000000\n",
      "Train Epoch: 66 [336/918 (37%)] Loss: 13626813.000000\n",
      "Train Epoch: 66 [352/918 (38%)] Loss: 13152245.000000\n",
      "Train Epoch: 66 [368/918 (40%)] Loss: 18856076.000000\n",
      "Train Epoch: 66 [384/918 (42%)] Loss: 14656680.000000\n",
      "Train Epoch: 66 [400/918 (44%)] Loss: 16249789.000000\n",
      "Train Epoch: 66 [416/918 (45%)] Loss: 13638506.000000\n",
      "Train Epoch: 66 [432/918 (47%)] Loss: 11767155.000000\n",
      "Train Epoch: 66 [448/918 (49%)] Loss: 15163349.000000\n",
      "Train Epoch: 66 [464/918 (51%)] Loss: 16038659.000000\n",
      "Train Epoch: 66 [480/918 (52%)] Loss: 12676980.000000\n",
      "Train Epoch: 66 [496/918 (54%)] Loss: 11083603.000000\n",
      "Train Epoch: 66 [512/918 (56%)] Loss: 12857098.000000\n",
      "Train Epoch: 66 [528/918 (58%)] Loss: 12713478.000000\n",
      "Train Epoch: 66 [544/918 (59%)] Loss: 9644960.000000\n",
      "Train Epoch: 66 [560/918 (61%)] Loss: 14142931.000000\n",
      "Train Epoch: 66 [576/918 (63%)] Loss: 11876956.000000\n",
      "Train Epoch: 66 [592/918 (64%)] Loss: 10868263.000000\n",
      "Train Epoch: 66 [608/918 (66%)] Loss: 13398979.000000\n",
      "Train Epoch: 66 [624/918 (68%)] Loss: 13373187.000000\n",
      "Train Epoch: 66 [640/918 (70%)] Loss: 14176704.000000\n",
      "Train Epoch: 66 [656/918 (71%)] Loss: 16581219.000000\n",
      "Train Epoch: 66 [672/918 (73%)] Loss: 13361100.000000\n",
      "Train Epoch: 66 [688/918 (75%)] Loss: 14077527.000000\n",
      "Train Epoch: 66 [704/918 (77%)] Loss: 11339967.000000\n",
      "Train Epoch: 66 [720/918 (78%)] Loss: 11017614.000000\n",
      "Train Epoch: 66 [736/918 (80%)] Loss: 13714691.000000\n",
      "Train Epoch: 66 [752/918 (82%)] Loss: 12911432.000000\n",
      "Train Epoch: 66 [768/918 (84%)] Loss: 16886004.000000\n",
      "Train Epoch: 66 [784/918 (85%)] Loss: 11708563.000000\n",
      "Train Epoch: 66 [800/918 (87%)] Loss: 14880259.000000\n",
      "Train Epoch: 66 [816/918 (89%)] Loss: 15683594.000000\n",
      "Train Epoch: 66 [832/918 (91%)] Loss: 12416440.000000\n",
      "Train Epoch: 66 [848/918 (92%)] Loss: 11993445.000000\n",
      "Train Epoch: 66 [864/918 (94%)] Loss: 13828096.000000\n",
      "Train Epoch: 66 [880/918 (96%)] Loss: 14349211.000000\n",
      "Train Epoch: 66 [896/918 (98%)] Loss: 10070943.000000\n",
      "Train Epoch: 66 [912/918 (99%)] Loss: 22037130.000000\n",
      "    epoch          : 66\n",
      "    loss           : 13504744.173913043\n",
      "    ess            : 12.484580616329028\n",
      "    log_marginal   : -13504742.634782609\n",
      "    val_loss       : 12170650.615384616\n",
      "    val_ess        : 10.630936530920176\n",
      "    val_log_marginal: -12170648.307692308\n",
      "Train Epoch: 67 [0/918 (0%)] Loss: 14941575.000000\n",
      "Train Epoch: 67 [16/918 (2%)] Loss: 14744042.000000\n",
      "Train Epoch: 67 [32/918 (3%)] Loss: 16100867.000000\n",
      "Train Epoch: 67 [48/918 (5%)] Loss: 15747421.000000\n",
      "Train Epoch: 67 [64/918 (7%)] Loss: 15143488.000000\n",
      "Train Epoch: 67 [80/918 (9%)] Loss: 13272296.000000\n",
      "Train Epoch: 67 [96/918 (10%)] Loss: 12972274.000000\n",
      "Train Epoch: 67 [112/918 (12%)] Loss: 11227663.000000\n",
      "Train Epoch: 67 [128/918 (14%)] Loss: 14296525.000000\n",
      "Train Epoch: 67 [144/918 (16%)] Loss: 14458893.000000\n",
      "Train Epoch: 67 [160/918 (17%)] Loss: 11939367.000000\n",
      "Train Epoch: 67 [176/918 (19%)] Loss: 11289028.000000\n",
      "Train Epoch: 67 [192/918 (21%)] Loss: 14346765.000000\n",
      "Train Epoch: 67 [208/918 (23%)] Loss: 20644944.000000\n",
      "Train Epoch: 67 [224/918 (24%)] Loss: 14257963.000000\n",
      "Train Epoch: 67 [240/918 (26%)] Loss: 16189672.000000\n",
      "Train Epoch: 67 [256/918 (28%)] Loss: 14144714.000000\n",
      "Train Epoch: 67 [272/918 (30%)] Loss: 8761717.000000\n",
      "Train Epoch: 67 [288/918 (31%)] Loss: 14191811.000000\n",
      "Train Epoch: 67 [304/918 (33%)] Loss: 13803576.000000\n",
      "Train Epoch: 67 [320/918 (35%)] Loss: 14780255.000000\n",
      "Train Epoch: 67 [336/918 (37%)] Loss: 12120711.000000\n",
      "Train Epoch: 67 [352/918 (38%)] Loss: 12707624.000000\n",
      "Train Epoch: 67 [368/918 (40%)] Loss: 13781088.000000\n",
      "Train Epoch: 67 [384/918 (42%)] Loss: 15852776.000000\n",
      "Train Epoch: 67 [400/918 (44%)] Loss: 12480984.000000\n",
      "Train Epoch: 67 [416/918 (45%)] Loss: 11799822.000000\n",
      "Train Epoch: 67 [432/918 (47%)] Loss: 11989528.000000\n",
      "Train Epoch: 67 [448/918 (49%)] Loss: 13496578.000000\n",
      "Train Epoch: 67 [464/918 (51%)] Loss: 14505581.000000\n",
      "Train Epoch: 67 [480/918 (52%)] Loss: 12314323.000000\n",
      "Train Epoch: 67 [496/918 (54%)] Loss: 15295493.000000\n",
      "Train Epoch: 67 [512/918 (56%)] Loss: 12502924.000000\n",
      "Train Epoch: 67 [528/918 (58%)] Loss: 13162277.000000\n",
      "Train Epoch: 67 [544/918 (59%)] Loss: 10175247.000000\n",
      "Train Epoch: 67 [560/918 (61%)] Loss: 15730167.000000\n",
      "Train Epoch: 67 [576/918 (63%)] Loss: 16658816.000000\n",
      "Train Epoch: 67 [592/918 (64%)] Loss: 9800632.000000\n",
      "Train Epoch: 67 [608/918 (66%)] Loss: 19901800.000000\n",
      "Train Epoch: 67 [624/918 (68%)] Loss: 11369983.000000\n",
      "Train Epoch: 67 [640/918 (70%)] Loss: 16811828.000000\n",
      "Train Epoch: 67 [656/918 (71%)] Loss: 11420131.000000\n",
      "Train Epoch: 67 [672/918 (73%)] Loss: 12010165.000000\n",
      "Train Epoch: 67 [688/918 (75%)] Loss: 13747043.000000\n",
      "Train Epoch: 67 [704/918 (77%)] Loss: 10539207.000000\n",
      "Train Epoch: 67 [720/918 (78%)] Loss: 14063927.000000\n",
      "Train Epoch: 67 [736/918 (80%)] Loss: 13193268.000000\n",
      "Train Epoch: 67 [752/918 (82%)] Loss: 13950555.000000\n",
      "Train Epoch: 67 [768/918 (84%)] Loss: 15291799.000000\n",
      "Train Epoch: 67 [784/918 (85%)] Loss: 10167370.000000\n",
      "Train Epoch: 67 [800/918 (87%)] Loss: 13931728.000000\n",
      "Train Epoch: 67 [816/918 (89%)] Loss: 15780245.000000\n",
      "Train Epoch: 67 [832/918 (91%)] Loss: 12996397.000000\n",
      "Train Epoch: 67 [848/918 (92%)] Loss: 12711461.000000\n",
      "Train Epoch: 67 [864/918 (94%)] Loss: 14139136.000000\n",
      "Train Epoch: 67 [880/918 (96%)] Loss: 12383276.000000\n",
      "Train Epoch: 67 [896/918 (98%)] Loss: 14415663.000000\n",
      "Train Epoch: 67 [912/918 (99%)] Loss: 14315810.000000\n",
      "    epoch          : 67\n",
      "    loss           : 13571793.87826087\n",
      "    ess            : 13.139462497959967\n",
      "    log_marginal   : -13571792.460869566\n",
      "    val_loss       : 12139061.384615384\n",
      "    val_ess        : 10.833952903747559\n",
      "    val_log_marginal: -12139059.923076924\n",
      "Train Epoch: 68 [0/918 (0%)] Loss: 13049578.000000\n",
      "Train Epoch: 68 [16/918 (2%)] Loss: 15893491.000000\n",
      "Train Epoch: 68 [32/918 (3%)] Loss: 10749633.000000\n",
      "Train Epoch: 68 [48/918 (5%)] Loss: 15107069.000000\n",
      "Train Epoch: 68 [64/918 (7%)] Loss: 13392400.000000\n",
      "Train Epoch: 68 [80/918 (9%)] Loss: 10965511.000000\n",
      "Train Epoch: 68 [96/918 (10%)] Loss: 13812368.000000\n",
      "Train Epoch: 68 [112/918 (12%)] Loss: 10074039.000000\n",
      "Train Epoch: 68 [128/918 (14%)] Loss: 18811724.000000\n",
      "Train Epoch: 68 [144/918 (16%)] Loss: 18264976.000000\n",
      "Train Epoch: 68 [160/918 (17%)] Loss: 10596356.000000\n",
      "Train Epoch: 68 [176/918 (19%)] Loss: 14636765.000000\n",
      "Train Epoch: 68 [192/918 (21%)] Loss: 14025672.000000\n",
      "Train Epoch: 68 [208/918 (23%)] Loss: 12097200.000000\n",
      "Train Epoch: 68 [224/918 (24%)] Loss: 9493272.000000\n",
      "Train Epoch: 68 [240/918 (26%)] Loss: 11732126.000000\n",
      "Train Epoch: 68 [256/918 (28%)] Loss: 10244146.000000\n",
      "Train Epoch: 68 [272/918 (30%)] Loss: 12203197.000000\n",
      "Train Epoch: 68 [288/918 (31%)] Loss: 12587477.000000\n",
      "Train Epoch: 68 [304/918 (33%)] Loss: 11143029.000000\n",
      "Train Epoch: 68 [320/918 (35%)] Loss: 20071722.000000\n",
      "Train Epoch: 68 [336/918 (37%)] Loss: 13468469.000000\n",
      "Train Epoch: 68 [352/918 (38%)] Loss: 11543879.000000\n",
      "Train Epoch: 68 [368/918 (40%)] Loss: 10037331.000000\n",
      "Train Epoch: 68 [384/918 (42%)] Loss: 11751705.000000\n",
      "Train Epoch: 68 [400/918 (44%)] Loss: 10719586.000000\n",
      "Train Epoch: 68 [416/918 (45%)] Loss: 13924179.000000\n",
      "Train Epoch: 68 [432/918 (47%)] Loss: 12005642.000000\n",
      "Train Epoch: 68 [448/918 (49%)] Loss: 14529669.000000\n",
      "Train Epoch: 68 [464/918 (51%)] Loss: 10181187.000000\n",
      "Train Epoch: 68 [480/918 (52%)] Loss: 14687085.000000\n",
      "Train Epoch: 68 [496/918 (54%)] Loss: 9650383.000000\n",
      "Train Epoch: 68 [512/918 (56%)] Loss: 10733727.000000\n",
      "Train Epoch: 68 [528/918 (58%)] Loss: 14237909.000000\n",
      "Train Epoch: 68 [544/918 (59%)] Loss: 16633365.000000\n",
      "Train Epoch: 68 [560/918 (61%)] Loss: 15264531.000000\n",
      "Train Epoch: 68 [576/918 (63%)] Loss: 16769613.000000\n",
      "Train Epoch: 68 [592/918 (64%)] Loss: 17450080.000000\n",
      "Train Epoch: 68 [608/918 (66%)] Loss: 11762750.000000\n",
      "Train Epoch: 68 [624/918 (68%)] Loss: 14871291.000000\n",
      "Train Epoch: 68 [640/918 (70%)] Loss: 13713229.000000\n",
      "Train Epoch: 68 [656/918 (71%)] Loss: 14522445.000000\n",
      "Train Epoch: 68 [672/918 (73%)] Loss: 15146563.000000\n",
      "Train Epoch: 68 [688/918 (75%)] Loss: 19537302.000000\n",
      "Train Epoch: 68 [704/918 (77%)] Loss: 15537219.000000\n",
      "Train Epoch: 68 [720/918 (78%)] Loss: 12567552.000000\n",
      "Train Epoch: 68 [736/918 (80%)] Loss: 12792563.000000\n",
      "Train Epoch: 68 [752/918 (82%)] Loss: 13368858.000000\n",
      "Train Epoch: 68 [768/918 (84%)] Loss: 11205513.000000\n",
      "Train Epoch: 68 [784/918 (85%)] Loss: 11097259.000000\n",
      "Train Epoch: 68 [800/918 (87%)] Loss: 13230402.000000\n",
      "Train Epoch: 68 [816/918 (89%)] Loss: 14979923.000000\n",
      "Train Epoch: 68 [832/918 (91%)] Loss: 11670691.000000\n",
      "Train Epoch: 68 [848/918 (92%)] Loss: 17081696.000000\n",
      "Train Epoch: 68 [864/918 (94%)] Loss: 11362979.000000\n",
      "Train Epoch: 68 [880/918 (96%)] Loss: 12223941.000000\n",
      "Train Epoch: 68 [896/918 (98%)] Loss: 10950079.000000\n",
      "Train Epoch: 68 [912/918 (99%)] Loss: 13737739.000000\n",
      "    epoch          : 68\n",
      "    loss           : 13394592.669565218\n",
      "    ess            : 13.211955406354821\n",
      "    log_marginal   : -13394591.017391304\n",
      "    val_loss       : 11601797.461538462\n",
      "    val_ess        : 11.658246737260084\n",
      "    val_log_marginal: -11601796.384615384\n",
      "Train Epoch: 69 [0/918 (0%)] Loss: 14331591.000000\n",
      "Train Epoch: 69 [16/918 (2%)] Loss: 17773072.000000\n",
      "Train Epoch: 69 [32/918 (3%)] Loss: 14574781.000000\n",
      "Train Epoch: 69 [48/918 (5%)] Loss: 14474608.000000\n",
      "Train Epoch: 69 [64/918 (7%)] Loss: 11940934.000000\n",
      "Train Epoch: 69 [80/918 (9%)] Loss: 15920167.000000\n",
      "Train Epoch: 69 [96/918 (10%)] Loss: 14743165.000000\n",
      "Train Epoch: 69 [112/918 (12%)] Loss: 15337485.000000\n",
      "Train Epoch: 69 [128/918 (14%)] Loss: 12611998.000000\n",
      "Train Epoch: 69 [144/918 (16%)] Loss: 14521267.000000\n",
      "Train Epoch: 69 [160/918 (17%)] Loss: 13514432.000000\n",
      "Train Epoch: 69 [176/918 (19%)] Loss: 14111143.000000\n",
      "Train Epoch: 69 [192/918 (21%)] Loss: 11580368.000000\n",
      "Train Epoch: 69 [208/918 (23%)] Loss: 15362200.000000\n",
      "Train Epoch: 69 [224/918 (24%)] Loss: 11299431.000000\n",
      "Train Epoch: 69 [240/918 (26%)] Loss: 16518842.000000\n",
      "Train Epoch: 69 [256/918 (28%)] Loss: 14735053.000000\n",
      "Train Epoch: 69 [272/918 (30%)] Loss: 13448803.000000\n",
      "Train Epoch: 69 [288/918 (31%)] Loss: 12604470.000000\n",
      "Train Epoch: 69 [304/918 (33%)] Loss: 11551374.000000\n",
      "Train Epoch: 69 [320/918 (35%)] Loss: 13471143.000000\n",
      "Train Epoch: 69 [336/918 (37%)] Loss: 11381538.000000\n",
      "Train Epoch: 69 [352/918 (38%)] Loss: 12536139.000000\n",
      "Train Epoch: 69 [368/918 (40%)] Loss: 14037819.000000\n",
      "Train Epoch: 69 [384/918 (42%)] Loss: 13002536.000000\n",
      "Train Epoch: 69 [400/918 (44%)] Loss: 11538811.000000\n",
      "Train Epoch: 69 [416/918 (45%)] Loss: 15728931.000000\n",
      "Train Epoch: 69 [432/918 (47%)] Loss: 9582142.000000\n",
      "Train Epoch: 69 [448/918 (49%)] Loss: 12500929.000000\n",
      "Train Epoch: 69 [464/918 (51%)] Loss: 14690099.000000\n",
      "Train Epoch: 69 [480/918 (52%)] Loss: 13506584.000000\n",
      "Train Epoch: 69 [496/918 (54%)] Loss: 18606776.000000\n",
      "Train Epoch: 69 [512/918 (56%)] Loss: 11738256.000000\n",
      "Train Epoch: 69 [528/918 (58%)] Loss: 15714471.000000\n",
      "Train Epoch: 69 [544/918 (59%)] Loss: 18657400.000000\n",
      "Train Epoch: 69 [560/918 (61%)] Loss: 10190645.000000\n",
      "Train Epoch: 69 [576/918 (63%)] Loss: 10630861.000000\n",
      "Train Epoch: 69 [592/918 (64%)] Loss: 12620114.000000\n",
      "Train Epoch: 69 [608/918 (66%)] Loss: 14823904.000000\n",
      "Train Epoch: 69 [624/918 (68%)] Loss: 11167263.000000\n",
      "Train Epoch: 69 [640/918 (70%)] Loss: 9746371.000000\n",
      "Train Epoch: 69 [656/918 (71%)] Loss: 16542981.000000\n",
      "Train Epoch: 69 [672/918 (73%)] Loss: 13091048.000000\n",
      "Train Epoch: 69 [688/918 (75%)] Loss: 15239373.000000\n",
      "Train Epoch: 69 [704/918 (77%)] Loss: 15949370.000000\n",
      "Train Epoch: 69 [720/918 (78%)] Loss: 13095056.000000\n",
      "Train Epoch: 69 [736/918 (80%)] Loss: 10216804.000000\n",
      "Train Epoch: 69 [752/918 (82%)] Loss: 11465568.000000\n",
      "Train Epoch: 69 [768/918 (84%)] Loss: 11117775.000000\n",
      "Train Epoch: 69 [784/918 (85%)] Loss: 13834775.000000\n",
      "Train Epoch: 69 [800/918 (87%)] Loss: 15418003.000000\n",
      "Train Epoch: 69 [816/918 (89%)] Loss: 11651326.000000\n",
      "Train Epoch: 69 [832/918 (91%)] Loss: 10280019.000000\n",
      "Train Epoch: 69 [848/918 (92%)] Loss: 11864107.000000\n",
      "Train Epoch: 69 [864/918 (94%)] Loss: 12295752.000000\n",
      "Train Epoch: 69 [880/918 (96%)] Loss: 16079283.000000\n",
      "Train Epoch: 69 [896/918 (98%)] Loss: 12657697.000000\n",
      "Train Epoch: 69 [912/918 (99%)] Loss: 12114396.000000\n",
      "    epoch          : 69\n",
      "    loss           : 13265180.452173913\n",
      "    ess            : 13.443186457260795\n",
      "    log_marginal   : -13265179.117391305\n",
      "    val_loss       : 12735278.692307692\n",
      "    val_ess        : 12.816557003901554\n",
      "    val_log_marginal: -12735277.23076923\n",
      "Train Epoch: 70 [0/918 (0%)] Loss: 11388446.000000\n",
      "Train Epoch: 70 [16/918 (2%)] Loss: 10806944.000000\n",
      "Train Epoch: 70 [32/918 (3%)] Loss: 12114891.000000\n",
      "Train Epoch: 70 [48/918 (5%)] Loss: 15388631.000000\n",
      "Train Epoch: 70 [64/918 (7%)] Loss: 14578234.000000\n",
      "Train Epoch: 70 [80/918 (9%)] Loss: 13926659.000000\n",
      "Train Epoch: 70 [96/918 (10%)] Loss: 12950240.000000\n",
      "Train Epoch: 70 [112/918 (12%)] Loss: 11207568.000000\n",
      "Train Epoch: 70 [128/918 (14%)] Loss: 12496999.000000\n",
      "Train Epoch: 70 [144/918 (16%)] Loss: 15844245.000000\n",
      "Train Epoch: 70 [160/918 (17%)] Loss: 9590948.000000\n",
      "Train Epoch: 70 [176/918 (19%)] Loss: 12722659.000000\n",
      "Train Epoch: 70 [192/918 (21%)] Loss: 15643675.000000\n",
      "Train Epoch: 70 [208/918 (23%)] Loss: 14838027.000000\n",
      "Train Epoch: 70 [224/918 (24%)] Loss: 16470896.000000\n",
      "Train Epoch: 70 [240/918 (26%)] Loss: 11706207.000000\n",
      "Train Epoch: 70 [256/918 (28%)] Loss: 13538835.000000\n",
      "Train Epoch: 70 [272/918 (30%)] Loss: 13721984.000000\n",
      "Train Epoch: 70 [288/918 (31%)] Loss: 9564962.000000\n",
      "Train Epoch: 70 [304/918 (33%)] Loss: 10799799.000000\n",
      "Train Epoch: 70 [320/918 (35%)] Loss: 10526767.000000\n",
      "Train Epoch: 70 [336/918 (37%)] Loss: 16630637.000000\n",
      "Train Epoch: 70 [352/918 (38%)] Loss: 18597840.000000\n",
      "Train Epoch: 70 [368/918 (40%)] Loss: 13023655.000000\n",
      "Train Epoch: 70 [384/918 (42%)] Loss: 11353986.000000\n",
      "Train Epoch: 70 [400/918 (44%)] Loss: 12905556.000000\n",
      "Train Epoch: 70 [416/918 (45%)] Loss: 11728677.000000\n",
      "Train Epoch: 70 [432/918 (47%)] Loss: 10283910.000000\n",
      "Train Epoch: 70 [448/918 (49%)] Loss: 8579715.000000\n",
      "Train Epoch: 70 [464/918 (51%)] Loss: 15309279.000000\n",
      "Train Epoch: 70 [480/918 (52%)] Loss: 11790931.000000\n",
      "Train Epoch: 70 [496/918 (54%)] Loss: 15359903.000000\n",
      "Train Epoch: 70 [512/918 (56%)] Loss: 12290237.000000\n",
      "Train Epoch: 70 [528/918 (58%)] Loss: 18415174.000000\n",
      "Train Epoch: 70 [544/918 (59%)] Loss: 12694967.000000\n",
      "Train Epoch: 70 [560/918 (61%)] Loss: 13701443.000000\n",
      "Train Epoch: 70 [576/918 (63%)] Loss: 11090565.000000\n",
      "Train Epoch: 70 [592/918 (64%)] Loss: 10255698.000000\n",
      "Train Epoch: 70 [608/918 (66%)] Loss: 10877082.000000\n",
      "Train Epoch: 70 [624/918 (68%)] Loss: 16560207.000000\n",
      "Train Epoch: 70 [640/918 (70%)] Loss: 12793199.000000\n",
      "Train Epoch: 70 [656/918 (71%)] Loss: 10507991.000000\n",
      "Train Epoch: 70 [672/918 (73%)] Loss: 14867187.000000\n",
      "Train Epoch: 70 [688/918 (75%)] Loss: 12531363.000000\n",
      "Train Epoch: 70 [704/918 (77%)] Loss: 13479541.000000\n",
      "Train Epoch: 70 [720/918 (78%)] Loss: 14760325.000000\n",
      "Train Epoch: 70 [736/918 (80%)] Loss: 14119354.000000\n",
      "Train Epoch: 70 [752/918 (82%)] Loss: 18155238.000000\n",
      "Train Epoch: 70 [768/918 (84%)] Loss: 9794870.000000\n",
      "Train Epoch: 70 [784/918 (85%)] Loss: 13492264.000000\n",
      "Train Epoch: 70 [800/918 (87%)] Loss: 15687085.000000\n",
      "Train Epoch: 70 [816/918 (89%)] Loss: 12383131.000000\n",
      "Train Epoch: 70 [832/918 (91%)] Loss: 10994079.000000\n",
      "Train Epoch: 70 [848/918 (92%)] Loss: 15309512.000000\n",
      "Train Epoch: 70 [864/918 (94%)] Loss: 14202826.000000\n",
      "Train Epoch: 70 [880/918 (96%)] Loss: 17241344.000000\n",
      "Train Epoch: 70 [896/918 (98%)] Loss: 13476109.000000\n",
      "Train Epoch: 70 [912/918 (99%)] Loss: 10895479.000000\n",
      "    epoch          : 70\n",
      "    loss           : 13127464.208695652\n",
      "    ess            : 12.795057562123175\n",
      "    log_marginal   : -13127462.834782608\n",
      "    val_loss       : 11739843.538461538\n",
      "    val_ess        : 11.568424224853516\n",
      "    val_log_marginal: -11739840.538461538\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch70.pth ...\n",
      "Train Epoch: 71 [0/918 (0%)] Loss: 12974332.000000\n",
      "Train Epoch: 71 [16/918 (2%)] Loss: 12360314.000000\n",
      "Train Epoch: 71 [32/918 (3%)] Loss: 13351396.000000\n",
      "Train Epoch: 71 [48/918 (5%)] Loss: 12326747.000000\n",
      "Train Epoch: 71 [64/918 (7%)] Loss: 12436213.000000\n",
      "Train Epoch: 71 [80/918 (9%)] Loss: 12522806.000000\n",
      "Train Epoch: 71 [96/918 (10%)] Loss: 9646282.000000\n",
      "Train Epoch: 71 [112/918 (12%)] Loss: 17711220.000000\n",
      "Train Epoch: 71 [128/918 (14%)] Loss: 14919002.000000\n",
      "Train Epoch: 71 [144/918 (16%)] Loss: 15355509.000000\n",
      "Train Epoch: 71 [160/918 (17%)] Loss: 12893111.000000\n",
      "Train Epoch: 71 [176/918 (19%)] Loss: 15494746.000000\n",
      "Train Epoch: 71 [192/918 (21%)] Loss: 14363496.000000\n",
      "Train Epoch: 71 [208/918 (23%)] Loss: 13695485.000000\n",
      "Train Epoch: 71 [224/918 (24%)] Loss: 17561604.000000\n",
      "Train Epoch: 71 [240/918 (26%)] Loss: 13301397.000000\n",
      "Train Epoch: 71 [256/918 (28%)] Loss: 15280605.000000\n",
      "Train Epoch: 71 [272/918 (30%)] Loss: 16227968.000000\n",
      "Train Epoch: 71 [288/918 (31%)] Loss: 10624368.000000\n",
      "Train Epoch: 71 [304/918 (33%)] Loss: 13255934.000000\n",
      "Train Epoch: 71 [320/918 (35%)] Loss: 14963211.000000\n",
      "Train Epoch: 71 [336/918 (37%)] Loss: 12827394.000000\n",
      "Train Epoch: 71 [352/918 (38%)] Loss: 15372298.000000\n",
      "Train Epoch: 71 [368/918 (40%)] Loss: 12657862.000000\n",
      "Train Epoch: 71 [384/918 (42%)] Loss: 10483084.000000\n",
      "Train Epoch: 71 [400/918 (44%)] Loss: 17422186.000000\n",
      "Train Epoch: 71 [416/918 (45%)] Loss: 14097114.000000\n",
      "Train Epoch: 71 [432/918 (47%)] Loss: 10503232.000000\n",
      "Train Epoch: 71 [448/918 (49%)] Loss: 16348970.000000\n",
      "Train Epoch: 71 [464/918 (51%)] Loss: 13850283.000000\n",
      "Train Epoch: 71 [480/918 (52%)] Loss: 10697020.000000\n",
      "Train Epoch: 71 [496/918 (54%)] Loss: 11779003.000000\n",
      "Train Epoch: 71 [512/918 (56%)] Loss: 12249952.000000\n",
      "Train Epoch: 71 [528/918 (58%)] Loss: 10082882.000000\n",
      "Train Epoch: 71 [544/918 (59%)] Loss: 19755134.000000\n",
      "Train Epoch: 71 [560/918 (61%)] Loss: 13600688.000000\n",
      "Train Epoch: 71 [576/918 (63%)] Loss: 11522644.000000\n",
      "Train Epoch: 71 [592/918 (64%)] Loss: 10202245.000000\n",
      "Train Epoch: 71 [608/918 (66%)] Loss: 14266419.000000\n",
      "Train Epoch: 71 [624/918 (68%)] Loss: 12923909.000000\n",
      "Train Epoch: 71 [640/918 (70%)] Loss: 11565076.000000\n",
      "Train Epoch: 71 [656/918 (71%)] Loss: 12826194.000000\n",
      "Train Epoch: 71 [672/918 (73%)] Loss: 12471903.000000\n",
      "Train Epoch: 71 [688/918 (75%)] Loss: 21274762.000000\n",
      "Train Epoch: 71 [704/918 (77%)] Loss: 12880475.000000\n",
      "Train Epoch: 71 [720/918 (78%)] Loss: 13381965.000000\n",
      "Train Epoch: 71 [736/918 (80%)] Loss: 12067042.000000\n",
      "Train Epoch: 71 [752/918 (82%)] Loss: 13116024.000000\n",
      "Train Epoch: 71 [768/918 (84%)] Loss: 10670167.000000\n",
      "Train Epoch: 71 [784/918 (85%)] Loss: 13241683.000000\n",
      "Train Epoch: 71 [800/918 (87%)] Loss: 12223484.000000\n",
      "Train Epoch: 71 [816/918 (89%)] Loss: 11668402.000000\n",
      "Train Epoch: 71 [832/918 (91%)] Loss: 14944775.000000\n",
      "Train Epoch: 71 [848/918 (92%)] Loss: 11607316.000000\n",
      "Train Epoch: 71 [864/918 (94%)] Loss: 11517683.000000\n",
      "Train Epoch: 71 [880/918 (96%)] Loss: 15444797.000000\n",
      "Train Epoch: 71 [896/918 (98%)] Loss: 11205805.000000\n",
      "Train Epoch: 71 [912/918 (99%)] Loss: 18286590.000000\n",
      "    epoch          : 71\n",
      "    loss           : 13272594.313043479\n",
      "    ess            : 12.73170985760896\n",
      "    log_marginal   : -13272592.539130434\n",
      "    val_loss       : 11746129.0\n",
      "    val_ess        : 11.777702001424936\n",
      "    val_log_marginal: -11746128.384615384\n",
      "Train Epoch: 72 [0/918 (0%)] Loss: 18423734.000000\n",
      "Train Epoch: 72 [16/918 (2%)] Loss: 13727664.000000\n",
      "Train Epoch: 72 [32/918 (3%)] Loss: 13693607.000000\n",
      "Train Epoch: 72 [48/918 (5%)] Loss: 10447283.000000\n",
      "Train Epoch: 72 [64/918 (7%)] Loss: 11518731.000000\n",
      "Train Epoch: 72 [80/918 (9%)] Loss: 10924205.000000\n",
      "Train Epoch: 72 [96/918 (10%)] Loss: 10427468.000000\n",
      "Train Epoch: 72 [112/918 (12%)] Loss: 13060094.000000\n",
      "Train Epoch: 72 [128/918 (14%)] Loss: 15260887.000000\n",
      "Train Epoch: 72 [144/918 (16%)] Loss: 12790394.000000\n",
      "Train Epoch: 72 [160/918 (17%)] Loss: 15368080.000000\n",
      "Train Epoch: 72 [176/918 (19%)] Loss: 16878910.000000\n",
      "Train Epoch: 72 [192/918 (21%)] Loss: 20638566.000000\n",
      "Train Epoch: 72 [208/918 (23%)] Loss: 14618424.000000\n",
      "Train Epoch: 72 [224/918 (24%)] Loss: 10094430.000000\n",
      "Train Epoch: 72 [240/918 (26%)] Loss: 11927059.000000\n",
      "Train Epoch: 72 [256/918 (28%)] Loss: 15586599.000000\n",
      "Train Epoch: 72 [272/918 (30%)] Loss: 13933363.000000\n",
      "Train Epoch: 72 [288/918 (31%)] Loss: 11265999.000000\n",
      "Train Epoch: 72 [304/918 (33%)] Loss: 17474992.000000\n",
      "Train Epoch: 72 [320/918 (35%)] Loss: 14877917.000000\n",
      "Train Epoch: 72 [336/918 (37%)] Loss: 13110814.000000\n",
      "Train Epoch: 72 [352/918 (38%)] Loss: 12156476.000000\n",
      "Train Epoch: 72 [368/918 (40%)] Loss: 10771104.000000\n",
      "Train Epoch: 72 [384/918 (42%)] Loss: 18485118.000000\n",
      "Train Epoch: 72 [400/918 (44%)] Loss: 13342669.000000\n",
      "Train Epoch: 72 [416/918 (45%)] Loss: 14900775.000000\n",
      "Train Epoch: 72 [432/918 (47%)] Loss: 13357999.000000\n",
      "Train Epoch: 72 [448/918 (49%)] Loss: 15545544.000000\n",
      "Train Epoch: 72 [464/918 (51%)] Loss: 16555880.000000\n",
      "Train Epoch: 72 [480/918 (52%)] Loss: 14337989.000000\n",
      "Train Epoch: 72 [496/918 (54%)] Loss: 12739455.000000\n",
      "Train Epoch: 72 [512/918 (56%)] Loss: 12435430.000000\n",
      "Train Epoch: 72 [528/918 (58%)] Loss: 17396596.000000\n",
      "Train Epoch: 72 [544/918 (59%)] Loss: 13693336.000000\n",
      "Train Epoch: 72 [560/918 (61%)] Loss: 9275960.000000\n",
      "Train Epoch: 72 [576/918 (63%)] Loss: 11476331.000000\n",
      "Train Epoch: 72 [592/918 (64%)] Loss: 12646040.000000\n",
      "Train Epoch: 72 [608/918 (66%)] Loss: 13714698.000000\n",
      "Train Epoch: 72 [624/918 (68%)] Loss: 13079681.000000\n",
      "Train Epoch: 72 [640/918 (70%)] Loss: 11082791.000000\n",
      "Train Epoch: 72 [656/918 (71%)] Loss: 15551880.000000\n",
      "Train Epoch: 72 [672/918 (73%)] Loss: 14656578.000000\n",
      "Train Epoch: 72 [688/918 (75%)] Loss: 10059851.000000\n",
      "Train Epoch: 72 [704/918 (77%)] Loss: 10229314.000000\n",
      "Train Epoch: 72 [720/918 (78%)] Loss: 14817386.000000\n",
      "Train Epoch: 72 [736/918 (80%)] Loss: 11152670.000000\n",
      "Train Epoch: 72 [752/918 (82%)] Loss: 13680773.000000\n",
      "Train Epoch: 72 [768/918 (84%)] Loss: 14071245.000000\n",
      "Train Epoch: 72 [784/918 (85%)] Loss: 12587880.000000\n",
      "Train Epoch: 72 [800/918 (87%)] Loss: 11882123.000000\n",
      "Train Epoch: 72 [816/918 (89%)] Loss: 15675112.000000\n",
      "Train Epoch: 72 [832/918 (91%)] Loss: 8955411.000000\n",
      "Train Epoch: 72 [848/918 (92%)] Loss: 12988507.000000\n",
      "Train Epoch: 72 [864/918 (94%)] Loss: 15271680.000000\n",
      "Train Epoch: 72 [880/918 (96%)] Loss: 10678872.000000\n",
      "Train Epoch: 72 [896/918 (98%)] Loss: 11707441.000000\n",
      "Train Epoch: 72 [912/918 (99%)] Loss: 15319994.000000\n",
      "    epoch          : 72\n",
      "    loss           : 13090415.069565218\n",
      "    ess            : 11.765290525685186\n",
      "    log_marginal   : -13090413.573913043\n",
      "    val_loss       : 11603873.0\n",
      "    val_ess        : 10.590624167368961\n",
      "    val_log_marginal: -11603870.076923076\n",
      "Train Epoch: 73 [0/918 (0%)] Loss: 15884349.000000\n",
      "Train Epoch: 73 [16/918 (2%)] Loss: 11540739.000000\n",
      "Train Epoch: 73 [32/918 (3%)] Loss: 10038491.000000\n",
      "Train Epoch: 73 [48/918 (5%)] Loss: 16266467.000000\n",
      "Train Epoch: 73 [64/918 (7%)] Loss: 14376288.000000\n",
      "Train Epoch: 73 [80/918 (9%)] Loss: 14033338.000000\n",
      "Train Epoch: 73 [96/918 (10%)] Loss: 15819619.000000\n",
      "Train Epoch: 73 [112/918 (12%)] Loss: 14187159.000000\n",
      "Train Epoch: 73 [128/918 (14%)] Loss: 11580397.000000\n",
      "Train Epoch: 73 [144/918 (16%)] Loss: 16207967.000000\n",
      "Train Epoch: 73 [160/918 (17%)] Loss: 14002464.000000\n",
      "Train Epoch: 73 [176/918 (19%)] Loss: 10848728.000000\n",
      "Train Epoch: 73 [192/918 (21%)] Loss: 12303104.000000\n",
      "Train Epoch: 73 [208/918 (23%)] Loss: 11412374.000000\n",
      "Train Epoch: 73 [224/918 (24%)] Loss: 11870251.000000\n",
      "Train Epoch: 73 [240/918 (26%)] Loss: 14425197.000000\n",
      "Train Epoch: 73 [256/918 (28%)] Loss: 15012013.000000\n",
      "Train Epoch: 73 [272/918 (30%)] Loss: 15057474.000000\n",
      "Train Epoch: 73 [288/918 (31%)] Loss: 17235204.000000\n",
      "Train Epoch: 73 [304/918 (33%)] Loss: 9494487.000000\n",
      "Train Epoch: 73 [320/918 (35%)] Loss: 9204082.000000\n",
      "Train Epoch: 73 [336/918 (37%)] Loss: 15033837.000000\n",
      "Train Epoch: 73 [352/918 (38%)] Loss: 11590158.000000\n",
      "Train Epoch: 73 [368/918 (40%)] Loss: 9628135.000000\n",
      "Train Epoch: 73 [384/918 (42%)] Loss: 13866019.000000\n",
      "Train Epoch: 73 [400/918 (44%)] Loss: 13769240.000000\n",
      "Train Epoch: 73 [416/918 (45%)] Loss: 12116277.000000\n",
      "Train Epoch: 73 [432/918 (47%)] Loss: 15318269.000000\n",
      "Train Epoch: 73 [448/918 (49%)] Loss: 10325240.000000\n",
      "Train Epoch: 73 [464/918 (51%)] Loss: 14331043.000000\n",
      "Train Epoch: 73 [480/918 (52%)] Loss: 11818182.000000\n",
      "Train Epoch: 73 [496/918 (54%)] Loss: 16222698.000000\n",
      "Train Epoch: 73 [512/918 (56%)] Loss: 8901547.000000\n",
      "Train Epoch: 73 [528/918 (58%)] Loss: 15418451.000000\n",
      "Train Epoch: 73 [544/918 (59%)] Loss: 9361792.000000\n",
      "Train Epoch: 73 [560/918 (61%)] Loss: 11208105.000000\n",
      "Train Epoch: 73 [576/918 (63%)] Loss: 16259368.000000\n",
      "Train Epoch: 73 [592/918 (64%)] Loss: 12528011.000000\n",
      "Train Epoch: 73 [608/918 (66%)] Loss: 11152820.000000\n",
      "Train Epoch: 73 [624/918 (68%)] Loss: 13620691.000000\n",
      "Train Epoch: 73 [640/918 (70%)] Loss: 9262328.000000\n",
      "Train Epoch: 73 [656/918 (71%)] Loss: 11702739.000000\n",
      "Train Epoch: 73 [672/918 (73%)] Loss: 13301520.000000\n",
      "Train Epoch: 73 [688/918 (75%)] Loss: 13948320.000000\n",
      "Train Epoch: 73 [704/918 (77%)] Loss: 10126192.000000\n",
      "Train Epoch: 73 [720/918 (78%)] Loss: 11556447.000000\n",
      "Train Epoch: 73 [736/918 (80%)] Loss: 11175920.000000\n",
      "Train Epoch: 73 [752/918 (82%)] Loss: 11170825.000000\n",
      "Train Epoch: 73 [768/918 (84%)] Loss: 14023843.000000\n",
      "Train Epoch: 73 [784/918 (85%)] Loss: 16267560.000000\n",
      "Train Epoch: 73 [800/918 (87%)] Loss: 9213577.000000\n",
      "Train Epoch: 73 [816/918 (89%)] Loss: 15587997.000000\n",
      "Train Epoch: 73 [832/918 (91%)] Loss: 16859914.000000\n",
      "Train Epoch: 73 [848/918 (92%)] Loss: 21283780.000000\n",
      "Train Epoch: 73 [864/918 (94%)] Loss: 10556403.000000\n",
      "Train Epoch: 73 [880/918 (96%)] Loss: 17866564.000000\n",
      "Train Epoch: 73 [896/918 (98%)] Loss: 13126483.000000\n",
      "Train Epoch: 73 [912/918 (99%)] Loss: 11081291.000000\n",
      "    epoch          : 73\n",
      "    loss           : 12795115.365217391\n",
      "    ess            : 11.650798778948577\n",
      "    log_marginal   : -12795112.973913044\n",
      "    val_loss       : 11158492.76923077\n",
      "    val_ess        : 11.796028137207031\n",
      "    val_log_marginal: -11158491.76923077\n",
      "Train Epoch: 74 [0/918 (0%)] Loss: 14296419.000000\n",
      "Train Epoch: 74 [16/918 (2%)] Loss: 10724835.000000\n",
      "Train Epoch: 74 [32/918 (3%)] Loss: 12949576.000000\n",
      "Train Epoch: 74 [48/918 (5%)] Loss: 13538392.000000\n",
      "Train Epoch: 74 [64/918 (7%)] Loss: 10028218.000000\n",
      "Train Epoch: 74 [80/918 (9%)] Loss: 15047267.000000\n",
      "Train Epoch: 74 [96/918 (10%)] Loss: 12691092.000000\n",
      "Train Epoch: 74 [112/918 (12%)] Loss: 15405767.000000\n",
      "Train Epoch: 74 [128/918 (14%)] Loss: 12398440.000000\n",
      "Train Epoch: 74 [144/918 (16%)] Loss: 12095719.000000\n",
      "Train Epoch: 74 [160/918 (17%)] Loss: 10568411.000000\n",
      "Train Epoch: 74 [176/918 (19%)] Loss: 10184563.000000\n",
      "Train Epoch: 74 [192/918 (21%)] Loss: 8352294.500000\n",
      "Train Epoch: 74 [208/918 (23%)] Loss: 9284765.000000\n",
      "Train Epoch: 74 [224/918 (24%)] Loss: 12473024.000000\n",
      "Train Epoch: 74 [240/918 (26%)] Loss: 10481578.000000\n",
      "Train Epoch: 74 [256/918 (28%)] Loss: 10850420.000000\n",
      "Train Epoch: 74 [272/918 (30%)] Loss: 11345997.000000\n",
      "Train Epoch: 74 [288/918 (31%)] Loss: 11901882.000000\n",
      "Train Epoch: 74 [304/918 (33%)] Loss: 13021768.000000\n",
      "Train Epoch: 74 [320/918 (35%)] Loss: 14948016.000000\n",
      "Train Epoch: 74 [336/918 (37%)] Loss: 9790189.000000\n",
      "Train Epoch: 74 [352/918 (38%)] Loss: 10861101.000000\n",
      "Train Epoch: 74 [368/918 (40%)] Loss: 12014712.000000\n",
      "Train Epoch: 74 [384/918 (42%)] Loss: 17339118.000000\n",
      "Train Epoch: 74 [400/918 (44%)] Loss: 11268840.000000\n",
      "Train Epoch: 74 [416/918 (45%)] Loss: 17487172.000000\n",
      "Train Epoch: 74 [432/918 (47%)] Loss: 13342531.000000\n",
      "Train Epoch: 74 [448/918 (49%)] Loss: 15602349.000000\n",
      "Train Epoch: 74 [464/918 (51%)] Loss: 11773224.000000\n",
      "Train Epoch: 74 [480/918 (52%)] Loss: 10627629.000000\n",
      "Train Epoch: 74 [496/918 (54%)] Loss: 9899320.000000\n",
      "Train Epoch: 74 [512/918 (56%)] Loss: 9480936.000000\n",
      "Train Epoch: 74 [528/918 (58%)] Loss: 10540967.000000\n",
      "Train Epoch: 74 [544/918 (59%)] Loss: 15234499.000000\n",
      "Train Epoch: 74 [560/918 (61%)] Loss: 16322954.000000\n",
      "Train Epoch: 74 [576/918 (63%)] Loss: 21246254.000000\n",
      "Train Epoch: 74 [592/918 (64%)] Loss: 16038973.000000\n",
      "Train Epoch: 74 [608/918 (66%)] Loss: 11587085.000000\n",
      "Train Epoch: 74 [624/918 (68%)] Loss: 14571264.000000\n",
      "Train Epoch: 74 [640/918 (70%)] Loss: 14171738.000000\n",
      "Train Epoch: 74 [656/918 (71%)] Loss: 18249072.000000\n",
      "Train Epoch: 74 [672/918 (73%)] Loss: 13671634.000000\n",
      "Train Epoch: 74 [688/918 (75%)] Loss: 12703723.000000\n",
      "Train Epoch: 74 [704/918 (77%)] Loss: 15226493.000000\n",
      "Train Epoch: 74 [720/918 (78%)] Loss: 12249752.000000\n",
      "Train Epoch: 74 [736/918 (80%)] Loss: 15280659.000000\n",
      "Train Epoch: 74 [752/918 (82%)] Loss: 12740568.000000\n",
      "Train Epoch: 74 [768/918 (84%)] Loss: 10628796.000000\n",
      "Train Epoch: 74 [784/918 (85%)] Loss: 13492259.000000\n",
      "Train Epoch: 74 [800/918 (87%)] Loss: 11411603.000000\n",
      "Train Epoch: 74 [816/918 (89%)] Loss: 11688509.000000\n",
      "Train Epoch: 74 [832/918 (91%)] Loss: 13620173.000000\n",
      "Train Epoch: 74 [848/918 (92%)] Loss: 12524499.000000\n",
      "Train Epoch: 74 [864/918 (94%)] Loss: 9133695.000000\n",
      "Train Epoch: 74 [880/918 (96%)] Loss: 14209323.000000\n",
      "Train Epoch: 74 [896/918 (98%)] Loss: 11622128.000000\n",
      "Train Epoch: 74 [912/918 (99%)] Loss: 12944532.000000\n",
      "    epoch          : 74\n",
      "    loss           : 12785165.491304347\n",
      "    ess            : 12.734691317185112\n",
      "    log_marginal   : -12785164.408695653\n",
      "    val_loss       : 11482530.923076924\n",
      "    val_ess        : 10.181238376177275\n",
      "    val_log_marginal: -11482529.76923077\n",
      "Train Epoch: 75 [0/918 (0%)] Loss: 13505301.000000\n",
      "Train Epoch: 75 [16/918 (2%)] Loss: 16602712.000000\n",
      "Train Epoch: 75 [32/918 (3%)] Loss: 13717619.000000\n",
      "Train Epoch: 75 [48/918 (5%)] Loss: 10323653.000000\n",
      "Train Epoch: 75 [64/918 (7%)] Loss: 14058519.000000\n",
      "Train Epoch: 75 [80/918 (9%)] Loss: 9532239.000000\n",
      "Train Epoch: 75 [96/918 (10%)] Loss: 15683611.000000\n",
      "Train Epoch: 75 [112/918 (12%)] Loss: 14160602.000000\n",
      "Train Epoch: 75 [128/918 (14%)] Loss: 9961871.000000\n",
      "Train Epoch: 75 [144/918 (16%)] Loss: 13379673.000000\n",
      "Train Epoch: 75 [160/918 (17%)] Loss: 15848845.000000\n",
      "Train Epoch: 75 [176/918 (19%)] Loss: 12012216.000000\n",
      "Train Epoch: 75 [192/918 (21%)] Loss: 11062917.000000\n",
      "Train Epoch: 75 [208/918 (23%)] Loss: 12092875.000000\n",
      "Train Epoch: 75 [224/918 (24%)] Loss: 13359988.000000\n",
      "Train Epoch: 75 [240/918 (26%)] Loss: 11765800.000000\n",
      "Train Epoch: 75 [256/918 (28%)] Loss: 14344829.000000\n",
      "Train Epoch: 75 [272/918 (30%)] Loss: 12115196.000000\n",
      "Train Epoch: 75 [288/918 (31%)] Loss: 15184970.000000\n",
      "Train Epoch: 75 [304/918 (33%)] Loss: 11478540.000000\n",
      "Train Epoch: 75 [320/918 (35%)] Loss: 12663315.000000\n",
      "Train Epoch: 75 [336/918 (37%)] Loss: 12587789.000000\n",
      "Train Epoch: 75 [352/918 (38%)] Loss: 11972943.000000\n",
      "Train Epoch: 75 [368/918 (40%)] Loss: 21183560.000000\n",
      "Train Epoch: 75 [384/918 (42%)] Loss: 12298539.000000\n",
      "Train Epoch: 75 [400/918 (44%)] Loss: 11080013.000000\n",
      "Train Epoch: 75 [416/918 (45%)] Loss: 10048538.000000\n",
      "Train Epoch: 75 [432/918 (47%)] Loss: 15852626.000000\n",
      "Train Epoch: 75 [448/918 (49%)] Loss: 18534456.000000\n",
      "Train Epoch: 75 [464/918 (51%)] Loss: 10330073.000000\n",
      "Train Epoch: 75 [480/918 (52%)] Loss: 11853987.000000\n",
      "Train Epoch: 75 [496/918 (54%)] Loss: 18023044.000000\n",
      "Train Epoch: 75 [512/918 (56%)] Loss: 13324699.000000\n",
      "Train Epoch: 75 [528/918 (58%)] Loss: 12645048.000000\n",
      "Train Epoch: 75 [544/918 (59%)] Loss: 10880697.000000\n",
      "Train Epoch: 75 [560/918 (61%)] Loss: 13975383.000000\n",
      "Train Epoch: 75 [576/918 (63%)] Loss: 8516572.000000\n",
      "Train Epoch: 75 [592/918 (64%)] Loss: 10720105.000000\n",
      "Train Epoch: 75 [608/918 (66%)] Loss: 12057297.000000\n",
      "Train Epoch: 75 [624/918 (68%)] Loss: 10899862.000000\n",
      "Train Epoch: 75 [640/918 (70%)] Loss: 13439339.000000\n",
      "Train Epoch: 75 [656/918 (71%)] Loss: 11415154.000000\n",
      "Train Epoch: 75 [672/918 (73%)] Loss: 14623621.000000\n",
      "Train Epoch: 75 [688/918 (75%)] Loss: 15185962.000000\n",
      "Train Epoch: 75 [704/918 (77%)] Loss: 8913136.000000\n",
      "Train Epoch: 75 [720/918 (78%)] Loss: 9863350.000000\n",
      "Train Epoch: 75 [736/918 (80%)] Loss: 8771501.000000\n",
      "Train Epoch: 75 [752/918 (82%)] Loss: 10168496.000000\n",
      "Train Epoch: 75 [768/918 (84%)] Loss: 9332926.000000\n",
      "Train Epoch: 75 [784/918 (85%)] Loss: 11145102.000000\n",
      "Train Epoch: 75 [800/918 (87%)] Loss: 9965539.000000\n",
      "Train Epoch: 75 [816/918 (89%)] Loss: 12127150.000000\n",
      "Train Epoch: 75 [832/918 (91%)] Loss: 8204552.000000\n",
      "Train Epoch: 75 [848/918 (92%)] Loss: 10769624.000000\n",
      "Train Epoch: 75 [864/918 (94%)] Loss: 14423181.000000\n",
      "Train Epoch: 75 [880/918 (96%)] Loss: 13091738.000000\n",
      "Train Epoch: 75 [896/918 (98%)] Loss: 14554143.000000\n",
      "Train Epoch: 75 [912/918 (99%)] Loss: 9791864.000000\n",
      "    epoch          : 75\n",
      "    loss           : 12530214.082608696\n",
      "    ess            : 11.372249319242394\n",
      "    log_marginal   : -12530212.173913043\n",
      "    val_loss       : 10720641.153846154\n",
      "    val_ess        : 8.461532629453218\n",
      "    val_log_marginal: -10720639.692307692\n",
      "Train Epoch: 76 [0/918 (0%)] Loss: 12835403.000000\n",
      "Train Epoch: 76 [16/918 (2%)] Loss: 12584312.000000\n",
      "Train Epoch: 76 [32/918 (3%)] Loss: 8454328.000000\n",
      "Train Epoch: 76 [48/918 (5%)] Loss: 12289514.000000\n",
      "Train Epoch: 76 [64/918 (7%)] Loss: 12705675.000000\n",
      "Train Epoch: 76 [80/918 (9%)] Loss: 19547920.000000\n",
      "Train Epoch: 76 [96/918 (10%)] Loss: 13529767.000000\n",
      "Train Epoch: 76 [112/918 (12%)] Loss: 9390527.000000\n",
      "Train Epoch: 76 [128/918 (14%)] Loss: 12673463.000000\n",
      "Train Epoch: 76 [144/918 (16%)] Loss: 11102655.000000\n",
      "Train Epoch: 76 [160/918 (17%)] Loss: 8910591.000000\n",
      "Train Epoch: 76 [176/918 (19%)] Loss: 12254693.000000\n",
      "Train Epoch: 76 [192/918 (21%)] Loss: 12123792.000000\n",
      "Train Epoch: 76 [208/918 (23%)] Loss: 10766664.000000\n",
      "Train Epoch: 76 [224/918 (24%)] Loss: 10363171.000000\n",
      "Train Epoch: 76 [240/918 (26%)] Loss: 13378437.000000\n",
      "Train Epoch: 76 [256/918 (28%)] Loss: 10522693.000000\n",
      "Train Epoch: 76 [272/918 (30%)] Loss: 15531672.000000\n",
      "Train Epoch: 76 [288/918 (31%)] Loss: 10296890.000000\n",
      "Train Epoch: 76 [304/918 (33%)] Loss: 15188005.000000\n",
      "Train Epoch: 76 [320/918 (35%)] Loss: 13944899.000000\n",
      "Train Epoch: 76 [336/918 (37%)] Loss: 15469336.000000\n",
      "Train Epoch: 76 [352/918 (38%)] Loss: 13816227.000000\n",
      "Train Epoch: 76 [368/918 (40%)] Loss: 13648387.000000\n",
      "Train Epoch: 76 [384/918 (42%)] Loss: 18408308.000000\n",
      "Train Epoch: 76 [400/918 (44%)] Loss: 14891208.000000\n",
      "Train Epoch: 76 [416/918 (45%)] Loss: 12794563.000000\n",
      "Train Epoch: 76 [432/918 (47%)] Loss: 15062607.000000\n",
      "Train Epoch: 76 [448/918 (49%)] Loss: 11873496.000000\n",
      "Train Epoch: 76 [464/918 (51%)] Loss: 12040877.000000\n",
      "Train Epoch: 76 [480/918 (52%)] Loss: 10702796.000000\n",
      "Train Epoch: 76 [496/918 (54%)] Loss: 13045203.000000\n",
      "Train Epoch: 76 [512/918 (56%)] Loss: 10561287.000000\n",
      "Train Epoch: 76 [528/918 (58%)] Loss: 9712467.000000\n",
      "Train Epoch: 76 [544/918 (59%)] Loss: 13537080.000000\n",
      "Train Epoch: 76 [560/918 (61%)] Loss: 12514443.000000\n",
      "Train Epoch: 76 [576/918 (63%)] Loss: 10085386.000000\n",
      "Train Epoch: 76 [592/918 (64%)] Loss: 10830108.000000\n",
      "Train Epoch: 76 [608/918 (66%)] Loss: 13431304.000000\n",
      "Train Epoch: 76 [624/918 (68%)] Loss: 7908477.000000\n",
      "Train Epoch: 76 [640/918 (70%)] Loss: 15327823.000000\n",
      "Train Epoch: 76 [656/918 (71%)] Loss: 11907655.000000\n",
      "Train Epoch: 76 [672/918 (73%)] Loss: 15859712.000000\n",
      "Train Epoch: 76 [688/918 (75%)] Loss: 9332005.000000\n",
      "Train Epoch: 76 [704/918 (77%)] Loss: 10166808.000000\n",
      "Train Epoch: 76 [720/918 (78%)] Loss: 11884704.000000\n",
      "Train Epoch: 76 [736/918 (80%)] Loss: 12815546.000000\n",
      "Train Epoch: 76 [752/918 (82%)] Loss: 15241149.000000\n",
      "Train Epoch: 76 [768/918 (84%)] Loss: 11491387.000000\n",
      "Train Epoch: 76 [784/918 (85%)] Loss: 13619159.000000\n",
      "Train Epoch: 76 [800/918 (87%)] Loss: 15821736.000000\n",
      "Train Epoch: 76 [816/918 (89%)] Loss: 14400275.000000\n",
      "Train Epoch: 76 [832/918 (91%)] Loss: 11031580.000000\n",
      "Train Epoch: 76 [848/918 (92%)] Loss: 10087218.000000\n",
      "Train Epoch: 76 [864/918 (94%)] Loss: 11964473.000000\n",
      "Train Epoch: 76 [880/918 (96%)] Loss: 14310525.000000\n",
      "Train Epoch: 76 [896/918 (98%)] Loss: 9397298.000000\n",
      "Train Epoch: 76 [912/918 (99%)] Loss: 13637571.000000\n",
      "    epoch          : 76\n",
      "    loss           : 12550062.313043479\n",
      "    ess            : 10.913045706956282\n",
      "    log_marginal   : -12550060.665217392\n",
      "    val_loss       : 10961450.692307692\n",
      "    val_ess        : 10.383026563204252\n",
      "    val_log_marginal: -10961449.846153846\n",
      "Train Epoch: 77 [0/918 (0%)] Loss: 11633131.000000\n",
      "Train Epoch: 77 [16/918 (2%)] Loss: 13166498.000000\n",
      "Train Epoch: 77 [32/918 (3%)] Loss: 10425124.000000\n",
      "Train Epoch: 77 [48/918 (5%)] Loss: 10321640.000000\n",
      "Train Epoch: 77 [64/918 (7%)] Loss: 11115402.000000\n",
      "Train Epoch: 77 [80/918 (9%)] Loss: 11936403.000000\n",
      "Train Epoch: 77 [96/918 (10%)] Loss: 13137160.000000\n",
      "Train Epoch: 77 [112/918 (12%)] Loss: 13798471.000000\n",
      "Train Epoch: 77 [128/918 (14%)] Loss: 11737867.000000\n",
      "Train Epoch: 77 [144/918 (16%)] Loss: 13944307.000000\n",
      "Train Epoch: 77 [160/918 (17%)] Loss: 9672370.000000\n",
      "Train Epoch: 77 [176/918 (19%)] Loss: 11772220.000000\n",
      "Train Epoch: 77 [192/918 (21%)] Loss: 11324048.000000\n",
      "Train Epoch: 77 [208/918 (23%)] Loss: 11254931.000000\n",
      "Train Epoch: 77 [224/918 (24%)] Loss: 11000436.000000\n",
      "Train Epoch: 77 [240/918 (26%)] Loss: 11803819.000000\n",
      "Train Epoch: 77 [256/918 (28%)] Loss: 17768814.000000\n",
      "Train Epoch: 77 [272/918 (30%)] Loss: 17854326.000000\n",
      "Train Epoch: 77 [288/918 (31%)] Loss: 8666081.000000\n",
      "Train Epoch: 77 [304/918 (33%)] Loss: 12906207.000000\n",
      "Train Epoch: 77 [320/918 (35%)] Loss: 14564627.000000\n",
      "Train Epoch: 77 [336/918 (37%)] Loss: 11406595.000000\n",
      "Train Epoch: 77 [352/918 (38%)] Loss: 17032762.000000\n",
      "Train Epoch: 77 [368/918 (40%)] Loss: 13432112.000000\n",
      "Train Epoch: 77 [384/918 (42%)] Loss: 15759178.000000\n",
      "Train Epoch: 77 [400/918 (44%)] Loss: 9284852.000000\n",
      "Train Epoch: 77 [416/918 (45%)] Loss: 13389172.000000\n",
      "Train Epoch: 77 [432/918 (47%)] Loss: 13083365.000000\n",
      "Train Epoch: 77 [448/918 (49%)] Loss: 11943749.000000\n",
      "Train Epoch: 77 [464/918 (51%)] Loss: 10592587.000000\n",
      "Train Epoch: 77 [480/918 (52%)] Loss: 14849088.000000\n",
      "Train Epoch: 77 [496/918 (54%)] Loss: 11112014.000000\n",
      "Train Epoch: 77 [512/918 (56%)] Loss: 15257306.000000\n",
      "Train Epoch: 77 [528/918 (58%)] Loss: 11275115.000000\n",
      "Train Epoch: 77 [544/918 (59%)] Loss: 14236435.000000\n",
      "Train Epoch: 77 [560/918 (61%)] Loss: 8547288.000000\n",
      "Train Epoch: 77 [576/918 (63%)] Loss: 12588223.000000\n",
      "Train Epoch: 77 [592/918 (64%)] Loss: 11008613.000000\n",
      "Train Epoch: 77 [608/918 (66%)] Loss: 16250512.000000\n",
      "Train Epoch: 77 [624/918 (68%)] Loss: 15573933.000000\n",
      "Train Epoch: 77 [640/918 (70%)] Loss: 15012296.000000\n",
      "Train Epoch: 77 [656/918 (71%)] Loss: 9929482.000000\n",
      "Train Epoch: 77 [672/918 (73%)] Loss: 11745611.000000\n",
      "Train Epoch: 77 [688/918 (75%)] Loss: 9992092.000000\n",
      "Train Epoch: 77 [704/918 (77%)] Loss: 10333637.000000\n",
      "Train Epoch: 77 [720/918 (78%)] Loss: 8539138.000000\n",
      "Train Epoch: 77 [736/918 (80%)] Loss: 14210221.000000\n",
      "Train Epoch: 77 [752/918 (82%)] Loss: 13339234.000000\n",
      "Train Epoch: 77 [768/918 (84%)] Loss: 14986279.000000\n",
      "Train Epoch: 77 [784/918 (85%)] Loss: 14186008.000000\n",
      "Train Epoch: 77 [800/918 (87%)] Loss: 20197222.000000\n",
      "Train Epoch: 77 [816/918 (89%)] Loss: 11710539.000000\n",
      "Train Epoch: 77 [832/918 (91%)] Loss: 11017416.000000\n",
      "Train Epoch: 77 [848/918 (92%)] Loss: 8613226.000000\n",
      "Train Epoch: 77 [864/918 (94%)] Loss: 13324983.000000\n",
      "Train Epoch: 77 [880/918 (96%)] Loss: 12075082.000000\n",
      "Train Epoch: 77 [896/918 (98%)] Loss: 8611219.000000\n",
      "Train Epoch: 77 [912/918 (99%)] Loss: 12252421.000000\n",
      "    epoch          : 77\n",
      "    loss           : 12325900.426086957\n",
      "    ess            : 10.173999508567478\n",
      "    log_marginal   : -12325898.417391304\n",
      "    val_loss       : 10694228.384615384\n",
      "    val_ess        : 10.045374980339638\n",
      "    val_log_marginal: -10694225.76923077\n",
      "Train Epoch: 78 [0/918 (0%)] Loss: 11235056.000000\n",
      "Train Epoch: 78 [16/918 (2%)] Loss: 11685063.000000\n",
      "Train Epoch: 78 [32/918 (3%)] Loss: 10693167.000000\n",
      "Train Epoch: 78 [48/918 (5%)] Loss: 10393756.000000\n",
      "Train Epoch: 78 [64/918 (7%)] Loss: 9432640.000000\n",
      "Train Epoch: 78 [80/918 (9%)] Loss: 12117576.000000\n",
      "Train Epoch: 78 [96/918 (10%)] Loss: 14035917.000000\n",
      "Train Epoch: 78 [112/918 (12%)] Loss: 15595360.000000\n",
      "Train Epoch: 78 [128/918 (14%)] Loss: 14897053.000000\n",
      "Train Epoch: 78 [144/918 (16%)] Loss: 11628162.000000\n",
      "Train Epoch: 78 [160/918 (17%)] Loss: 16491648.000000\n",
      "Train Epoch: 78 [176/918 (19%)] Loss: 16911600.000000\n",
      "Train Epoch: 78 [192/918 (21%)] Loss: 14186279.000000\n",
      "Train Epoch: 78 [208/918 (23%)] Loss: 10243758.000000\n",
      "Train Epoch: 78 [224/918 (24%)] Loss: 11667958.000000\n",
      "Train Epoch: 78 [240/918 (26%)] Loss: 11652047.000000\n",
      "Train Epoch: 78 [256/918 (28%)] Loss: 11064554.000000\n",
      "Train Epoch: 78 [272/918 (30%)] Loss: 11142893.000000\n",
      "Train Epoch: 78 [288/918 (31%)] Loss: 12318881.000000\n",
      "Train Epoch: 78 [304/918 (33%)] Loss: 12521322.000000\n",
      "Train Epoch: 78 [320/918 (35%)] Loss: 12966407.000000\n",
      "Train Epoch: 78 [336/918 (37%)] Loss: 15891405.000000\n",
      "Train Epoch: 78 [352/918 (38%)] Loss: 13440986.000000\n",
      "Train Epoch: 78 [368/918 (40%)] Loss: 15841466.000000\n",
      "Train Epoch: 78 [384/918 (42%)] Loss: 8958325.000000\n",
      "Train Epoch: 78 [400/918 (44%)] Loss: 12107536.000000\n",
      "Train Epoch: 78 [416/918 (45%)] Loss: 13661469.000000\n",
      "Train Epoch: 78 [432/918 (47%)] Loss: 8971100.000000\n",
      "Train Epoch: 78 [448/918 (49%)] Loss: 12311380.000000\n",
      "Train Epoch: 78 [464/918 (51%)] Loss: 9754738.000000\n",
      "Train Epoch: 78 [480/918 (52%)] Loss: 9046967.000000\n",
      "Train Epoch: 78 [496/918 (54%)] Loss: 10315707.000000\n",
      "Train Epoch: 78 [512/918 (56%)] Loss: 9157639.000000\n",
      "Train Epoch: 78 [528/918 (58%)] Loss: 13090424.000000\n",
      "Train Epoch: 78 [544/918 (59%)] Loss: 10728091.000000\n",
      "Train Epoch: 78 [560/918 (61%)] Loss: 11546421.000000\n",
      "Train Epoch: 78 [576/918 (63%)] Loss: 12574131.000000\n",
      "Train Epoch: 78 [592/918 (64%)] Loss: 10458192.000000\n",
      "Train Epoch: 78 [608/918 (66%)] Loss: 9490943.000000\n",
      "Train Epoch: 78 [624/918 (68%)] Loss: 13116640.000000\n",
      "Train Epoch: 78 [640/918 (70%)] Loss: 12732415.000000\n",
      "Train Epoch: 78 [656/918 (71%)] Loss: 13813435.000000\n",
      "Train Epoch: 78 [672/918 (73%)] Loss: 11986132.000000\n",
      "Train Epoch: 78 [688/918 (75%)] Loss: 15517640.000000\n",
      "Train Epoch: 78 [704/918 (77%)] Loss: 13702215.000000\n",
      "Train Epoch: 78 [720/918 (78%)] Loss: 9553208.000000\n",
      "Train Epoch: 78 [736/918 (80%)] Loss: 11407823.000000\n",
      "Train Epoch: 78 [752/918 (82%)] Loss: 12639667.000000\n",
      "Train Epoch: 78 [768/918 (84%)] Loss: 9067216.000000\n",
      "Train Epoch: 78 [784/918 (85%)] Loss: 13018203.000000\n",
      "Train Epoch: 78 [800/918 (87%)] Loss: 8565118.000000\n",
      "Train Epoch: 78 [816/918 (89%)] Loss: 12018485.000000\n",
      "Train Epoch: 78 [832/918 (91%)] Loss: 9580244.000000\n",
      "Train Epoch: 78 [848/918 (92%)] Loss: 9913750.000000\n",
      "Train Epoch: 78 [864/918 (94%)] Loss: 14144304.000000\n",
      "Train Epoch: 78 [880/918 (96%)] Loss: 15825691.000000\n",
      "Train Epoch: 78 [896/918 (98%)] Loss: 11256389.000000\n",
      "Train Epoch: 78 [912/918 (99%)] Loss: 9963955.000000\n",
      "    epoch          : 78\n",
      "    loss           : 12120937.386956522\n",
      "    ess            : 9.750495027459186\n",
      "    log_marginal   : -12120935.639130434\n",
      "    val_loss       : 10619438.192307692\n",
      "    val_ess        : 9.520221838584312\n",
      "    val_log_marginal: -10619436.346153846\n",
      "Train Epoch: 79 [0/918 (0%)] Loss: 10878546.000000\n",
      "Train Epoch: 79 [16/918 (2%)] Loss: 10742631.000000\n",
      "Train Epoch: 79 [32/918 (3%)] Loss: 14878496.000000\n",
      "Train Epoch: 79 [48/918 (5%)] Loss: 13744911.000000\n",
      "Train Epoch: 79 [64/918 (7%)] Loss: 13044715.000000\n",
      "Train Epoch: 79 [80/918 (9%)] Loss: 9749411.000000\n",
      "Train Epoch: 79 [96/918 (10%)] Loss: 13515242.000000\n",
      "Train Epoch: 79 [112/918 (12%)] Loss: 7686337.500000\n",
      "Train Epoch: 79 [128/918 (14%)] Loss: 14017626.000000\n",
      "Train Epoch: 79 [144/918 (16%)] Loss: 9153565.000000\n",
      "Train Epoch: 79 [160/918 (17%)] Loss: 15009299.000000\n",
      "Train Epoch: 79 [176/918 (19%)] Loss: 9990947.000000\n",
      "Train Epoch: 79 [192/918 (21%)] Loss: 9559037.000000\n",
      "Train Epoch: 79 [208/918 (23%)] Loss: 11952801.000000\n",
      "Train Epoch: 79 [224/918 (24%)] Loss: 11718269.000000\n",
      "Train Epoch: 79 [240/918 (26%)] Loss: 7693262.500000\n",
      "Train Epoch: 79 [256/918 (28%)] Loss: 8170050.500000\n",
      "Train Epoch: 79 [272/918 (30%)] Loss: 17695982.000000\n",
      "Train Epoch: 79 [288/918 (31%)] Loss: 11382843.000000\n",
      "Train Epoch: 79 [304/918 (33%)] Loss: 10374911.000000\n",
      "Train Epoch: 79 [320/918 (35%)] Loss: 12652933.000000\n",
      "Train Epoch: 79 [336/918 (37%)] Loss: 11340168.000000\n",
      "Train Epoch: 79 [352/918 (38%)] Loss: 10747831.000000\n",
      "Train Epoch: 79 [368/918 (40%)] Loss: 8963606.000000\n",
      "Train Epoch: 79 [384/918 (42%)] Loss: 15432067.000000\n",
      "Train Epoch: 79 [400/918 (44%)] Loss: 13020262.000000\n",
      "Train Epoch: 79 [416/918 (45%)] Loss: 9181488.000000\n",
      "Train Epoch: 79 [432/918 (47%)] Loss: 13769776.000000\n",
      "Train Epoch: 79 [448/918 (49%)] Loss: 12141055.000000\n",
      "Train Epoch: 79 [464/918 (51%)] Loss: 12444859.000000\n",
      "Train Epoch: 79 [480/918 (52%)] Loss: 10094469.000000\n",
      "Train Epoch: 79 [496/918 (54%)] Loss: 17723560.000000\n",
      "Train Epoch: 79 [512/918 (56%)] Loss: 12651083.000000\n",
      "Train Epoch: 79 [528/918 (58%)] Loss: 8624638.000000\n",
      "Train Epoch: 79 [544/918 (59%)] Loss: 12121558.000000\n",
      "Train Epoch: 79 [560/918 (61%)] Loss: 19092756.000000\n",
      "Train Epoch: 79 [576/918 (63%)] Loss: 12815039.000000\n",
      "Train Epoch: 79 [592/918 (64%)] Loss: 8885621.000000\n",
      "Train Epoch: 79 [608/918 (66%)] Loss: 10814752.000000\n",
      "Train Epoch: 79 [624/918 (68%)] Loss: 12005164.000000\n",
      "Train Epoch: 79 [640/918 (70%)] Loss: 11913894.000000\n",
      "Train Epoch: 79 [656/918 (71%)] Loss: 9193193.000000\n",
      "Train Epoch: 79 [672/918 (73%)] Loss: 10868680.000000\n",
      "Train Epoch: 79 [688/918 (75%)] Loss: 8211461.000000\n",
      "Train Epoch: 79 [704/918 (77%)] Loss: 9278773.000000\n",
      "Train Epoch: 79 [720/918 (78%)] Loss: 10177240.000000\n",
      "Train Epoch: 79 [736/918 (80%)] Loss: 8965167.000000\n",
      "Train Epoch: 79 [752/918 (82%)] Loss: 12087989.000000\n",
      "Train Epoch: 79 [768/918 (84%)] Loss: 13165859.000000\n",
      "Train Epoch: 79 [784/918 (85%)] Loss: 9965263.000000\n",
      "Train Epoch: 79 [800/918 (87%)] Loss: 13795165.000000\n",
      "Train Epoch: 79 [816/918 (89%)] Loss: 14090275.000000\n",
      "Train Epoch: 79 [832/918 (91%)] Loss: 10823992.000000\n",
      "Train Epoch: 79 [848/918 (92%)] Loss: 11071503.000000\n",
      "Train Epoch: 79 [864/918 (94%)] Loss: 12437014.000000\n",
      "Train Epoch: 79 [880/918 (96%)] Loss: 15297344.000000\n",
      "Train Epoch: 79 [896/918 (98%)] Loss: 12145411.000000\n",
      "Train Epoch: 79 [912/918 (99%)] Loss: 8159088.500000\n",
      "    epoch          : 79\n",
      "    loss           : 11989830.886956522\n",
      "    ess            : 11.066561626351398\n",
      "    log_marginal   : -11989828.34347826\n",
      "    val_loss       : 10540128.961538462\n",
      "    val_ess        : 9.78250844662006\n",
      "    val_log_marginal: -10540127.153846154\n",
      "Train Epoch: 80 [0/918 (0%)] Loss: 12496377.000000\n",
      "Train Epoch: 80 [16/918 (2%)] Loss: 12479196.000000\n",
      "Train Epoch: 80 [32/918 (3%)] Loss: 11517382.000000\n",
      "Train Epoch: 80 [48/918 (5%)] Loss: 10507458.000000\n",
      "Train Epoch: 80 [64/918 (7%)] Loss: 13628923.000000\n",
      "Train Epoch: 80 [80/918 (9%)] Loss: 8617420.000000\n",
      "Train Epoch: 80 [96/918 (10%)] Loss: 11186531.000000\n",
      "Train Epoch: 80 [112/918 (12%)] Loss: 15119608.000000\n",
      "Train Epoch: 80 [128/918 (14%)] Loss: 12389073.000000\n",
      "Train Epoch: 80 [144/918 (16%)] Loss: 15024242.000000\n",
      "Train Epoch: 80 [160/918 (17%)] Loss: 12102639.000000\n",
      "Train Epoch: 80 [176/918 (19%)] Loss: 11722170.000000\n",
      "Train Epoch: 80 [192/918 (21%)] Loss: 14347677.000000\n",
      "Train Epoch: 80 [208/918 (23%)] Loss: 11826116.000000\n",
      "Train Epoch: 80 [224/918 (24%)] Loss: 9540951.000000\n",
      "Train Epoch: 80 [240/918 (26%)] Loss: 11499897.000000\n",
      "Train Epoch: 80 [256/918 (28%)] Loss: 16070424.000000\n",
      "Train Epoch: 80 [272/918 (30%)] Loss: 8853248.000000\n",
      "Train Epoch: 80 [288/918 (31%)] Loss: 15928347.000000\n",
      "Train Epoch: 80 [304/918 (33%)] Loss: 10848058.000000\n",
      "Train Epoch: 80 [320/918 (35%)] Loss: 11048856.000000\n",
      "Train Epoch: 80 [336/918 (37%)] Loss: 9114511.000000\n",
      "Train Epoch: 80 [352/918 (38%)] Loss: 10851240.000000\n",
      "Train Epoch: 80 [368/918 (40%)] Loss: 13169248.000000\n",
      "Train Epoch: 80 [384/918 (42%)] Loss: 10695692.000000\n",
      "Train Epoch: 80 [400/918 (44%)] Loss: 12142070.000000\n",
      "Train Epoch: 80 [416/918 (45%)] Loss: 14927375.000000\n",
      "Train Epoch: 80 [432/918 (47%)] Loss: 14532077.000000\n",
      "Train Epoch: 80 [448/918 (49%)] Loss: 12499042.000000\n",
      "Train Epoch: 80 [464/918 (51%)] Loss: 11068319.000000\n",
      "Train Epoch: 80 [480/918 (52%)] Loss: 13249320.000000\n",
      "Train Epoch: 80 [496/918 (54%)] Loss: 13615395.000000\n",
      "Train Epoch: 80 [512/918 (56%)] Loss: 10007391.000000\n",
      "Train Epoch: 80 [528/918 (58%)] Loss: 11834022.000000\n",
      "Train Epoch: 80 [544/918 (59%)] Loss: 11888046.000000\n",
      "Train Epoch: 80 [560/918 (61%)] Loss: 10753987.000000\n",
      "Train Epoch: 80 [576/918 (63%)] Loss: 8292581.000000\n",
      "Train Epoch: 80 [592/918 (64%)] Loss: 10639261.000000\n",
      "Train Epoch: 80 [608/918 (66%)] Loss: 8405885.000000\n",
      "Train Epoch: 80 [624/918 (68%)] Loss: 14699173.000000\n",
      "Train Epoch: 80 [640/918 (70%)] Loss: 14470643.000000\n",
      "Train Epoch: 80 [656/918 (71%)] Loss: 13503000.000000\n",
      "Train Epoch: 80 [672/918 (73%)] Loss: 9833426.000000\n",
      "Train Epoch: 80 [688/918 (75%)] Loss: 11431301.000000\n",
      "Train Epoch: 80 [704/918 (77%)] Loss: 12862766.000000\n",
      "Train Epoch: 80 [720/918 (78%)] Loss: 11641309.000000\n",
      "Train Epoch: 80 [736/918 (80%)] Loss: 10000527.000000\n",
      "Train Epoch: 80 [752/918 (82%)] Loss: 11092962.000000\n",
      "Train Epoch: 80 [768/918 (84%)] Loss: 16341290.000000\n",
      "Train Epoch: 80 [784/918 (85%)] Loss: 8827909.000000\n",
      "Train Epoch: 80 [800/918 (87%)] Loss: 9567292.000000\n",
      "Train Epoch: 80 [816/918 (89%)] Loss: 8937327.000000\n",
      "Train Epoch: 80 [832/918 (91%)] Loss: 17607780.000000\n",
      "Train Epoch: 80 [848/918 (92%)] Loss: 10866839.000000\n",
      "Train Epoch: 80 [864/918 (94%)] Loss: 8110909.500000\n",
      "Train Epoch: 80 [880/918 (96%)] Loss: 10698583.000000\n",
      "Train Epoch: 80 [896/918 (98%)] Loss: 9447639.000000\n",
      "Train Epoch: 80 [912/918 (99%)] Loss: 12204282.000000\n",
      "    epoch          : 80\n",
      "    loss           : 11945520.404347826\n",
      "    ess            : 10.503632745535477\n",
      "    log_marginal   : -11945518.386956522\n",
      "    val_loss       : 9978090.384615384\n",
      "    val_ess        : 6.581483529164241\n",
      "    val_log_marginal: -9978085.461538462\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch80.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 81 [0/918 (0%)] Loss: 13501770.000000\n",
      "Train Epoch: 81 [16/918 (2%)] Loss: 8437974.000000\n",
      "Train Epoch: 81 [32/918 (3%)] Loss: 10149714.000000\n",
      "Train Epoch: 81 [48/918 (5%)] Loss: 7206235.500000\n",
      "Train Epoch: 81 [64/918 (7%)] Loss: 14524149.000000\n",
      "Train Epoch: 81 [80/918 (9%)] Loss: 13418143.000000\n",
      "Train Epoch: 81 [96/918 (10%)] Loss: 8490686.000000\n",
      "Train Epoch: 81 [112/918 (12%)] Loss: 10568234.000000\n",
      "Train Epoch: 81 [128/918 (14%)] Loss: 11569796.000000\n",
      "Train Epoch: 81 [144/918 (16%)] Loss: 11422243.000000\n",
      "Train Epoch: 81 [160/918 (17%)] Loss: 15868520.000000\n",
      "Train Epoch: 81 [176/918 (19%)] Loss: 10628128.000000\n",
      "Train Epoch: 81 [192/918 (21%)] Loss: 16178701.000000\n",
      "Train Epoch: 81 [208/918 (23%)] Loss: 13386645.000000\n",
      "Train Epoch: 81 [224/918 (24%)] Loss: 11298249.000000\n",
      "Train Epoch: 81 [240/918 (26%)] Loss: 10242887.000000\n",
      "Train Epoch: 81 [256/918 (28%)] Loss: 11893060.000000\n",
      "Train Epoch: 81 [272/918 (30%)] Loss: 9524229.000000\n",
      "Train Epoch: 81 [288/918 (31%)] Loss: 12860242.000000\n",
      "Train Epoch: 81 [304/918 (33%)] Loss: 11106511.000000\n",
      "Train Epoch: 81 [320/918 (35%)] Loss: 12082694.000000\n",
      "Train Epoch: 81 [336/918 (37%)] Loss: 10578061.000000\n",
      "Train Epoch: 81 [352/918 (38%)] Loss: 10381272.000000\n",
      "Train Epoch: 81 [368/918 (40%)] Loss: 11935582.000000\n",
      "Train Epoch: 81 [384/918 (42%)] Loss: 12588847.000000\n",
      "Train Epoch: 81 [400/918 (44%)] Loss: 12854784.000000\n",
      "Train Epoch: 81 [416/918 (45%)] Loss: 10214439.000000\n",
      "Train Epoch: 81 [432/918 (47%)] Loss: 11826485.000000\n",
      "Train Epoch: 81 [448/918 (49%)] Loss: 11251054.000000\n",
      "Train Epoch: 81 [464/918 (51%)] Loss: 11311164.000000\n",
      "Train Epoch: 81 [480/918 (52%)] Loss: 8442808.000000\n",
      "Train Epoch: 81 [496/918 (54%)] Loss: 10913921.000000\n",
      "Train Epoch: 81 [512/918 (56%)] Loss: 11458931.000000\n",
      "Train Epoch: 81 [528/918 (58%)] Loss: 13642888.000000\n",
      "Train Epoch: 81 [544/918 (59%)] Loss: 12245443.000000\n",
      "Train Epoch: 81 [560/918 (61%)] Loss: 14671274.000000\n",
      "Train Epoch: 81 [576/918 (63%)] Loss: 15020575.000000\n",
      "Train Epoch: 81 [592/918 (64%)] Loss: 12511495.000000\n",
      "Train Epoch: 81 [608/918 (66%)] Loss: 11919182.000000\n",
      "Train Epoch: 81 [624/918 (68%)] Loss: 14262095.000000\n",
      "Train Epoch: 81 [640/918 (70%)] Loss: 9131440.000000\n",
      "Train Epoch: 81 [656/918 (71%)] Loss: 8993504.000000\n",
      "Train Epoch: 81 [672/918 (73%)] Loss: 11850262.000000\n",
      "Train Epoch: 81 [688/918 (75%)] Loss: 10520247.000000\n",
      "Train Epoch: 81 [704/918 (77%)] Loss: 9594438.000000\n",
      "Train Epoch: 81 [720/918 (78%)] Loss: 10501623.000000\n",
      "Train Epoch: 81 [736/918 (80%)] Loss: 9381392.000000\n",
      "Train Epoch: 81 [752/918 (82%)] Loss: 8761879.000000\n",
      "Train Epoch: 81 [768/918 (84%)] Loss: 13028962.000000\n",
      "Train Epoch: 81 [784/918 (85%)] Loss: 13269667.000000\n",
      "Train Epoch: 81 [800/918 (87%)] Loss: 10298109.000000\n",
      "Train Epoch: 81 [816/918 (89%)] Loss: 16250151.000000\n",
      "Train Epoch: 81 [832/918 (91%)] Loss: 13855603.000000\n",
      "Train Epoch: 81 [848/918 (92%)] Loss: 13650803.000000\n",
      "Train Epoch: 81 [864/918 (94%)] Loss: 10582008.000000\n",
      "Train Epoch: 81 [880/918 (96%)] Loss: 13372900.000000\n",
      "Train Epoch: 81 [896/918 (98%)] Loss: 9614663.000000\n",
      "Train Epoch: 81 [912/918 (99%)] Loss: 12336474.000000\n",
      "    epoch          : 81\n",
      "    loss           : 11566308.726086957\n",
      "    ess            : 9.078679448625316\n",
      "    log_marginal   : -11566307.0\n",
      "    val_loss       : 10627581.076923076\n",
      "    val_ess        : 10.776755369626558\n",
      "    val_log_marginal: -10627577.576923076\n",
      "Train Epoch: 82 [0/918 (0%)] Loss: 11179568.000000\n",
      "Train Epoch: 82 [16/918 (2%)] Loss: 13303230.000000\n",
      "Train Epoch: 82 [32/918 (3%)] Loss: 8094637.500000\n",
      "Train Epoch: 82 [48/918 (5%)] Loss: 8802495.000000\n",
      "Train Epoch: 82 [64/918 (7%)] Loss: 11861630.000000\n",
      "Train Epoch: 82 [80/918 (9%)] Loss: 10385332.000000\n",
      "Train Epoch: 82 [96/918 (10%)] Loss: 10051096.000000\n",
      "Train Epoch: 82 [112/918 (12%)] Loss: 11946848.000000\n",
      "Train Epoch: 82 [128/918 (14%)] Loss: 9229237.000000\n",
      "Train Epoch: 82 [144/918 (16%)] Loss: 10524855.000000\n",
      "Train Epoch: 82 [160/918 (17%)] Loss: 13215119.000000\n",
      "Train Epoch: 82 [176/918 (19%)] Loss: 10765578.000000\n",
      "Train Epoch: 82 [192/918 (21%)] Loss: 10565706.000000\n",
      "Train Epoch: 82 [208/918 (23%)] Loss: 12527635.000000\n",
      "Train Epoch: 82 [224/918 (24%)] Loss: 16375866.000000\n",
      "Train Epoch: 82 [240/918 (26%)] Loss: 10058117.000000\n",
      "Train Epoch: 82 [256/918 (28%)] Loss: 12356368.000000\n",
      "Train Epoch: 82 [272/918 (30%)] Loss: 10974344.000000\n",
      "Train Epoch: 82 [288/918 (31%)] Loss: 9481866.000000\n",
      "Train Epoch: 82 [304/918 (33%)] Loss: 13801027.000000\n",
      "Train Epoch: 82 [320/918 (35%)] Loss: 14400794.000000\n",
      "Train Epoch: 82 [336/918 (37%)] Loss: 10446746.000000\n",
      "Train Epoch: 82 [352/918 (38%)] Loss: 9537423.000000\n",
      "Train Epoch: 82 [368/918 (40%)] Loss: 14861496.000000\n",
      "Train Epoch: 82 [384/918 (42%)] Loss: 12357401.000000\n",
      "Train Epoch: 82 [400/918 (44%)] Loss: 8110601.500000\n",
      "Train Epoch: 82 [416/918 (45%)] Loss: 9335120.000000\n",
      "Train Epoch: 82 [432/918 (47%)] Loss: 9227671.000000\n",
      "Train Epoch: 82 [448/918 (49%)] Loss: 12425246.000000\n",
      "Train Epoch: 82 [464/918 (51%)] Loss: 12819126.000000\n",
      "Train Epoch: 82 [480/918 (52%)] Loss: 17478080.000000\n",
      "Train Epoch: 82 [496/918 (54%)] Loss: 12170559.000000\n",
      "Train Epoch: 82 [512/918 (56%)] Loss: 11680211.000000\n",
      "Train Epoch: 82 [528/918 (58%)] Loss: 13330849.000000\n",
      "Train Epoch: 82 [544/918 (59%)] Loss: 12098864.000000\n",
      "Train Epoch: 82 [560/918 (61%)] Loss: 11677144.000000\n",
      "Train Epoch: 82 [576/918 (63%)] Loss: 12006051.000000\n",
      "Train Epoch: 82 [592/918 (64%)] Loss: 9132608.000000\n",
      "Train Epoch: 82 [608/918 (66%)] Loss: 12730195.000000\n",
      "Train Epoch: 82 [624/918 (68%)] Loss: 8472376.000000\n",
      "Train Epoch: 82 [640/918 (70%)] Loss: 12085084.000000\n",
      "Train Epoch: 82 [656/918 (71%)] Loss: 9502699.000000\n",
      "Train Epoch: 82 [672/918 (73%)] Loss: 8851277.000000\n",
      "Train Epoch: 82 [688/918 (75%)] Loss: 10535221.000000\n",
      "Train Epoch: 82 [704/918 (77%)] Loss: 7372977.500000\n",
      "Train Epoch: 82 [720/918 (78%)] Loss: 10146615.000000\n",
      "Train Epoch: 82 [736/918 (80%)] Loss: 10944611.000000\n",
      "Train Epoch: 82 [752/918 (82%)] Loss: 11768949.000000\n",
      "Train Epoch: 82 [768/918 (84%)] Loss: 17995106.000000\n",
      "Train Epoch: 82 [784/918 (85%)] Loss: 7843776.000000\n",
      "Train Epoch: 82 [800/918 (87%)] Loss: 11306978.000000\n",
      "Train Epoch: 82 [816/918 (89%)] Loss: 10570234.000000\n",
      "Train Epoch: 82 [832/918 (91%)] Loss: 12199554.000000\n",
      "Train Epoch: 82 [848/918 (92%)] Loss: 13020391.000000\n",
      "Train Epoch: 82 [864/918 (94%)] Loss: 8706219.000000\n",
      "Train Epoch: 82 [880/918 (96%)] Loss: 10447958.000000\n",
      "Train Epoch: 82 [896/918 (98%)] Loss: 12595213.000000\n",
      "Train Epoch: 82 [912/918 (99%)] Loss: 8385447.000000\n",
      "    epoch          : 82\n",
      "    loss           : 11531969.813043479\n",
      "    ess            : 9.215415589705758\n",
      "    log_marginal   : -11531967.7\n",
      "    val_loss       : 9963485.923076924\n",
      "    val_ess        : 8.551201086777906\n",
      "    val_log_marginal: -9963482.76923077\n",
      "Train Epoch: 83 [0/918 (0%)] Loss: 9702007.000000\n",
      "Train Epoch: 83 [16/918 (2%)] Loss: 10737179.000000\n",
      "Train Epoch: 83 [32/918 (3%)] Loss: 10863976.000000\n",
      "Train Epoch: 83 [48/918 (5%)] Loss: 8573818.000000\n",
      "Train Epoch: 83 [64/918 (7%)] Loss: 11149687.000000\n",
      "Train Epoch: 83 [80/918 (9%)] Loss: 9489732.000000\n",
      "Train Epoch: 83 [96/918 (10%)] Loss: 11491328.000000\n",
      "Train Epoch: 83 [112/918 (12%)] Loss: 16165392.000000\n",
      "Train Epoch: 83 [128/918 (14%)] Loss: 7844608.000000\n",
      "Train Epoch: 83 [144/918 (16%)] Loss: 13285260.000000\n",
      "Train Epoch: 83 [160/918 (17%)] Loss: 8769103.000000\n",
      "Train Epoch: 83 [176/918 (19%)] Loss: 10472303.000000\n",
      "Train Epoch: 83 [192/918 (21%)] Loss: 10639351.000000\n",
      "Train Epoch: 83 [208/918 (23%)] Loss: 9387712.000000\n",
      "Train Epoch: 83 [224/918 (24%)] Loss: 12831335.000000\n",
      "Train Epoch: 83 [240/918 (26%)] Loss: 12785355.000000\n",
      "Train Epoch: 83 [256/918 (28%)] Loss: 15276845.000000\n",
      "Train Epoch: 83 [272/918 (30%)] Loss: 11553171.000000\n",
      "Train Epoch: 83 [288/918 (31%)] Loss: 7851177.500000\n",
      "Train Epoch: 83 [304/918 (33%)] Loss: 10964323.000000\n",
      "Train Epoch: 83 [320/918 (35%)] Loss: 9606881.000000\n",
      "Train Epoch: 83 [336/918 (37%)] Loss: 10932695.000000\n",
      "Train Epoch: 83 [352/918 (38%)] Loss: 8569199.000000\n",
      "Train Epoch: 83 [368/918 (40%)] Loss: 15989776.000000\n",
      "Train Epoch: 83 [384/918 (42%)] Loss: 11507347.000000\n",
      "Train Epoch: 83 [400/918 (44%)] Loss: 11178099.000000\n",
      "Train Epoch: 83 [416/918 (45%)] Loss: 9549786.000000\n",
      "Train Epoch: 83 [432/918 (47%)] Loss: 13973811.000000\n",
      "Train Epoch: 83 [448/918 (49%)] Loss: 12809343.000000\n",
      "Train Epoch: 83 [464/918 (51%)] Loss: 14330973.000000\n",
      "Train Epoch: 83 [480/918 (52%)] Loss: 12560272.000000\n",
      "Train Epoch: 83 [496/918 (54%)] Loss: 10935554.000000\n",
      "Train Epoch: 83 [512/918 (56%)] Loss: 10687298.000000\n",
      "Train Epoch: 83 [528/918 (58%)] Loss: 11138388.000000\n",
      "Train Epoch: 83 [544/918 (59%)] Loss: 7809054.500000\n",
      "Train Epoch: 83 [560/918 (61%)] Loss: 9310058.000000\n",
      "Train Epoch: 83 [576/918 (63%)] Loss: 10571524.000000\n",
      "Train Epoch: 83 [592/918 (64%)] Loss: 11261081.000000\n",
      "Train Epoch: 83 [608/918 (66%)] Loss: 9062020.000000\n",
      "Train Epoch: 83 [624/918 (68%)] Loss: 11297831.000000\n",
      "Train Epoch: 83 [640/918 (70%)] Loss: 9464203.000000\n",
      "Train Epoch: 83 [656/918 (71%)] Loss: 16382490.000000\n",
      "Train Epoch: 83 [672/918 (73%)] Loss: 12063250.000000\n",
      "Train Epoch: 83 [688/918 (75%)] Loss: 7948032.000000\n",
      "Train Epoch: 83 [704/918 (77%)] Loss: 10214637.000000\n",
      "Train Epoch: 83 [720/918 (78%)] Loss: 9752730.000000\n",
      "Train Epoch: 83 [736/918 (80%)] Loss: 8334336.000000\n",
      "Train Epoch: 83 [752/918 (82%)] Loss: 10797120.000000\n",
      "Train Epoch: 83 [768/918 (84%)] Loss: 12843899.000000\n",
      "Train Epoch: 83 [784/918 (85%)] Loss: 9981420.000000\n",
      "Train Epoch: 83 [800/918 (87%)] Loss: 10960032.000000\n",
      "Train Epoch: 83 [816/918 (89%)] Loss: 10720645.000000\n",
      "Train Epoch: 83 [832/918 (91%)] Loss: 8876294.000000\n",
      "Train Epoch: 83 [848/918 (92%)] Loss: 12178112.000000\n",
      "Train Epoch: 83 [864/918 (94%)] Loss: 9679322.000000\n",
      "Train Epoch: 83 [880/918 (96%)] Loss: 9358167.000000\n",
      "Train Epoch: 83 [896/918 (98%)] Loss: 12645607.000000\n",
      "Train Epoch: 83 [912/918 (99%)] Loss: 10299527.000000\n",
      "    epoch          : 83\n",
      "    loss           : 11089394.273913043\n",
      "    ess            : 9.700552368164063\n",
      "    log_marginal   : -11089392.895652173\n",
      "    val_loss       : 10052698.115384616\n",
      "    val_ess        : 7.7012302325322075\n",
      "    val_log_marginal: -10052697.115384616\n",
      "Train Epoch: 84 [0/918 (0%)] Loss: 16291773.000000\n",
      "Train Epoch: 84 [16/918 (2%)] Loss: 13083638.000000\n",
      "Train Epoch: 84 [32/918 (3%)] Loss: 8041202.500000\n",
      "Train Epoch: 84 [48/918 (5%)] Loss: 10823434.000000\n",
      "Train Epoch: 84 [64/918 (7%)] Loss: 8541852.000000\n",
      "Train Epoch: 84 [80/918 (9%)] Loss: 10812269.000000\n",
      "Train Epoch: 84 [96/918 (10%)] Loss: 18022100.000000\n",
      "Train Epoch: 84 [112/918 (12%)] Loss: 7901446.500000\n",
      "Train Epoch: 84 [128/918 (14%)] Loss: 9932572.000000\n",
      "Train Epoch: 84 [144/918 (16%)] Loss: 12240379.000000\n",
      "Train Epoch: 84 [160/918 (17%)] Loss: 11818810.000000\n",
      "Train Epoch: 84 [176/918 (19%)] Loss: 10995559.000000\n",
      "Train Epoch: 84 [192/918 (21%)] Loss: 7909136.000000\n",
      "Train Epoch: 84 [208/918 (23%)] Loss: 8784494.000000\n",
      "Train Epoch: 84 [224/918 (24%)] Loss: 10493533.000000\n",
      "Train Epoch: 84 [240/918 (26%)] Loss: 10580790.000000\n",
      "Train Epoch: 84 [256/918 (28%)] Loss: 10053054.000000\n",
      "Train Epoch: 84 [272/918 (30%)] Loss: 8035685.500000\n",
      "Train Epoch: 84 [288/918 (31%)] Loss: 10016115.000000\n",
      "Train Epoch: 84 [304/918 (33%)] Loss: 12237179.000000\n",
      "Train Epoch: 84 [320/918 (35%)] Loss: 9457055.000000\n",
      "Train Epoch: 84 [336/918 (37%)] Loss: 15650927.000000\n",
      "Train Epoch: 84 [352/918 (38%)] Loss: 7286489.000000\n",
      "Train Epoch: 84 [368/918 (40%)] Loss: 12637257.000000\n",
      "Train Epoch: 84 [384/918 (42%)] Loss: 9294742.000000\n",
      "Train Epoch: 84 [400/918 (44%)] Loss: 10577944.000000\n",
      "Train Epoch: 84 [416/918 (45%)] Loss: 15727936.000000\n",
      "Train Epoch: 84 [432/918 (47%)] Loss: 10753487.000000\n",
      "Train Epoch: 84 [448/918 (49%)] Loss: 14127007.000000\n",
      "Train Epoch: 84 [464/918 (51%)] Loss: 11222659.000000\n",
      "Train Epoch: 84 [480/918 (52%)] Loss: 13375835.000000\n",
      "Train Epoch: 84 [496/918 (54%)] Loss: 9897212.000000\n",
      "Train Epoch: 84 [512/918 (56%)] Loss: 12279128.000000\n",
      "Train Epoch: 84 [528/918 (58%)] Loss: 10855259.000000\n",
      "Train Epoch: 84 [544/918 (59%)] Loss: 9883259.000000\n",
      "Train Epoch: 84 [560/918 (61%)] Loss: 8323193.500000\n",
      "Train Epoch: 84 [576/918 (63%)] Loss: 9926651.000000\n",
      "Train Epoch: 84 [592/918 (64%)] Loss: 13383854.000000\n",
      "Train Epoch: 84 [608/918 (66%)] Loss: 9869192.000000\n",
      "Train Epoch: 84 [624/918 (68%)] Loss: 18422516.000000\n",
      "Train Epoch: 84 [640/918 (70%)] Loss: 13087154.000000\n",
      "Train Epoch: 84 [656/918 (71%)] Loss: 12389376.000000\n",
      "Train Epoch: 84 [672/918 (73%)] Loss: 11166582.000000\n",
      "Train Epoch: 84 [688/918 (75%)] Loss: 12842736.000000\n",
      "Train Epoch: 84 [704/918 (77%)] Loss: 10915259.000000\n",
      "Train Epoch: 84 [720/918 (78%)] Loss: 9008924.000000\n",
      "Train Epoch: 84 [736/918 (80%)] Loss: 8152169.500000\n",
      "Train Epoch: 84 [752/918 (82%)] Loss: 14094349.000000\n",
      "Train Epoch: 84 [768/918 (84%)] Loss: 14677015.000000\n",
      "Train Epoch: 84 [784/918 (85%)] Loss: 8299916.000000\n",
      "Train Epoch: 84 [800/918 (87%)] Loss: 9128358.000000\n",
      "Train Epoch: 84 [816/918 (89%)] Loss: 11019867.000000\n",
      "Train Epoch: 84 [832/918 (91%)] Loss: 13197623.000000\n",
      "Train Epoch: 84 [848/918 (92%)] Loss: 8283825.500000\n",
      "Train Epoch: 84 [864/918 (94%)] Loss: 8877431.000000\n",
      "Train Epoch: 84 [880/918 (96%)] Loss: 7713304.000000\n",
      "Train Epoch: 84 [896/918 (98%)] Loss: 10349833.000000\n",
      "Train Epoch: 84 [912/918 (99%)] Loss: 10457383.000000\n",
      "    epoch          : 84\n",
      "    loss           : 10989011.473913044\n",
      "    ess            : 9.347507866569188\n",
      "    log_marginal   : -10989009.869565217\n",
      "    val_loss       : 9593681.346153846\n",
      "    val_ess        : 8.607979939534115\n",
      "    val_log_marginal: -9593678.538461538\n",
      "Train Epoch: 85 [0/918 (0%)] Loss: 11093395.000000\n",
      "Train Epoch: 85 [16/918 (2%)] Loss: 11811368.000000\n",
      "Train Epoch: 85 [32/918 (3%)] Loss: 8935830.000000\n",
      "Train Epoch: 85 [48/918 (5%)] Loss: 10570865.000000\n",
      "Train Epoch: 85 [64/918 (7%)] Loss: 10967037.000000\n",
      "Train Epoch: 85 [80/918 (9%)] Loss: 9347367.000000\n",
      "Train Epoch: 85 [96/918 (10%)] Loss: 7492025.500000\n",
      "Train Epoch: 85 [112/918 (12%)] Loss: 16143155.000000\n",
      "Train Epoch: 85 [128/918 (14%)] Loss: 10196301.000000\n",
      "Train Epoch: 85 [144/918 (16%)] Loss: 16908280.000000\n",
      "Train Epoch: 85 [160/918 (17%)] Loss: 11727937.000000\n",
      "Train Epoch: 85 [176/918 (19%)] Loss: 13992339.000000\n",
      "Train Epoch: 85 [192/918 (21%)] Loss: 10417525.000000\n",
      "Train Epoch: 85 [208/918 (23%)] Loss: 13975479.000000\n",
      "Train Epoch: 85 [224/918 (24%)] Loss: 11193604.000000\n",
      "Train Epoch: 85 [240/918 (26%)] Loss: 10475882.000000\n",
      "Train Epoch: 85 [256/918 (28%)] Loss: 11688936.000000\n",
      "Train Epoch: 85 [272/918 (30%)] Loss: 12094911.000000\n",
      "Train Epoch: 85 [288/918 (31%)] Loss: 10709864.000000\n",
      "Train Epoch: 85 [304/918 (33%)] Loss: 11855520.000000\n",
      "Train Epoch: 85 [320/918 (35%)] Loss: 12696427.000000\n",
      "Train Epoch: 85 [336/918 (37%)] Loss: 9846794.000000\n",
      "Train Epoch: 85 [352/918 (38%)] Loss: 13906679.000000\n",
      "Train Epoch: 85 [368/918 (40%)] Loss: 11417762.000000\n",
      "Train Epoch: 85 [384/918 (42%)] Loss: 8383997.000000\n",
      "Train Epoch: 85 [400/918 (44%)] Loss: 13811144.000000\n",
      "Train Epoch: 85 [416/918 (45%)] Loss: 13334318.000000\n",
      "Train Epoch: 85 [432/918 (47%)] Loss: 10548639.000000\n",
      "Train Epoch: 85 [448/918 (49%)] Loss: 10798929.000000\n",
      "Train Epoch: 85 [464/918 (51%)] Loss: 9820669.000000\n",
      "Train Epoch: 85 [480/918 (52%)] Loss: 14035187.000000\n",
      "Train Epoch: 85 [496/918 (54%)] Loss: 7572305.500000\n",
      "Train Epoch: 85 [512/918 (56%)] Loss: 9745850.000000\n",
      "Train Epoch: 85 [528/918 (58%)] Loss: 9553731.000000\n",
      "Train Epoch: 85 [544/918 (59%)] Loss: 12954856.000000\n",
      "Train Epoch: 85 [560/918 (61%)] Loss: 12875595.000000\n",
      "Train Epoch: 85 [576/918 (63%)] Loss: 12650187.000000\n",
      "Train Epoch: 85 [592/918 (64%)] Loss: 9747015.000000\n",
      "Train Epoch: 85 [608/918 (66%)] Loss: 9842106.000000\n",
      "Train Epoch: 85 [624/918 (68%)] Loss: 10862541.000000\n",
      "Train Epoch: 85 [640/918 (70%)] Loss: 10295413.000000\n",
      "Train Epoch: 85 [656/918 (71%)] Loss: 8679663.000000\n",
      "Train Epoch: 85 [672/918 (73%)] Loss: 10191656.000000\n",
      "Train Epoch: 85 [688/918 (75%)] Loss: 8164142.500000\n",
      "Train Epoch: 85 [704/918 (77%)] Loss: 8374653.000000\n",
      "Train Epoch: 85 [720/918 (78%)] Loss: 9671983.000000\n",
      "Train Epoch: 85 [736/918 (80%)] Loss: 12922161.000000\n",
      "Train Epoch: 85 [752/918 (82%)] Loss: 8240785.500000\n",
      "Train Epoch: 85 [768/918 (84%)] Loss: 12779380.000000\n",
      "Train Epoch: 85 [784/918 (85%)] Loss: 10647386.000000\n",
      "Train Epoch: 85 [800/918 (87%)] Loss: 8532467.000000\n",
      "Train Epoch: 85 [816/918 (89%)] Loss: 11434535.000000\n",
      "Train Epoch: 85 [832/918 (91%)] Loss: 8587664.000000\n",
      "Train Epoch: 85 [848/918 (92%)] Loss: 12398199.000000\n",
      "Train Epoch: 85 [864/918 (94%)] Loss: 9266522.000000\n",
      "Train Epoch: 85 [880/918 (96%)] Loss: 11540616.000000\n",
      "Train Epoch: 85 [896/918 (98%)] Loss: 11001559.000000\n",
      "Train Epoch: 85 [912/918 (99%)] Loss: 10319657.000000\n",
      "    epoch          : 85\n",
      "    loss           : 10957304.265217392\n",
      "    ess            : 9.151811759368233\n",
      "    log_marginal   : -10957301.569565218\n",
      "    val_loss       : 9502043.076923076\n",
      "    val_ess        : 6.47160502580496\n",
      "    val_log_marginal: -9502040.307692308\n",
      "Train Epoch: 86 [0/918 (0%)] Loss: 8791624.000000\n",
      "Train Epoch: 86 [16/918 (2%)] Loss: 10257432.000000\n",
      "Train Epoch: 86 [32/918 (3%)] Loss: 10165679.000000\n",
      "Train Epoch: 86 [48/918 (5%)] Loss: 12828626.000000\n",
      "Train Epoch: 86 [64/918 (7%)] Loss: 10928286.000000\n",
      "Train Epoch: 86 [80/918 (9%)] Loss: 12389103.000000\n",
      "Train Epoch: 86 [96/918 (10%)] Loss: 9753003.000000\n",
      "Train Epoch: 86 [112/918 (12%)] Loss: 9693985.000000\n",
      "Train Epoch: 86 [128/918 (14%)] Loss: 8233737.500000\n",
      "Train Epoch: 86 [144/918 (16%)] Loss: 12014844.000000\n",
      "Train Epoch: 86 [160/918 (17%)] Loss: 7496678.500000\n",
      "Train Epoch: 86 [176/918 (19%)] Loss: 9726943.000000\n",
      "Train Epoch: 86 [192/918 (21%)] Loss: 7315027.500000\n",
      "Train Epoch: 86 [208/918 (23%)] Loss: 10243984.000000\n",
      "Train Epoch: 86 [224/918 (24%)] Loss: 8457472.000000\n",
      "Train Epoch: 86 [240/918 (26%)] Loss: 8525639.000000\n",
      "Train Epoch: 86 [256/918 (28%)] Loss: 9349109.000000\n",
      "Train Epoch: 86 [272/918 (30%)] Loss: 12561693.000000\n",
      "Train Epoch: 86 [288/918 (31%)] Loss: 13429127.000000\n",
      "Train Epoch: 86 [304/918 (33%)] Loss: 8759960.000000\n",
      "Train Epoch: 86 [320/918 (35%)] Loss: 11854274.000000\n",
      "Train Epoch: 86 [336/918 (37%)] Loss: 11463139.000000\n",
      "Train Epoch: 86 [352/918 (38%)] Loss: 16459290.000000\n",
      "Train Epoch: 86 [368/918 (40%)] Loss: 10421130.000000\n",
      "Train Epoch: 86 [384/918 (42%)] Loss: 10245998.000000\n",
      "Train Epoch: 86 [400/918 (44%)] Loss: 14682549.000000\n",
      "Train Epoch: 86 [416/918 (45%)] Loss: 11878955.000000\n",
      "Train Epoch: 86 [432/918 (47%)] Loss: 9923200.000000\n",
      "Train Epoch: 86 [448/918 (49%)] Loss: 8233392.000000\n",
      "Train Epoch: 86 [464/918 (51%)] Loss: 13481847.000000\n",
      "Train Epoch: 86 [480/918 (52%)] Loss: 14301479.000000\n",
      "Train Epoch: 86 [496/918 (54%)] Loss: 10619232.000000\n",
      "Train Epoch: 86 [512/918 (56%)] Loss: 9701462.000000\n",
      "Train Epoch: 86 [528/918 (58%)] Loss: 9948624.000000\n",
      "Train Epoch: 86 [544/918 (59%)] Loss: 8630098.000000\n",
      "Train Epoch: 86 [560/918 (61%)] Loss: 7984806.500000\n",
      "Train Epoch: 86 [576/918 (63%)] Loss: 11424446.000000\n",
      "Train Epoch: 86 [592/918 (64%)] Loss: 10191674.000000\n",
      "Train Epoch: 86 [608/918 (66%)] Loss: 9099164.000000\n",
      "Train Epoch: 86 [624/918 (68%)] Loss: 10973242.000000\n",
      "Train Epoch: 86 [640/918 (70%)] Loss: 10357577.000000\n",
      "Train Epoch: 86 [656/918 (71%)] Loss: 10522496.000000\n",
      "Train Epoch: 86 [672/918 (73%)] Loss: 10110447.000000\n",
      "Train Epoch: 86 [688/918 (75%)] Loss: 9971138.000000\n",
      "Train Epoch: 86 [704/918 (77%)] Loss: 15207287.000000\n",
      "Train Epoch: 86 [720/918 (78%)] Loss: 10370642.000000\n",
      "Train Epoch: 86 [736/918 (80%)] Loss: 10317828.000000\n",
      "Train Epoch: 86 [752/918 (82%)] Loss: 8107424.000000\n",
      "Train Epoch: 86 [768/918 (84%)] Loss: 8845711.000000\n",
      "Train Epoch: 86 [784/918 (85%)] Loss: 14758608.000000\n",
      "Train Epoch: 86 [800/918 (87%)] Loss: 7435389.000000\n",
      "Train Epoch: 86 [816/918 (89%)] Loss: 7610793.000000\n",
      "Train Epoch: 86 [832/918 (91%)] Loss: 9951747.000000\n",
      "Train Epoch: 86 [848/918 (92%)] Loss: 8878314.000000\n",
      "Train Epoch: 86 [864/918 (94%)] Loss: 10250683.000000\n",
      "Train Epoch: 86 [880/918 (96%)] Loss: 8694171.000000\n",
      "Train Epoch: 86 [896/918 (98%)] Loss: 11393893.000000\n",
      "Train Epoch: 86 [912/918 (99%)] Loss: 6758658.000000\n",
      "    epoch          : 86\n",
      "    loss           : 10580559.604347827\n",
      "    ess            : 8.768938931174901\n",
      "    log_marginal   : -10580557.913043479\n",
      "    val_loss       : 10015822.23076923\n",
      "    val_ess        : 5.795329900888296\n",
      "    val_log_marginal: -10015818.76923077\n",
      "Train Epoch: 87 [0/918 (0%)] Loss: 9672197.000000\n",
      "Train Epoch: 87 [16/918 (2%)] Loss: 14814754.000000\n",
      "Train Epoch: 87 [32/918 (3%)] Loss: 7718211.500000\n",
      "Train Epoch: 87 [48/918 (5%)] Loss: 14245440.000000\n",
      "Train Epoch: 87 [64/918 (7%)] Loss: 7718186.500000\n",
      "Train Epoch: 87 [80/918 (9%)] Loss: 13696288.000000\n",
      "Train Epoch: 87 [96/918 (10%)] Loss: 8203800.000000\n",
      "Train Epoch: 87 [112/918 (12%)] Loss: 8372556.000000\n",
      "Train Epoch: 87 [128/918 (14%)] Loss: 7166294.500000\n",
      "Train Epoch: 87 [144/918 (16%)] Loss: 13151622.000000\n",
      "Train Epoch: 87 [160/918 (17%)] Loss: 12075195.000000\n",
      "Train Epoch: 87 [176/918 (19%)] Loss: 12203392.000000\n",
      "Train Epoch: 87 [192/918 (21%)] Loss: 12505232.000000\n",
      "Train Epoch: 87 [208/918 (23%)] Loss: 10503117.000000\n",
      "Train Epoch: 87 [224/918 (24%)] Loss: 10587031.000000\n",
      "Train Epoch: 87 [240/918 (26%)] Loss: 17161470.000000\n",
      "Train Epoch: 87 [256/918 (28%)] Loss: 9638021.000000\n",
      "Train Epoch: 87 [272/918 (30%)] Loss: 10961084.000000\n",
      "Train Epoch: 87 [288/918 (31%)] Loss: 10158295.000000\n",
      "Train Epoch: 87 [304/918 (33%)] Loss: 10178789.000000\n",
      "Train Epoch: 87 [320/918 (35%)] Loss: 14932472.000000\n",
      "Train Epoch: 87 [336/918 (37%)] Loss: 7902964.000000\n",
      "Train Epoch: 87 [352/918 (38%)] Loss: 8662778.000000\n",
      "Train Epoch: 87 [368/918 (40%)] Loss: 7503989.000000\n",
      "Train Epoch: 87 [384/918 (42%)] Loss: 9267591.000000\n",
      "Train Epoch: 87 [400/918 (44%)] Loss: 9771139.000000\n",
      "Train Epoch: 87 [416/918 (45%)] Loss: 9776050.000000\n",
      "Train Epoch: 87 [432/918 (47%)] Loss: 15133272.000000\n",
      "Train Epoch: 87 [448/918 (49%)] Loss: 10833045.000000\n",
      "Train Epoch: 87 [464/918 (51%)] Loss: 10708051.000000\n",
      "Train Epoch: 87 [480/918 (52%)] Loss: 9093215.000000\n",
      "Train Epoch: 87 [496/918 (54%)] Loss: 12337337.000000\n",
      "Train Epoch: 87 [512/918 (56%)] Loss: 10199162.000000\n",
      "Train Epoch: 87 [528/918 (58%)] Loss: 9064589.000000\n",
      "Train Epoch: 87 [544/918 (59%)] Loss: 7519718.500000\n",
      "Train Epoch: 87 [560/918 (61%)] Loss: 10473759.000000\n",
      "Train Epoch: 87 [576/918 (63%)] Loss: 11656733.000000\n",
      "Train Epoch: 87 [592/918 (64%)] Loss: 7939206.500000\n",
      "Train Epoch: 87 [608/918 (66%)] Loss: 10957832.000000\n",
      "Train Epoch: 87 [624/918 (68%)] Loss: 11763736.000000\n",
      "Train Epoch: 87 [640/918 (70%)] Loss: 9887702.000000\n",
      "Train Epoch: 87 [656/918 (71%)] Loss: 8977723.000000\n",
      "Train Epoch: 87 [672/918 (73%)] Loss: 10032749.000000\n",
      "Train Epoch: 87 [688/918 (75%)] Loss: 8711141.000000\n",
      "Train Epoch: 87 [704/918 (77%)] Loss: 12050574.000000\n",
      "Train Epoch: 87 [720/918 (78%)] Loss: 8807632.000000\n",
      "Train Epoch: 87 [736/918 (80%)] Loss: 9895775.000000\n",
      "Train Epoch: 87 [752/918 (82%)] Loss: 9511511.000000\n",
      "Train Epoch: 87 [768/918 (84%)] Loss: 9869107.000000\n",
      "Train Epoch: 87 [784/918 (85%)] Loss: 11364866.000000\n",
      "Train Epoch: 87 [800/918 (87%)] Loss: 9208404.000000\n",
      "Train Epoch: 87 [816/918 (89%)] Loss: 10140892.000000\n",
      "Train Epoch: 87 [832/918 (91%)] Loss: 10576945.000000\n",
      "Train Epoch: 87 [848/918 (92%)] Loss: 8914298.000000\n",
      "Train Epoch: 87 [864/918 (94%)] Loss: 10477208.000000\n",
      "Train Epoch: 87 [880/918 (96%)] Loss: 7640134.500000\n",
      "Train Epoch: 87 [896/918 (98%)] Loss: 8517770.000000\n",
      "Train Epoch: 87 [912/918 (99%)] Loss: 14057295.000000\n",
      "    epoch          : 87\n",
      "    loss           : 10414593.395652173\n",
      "    ess            : 7.9597818022188935\n",
      "    log_marginal   : -10414591.986956522\n",
      "    val_loss       : 9004775.307692308\n",
      "    val_ess        : 6.067686337691087\n",
      "    val_log_marginal: -9004774.0\n",
      "Train Epoch: 88 [0/918 (0%)] Loss: 10189872.000000\n",
      "Train Epoch: 88 [16/918 (2%)] Loss: 10757364.000000\n",
      "Train Epoch: 88 [32/918 (3%)] Loss: 10899012.000000\n",
      "Train Epoch: 88 [48/918 (5%)] Loss: 7376477.500000\n",
      "Train Epoch: 88 [64/918 (7%)] Loss: 7495027.500000\n",
      "Train Epoch: 88 [80/918 (9%)] Loss: 10289332.000000\n",
      "Train Epoch: 88 [96/918 (10%)] Loss: 12888727.000000\n",
      "Train Epoch: 88 [112/918 (12%)] Loss: 11988155.000000\n",
      "Train Epoch: 88 [128/918 (14%)] Loss: 9355067.000000\n",
      "Train Epoch: 88 [144/918 (16%)] Loss: 8532674.000000\n",
      "Train Epoch: 88 [160/918 (17%)] Loss: 9204871.000000\n",
      "Train Epoch: 88 [176/918 (19%)] Loss: 9307268.000000\n",
      "Train Epoch: 88 [192/918 (21%)] Loss: 10119305.000000\n",
      "Train Epoch: 88 [208/918 (23%)] Loss: 9544769.000000\n",
      "Train Epoch: 88 [224/918 (24%)] Loss: 8548623.000000\n",
      "Train Epoch: 88 [240/918 (26%)] Loss: 8606314.000000\n",
      "Train Epoch: 88 [256/918 (28%)] Loss: 9800723.000000\n",
      "Train Epoch: 88 [272/918 (30%)] Loss: 18343456.000000\n",
      "Train Epoch: 88 [288/918 (31%)] Loss: 9057143.000000\n",
      "Train Epoch: 88 [304/918 (33%)] Loss: 11009386.000000\n",
      "Train Epoch: 88 [320/918 (35%)] Loss: 8898869.000000\n",
      "Train Epoch: 88 [336/918 (37%)] Loss: 7209612.000000\n",
      "Train Epoch: 88 [352/918 (38%)] Loss: 7725188.000000\n",
      "Train Epoch: 88 [368/918 (40%)] Loss: 11881609.000000\n",
      "Train Epoch: 88 [384/918 (42%)] Loss: 8437037.000000\n",
      "Train Epoch: 88 [400/918 (44%)] Loss: 7893357.000000\n",
      "Train Epoch: 88 [416/918 (45%)] Loss: 9918820.000000\n",
      "Train Epoch: 88 [432/918 (47%)] Loss: 8492242.000000\n",
      "Train Epoch: 88 [448/918 (49%)] Loss: 11118752.000000\n",
      "Train Epoch: 88 [464/918 (51%)] Loss: 11890373.000000\n",
      "Train Epoch: 88 [480/918 (52%)] Loss: 9240743.000000\n",
      "Train Epoch: 88 [496/918 (54%)] Loss: 11057655.000000\n",
      "Train Epoch: 88 [512/918 (56%)] Loss: 12486423.000000\n",
      "Train Epoch: 88 [528/918 (58%)] Loss: 11287671.000000\n",
      "Train Epoch: 88 [544/918 (59%)] Loss: 6565229.000000\n",
      "Train Epoch: 88 [560/918 (61%)] Loss: 8238252.000000\n",
      "Train Epoch: 88 [576/918 (63%)] Loss: 11463838.000000\n",
      "Train Epoch: 88 [592/918 (64%)] Loss: 9015100.000000\n",
      "Train Epoch: 88 [608/918 (66%)] Loss: 9748349.000000\n",
      "Train Epoch: 88 [624/918 (68%)] Loss: 7861768.000000\n",
      "Train Epoch: 88 [640/918 (70%)] Loss: 11309880.000000\n",
      "Train Epoch: 88 [656/918 (71%)] Loss: 15680453.000000\n",
      "Train Epoch: 88 [672/918 (73%)] Loss: 7734929.500000\n",
      "Train Epoch: 88 [688/918 (75%)] Loss: 7979704.000000\n",
      "Train Epoch: 88 [704/918 (77%)] Loss: 9554562.000000\n",
      "Train Epoch: 88 [720/918 (78%)] Loss: 9677405.000000\n",
      "Train Epoch: 88 [736/918 (80%)] Loss: 13592629.000000\n",
      "Train Epoch: 88 [752/918 (82%)] Loss: 8480596.000000\n",
      "Train Epoch: 88 [768/918 (84%)] Loss: 12882383.000000\n",
      "Train Epoch: 88 [784/918 (85%)] Loss: 8723741.000000\n",
      "Train Epoch: 88 [800/918 (87%)] Loss: 8833282.000000\n",
      "Train Epoch: 88 [816/918 (89%)] Loss: 8711179.000000\n",
      "Train Epoch: 88 [832/918 (91%)] Loss: 5983236.000000\n",
      "Train Epoch: 88 [848/918 (92%)] Loss: 10677044.000000\n",
      "Train Epoch: 88 [864/918 (94%)] Loss: 15002323.000000\n",
      "Train Epoch: 88 [880/918 (96%)] Loss: 11584470.000000\n",
      "Train Epoch: 88 [896/918 (98%)] Loss: 7376933.500000\n",
      "Train Epoch: 88 [912/918 (99%)] Loss: 17462182.000000\n",
      "    epoch          : 88\n",
      "    loss           : 10232019.078260869\n",
      "    ess            : 8.571409358148989\n",
      "    log_marginal   : -10232017.360869566\n",
      "    val_loss       : 9473055.076923076\n",
      "    val_ess        : 6.202909396244929\n",
      "    val_log_marginal: -9473054.153846154\n",
      "Train Epoch: 89 [0/918 (0%)] Loss: 10973375.000000\n",
      "Train Epoch: 89 [16/918 (2%)] Loss: 7247972.000000\n",
      "Train Epoch: 89 [32/918 (3%)] Loss: 15502731.000000\n",
      "Train Epoch: 89 [48/918 (5%)] Loss: 11686956.000000\n",
      "Train Epoch: 89 [64/918 (7%)] Loss: 6790258.500000\n",
      "Train Epoch: 89 [80/918 (9%)] Loss: 10003352.000000\n",
      "Train Epoch: 89 [96/918 (10%)] Loss: 10229480.000000\n",
      "Train Epoch: 89 [112/918 (12%)] Loss: 8557443.000000\n",
      "Train Epoch: 89 [128/918 (14%)] Loss: 11306769.000000\n",
      "Train Epoch: 89 [144/918 (16%)] Loss: 12877787.000000\n",
      "Train Epoch: 89 [160/918 (17%)] Loss: 11850718.000000\n",
      "Train Epoch: 89 [176/918 (19%)] Loss: 10192104.000000\n",
      "Train Epoch: 89 [192/918 (21%)] Loss: 10530251.000000\n",
      "Train Epoch: 89 [208/918 (23%)] Loss: 10051898.000000\n",
      "Train Epoch: 89 [224/918 (24%)] Loss: 9656194.000000\n",
      "Train Epoch: 89 [240/918 (26%)] Loss: 9690133.000000\n",
      "Train Epoch: 89 [256/918 (28%)] Loss: 9918008.000000\n",
      "Train Epoch: 89 [272/918 (30%)] Loss: 9623148.000000\n",
      "Train Epoch: 89 [288/918 (31%)] Loss: 14641493.000000\n",
      "Train Epoch: 89 [304/918 (33%)] Loss: 15814890.000000\n",
      "Train Epoch: 89 [320/918 (35%)] Loss: 11107344.000000\n",
      "Train Epoch: 89 [336/918 (37%)] Loss: 8556007.000000\n",
      "Train Epoch: 89 [352/918 (38%)] Loss: 12833154.000000\n",
      "Train Epoch: 89 [368/918 (40%)] Loss: 8137088.000000\n",
      "Train Epoch: 89 [384/918 (42%)] Loss: 8473213.000000\n",
      "Train Epoch: 89 [400/918 (44%)] Loss: 7115159.500000\n",
      "Train Epoch: 89 [416/918 (45%)] Loss: 14819955.000000\n",
      "Train Epoch: 89 [432/918 (47%)] Loss: 9750250.000000\n",
      "Train Epoch: 89 [448/918 (49%)] Loss: 8044532.000000\n",
      "Train Epoch: 89 [464/918 (51%)] Loss: 10643650.000000\n",
      "Train Epoch: 89 [480/918 (52%)] Loss: 10725271.000000\n",
      "Train Epoch: 89 [496/918 (54%)] Loss: 9883407.000000\n",
      "Train Epoch: 89 [512/918 (56%)] Loss: 9351588.000000\n",
      "Train Epoch: 89 [528/918 (58%)] Loss: 11195104.000000\n",
      "Train Epoch: 89 [544/918 (59%)] Loss: 11783742.000000\n",
      "Train Epoch: 89 [560/918 (61%)] Loss: 11010260.000000\n",
      "Train Epoch: 89 [576/918 (63%)] Loss: 10873198.000000\n",
      "Train Epoch: 89 [592/918 (64%)] Loss: 13562320.000000\n",
      "Train Epoch: 89 [608/918 (66%)] Loss: 13908064.000000\n",
      "Train Epoch: 89 [624/918 (68%)] Loss: 9907067.000000\n",
      "Train Epoch: 89 [640/918 (70%)] Loss: 9577376.000000\n",
      "Train Epoch: 89 [656/918 (71%)] Loss: 7071475.500000\n",
      "Train Epoch: 89 [672/918 (73%)] Loss: 6788348.000000\n",
      "Train Epoch: 89 [688/918 (75%)] Loss: 13510080.000000\n",
      "Train Epoch: 89 [704/918 (77%)] Loss: 9656934.000000\n",
      "Train Epoch: 89 [720/918 (78%)] Loss: 9455551.000000\n",
      "Train Epoch: 89 [736/918 (80%)] Loss: 9566955.000000\n",
      "Train Epoch: 89 [752/918 (82%)] Loss: 6628670.000000\n",
      "Train Epoch: 89 [768/918 (84%)] Loss: 9166565.000000\n",
      "Train Epoch: 89 [784/918 (85%)] Loss: 9862935.000000\n",
      "Train Epoch: 89 [800/918 (87%)] Loss: 11340645.000000\n",
      "Train Epoch: 89 [816/918 (89%)] Loss: 10418427.000000\n",
      "Train Epoch: 89 [832/918 (91%)] Loss: 11916707.000000\n",
      "Train Epoch: 89 [848/918 (92%)] Loss: 7734433.000000\n",
      "Train Epoch: 89 [864/918 (94%)] Loss: 16941556.000000\n",
      "Train Epoch: 89 [880/918 (96%)] Loss: 10987456.000000\n",
      "Train Epoch: 89 [896/918 (98%)] Loss: 9798367.000000\n",
      "Train Epoch: 89 [912/918 (99%)] Loss: 7969351.000000\n",
      "    epoch          : 89\n",
      "    loss           : 9985235.617391305\n",
      "    ess            : 8.05673680305481\n",
      "    log_marginal   : -9985233.27826087\n",
      "    val_loss       : 9351217.884615384\n",
      "    val_ess        : 7.033086098157442\n",
      "    val_log_marginal: -9351216.423076924\n",
      "Train Epoch: 90 [0/918 (0%)] Loss: 9650221.000000\n",
      "Train Epoch: 90 [16/918 (2%)] Loss: 12281999.000000\n",
      "Train Epoch: 90 [32/918 (3%)] Loss: 8879124.000000\n",
      "Train Epoch: 90 [48/918 (5%)] Loss: 10634354.000000\n",
      "Train Epoch: 90 [64/918 (7%)] Loss: 8411807.000000\n",
      "Train Epoch: 90 [80/918 (9%)] Loss: 8815131.000000\n",
      "Train Epoch: 90 [96/918 (10%)] Loss: 8591507.000000\n",
      "Train Epoch: 90 [112/918 (12%)] Loss: 7171837.500000\n",
      "Train Epoch: 90 [128/918 (14%)] Loss: 8990824.000000\n",
      "Train Epoch: 90 [144/918 (16%)] Loss: 10943725.000000\n",
      "Train Epoch: 90 [160/918 (17%)] Loss: 13374817.000000\n",
      "Train Epoch: 90 [176/918 (19%)] Loss: 9938074.000000\n",
      "Train Epoch: 90 [192/918 (21%)] Loss: 9884026.000000\n",
      "Train Epoch: 90 [208/918 (23%)] Loss: 9100631.000000\n",
      "Train Epoch: 90 [224/918 (24%)] Loss: 10113914.000000\n",
      "Train Epoch: 90 [240/918 (26%)] Loss: 6560190.000000\n",
      "Train Epoch: 90 [256/918 (28%)] Loss: 8412596.000000\n",
      "Train Epoch: 90 [272/918 (30%)] Loss: 7569965.500000\n",
      "Train Epoch: 90 [288/918 (31%)] Loss: 11546779.000000\n",
      "Train Epoch: 90 [304/918 (33%)] Loss: 8799268.000000\n",
      "Train Epoch: 90 [320/918 (35%)] Loss: 8232393.000000\n",
      "Train Epoch: 90 [336/918 (37%)] Loss: 10371048.000000\n",
      "Train Epoch: 90 [352/918 (38%)] Loss: 7177031.500000\n",
      "Train Epoch: 90 [368/918 (40%)] Loss: 9245607.000000\n",
      "Train Epoch: 90 [384/918 (42%)] Loss: 8805576.000000\n",
      "Train Epoch: 90 [400/918 (44%)] Loss: 9433248.000000\n",
      "Train Epoch: 90 [416/918 (45%)] Loss: 8109159.500000\n",
      "Train Epoch: 90 [432/918 (47%)] Loss: 9128485.000000\n",
      "Train Epoch: 90 [448/918 (49%)] Loss: 8378745.500000\n",
      "Train Epoch: 90 [464/918 (51%)] Loss: 9340720.000000\n",
      "Train Epoch: 90 [480/918 (52%)] Loss: 7600875.500000\n",
      "Train Epoch: 90 [496/918 (54%)] Loss: 11912632.000000\n",
      "Train Epoch: 90 [512/918 (56%)] Loss: 16204291.000000\n",
      "Train Epoch: 90 [528/918 (58%)] Loss: 8936036.000000\n",
      "Train Epoch: 90 [544/918 (59%)] Loss: 10994720.000000\n",
      "Train Epoch: 90 [560/918 (61%)] Loss: 8189701.000000\n",
      "Train Epoch: 90 [576/918 (63%)] Loss: 9214875.000000\n",
      "Train Epoch: 90 [592/918 (64%)] Loss: 10463711.000000\n",
      "Train Epoch: 90 [608/918 (66%)] Loss: 7651065.000000\n",
      "Train Epoch: 90 [624/918 (68%)] Loss: 11309544.000000\n",
      "Train Epoch: 90 [640/918 (70%)] Loss: 10995658.000000\n",
      "Train Epoch: 90 [656/918 (71%)] Loss: 10227727.000000\n",
      "Train Epoch: 90 [672/918 (73%)] Loss: 9771715.000000\n",
      "Train Epoch: 90 [688/918 (75%)] Loss: 8270465.000000\n",
      "Train Epoch: 90 [704/918 (77%)] Loss: 9181411.000000\n",
      "Train Epoch: 90 [720/918 (78%)] Loss: 9196016.000000\n",
      "Train Epoch: 90 [736/918 (80%)] Loss: 9766223.000000\n",
      "Train Epoch: 90 [752/918 (82%)] Loss: 13775583.000000\n",
      "Train Epoch: 90 [768/918 (84%)] Loss: 6357723.000000\n",
      "Train Epoch: 90 [784/918 (85%)] Loss: 12286655.000000\n",
      "Train Epoch: 90 [800/918 (87%)] Loss: 10527335.000000\n",
      "Train Epoch: 90 [816/918 (89%)] Loss: 7791049.500000\n",
      "Train Epoch: 90 [832/918 (91%)] Loss: 10152660.000000\n",
      "Train Epoch: 90 [848/918 (92%)] Loss: 9672972.000000\n",
      "Train Epoch: 90 [864/918 (94%)] Loss: 11089566.000000\n",
      "Train Epoch: 90 [880/918 (96%)] Loss: 13271989.000000\n",
      "Train Epoch: 90 [896/918 (98%)] Loss: 11086988.000000\n",
      "Train Epoch: 90 [912/918 (99%)] Loss: 9739145.000000\n",
      "    epoch          : 90\n",
      "    loss           : 9682185.534782609\n",
      "    ess            : 8.029849201699962\n",
      "    log_marginal   : -9682182.543478262\n",
      "    val_loss       : 8622866.923076924\n",
      "    val_ess        : 6.779666093679575\n",
      "    val_log_marginal: -8622866.346153846\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch90.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 91 [0/918 (0%)] Loss: 9873171.000000\n",
      "Train Epoch: 91 [16/918 (2%)] Loss: 9240099.000000\n",
      "Train Epoch: 91 [32/918 (3%)] Loss: 10768388.000000\n",
      "Train Epoch: 91 [48/918 (5%)] Loss: 11643954.000000\n",
      "Train Epoch: 91 [64/918 (7%)] Loss: 10651752.000000\n",
      "Train Epoch: 91 [80/918 (9%)] Loss: 9165727.000000\n",
      "Train Epoch: 91 [96/918 (10%)] Loss: 8803244.000000\n",
      "Train Epoch: 91 [112/918 (12%)] Loss: 8600830.000000\n",
      "Train Epoch: 91 [128/918 (14%)] Loss: 8153244.000000\n",
      "Train Epoch: 91 [144/918 (16%)] Loss: 7316555.500000\n",
      "Train Epoch: 91 [160/918 (17%)] Loss: 10814895.000000\n",
      "Train Epoch: 91 [176/918 (19%)] Loss: 7209669.000000\n",
      "Train Epoch: 91 [192/918 (21%)] Loss: 7178381.000000\n",
      "Train Epoch: 91 [208/918 (23%)] Loss: 9119259.000000\n",
      "Train Epoch: 91 [224/918 (24%)] Loss: 9136234.000000\n",
      "Train Epoch: 91 [240/918 (26%)] Loss: 7166842.500000\n",
      "Train Epoch: 91 [256/918 (28%)] Loss: 8867756.000000\n",
      "Train Epoch: 91 [272/918 (30%)] Loss: 7748423.500000\n",
      "Train Epoch: 91 [288/918 (31%)] Loss: 6725353.500000\n",
      "Train Epoch: 91 [304/918 (33%)] Loss: 10721057.000000\n",
      "Train Epoch: 91 [320/918 (35%)] Loss: 8974356.000000\n",
      "Train Epoch: 91 [336/918 (37%)] Loss: 9721364.000000\n",
      "Train Epoch: 91 [352/918 (38%)] Loss: 10503266.000000\n",
      "Train Epoch: 91 [368/918 (40%)] Loss: 9455760.000000\n",
      "Train Epoch: 91 [384/918 (42%)] Loss: 8230534.500000\n",
      "Train Epoch: 91 [400/918 (44%)] Loss: 11362032.000000\n",
      "Train Epoch: 91 [416/918 (45%)] Loss: 10203467.000000\n",
      "Train Epoch: 91 [432/918 (47%)] Loss: 12131114.000000\n",
      "Train Epoch: 91 [448/918 (49%)] Loss: 15290639.000000\n",
      "Train Epoch: 91 [464/918 (51%)] Loss: 11840549.000000\n",
      "Train Epoch: 91 [480/918 (52%)] Loss: 9882722.000000\n",
      "Train Epoch: 91 [496/918 (54%)] Loss: 8053611.500000\n",
      "Train Epoch: 91 [512/918 (56%)] Loss: 8077952.000000\n",
      "Train Epoch: 91 [528/918 (58%)] Loss: 8084817.500000\n",
      "Train Epoch: 91 [544/918 (59%)] Loss: 8889995.000000\n",
      "Train Epoch: 91 [560/918 (61%)] Loss: 12139303.000000\n",
      "Train Epoch: 91 [576/918 (63%)] Loss: 10493005.000000\n",
      "Train Epoch: 91 [592/918 (64%)] Loss: 9384111.000000\n",
      "Train Epoch: 91 [608/918 (66%)] Loss: 8236002.500000\n",
      "Train Epoch: 91 [624/918 (68%)] Loss: 8743728.000000\n",
      "Train Epoch: 91 [640/918 (70%)] Loss: 10990375.000000\n",
      "Train Epoch: 91 [656/918 (71%)] Loss: 7468929.000000\n",
      "Train Epoch: 91 [672/918 (73%)] Loss: 8303451.500000\n",
      "Train Epoch: 91 [688/918 (75%)] Loss: 9477364.000000\n",
      "Train Epoch: 91 [704/918 (77%)] Loss: 6470426.500000\n",
      "Train Epoch: 91 [720/918 (78%)] Loss: 10553864.000000\n",
      "Train Epoch: 91 [736/918 (80%)] Loss: 11170573.000000\n",
      "Train Epoch: 91 [752/918 (82%)] Loss: 8065021.000000\n",
      "Train Epoch: 91 [768/918 (84%)] Loss: 9051279.000000\n",
      "Train Epoch: 91 [784/918 (85%)] Loss: 8875327.000000\n",
      "Train Epoch: 91 [800/918 (87%)] Loss: 7410270.500000\n",
      "Train Epoch: 91 [816/918 (89%)] Loss: 8788002.000000\n",
      "Train Epoch: 91 [832/918 (91%)] Loss: 8933084.000000\n",
      "Train Epoch: 91 [848/918 (92%)] Loss: 8065687.500000\n",
      "Train Epoch: 91 [864/918 (94%)] Loss: 8299844.000000\n",
      "Train Epoch: 91 [880/918 (96%)] Loss: 13801459.000000\n",
      "Train Epoch: 91 [896/918 (98%)] Loss: 10160049.000000\n",
      "Train Epoch: 91 [912/918 (99%)] Loss: 17594302.000000\n",
      "    epoch          : 91\n",
      "    loss           : 9591582.456521738\n",
      "    ess            : 7.409189359001491\n",
      "    log_marginal   : -9591580.956521738\n",
      "    val_loss       : 9517442.923076924\n",
      "    val_ess        : 8.974635949501625\n",
      "    val_log_marginal: -9517441.076923076\n",
      "Train Epoch: 92 [0/918 (0%)] Loss: 8498034.000000\n",
      "Train Epoch: 92 [16/918 (2%)] Loss: 9302215.000000\n",
      "Train Epoch: 92 [32/918 (3%)] Loss: 8009345.500000\n",
      "Train Epoch: 92 [48/918 (5%)] Loss: 11881551.000000\n",
      "Train Epoch: 92 [64/918 (7%)] Loss: 8558099.000000\n",
      "Train Epoch: 92 [80/918 (9%)] Loss: 7198110.500000\n",
      "Train Epoch: 92 [96/918 (10%)] Loss: 10340312.000000\n",
      "Train Epoch: 92 [112/918 (12%)] Loss: 6420303.500000\n",
      "Train Epoch: 92 [128/918 (14%)] Loss: 12571443.000000\n",
      "Train Epoch: 92 [144/918 (16%)] Loss: 9586907.000000\n",
      "Train Epoch: 92 [160/918 (17%)] Loss: 10466656.000000\n",
      "Train Epoch: 92 [176/918 (19%)] Loss: 9995568.000000\n",
      "Train Epoch: 92 [192/918 (21%)] Loss: 11648346.000000\n",
      "Train Epoch: 92 [208/918 (23%)] Loss: 7074013.000000\n",
      "Train Epoch: 92 [224/918 (24%)] Loss: 8320029.500000\n",
      "Train Epoch: 92 [240/918 (26%)] Loss: 11541962.000000\n",
      "Train Epoch: 92 [256/918 (28%)] Loss: 13483275.000000\n",
      "Train Epoch: 92 [272/918 (30%)] Loss: 10186261.000000\n",
      "Train Epoch: 92 [288/918 (31%)] Loss: 8457507.000000\n",
      "Train Epoch: 92 [304/918 (33%)] Loss: 9429619.000000\n",
      "Train Epoch: 92 [320/918 (35%)] Loss: 7524792.000000\n",
      "Train Epoch: 92 [336/918 (37%)] Loss: 9951147.000000\n",
      "Train Epoch: 92 [352/918 (38%)] Loss: 7001729.000000\n",
      "Train Epoch: 92 [368/918 (40%)] Loss: 11736632.000000\n",
      "Train Epoch: 92 [384/918 (42%)] Loss: 9584128.000000\n",
      "Train Epoch: 92 [400/918 (44%)] Loss: 12912112.000000\n",
      "Train Epoch: 92 [416/918 (45%)] Loss: 13936021.000000\n",
      "Train Epoch: 92 [432/918 (47%)] Loss: 8857571.000000\n",
      "Train Epoch: 92 [448/918 (49%)] Loss: 6562675.500000\n",
      "Train Epoch: 92 [464/918 (51%)] Loss: 8468799.000000\n",
      "Train Epoch: 92 [480/918 (52%)] Loss: 7478113.500000\n",
      "Train Epoch: 92 [496/918 (54%)] Loss: 8099316.000000\n",
      "Train Epoch: 92 [512/918 (56%)] Loss: 8982895.000000\n",
      "Train Epoch: 92 [528/918 (58%)] Loss: 9322500.000000\n",
      "Train Epoch: 92 [544/918 (59%)] Loss: 7363632.000000\n",
      "Train Epoch: 92 [560/918 (61%)] Loss: 9264760.000000\n",
      "Train Epoch: 92 [576/918 (63%)] Loss: 8381609.500000\n",
      "Train Epoch: 92 [592/918 (64%)] Loss: 8136278.500000\n",
      "Train Epoch: 92 [608/918 (66%)] Loss: 10329120.000000\n",
      "Train Epoch: 92 [624/918 (68%)] Loss: 9994827.000000\n",
      "Train Epoch: 92 [640/918 (70%)] Loss: 7139662.500000\n",
      "Train Epoch: 92 [656/918 (71%)] Loss: 8585036.000000\n",
      "Train Epoch: 92 [672/918 (73%)] Loss: 8552635.000000\n",
      "Train Epoch: 92 [688/918 (75%)] Loss: 10791568.000000\n",
      "Train Epoch: 92 [704/918 (77%)] Loss: 8110677.000000\n",
      "Train Epoch: 92 [720/918 (78%)] Loss: 9930042.000000\n",
      "Train Epoch: 92 [736/918 (80%)] Loss: 7075318.500000\n",
      "Train Epoch: 92 [752/918 (82%)] Loss: 8853630.000000\n",
      "Train Epoch: 92 [768/918 (84%)] Loss: 7927213.000000\n",
      "Train Epoch: 92 [784/918 (85%)] Loss: 8944079.000000\n",
      "Train Epoch: 92 [800/918 (87%)] Loss: 8939949.000000\n",
      "Train Epoch: 92 [816/918 (89%)] Loss: 10462519.000000\n",
      "Train Epoch: 92 [832/918 (91%)] Loss: 9066036.000000\n",
      "Train Epoch: 92 [848/918 (92%)] Loss: 10134630.000000\n",
      "Train Epoch: 92 [864/918 (94%)] Loss: 7432373.000000\n",
      "Train Epoch: 92 [880/918 (96%)] Loss: 10159477.000000\n",
      "Train Epoch: 92 [896/918 (98%)] Loss: 7462595.500000\n",
      "Train Epoch: 92 [912/918 (99%)] Loss: 10216780.000000\n",
      "    epoch          : 92\n",
      "    loss           : 9403504.1\n",
      "    ess            : 7.378704058605692\n",
      "    log_marginal   : -9403501.804347826\n",
      "    val_loss       : 8688145.807692308\n",
      "    val_ess        : 6.3825279749356785\n",
      "    val_log_marginal: -8688142.423076924\n",
      "Train Epoch: 93 [0/918 (0%)] Loss: 7809749.500000\n",
      "Train Epoch: 93 [16/918 (2%)] Loss: 8351376.000000\n",
      "Train Epoch: 93 [32/918 (3%)] Loss: 9036197.000000\n",
      "Train Epoch: 93 [48/918 (5%)] Loss: 10077832.000000\n",
      "Train Epoch: 93 [64/918 (7%)] Loss: 7481742.500000\n",
      "Train Epoch: 93 [80/918 (9%)] Loss: 10167044.000000\n",
      "Train Epoch: 93 [96/918 (10%)] Loss: 8085637.000000\n",
      "Train Epoch: 93 [112/918 (12%)] Loss: 11298767.000000\n",
      "Train Epoch: 93 [128/918 (14%)] Loss: 9463649.000000\n",
      "Train Epoch: 93 [144/918 (16%)] Loss: 8749687.000000\n",
      "Train Epoch: 93 [160/918 (17%)] Loss: 7297486.500000\n",
      "Train Epoch: 93 [176/918 (19%)] Loss: 12431462.000000\n",
      "Train Epoch: 93 [192/918 (21%)] Loss: 9186601.000000\n",
      "Train Epoch: 93 [208/918 (23%)] Loss: 6107781.500000\n",
      "Train Epoch: 93 [224/918 (24%)] Loss: 9777055.000000\n",
      "Train Epoch: 93 [240/918 (26%)] Loss: 11243266.000000\n",
      "Train Epoch: 93 [256/918 (28%)] Loss: 8178337.500000\n",
      "Train Epoch: 93 [272/918 (30%)] Loss: 5717551.500000\n",
      "Train Epoch: 93 [288/918 (31%)] Loss: 6195317.500000\n",
      "Train Epoch: 93 [304/918 (33%)] Loss: 9577426.000000\n",
      "Train Epoch: 93 [320/918 (35%)] Loss: 13622618.000000\n",
      "Train Epoch: 93 [336/918 (37%)] Loss: 8175635.500000\n",
      "Train Epoch: 93 [352/918 (38%)] Loss: 7656401.500000\n",
      "Train Epoch: 93 [368/918 (40%)] Loss: 9031770.000000\n",
      "Train Epoch: 93 [384/918 (42%)] Loss: 9851823.000000\n",
      "Train Epoch: 93 [400/918 (44%)] Loss: 12598335.000000\n",
      "Train Epoch: 93 [416/918 (45%)] Loss: 9692208.000000\n",
      "Train Epoch: 93 [432/918 (47%)] Loss: 12392060.000000\n",
      "Train Epoch: 93 [448/918 (49%)] Loss: 8261205.500000\n",
      "Train Epoch: 93 [464/918 (51%)] Loss: 6988008.000000\n",
      "Train Epoch: 93 [480/918 (52%)] Loss: 9219807.000000\n",
      "Train Epoch: 93 [496/918 (54%)] Loss: 9388465.000000\n",
      "Train Epoch: 93 [512/918 (56%)] Loss: 10811564.000000\n",
      "Train Epoch: 93 [528/918 (58%)] Loss: 8483928.000000\n",
      "Train Epoch: 93 [544/918 (59%)] Loss: 12023786.000000\n",
      "Train Epoch: 93 [560/918 (61%)] Loss: 11256964.000000\n",
      "Train Epoch: 93 [576/918 (63%)] Loss: 7719417.500000\n",
      "Train Epoch: 93 [592/918 (64%)] Loss: 9516405.000000\n",
      "Train Epoch: 93 [608/918 (66%)] Loss: 7856432.000000\n",
      "Train Epoch: 93 [624/918 (68%)] Loss: 12430435.000000\n",
      "Train Epoch: 93 [640/918 (70%)] Loss: 12949518.000000\n",
      "Train Epoch: 93 [656/918 (71%)] Loss: 8850309.000000\n",
      "Train Epoch: 93 [672/918 (73%)] Loss: 7830841.500000\n",
      "Train Epoch: 93 [688/918 (75%)] Loss: 10510129.000000\n",
      "Train Epoch: 93 [704/918 (77%)] Loss: 9322075.000000\n",
      "Train Epoch: 93 [720/918 (78%)] Loss: 6971198.500000\n",
      "Train Epoch: 93 [736/918 (80%)] Loss: 8281293.500000\n",
      "Train Epoch: 93 [752/918 (82%)] Loss: 8740723.000000\n",
      "Train Epoch: 93 [768/918 (84%)] Loss: 12740299.000000\n",
      "Train Epoch: 93 [784/918 (85%)] Loss: 11990675.000000\n",
      "Train Epoch: 93 [800/918 (87%)] Loss: 13496995.000000\n",
      "Train Epoch: 93 [816/918 (89%)] Loss: 6298141.500000\n",
      "Train Epoch: 93 [832/918 (91%)] Loss: 7006793.000000\n",
      "Train Epoch: 93 [848/918 (92%)] Loss: 12160026.000000\n",
      "Train Epoch: 93 [864/918 (94%)] Loss: 8645488.000000\n",
      "Train Epoch: 93 [880/918 (96%)] Loss: 8593616.000000\n",
      "Train Epoch: 93 [896/918 (98%)] Loss: 7225169.000000\n",
      "Train Epoch: 93 [912/918 (99%)] Loss: 6325202.500000\n",
      "    epoch          : 93\n",
      "    loss           : 9244342.986956522\n",
      "    ess            : 6.980537242474763\n",
      "    log_marginal   : -9244341.095652174\n",
      "    val_loss       : 8861420.923076924\n",
      "    val_ess        : 6.899149784675012\n",
      "    val_log_marginal: -8861419.076923076\n",
      "Train Epoch: 94 [0/918 (0%)] Loss: 5932647.000000\n",
      "Train Epoch: 94 [16/918 (2%)] Loss: 7511817.500000\n",
      "Train Epoch: 94 [32/918 (3%)] Loss: 12890099.000000\n",
      "Train Epoch: 94 [48/918 (5%)] Loss: 7344264.000000\n",
      "Train Epoch: 94 [64/918 (7%)] Loss: 9109387.000000\n",
      "Train Epoch: 94 [80/918 (9%)] Loss: 8553711.000000\n",
      "Train Epoch: 94 [96/918 (10%)] Loss: 10027687.000000\n",
      "Train Epoch: 94 [112/918 (12%)] Loss: 9577204.000000\n",
      "Train Epoch: 94 [128/918 (14%)] Loss: 8940059.000000\n",
      "Train Epoch: 94 [144/918 (16%)] Loss: 9811463.000000\n",
      "Train Epoch: 94 [160/918 (17%)] Loss: 11906639.000000\n",
      "Train Epoch: 94 [176/918 (19%)] Loss: 9288954.000000\n",
      "Train Epoch: 94 [192/918 (21%)] Loss: 8571480.000000\n",
      "Train Epoch: 94 [208/918 (23%)] Loss: 8903170.000000\n",
      "Train Epoch: 94 [224/918 (24%)] Loss: 7026238.500000\n",
      "Train Epoch: 94 [240/918 (26%)] Loss: 5997987.000000\n",
      "Train Epoch: 94 [256/918 (28%)] Loss: 9211451.000000\n",
      "Train Epoch: 94 [272/918 (30%)] Loss: 6745558.500000\n",
      "Train Epoch: 94 [288/918 (31%)] Loss: 8629943.000000\n",
      "Train Epoch: 94 [304/918 (33%)] Loss: 13959479.000000\n",
      "Train Epoch: 94 [320/918 (35%)] Loss: 10463051.000000\n",
      "Train Epoch: 94 [336/918 (37%)] Loss: 7833173.000000\n",
      "Train Epoch: 94 [352/918 (38%)] Loss: 10796903.000000\n",
      "Train Epoch: 94 [368/918 (40%)] Loss: 12284827.000000\n",
      "Train Epoch: 94 [384/918 (42%)] Loss: 9007396.000000\n",
      "Train Epoch: 94 [400/918 (44%)] Loss: 8030951.500000\n",
      "Train Epoch: 94 [416/918 (45%)] Loss: 10546802.000000\n",
      "Train Epoch: 94 [432/918 (47%)] Loss: 7759559.500000\n",
      "Train Epoch: 94 [448/918 (49%)] Loss: 13834469.000000\n",
      "Train Epoch: 94 [464/918 (51%)] Loss: 8349112.000000\n",
      "Train Epoch: 94 [480/918 (52%)] Loss: 8468186.000000\n",
      "Train Epoch: 94 [496/918 (54%)] Loss: 9909809.000000\n",
      "Train Epoch: 94 [512/918 (56%)] Loss: 9562607.000000\n",
      "Train Epoch: 94 [528/918 (58%)] Loss: 8372669.000000\n",
      "Train Epoch: 94 [544/918 (59%)] Loss: 8877459.000000\n",
      "Train Epoch: 94 [560/918 (61%)] Loss: 10082654.000000\n",
      "Train Epoch: 94 [576/918 (63%)] Loss: 9625755.000000\n",
      "Train Epoch: 94 [592/918 (64%)] Loss: 8962919.000000\n",
      "Train Epoch: 94 [608/918 (66%)] Loss: 7389107.500000\n",
      "Train Epoch: 94 [624/918 (68%)] Loss: 6877736.000000\n",
      "Train Epoch: 94 [640/918 (70%)] Loss: 7532337.500000\n",
      "Train Epoch: 94 [656/918 (71%)] Loss: 7638869.000000\n",
      "Train Epoch: 94 [672/918 (73%)] Loss: 9244556.000000\n",
      "Train Epoch: 94 [688/918 (75%)] Loss: 8100539.500000\n",
      "Train Epoch: 94 [704/918 (77%)] Loss: 10730829.000000\n",
      "Train Epoch: 94 [720/918 (78%)] Loss: 9819785.000000\n",
      "Train Epoch: 94 [736/918 (80%)] Loss: 12687515.000000\n",
      "Train Epoch: 94 [752/918 (82%)] Loss: 9763819.000000\n",
      "Train Epoch: 94 [768/918 (84%)] Loss: 7877609.500000\n",
      "Train Epoch: 94 [784/918 (85%)] Loss: 8722647.000000\n",
      "Train Epoch: 94 [800/918 (87%)] Loss: 7776339.500000\n",
      "Train Epoch: 94 [816/918 (89%)] Loss: 7232846.500000\n",
      "Train Epoch: 94 [832/918 (91%)] Loss: 7411505.500000\n",
      "Train Epoch: 94 [848/918 (92%)] Loss: 8262224.000000\n",
      "Train Epoch: 94 [864/918 (94%)] Loss: 15315959.000000\n",
      "Train Epoch: 94 [880/918 (96%)] Loss: 6440591.500000\n",
      "Train Epoch: 94 [896/918 (98%)] Loss: 8087364.000000\n",
      "Train Epoch: 94 [912/918 (99%)] Loss: 6465058.500000\n",
      "    epoch          : 94\n",
      "    loss           : 9357189.717391305\n",
      "    ess            : 8.137448366828586\n",
      "    log_marginal   : -9357188.465217391\n",
      "    val_loss       : 8874252.384615384\n",
      "    val_ess        : 8.627296887911283\n",
      "    val_log_marginal: -8874251.0\n",
      "Train Epoch: 95 [0/918 (0%)] Loss: 8295785.500000\n",
      "Train Epoch: 95 [16/918 (2%)] Loss: 6750696.000000\n",
      "Train Epoch: 95 [32/918 (3%)] Loss: 8635344.000000\n",
      "Train Epoch: 95 [48/918 (5%)] Loss: 8941691.000000\n",
      "Train Epoch: 95 [64/918 (7%)] Loss: 8871218.000000\n",
      "Train Epoch: 95 [80/918 (9%)] Loss: 7955670.500000\n",
      "Train Epoch: 95 [96/918 (10%)] Loss: 6707818.000000\n",
      "Train Epoch: 95 [112/918 (12%)] Loss: 8352566.500000\n",
      "Train Epoch: 95 [128/918 (14%)] Loss: 9203345.000000\n",
      "Train Epoch: 95 [144/918 (16%)] Loss: 9135600.000000\n",
      "Train Epoch: 95 [160/918 (17%)] Loss: 6821561.500000\n",
      "Train Epoch: 95 [176/918 (19%)] Loss: 11404349.000000\n",
      "Train Epoch: 95 [192/918 (21%)] Loss: 11437283.000000\n",
      "Train Epoch: 95 [208/918 (23%)] Loss: 9333419.000000\n",
      "Train Epoch: 95 [224/918 (24%)] Loss: 9395687.000000\n",
      "Train Epoch: 95 [240/918 (26%)] Loss: 9387184.000000\n",
      "Train Epoch: 95 [256/918 (28%)] Loss: 10700219.000000\n",
      "Train Epoch: 95 [272/918 (30%)] Loss: 9461167.000000\n",
      "Train Epoch: 95 [288/918 (31%)] Loss: 9858048.000000\n",
      "Train Epoch: 95 [304/918 (33%)] Loss: 8307446.500000\n",
      "Train Epoch: 95 [320/918 (35%)] Loss: 6401798.500000\n",
      "Train Epoch: 95 [336/918 (37%)] Loss: 11398215.000000\n",
      "Train Epoch: 95 [352/918 (38%)] Loss: 7160369.000000\n",
      "Train Epoch: 95 [368/918 (40%)] Loss: 9090743.000000\n",
      "Train Epoch: 95 [384/918 (42%)] Loss: 7410071.500000\n",
      "Train Epoch: 95 [400/918 (44%)] Loss: 13229117.000000\n",
      "Train Epoch: 95 [416/918 (45%)] Loss: 9272493.000000\n",
      "Train Epoch: 95 [432/918 (47%)] Loss: 7689437.000000\n",
      "Train Epoch: 95 [448/918 (49%)] Loss: 9061624.000000\n",
      "Train Epoch: 95 [464/918 (51%)] Loss: 14076754.000000\n",
      "Train Epoch: 95 [480/918 (52%)] Loss: 8521716.000000\n",
      "Train Epoch: 95 [496/918 (54%)] Loss: 9991876.000000\n",
      "Train Epoch: 95 [512/918 (56%)] Loss: 11672093.000000\n",
      "Train Epoch: 95 [528/918 (58%)] Loss: 9398035.000000\n",
      "Train Epoch: 95 [544/918 (59%)] Loss: 17065108.000000\n",
      "Train Epoch: 95 [560/918 (61%)] Loss: 8061091.500000\n",
      "Train Epoch: 95 [576/918 (63%)] Loss: 9141802.000000\n",
      "Train Epoch: 95 [592/918 (64%)] Loss: 6515577.500000\n",
      "Train Epoch: 95 [608/918 (66%)] Loss: 7156304.000000\n",
      "Train Epoch: 95 [624/918 (68%)] Loss: 12326587.000000\n",
      "Train Epoch: 95 [640/918 (70%)] Loss: 8405157.000000\n",
      "Train Epoch: 95 [656/918 (71%)] Loss: 9118730.000000\n",
      "Train Epoch: 95 [672/918 (73%)] Loss: 10966237.000000\n",
      "Train Epoch: 95 [688/918 (75%)] Loss: 10774682.000000\n",
      "Train Epoch: 95 [704/918 (77%)] Loss: 7267203.500000\n",
      "Train Epoch: 95 [720/918 (78%)] Loss: 10446583.000000\n",
      "Train Epoch: 95 [736/918 (80%)] Loss: 8839986.000000\n",
      "Train Epoch: 95 [752/918 (82%)] Loss: 9686520.000000\n",
      "Train Epoch: 95 [768/918 (84%)] Loss: 11124518.000000\n",
      "Train Epoch: 95 [784/918 (85%)] Loss: 8170064.000000\n",
      "Train Epoch: 95 [800/918 (87%)] Loss: 8009593.500000\n",
      "Train Epoch: 95 [816/918 (89%)] Loss: 6701880.000000\n",
      "Train Epoch: 95 [832/918 (91%)] Loss: 11960957.000000\n",
      "Train Epoch: 95 [848/918 (92%)] Loss: 8226818.500000\n",
      "Train Epoch: 95 [864/918 (94%)] Loss: 8852282.000000\n",
      "Train Epoch: 95 [880/918 (96%)] Loss: 10608579.000000\n",
      "Train Epoch: 95 [896/918 (98%)] Loss: 6282084.000000\n",
      "Train Epoch: 95 [912/918 (99%)] Loss: 9110639.000000\n",
      "    epoch          : 95\n",
      "    loss           : 9178332.043478262\n",
      "    ess            : 7.203350458974423\n",
      "    log_marginal   : -9178329.078260869\n",
      "    val_loss       : 8293467.538461538\n",
      "    val_ess        : 5.957665773538443\n",
      "    val_log_marginal: -8293463.961538462\n",
      "Train Epoch: 96 [0/918 (0%)] Loss: 9283739.000000\n",
      "Train Epoch: 96 [16/918 (2%)] Loss: 10629207.000000\n",
      "Train Epoch: 96 [32/918 (3%)] Loss: 7492489.000000\n",
      "Train Epoch: 96 [48/918 (5%)] Loss: 9403054.000000\n",
      "Train Epoch: 96 [64/918 (7%)] Loss: 7693488.000000\n",
      "Train Epoch: 96 [80/918 (9%)] Loss: 8229152.000000\n",
      "Train Epoch: 96 [96/918 (10%)] Loss: 10574241.000000\n",
      "Train Epoch: 96 [112/918 (12%)] Loss: 8029388.000000\n",
      "Train Epoch: 96 [128/918 (14%)] Loss: 11641312.000000\n",
      "Train Epoch: 96 [144/918 (16%)] Loss: 8340812.000000\n",
      "Train Epoch: 96 [160/918 (17%)] Loss: 6284085.000000\n",
      "Train Epoch: 96 [176/918 (19%)] Loss: 11064299.000000\n",
      "Train Epoch: 96 [192/918 (21%)] Loss: 7704577.500000\n",
      "Train Epoch: 96 [208/918 (23%)] Loss: 14432064.000000\n",
      "Train Epoch: 96 [224/918 (24%)] Loss: 14329816.000000\n",
      "Train Epoch: 96 [240/918 (26%)] Loss: 9747753.000000\n",
      "Train Epoch: 96 [256/918 (28%)] Loss: 11048372.000000\n",
      "Train Epoch: 96 [272/918 (30%)] Loss: 8937691.000000\n",
      "Train Epoch: 96 [288/918 (31%)] Loss: 6572192.000000\n",
      "Train Epoch: 96 [304/918 (33%)] Loss: 9259215.000000\n",
      "Train Epoch: 96 [320/918 (35%)] Loss: 9420870.000000\n",
      "Train Epoch: 96 [336/918 (37%)] Loss: 6769704.000000\n",
      "Train Epoch: 96 [352/918 (38%)] Loss: 11258474.000000\n",
      "Train Epoch: 96 [368/918 (40%)] Loss: 9766605.000000\n",
      "Train Epoch: 96 [384/918 (42%)] Loss: 6567173.500000\n",
      "Train Epoch: 96 [400/918 (44%)] Loss: 8705615.000000\n",
      "Train Epoch: 96 [416/918 (45%)] Loss: 8465504.000000\n",
      "Train Epoch: 96 [432/918 (47%)] Loss: 8962551.000000\n",
      "Train Epoch: 96 [448/918 (49%)] Loss: 7708077.500000\n",
      "Train Epoch: 96 [464/918 (51%)] Loss: 6848549.500000\n",
      "Train Epoch: 96 [480/918 (52%)] Loss: 6446641.500000\n",
      "Train Epoch: 96 [496/918 (54%)] Loss: 11086714.000000\n",
      "Train Epoch: 96 [512/918 (56%)] Loss: 6216198.000000\n",
      "Train Epoch: 96 [528/918 (58%)] Loss: 6588108.000000\n",
      "Train Epoch: 96 [544/918 (59%)] Loss: 8044976.000000\n",
      "Train Epoch: 96 [560/918 (61%)] Loss: 8839142.000000\n",
      "Train Epoch: 96 [576/918 (63%)] Loss: 10080300.000000\n",
      "Train Epoch: 96 [592/918 (64%)] Loss: 8241334.500000\n",
      "Train Epoch: 96 [608/918 (66%)] Loss: 8550867.000000\n",
      "Train Epoch: 96 [624/918 (68%)] Loss: 7838002.500000\n",
      "Train Epoch: 96 [640/918 (70%)] Loss: 10893509.000000\n",
      "Train Epoch: 96 [656/918 (71%)] Loss: 10815362.000000\n",
      "Train Epoch: 96 [672/918 (73%)] Loss: 11539767.000000\n",
      "Train Epoch: 96 [688/918 (75%)] Loss: 8413365.000000\n",
      "Train Epoch: 96 [704/918 (77%)] Loss: 8684167.000000\n",
      "Train Epoch: 96 [720/918 (78%)] Loss: 11350570.000000\n",
      "Train Epoch: 96 [736/918 (80%)] Loss: 7904925.500000\n",
      "Train Epoch: 96 [752/918 (82%)] Loss: 12508029.000000\n",
      "Train Epoch: 96 [768/918 (84%)] Loss: 8401922.000000\n",
      "Train Epoch: 96 [784/918 (85%)] Loss: 8178477.500000\n",
      "Train Epoch: 96 [800/918 (87%)] Loss: 8944896.000000\n",
      "Train Epoch: 96 [816/918 (89%)] Loss: 10773587.000000\n",
      "Train Epoch: 96 [832/918 (91%)] Loss: 6994760.000000\n",
      "Train Epoch: 96 [848/918 (92%)] Loss: 9980984.000000\n",
      "Train Epoch: 96 [864/918 (94%)] Loss: 7046789.000000\n",
      "Train Epoch: 96 [880/918 (96%)] Loss: 9203085.000000\n",
      "Train Epoch: 96 [896/918 (98%)] Loss: 7007081.500000\n",
      "Train Epoch: 96 [912/918 (99%)] Loss: 6819141.500000\n",
      "    epoch          : 96\n",
      "    loss           : 9074653.304347826\n",
      "    ess            : 7.609520505822223\n",
      "    log_marginal   : -9074651.791304348\n",
      "    val_loss       : 9396865.423076924\n",
      "    val_ess        : 7.173019115741436\n",
      "    val_log_marginal: -9396864.807692308\n",
      "Train Epoch: 97 [0/918 (0%)] Loss: 10069685.000000\n",
      "Train Epoch: 97 [16/918 (2%)] Loss: 8273982.500000\n",
      "Train Epoch: 97 [32/918 (3%)] Loss: 9347760.000000\n",
      "Train Epoch: 97 [48/918 (5%)] Loss: 6921179.500000\n",
      "Train Epoch: 97 [64/918 (7%)] Loss: 5984073.500000\n",
      "Train Epoch: 97 [80/918 (9%)] Loss: 6897343.500000\n",
      "Train Epoch: 97 [96/918 (10%)] Loss: 9947773.000000\n",
      "Train Epoch: 97 [112/918 (12%)] Loss: 8111605.000000\n",
      "Train Epoch: 97 [128/918 (14%)] Loss: 8498043.000000\n",
      "Train Epoch: 97 [144/918 (16%)] Loss: 8462411.000000\n",
      "Train Epoch: 97 [160/918 (17%)] Loss: 8879890.000000\n",
      "Train Epoch: 97 [176/918 (19%)] Loss: 8271072.000000\n",
      "Train Epoch: 97 [192/918 (21%)] Loss: 9044163.000000\n",
      "Train Epoch: 97 [208/918 (23%)] Loss: 8192158.500000\n",
      "Train Epoch: 97 [224/918 (24%)] Loss: 6285197.500000\n",
      "Train Epoch: 97 [240/918 (26%)] Loss: 10726939.000000\n",
      "Train Epoch: 97 [256/918 (28%)] Loss: 10173063.000000\n",
      "Train Epoch: 97 [272/918 (30%)] Loss: 11742194.000000\n",
      "Train Epoch: 97 [288/918 (31%)] Loss: 11713791.000000\n",
      "Train Epoch: 97 [304/918 (33%)] Loss: 7326817.500000\n",
      "Train Epoch: 97 [320/918 (35%)] Loss: 14474805.000000\n",
      "Train Epoch: 97 [336/918 (37%)] Loss: 6799595.500000\n",
      "Train Epoch: 97 [352/918 (38%)] Loss: 7465541.000000\n",
      "Train Epoch: 97 [368/918 (40%)] Loss: 7309241.500000\n",
      "Train Epoch: 97 [384/918 (42%)] Loss: 10679332.000000\n",
      "Train Epoch: 97 [400/918 (44%)] Loss: 7651768.000000\n",
      "Train Epoch: 97 [416/918 (45%)] Loss: 6983259.500000\n",
      "Train Epoch: 97 [432/918 (47%)] Loss: 7073233.500000\n",
      "Train Epoch: 97 [448/918 (49%)] Loss: 8815497.000000\n",
      "Train Epoch: 97 [464/918 (51%)] Loss: 11180595.000000\n",
      "Train Epoch: 97 [480/918 (52%)] Loss: 6577359.000000\n",
      "Train Epoch: 97 [496/918 (54%)] Loss: 7650912.000000\n",
      "Train Epoch: 97 [512/918 (56%)] Loss: 6853645.000000\n",
      "Train Epoch: 97 [528/918 (58%)] Loss: 10814038.000000\n",
      "Train Epoch: 97 [544/918 (59%)] Loss: 7878712.000000\n",
      "Train Epoch: 97 [560/918 (61%)] Loss: 9924944.000000\n",
      "Train Epoch: 97 [576/918 (63%)] Loss: 8146003.500000\n",
      "Train Epoch: 97 [592/918 (64%)] Loss: 7806806.500000\n",
      "Train Epoch: 97 [608/918 (66%)] Loss: 10438920.000000\n",
      "Train Epoch: 97 [624/918 (68%)] Loss: 11130756.000000\n",
      "Train Epoch: 97 [640/918 (70%)] Loss: 9414891.000000\n",
      "Train Epoch: 97 [656/918 (71%)] Loss: 7707174.500000\n",
      "Train Epoch: 97 [672/918 (73%)] Loss: 9272015.000000\n",
      "Train Epoch: 97 [688/918 (75%)] Loss: 8210326.500000\n",
      "Train Epoch: 97 [704/918 (77%)] Loss: 13115525.000000\n",
      "Train Epoch: 97 [720/918 (78%)] Loss: 8034822.500000\n",
      "Train Epoch: 97 [736/918 (80%)] Loss: 11157787.000000\n",
      "Train Epoch: 97 [752/918 (82%)] Loss: 9762221.000000\n",
      "Train Epoch: 97 [768/918 (84%)] Loss: 10895736.000000\n",
      "Train Epoch: 97 [784/918 (85%)] Loss: 8829960.000000\n",
      "Train Epoch: 97 [800/918 (87%)] Loss: 8025625.500000\n",
      "Train Epoch: 97 [816/918 (89%)] Loss: 7087898.500000\n",
      "Train Epoch: 97 [832/918 (91%)] Loss: 12447167.000000\n",
      "Train Epoch: 97 [848/918 (92%)] Loss: 10894091.000000\n",
      "Train Epoch: 97 [864/918 (94%)] Loss: 8241177.000000\n",
      "Train Epoch: 97 [880/918 (96%)] Loss: 8223086.500000\n",
      "Train Epoch: 97 [896/918 (98%)] Loss: 8539429.000000\n",
      "Train Epoch: 97 [912/918 (99%)] Loss: 6198668.500000\n",
      "    epoch          : 97\n",
      "    loss           : 8950392.208695652\n",
      "    ess            : 7.441614791621332\n",
      "    log_marginal   : -8950390.613043478\n",
      "    val_loss       : 8673104.461538462\n",
      "    val_ess        : 7.834075395877544\n",
      "    val_log_marginal: -8673102.884615384\n",
      "Train Epoch: 98 [0/918 (0%)] Loss: 9091319.000000\n",
      "Train Epoch: 98 [16/918 (2%)] Loss: 12612163.000000\n",
      "Train Epoch: 98 [32/918 (3%)] Loss: 8910877.000000\n",
      "Train Epoch: 98 [48/918 (5%)] Loss: 8213283.500000\n",
      "Train Epoch: 98 [64/918 (7%)] Loss: 7692002.500000\n",
      "Train Epoch: 98 [80/918 (9%)] Loss: 9894299.000000\n",
      "Train Epoch: 98 [96/918 (10%)] Loss: 12072074.000000\n",
      "Train Epoch: 98 [112/918 (12%)] Loss: 11385207.000000\n",
      "Train Epoch: 98 [128/918 (14%)] Loss: 10226866.000000\n",
      "Train Epoch: 98 [144/918 (16%)] Loss: 10922807.000000\n",
      "Train Epoch: 98 [160/918 (17%)] Loss: 12939621.000000\n",
      "Train Epoch: 98 [176/918 (19%)] Loss: 7871799.500000\n",
      "Train Epoch: 98 [192/918 (21%)] Loss: 7326001.000000\n",
      "Train Epoch: 98 [208/918 (23%)] Loss: 10589679.000000\n",
      "Train Epoch: 98 [224/918 (24%)] Loss: 7604049.500000\n",
      "Train Epoch: 98 [240/918 (26%)] Loss: 9451722.000000\n",
      "Train Epoch: 98 [256/918 (28%)] Loss: 9292491.000000\n",
      "Train Epoch: 98 [272/918 (30%)] Loss: 5292393.500000\n",
      "Train Epoch: 98 [288/918 (31%)] Loss: 9817115.000000\n",
      "Train Epoch: 98 [304/918 (33%)] Loss: 5633617.000000\n",
      "Train Epoch: 98 [320/918 (35%)] Loss: 7261637.000000\n",
      "Train Epoch: 98 [336/918 (37%)] Loss: 10046703.000000\n",
      "Train Epoch: 98 [352/918 (38%)] Loss: 10478109.000000\n",
      "Train Epoch: 98 [368/918 (40%)] Loss: 8337248.000000\n",
      "Train Epoch: 98 [384/918 (42%)] Loss: 7745754.500000\n",
      "Train Epoch: 98 [400/918 (44%)] Loss: 12607144.000000\n",
      "Train Epoch: 98 [416/918 (45%)] Loss: 8064930.500000\n",
      "Train Epoch: 98 [432/918 (47%)] Loss: 10629103.000000\n",
      "Train Epoch: 98 [448/918 (49%)] Loss: 7537605.000000\n",
      "Train Epoch: 98 [464/918 (51%)] Loss: 6716051.500000\n",
      "Train Epoch: 98 [480/918 (52%)] Loss: 7113233.500000\n",
      "Train Epoch: 98 [496/918 (54%)] Loss: 7119112.000000\n",
      "Train Epoch: 98 [512/918 (56%)] Loss: 9275551.000000\n",
      "Train Epoch: 98 [528/918 (58%)] Loss: 8187249.000000\n",
      "Train Epoch: 98 [544/918 (59%)] Loss: 8621415.000000\n",
      "Train Epoch: 98 [560/918 (61%)] Loss: 6666533.000000\n",
      "Train Epoch: 98 [576/918 (63%)] Loss: 11917519.000000\n",
      "Train Epoch: 98 [592/918 (64%)] Loss: 7442798.500000\n",
      "Train Epoch: 98 [608/918 (66%)] Loss: 7617602.500000\n",
      "Train Epoch: 98 [624/918 (68%)] Loss: 8624803.000000\n",
      "Train Epoch: 98 [640/918 (70%)] Loss: 7852837.500000\n",
      "Train Epoch: 98 [656/918 (71%)] Loss: 11318328.000000\n",
      "Train Epoch: 98 [672/918 (73%)] Loss: 7989283.500000\n",
      "Train Epoch: 98 [688/918 (75%)] Loss: 7296591.500000\n",
      "Train Epoch: 98 [704/918 (77%)] Loss: 7397580.000000\n",
      "Train Epoch: 98 [720/918 (78%)] Loss: 8178024.000000\n",
      "Train Epoch: 98 [736/918 (80%)] Loss: 9363115.000000\n",
      "Train Epoch: 98 [752/918 (82%)] Loss: 9632533.000000\n",
      "Train Epoch: 98 [768/918 (84%)] Loss: 9559521.000000\n",
      "Train Epoch: 98 [784/918 (85%)] Loss: 10526783.000000\n",
      "Train Epoch: 98 [800/918 (87%)] Loss: 12310933.000000\n",
      "Train Epoch: 98 [816/918 (89%)] Loss: 7670008.000000\n",
      "Train Epoch: 98 [832/918 (91%)] Loss: 9656091.000000\n",
      "Train Epoch: 98 [848/918 (92%)] Loss: 12400985.000000\n",
      "Train Epoch: 98 [864/918 (94%)] Loss: 7253187.500000\n",
      "Train Epoch: 98 [880/918 (96%)] Loss: 9293002.000000\n",
      "Train Epoch: 98 [896/918 (98%)] Loss: 10523536.000000\n",
      "Train Epoch: 98 [912/918 (99%)] Loss: 13446066.000000\n",
      "    epoch          : 98\n",
      "    loss           : 8895499.7\n",
      "    ess            : 7.525166017076243\n",
      "    log_marginal   : -8895497.804347826\n",
      "    val_loss       : 8573638.653846154\n",
      "    val_ess        : 6.609363941045908\n",
      "    val_log_marginal: -8573637.307692308\n",
      "Train Epoch: 99 [0/918 (0%)] Loss: 6093611.500000\n",
      "Train Epoch: 99 [16/918 (2%)] Loss: 7566821.000000\n",
      "Train Epoch: 99 [32/918 (3%)] Loss: 8755190.000000\n",
      "Train Epoch: 99 [48/918 (5%)] Loss: 10863450.000000\n",
      "Train Epoch: 99 [64/918 (7%)] Loss: 5420493.500000\n",
      "Train Epoch: 99 [80/918 (9%)] Loss: 12808280.000000\n",
      "Train Epoch: 99 [96/918 (10%)] Loss: 7367971.500000\n",
      "Train Epoch: 99 [112/918 (12%)] Loss: 7766012.000000\n",
      "Train Epoch: 99 [128/918 (14%)] Loss: 9956606.000000\n",
      "Train Epoch: 99 [144/918 (16%)] Loss: 10633007.000000\n",
      "Train Epoch: 99 [160/918 (17%)] Loss: 11437827.000000\n",
      "Train Epoch: 99 [176/918 (19%)] Loss: 8030197.000000\n",
      "Train Epoch: 99 [192/918 (21%)] Loss: 9793008.000000\n",
      "Train Epoch: 99 [208/918 (23%)] Loss: 5954995.500000\n",
      "Train Epoch: 99 [224/918 (24%)] Loss: 8000598.500000\n",
      "Train Epoch: 99 [240/918 (26%)] Loss: 7929963.500000\n",
      "Train Epoch: 99 [256/918 (28%)] Loss: 6879996.000000\n",
      "Train Epoch: 99 [272/918 (30%)] Loss: 7663808.000000\n",
      "Train Epoch: 99 [288/918 (31%)] Loss: 9448586.000000\n",
      "Train Epoch: 99 [304/918 (33%)] Loss: 6423815.500000\n",
      "Train Epoch: 99 [320/918 (35%)] Loss: 9372765.000000\n",
      "Train Epoch: 99 [336/918 (37%)] Loss: 9850685.000000\n",
      "Train Epoch: 99 [352/918 (38%)] Loss: 8331613.500000\n",
      "Train Epoch: 99 [368/918 (40%)] Loss: 7031123.500000\n",
      "Train Epoch: 99 [384/918 (42%)] Loss: 9897570.000000\n",
      "Train Epoch: 99 [400/918 (44%)] Loss: 8651836.000000\n",
      "Train Epoch: 99 [416/918 (45%)] Loss: 8961751.000000\n",
      "Train Epoch: 99 [432/918 (47%)] Loss: 7665841.000000\n",
      "Train Epoch: 99 [448/918 (49%)] Loss: 15159523.000000\n",
      "Train Epoch: 99 [464/918 (51%)] Loss: 10571679.000000\n",
      "Train Epoch: 99 [480/918 (52%)] Loss: 7369000.000000\n",
      "Train Epoch: 99 [496/918 (54%)] Loss: 6908795.500000\n",
      "Train Epoch: 99 [512/918 (56%)] Loss: 10682432.000000\n",
      "Train Epoch: 99 [528/918 (58%)] Loss: 8485680.000000\n",
      "Train Epoch: 99 [544/918 (59%)] Loss: 12589492.000000\n",
      "Train Epoch: 99 [560/918 (61%)] Loss: 6088142.500000\n",
      "Train Epoch: 99 [576/918 (63%)] Loss: 7033449.500000\n",
      "Train Epoch: 99 [592/918 (64%)] Loss: 9854659.000000\n",
      "Train Epoch: 99 [608/918 (66%)] Loss: 11202678.000000\n",
      "Train Epoch: 99 [624/918 (68%)] Loss: 7819617.000000\n",
      "Train Epoch: 99 [640/918 (70%)] Loss: 7881041.500000\n",
      "Train Epoch: 99 [656/918 (71%)] Loss: 9244383.000000\n",
      "Train Epoch: 99 [672/918 (73%)] Loss: 7243092.000000\n",
      "Train Epoch: 99 [688/918 (75%)] Loss: 8809946.000000\n",
      "Train Epoch: 99 [704/918 (77%)] Loss: 6616582.000000\n",
      "Train Epoch: 99 [720/918 (78%)] Loss: 8526864.000000\n",
      "Train Epoch: 99 [736/918 (80%)] Loss: 10704708.000000\n",
      "Train Epoch: 99 [752/918 (82%)] Loss: 12251141.000000\n",
      "Train Epoch: 99 [768/918 (84%)] Loss: 7396341.000000\n",
      "Train Epoch: 99 [784/918 (85%)] Loss: 7513527.500000\n",
      "Train Epoch: 99 [800/918 (87%)] Loss: 8571336.000000\n",
      "Train Epoch: 99 [816/918 (89%)] Loss: 13007920.000000\n",
      "Train Epoch: 99 [832/918 (91%)] Loss: 15637283.000000\n",
      "Train Epoch: 99 [848/918 (92%)] Loss: 7128991.500000\n",
      "Train Epoch: 99 [864/918 (94%)] Loss: 9657026.000000\n",
      "Train Epoch: 99 [880/918 (96%)] Loss: 11596408.000000\n",
      "Train Epoch: 99 [896/918 (98%)] Loss: 6638434.000000\n",
      "Train Epoch: 99 [912/918 (99%)] Loss: 8553069.000000\n",
      "    epoch          : 99\n",
      "    loss           : 8978775.652173912\n",
      "    ess            : 7.568306518637615\n",
      "    log_marginal   : -8978773.886956522\n",
      "    val_loss       : 8361680.5\n",
      "    val_ess        : 7.045963800870455\n",
      "    val_log_marginal: -8361677.653846154\n",
      "Train Epoch: 100 [0/918 (0%)] Loss: 11625829.000000\n",
      "Train Epoch: 100 [16/918 (2%)] Loss: 8212751.500000\n",
      "Train Epoch: 100 [32/918 (3%)] Loss: 8616111.000000\n",
      "Train Epoch: 100 [48/918 (5%)] Loss: 8173048.000000\n",
      "Train Epoch: 100 [64/918 (7%)] Loss: 9980557.000000\n",
      "Train Epoch: 100 [80/918 (9%)] Loss: 10349005.000000\n",
      "Train Epoch: 100 [96/918 (10%)] Loss: 7007500.000000\n",
      "Train Epoch: 100 [112/918 (12%)] Loss: 10420042.000000\n",
      "Train Epoch: 100 [128/918 (14%)] Loss: 8822540.000000\n",
      "Train Epoch: 100 [144/918 (16%)] Loss: 8523170.000000\n",
      "Train Epoch: 100 [160/918 (17%)] Loss: 7620173.500000\n",
      "Train Epoch: 100 [176/918 (19%)] Loss: 12140662.000000\n",
      "Train Epoch: 100 [192/918 (21%)] Loss: 6649761.000000\n",
      "Train Epoch: 100 [208/918 (23%)] Loss: 6956754.500000\n",
      "Train Epoch: 100 [224/918 (24%)] Loss: 10039865.000000\n",
      "Train Epoch: 100 [240/918 (26%)] Loss: 8688095.000000\n",
      "Train Epoch: 100 [256/918 (28%)] Loss: 11799651.000000\n",
      "Train Epoch: 100 [272/918 (30%)] Loss: 6929013.500000\n",
      "Train Epoch: 100 [288/918 (31%)] Loss: 7529423.500000\n",
      "Train Epoch: 100 [304/918 (33%)] Loss: 7446419.500000\n",
      "Train Epoch: 100 [320/918 (35%)] Loss: 6839713.000000\n",
      "Train Epoch: 100 [336/918 (37%)] Loss: 8069418.500000\n",
      "Train Epoch: 100 [352/918 (38%)] Loss: 9027047.000000\n",
      "Train Epoch: 100 [368/918 (40%)] Loss: 6721510.500000\n",
      "Train Epoch: 100 [384/918 (42%)] Loss: 8826098.000000\n",
      "Train Epoch: 100 [400/918 (44%)] Loss: 6838181.500000\n",
      "Train Epoch: 100 [416/918 (45%)] Loss: 10448412.000000\n",
      "Train Epoch: 100 [432/918 (47%)] Loss: 7685219.500000\n",
      "Train Epoch: 100 [448/918 (49%)] Loss: 6872273.500000\n",
      "Train Epoch: 100 [464/918 (51%)] Loss: 15184013.000000\n",
      "Train Epoch: 100 [480/918 (52%)] Loss: 11477575.000000\n",
      "Train Epoch: 100 [496/918 (54%)] Loss: 7744725.000000\n",
      "Train Epoch: 100 [512/918 (56%)] Loss: 10868847.000000\n",
      "Train Epoch: 100 [528/918 (58%)] Loss: 8791408.000000\n",
      "Train Epoch: 100 [544/918 (59%)] Loss: 8780717.000000\n",
      "Train Epoch: 100 [560/918 (61%)] Loss: 7325243.500000\n",
      "Train Epoch: 100 [576/918 (63%)] Loss: 14229170.000000\n",
      "Train Epoch: 100 [592/918 (64%)] Loss: 8341192.000000\n",
      "Train Epoch: 100 [608/918 (66%)] Loss: 6681389.500000\n",
      "Train Epoch: 100 [624/918 (68%)] Loss: 5937751.500000\n",
      "Train Epoch: 100 [640/918 (70%)] Loss: 7984163.500000\n",
      "Train Epoch: 100 [656/918 (71%)] Loss: 6531749.000000\n",
      "Train Epoch: 100 [672/918 (73%)] Loss: 11610698.000000\n",
      "Train Epoch: 100 [688/918 (75%)] Loss: 13007344.000000\n",
      "Train Epoch: 100 [704/918 (77%)] Loss: 8365362.500000\n",
      "Train Epoch: 100 [720/918 (78%)] Loss: 8132270.500000\n",
      "Train Epoch: 100 [736/918 (80%)] Loss: 6376421.000000\n",
      "Train Epoch: 100 [752/918 (82%)] Loss: 10995287.000000\n",
      "Train Epoch: 100 [768/918 (84%)] Loss: 7020489.500000\n",
      "Train Epoch: 100 [784/918 (85%)] Loss: 9591278.000000\n",
      "Train Epoch: 100 [800/918 (87%)] Loss: 10496580.000000\n",
      "Train Epoch: 100 [816/918 (89%)] Loss: 10921298.000000\n",
      "Train Epoch: 100 [832/918 (91%)] Loss: 9704838.000000\n",
      "Train Epoch: 100 [848/918 (92%)] Loss: 9355989.000000\n",
      "Train Epoch: 100 [864/918 (94%)] Loss: 9180428.000000\n",
      "Train Epoch: 100 [880/918 (96%)] Loss: 5725651.500000\n",
      "Train Epoch: 100 [896/918 (98%)] Loss: 8843667.000000\n",
      "Train Epoch: 100 [912/918 (99%)] Loss: 11011235.000000\n",
      "    epoch          : 100\n",
      "    loss           : 8702045.926086957\n",
      "    ess            : 7.076283614531807\n",
      "    log_marginal   : -8702042.72173913\n",
      "    val_loss       : 9482133.076923076\n",
      "    val_ess        : 7.837822639025175\n",
      "    val_log_marginal: -9482131.038461538\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [0/918 (0%)] Loss: 6417219.500000\n",
      "Train Epoch: 101 [16/918 (2%)] Loss: 7045617.000000\n",
      "Train Epoch: 101 [32/918 (3%)] Loss: 7361931.500000\n",
      "Train Epoch: 101 [48/918 (5%)] Loss: 7083689.500000\n",
      "Train Epoch: 101 [64/918 (7%)] Loss: 9521451.000000\n",
      "Train Epoch: 101 [80/918 (9%)] Loss: 7361896.000000\n",
      "Train Epoch: 101 [96/918 (10%)] Loss: 10193223.000000\n",
      "Train Epoch: 101 [112/918 (12%)] Loss: 8293743.500000\n",
      "Train Epoch: 101 [128/918 (14%)] Loss: 7980003.500000\n",
      "Train Epoch: 101 [144/918 (16%)] Loss: 8709890.000000\n",
      "Train Epoch: 101 [160/918 (17%)] Loss: 7946576.000000\n",
      "Train Epoch: 101 [176/918 (19%)] Loss: 7028424.000000\n",
      "Train Epoch: 101 [192/918 (21%)] Loss: 7697002.500000\n",
      "Train Epoch: 101 [208/918 (23%)] Loss: 8083073.500000\n",
      "Train Epoch: 101 [224/918 (24%)] Loss: 11783176.000000\n",
      "Train Epoch: 101 [240/918 (26%)] Loss: 5734966.000000\n",
      "Train Epoch: 101 [256/918 (28%)] Loss: 10365263.000000\n",
      "Train Epoch: 101 [272/918 (30%)] Loss: 10162560.000000\n",
      "Train Epoch: 101 [288/918 (31%)] Loss: 11710693.000000\n",
      "Train Epoch: 101 [304/918 (33%)] Loss: 8423608.000000\n",
      "Train Epoch: 101 [320/918 (35%)] Loss: 9013986.000000\n",
      "Train Epoch: 101 [336/918 (37%)] Loss: 7769860.000000\n",
      "Train Epoch: 101 [352/918 (38%)] Loss: 10414237.000000\n",
      "Train Epoch: 101 [368/918 (40%)] Loss: 8628006.000000\n",
      "Train Epoch: 101 [384/918 (42%)] Loss: 11545993.000000\n",
      "Train Epoch: 101 [400/918 (44%)] Loss: 8857770.000000\n",
      "Train Epoch: 101 [416/918 (45%)] Loss: 12800837.000000\n",
      "Train Epoch: 101 [432/918 (47%)] Loss: 6133574.500000\n",
      "Train Epoch: 101 [448/918 (49%)] Loss: 15322683.000000\n",
      "Train Epoch: 101 [464/918 (51%)] Loss: 10318031.000000\n",
      "Train Epoch: 101 [480/918 (52%)] Loss: 7853837.000000\n",
      "Train Epoch: 101 [496/918 (54%)] Loss: 7091701.000000\n",
      "Train Epoch: 101 [512/918 (56%)] Loss: 6697983.500000\n",
      "Train Epoch: 101 [528/918 (58%)] Loss: 7917409.500000\n",
      "Train Epoch: 101 [544/918 (59%)] Loss: 8903930.000000\n",
      "Train Epoch: 101 [560/918 (61%)] Loss: 6495153.500000\n",
      "Train Epoch: 101 [576/918 (63%)] Loss: 8368256.000000\n",
      "Train Epoch: 101 [592/918 (64%)] Loss: 6501630.000000\n",
      "Train Epoch: 101 [608/918 (66%)] Loss: 7741857.500000\n",
      "Train Epoch: 101 [624/918 (68%)] Loss: 9220144.000000\n",
      "Train Epoch: 101 [640/918 (70%)] Loss: 7480763.500000\n",
      "Train Epoch: 101 [656/918 (71%)] Loss: 8502970.000000\n",
      "Train Epoch: 101 [672/918 (73%)] Loss: 10427212.000000\n",
      "Train Epoch: 101 [688/918 (75%)] Loss: 10959196.000000\n",
      "Train Epoch: 101 [704/918 (77%)] Loss: 11394579.000000\n",
      "Train Epoch: 101 [720/918 (78%)] Loss: 12824237.000000\n",
      "Train Epoch: 101 [736/918 (80%)] Loss: 10775011.000000\n",
      "Train Epoch: 101 [752/918 (82%)] Loss: 9423623.000000\n",
      "Train Epoch: 101 [768/918 (84%)] Loss: 7190568.000000\n",
      "Train Epoch: 101 [784/918 (85%)] Loss: 9081678.000000\n",
      "Train Epoch: 101 [800/918 (87%)] Loss: 7269589.000000\n",
      "Train Epoch: 101 [816/918 (89%)] Loss: 11591493.000000\n",
      "Train Epoch: 101 [832/918 (91%)] Loss: 7698174.500000\n",
      "Train Epoch: 101 [848/918 (92%)] Loss: 6575318.000000\n",
      "Train Epoch: 101 [864/918 (94%)] Loss: 9845800.000000\n",
      "Train Epoch: 101 [880/918 (96%)] Loss: 7738841.000000\n",
      "Train Epoch: 101 [896/918 (98%)] Loss: 8955911.000000\n",
      "Train Epoch: 101 [912/918 (99%)] Loss: 9667354.000000\n",
      "    epoch          : 101\n",
      "    loss           : 8873249.965217391\n",
      "    ess            : 7.707849268291308\n",
      "    log_marginal   : -8873248.339130435\n",
      "    val_loss       : 8880636.307692308\n",
      "    val_ess        : 6.576049566268921\n",
      "    val_log_marginal: -8880633.653846154\n",
      "Train Epoch: 102 [0/918 (0%)] Loss: 7145362.500000\n",
      "Train Epoch: 102 [16/918 (2%)] Loss: 6894168.000000\n",
      "Train Epoch: 102 [32/918 (3%)] Loss: 6495837.500000\n",
      "Train Epoch: 102 [48/918 (5%)] Loss: 8976954.000000\n",
      "Train Epoch: 102 [64/918 (7%)] Loss: 12835747.000000\n",
      "Train Epoch: 102 [80/918 (9%)] Loss: 7771091.500000\n",
      "Train Epoch: 102 [96/918 (10%)] Loss: 7004608.000000\n",
      "Train Epoch: 102 [112/918 (12%)] Loss: 8040678.500000\n",
      "Train Epoch: 102 [128/918 (14%)] Loss: 13294292.000000\n",
      "Train Epoch: 102 [144/918 (16%)] Loss: 6764481.000000\n",
      "Train Epoch: 102 [160/918 (17%)] Loss: 8120957.000000\n",
      "Train Epoch: 102 [176/918 (19%)] Loss: 10044995.000000\n",
      "Train Epoch: 102 [192/918 (21%)] Loss: 9413616.000000\n",
      "Train Epoch: 102 [208/918 (23%)] Loss: 7945825.500000\n",
      "Train Epoch: 102 [224/918 (24%)] Loss: 9569331.000000\n",
      "Train Epoch: 102 [240/918 (26%)] Loss: 6818708.000000\n",
      "Train Epoch: 102 [256/918 (28%)] Loss: 10798740.000000\n",
      "Train Epoch: 102 [272/918 (30%)] Loss: 7695849.000000\n",
      "Train Epoch: 102 [288/918 (31%)] Loss: 7320874.500000\n",
      "Train Epoch: 102 [304/918 (33%)] Loss: 8254763.500000\n",
      "Train Epoch: 102 [320/918 (35%)] Loss: 8223180.000000\n",
      "Train Epoch: 102 [336/918 (37%)] Loss: 10587453.000000\n",
      "Train Epoch: 102 [352/918 (38%)] Loss: 10963339.000000\n",
      "Train Epoch: 102 [368/918 (40%)] Loss: 5662475.500000\n",
      "Train Epoch: 102 [384/918 (42%)] Loss: 9471815.000000\n",
      "Train Epoch: 102 [400/918 (44%)] Loss: 8645854.000000\n",
      "Train Epoch: 102 [416/918 (45%)] Loss: 9271508.000000\n",
      "Train Epoch: 102 [432/918 (47%)] Loss: 9142160.000000\n",
      "Train Epoch: 102 [448/918 (49%)] Loss: 7374821.000000\n",
      "Train Epoch: 102 [464/918 (51%)] Loss: 7588312.000000\n",
      "Train Epoch: 102 [480/918 (52%)] Loss: 9488525.000000\n",
      "Train Epoch: 102 [496/918 (54%)] Loss: 9915165.000000\n",
      "Train Epoch: 102 [512/918 (56%)] Loss: 9419034.000000\n",
      "Train Epoch: 102 [528/918 (58%)] Loss: 5500918.000000\n",
      "Train Epoch: 102 [544/918 (59%)] Loss: 9500992.000000\n",
      "Train Epoch: 102 [560/918 (61%)] Loss: 9767441.000000\n",
      "Train Epoch: 102 [576/918 (63%)] Loss: 7997863.500000\n",
      "Train Epoch: 102 [592/918 (64%)] Loss: 7392016.000000\n",
      "Train Epoch: 102 [608/918 (66%)] Loss: 9896050.000000\n",
      "Train Epoch: 102 [624/918 (68%)] Loss: 12284281.000000\n",
      "Train Epoch: 102 [640/918 (70%)] Loss: 13365357.000000\n",
      "Train Epoch: 102 [656/918 (71%)] Loss: 8879893.000000\n",
      "Train Epoch: 102 [672/918 (73%)] Loss: 6780433.500000\n",
      "Train Epoch: 102 [688/918 (75%)] Loss: 13650183.000000\n",
      "Train Epoch: 102 [704/918 (77%)] Loss: 9651219.000000\n",
      "Train Epoch: 102 [720/918 (78%)] Loss: 7831216.000000\n",
      "Train Epoch: 102 [736/918 (80%)] Loss: 13285323.000000\n",
      "Train Epoch: 102 [752/918 (82%)] Loss: 8756223.000000\n",
      "Train Epoch: 102 [768/918 (84%)] Loss: 9825554.000000\n",
      "Train Epoch: 102 [784/918 (85%)] Loss: 9134456.000000\n",
      "Train Epoch: 102 [800/918 (87%)] Loss: 12299439.000000\n",
      "Train Epoch: 102 [816/918 (89%)] Loss: 7491925.000000\n",
      "Train Epoch: 102 [832/918 (91%)] Loss: 7454341.000000\n",
      "Train Epoch: 102 [848/918 (92%)] Loss: 8877264.000000\n",
      "Train Epoch: 102 [864/918 (94%)] Loss: 5634965.500000\n",
      "Train Epoch: 102 [880/918 (96%)] Loss: 6534476.500000\n",
      "Train Epoch: 102 [896/918 (98%)] Loss: 11447446.000000\n",
      "Train Epoch: 102 [912/918 (99%)] Loss: 9922854.000000\n",
      "    epoch          : 102\n",
      "    loss           : 9053811.813043479\n",
      "    ess            : 7.357179565015047\n",
      "    log_marginal   : -9053808.147826087\n",
      "    val_loss       : 9003059.76923077\n",
      "    val_ess        : 6.436931500068078\n",
      "    val_log_marginal: -9003058.423076924\n",
      "Train Epoch: 103 [0/918 (0%)] Loss: 6476899.000000\n",
      "Train Epoch: 103 [16/918 (2%)] Loss: 12292136.000000\n",
      "Train Epoch: 103 [32/918 (3%)] Loss: 7344363.500000\n",
      "Train Epoch: 103 [48/918 (5%)] Loss: 12934263.000000\n",
      "Train Epoch: 103 [64/918 (7%)] Loss: 10002575.000000\n",
      "Train Epoch: 103 [80/918 (9%)] Loss: 9119455.000000\n",
      "Train Epoch: 103 [96/918 (10%)] Loss: 6956734.500000\n",
      "Train Epoch: 103 [112/918 (12%)] Loss: 9025391.000000\n",
      "Train Epoch: 103 [128/918 (14%)] Loss: 7171967.500000\n",
      "Train Epoch: 103 [144/918 (16%)] Loss: 10400682.000000\n",
      "Train Epoch: 103 [160/918 (17%)] Loss: 8538987.000000\n",
      "Train Epoch: 103 [176/918 (19%)] Loss: 10896348.000000\n",
      "Train Epoch: 103 [192/918 (21%)] Loss: 9382179.000000\n",
      "Train Epoch: 103 [208/918 (23%)] Loss: 7981049.500000\n",
      "Train Epoch: 103 [224/918 (24%)] Loss: 8046569.500000\n",
      "Train Epoch: 103 [240/918 (26%)] Loss: 12599864.000000\n",
      "Train Epoch: 103 [256/918 (28%)] Loss: 8433303.000000\n",
      "Train Epoch: 103 [272/918 (30%)] Loss: 8113257.500000\n",
      "Train Epoch: 103 [288/918 (31%)] Loss: 9834549.000000\n",
      "Train Epoch: 103 [304/918 (33%)] Loss: 6804000.000000\n",
      "Train Epoch: 103 [320/918 (35%)] Loss: 7842491.500000\n",
      "Train Epoch: 103 [336/918 (37%)] Loss: 7579911.500000\n",
      "Train Epoch: 103 [352/918 (38%)] Loss: 9703658.000000\n",
      "Train Epoch: 103 [368/918 (40%)] Loss: 8534118.000000\n",
      "Train Epoch: 103 [384/918 (42%)] Loss: 7946545.500000\n",
      "Train Epoch: 103 [400/918 (44%)] Loss: 9818083.000000\n",
      "Train Epoch: 103 [416/918 (45%)] Loss: 14470066.000000\n",
      "Train Epoch: 103 [432/918 (47%)] Loss: 8617303.000000\n",
      "Train Epoch: 103 [448/918 (49%)] Loss: 9299787.000000\n",
      "Train Epoch: 103 [464/918 (51%)] Loss: 8293104.000000\n",
      "Train Epoch: 103 [480/918 (52%)] Loss: 9524336.000000\n",
      "Train Epoch: 103 [496/918 (54%)] Loss: 9028932.000000\n",
      "Train Epoch: 103 [512/918 (56%)] Loss: 11429522.000000\n",
      "Train Epoch: 103 [528/918 (58%)] Loss: 8525901.000000\n",
      "Train Epoch: 103 [544/918 (59%)] Loss: 7915537.000000\n",
      "Train Epoch: 103 [560/918 (61%)] Loss: 11587537.000000\n",
      "Train Epoch: 103 [576/918 (63%)] Loss: 9077831.000000\n",
      "Train Epoch: 103 [592/918 (64%)] Loss: 10804963.000000\n",
      "Train Epoch: 103 [608/918 (66%)] Loss: 7782830.500000\n",
      "Train Epoch: 103 [624/918 (68%)] Loss: 10478746.000000\n",
      "Train Epoch: 103 [640/918 (70%)] Loss: 6258253.500000\n",
      "Train Epoch: 103 [656/918 (71%)] Loss: 8032606.500000\n",
      "Train Epoch: 103 [672/918 (73%)] Loss: 7827489.000000\n",
      "Train Epoch: 103 [688/918 (75%)] Loss: 8734665.000000\n",
      "Train Epoch: 103 [704/918 (77%)] Loss: 6268855.500000\n",
      "Train Epoch: 103 [720/918 (78%)] Loss: 7856437.000000\n",
      "Train Epoch: 103 [736/918 (80%)] Loss: 7631113.000000\n",
      "Train Epoch: 103 [752/918 (82%)] Loss: 6418359.500000\n",
      "Train Epoch: 103 [768/918 (84%)] Loss: 7663189.000000\n",
      "Train Epoch: 103 [784/918 (85%)] Loss: 11647835.000000\n",
      "Train Epoch: 103 [800/918 (87%)] Loss: 9885359.000000\n",
      "Train Epoch: 103 [816/918 (89%)] Loss: 8028569.500000\n",
      "Train Epoch: 103 [832/918 (91%)] Loss: 8384328.000000\n",
      "Train Epoch: 103 [848/918 (92%)] Loss: 7884997.500000\n",
      "Train Epoch: 103 [864/918 (94%)] Loss: 7172293.000000\n",
      "Train Epoch: 103 [880/918 (96%)] Loss: 6665907.000000\n",
      "Train Epoch: 103 [896/918 (98%)] Loss: 6675327.500000\n",
      "Train Epoch: 103 [912/918 (99%)] Loss: 7641496.000000\n",
      "    epoch          : 103\n",
      "    loss           : 8703744.930434782\n",
      "    ess            : 7.068061098845109\n",
      "    log_marginal   : -8703742.330434782\n",
      "    val_loss       : 8749271.692307692\n",
      "    val_ess        : 6.9490419167738695\n",
      "    val_log_marginal: -8749269.538461538\n",
      "Train Epoch: 104 [0/918 (0%)] Loss: 7289864.000000\n",
      "Train Epoch: 104 [16/918 (2%)] Loss: 8826539.000000\n",
      "Train Epoch: 104 [32/918 (3%)] Loss: 8784836.000000\n",
      "Train Epoch: 104 [48/918 (5%)] Loss: 8402824.000000\n",
      "Train Epoch: 104 [64/918 (7%)] Loss: 8474088.000000\n",
      "Train Epoch: 104 [80/918 (9%)] Loss: 8076688.000000\n",
      "Train Epoch: 104 [96/918 (10%)] Loss: 10220781.000000\n",
      "Train Epoch: 104 [112/918 (12%)] Loss: 6821864.000000\n",
      "Train Epoch: 104 [128/918 (14%)] Loss: 9812552.000000\n",
      "Train Epoch: 104 [144/918 (16%)] Loss: 9478168.000000\n",
      "Train Epoch: 104 [160/918 (17%)] Loss: 8958320.000000\n",
      "Train Epoch: 104 [176/918 (19%)] Loss: 9091932.000000\n",
      "Train Epoch: 104 [192/918 (21%)] Loss: 9845232.000000\n",
      "Train Epoch: 104 [208/918 (23%)] Loss: 8218404.000000\n",
      "Train Epoch: 104 [224/918 (24%)] Loss: 6490197.000000\n",
      "Train Epoch: 104 [240/918 (26%)] Loss: 9153240.000000\n",
      "Train Epoch: 104 [256/918 (28%)] Loss: 6470425.500000\n",
      "Train Epoch: 104 [272/918 (30%)] Loss: 5443845.500000\n",
      "Train Epoch: 104 [288/918 (31%)] Loss: 7172811.500000\n",
      "Train Epoch: 104 [304/918 (33%)] Loss: 10629826.000000\n",
      "Train Epoch: 104 [320/918 (35%)] Loss: 7615474.500000\n",
      "Train Epoch: 104 [336/918 (37%)] Loss: 9957605.000000\n",
      "Train Epoch: 104 [352/918 (38%)] Loss: 7217521.500000\n",
      "Train Epoch: 104 [368/918 (40%)] Loss: 7865896.000000\n",
      "Train Epoch: 104 [384/918 (42%)] Loss: 10592423.000000\n",
      "Train Epoch: 104 [400/918 (44%)] Loss: 12598567.000000\n",
      "Train Epoch: 104 [416/918 (45%)] Loss: 8044405.000000\n",
      "Train Epoch: 104 [432/918 (47%)] Loss: 7374488.000000\n",
      "Train Epoch: 104 [448/918 (49%)] Loss: 6994677.000000\n",
      "Train Epoch: 104 [464/918 (51%)] Loss: 12858885.000000\n",
      "Train Epoch: 104 [480/918 (52%)] Loss: 11744099.000000\n",
      "Train Epoch: 104 [496/918 (54%)] Loss: 7079025.000000\n",
      "Train Epoch: 104 [512/918 (56%)] Loss: 8495804.000000\n",
      "Train Epoch: 104 [528/918 (58%)] Loss: 8574736.000000\n",
      "Train Epoch: 104 [544/918 (59%)] Loss: 5946246.500000\n",
      "Train Epoch: 104 [560/918 (61%)] Loss: 7123932.000000\n",
      "Train Epoch: 104 [576/918 (63%)] Loss: 10201239.000000\n",
      "Train Epoch: 104 [592/918 (64%)] Loss: 6535773.000000\n",
      "Train Epoch: 104 [608/918 (66%)] Loss: 9416959.000000\n",
      "Train Epoch: 104 [624/918 (68%)] Loss: 8752493.000000\n",
      "Train Epoch: 104 [640/918 (70%)] Loss: 8989096.000000\n",
      "Train Epoch: 104 [656/918 (71%)] Loss: 7512913.000000\n",
      "Train Epoch: 104 [672/918 (73%)] Loss: 9202787.000000\n",
      "Train Epoch: 104 [688/918 (75%)] Loss: 10699295.000000\n",
      "Train Epoch: 104 [704/918 (77%)] Loss: 8247821.500000\n",
      "Train Epoch: 104 [720/918 (78%)] Loss: 8439523.000000\n",
      "Train Epoch: 104 [736/918 (80%)] Loss: 11305674.000000\n",
      "Train Epoch: 104 [752/918 (82%)] Loss: 8857125.000000\n",
      "Train Epoch: 104 [768/918 (84%)] Loss: 7670549.000000\n",
      "Train Epoch: 104 [784/918 (85%)] Loss: 9700418.000000\n",
      "Train Epoch: 104 [800/918 (87%)] Loss: 9563703.000000\n",
      "Train Epoch: 104 [816/918 (89%)] Loss: 7812629.000000\n",
      "Train Epoch: 104 [832/918 (91%)] Loss: 11676728.000000\n",
      "Train Epoch: 104 [848/918 (92%)] Loss: 10307922.000000\n",
      "Train Epoch: 104 [864/918 (94%)] Loss: 10644946.000000\n",
      "Train Epoch: 104 [880/918 (96%)] Loss: 8477840.000000\n",
      "Train Epoch: 104 [896/918 (98%)] Loss: 9342199.000000\n",
      "Train Epoch: 104 [912/918 (99%)] Loss: 10078665.000000\n",
      "    epoch          : 104\n",
      "    loss           : 8769818.073913043\n",
      "    ess            : 7.472502326965332\n",
      "    log_marginal   : -8769816.204347827\n",
      "    val_loss       : 9322316.846153846\n",
      "    val_ess        : 7.139221283105703\n",
      "    val_log_marginal: -9322315.115384616\n",
      "Train Epoch: 105 [0/918 (0%)] Loss: 8312531.500000\n",
      "Train Epoch: 105 [16/918 (2%)] Loss: 7496322.500000\n",
      "Train Epoch: 105 [32/918 (3%)] Loss: 7344736.000000\n",
      "Train Epoch: 105 [48/918 (5%)] Loss: 5866808.000000\n",
      "Train Epoch: 105 [64/918 (7%)] Loss: 11777211.000000\n",
      "Train Epoch: 105 [80/918 (9%)] Loss: 7965365.000000\n",
      "Train Epoch: 105 [96/918 (10%)] Loss: 8078203.500000\n",
      "Train Epoch: 105 [112/918 (12%)] Loss: 9544800.000000\n",
      "Train Epoch: 105 [128/918 (14%)] Loss: 8471301.000000\n",
      "Train Epoch: 105 [144/918 (16%)] Loss: 8088742.500000\n",
      "Train Epoch: 105 [160/918 (17%)] Loss: 7612944.000000\n",
      "Train Epoch: 105 [176/918 (19%)] Loss: 11204881.000000\n",
      "Train Epoch: 105 [192/918 (21%)] Loss: 8145052.000000\n",
      "Train Epoch: 105 [208/918 (23%)] Loss: 7247353.500000\n",
      "Train Epoch: 105 [224/918 (24%)] Loss: 9773419.000000\n",
      "Train Epoch: 105 [240/918 (26%)] Loss: 11316680.000000\n",
      "Train Epoch: 105 [256/918 (28%)] Loss: 9800234.000000\n",
      "Train Epoch: 105 [272/918 (30%)] Loss: 8185029.000000\n",
      "Train Epoch: 105 [288/918 (31%)] Loss: 9659493.000000\n",
      "Train Epoch: 105 [304/918 (33%)] Loss: 9003925.000000\n",
      "Train Epoch: 105 [320/918 (35%)] Loss: 9705599.000000\n",
      "Train Epoch: 105 [336/918 (37%)] Loss: 10690437.000000\n",
      "Train Epoch: 105 [352/918 (38%)] Loss: 12528534.000000\n",
      "Train Epoch: 105 [368/918 (40%)] Loss: 9622143.000000\n",
      "Train Epoch: 105 [384/918 (42%)] Loss: 9784215.000000\n",
      "Train Epoch: 105 [400/918 (44%)] Loss: 8541983.000000\n",
      "Train Epoch: 105 [416/918 (45%)] Loss: 9176424.000000\n",
      "Train Epoch: 105 [432/918 (47%)] Loss: 12308871.000000\n",
      "Train Epoch: 105 [448/918 (49%)] Loss: 10338332.000000\n",
      "Train Epoch: 105 [464/918 (51%)] Loss: 6777843.500000\n",
      "Train Epoch: 105 [480/918 (52%)] Loss: 7055688.000000\n",
      "Train Epoch: 105 [496/918 (54%)] Loss: 6981822.500000\n",
      "Train Epoch: 105 [512/918 (56%)] Loss: 11476803.000000\n",
      "Train Epoch: 105 [528/918 (58%)] Loss: 6091417.500000\n",
      "Train Epoch: 105 [544/918 (59%)] Loss: 11642184.000000\n",
      "Train Epoch: 105 [560/918 (61%)] Loss: 8216054.500000\n",
      "Train Epoch: 105 [576/918 (63%)] Loss: 6293920.000000\n",
      "Train Epoch: 105 [592/918 (64%)] Loss: 11041672.000000\n",
      "Train Epoch: 105 [608/918 (66%)] Loss: 7832386.500000\n",
      "Train Epoch: 105 [624/918 (68%)] Loss: 6946214.500000\n",
      "Train Epoch: 105 [640/918 (70%)] Loss: 7755253.000000\n",
      "Train Epoch: 105 [656/918 (71%)] Loss: 7656088.000000\n",
      "Train Epoch: 105 [672/918 (73%)] Loss: 6021256.000000\n",
      "Train Epoch: 105 [688/918 (75%)] Loss: 8884891.000000\n",
      "Train Epoch: 105 [704/918 (77%)] Loss: 10318399.000000\n",
      "Train Epoch: 105 [720/918 (78%)] Loss: 7850017.500000\n",
      "Train Epoch: 105 [736/918 (80%)] Loss: 8564403.000000\n",
      "Train Epoch: 105 [752/918 (82%)] Loss: 6369088.500000\n",
      "Train Epoch: 105 [768/918 (84%)] Loss: 7904469.000000\n",
      "Train Epoch: 105 [784/918 (85%)] Loss: 7791005.000000\n",
      "Train Epoch: 105 [800/918 (87%)] Loss: 6000761.000000\n",
      "Train Epoch: 105 [816/918 (89%)] Loss: 13285000.000000\n",
      "Train Epoch: 105 [832/918 (91%)] Loss: 8001630.500000\n",
      "Train Epoch: 105 [848/918 (92%)] Loss: 7609303.500000\n",
      "Train Epoch: 105 [864/918 (94%)] Loss: 9254917.000000\n",
      "Train Epoch: 105 [880/918 (96%)] Loss: 6871952.000000\n",
      "Train Epoch: 105 [896/918 (98%)] Loss: 7859221.000000\n",
      "Train Epoch: 105 [912/918 (99%)] Loss: 9580695.000000\n",
      "    epoch          : 105\n",
      "    loss           : 8833070.304347826\n",
      "    ess            : 6.877254133639128\n",
      "    log_marginal   : -8833068.717391305\n",
      "    val_loss       : 8983527.423076924\n",
      "    val_ess        : 6.423142616565411\n",
      "    val_log_marginal: -8983525.961538462\n",
      "Train Epoch: 106 [0/918 (0%)] Loss: 9840981.000000\n",
      "Train Epoch: 106 [16/918 (2%)] Loss: 8685048.000000\n",
      "Train Epoch: 106 [32/918 (3%)] Loss: 9904269.000000\n",
      "Train Epoch: 106 [48/918 (5%)] Loss: 10168653.000000\n",
      "Train Epoch: 106 [64/918 (7%)] Loss: 14572643.000000\n",
      "Train Epoch: 106 [80/918 (9%)] Loss: 7067180.000000\n",
      "Train Epoch: 106 [96/918 (10%)] Loss: 9297691.000000\n",
      "Train Epoch: 106 [112/918 (12%)] Loss: 7589789.000000\n",
      "Train Epoch: 106 [128/918 (14%)] Loss: 9776037.000000\n",
      "Train Epoch: 106 [144/918 (16%)] Loss: 9238523.000000\n",
      "Train Epoch: 106 [160/918 (17%)] Loss: 8743335.000000\n",
      "Train Epoch: 106 [176/918 (19%)] Loss: 7943433.000000\n",
      "Train Epoch: 106 [192/918 (21%)] Loss: 6584816.000000\n",
      "Train Epoch: 106 [208/918 (23%)] Loss: 7967109.000000\n",
      "Train Epoch: 106 [224/918 (24%)] Loss: 9539839.000000\n",
      "Train Epoch: 106 [240/918 (26%)] Loss: 8696850.000000\n",
      "Train Epoch: 106 [256/918 (28%)] Loss: 8976380.000000\n",
      "Train Epoch: 106 [272/918 (30%)] Loss: 8171158.500000\n",
      "Train Epoch: 106 [288/918 (31%)] Loss: 8021053.000000\n",
      "Train Epoch: 106 [304/918 (33%)] Loss: 8957251.000000\n",
      "Train Epoch: 106 [320/918 (35%)] Loss: 14908797.000000\n",
      "Train Epoch: 106 [336/918 (37%)] Loss: 9640915.000000\n",
      "Train Epoch: 106 [352/918 (38%)] Loss: 10299520.000000\n",
      "Train Epoch: 106 [368/918 (40%)] Loss: 11705782.000000\n",
      "Train Epoch: 106 [384/918 (42%)] Loss: 9070301.000000\n",
      "Train Epoch: 106 [400/918 (44%)] Loss: 8402247.000000\n",
      "Train Epoch: 106 [416/918 (45%)] Loss: 10421095.000000\n",
      "Train Epoch: 106 [432/918 (47%)] Loss: 7963769.500000\n",
      "Train Epoch: 106 [448/918 (49%)] Loss: 6721741.000000\n",
      "Train Epoch: 106 [464/918 (51%)] Loss: 9049309.000000\n",
      "Train Epoch: 106 [480/918 (52%)] Loss: 7036926.500000\n",
      "Train Epoch: 106 [496/918 (54%)] Loss: 11540136.000000\n",
      "Train Epoch: 106 [512/918 (56%)] Loss: 12919511.000000\n",
      "Train Epoch: 106 [528/918 (58%)] Loss: 7913453.000000\n",
      "Train Epoch: 106 [544/918 (59%)] Loss: 9801171.000000\n",
      "Train Epoch: 106 [560/918 (61%)] Loss: 7970261.000000\n",
      "Train Epoch: 106 [576/918 (63%)] Loss: 9579872.000000\n",
      "Train Epoch: 106 [592/918 (64%)] Loss: 9444707.000000\n",
      "Train Epoch: 106 [608/918 (66%)] Loss: 6237553.500000\n",
      "Train Epoch: 106 [624/918 (68%)] Loss: 6087665.500000\n",
      "Train Epoch: 106 [640/918 (70%)] Loss: 8233763.500000\n",
      "Train Epoch: 106 [656/918 (71%)] Loss: 8071953.000000\n",
      "Train Epoch: 106 [672/918 (73%)] Loss: 10601147.000000\n",
      "Train Epoch: 106 [688/918 (75%)] Loss: 10545928.000000\n",
      "Train Epoch: 106 [704/918 (77%)] Loss: 11446004.000000\n",
      "Train Epoch: 106 [720/918 (78%)] Loss: 9535579.000000\n",
      "Train Epoch: 106 [736/918 (80%)] Loss: 10407990.000000\n",
      "Train Epoch: 106 [752/918 (82%)] Loss: 7681301.000000\n",
      "Train Epoch: 106 [768/918 (84%)] Loss: 13372707.000000\n",
      "Train Epoch: 106 [784/918 (85%)] Loss: 8505303.000000\n",
      "Train Epoch: 106 [800/918 (87%)] Loss: 9805736.000000\n",
      "Train Epoch: 106 [816/918 (89%)] Loss: 9337372.000000\n",
      "Train Epoch: 106 [832/918 (91%)] Loss: 9107365.000000\n",
      "Train Epoch: 106 [848/918 (92%)] Loss: 6569675.500000\n",
      "Train Epoch: 106 [864/918 (94%)] Loss: 8413623.000000\n",
      "Train Epoch: 106 [880/918 (96%)] Loss: 7101768.000000\n",
      "Train Epoch: 106 [896/918 (98%)] Loss: 10054710.000000\n",
      "Train Epoch: 106 [912/918 (99%)] Loss: 6891233.500000\n",
      "    epoch          : 106\n",
      "    loss           : 8966624.234782608\n",
      "    ess            : 7.859907571129177\n",
      "    log_marginal   : -8966622.439130435\n",
      "    val_loss       : 9338438.26923077\n",
      "    val_ess        : 6.73051905632019\n",
      "    val_log_marginal: -9338434.153846154\n",
      "Train Epoch: 107 [0/918 (0%)] Loss: 7475168.000000\n",
      "Train Epoch: 107 [16/918 (2%)] Loss: 11240994.000000\n",
      "Train Epoch: 107 [32/918 (3%)] Loss: 7015709.000000\n",
      "Train Epoch: 107 [48/918 (5%)] Loss: 9506147.000000\n",
      "Train Epoch: 107 [64/918 (7%)] Loss: 6780361.500000\n",
      "Train Epoch: 107 [80/918 (9%)] Loss: 7289909.000000\n",
      "Train Epoch: 107 [96/918 (10%)] Loss: 9368972.000000\n",
      "Train Epoch: 107 [112/918 (12%)] Loss: 9251517.000000\n",
      "Train Epoch: 107 [128/918 (14%)] Loss: 5185239.500000\n",
      "Train Epoch: 107 [144/918 (16%)] Loss: 7751373.500000\n",
      "Train Epoch: 107 [160/918 (17%)] Loss: 8776200.000000\n",
      "Train Epoch: 107 [176/918 (19%)] Loss: 6019442.500000\n",
      "Train Epoch: 107 [192/918 (21%)] Loss: 10798594.000000\n",
      "Train Epoch: 107 [208/918 (23%)] Loss: 8563063.000000\n",
      "Train Epoch: 107 [224/918 (24%)] Loss: 9775271.000000\n",
      "Train Epoch: 107 [240/918 (26%)] Loss: 5202541.500000\n",
      "Train Epoch: 107 [256/918 (28%)] Loss: 12311664.000000\n",
      "Train Epoch: 107 [272/918 (30%)] Loss: 6993838.500000\n",
      "Train Epoch: 107 [288/918 (31%)] Loss: 13542703.000000\n",
      "Train Epoch: 107 [304/918 (33%)] Loss: 7625161.500000\n",
      "Train Epoch: 107 [320/918 (35%)] Loss: 9701632.000000\n",
      "Train Epoch: 107 [336/918 (37%)] Loss: 12169027.000000\n",
      "Train Epoch: 107 [352/918 (38%)] Loss: 11367892.000000\n",
      "Train Epoch: 107 [368/918 (40%)] Loss: 7889416.000000\n",
      "Train Epoch: 107 [384/918 (42%)] Loss: 6987596.000000\n",
      "Train Epoch: 107 [400/918 (44%)] Loss: 13856291.000000\n",
      "Train Epoch: 107 [416/918 (45%)] Loss: 12173021.000000\n",
      "Train Epoch: 107 [432/918 (47%)] Loss: 6866485.000000\n",
      "Train Epoch: 107 [448/918 (49%)] Loss: 7027953.500000\n",
      "Train Epoch: 107 [464/918 (51%)] Loss: 6711181.000000\n",
      "Train Epoch: 107 [480/918 (52%)] Loss: 10579999.000000\n",
      "Train Epoch: 107 [496/918 (54%)] Loss: 8532082.000000\n",
      "Train Epoch: 107 [512/918 (56%)] Loss: 10218387.000000\n",
      "Train Epoch: 107 [528/918 (58%)] Loss: 11542744.000000\n",
      "Train Epoch: 107 [544/918 (59%)] Loss: 6182976.000000\n",
      "Train Epoch: 107 [560/918 (61%)] Loss: 10110435.000000\n",
      "Train Epoch: 107 [576/918 (63%)] Loss: 6513908.500000\n",
      "Train Epoch: 107 [592/918 (64%)] Loss: 7288646.500000\n",
      "Train Epoch: 107 [608/918 (66%)] Loss: 12309567.000000\n",
      "Train Epoch: 107 [624/918 (68%)] Loss: 10923958.000000\n",
      "Train Epoch: 107 [640/918 (70%)] Loss: 5305024.000000\n",
      "Train Epoch: 107 [656/918 (71%)] Loss: 10664007.000000\n",
      "Train Epoch: 107 [672/918 (73%)] Loss: 10695093.000000\n",
      "Train Epoch: 107 [688/918 (75%)] Loss: 10364583.000000\n",
      "Train Epoch: 107 [704/918 (77%)] Loss: 6182593.500000\n",
      "Train Epoch: 107 [720/918 (78%)] Loss: 7983320.000000\n",
      "Train Epoch: 107 [736/918 (80%)] Loss: 7374967.500000\n",
      "Train Epoch: 107 [752/918 (82%)] Loss: 10517162.000000\n",
      "Train Epoch: 107 [768/918 (84%)] Loss: 6853627.500000\n",
      "Train Epoch: 107 [784/918 (85%)] Loss: 8387360.000000\n",
      "Train Epoch: 107 [800/918 (87%)] Loss: 6662110.000000\n",
      "Train Epoch: 107 [816/918 (89%)] Loss: 8402490.000000\n",
      "Train Epoch: 107 [832/918 (91%)] Loss: 10274776.000000\n",
      "Train Epoch: 107 [848/918 (92%)] Loss: 6865046.500000\n",
      "Train Epoch: 107 [864/918 (94%)] Loss: 7525989.000000\n",
      "Train Epoch: 107 [880/918 (96%)] Loss: 7936966.500000\n",
      "Train Epoch: 107 [896/918 (98%)] Loss: 7371701.500000\n",
      "Train Epoch: 107 [912/918 (99%)] Loss: 6930852.000000\n",
      "    epoch          : 107\n",
      "    loss           : 8891146.113043478\n",
      "    ess            : 7.792743428893711\n",
      "    log_marginal   : -8891142.917391304\n",
      "    val_loss       : 9477322.461538462\n",
      "    val_ess        : 8.370622579868023\n",
      "    val_log_marginal: -9477319.576923076\n",
      "Train Epoch: 108 [0/918 (0%)] Loss: 9597583.000000\n",
      "Train Epoch: 108 [16/918 (2%)] Loss: 7659399.500000\n",
      "Train Epoch: 108 [32/918 (3%)] Loss: 6660721.000000\n",
      "Train Epoch: 108 [48/918 (5%)] Loss: 8801715.000000\n",
      "Train Epoch: 108 [64/918 (7%)] Loss: 13016117.000000\n",
      "Train Epoch: 108 [80/918 (9%)] Loss: 5029367.000000\n",
      "Train Epoch: 108 [96/918 (10%)] Loss: 7631393.500000\n",
      "Train Epoch: 108 [112/918 (12%)] Loss: 10101681.000000\n",
      "Train Epoch: 108 [128/918 (14%)] Loss: 6374962.000000\n",
      "Train Epoch: 108 [144/918 (16%)] Loss: 9328235.000000\n",
      "Train Epoch: 108 [160/918 (17%)] Loss: 12668435.000000\n",
      "Train Epoch: 108 [176/918 (19%)] Loss: 8383685.000000\n",
      "Train Epoch: 108 [192/918 (21%)] Loss: 10030335.000000\n",
      "Train Epoch: 108 [208/918 (23%)] Loss: 7126054.500000\n",
      "Train Epoch: 108 [224/918 (24%)] Loss: 6921571.500000\n",
      "Train Epoch: 108 [240/918 (26%)] Loss: 9532855.000000\n",
      "Train Epoch: 108 [256/918 (28%)] Loss: 15422589.000000\n",
      "Train Epoch: 108 [272/918 (30%)] Loss: 10863928.000000\n",
      "Train Epoch: 108 [288/918 (31%)] Loss: 12019371.000000\n",
      "Train Epoch: 108 [304/918 (33%)] Loss: 7202640.000000\n",
      "Train Epoch: 108 [320/918 (35%)] Loss: 8866869.000000\n",
      "Train Epoch: 108 [336/918 (37%)] Loss: 6296751.500000\n",
      "Train Epoch: 108 [352/918 (38%)] Loss: 9120368.000000\n",
      "Train Epoch: 108 [368/918 (40%)] Loss: 10009168.000000\n",
      "Train Epoch: 108 [384/918 (42%)] Loss: 7274915.500000\n",
      "Train Epoch: 108 [400/918 (44%)] Loss: 9434570.000000\n",
      "Train Epoch: 108 [416/918 (45%)] Loss: 6716985.500000\n",
      "Train Epoch: 108 [432/918 (47%)] Loss: 5897715.500000\n",
      "Train Epoch: 108 [448/918 (49%)] Loss: 13404067.000000\n",
      "Train Epoch: 108 [464/918 (51%)] Loss: 9271791.000000\n",
      "Train Epoch: 108 [480/918 (52%)] Loss: 7789526.500000\n",
      "Train Epoch: 108 [496/918 (54%)] Loss: 9048556.000000\n",
      "Train Epoch: 108 [512/918 (56%)] Loss: 6955649.500000\n",
      "Train Epoch: 108 [528/918 (58%)] Loss: 8697742.000000\n",
      "Train Epoch: 108 [544/918 (59%)] Loss: 7981856.000000\n",
      "Train Epoch: 108 [560/918 (61%)] Loss: 12257523.000000\n",
      "Train Epoch: 108 [576/918 (63%)] Loss: 7191297.500000\n",
      "Train Epoch: 108 [592/918 (64%)] Loss: 4757115.500000\n",
      "Train Epoch: 108 [608/918 (66%)] Loss: 8348609.500000\n",
      "Train Epoch: 108 [624/918 (68%)] Loss: 8576154.000000\n",
      "Train Epoch: 108 [640/918 (70%)] Loss: 10308864.000000\n",
      "Train Epoch: 108 [656/918 (71%)] Loss: 7349060.000000\n",
      "Train Epoch: 108 [672/918 (73%)] Loss: 9345453.000000\n",
      "Train Epoch: 108 [688/918 (75%)] Loss: 10372903.000000\n",
      "Train Epoch: 108 [704/918 (77%)] Loss: 9419032.000000\n",
      "Train Epoch: 108 [720/918 (78%)] Loss: 5919564.000000\n",
      "Train Epoch: 108 [736/918 (80%)] Loss: 9965664.000000\n",
      "Train Epoch: 108 [752/918 (82%)] Loss: 11213074.000000\n",
      "Train Epoch: 108 [768/918 (84%)] Loss: 6585209.000000\n",
      "Train Epoch: 108 [784/918 (85%)] Loss: 7459453.500000\n",
      "Train Epoch: 108 [800/918 (87%)] Loss: 7999104.000000\n",
      "Train Epoch: 108 [816/918 (89%)] Loss: 9725173.000000\n",
      "Train Epoch: 108 [832/918 (91%)] Loss: 9839066.000000\n",
      "Train Epoch: 108 [848/918 (92%)] Loss: 10010855.000000\n",
      "Train Epoch: 108 [864/918 (94%)] Loss: 8256229.000000\n",
      "Train Epoch: 108 [880/918 (96%)] Loss: 9642083.000000\n",
      "Train Epoch: 108 [896/918 (98%)] Loss: 11349606.000000\n",
      "Train Epoch: 108 [912/918 (99%)] Loss: 7860699.500000\n",
      "    epoch          : 108\n",
      "    loss           : 9084605.413043479\n",
      "    ess            : 7.4342951981917675\n",
      "    log_marginal   : -9084602.87826087\n",
      "    val_loss       : 8250599.269230769\n",
      "    val_ess        : 7.447741453464214\n",
      "    val_log_marginal: -8250597.576923077\n",
      "Train Epoch: 109 [0/918 (0%)] Loss: 8444591.000000\n",
      "Train Epoch: 109 [16/918 (2%)] Loss: 8972247.000000\n",
      "Train Epoch: 109 [32/918 (3%)] Loss: 7545289.500000\n",
      "Train Epoch: 109 [48/918 (5%)] Loss: 6323925.000000\n",
      "Train Epoch: 109 [64/918 (7%)] Loss: 7070467.500000\n",
      "Train Epoch: 109 [80/918 (9%)] Loss: 9741186.000000\n",
      "Train Epoch: 109 [96/918 (10%)] Loss: 7453974.500000\n",
      "Train Epoch: 109 [112/918 (12%)] Loss: 9586111.000000\n",
      "Train Epoch: 109 [128/918 (14%)] Loss: 10371574.000000\n",
      "Train Epoch: 109 [144/918 (16%)] Loss: 9747936.000000\n",
      "Train Epoch: 109 [160/918 (17%)] Loss: 9631110.000000\n",
      "Train Epoch: 109 [176/918 (19%)] Loss: 6742055.500000\n",
      "Train Epoch: 109 [192/918 (21%)] Loss: 11790242.000000\n",
      "Train Epoch: 109 [208/918 (23%)] Loss: 10506501.000000\n",
      "Train Epoch: 109 [224/918 (24%)] Loss: 8103786.500000\n",
      "Train Epoch: 109 [240/918 (26%)] Loss: 8261938.500000\n",
      "Train Epoch: 109 [256/918 (28%)] Loss: 8718541.000000\n",
      "Train Epoch: 109 [272/918 (30%)] Loss: 10500523.000000\n",
      "Train Epoch: 109 [288/918 (31%)] Loss: 7142123.500000\n",
      "Train Epoch: 109 [304/918 (33%)] Loss: 8502930.000000\n",
      "Train Epoch: 109 [320/918 (35%)] Loss: 11385603.000000\n",
      "Train Epoch: 109 [336/918 (37%)] Loss: 6660663.500000\n",
      "Train Epoch: 109 [352/918 (38%)] Loss: 9256271.000000\n",
      "Train Epoch: 109 [368/918 (40%)] Loss: 11731113.000000\n",
      "Train Epoch: 109 [384/918 (42%)] Loss: 7542176.000000\n",
      "Train Epoch: 109 [400/918 (44%)] Loss: 7078990.500000\n",
      "Train Epoch: 109 [416/918 (45%)] Loss: 11334899.000000\n",
      "Train Epoch: 109 [432/918 (47%)] Loss: 10088001.000000\n",
      "Train Epoch: 109 [448/918 (49%)] Loss: 9958235.000000\n",
      "Train Epoch: 109 [464/918 (51%)] Loss: 8543131.000000\n",
      "Train Epoch: 109 [480/918 (52%)] Loss: 9812567.000000\n",
      "Train Epoch: 109 [496/918 (54%)] Loss: 15263501.000000\n",
      "Train Epoch: 109 [512/918 (56%)] Loss: 8260872.000000\n",
      "Train Epoch: 109 [528/918 (58%)] Loss: 8476008.000000\n",
      "Train Epoch: 109 [544/918 (59%)] Loss: 6948741.500000\n",
      "Train Epoch: 109 [560/918 (61%)] Loss: 9172719.000000\n",
      "Train Epoch: 109 [576/918 (63%)] Loss: 6002657.000000\n",
      "Train Epoch: 109 [592/918 (64%)] Loss: 9705575.000000\n",
      "Train Epoch: 109 [608/918 (66%)] Loss: 6359529.500000\n",
      "Train Epoch: 109 [624/918 (68%)] Loss: 6112890.500000\n",
      "Train Epoch: 109 [640/918 (70%)] Loss: 16043642.000000\n",
      "Train Epoch: 109 [656/918 (71%)] Loss: 8605283.000000\n",
      "Train Epoch: 109 [672/918 (73%)] Loss: 11743168.000000\n",
      "Train Epoch: 109 [688/918 (75%)] Loss: 13035494.000000\n",
      "Train Epoch: 109 [704/918 (77%)] Loss: 11088700.000000\n",
      "Train Epoch: 109 [720/918 (78%)] Loss: 9875407.000000\n",
      "Train Epoch: 109 [736/918 (80%)] Loss: 6523059.500000\n",
      "Train Epoch: 109 [752/918 (82%)] Loss: 11197618.000000\n",
      "Train Epoch: 109 [768/918 (84%)] Loss: 13435955.000000\n",
      "Train Epoch: 109 [784/918 (85%)] Loss: 10106015.000000\n",
      "Train Epoch: 109 [800/918 (87%)] Loss: 7687774.500000\n",
      "Train Epoch: 109 [816/918 (89%)] Loss: 10511354.000000\n",
      "Train Epoch: 109 [832/918 (91%)] Loss: 8464749.000000\n",
      "Train Epoch: 109 [848/918 (92%)] Loss: 14614823.000000\n",
      "Train Epoch: 109 [864/918 (94%)] Loss: 7468569.500000\n",
      "Train Epoch: 109 [880/918 (96%)] Loss: 6392539.000000\n",
      "Train Epoch: 109 [896/918 (98%)] Loss: 9025995.000000\n",
      "Train Epoch: 109 [912/918 (99%)] Loss: 10363861.000000\n",
      "    epoch          : 109\n",
      "    loss           : 8912608.582608696\n",
      "    ess            : 7.2264269020246426\n",
      "    log_marginal   : -8912605.921739131\n",
      "    val_loss       : 9639494.615384616\n",
      "    val_ess        : 7.278791024134709\n",
      "    val_log_marginal: -9639469.576923076\n",
      "Train Epoch: 110 [0/918 (0%)] Loss: 8530319.000000\n",
      "Train Epoch: 110 [16/918 (2%)] Loss: 7358806.500000\n",
      "Train Epoch: 110 [32/918 (3%)] Loss: 6287357.500000\n",
      "Train Epoch: 110 [48/918 (5%)] Loss: 8516394.000000\n",
      "Train Epoch: 110 [64/918 (7%)] Loss: 10994648.000000\n",
      "Train Epoch: 110 [80/918 (9%)] Loss: 7647865.000000\n",
      "Train Epoch: 110 [96/918 (10%)] Loss: 12143760.000000\n",
      "Train Epoch: 110 [112/918 (12%)] Loss: 9522153.000000\n",
      "Train Epoch: 110 [128/918 (14%)] Loss: 6786625.000000\n",
      "Train Epoch: 110 [144/918 (16%)] Loss: 7353001.500000\n",
      "Train Epoch: 110 [160/918 (17%)] Loss: 9551042.000000\n",
      "Train Epoch: 110 [176/918 (19%)] Loss: 8550458.000000\n",
      "Train Epoch: 110 [192/918 (21%)] Loss: 13068509.000000\n",
      "Train Epoch: 110 [208/918 (23%)] Loss: 6010827.500000\n",
      "Train Epoch: 110 [224/918 (24%)] Loss: 8472778.000000\n",
      "Train Epoch: 110 [240/918 (26%)] Loss: 11535128.000000\n",
      "Train Epoch: 110 [256/918 (28%)] Loss: 5556713.500000\n",
      "Train Epoch: 110 [272/918 (30%)] Loss: 7975629.500000\n",
      "Train Epoch: 110 [288/918 (31%)] Loss: 8592466.000000\n",
      "Train Epoch: 110 [304/918 (33%)] Loss: 11273900.000000\n",
      "Train Epoch: 110 [320/918 (35%)] Loss: 8835055.000000\n",
      "Train Epoch: 110 [336/918 (37%)] Loss: 10272138.000000\n",
      "Train Epoch: 110 [352/918 (38%)] Loss: 11746487.000000\n",
      "Train Epoch: 110 [368/918 (40%)] Loss: 9194887.000000\n",
      "Train Epoch: 110 [384/918 (42%)] Loss: 8733298.000000\n",
      "Train Epoch: 110 [400/918 (44%)] Loss: 7665251.500000\n",
      "Train Epoch: 110 [416/918 (45%)] Loss: 10353350.000000\n",
      "Train Epoch: 110 [432/918 (47%)] Loss: 8441035.000000\n",
      "Train Epoch: 110 [448/918 (49%)] Loss: 7857583.500000\n",
      "Train Epoch: 110 [464/918 (51%)] Loss: 7855182.500000\n",
      "Train Epoch: 110 [480/918 (52%)] Loss: 8861242.000000\n",
      "Train Epoch: 110 [496/918 (54%)] Loss: 6241410.000000\n",
      "Train Epoch: 110 [512/918 (56%)] Loss: 7610089.000000\n",
      "Train Epoch: 110 [528/918 (58%)] Loss: 7036314.500000\n",
      "Train Epoch: 110 [544/918 (59%)] Loss: 11408909.000000\n",
      "Train Epoch: 110 [560/918 (61%)] Loss: 8456431.000000\n",
      "Train Epoch: 110 [576/918 (63%)] Loss: 9139619.000000\n",
      "Train Epoch: 110 [592/918 (64%)] Loss: 13690259.000000\n",
      "Train Epoch: 110 [608/918 (66%)] Loss: 7399617.500000\n",
      "Train Epoch: 110 [624/918 (68%)] Loss: 8528747.000000\n",
      "Train Epoch: 110 [640/918 (70%)] Loss: 10696488.000000\n",
      "Train Epoch: 110 [656/918 (71%)] Loss: 9562519.000000\n",
      "Train Epoch: 110 [672/918 (73%)] Loss: 11437337.000000\n",
      "Train Epoch: 110 [688/918 (75%)] Loss: 6635708.000000\n",
      "Train Epoch: 110 [704/918 (77%)] Loss: 12633528.000000\n",
      "Train Epoch: 110 [720/918 (78%)] Loss: 14190826.000000\n",
      "Train Epoch: 110 [736/918 (80%)] Loss: 8613952.000000\n",
      "Train Epoch: 110 [752/918 (82%)] Loss: 7135360.000000\n",
      "Train Epoch: 110 [768/918 (84%)] Loss: 9267167.000000\n",
      "Train Epoch: 110 [784/918 (85%)] Loss: 12152513.000000\n",
      "Train Epoch: 110 [800/918 (87%)] Loss: 13083312.000000\n",
      "Train Epoch: 110 [816/918 (89%)] Loss: 7364816.000000\n",
      "Train Epoch: 110 [832/918 (91%)] Loss: 9853122.000000\n",
      "Train Epoch: 110 [848/918 (92%)] Loss: 12260023.000000\n",
      "Train Epoch: 110 [864/918 (94%)] Loss: 10249791.000000\n",
      "Train Epoch: 110 [880/918 (96%)] Loss: 5170731.500000\n",
      "Train Epoch: 110 [896/918 (98%)] Loss: 7530576.000000\n",
      "Train Epoch: 110 [912/918 (99%)] Loss: 13772131.000000\n",
      "    epoch          : 110\n",
      "    loss           : 9125955.786956523\n",
      "    ess            : 7.776676590546318\n",
      "    log_marginal   : -9125953.97826087\n",
      "    val_loss       : 9244369.23076923\n",
      "    val_ess        : 6.437235813874465\n",
      "    val_log_marginal: -9244367.615384616\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch110.pth ...\n",
      "Train Epoch: 111 [0/918 (0%)] Loss: 7355985.500000\n",
      "Train Epoch: 111 [16/918 (2%)] Loss: 10199282.000000\n",
      "Train Epoch: 111 [32/918 (3%)] Loss: 9175841.000000\n",
      "Train Epoch: 111 [48/918 (5%)] Loss: 9401072.000000\n",
      "Train Epoch: 111 [64/918 (7%)] Loss: 8505970.000000\n",
      "Train Epoch: 111 [80/918 (9%)] Loss: 9890320.000000\n",
      "Train Epoch: 111 [96/918 (10%)] Loss: 9603554.000000\n",
      "Train Epoch: 111 [112/918 (12%)] Loss: 7422010.500000\n",
      "Train Epoch: 111 [128/918 (14%)] Loss: 11003440.000000\n",
      "Train Epoch: 111 [144/918 (16%)] Loss: 15568344.000000\n",
      "Train Epoch: 111 [160/918 (17%)] Loss: 6719694.500000\n",
      "Train Epoch: 111 [176/918 (19%)] Loss: 7273280.000000\n",
      "Train Epoch: 111 [192/918 (21%)] Loss: 7422141.000000\n",
      "Train Epoch: 111 [208/918 (23%)] Loss: 7625598.500000\n",
      "Train Epoch: 111 [224/918 (24%)] Loss: 10644770.000000\n",
      "Train Epoch: 111 [240/918 (26%)] Loss: 10848615.000000\n",
      "Train Epoch: 111 [256/918 (28%)] Loss: 5676299.500000\n",
      "Train Epoch: 111 [272/918 (30%)] Loss: 10357819.000000\n",
      "Train Epoch: 111 [288/918 (31%)] Loss: 11213272.000000\n",
      "Train Epoch: 111 [304/918 (33%)] Loss: 10518873.000000\n",
      "Train Epoch: 111 [320/918 (35%)] Loss: 12731770.000000\n",
      "Train Epoch: 111 [336/918 (37%)] Loss: 5331395.500000\n",
      "Train Epoch: 111 [352/918 (38%)] Loss: 12124547.000000\n",
      "Train Epoch: 111 [368/918 (40%)] Loss: 13048975.000000\n",
      "Train Epoch: 111 [384/918 (42%)] Loss: 8833851.000000\n",
      "Train Epoch: 111 [400/918 (44%)] Loss: 7882982.500000\n",
      "Train Epoch: 111 [416/918 (45%)] Loss: 13697858.000000\n",
      "Train Epoch: 111 [432/918 (47%)] Loss: 8186876.000000\n",
      "Train Epoch: 111 [448/918 (49%)] Loss: 11793166.000000\n",
      "Train Epoch: 111 [464/918 (51%)] Loss: 15462149.000000\n",
      "Train Epoch: 111 [480/918 (52%)] Loss: 9155278.000000\n",
      "Train Epoch: 111 [496/918 (54%)] Loss: 8739195.000000\n",
      "Train Epoch: 111 [512/918 (56%)] Loss: 13735557.000000\n",
      "Train Epoch: 111 [528/918 (58%)] Loss: 5886025.000000\n",
      "Train Epoch: 111 [544/918 (59%)] Loss: 8902975.000000\n",
      "Train Epoch: 111 [560/918 (61%)] Loss: 9820523.000000\n",
      "Train Epoch: 111 [576/918 (63%)] Loss: 7650931.500000\n",
      "Train Epoch: 111 [592/918 (64%)] Loss: 8631088.000000\n",
      "Train Epoch: 111 [608/918 (66%)] Loss: 6187882.000000\n",
      "Train Epoch: 111 [624/918 (68%)] Loss: 6925280.000000\n",
      "Train Epoch: 111 [640/918 (70%)] Loss: 9306258.000000\n",
      "Train Epoch: 111 [656/918 (71%)] Loss: 10959630.000000\n",
      "Train Epoch: 111 [672/918 (73%)] Loss: 14485379.000000\n",
      "Train Epoch: 111 [688/918 (75%)] Loss: 8810896.000000\n",
      "Train Epoch: 111 [704/918 (77%)] Loss: 10032234.000000\n",
      "Train Epoch: 111 [720/918 (78%)] Loss: 8776320.000000\n",
      "Train Epoch: 111 [736/918 (80%)] Loss: 8428272.000000\n",
      "Train Epoch: 111 [752/918 (82%)] Loss: 7016172.000000\n",
      "Train Epoch: 111 [768/918 (84%)] Loss: 8816884.000000\n",
      "Train Epoch: 111 [784/918 (85%)] Loss: 8199990.500000\n",
      "Train Epoch: 111 [800/918 (87%)] Loss: 7336429.500000\n",
      "Train Epoch: 111 [816/918 (89%)] Loss: 8104141.000000\n",
      "Train Epoch: 111 [832/918 (91%)] Loss: 9341367.000000\n",
      "Train Epoch: 111 [848/918 (92%)] Loss: 11534008.000000\n",
      "Train Epoch: 111 [864/918 (94%)] Loss: 10978399.000000\n",
      "Train Epoch: 111 [880/918 (96%)] Loss: 6777837.000000\n",
      "Train Epoch: 111 [896/918 (98%)] Loss: 7737941.000000\n",
      "Train Epoch: 111 [912/918 (99%)] Loss: 4913312.500000\n",
      "    epoch          : 111\n",
      "    loss           : 9077690.239130436\n",
      "    ess            : 7.783038191173388\n",
      "    log_marginal   : -9077688.126086956\n",
      "    val_loss       : 9740332.115384616\n",
      "    val_ess        : 9.068065936748798\n",
      "    val_log_marginal: -9740329.5\n",
      "Train Epoch: 112 [0/918 (0%)] Loss: 11356549.000000\n",
      "Train Epoch: 112 [16/918 (2%)] Loss: 12248146.000000\n",
      "Train Epoch: 112 [32/918 (3%)] Loss: 8830985.000000\n",
      "Train Epoch: 112 [48/918 (5%)] Loss: 12368955.000000\n",
      "Train Epoch: 112 [64/918 (7%)] Loss: 8266296.000000\n",
      "Train Epoch: 112 [80/918 (9%)] Loss: 9290838.000000\n",
      "Train Epoch: 112 [96/918 (10%)] Loss: 8889442.000000\n",
      "Train Epoch: 112 [112/918 (12%)] Loss: 10718821.000000\n",
      "Train Epoch: 112 [128/918 (14%)] Loss: 13042283.000000\n",
      "Train Epoch: 112 [144/918 (16%)] Loss: 7282259.500000\n",
      "Train Epoch: 112 [160/918 (17%)] Loss: 11399035.000000\n",
      "Train Epoch: 112 [176/918 (19%)] Loss: 6176577.000000\n",
      "Train Epoch: 112 [192/918 (21%)] Loss: 11873040.000000\n",
      "Train Epoch: 112 [208/918 (23%)] Loss: 8838970.000000\n",
      "Train Epoch: 112 [224/918 (24%)] Loss: 9319653.000000\n",
      "Train Epoch: 112 [240/918 (26%)] Loss: 8127062.500000\n",
      "Train Epoch: 112 [256/918 (28%)] Loss: 7533525.000000\n",
      "Train Epoch: 112 [272/918 (30%)] Loss: 10290973.000000\n",
      "Train Epoch: 112 [288/918 (31%)] Loss: 15243133.000000\n",
      "Train Epoch: 112 [304/918 (33%)] Loss: 10708899.000000\n",
      "Train Epoch: 112 [320/918 (35%)] Loss: 10607751.000000\n",
      "Train Epoch: 112 [336/918 (37%)] Loss: 4927261.500000\n",
      "Train Epoch: 112 [352/918 (38%)] Loss: 10773195.000000\n",
      "Train Epoch: 112 [368/918 (40%)] Loss: 12953987.000000\n",
      "Train Epoch: 112 [384/918 (42%)] Loss: 6939840.000000\n",
      "Train Epoch: 112 [400/918 (44%)] Loss: 8655107.000000\n",
      "Train Epoch: 112 [416/918 (45%)] Loss: 7348040.000000\n",
      "Train Epoch: 112 [432/918 (47%)] Loss: 12060593.000000\n",
      "Train Epoch: 112 [448/918 (49%)] Loss: 7701249.500000\n",
      "Train Epoch: 112 [464/918 (51%)] Loss: 6352355.000000\n",
      "Train Epoch: 112 [480/918 (52%)] Loss: 10608791.000000\n",
      "Train Epoch: 112 [496/918 (54%)] Loss: 19392922.000000\n",
      "Train Epoch: 112 [512/918 (56%)] Loss: 8489667.000000\n",
      "Train Epoch: 112 [528/918 (58%)] Loss: 8896602.000000\n",
      "Train Epoch: 112 [544/918 (59%)] Loss: 8965512.000000\n",
      "Train Epoch: 112 [560/918 (61%)] Loss: 7443752.000000\n",
      "Train Epoch: 112 [576/918 (63%)] Loss: 13637899.000000\n",
      "Train Epoch: 112 [592/918 (64%)] Loss: 8127268.000000\n",
      "Train Epoch: 112 [608/918 (66%)] Loss: 8543906.000000\n",
      "Train Epoch: 112 [624/918 (68%)] Loss: 11520560.000000\n",
      "Train Epoch: 112 [640/918 (70%)] Loss: 8992039.000000\n",
      "Train Epoch: 112 [656/918 (71%)] Loss: 12257695.000000\n",
      "Train Epoch: 112 [672/918 (73%)] Loss: 8344171.500000\n",
      "Train Epoch: 112 [688/918 (75%)] Loss: 9786312.000000\n",
      "Train Epoch: 112 [704/918 (77%)] Loss: 7964505.500000\n",
      "Train Epoch: 112 [720/918 (78%)] Loss: 10707586.000000\n",
      "Train Epoch: 112 [736/918 (80%)] Loss: 12078160.000000\n",
      "Train Epoch: 112 [752/918 (82%)] Loss: 8491309.000000\n",
      "Train Epoch: 112 [768/918 (84%)] Loss: 6702278.500000\n",
      "Train Epoch: 112 [784/918 (85%)] Loss: 12037325.000000\n",
      "Train Epoch: 112 [800/918 (87%)] Loss: 8728057.000000\n",
      "Train Epoch: 112 [816/918 (89%)] Loss: 9291068.000000\n",
      "Train Epoch: 112 [832/918 (91%)] Loss: 8246969.000000\n",
      "Train Epoch: 112 [848/918 (92%)] Loss: 8362833.500000\n",
      "Train Epoch: 112 [864/918 (94%)] Loss: 7190296.000000\n",
      "Train Epoch: 112 [880/918 (96%)] Loss: 9409084.000000\n",
      "Train Epoch: 112 [896/918 (98%)] Loss: 10065887.000000\n",
      "Train Epoch: 112 [912/918 (99%)] Loss: 11335065.000000\n",
      "    epoch          : 112\n",
      "    loss           : 9485963.347826088\n",
      "    ess            : 7.992043252613233\n",
      "    log_marginal   : -9485960.713043477\n",
      "    val_loss       : 9795020.73076923\n",
      "    val_ess        : 8.644973314725435\n",
      "    val_log_marginal: -9795017.961538462\n",
      "Train Epoch: 113 [0/918 (0%)] Loss: 7423359.500000\n",
      "Train Epoch: 113 [16/918 (2%)] Loss: 7500609.500000\n",
      "Train Epoch: 113 [32/918 (3%)] Loss: 13077431.000000\n",
      "Train Epoch: 113 [48/918 (5%)] Loss: 12359264.000000\n",
      "Train Epoch: 113 [64/918 (7%)] Loss: 13250611.000000\n",
      "Train Epoch: 113 [80/918 (9%)] Loss: 8803163.000000\n",
      "Train Epoch: 113 [96/918 (10%)] Loss: 7673582.500000\n",
      "Train Epoch: 113 [112/918 (12%)] Loss: 11110336.000000\n",
      "Train Epoch: 113 [128/918 (14%)] Loss: 7562787.500000\n",
      "Train Epoch: 113 [144/918 (16%)] Loss: 7732647.500000\n",
      "Train Epoch: 113 [160/918 (17%)] Loss: 8577391.000000\n",
      "Train Epoch: 113 [176/918 (19%)] Loss: 8707752.000000\n",
      "Train Epoch: 113 [192/918 (21%)] Loss: 6759646.500000\n",
      "Train Epoch: 113 [208/918 (23%)] Loss: 10705335.000000\n",
      "Train Epoch: 113 [224/918 (24%)] Loss: 9886498.000000\n",
      "Train Epoch: 113 [240/918 (26%)] Loss: 7016724.000000\n",
      "Train Epoch: 113 [256/918 (28%)] Loss: 12683005.000000\n",
      "Train Epoch: 113 [272/918 (30%)] Loss: 7337969.500000\n",
      "Train Epoch: 113 [288/918 (31%)] Loss: 19632086.000000\n",
      "Train Epoch: 113 [304/918 (33%)] Loss: 9095876.000000\n",
      "Train Epoch: 113 [320/918 (35%)] Loss: 6006770.000000\n",
      "Train Epoch: 113 [336/918 (37%)] Loss: 6634334.500000\n",
      "Train Epoch: 113 [352/918 (38%)] Loss: 6721314.500000\n",
      "Train Epoch: 113 [368/918 (40%)] Loss: 9555498.000000\n",
      "Train Epoch: 113 [384/918 (42%)] Loss: 10430469.000000\n",
      "Train Epoch: 113 [400/918 (44%)] Loss: 10719744.000000\n",
      "Train Epoch: 113 [416/918 (45%)] Loss: 4820520.000000\n",
      "Train Epoch: 113 [432/918 (47%)] Loss: 7974481.000000\n",
      "Train Epoch: 113 [448/918 (49%)] Loss: 9268271.000000\n",
      "Train Epoch: 113 [464/918 (51%)] Loss: 9286788.000000\n",
      "Train Epoch: 113 [480/918 (52%)] Loss: 11162130.000000\n",
      "Train Epoch: 113 [496/918 (54%)] Loss: 9319133.000000\n",
      "Train Epoch: 113 [512/918 (56%)] Loss: 8242067.500000\n",
      "Train Epoch: 113 [528/918 (58%)] Loss: 6112599.500000\n",
      "Train Epoch: 113 [544/918 (59%)] Loss: 12160376.000000\n",
      "Train Epoch: 113 [560/918 (61%)] Loss: 6379889.500000\n",
      "Train Epoch: 113 [576/918 (63%)] Loss: 7010417.500000\n",
      "Train Epoch: 113 [592/918 (64%)] Loss: 8496240.000000\n",
      "Train Epoch: 113 [608/918 (66%)] Loss: 8475680.000000\n",
      "Train Epoch: 113 [624/918 (68%)] Loss: 9256663.000000\n",
      "Train Epoch: 113 [640/918 (70%)] Loss: 9038875.000000\n",
      "Train Epoch: 113 [656/918 (71%)] Loss: 10967327.000000\n",
      "Train Epoch: 113 [672/918 (73%)] Loss: 13282513.000000\n",
      "Train Epoch: 113 [688/918 (75%)] Loss: 8729271.000000\n",
      "Train Epoch: 113 [704/918 (77%)] Loss: 8114072.000000\n",
      "Train Epoch: 113 [720/918 (78%)] Loss: 9074799.000000\n",
      "Train Epoch: 113 [736/918 (80%)] Loss: 8440482.000000\n",
      "Train Epoch: 113 [752/918 (82%)] Loss: 7640150.500000\n",
      "Train Epoch: 113 [768/918 (84%)] Loss: 10678576.000000\n",
      "Train Epoch: 113 [784/918 (85%)] Loss: 8490016.000000\n",
      "Train Epoch: 113 [800/918 (87%)] Loss: 9387066.000000\n",
      "Train Epoch: 113 [816/918 (89%)] Loss: 8055560.000000\n",
      "Train Epoch: 113 [832/918 (91%)] Loss: 13752509.000000\n",
      "Train Epoch: 113 [848/918 (92%)] Loss: 8954315.000000\n",
      "Train Epoch: 113 [864/918 (94%)] Loss: 9286880.000000\n",
      "Train Epoch: 113 [880/918 (96%)] Loss: 8174793.000000\n",
      "Train Epoch: 113 [896/918 (98%)] Loss: 9314640.000000\n",
      "Train Epoch: 113 [912/918 (99%)] Loss: 16410900.000000\n",
      "    epoch          : 113\n",
      "    loss           : 9405219.539130434\n",
      "    ess            : 7.19572350045909\n",
      "    log_marginal   : -9405217.295652173\n",
      "    val_loss       : 8694789.76923077\n",
      "    val_ess        : 5.7842754767491265\n",
      "    val_log_marginal: -8694783.5\n",
      "Train Epoch: 114 [0/918 (0%)] Loss: 6810961.500000\n",
      "Train Epoch: 114 [16/918 (2%)] Loss: 11880315.000000\n",
      "Train Epoch: 114 [32/918 (3%)] Loss: 16733863.000000\n",
      "Train Epoch: 114 [48/918 (5%)] Loss: 10126295.000000\n",
      "Train Epoch: 114 [64/918 (7%)] Loss: 9268443.000000\n",
      "Train Epoch: 114 [80/918 (9%)] Loss: 6377305.500000\n",
      "Train Epoch: 114 [96/918 (10%)] Loss: 7475800.000000\n",
      "Train Epoch: 114 [112/918 (12%)] Loss: 10074450.000000\n",
      "Train Epoch: 114 [128/918 (14%)] Loss: 8334945.500000\n",
      "Train Epoch: 114 [144/918 (16%)] Loss: 6937224.000000\n",
      "Train Epoch: 114 [160/918 (17%)] Loss: 7000751.500000\n",
      "Train Epoch: 114 [176/918 (19%)] Loss: 9540031.000000\n",
      "Train Epoch: 114 [192/918 (21%)] Loss: 8504885.000000\n",
      "Train Epoch: 114 [208/918 (23%)] Loss: 14645992.000000\n",
      "Train Epoch: 114 [224/918 (24%)] Loss: 7442739.500000\n",
      "Train Epoch: 114 [240/918 (26%)] Loss: 6910400.000000\n",
      "Train Epoch: 114 [256/918 (28%)] Loss: 8072982.500000\n",
      "Train Epoch: 114 [272/918 (30%)] Loss: 9329703.000000\n",
      "Train Epoch: 114 [288/918 (31%)] Loss: 6471764.500000\n",
      "Train Epoch: 114 [304/918 (33%)] Loss: 6782872.000000\n",
      "Train Epoch: 114 [320/918 (35%)] Loss: 10496445.000000\n",
      "Train Epoch: 114 [336/918 (37%)] Loss: 13839562.000000\n",
      "Train Epoch: 114 [352/918 (38%)] Loss: 9773870.000000\n",
      "Train Epoch: 114 [368/918 (40%)] Loss: 5779803.000000\n",
      "Train Epoch: 114 [384/918 (42%)] Loss: 7673581.000000\n",
      "Train Epoch: 114 [400/918 (44%)] Loss: 8298526.500000\n",
      "Train Epoch: 114 [416/918 (45%)] Loss: 10703077.000000\n",
      "Train Epoch: 114 [432/918 (47%)] Loss: 11548952.000000\n",
      "Train Epoch: 114 [448/918 (49%)] Loss: 11852886.000000\n",
      "Train Epoch: 114 [464/918 (51%)] Loss: 9435184.000000\n",
      "Train Epoch: 114 [480/918 (52%)] Loss: 8097245.500000\n",
      "Train Epoch: 114 [496/918 (54%)] Loss: 8108441.500000\n",
      "Train Epoch: 114 [512/918 (56%)] Loss: 12915579.000000\n",
      "Train Epoch: 114 [528/918 (58%)] Loss: 7640032.000000\n",
      "Train Epoch: 114 [544/918 (59%)] Loss: 8516200.000000\n",
      "Train Epoch: 114 [560/918 (61%)] Loss: 10868682.000000\n",
      "Train Epoch: 114 [576/918 (63%)] Loss: 12823038.000000\n",
      "Train Epoch: 114 [592/918 (64%)] Loss: 8295894.500000\n",
      "Train Epoch: 114 [608/918 (66%)] Loss: 10913369.000000\n",
      "Train Epoch: 114 [624/918 (68%)] Loss: 6188881.000000\n",
      "Train Epoch: 114 [640/918 (70%)] Loss: 9380639.000000\n",
      "Train Epoch: 114 [656/918 (71%)] Loss: 14052083.000000\n",
      "Train Epoch: 114 [672/918 (73%)] Loss: 13638605.000000\n",
      "Train Epoch: 114 [688/918 (75%)] Loss: 8487698.000000\n",
      "Train Epoch: 114 [704/918 (77%)] Loss: 7678807.500000\n",
      "Train Epoch: 114 [720/918 (78%)] Loss: 12664158.000000\n",
      "Train Epoch: 114 [736/918 (80%)] Loss: 7884323.500000\n",
      "Train Epoch: 114 [752/918 (82%)] Loss: 8352113.000000\n",
      "Train Epoch: 114 [768/918 (84%)] Loss: 8035482.500000\n",
      "Train Epoch: 114 [784/918 (85%)] Loss: 9561503.000000\n",
      "Train Epoch: 114 [800/918 (87%)] Loss: 7482860.000000\n",
      "Train Epoch: 114 [816/918 (89%)] Loss: 8640519.000000\n",
      "Train Epoch: 114 [832/918 (91%)] Loss: 10871375.000000\n",
      "Train Epoch: 114 [848/918 (92%)] Loss: 10420775.000000\n",
      "Train Epoch: 114 [864/918 (94%)] Loss: 18160262.000000\n",
      "Train Epoch: 114 [880/918 (96%)] Loss: 7037745.500000\n",
      "Train Epoch: 114 [896/918 (98%)] Loss: 10216216.000000\n",
      "Train Epoch: 114 [912/918 (99%)] Loss: 11040666.000000\n",
      "    epoch          : 114\n",
      "    loss           : 9420025.091304347\n",
      "    ess            : 7.934606392487236\n",
      "    log_marginal   : -9420021.22173913\n",
      "    val_loss       : 8894005.5\n",
      "    val_ess        : 6.875429942057683\n",
      "    val_log_marginal: -8894004.692307692\n",
      "Train Epoch: 115 [0/918 (0%)] Loss: 7832872.000000\n",
      "Train Epoch: 115 [16/918 (2%)] Loss: 8288486.500000\n",
      "Train Epoch: 115 [32/918 (3%)] Loss: 10103540.000000\n",
      "Train Epoch: 115 [48/918 (5%)] Loss: 11547584.000000\n",
      "Train Epoch: 115 [64/918 (7%)] Loss: 6421972.000000\n",
      "Train Epoch: 115 [80/918 (9%)] Loss: 6751744.000000\n",
      "Train Epoch: 115 [96/918 (10%)] Loss: 10713253.000000\n",
      "Train Epoch: 115 [112/918 (12%)] Loss: 8682786.000000\n",
      "Train Epoch: 115 [128/918 (14%)] Loss: 8294263.500000\n",
      "Train Epoch: 115 [144/918 (16%)] Loss: 10850619.000000\n",
      "Train Epoch: 115 [160/918 (17%)] Loss: 16914944.000000\n",
      "Train Epoch: 115 [176/918 (19%)] Loss: 9949019.000000\n",
      "Train Epoch: 115 [192/918 (21%)] Loss: 8061048.000000\n",
      "Train Epoch: 115 [208/918 (23%)] Loss: 8008621.500000\n",
      "Train Epoch: 115 [224/918 (24%)] Loss: 13535794.000000\n",
      "Train Epoch: 115 [240/918 (26%)] Loss: 12403658.000000\n",
      "Train Epoch: 115 [256/918 (28%)] Loss: 17809608.000000\n",
      "Train Epoch: 115 [272/918 (30%)] Loss: 7015582.500000\n",
      "Train Epoch: 115 [288/918 (31%)] Loss: 8490447.000000\n",
      "Train Epoch: 115 [304/918 (33%)] Loss: 7505497.500000\n",
      "Train Epoch: 115 [320/918 (35%)] Loss: 7360286.500000\n",
      "Train Epoch: 115 [336/918 (37%)] Loss: 9720144.000000\n",
      "Train Epoch: 115 [352/918 (38%)] Loss: 8560755.000000\n",
      "Train Epoch: 115 [368/918 (40%)] Loss: 5295378.000000\n",
      "Train Epoch: 115 [384/918 (42%)] Loss: 5757421.500000\n",
      "Train Epoch: 115 [400/918 (44%)] Loss: 9521239.000000\n",
      "Train Epoch: 115 [416/918 (45%)] Loss: 8088443.500000\n",
      "Train Epoch: 115 [432/918 (47%)] Loss: 7363006.500000\n",
      "Train Epoch: 115 [448/918 (49%)] Loss: 8717739.000000\n",
      "Train Epoch: 115 [464/918 (51%)] Loss: 8780397.000000\n",
      "Train Epoch: 115 [480/918 (52%)] Loss: 6973277.000000\n",
      "Train Epoch: 115 [496/918 (54%)] Loss: 6375318.500000\n",
      "Train Epoch: 115 [512/918 (56%)] Loss: 8900445.000000\n",
      "Train Epoch: 115 [528/918 (58%)] Loss: 11856458.000000\n",
      "Train Epoch: 115 [544/918 (59%)] Loss: 10619799.000000\n",
      "Train Epoch: 115 [560/918 (61%)] Loss: 7752455.500000\n",
      "Train Epoch: 115 [576/918 (63%)] Loss: 13896155.000000\n",
      "Train Epoch: 115 [592/918 (64%)] Loss: 10312319.000000\n",
      "Train Epoch: 115 [608/918 (66%)] Loss: 9212405.000000\n",
      "Train Epoch: 115 [624/918 (68%)] Loss: 9790509.000000\n",
      "Train Epoch: 115 [640/918 (70%)] Loss: 16520984.000000\n",
      "Train Epoch: 115 [656/918 (71%)] Loss: 10148195.000000\n",
      "Train Epoch: 115 [672/918 (73%)] Loss: 6904897.500000\n",
      "Train Epoch: 115 [688/918 (75%)] Loss: 9929498.000000\n",
      "Train Epoch: 115 [704/918 (77%)] Loss: 8607192.000000\n",
      "Train Epoch: 115 [720/918 (78%)] Loss: 15244186.000000\n",
      "Train Epoch: 115 [736/918 (80%)] Loss: 11342907.000000\n",
      "Train Epoch: 115 [752/918 (82%)] Loss: 8008876.000000\n",
      "Train Epoch: 115 [768/918 (84%)] Loss: 13000731.000000\n",
      "Train Epoch: 115 [784/918 (85%)] Loss: 6241227.500000\n",
      "Train Epoch: 115 [800/918 (87%)] Loss: 7249262.500000\n",
      "Train Epoch: 115 [816/918 (89%)] Loss: 13288134.000000\n",
      "Train Epoch: 115 [832/918 (91%)] Loss: 14205595.000000\n",
      "Train Epoch: 115 [848/918 (92%)] Loss: 8270238.500000\n",
      "Train Epoch: 115 [864/918 (94%)] Loss: 7341459.500000\n",
      "Train Epoch: 115 [880/918 (96%)] Loss: 7251301.000000\n",
      "Train Epoch: 115 [896/918 (98%)] Loss: 7212141.000000\n",
      "Train Epoch: 115 [912/918 (99%)] Loss: 13784306.000000\n",
      "    epoch          : 115\n",
      "    loss           : 9286278.617391305\n",
      "    ess            : 7.500535096292911\n",
      "    log_marginal   : -9286275.873913044\n",
      "    val_loss       : 9129634.153846154\n",
      "    val_ess        : 5.397586639110859\n",
      "    val_log_marginal: -9129632.384615384\n",
      "Train Epoch: 116 [0/918 (0%)] Loss: 11447489.000000\n",
      "Train Epoch: 116 [16/918 (2%)] Loss: 8933619.000000\n",
      "Train Epoch: 116 [32/918 (3%)] Loss: 8019811.500000\n",
      "Train Epoch: 116 [48/918 (5%)] Loss: 8713235.000000\n",
      "Train Epoch: 116 [64/918 (7%)] Loss: 11481391.000000\n",
      "Train Epoch: 116 [80/918 (9%)] Loss: 6788969.000000\n",
      "Train Epoch: 116 [96/918 (10%)] Loss: 6761373.000000\n",
      "Train Epoch: 116 [112/918 (12%)] Loss: 14163195.000000\n",
      "Train Epoch: 116 [128/918 (14%)] Loss: 10368127.000000\n",
      "Train Epoch: 116 [144/918 (16%)] Loss: 5663143.000000\n",
      "Train Epoch: 116 [160/918 (17%)] Loss: 15416178.000000\n",
      "Train Epoch: 116 [176/918 (19%)] Loss: 7703969.500000\n",
      "Train Epoch: 116 [192/918 (21%)] Loss: 7765113.500000\n",
      "Train Epoch: 116 [208/918 (23%)] Loss: 8858819.000000\n",
      "Train Epoch: 116 [224/918 (24%)] Loss: 10490394.000000\n",
      "Train Epoch: 116 [240/918 (26%)] Loss: 13300472.000000\n",
      "Train Epoch: 116 [256/918 (28%)] Loss: 6201324.500000\n",
      "Train Epoch: 116 [272/918 (30%)] Loss: 10348733.000000\n",
      "Train Epoch: 116 [288/918 (31%)] Loss: 13882634.000000\n",
      "Train Epoch: 116 [304/918 (33%)] Loss: 8073961.500000\n",
      "Train Epoch: 116 [320/918 (35%)] Loss: 9863115.000000\n",
      "Train Epoch: 116 [336/918 (37%)] Loss: 5874533.500000\n",
      "Train Epoch: 116 [352/918 (38%)] Loss: 7409389.000000\n",
      "Train Epoch: 116 [368/918 (40%)] Loss: 13751072.000000\n",
      "Train Epoch: 116 [384/918 (42%)] Loss: 6746477.000000\n",
      "Train Epoch: 116 [400/918 (44%)] Loss: 8475511.000000\n",
      "Train Epoch: 116 [416/918 (45%)] Loss: 9977842.000000\n",
      "Train Epoch: 116 [432/918 (47%)] Loss: 6383976.000000\n",
      "Train Epoch: 116 [448/918 (49%)] Loss: 11279815.000000\n",
      "Train Epoch: 116 [464/918 (51%)] Loss: 10025447.000000\n",
      "Train Epoch: 116 [480/918 (52%)] Loss: 9859840.000000\n",
      "Train Epoch: 116 [496/918 (54%)] Loss: 8101610.500000\n",
      "Train Epoch: 116 [512/918 (56%)] Loss: 11672765.000000\n",
      "Train Epoch: 116 [528/918 (58%)] Loss: 10279708.000000\n",
      "Train Epoch: 116 [544/918 (59%)] Loss: 7414828.000000\n",
      "Train Epoch: 116 [560/918 (61%)] Loss: 10039527.000000\n",
      "Train Epoch: 116 [576/918 (63%)] Loss: 15132935.000000\n",
      "Train Epoch: 116 [592/918 (64%)] Loss: 11596232.000000\n",
      "Train Epoch: 116 [608/918 (66%)] Loss: 14075626.000000\n",
      "Train Epoch: 116 [624/918 (68%)] Loss: 8528570.000000\n",
      "Train Epoch: 116 [640/918 (70%)] Loss: 9165253.000000\n",
      "Train Epoch: 116 [656/918 (71%)] Loss: 8591211.000000\n",
      "Train Epoch: 116 [672/918 (73%)] Loss: 10637151.000000\n",
      "Train Epoch: 116 [688/918 (75%)] Loss: 5649074.000000\n",
      "Train Epoch: 116 [704/918 (77%)] Loss: 6063181.500000\n",
      "Train Epoch: 116 [720/918 (78%)] Loss: 7401925.000000\n",
      "Train Epoch: 116 [736/918 (80%)] Loss: 8949839.000000\n",
      "Train Epoch: 116 [752/918 (82%)] Loss: 7932630.500000\n",
      "Train Epoch: 116 [768/918 (84%)] Loss: 9215683.000000\n",
      "Train Epoch: 116 [784/918 (85%)] Loss: 8934019.000000\n",
      "Train Epoch: 116 [800/918 (87%)] Loss: 6874798.500000\n",
      "Train Epoch: 116 [816/918 (89%)] Loss: 8419869.000000\n",
      "Train Epoch: 116 [832/918 (91%)] Loss: 8100075.500000\n",
      "Train Epoch: 116 [848/918 (92%)] Loss: 10542619.000000\n",
      "Train Epoch: 116 [864/918 (94%)] Loss: 9522859.000000\n",
      "Train Epoch: 116 [880/918 (96%)] Loss: 8822343.000000\n",
      "Train Epoch: 116 [896/918 (98%)] Loss: 13394788.000000\n",
      "Train Epoch: 116 [912/918 (99%)] Loss: 5524594.000000\n",
      "    epoch          : 116\n",
      "    loss           : 9377656.926086957\n",
      "    ess            : 7.585324028263921\n",
      "    log_marginal   : -9377654.7\n",
      "    val_loss       : 9946578.115384616\n",
      "    val_ess        : 9.084418791991014\n",
      "    val_log_marginal: -9946573.884615384\n",
      "Train Epoch: 117 [0/918 (0%)] Loss: 13837755.000000\n",
      "Train Epoch: 117 [16/918 (2%)] Loss: 18667168.000000\n",
      "Train Epoch: 117 [32/918 (3%)] Loss: 9911381.000000\n",
      "Train Epoch: 117 [48/918 (5%)] Loss: 8299390.500000\n",
      "Train Epoch: 117 [64/918 (7%)] Loss: 17317838.000000\n",
      "Train Epoch: 117 [80/918 (9%)] Loss: 7677469.000000\n",
      "Train Epoch: 117 [96/918 (10%)] Loss: 10759799.000000\n",
      "Train Epoch: 117 [112/918 (12%)] Loss: 12217363.000000\n",
      "Train Epoch: 117 [128/918 (14%)] Loss: 7569325.000000\n",
      "Train Epoch: 117 [144/918 (16%)] Loss: 8277025.000000\n",
      "Train Epoch: 117 [160/918 (17%)] Loss: 6980460.000000\n",
      "Train Epoch: 117 [176/918 (19%)] Loss: 11259265.000000\n",
      "Train Epoch: 117 [192/918 (21%)] Loss: 13724627.000000\n",
      "Train Epoch: 117 [208/918 (23%)] Loss: 8675883.000000\n",
      "Train Epoch: 117 [224/918 (24%)] Loss: 8462026.000000\n",
      "Train Epoch: 117 [240/918 (26%)] Loss: 8025644.000000\n",
      "Train Epoch: 117 [256/918 (28%)] Loss: 10883031.000000\n",
      "Train Epoch: 117 [272/918 (30%)] Loss: 7733390.500000\n",
      "Train Epoch: 117 [288/918 (31%)] Loss: 11981901.000000\n",
      "Train Epoch: 117 [304/918 (33%)] Loss: 6317714.500000\n",
      "Train Epoch: 117 [320/918 (35%)] Loss: 5564296.500000\n",
      "Train Epoch: 117 [336/918 (37%)] Loss: 11454357.000000\n",
      "Train Epoch: 117 [352/918 (38%)] Loss: 13896639.000000\n",
      "Train Epoch: 117 [368/918 (40%)] Loss: 6841801.000000\n",
      "Train Epoch: 117 [384/918 (42%)] Loss: 9768989.000000\n",
      "Train Epoch: 117 [400/918 (44%)] Loss: 8989006.000000\n",
      "Train Epoch: 117 [416/918 (45%)] Loss: 5396948.000000\n",
      "Train Epoch: 117 [432/918 (47%)] Loss: 8903840.000000\n",
      "Train Epoch: 117 [448/918 (49%)] Loss: 8331957.000000\n",
      "Train Epoch: 117 [464/918 (51%)] Loss: 8081581.000000\n",
      "Train Epoch: 117 [480/918 (52%)] Loss: 8638816.000000\n",
      "Train Epoch: 117 [496/918 (54%)] Loss: 9477708.000000\n",
      "Train Epoch: 117 [512/918 (56%)] Loss: 7476741.000000\n",
      "Train Epoch: 117 [528/918 (58%)] Loss: 9518195.000000\n",
      "Train Epoch: 117 [544/918 (59%)] Loss: 8529480.000000\n",
      "Train Epoch: 117 [560/918 (61%)] Loss: 6925889.000000\n",
      "Train Epoch: 117 [576/918 (63%)] Loss: 14454547.000000\n",
      "Train Epoch: 117 [592/918 (64%)] Loss: 5943293.000000\n",
      "Train Epoch: 117 [608/918 (66%)] Loss: 7808134.500000\n",
      "Train Epoch: 117 [624/918 (68%)] Loss: 10326229.000000\n",
      "Train Epoch: 117 [640/918 (70%)] Loss: 11182053.000000\n",
      "Train Epoch: 117 [656/918 (71%)] Loss: 8832210.000000\n",
      "Train Epoch: 117 [672/918 (73%)] Loss: 7147577.500000\n",
      "Train Epoch: 117 [688/918 (75%)] Loss: 14204533.000000\n",
      "Train Epoch: 117 [704/918 (77%)] Loss: 9158632.000000\n",
      "Train Epoch: 117 [720/918 (78%)] Loss: 5615452.000000\n",
      "Train Epoch: 117 [736/918 (80%)] Loss: 10236874.000000\n",
      "Train Epoch: 117 [752/918 (82%)] Loss: 5734718.000000\n",
      "Train Epoch: 117 [768/918 (84%)] Loss: 9796109.000000\n",
      "Train Epoch: 117 [784/918 (85%)] Loss: 7198929.500000\n",
      "Train Epoch: 117 [800/918 (87%)] Loss: 17488742.000000\n",
      "Train Epoch: 117 [816/918 (89%)] Loss: 8476951.000000\n",
      "Train Epoch: 117 [832/918 (91%)] Loss: 7229366.500000\n",
      "Train Epoch: 117 [848/918 (92%)] Loss: 9588925.000000\n",
      "Train Epoch: 117 [864/918 (94%)] Loss: 11217599.000000\n",
      "Train Epoch: 117 [880/918 (96%)] Loss: 7557937.500000\n",
      "Train Epoch: 117 [896/918 (98%)] Loss: 9396956.000000\n",
      "Train Epoch: 117 [912/918 (99%)] Loss: 8429460.000000\n",
      "    epoch          : 117\n",
      "    loss           : 9494264.665217392\n",
      "    ess            : 8.049928236007691\n",
      "    log_marginal   : -9494262.8\n",
      "    val_loss       : 9240100.23076923\n",
      "    val_ess        : 7.979106187820435\n",
      "    val_log_marginal: -9240098.076923076\n",
      "Train Epoch: 118 [0/918 (0%)] Loss: 12371925.000000\n",
      "Train Epoch: 118 [16/918 (2%)] Loss: 9810855.000000\n",
      "Train Epoch: 118 [32/918 (3%)] Loss: 9721730.000000\n",
      "Train Epoch: 118 [48/918 (5%)] Loss: 13148915.000000\n",
      "Train Epoch: 118 [64/918 (7%)] Loss: 8877720.000000\n",
      "Train Epoch: 118 [80/918 (9%)] Loss: 11577212.000000\n",
      "Train Epoch: 118 [96/918 (10%)] Loss: 7992555.500000\n",
      "Train Epoch: 118 [112/918 (12%)] Loss: 7588258.500000\n",
      "Train Epoch: 118 [128/918 (14%)] Loss: 7548034.500000\n",
      "Train Epoch: 118 [144/918 (16%)] Loss: 5938685.500000\n",
      "Train Epoch: 118 [160/918 (17%)] Loss: 7293654.500000\n",
      "Train Epoch: 118 [176/918 (19%)] Loss: 7505400.000000\n",
      "Train Epoch: 118 [192/918 (21%)] Loss: 9576103.000000\n",
      "Train Epoch: 118 [208/918 (23%)] Loss: 9994964.000000\n",
      "Train Epoch: 118 [224/918 (24%)] Loss: 8588546.000000\n",
      "Train Epoch: 118 [240/918 (26%)] Loss: 9730376.000000\n",
      "Train Epoch: 118 [256/918 (28%)] Loss: 13452352.000000\n",
      "Train Epoch: 118 [272/918 (30%)] Loss: 8592827.000000\n",
      "Train Epoch: 118 [288/918 (31%)] Loss: 10087204.000000\n",
      "Train Epoch: 118 [304/918 (33%)] Loss: 7338635.500000\n",
      "Train Epoch: 118 [320/918 (35%)] Loss: 9036936.000000\n",
      "Train Epoch: 118 [336/918 (37%)] Loss: 10388407.000000\n",
      "Train Epoch: 118 [352/918 (38%)] Loss: 7914177.500000\n",
      "Train Epoch: 118 [368/918 (40%)] Loss: 9408343.000000\n",
      "Train Epoch: 118 [384/918 (42%)] Loss: 7043783.500000\n",
      "Train Epoch: 118 [400/918 (44%)] Loss: 9379402.000000\n",
      "Train Epoch: 118 [416/918 (45%)] Loss: 16563984.000000\n",
      "Train Epoch: 118 [432/918 (47%)] Loss: 10756591.000000\n",
      "Train Epoch: 118 [448/918 (49%)] Loss: 7930079.500000\n",
      "Train Epoch: 118 [464/918 (51%)] Loss: 12565412.000000\n",
      "Train Epoch: 118 [480/918 (52%)] Loss: 6733845.000000\n",
      "Train Epoch: 118 [496/918 (54%)] Loss: 7487896.000000\n",
      "Train Epoch: 118 [512/918 (56%)] Loss: 9558124.000000\n",
      "Train Epoch: 118 [528/918 (58%)] Loss: 7693491.500000\n",
      "Train Epoch: 118 [544/918 (59%)] Loss: 11339604.000000\n",
      "Train Epoch: 118 [560/918 (61%)] Loss: 17941726.000000\n",
      "Train Epoch: 118 [576/918 (63%)] Loss: 14711808.000000\n",
      "Train Epoch: 118 [592/918 (64%)] Loss: 11486061.000000\n",
      "Train Epoch: 118 [608/918 (66%)] Loss: 9909198.000000\n",
      "Train Epoch: 118 [624/918 (68%)] Loss: 11296415.000000\n",
      "Train Epoch: 118 [640/918 (70%)] Loss: 7884490.500000\n",
      "Train Epoch: 118 [656/918 (71%)] Loss: 6496565.500000\n",
      "Train Epoch: 118 [672/918 (73%)] Loss: 8567933.000000\n",
      "Train Epoch: 118 [688/918 (75%)] Loss: 7700083.500000\n",
      "Train Epoch: 118 [704/918 (77%)] Loss: 10063996.000000\n",
      "Train Epoch: 118 [720/918 (78%)] Loss: 9726848.000000\n",
      "Train Epoch: 118 [736/918 (80%)] Loss: 10145707.000000\n",
      "Train Epoch: 118 [752/918 (82%)] Loss: 10731329.000000\n",
      "Train Epoch: 118 [768/918 (84%)] Loss: 9207594.000000\n",
      "Train Epoch: 118 [784/918 (85%)] Loss: 10018549.000000\n",
      "Train Epoch: 118 [800/918 (87%)] Loss: 7046078.500000\n",
      "Train Epoch: 118 [816/918 (89%)] Loss: 6835577.500000\n",
      "Train Epoch: 118 [832/918 (91%)] Loss: 8503067.000000\n",
      "Train Epoch: 118 [848/918 (92%)] Loss: 6615321.500000\n",
      "Train Epoch: 118 [864/918 (94%)] Loss: 10207887.000000\n",
      "Train Epoch: 118 [880/918 (96%)] Loss: 6575617.000000\n",
      "Train Epoch: 118 [896/918 (98%)] Loss: 12748514.000000\n",
      "Train Epoch: 118 [912/918 (99%)] Loss: 9952730.000000\n",
      "    epoch          : 118\n",
      "    loss           : 9729847.773913043\n",
      "    ess            : 7.958728227408036\n",
      "    log_marginal   : -9729845.569565218\n",
      "    val_loss       : 9932415.73076923\n",
      "    val_ess        : 6.394128946157602\n",
      "    val_log_marginal: -9932414.26923077\n",
      "Train Epoch: 119 [0/918 (0%)] Loss: 6394789.500000\n",
      "Train Epoch: 119 [16/918 (2%)] Loss: 5925248.000000\n",
      "Train Epoch: 119 [32/918 (3%)] Loss: 11928639.000000\n",
      "Train Epoch: 119 [48/918 (5%)] Loss: 10417672.000000\n",
      "Train Epoch: 119 [64/918 (7%)] Loss: 8197472.000000\n",
      "Train Epoch: 119 [80/918 (9%)] Loss: 10454669.000000\n",
      "Train Epoch: 119 [96/918 (10%)] Loss: 15668290.000000\n",
      "Train Epoch: 119 [112/918 (12%)] Loss: 8447954.000000\n",
      "Train Epoch: 119 [128/918 (14%)] Loss: 7626065.500000\n",
      "Train Epoch: 119 [144/918 (16%)] Loss: 7904833.500000\n",
      "Train Epoch: 119 [160/918 (17%)] Loss: 16329323.000000\n",
      "Train Epoch: 119 [176/918 (19%)] Loss: 10752512.000000\n",
      "Train Epoch: 119 [192/918 (21%)] Loss: 9994083.000000\n",
      "Train Epoch: 119 [208/918 (23%)] Loss: 9377967.000000\n",
      "Train Epoch: 119 [224/918 (24%)] Loss: 8240779.500000\n",
      "Train Epoch: 119 [240/918 (26%)] Loss: 10701922.000000\n",
      "Train Epoch: 119 [256/918 (28%)] Loss: 12015923.000000\n",
      "Train Epoch: 119 [272/918 (30%)] Loss: 9574989.000000\n",
      "Train Epoch: 119 [288/918 (31%)] Loss: 6632574.500000\n",
      "Train Epoch: 119 [304/918 (33%)] Loss: 10638586.000000\n",
      "Train Epoch: 119 [320/918 (35%)] Loss: 6797041.500000\n",
      "Train Epoch: 119 [336/918 (37%)] Loss: 14074883.000000\n",
      "Train Epoch: 119 [352/918 (38%)] Loss: 13078761.000000\n",
      "Train Epoch: 119 [368/918 (40%)] Loss: 12002345.000000\n",
      "Train Epoch: 119 [384/918 (42%)] Loss: 9840469.000000\n",
      "Train Epoch: 119 [400/918 (44%)] Loss: 10438047.000000\n",
      "Train Epoch: 119 [416/918 (45%)] Loss: 6056064.500000\n",
      "Train Epoch: 119 [432/918 (47%)] Loss: 8936341.000000\n",
      "Train Epoch: 119 [448/918 (49%)] Loss: 10176916.000000\n",
      "Train Epoch: 119 [464/918 (51%)] Loss: 9333386.000000\n",
      "Train Epoch: 119 [480/918 (52%)] Loss: 9314408.000000\n",
      "Train Epoch: 119 [496/918 (54%)] Loss: 7818012.000000\n",
      "Train Epoch: 119 [512/918 (56%)] Loss: 6701968.000000\n",
      "Train Epoch: 119 [528/918 (58%)] Loss: 10111506.000000\n",
      "Train Epoch: 119 [544/918 (59%)] Loss: 9724888.000000\n",
      "Train Epoch: 119 [560/918 (61%)] Loss: 8393935.000000\n",
      "Train Epoch: 119 [576/918 (63%)] Loss: 10422584.000000\n",
      "Train Epoch: 119 [592/918 (64%)] Loss: 9925930.000000\n",
      "Train Epoch: 119 [608/918 (66%)] Loss: 9101351.000000\n",
      "Train Epoch: 119 [624/918 (68%)] Loss: 13954639.000000\n",
      "Train Epoch: 119 [640/918 (70%)] Loss: 10542100.000000\n",
      "Train Epoch: 119 [656/918 (71%)] Loss: 7695049.500000\n",
      "Train Epoch: 119 [672/918 (73%)] Loss: 6638911.000000\n",
      "Train Epoch: 119 [688/918 (75%)] Loss: 6606249.500000\n",
      "Train Epoch: 119 [704/918 (77%)] Loss: 7480254.500000\n",
      "Train Epoch: 119 [720/918 (78%)] Loss: 13608570.000000\n",
      "Train Epoch: 119 [736/918 (80%)] Loss: 6392594.000000\n",
      "Train Epoch: 119 [752/918 (82%)] Loss: 7429032.000000\n",
      "Train Epoch: 119 [768/918 (84%)] Loss: 14718848.000000\n",
      "Train Epoch: 119 [784/918 (85%)] Loss: 7044049.500000\n",
      "Train Epoch: 119 [800/918 (87%)] Loss: 4706523.000000\n",
      "Train Epoch: 119 [816/918 (89%)] Loss: 11448681.000000\n",
      "Train Epoch: 119 [832/918 (91%)] Loss: 6390789.500000\n",
      "Train Epoch: 119 [848/918 (92%)] Loss: 6875321.500000\n",
      "Train Epoch: 119 [864/918 (94%)] Loss: 15057005.000000\n",
      "Train Epoch: 119 [880/918 (96%)] Loss: 7014934.500000\n",
      "Train Epoch: 119 [896/918 (98%)] Loss: 21129606.000000\n",
      "Train Epoch: 119 [912/918 (99%)] Loss: 6459201.500000\n",
      "    epoch          : 119\n",
      "    loss           : 9341734.495652175\n",
      "    ess            : 7.5918287007705025\n",
      "    log_marginal   : -9341732.5\n",
      "    val_loss       : 9271162.192307692\n",
      "    val_ess        : 8.794033490694487\n",
      "    val_log_marginal: -9271160.384615384\n",
      "Train Epoch: 120 [0/918 (0%)] Loss: 12785250.000000\n",
      "Train Epoch: 120 [16/918 (2%)] Loss: 8377029.000000\n",
      "Train Epoch: 120 [32/918 (3%)] Loss: 10159515.000000\n",
      "Train Epoch: 120 [48/918 (5%)] Loss: 13927418.000000\n",
      "Train Epoch: 120 [64/918 (7%)] Loss: 9571987.000000\n",
      "Train Epoch: 120 [80/918 (9%)] Loss: 8169894.500000\n",
      "Train Epoch: 120 [96/918 (10%)] Loss: 7792046.500000\n",
      "Train Epoch: 120 [112/918 (12%)] Loss: 7479373.500000\n",
      "Train Epoch: 120 [128/918 (14%)] Loss: 17862128.000000\n",
      "Train Epoch: 120 [144/918 (16%)] Loss: 7123065.500000\n",
      "Train Epoch: 120 [160/918 (17%)] Loss: 5286036.000000\n",
      "Train Epoch: 120 [176/918 (19%)] Loss: 8876957.000000\n",
      "Train Epoch: 120 [192/918 (21%)] Loss: 9802326.000000\n",
      "Train Epoch: 120 [208/918 (23%)] Loss: 7341025.500000\n",
      "Train Epoch: 120 [224/918 (24%)] Loss: 5604908.000000\n",
      "Train Epoch: 120 [240/918 (26%)] Loss: 10087338.000000\n",
      "Train Epoch: 120 [256/918 (28%)] Loss: 13879514.000000\n",
      "Train Epoch: 120 [272/918 (30%)] Loss: 10157096.000000\n",
      "Train Epoch: 120 [288/918 (31%)] Loss: 7024585.500000\n",
      "Train Epoch: 120 [304/918 (33%)] Loss: 9421988.000000\n",
      "Train Epoch: 120 [320/918 (35%)] Loss: 8182613.000000\n",
      "Train Epoch: 120 [336/918 (37%)] Loss: 8900367.000000\n",
      "Train Epoch: 120 [352/918 (38%)] Loss: 10655924.000000\n",
      "Train Epoch: 120 [368/918 (40%)] Loss: 12858959.000000\n",
      "Train Epoch: 120 [384/918 (42%)] Loss: 8077232.000000\n",
      "Train Epoch: 120 [400/918 (44%)] Loss: 8022230.500000\n",
      "Train Epoch: 120 [416/918 (45%)] Loss: 8108192.000000\n",
      "Train Epoch: 120 [432/918 (47%)] Loss: 9523955.000000\n",
      "Train Epoch: 120 [448/918 (49%)] Loss: 8326598.500000\n",
      "Train Epoch: 120 [464/918 (51%)] Loss: 7687976.000000\n",
      "Train Epoch: 120 [480/918 (52%)] Loss: 11966045.000000\n",
      "Train Epoch: 120 [496/918 (54%)] Loss: 10331356.000000\n",
      "Train Epoch: 120 [512/918 (56%)] Loss: 7696219.500000\n",
      "Train Epoch: 120 [528/918 (58%)] Loss: 17838622.000000\n",
      "Train Epoch: 120 [544/918 (59%)] Loss: 9556520.000000\n",
      "Train Epoch: 120 [560/918 (61%)] Loss: 9776173.000000\n",
      "Train Epoch: 120 [576/918 (63%)] Loss: 8510738.000000\n",
      "Train Epoch: 120 [592/918 (64%)] Loss: 8071749.500000\n",
      "Train Epoch: 120 [608/918 (66%)] Loss: 8106096.000000\n",
      "Train Epoch: 120 [624/918 (68%)] Loss: 15000344.000000\n",
      "Train Epoch: 120 [640/918 (70%)] Loss: 10179917.000000\n",
      "Train Epoch: 120 [656/918 (71%)] Loss: 12948464.000000\n",
      "Train Epoch: 120 [672/918 (73%)] Loss: 9138940.000000\n",
      "Train Epoch: 120 [688/918 (75%)] Loss: 11079130.000000\n",
      "Train Epoch: 120 [704/918 (77%)] Loss: 10528874.000000\n",
      "Train Epoch: 120 [720/918 (78%)] Loss: 9673571.000000\n",
      "Train Epoch: 120 [736/918 (80%)] Loss: 7539592.000000\n",
      "Train Epoch: 120 [752/918 (82%)] Loss: 10977135.000000\n",
      "Train Epoch: 120 [768/918 (84%)] Loss: 6875448.000000\n",
      "Train Epoch: 120 [784/918 (85%)] Loss: 10284487.000000\n",
      "Train Epoch: 120 [800/918 (87%)] Loss: 8509779.000000\n",
      "Train Epoch: 120 [816/918 (89%)] Loss: 10582567.000000\n",
      "Train Epoch: 120 [832/918 (91%)] Loss: 6830309.500000\n",
      "Train Epoch: 120 [848/918 (92%)] Loss: 9009863.000000\n",
      "Train Epoch: 120 [864/918 (94%)] Loss: 9137367.000000\n",
      "Train Epoch: 120 [880/918 (96%)] Loss: 11474278.000000\n",
      "Train Epoch: 120 [896/918 (98%)] Loss: 8978194.000000\n",
      "Train Epoch: 120 [912/918 (99%)] Loss: 10654951.000000\n",
      "    epoch          : 120\n",
      "    loss           : 9619366.530434782\n",
      "    ess            : 8.142866812581602\n",
      "    log_marginal   : -9619364.282608695\n",
      "    val_loss       : 9049807.0\n",
      "    val_ess        : 7.581191796522874\n",
      "    val_log_marginal: -9049805.192307692\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch120.pth ...\n",
      "Train Epoch: 121 [0/918 (0%)] Loss: 7057902.500000\n",
      "Train Epoch: 121 [16/918 (2%)] Loss: 9131058.000000\n",
      "Train Epoch: 121 [32/918 (3%)] Loss: 8946392.000000\n",
      "Train Epoch: 121 [48/918 (5%)] Loss: 11848269.000000\n",
      "Train Epoch: 121 [64/918 (7%)] Loss: 7170385.500000\n",
      "Train Epoch: 121 [80/918 (9%)] Loss: 9542926.000000\n",
      "Train Epoch: 121 [96/918 (10%)] Loss: 8842735.000000\n",
      "Train Epoch: 121 [112/918 (12%)] Loss: 16630189.000000\n",
      "Train Epoch: 121 [128/918 (14%)] Loss: 7173296.000000\n",
      "Train Epoch: 121 [144/918 (16%)] Loss: 5393046.500000\n",
      "Train Epoch: 121 [160/918 (17%)] Loss: 8204747.500000\n",
      "Train Epoch: 121 [176/918 (19%)] Loss: 8106761.500000\n",
      "Train Epoch: 121 [192/918 (21%)] Loss: 7634343.500000\n",
      "Train Epoch: 121 [208/918 (23%)] Loss: 11994270.000000\n",
      "Train Epoch: 121 [224/918 (24%)] Loss: 10076609.000000\n",
      "Train Epoch: 121 [240/918 (26%)] Loss: 4505184.000000\n",
      "Train Epoch: 121 [256/918 (28%)] Loss: 7812340.000000\n",
      "Train Epoch: 121 [272/918 (30%)] Loss: 9676164.000000\n",
      "Train Epoch: 121 [288/918 (31%)] Loss: 7093437.500000\n",
      "Train Epoch: 121 [304/918 (33%)] Loss: 9064047.000000\n",
      "Train Epoch: 121 [320/918 (35%)] Loss: 16296522.000000\n",
      "Train Epoch: 121 [336/918 (37%)] Loss: 9903937.000000\n",
      "Train Epoch: 121 [352/918 (38%)] Loss: 8314486.500000\n",
      "Train Epoch: 121 [368/918 (40%)] Loss: 6723621.500000\n",
      "Train Epoch: 121 [384/918 (42%)] Loss: 8223338.500000\n",
      "Train Epoch: 121 [400/918 (44%)] Loss: 9992156.000000\n",
      "Train Epoch: 121 [416/918 (45%)] Loss: 8351296.000000\n",
      "Train Epoch: 121 [432/918 (47%)] Loss: 8598837.000000\n",
      "Train Epoch: 121 [448/918 (49%)] Loss: 10264578.000000\n",
      "Train Epoch: 121 [464/918 (51%)] Loss: 7588720.000000\n",
      "Train Epoch: 121 [480/918 (52%)] Loss: 9027463.000000\n",
      "Train Epoch: 121 [496/918 (54%)] Loss: 9922023.000000\n",
      "Train Epoch: 121 [512/918 (56%)] Loss: 8562605.000000\n",
      "Train Epoch: 121 [528/918 (58%)] Loss: 7672628.000000\n",
      "Train Epoch: 121 [544/918 (59%)] Loss: 12409136.000000\n",
      "Train Epoch: 121 [560/918 (61%)] Loss: 6387432.000000\n",
      "Train Epoch: 121 [576/918 (63%)] Loss: 10265472.000000\n",
      "Train Epoch: 121 [592/918 (64%)] Loss: 7146945.500000\n",
      "Train Epoch: 121 [608/918 (66%)] Loss: 7912221.000000\n",
      "Train Epoch: 121 [624/918 (68%)] Loss: 6715625.000000\n",
      "Train Epoch: 121 [640/918 (70%)] Loss: 11569026.000000\n",
      "Train Epoch: 121 [656/918 (71%)] Loss: 6902599.500000\n",
      "Train Epoch: 121 [672/918 (73%)] Loss: 19857918.000000\n",
      "Train Epoch: 121 [688/918 (75%)] Loss: 10278074.000000\n",
      "Train Epoch: 121 [704/918 (77%)] Loss: 6171540.000000\n",
      "Train Epoch: 121 [720/918 (78%)] Loss: 6676905.500000\n",
      "Train Epoch: 121 [736/918 (80%)] Loss: 14760416.000000\n",
      "Train Epoch: 121 [752/918 (82%)] Loss: 12312476.000000\n",
      "Train Epoch: 121 [768/918 (84%)] Loss: 12121874.000000\n",
      "Train Epoch: 121 [784/918 (85%)] Loss: 7843224.000000\n",
      "Train Epoch: 121 [800/918 (87%)] Loss: 7317048.000000\n",
      "Train Epoch: 121 [816/918 (89%)] Loss: 8551655.000000\n",
      "Train Epoch: 121 [832/918 (91%)] Loss: 6952457.000000\n",
      "Train Epoch: 121 [848/918 (92%)] Loss: 12488883.000000\n",
      "Train Epoch: 121 [864/918 (94%)] Loss: 7162136.000000\n",
      "Train Epoch: 121 [880/918 (96%)] Loss: 7285661.500000\n",
      "Train Epoch: 121 [896/918 (98%)] Loss: 6253487.000000\n",
      "Train Epoch: 121 [912/918 (99%)] Loss: 5040237.000000\n",
      "    epoch          : 121\n",
      "    loss           : 9339987.286956523\n",
      "    ess            : 7.55177435460298\n",
      "    log_marginal   : -9339985.308695652\n",
      "    val_loss       : 9359803.846153846\n",
      "    val_ess        : 8.136014058039738\n",
      "    val_log_marginal: -9359802.26923077\n",
      "Train Epoch: 122 [0/918 (0%)] Loss: 5253888.000000\n",
      "Train Epoch: 122 [16/918 (2%)] Loss: 13563642.000000\n",
      "Train Epoch: 122 [32/918 (3%)] Loss: 7393533.000000\n",
      "Train Epoch: 122 [48/918 (5%)] Loss: 9032485.000000\n",
      "Train Epoch: 122 [64/918 (7%)] Loss: 16835026.000000\n",
      "Train Epoch: 122 [80/918 (9%)] Loss: 7723891.500000\n",
      "Train Epoch: 122 [96/918 (10%)] Loss: 7481177.500000\n",
      "Train Epoch: 122 [112/918 (12%)] Loss: 7529949.000000\n",
      "Train Epoch: 122 [128/918 (14%)] Loss: 7876262.500000\n",
      "Train Epoch: 122 [144/918 (16%)] Loss: 10106829.000000\n",
      "Train Epoch: 122 [160/918 (17%)] Loss: 7527321.500000\n",
      "Train Epoch: 122 [176/918 (19%)] Loss: 9338291.000000\n",
      "Train Epoch: 122 [192/918 (21%)] Loss: 7994953.500000\n",
      "Train Epoch: 122 [208/918 (23%)] Loss: 13954736.000000\n",
      "Train Epoch: 122 [224/918 (24%)] Loss: 7872289.500000\n",
      "Train Epoch: 122 [240/918 (26%)] Loss: 6623963.500000\n",
      "Train Epoch: 122 [256/918 (28%)] Loss: 8148372.000000\n",
      "Train Epoch: 122 [272/918 (30%)] Loss: 13818455.000000\n",
      "Train Epoch: 122 [288/918 (31%)] Loss: 5756816.000000\n",
      "Train Epoch: 122 [304/918 (33%)] Loss: 7943261.000000\n",
      "Train Epoch: 122 [320/918 (35%)] Loss: 5843917.500000\n",
      "Train Epoch: 122 [336/918 (37%)] Loss: 5582032.000000\n",
      "Train Epoch: 122 [352/918 (38%)] Loss: 6690860.000000\n",
      "Train Epoch: 122 [368/918 (40%)] Loss: 13373120.000000\n",
      "Train Epoch: 122 [384/918 (42%)] Loss: 9532626.000000\n",
      "Train Epoch: 122 [400/918 (44%)] Loss: 8118897.000000\n",
      "Train Epoch: 122 [416/918 (45%)] Loss: 8464120.000000\n",
      "Train Epoch: 122 [432/918 (47%)] Loss: 9119762.000000\n",
      "Train Epoch: 122 [448/918 (49%)] Loss: 7554494.500000\n",
      "Train Epoch: 122 [464/918 (51%)] Loss: 12489307.000000\n",
      "Train Epoch: 122 [480/918 (52%)] Loss: 8644526.000000\n",
      "Train Epoch: 122 [496/918 (54%)] Loss: 8570051.000000\n",
      "Train Epoch: 122 [512/918 (56%)] Loss: 8893208.000000\n",
      "Train Epoch: 122 [528/918 (58%)] Loss: 9055339.000000\n",
      "Train Epoch: 122 [544/918 (59%)] Loss: 8936500.000000\n",
      "Train Epoch: 122 [560/918 (61%)] Loss: 10203629.000000\n",
      "Train Epoch: 122 [576/918 (63%)] Loss: 7714130.500000\n",
      "Train Epoch: 122 [592/918 (64%)] Loss: 8989327.000000\n",
      "Train Epoch: 122 [608/918 (66%)] Loss: 12329925.000000\n",
      "Train Epoch: 122 [624/918 (68%)] Loss: 11858108.000000\n",
      "Train Epoch: 122 [640/918 (70%)] Loss: 12017585.000000\n",
      "Train Epoch: 122 [656/918 (71%)] Loss: 6642099.000000\n",
      "Train Epoch: 122 [672/918 (73%)] Loss: 9018151.000000\n",
      "Train Epoch: 122 [688/918 (75%)] Loss: 7830597.000000\n",
      "Train Epoch: 122 [704/918 (77%)] Loss: 8522805.000000\n",
      "Train Epoch: 122 [720/918 (78%)] Loss: 5692989.000000\n",
      "Train Epoch: 122 [736/918 (80%)] Loss: 11206082.000000\n",
      "Train Epoch: 122 [752/918 (82%)] Loss: 9275290.000000\n",
      "Train Epoch: 122 [768/918 (84%)] Loss: 11841544.000000\n",
      "Train Epoch: 122 [784/918 (85%)] Loss: 6719177.000000\n",
      "Train Epoch: 122 [800/918 (87%)] Loss: 12845645.000000\n",
      "Train Epoch: 122 [816/918 (89%)] Loss: 9475611.000000\n",
      "Train Epoch: 122 [832/918 (91%)] Loss: 9793752.000000\n",
      "Train Epoch: 122 [848/918 (92%)] Loss: 11750533.000000\n",
      "Train Epoch: 122 [864/918 (94%)] Loss: 6628858.500000\n",
      "Train Epoch: 122 [880/918 (96%)] Loss: 5880737.500000\n",
      "Train Epoch: 122 [896/918 (98%)] Loss: 9375951.000000\n",
      "Train Epoch: 122 [912/918 (99%)] Loss: 9720673.000000\n",
      "    epoch          : 122\n",
      "    loss           : 9219450.710869566\n",
      "    ess            : 7.350289402837339\n",
      "    log_marginal   : -9219448.77826087\n",
      "    val_loss       : 8660214.384615384\n",
      "    val_ess        : 7.677371593622061\n",
      "    val_log_marginal: -8660211.346153846\n",
      "Train Epoch: 123 [0/918 (0%)] Loss: 8845199.000000\n",
      "Train Epoch: 123 [16/918 (2%)] Loss: 12889295.000000\n",
      "Train Epoch: 123 [32/918 (3%)] Loss: 8543362.000000\n",
      "Train Epoch: 123 [48/918 (5%)] Loss: 12019800.000000\n",
      "Train Epoch: 123 [64/918 (7%)] Loss: 8863765.000000\n",
      "Train Epoch: 123 [80/918 (9%)] Loss: 5685590.000000\n",
      "Train Epoch: 123 [96/918 (10%)] Loss: 13583715.000000\n",
      "Train Epoch: 123 [112/918 (12%)] Loss: 10236532.000000\n",
      "Train Epoch: 123 [128/918 (14%)] Loss: 7112245.000000\n",
      "Train Epoch: 123 [144/918 (16%)] Loss: 7450529.500000\n",
      "Train Epoch: 123 [160/918 (17%)] Loss: 10130077.000000\n",
      "Train Epoch: 123 [176/918 (19%)] Loss: 8871331.000000\n",
      "Train Epoch: 123 [192/918 (21%)] Loss: 6935414.500000\n",
      "Train Epoch: 123 [208/918 (23%)] Loss: 6762445.000000\n",
      "Train Epoch: 123 [224/918 (24%)] Loss: 7992601.500000\n",
      "Train Epoch: 123 [240/918 (26%)] Loss: 9188341.000000\n",
      "Train Epoch: 123 [256/918 (28%)] Loss: 9915286.000000\n",
      "Train Epoch: 123 [272/918 (30%)] Loss: 6346881.500000\n",
      "Train Epoch: 123 [288/918 (31%)] Loss: 15297783.000000\n",
      "Train Epoch: 123 [304/918 (33%)] Loss: 8815948.000000\n",
      "Train Epoch: 123 [320/918 (35%)] Loss: 11130000.000000\n",
      "Train Epoch: 123 [336/918 (37%)] Loss: 11150436.000000\n",
      "Train Epoch: 123 [352/918 (38%)] Loss: 13895712.000000\n",
      "Train Epoch: 123 [368/918 (40%)] Loss: 13637847.000000\n",
      "Train Epoch: 123 [384/918 (42%)] Loss: 7238706.500000\n",
      "Train Epoch: 123 [400/918 (44%)] Loss: 9541130.000000\n",
      "Train Epoch: 123 [416/918 (45%)] Loss: 9230078.000000\n",
      "Train Epoch: 123 [432/918 (47%)] Loss: 6677845.000000\n",
      "Train Epoch: 123 [448/918 (49%)] Loss: 13047824.000000\n",
      "Train Epoch: 123 [464/918 (51%)] Loss: 6969525.000000\n",
      "Train Epoch: 123 [480/918 (52%)] Loss: 14595466.000000\n",
      "Train Epoch: 123 [496/918 (54%)] Loss: 9440069.000000\n",
      "Train Epoch: 123 [512/918 (56%)] Loss: 11108477.000000\n",
      "Train Epoch: 123 [528/918 (58%)] Loss: 8728667.000000\n",
      "Train Epoch: 123 [544/918 (59%)] Loss: 9010224.000000\n",
      "Train Epoch: 123 [560/918 (61%)] Loss: 9892855.000000\n",
      "Train Epoch: 123 [576/918 (63%)] Loss: 12977656.000000\n",
      "Train Epoch: 123 [592/918 (64%)] Loss: 8693336.000000\n",
      "Train Epoch: 123 [608/918 (66%)] Loss: 6444963.500000\n",
      "Train Epoch: 123 [624/918 (68%)] Loss: 9573344.000000\n",
      "Train Epoch: 123 [640/918 (70%)] Loss: 8597323.000000\n",
      "Train Epoch: 123 [656/918 (71%)] Loss: 7552385.500000\n",
      "Train Epoch: 123 [672/918 (73%)] Loss: 11948858.000000\n",
      "Train Epoch: 123 [688/918 (75%)] Loss: 8389887.000000\n",
      "Train Epoch: 123 [704/918 (77%)] Loss: 11768295.000000\n",
      "Train Epoch: 123 [720/918 (78%)] Loss: 7181725.000000\n",
      "Train Epoch: 123 [736/918 (80%)] Loss: 6848815.500000\n",
      "Train Epoch: 123 [752/918 (82%)] Loss: 8122462.500000\n",
      "Train Epoch: 123 [768/918 (84%)] Loss: 8949066.000000\n",
      "Train Epoch: 123 [784/918 (85%)] Loss: 9180231.000000\n",
      "Train Epoch: 123 [800/918 (87%)] Loss: 6197985.000000\n",
      "Train Epoch: 123 [816/918 (89%)] Loss: 8160809.000000\n",
      "Train Epoch: 123 [832/918 (91%)] Loss: 11468391.000000\n",
      "Train Epoch: 123 [848/918 (92%)] Loss: 9074431.000000\n",
      "Train Epoch: 123 [864/918 (94%)] Loss: 8386508.000000\n",
      "Train Epoch: 123 [880/918 (96%)] Loss: 8233774.500000\n",
      "Train Epoch: 123 [896/918 (98%)] Loss: 11188018.000000\n",
      "Train Epoch: 123 [912/918 (99%)] Loss: 12770294.000000\n",
      "    epoch          : 123\n",
      "    loss           : 9398211.243478261\n",
      "    ess            : 8.184236941130266\n",
      "    log_marginal   : -9398207.047826087\n",
      "    val_loss       : 9457563.538461538\n",
      "    val_ess        : 9.12720848963811\n",
      "    val_log_marginal: -9457560.384615384\n",
      "Train Epoch: 124 [0/918 (0%)] Loss: 6715805.000000\n",
      "Train Epoch: 124 [16/918 (2%)] Loss: 12693952.000000\n",
      "Train Epoch: 124 [32/918 (3%)] Loss: 8462107.000000\n",
      "Train Epoch: 124 [48/918 (5%)] Loss: 12691372.000000\n",
      "Train Epoch: 124 [64/918 (7%)] Loss: 11853459.000000\n",
      "Train Epoch: 124 [80/918 (9%)] Loss: 8525178.000000\n",
      "Train Epoch: 124 [96/918 (10%)] Loss: 7455741.000000\n",
      "Train Epoch: 124 [112/918 (12%)] Loss: 8974228.000000\n",
      "Train Epoch: 124 [128/918 (14%)] Loss: 8313784.000000\n",
      "Train Epoch: 124 [144/918 (16%)] Loss: 9928746.000000\n",
      "Train Epoch: 124 [160/918 (17%)] Loss: 7427749.000000\n",
      "Train Epoch: 124 [176/918 (19%)] Loss: 15547160.000000\n",
      "Train Epoch: 124 [192/918 (21%)] Loss: 7182557.500000\n",
      "Train Epoch: 124 [208/918 (23%)] Loss: 12927735.000000\n",
      "Train Epoch: 124 [224/918 (24%)] Loss: 14492624.000000\n",
      "Train Epoch: 124 [240/918 (26%)] Loss: 12919859.000000\n",
      "Train Epoch: 124 [256/918 (28%)] Loss: 10137059.000000\n",
      "Train Epoch: 124 [272/918 (30%)] Loss: 9046250.000000\n",
      "Train Epoch: 124 [288/918 (31%)] Loss: 11636440.000000\n",
      "Train Epoch: 124 [304/918 (33%)] Loss: 11176298.000000\n",
      "Train Epoch: 124 [320/918 (35%)] Loss: 7960584.000000\n",
      "Train Epoch: 124 [336/918 (37%)] Loss: 8707861.000000\n",
      "Train Epoch: 124 [352/918 (38%)] Loss: 7273895.500000\n",
      "Train Epoch: 124 [368/918 (40%)] Loss: 12826129.000000\n",
      "Train Epoch: 124 [384/918 (42%)] Loss: 8639191.000000\n",
      "Train Epoch: 124 [400/918 (44%)] Loss: 7831217.500000\n",
      "Train Epoch: 124 [416/918 (45%)] Loss: 5829324.000000\n",
      "Train Epoch: 124 [432/918 (47%)] Loss: 5809063.500000\n",
      "Train Epoch: 124 [448/918 (49%)] Loss: 10177139.000000\n",
      "Train Epoch: 124 [464/918 (51%)] Loss: 15606464.000000\n",
      "Train Epoch: 124 [480/918 (52%)] Loss: 13719223.000000\n",
      "Train Epoch: 124 [496/918 (54%)] Loss: 8585523.000000\n",
      "Train Epoch: 124 [512/918 (56%)] Loss: 8246229.500000\n",
      "Train Epoch: 124 [528/918 (58%)] Loss: 11071359.000000\n",
      "Train Epoch: 124 [544/918 (59%)] Loss: 8060327.500000\n",
      "Train Epoch: 124 [560/918 (61%)] Loss: 10207079.000000\n",
      "Train Epoch: 124 [576/918 (63%)] Loss: 14468400.000000\n",
      "Train Epoch: 124 [592/918 (64%)] Loss: 10604259.000000\n",
      "Train Epoch: 124 [608/918 (66%)] Loss: 9258795.000000\n",
      "Train Epoch: 124 [624/918 (68%)] Loss: 9126850.000000\n",
      "Train Epoch: 124 [640/918 (70%)] Loss: 9905991.000000\n",
      "Train Epoch: 124 [656/918 (71%)] Loss: 13456829.000000\n",
      "Train Epoch: 124 [672/918 (73%)] Loss: 8623875.000000\n",
      "Train Epoch: 124 [688/918 (75%)] Loss: 5343577.000000\n",
      "Train Epoch: 124 [704/918 (77%)] Loss: 6903665.000000\n",
      "Train Epoch: 124 [720/918 (78%)] Loss: 10713232.000000\n",
      "Train Epoch: 124 [736/918 (80%)] Loss: 8564330.000000\n",
      "Train Epoch: 124 [752/918 (82%)] Loss: 9765055.000000\n",
      "Train Epoch: 124 [768/918 (84%)] Loss: 8404090.000000\n",
      "Train Epoch: 124 [784/918 (85%)] Loss: 7362525.000000\n",
      "Train Epoch: 124 [800/918 (87%)] Loss: 12797544.000000\n",
      "Train Epoch: 124 [816/918 (89%)] Loss: 5640860.000000\n",
      "Train Epoch: 124 [832/918 (91%)] Loss: 6429685.500000\n",
      "Train Epoch: 124 [848/918 (92%)] Loss: 9647824.000000\n",
      "Train Epoch: 124 [864/918 (94%)] Loss: 12333957.000000\n",
      "Train Epoch: 124 [880/918 (96%)] Loss: 12856758.000000\n",
      "Train Epoch: 124 [896/918 (98%)] Loss: 9569338.000000\n",
      "Train Epoch: 124 [912/918 (99%)] Loss: 6290650.000000\n",
      "    epoch          : 124\n",
      "    loss           : 9501275.269565217\n",
      "    ess            : 7.950988968558933\n",
      "    log_marginal   : -9501273.234782608\n",
      "    val_loss       : 8338034.576923077\n",
      "    val_ess        : 6.160717835793128\n",
      "    val_log_marginal: -8338032.192307692\n",
      "Train Epoch: 125 [0/918 (0%)] Loss: 6993035.500000\n",
      "Train Epoch: 125 [16/918 (2%)] Loss: 9202443.000000\n",
      "Train Epoch: 125 [32/918 (3%)] Loss: 7755870.500000\n",
      "Train Epoch: 125 [48/918 (5%)] Loss: 12501135.000000\n",
      "Train Epoch: 125 [64/918 (7%)] Loss: 11596527.000000\n",
      "Train Epoch: 125 [80/918 (9%)] Loss: 10246341.000000\n",
      "Train Epoch: 125 [96/918 (10%)] Loss: 12374040.000000\n",
      "Train Epoch: 125 [112/918 (12%)] Loss: 9462983.000000\n",
      "Train Epoch: 125 [128/918 (14%)] Loss: 8447365.000000\n",
      "Train Epoch: 125 [144/918 (16%)] Loss: 8844110.000000\n",
      "Train Epoch: 125 [160/918 (17%)] Loss: 11135789.000000\n",
      "Train Epoch: 125 [176/918 (19%)] Loss: 6006923.000000\n",
      "Train Epoch: 125 [192/918 (21%)] Loss: 8765752.000000\n",
      "Train Epoch: 125 [208/918 (23%)] Loss: 6578372.000000\n",
      "Train Epoch: 125 [224/918 (24%)] Loss: 8286373.000000\n",
      "Train Epoch: 125 [240/918 (26%)] Loss: 10973816.000000\n",
      "Train Epoch: 125 [256/918 (28%)] Loss: 7135833.500000\n",
      "Train Epoch: 125 [272/918 (30%)] Loss: 8605852.000000\n",
      "Train Epoch: 125 [288/918 (31%)] Loss: 5756745.500000\n",
      "Train Epoch: 125 [304/918 (33%)] Loss: 12415304.000000\n",
      "Train Epoch: 125 [320/918 (35%)] Loss: 5043244.000000\n",
      "Train Epoch: 125 [336/918 (37%)] Loss: 6284478.000000\n",
      "Train Epoch: 125 [352/918 (38%)] Loss: 8950536.000000\n",
      "Train Epoch: 125 [368/918 (40%)] Loss: 12477074.000000\n",
      "Train Epoch: 125 [384/918 (42%)] Loss: 7059454.500000\n",
      "Train Epoch: 125 [400/918 (44%)] Loss: 8298400.000000\n",
      "Train Epoch: 125 [416/918 (45%)] Loss: 8794613.000000\n",
      "Train Epoch: 125 [432/918 (47%)] Loss: 6738326.500000\n",
      "Train Epoch: 125 [448/918 (49%)] Loss: 8329023.500000\n",
      "Train Epoch: 125 [464/918 (51%)] Loss: 6533235.000000\n",
      "Train Epoch: 125 [480/918 (52%)] Loss: 8254401.500000\n",
      "Train Epoch: 125 [496/918 (54%)] Loss: 8560722.000000\n",
      "Train Epoch: 125 [512/918 (56%)] Loss: 9802591.000000\n",
      "Train Epoch: 125 [528/918 (58%)] Loss: 8624627.000000\n",
      "Train Epoch: 125 [544/918 (59%)] Loss: 9793025.000000\n",
      "Train Epoch: 125 [560/918 (61%)] Loss: 12239635.000000\n",
      "Train Epoch: 125 [576/918 (63%)] Loss: 7736145.500000\n",
      "Train Epoch: 125 [592/918 (64%)] Loss: 7385086.500000\n",
      "Train Epoch: 125 [608/918 (66%)] Loss: 8506507.000000\n",
      "Train Epoch: 125 [624/918 (68%)] Loss: 13548167.000000\n",
      "Train Epoch: 125 [640/918 (70%)] Loss: 10669319.000000\n",
      "Train Epoch: 125 [656/918 (71%)] Loss: 11212312.000000\n",
      "Train Epoch: 125 [672/918 (73%)] Loss: 7983517.500000\n",
      "Train Epoch: 125 [688/918 (75%)] Loss: 6646526.500000\n",
      "Train Epoch: 125 [704/918 (77%)] Loss: 6252988.000000\n",
      "Train Epoch: 125 [720/918 (78%)] Loss: 8354174.500000\n",
      "Train Epoch: 125 [736/918 (80%)] Loss: 6908565.000000\n",
      "Train Epoch: 125 [752/918 (82%)] Loss: 7327183.500000\n",
      "Train Epoch: 125 [768/918 (84%)] Loss: 7574829.000000\n",
      "Train Epoch: 125 [784/918 (85%)] Loss: 4464353.500000\n",
      "Train Epoch: 125 [800/918 (87%)] Loss: 10450570.000000\n",
      "Train Epoch: 125 [816/918 (89%)] Loss: 6098079.000000\n",
      "Train Epoch: 125 [832/918 (91%)] Loss: 7077439.500000\n",
      "Train Epoch: 125 [848/918 (92%)] Loss: 6993856.000000\n",
      "Train Epoch: 125 [864/918 (94%)] Loss: 7550353.500000\n",
      "Train Epoch: 125 [880/918 (96%)] Loss: 10828730.000000\n",
      "Train Epoch: 125 [896/918 (98%)] Loss: 5218907.500000\n",
      "Train Epoch: 125 [912/918 (99%)] Loss: 8852656.000000\n",
      "    epoch          : 125\n",
      "    loss           : 9351611.847826088\n",
      "    ess            : 7.818711003013279\n",
      "    log_marginal   : -9351609.895652173\n",
      "    val_loss       : 8676171.26923077\n",
      "    val_ess        : 7.0371637894557075\n",
      "    val_log_marginal: -8676169.846153846\n",
      "Train Epoch: 126 [0/918 (0%)] Loss: 11951838.000000\n",
      "Train Epoch: 126 [16/918 (2%)] Loss: 13830373.000000\n",
      "Train Epoch: 126 [32/918 (3%)] Loss: 12163570.000000\n",
      "Train Epoch: 126 [48/918 (5%)] Loss: 6540532.000000\n",
      "Train Epoch: 126 [64/918 (7%)] Loss: 10821908.000000\n",
      "Train Epoch: 126 [80/918 (9%)] Loss: 12001621.000000\n",
      "Train Epoch: 126 [96/918 (10%)] Loss: 9700986.000000\n",
      "Train Epoch: 126 [112/918 (12%)] Loss: 18031458.000000\n",
      "Train Epoch: 126 [128/918 (14%)] Loss: 11757255.000000\n",
      "Train Epoch: 126 [144/918 (16%)] Loss: 9034017.000000\n",
      "Train Epoch: 126 [160/918 (17%)] Loss: 5803213.500000\n",
      "Train Epoch: 126 [176/918 (19%)] Loss: 10069285.000000\n",
      "Train Epoch: 126 [192/918 (21%)] Loss: 8949212.000000\n",
      "Train Epoch: 126 [208/918 (23%)] Loss: 6817294.500000\n",
      "Train Epoch: 126 [224/918 (24%)] Loss: 10325490.000000\n",
      "Train Epoch: 126 [240/918 (26%)] Loss: 6614048.500000\n",
      "Train Epoch: 126 [256/918 (28%)] Loss: 7583797.000000\n",
      "Train Epoch: 126 [272/918 (30%)] Loss: 8057437.500000\n",
      "Train Epoch: 126 [288/918 (31%)] Loss: 8790307.000000\n",
      "Train Epoch: 126 [304/918 (33%)] Loss: 11776239.000000\n",
      "Train Epoch: 126 [320/918 (35%)] Loss: 8014541.500000\n",
      "Train Epoch: 126 [336/918 (37%)] Loss: 7946241.500000\n",
      "Train Epoch: 126 [352/918 (38%)] Loss: 9732672.000000\n",
      "Train Epoch: 126 [368/918 (40%)] Loss: 9185063.000000\n",
      "Train Epoch: 126 [384/918 (42%)] Loss: 10486967.000000\n",
      "Train Epoch: 126 [400/918 (44%)] Loss: 14689248.000000\n",
      "Train Epoch: 126 [416/918 (45%)] Loss: 7402208.000000\n",
      "Train Epoch: 126 [432/918 (47%)] Loss: 9351151.000000\n",
      "Train Epoch: 126 [448/918 (49%)] Loss: 8936325.000000\n",
      "Train Epoch: 126 [464/918 (51%)] Loss: 9597555.000000\n",
      "Train Epoch: 126 [480/918 (52%)] Loss: 9559410.000000\n",
      "Train Epoch: 126 [496/918 (54%)] Loss: 9136986.000000\n",
      "Train Epoch: 126 [512/918 (56%)] Loss: 9859356.000000\n",
      "Train Epoch: 126 [528/918 (58%)] Loss: 10905818.000000\n",
      "Train Epoch: 126 [544/918 (59%)] Loss: 10239920.000000\n",
      "Train Epoch: 126 [560/918 (61%)] Loss: 9510223.000000\n",
      "Train Epoch: 126 [576/918 (63%)] Loss: 10512198.000000\n",
      "Train Epoch: 126 [592/918 (64%)] Loss: 7730240.000000\n",
      "Train Epoch: 126 [608/918 (66%)] Loss: 7368422.500000\n",
      "Train Epoch: 126 [624/918 (68%)] Loss: 6875353.000000\n",
      "Train Epoch: 126 [640/918 (70%)] Loss: 8060055.500000\n",
      "Train Epoch: 126 [656/918 (71%)] Loss: 10172792.000000\n",
      "Train Epoch: 126 [672/918 (73%)] Loss: 7478645.500000\n",
      "Train Epoch: 126 [688/918 (75%)] Loss: 6985393.000000\n",
      "Train Epoch: 126 [704/918 (77%)] Loss: 8749122.000000\n",
      "Train Epoch: 126 [720/918 (78%)] Loss: 12505680.000000\n",
      "Train Epoch: 126 [736/918 (80%)] Loss: 7802777.500000\n",
      "Train Epoch: 126 [752/918 (82%)] Loss: 9866797.000000\n",
      "Train Epoch: 126 [768/918 (84%)] Loss: 14517643.000000\n",
      "Train Epoch: 126 [784/918 (85%)] Loss: 8804465.000000\n",
      "Train Epoch: 126 [800/918 (87%)] Loss: 12793385.000000\n",
      "Train Epoch: 126 [816/918 (89%)] Loss: 12645864.000000\n",
      "Train Epoch: 126 [832/918 (91%)] Loss: 7274019.500000\n",
      "Train Epoch: 126 [848/918 (92%)] Loss: 12381752.000000\n",
      "Train Epoch: 126 [864/918 (94%)] Loss: 12829064.000000\n",
      "Train Epoch: 126 [880/918 (96%)] Loss: 10856363.000000\n",
      "Train Epoch: 126 [896/918 (98%)] Loss: 9069106.000000\n",
      "Train Epoch: 126 [912/918 (99%)] Loss: 12100865.000000\n",
      "    epoch          : 126\n",
      "    loss           : 9367000.652173912\n",
      "    ess            : 8.463342164910358\n",
      "    log_marginal   : -9366997.8\n",
      "    val_loss       : 9188868.307692308\n",
      "    val_ess        : 7.836301253392146\n",
      "    val_log_marginal: -9188867.576923076\n",
      "Train Epoch: 127 [0/918 (0%)] Loss: 11362060.000000\n",
      "Train Epoch: 127 [16/918 (2%)] Loss: 6471820.000000\n",
      "Train Epoch: 127 [32/918 (3%)] Loss: 9160650.000000\n",
      "Train Epoch: 127 [48/918 (5%)] Loss: 9914443.000000\n",
      "Train Epoch: 127 [64/918 (7%)] Loss: 9806674.000000\n",
      "Train Epoch: 127 [80/918 (9%)] Loss: 9125773.000000\n",
      "Train Epoch: 127 [96/918 (10%)] Loss: 6980677.000000\n",
      "Train Epoch: 127 [112/918 (12%)] Loss: 11012299.000000\n",
      "Train Epoch: 127 [128/918 (14%)] Loss: 8194145.500000\n",
      "Train Epoch: 127 [144/918 (16%)] Loss: 8935528.000000\n",
      "Train Epoch: 127 [160/918 (17%)] Loss: 9173183.000000\n",
      "Train Epoch: 127 [176/918 (19%)] Loss: 8119113.000000\n",
      "Train Epoch: 127 [192/918 (21%)] Loss: 8183197.500000\n",
      "Train Epoch: 127 [208/918 (23%)] Loss: 7437861.000000\n",
      "Train Epoch: 127 [224/918 (24%)] Loss: 7242569.500000\n",
      "Train Epoch: 127 [240/918 (26%)] Loss: 11869741.000000\n",
      "Train Epoch: 127 [256/918 (28%)] Loss: 7895613.500000\n",
      "Train Epoch: 127 [272/918 (30%)] Loss: 7267137.500000\n",
      "Train Epoch: 127 [288/918 (31%)] Loss: 6514080.000000\n",
      "Train Epoch: 127 [304/918 (33%)] Loss: 7401709.000000\n",
      "Train Epoch: 127 [320/918 (35%)] Loss: 5242449.500000\n",
      "Train Epoch: 127 [336/918 (37%)] Loss: 11067951.000000\n",
      "Train Epoch: 127 [352/918 (38%)] Loss: 6855762.500000\n",
      "Train Epoch: 127 [368/918 (40%)] Loss: 11384493.000000\n",
      "Train Epoch: 127 [384/918 (42%)] Loss: 6881286.500000\n",
      "Train Epoch: 127 [400/918 (44%)] Loss: 8042893.500000\n",
      "Train Epoch: 127 [416/918 (45%)] Loss: 6411218.000000\n",
      "Train Epoch: 127 [432/918 (47%)] Loss: 9439482.000000\n",
      "Train Epoch: 127 [448/918 (49%)] Loss: 10989584.000000\n",
      "Train Epoch: 127 [464/918 (51%)] Loss: 10700979.000000\n",
      "Train Epoch: 127 [480/918 (52%)] Loss: 7750464.000000\n",
      "Train Epoch: 127 [496/918 (54%)] Loss: 7901433.500000\n",
      "Train Epoch: 127 [512/918 (56%)] Loss: 9894622.000000\n",
      "Train Epoch: 127 [528/918 (58%)] Loss: 9209243.000000\n",
      "Train Epoch: 127 [544/918 (59%)] Loss: 7477201.500000\n",
      "Train Epoch: 127 [560/918 (61%)] Loss: 11188887.000000\n",
      "Train Epoch: 127 [576/918 (63%)] Loss: 8406079.000000\n",
      "Train Epoch: 127 [592/918 (64%)] Loss: 6960782.500000\n",
      "Train Epoch: 127 [608/918 (66%)] Loss: 13297402.000000\n",
      "Train Epoch: 127 [624/918 (68%)] Loss: 10255063.000000\n",
      "Train Epoch: 127 [640/918 (70%)] Loss: 11744260.000000\n",
      "Train Epoch: 127 [656/918 (71%)] Loss: 7487506.500000\n",
      "Train Epoch: 127 [672/918 (73%)] Loss: 8290745.000000\n",
      "Train Epoch: 127 [688/918 (75%)] Loss: 7114350.500000\n",
      "Train Epoch: 127 [704/918 (77%)] Loss: 11056042.000000\n",
      "Train Epoch: 127 [720/918 (78%)] Loss: 10965504.000000\n",
      "Train Epoch: 127 [736/918 (80%)] Loss: 12656219.000000\n",
      "Train Epoch: 127 [752/918 (82%)] Loss: 9902121.000000\n",
      "Train Epoch: 127 [768/918 (84%)] Loss: 8346709.500000\n",
      "Train Epoch: 127 [784/918 (85%)] Loss: 8717923.000000\n",
      "Train Epoch: 127 [800/918 (87%)] Loss: 6731798.500000\n",
      "Train Epoch: 127 [816/918 (89%)] Loss: 7004252.000000\n",
      "Train Epoch: 127 [832/918 (91%)] Loss: 11169780.000000\n",
      "Train Epoch: 127 [848/918 (92%)] Loss: 13289319.000000\n",
      "Train Epoch: 127 [864/918 (94%)] Loss: 11199451.000000\n",
      "Train Epoch: 127 [880/918 (96%)] Loss: 9253959.000000\n",
      "Train Epoch: 127 [896/918 (98%)] Loss: 12119679.000000\n",
      "Train Epoch: 127 [912/918 (99%)] Loss: 6773015.000000\n",
      "    epoch          : 127\n",
      "    loss           : 9405587.817391304\n",
      "    ess            : 8.648782408755759\n",
      "    log_marginal   : -9405586.104347827\n",
      "    val_loss       : 9747264.192307692\n",
      "    val_ess        : 9.034852871528038\n",
      "    val_log_marginal: -9747261.807692308\n",
      "Train Epoch: 128 [0/918 (0%)] Loss: 8446127.000000\n",
      "Train Epoch: 128 [16/918 (2%)] Loss: 7842655.500000\n",
      "Train Epoch: 128 [32/918 (3%)] Loss: 9553523.000000\n",
      "Train Epoch: 128 [48/918 (5%)] Loss: 11331224.000000\n",
      "Train Epoch: 128 [64/918 (7%)] Loss: 8952386.000000\n",
      "Train Epoch: 128 [80/918 (9%)] Loss: 7988718.500000\n",
      "Train Epoch: 128 [96/918 (10%)] Loss: 10809327.000000\n",
      "Train Epoch: 128 [112/918 (12%)] Loss: 8259132.000000\n",
      "Train Epoch: 128 [128/918 (14%)] Loss: 6331920.500000\n",
      "Train Epoch: 128 [144/918 (16%)] Loss: 14469283.000000\n",
      "Train Epoch: 128 [160/918 (17%)] Loss: 13893635.000000\n",
      "Train Epoch: 128 [176/918 (19%)] Loss: 8540312.000000\n",
      "Train Epoch: 128 [192/918 (21%)] Loss: 11433917.000000\n",
      "Train Epoch: 128 [208/918 (23%)] Loss: 9576566.000000\n",
      "Train Epoch: 128 [224/918 (24%)] Loss: 9387186.000000\n",
      "Train Epoch: 128 [240/918 (26%)] Loss: 10637546.000000\n",
      "Train Epoch: 128 [256/918 (28%)] Loss: 10830066.000000\n",
      "Train Epoch: 128 [272/918 (30%)] Loss: 8958247.000000\n",
      "Train Epoch: 128 [288/918 (31%)] Loss: 8445632.000000\n",
      "Train Epoch: 128 [304/918 (33%)] Loss: 11277611.000000\n",
      "Train Epoch: 128 [320/918 (35%)] Loss: 11593557.000000\n",
      "Train Epoch: 128 [336/918 (37%)] Loss: 8157392.000000\n",
      "Train Epoch: 128 [352/918 (38%)] Loss: 9399200.000000\n",
      "Train Epoch: 128 [368/918 (40%)] Loss: 5585605.000000\n",
      "Train Epoch: 128 [384/918 (42%)] Loss: 11042208.000000\n",
      "Train Epoch: 128 [400/918 (44%)] Loss: 6519970.500000\n",
      "Train Epoch: 128 [416/918 (45%)] Loss: 13842666.000000\n",
      "Train Epoch: 128 [432/918 (47%)] Loss: 7056056.000000\n",
      "Train Epoch: 128 [448/918 (49%)] Loss: 10204715.000000\n",
      "Train Epoch: 128 [464/918 (51%)] Loss: 10009740.000000\n",
      "Train Epoch: 128 [480/918 (52%)] Loss: 7923429.500000\n",
      "Train Epoch: 128 [496/918 (54%)] Loss: 10551828.000000\n",
      "Train Epoch: 128 [512/918 (56%)] Loss: 7810670.500000\n",
      "Train Epoch: 128 [528/918 (58%)] Loss: 11512011.000000\n",
      "Train Epoch: 128 [544/918 (59%)] Loss: 9922986.000000\n",
      "Train Epoch: 128 [560/918 (61%)] Loss: 8761349.000000\n",
      "Train Epoch: 128 [576/918 (63%)] Loss: 9353647.000000\n",
      "Train Epoch: 128 [592/918 (64%)] Loss: 7731620.000000\n",
      "Train Epoch: 128 [608/918 (66%)] Loss: 8429046.000000\n",
      "Train Epoch: 128 [624/918 (68%)] Loss: 5823089.500000\n",
      "Train Epoch: 128 [640/918 (70%)] Loss: 8206626.500000\n",
      "Train Epoch: 128 [656/918 (71%)] Loss: 9966960.000000\n",
      "Train Epoch: 128 [672/918 (73%)] Loss: 10204239.000000\n",
      "Train Epoch: 128 [688/918 (75%)] Loss: 8725434.000000\n",
      "Train Epoch: 128 [704/918 (77%)] Loss: 8762114.000000\n",
      "Train Epoch: 128 [720/918 (78%)] Loss: 9908303.000000\n",
      "Train Epoch: 128 [736/918 (80%)] Loss: 10726944.000000\n",
      "Train Epoch: 128 [752/918 (82%)] Loss: 9525663.000000\n",
      "Train Epoch: 128 [768/918 (84%)] Loss: 10896922.000000\n",
      "Train Epoch: 128 [784/918 (85%)] Loss: 7898024.000000\n",
      "Train Epoch: 128 [800/918 (87%)] Loss: 11527749.000000\n",
      "Train Epoch: 128 [816/918 (89%)] Loss: 16745008.000000\n",
      "Train Epoch: 128 [832/918 (91%)] Loss: 8477364.000000\n",
      "Train Epoch: 128 [848/918 (92%)] Loss: 9706498.000000\n",
      "Train Epoch: 128 [864/918 (94%)] Loss: 9669578.000000\n",
      "Train Epoch: 128 [880/918 (96%)] Loss: 7281259.500000\n",
      "Train Epoch: 128 [896/918 (98%)] Loss: 11363303.000000\n",
      "Train Epoch: 128 [912/918 (99%)] Loss: 5953612.500000\n",
      "    epoch          : 128\n",
      "    loss           : 9545075.465217391\n",
      "    ess            : 9.499208157995472\n",
      "    log_marginal   : -9545073.591304347\n",
      "    val_loss       : 9164203.076923076\n",
      "    val_ess        : 6.804718586114737\n",
      "    val_log_marginal: -9164201.076923076\n",
      "Train Epoch: 129 [0/918 (0%)] Loss: 7617293.500000\n",
      "Train Epoch: 129 [16/918 (2%)] Loss: 6203010.500000\n",
      "Train Epoch: 129 [32/918 (3%)] Loss: 13832893.000000\n",
      "Train Epoch: 129 [48/918 (5%)] Loss: 6421104.000000\n",
      "Train Epoch: 129 [64/918 (7%)] Loss: 9969927.000000\n",
      "Train Epoch: 129 [80/918 (9%)] Loss: 12782142.000000\n",
      "Train Epoch: 129 [96/918 (10%)] Loss: 13082380.000000\n",
      "Train Epoch: 129 [112/918 (12%)] Loss: 6841345.500000\n",
      "Train Epoch: 129 [128/918 (14%)] Loss: 10878491.000000\n",
      "Train Epoch: 129 [144/918 (16%)] Loss: 7879637.000000\n",
      "Train Epoch: 129 [160/918 (17%)] Loss: 11070723.000000\n",
      "Train Epoch: 129 [176/918 (19%)] Loss: 11627244.000000\n",
      "Train Epoch: 129 [192/918 (21%)] Loss: 8173341.000000\n",
      "Train Epoch: 129 [208/918 (23%)] Loss: 7805610.500000\n",
      "Train Epoch: 129 [224/918 (24%)] Loss: 9609447.000000\n",
      "Train Epoch: 129 [240/918 (26%)] Loss: 24208144.000000\n",
      "Train Epoch: 129 [256/918 (28%)] Loss: 6421637.500000\n",
      "Train Epoch: 129 [272/918 (30%)] Loss: 12862392.000000\n",
      "Train Epoch: 129 [288/918 (31%)] Loss: 6052447.000000\n",
      "Train Epoch: 129 [304/918 (33%)] Loss: 6767125.000000\n",
      "Train Epoch: 129 [320/918 (35%)] Loss: 7573106.500000\n",
      "Train Epoch: 129 [336/918 (37%)] Loss: 13563517.000000\n",
      "Train Epoch: 129 [352/918 (38%)] Loss: 15649659.000000\n",
      "Train Epoch: 129 [368/918 (40%)] Loss: 10835363.000000\n",
      "Train Epoch: 129 [384/918 (42%)] Loss: 10976103.000000\n",
      "Train Epoch: 129 [400/918 (44%)] Loss: 7205354.500000\n",
      "Train Epoch: 129 [416/918 (45%)] Loss: 6205861.500000\n",
      "Train Epoch: 129 [432/918 (47%)] Loss: 7845043.500000\n",
      "Train Epoch: 129 [448/918 (49%)] Loss: 11344371.000000\n",
      "Train Epoch: 129 [464/918 (51%)] Loss: 12020776.000000\n",
      "Train Epoch: 129 [480/918 (52%)] Loss: 9519506.000000\n",
      "Train Epoch: 129 [496/918 (54%)] Loss: 9087427.000000\n",
      "Train Epoch: 129 [512/918 (56%)] Loss: 13475592.000000\n",
      "Train Epoch: 129 [528/918 (58%)] Loss: 9966733.000000\n",
      "Train Epoch: 129 [544/918 (59%)] Loss: 9322818.000000\n",
      "Train Epoch: 129 [560/918 (61%)] Loss: 6588438.500000\n",
      "Train Epoch: 129 [576/918 (63%)] Loss: 12243101.000000\n",
      "Train Epoch: 129 [592/918 (64%)] Loss: 8179557.000000\n",
      "Train Epoch: 129 [608/918 (66%)] Loss: 9540605.000000\n",
      "Train Epoch: 129 [624/918 (68%)] Loss: 10297019.000000\n",
      "Train Epoch: 129 [640/918 (70%)] Loss: 12170022.000000\n",
      "Train Epoch: 129 [656/918 (71%)] Loss: 10512922.000000\n",
      "Train Epoch: 129 [672/918 (73%)] Loss: 7899991.500000\n",
      "Train Epoch: 129 [688/918 (75%)] Loss: 14606371.000000\n",
      "Train Epoch: 129 [704/918 (77%)] Loss: 10357360.000000\n",
      "Train Epoch: 129 [720/918 (78%)] Loss: 9168591.000000\n",
      "Train Epoch: 129 [736/918 (80%)] Loss: 7527385.000000\n",
      "Train Epoch: 129 [752/918 (82%)] Loss: 12670950.000000\n",
      "Train Epoch: 129 [768/918 (84%)] Loss: 8066748.000000\n",
      "Train Epoch: 129 [784/918 (85%)] Loss: 7938009.500000\n",
      "Train Epoch: 129 [800/918 (87%)] Loss: 11039692.000000\n",
      "Train Epoch: 129 [816/918 (89%)] Loss: 11577620.000000\n",
      "Train Epoch: 129 [832/918 (91%)] Loss: 11395043.000000\n",
      "Train Epoch: 129 [848/918 (92%)] Loss: 6903893.000000\n",
      "Train Epoch: 129 [864/918 (94%)] Loss: 10607751.000000\n",
      "Train Epoch: 129 [880/918 (96%)] Loss: 7214273.500000\n",
      "Train Epoch: 129 [896/918 (98%)] Loss: 6891579.500000\n",
      "Train Epoch: 129 [912/918 (99%)] Loss: 8737712.000000\n",
      "    epoch          : 129\n",
      "    loss           : 9253148.930434782\n",
      "    ess            : 7.085054627708767\n",
      "    log_marginal   : -9253146.534782609\n",
      "    val_loss       : 9313310.115384616\n",
      "    val_ess        : 7.118150582680335\n",
      "    val_log_marginal: -9313303.923076924\n",
      "Train Epoch: 130 [0/918 (0%)] Loss: 9041141.000000\n",
      "Train Epoch: 130 [16/918 (2%)] Loss: 10306848.000000\n",
      "Train Epoch: 130 [32/918 (3%)] Loss: 9974951.000000\n",
      "Train Epoch: 130 [48/918 (5%)] Loss: 12892803.000000\n",
      "Train Epoch: 130 [64/918 (7%)] Loss: 11469468.000000\n",
      "Train Epoch: 130 [80/918 (9%)] Loss: 15520635.000000\n",
      "Train Epoch: 130 [96/918 (10%)] Loss: 9562463.000000\n",
      "Train Epoch: 130 [112/918 (12%)] Loss: 7829886.500000\n",
      "Train Epoch: 130 [128/918 (14%)] Loss: 10490883.000000\n",
      "Train Epoch: 130 [144/918 (16%)] Loss: 8806028.000000\n",
      "Train Epoch: 130 [160/918 (17%)] Loss: 10301588.000000\n",
      "Train Epoch: 130 [176/918 (19%)] Loss: 8481247.000000\n",
      "Train Epoch: 130 [192/918 (21%)] Loss: 11529911.000000\n",
      "Train Epoch: 130 [208/918 (23%)] Loss: 9000227.000000\n",
      "Train Epoch: 130 [224/918 (24%)] Loss: 11711072.000000\n",
      "Train Epoch: 130 [240/918 (26%)] Loss: 9695136.000000\n",
      "Train Epoch: 130 [256/918 (28%)] Loss: 6878338.500000\n",
      "Train Epoch: 130 [272/918 (30%)] Loss: 8578342.000000\n",
      "Train Epoch: 130 [288/918 (31%)] Loss: 8566049.000000\n",
      "Train Epoch: 130 [304/918 (33%)] Loss: 8457040.000000\n",
      "Train Epoch: 130 [320/918 (35%)] Loss: 9708976.000000\n",
      "Train Epoch: 130 [336/918 (37%)] Loss: 8340905.500000\n",
      "Train Epoch: 130 [352/918 (38%)] Loss: 12228916.000000\n",
      "Train Epoch: 130 [368/918 (40%)] Loss: 6118682.500000\n",
      "Train Epoch: 130 [384/918 (42%)] Loss: 7862022.500000\n",
      "Train Epoch: 130 [400/918 (44%)] Loss: 8871109.000000\n",
      "Train Epoch: 130 [416/918 (45%)] Loss: 6987185.500000\n",
      "Train Epoch: 130 [432/918 (47%)] Loss: 10436834.000000\n",
      "Train Epoch: 130 [448/918 (49%)] Loss: 8057119.500000\n",
      "Train Epoch: 130 [464/918 (51%)] Loss: 9260011.000000\n",
      "Train Epoch: 130 [480/918 (52%)] Loss: 8334432.000000\n",
      "Train Epoch: 130 [496/918 (54%)] Loss: 6138410.000000\n",
      "Train Epoch: 130 [512/918 (56%)] Loss: 11803227.000000\n",
      "Train Epoch: 130 [528/918 (58%)] Loss: 6562131.500000\n",
      "Train Epoch: 130 [544/918 (59%)] Loss: 8728130.000000\n",
      "Train Epoch: 130 [560/918 (61%)] Loss: 13867013.000000\n",
      "Train Epoch: 130 [576/918 (63%)] Loss: 12108928.000000\n",
      "Train Epoch: 130 [592/918 (64%)] Loss: 8957781.000000\n",
      "Train Epoch: 130 [608/918 (66%)] Loss: 8112987.500000\n",
      "Train Epoch: 130 [624/918 (68%)] Loss: 6769351.500000\n",
      "Train Epoch: 130 [640/918 (70%)] Loss: 7816079.500000\n",
      "Train Epoch: 130 [656/918 (71%)] Loss: 15196218.000000\n",
      "Train Epoch: 130 [672/918 (73%)] Loss: 10651429.000000\n",
      "Train Epoch: 130 [688/918 (75%)] Loss: 8291781.000000\n",
      "Train Epoch: 130 [704/918 (77%)] Loss: 10901419.000000\n",
      "Train Epoch: 130 [720/918 (78%)] Loss: 12801904.000000\n",
      "Train Epoch: 130 [736/918 (80%)] Loss: 8366661.500000\n",
      "Train Epoch: 130 [752/918 (82%)] Loss: 9638419.000000\n",
      "Train Epoch: 130 [768/918 (84%)] Loss: 8408643.000000\n",
      "Train Epoch: 130 [784/918 (85%)] Loss: 8897298.000000\n",
      "Train Epoch: 130 [800/918 (87%)] Loss: 6782986.500000\n",
      "Train Epoch: 130 [816/918 (89%)] Loss: 7661616.000000\n",
      "Train Epoch: 130 [832/918 (91%)] Loss: 8929767.000000\n",
      "Train Epoch: 130 [848/918 (92%)] Loss: 8677122.000000\n",
      "Train Epoch: 130 [864/918 (94%)] Loss: 7101813.500000\n",
      "Train Epoch: 130 [880/918 (96%)] Loss: 5877632.000000\n",
      "Train Epoch: 130 [896/918 (98%)] Loss: 7437646.500000\n",
      "Train Epoch: 130 [912/918 (99%)] Loss: 7430821.500000\n",
      "    epoch          : 130\n",
      "    loss           : 9340177.043478262\n",
      "    ess            : 8.745173240744549\n",
      "    log_marginal   : -9340174.8\n",
      "    val_loss       : 9800595.153846154\n",
      "    val_ess        : 10.883511689993052\n",
      "    val_log_marginal: -9800592.576923076\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch130.pth ...\n",
      "Train Epoch: 131 [0/918 (0%)] Loss: 10397040.000000\n",
      "Train Epoch: 131 [16/918 (2%)] Loss: 5351435.500000\n",
      "Train Epoch: 131 [32/918 (3%)] Loss: 9169586.000000\n",
      "Train Epoch: 131 [48/918 (5%)] Loss: 9013258.000000\n",
      "Train Epoch: 131 [64/918 (7%)] Loss: 8923712.000000\n",
      "Train Epoch: 131 [80/918 (9%)] Loss: 12750903.000000\n",
      "Train Epoch: 131 [96/918 (10%)] Loss: 11783650.000000\n",
      "Train Epoch: 131 [112/918 (12%)] Loss: 8125734.500000\n",
      "Train Epoch: 131 [128/918 (14%)] Loss: 7059200.000000\n",
      "Train Epoch: 131 [144/918 (16%)] Loss: 6342792.000000\n",
      "Train Epoch: 131 [160/918 (17%)] Loss: 7665899.500000\n",
      "Train Epoch: 131 [176/918 (19%)] Loss: 5333157.000000\n",
      "Train Epoch: 131 [192/918 (21%)] Loss: 8581675.000000\n",
      "Train Epoch: 131 [208/918 (23%)] Loss: 9753175.000000\n",
      "Train Epoch: 131 [224/918 (24%)] Loss: 7804834.500000\n",
      "Train Epoch: 131 [240/918 (26%)] Loss: 6836744.000000\n",
      "Train Epoch: 131 [256/918 (28%)] Loss: 7740214.500000\n",
      "Train Epoch: 131 [272/918 (30%)] Loss: 9365662.000000\n",
      "Train Epoch: 131 [288/918 (31%)] Loss: 6883865.500000\n",
      "Train Epoch: 131 [304/918 (33%)] Loss: 6961366.500000\n",
      "Train Epoch: 131 [320/918 (35%)] Loss: 12471833.000000\n",
      "Train Epoch: 131 [336/918 (37%)] Loss: 13647907.000000\n",
      "Train Epoch: 131 [352/918 (38%)] Loss: 6702632.500000\n",
      "Train Epoch: 131 [368/918 (40%)] Loss: 8464093.000000\n",
      "Train Epoch: 131 [384/918 (42%)] Loss: 7055157.000000\n",
      "Train Epoch: 131 [400/918 (44%)] Loss: 8448335.000000\n",
      "Train Epoch: 131 [416/918 (45%)] Loss: 14516909.000000\n",
      "Train Epoch: 131 [432/918 (47%)] Loss: 9742383.000000\n",
      "Train Epoch: 131 [448/918 (49%)] Loss: 9507358.000000\n",
      "Train Epoch: 131 [464/918 (51%)] Loss: 7720919.500000\n",
      "Train Epoch: 131 [480/918 (52%)] Loss: 10696887.000000\n",
      "Train Epoch: 131 [496/918 (54%)] Loss: 7999949.500000\n",
      "Train Epoch: 131 [512/918 (56%)] Loss: 9536767.000000\n",
      "Train Epoch: 131 [528/918 (58%)] Loss: 10682779.000000\n",
      "Train Epoch: 131 [544/918 (59%)] Loss: 6568972.000000\n",
      "Train Epoch: 131 [560/918 (61%)] Loss: 8361518.500000\n",
      "Train Epoch: 131 [576/918 (63%)] Loss: 7972957.000000\n",
      "Train Epoch: 131 [592/918 (64%)] Loss: 11067103.000000\n",
      "Train Epoch: 131 [608/918 (66%)] Loss: 9355623.000000\n",
      "Train Epoch: 131 [624/918 (68%)] Loss: 8075215.500000\n",
      "Train Epoch: 131 [640/918 (70%)] Loss: 7880632.000000\n",
      "Train Epoch: 131 [656/918 (71%)] Loss: 8258368.000000\n",
      "Train Epoch: 131 [672/918 (73%)] Loss: 6109340.500000\n",
      "Train Epoch: 131 [688/918 (75%)] Loss: 7803785.500000\n",
      "Train Epoch: 131 [704/918 (77%)] Loss: 7867367.500000\n",
      "Train Epoch: 131 [720/918 (78%)] Loss: 9307683.000000\n",
      "Train Epoch: 131 [736/918 (80%)] Loss: 9370232.000000\n",
      "Train Epoch: 131 [752/918 (82%)] Loss: 7501622.500000\n",
      "Train Epoch: 131 [768/918 (84%)] Loss: 5251776.500000\n",
      "Train Epoch: 131 [784/918 (85%)] Loss: 9517979.000000\n",
      "Train Epoch: 131 [800/918 (87%)] Loss: 11989983.000000\n",
      "Train Epoch: 131 [816/918 (89%)] Loss: 8251683.500000\n",
      "Train Epoch: 131 [832/918 (91%)] Loss: 8483311.000000\n",
      "Train Epoch: 131 [848/918 (92%)] Loss: 12764503.000000\n",
      "Train Epoch: 131 [864/918 (94%)] Loss: 10685541.000000\n",
      "Train Epoch: 131 [880/918 (96%)] Loss: 12376230.000000\n",
      "Train Epoch: 131 [896/918 (98%)] Loss: 9580218.000000\n",
      "Train Epoch: 131 [912/918 (99%)] Loss: 6191979.000000\n",
      "    epoch          : 131\n",
      "    loss           : 9396041.208695652\n",
      "    ess            : 7.478446137386819\n",
      "    log_marginal   : -9396038.643478261\n",
      "    val_loss       : 9001814.423076924\n",
      "    val_ess        : 8.273213129777174\n",
      "    val_log_marginal: -9001813.076923076\n",
      "Train Epoch: 132 [0/918 (0%)] Loss: 10404384.000000\n",
      "Train Epoch: 132 [16/918 (2%)] Loss: 11391152.000000\n",
      "Train Epoch: 132 [32/918 (3%)] Loss: 8051127.500000\n",
      "Train Epoch: 132 [48/918 (5%)] Loss: 12379227.000000\n",
      "Train Epoch: 132 [64/918 (7%)] Loss: 5342873.500000\n",
      "Train Epoch: 132 [80/918 (9%)] Loss: 7050714.500000\n",
      "Train Epoch: 132 [96/918 (10%)] Loss: 10490879.000000\n",
      "Train Epoch: 132 [112/918 (12%)] Loss: 6955625.500000\n",
      "Train Epoch: 132 [128/918 (14%)] Loss: 11058340.000000\n",
      "Train Epoch: 132 [144/918 (16%)] Loss: 15073159.000000\n",
      "Train Epoch: 132 [160/918 (17%)] Loss: 10134252.000000\n",
      "Train Epoch: 132 [176/918 (19%)] Loss: 8581807.000000\n",
      "Train Epoch: 132 [192/918 (21%)] Loss: 10157239.000000\n",
      "Train Epoch: 132 [208/918 (23%)] Loss: 8062357.000000\n",
      "Train Epoch: 132 [224/918 (24%)] Loss: 7406539.500000\n",
      "Train Epoch: 132 [240/918 (26%)] Loss: 12208337.000000\n",
      "Train Epoch: 132 [256/918 (28%)] Loss: 10362320.000000\n",
      "Train Epoch: 132 [272/918 (30%)] Loss: 10120935.000000\n",
      "Train Epoch: 132 [288/918 (31%)] Loss: 8270594.500000\n",
      "Train Epoch: 132 [304/918 (33%)] Loss: 10706632.000000\n",
      "Train Epoch: 132 [320/918 (35%)] Loss: 5574650.500000\n",
      "Train Epoch: 132 [336/918 (37%)] Loss: 9210811.000000\n",
      "Train Epoch: 132 [352/918 (38%)] Loss: 5443925.000000\n",
      "Train Epoch: 132 [368/918 (40%)] Loss: 10162581.000000\n",
      "Train Epoch: 132 [384/918 (42%)] Loss: 10410466.000000\n",
      "Train Epoch: 132 [400/918 (44%)] Loss: 9934912.000000\n",
      "Train Epoch: 132 [416/918 (45%)] Loss: 6359121.500000\n",
      "Train Epoch: 132 [432/918 (47%)] Loss: 12669962.000000\n",
      "Train Epoch: 132 [448/918 (49%)] Loss: 5915177.500000\n",
      "Train Epoch: 132 [464/918 (51%)] Loss: 9265874.000000\n",
      "Train Epoch: 132 [480/918 (52%)] Loss: 9792408.000000\n",
      "Train Epoch: 132 [496/918 (54%)] Loss: 12626513.000000\n",
      "Train Epoch: 132 [512/918 (56%)] Loss: 8886304.000000\n",
      "Train Epoch: 132 [528/918 (58%)] Loss: 8410056.000000\n",
      "Train Epoch: 132 [544/918 (59%)] Loss: 12424429.000000\n",
      "Train Epoch: 132 [560/918 (61%)] Loss: 11681435.000000\n",
      "Train Epoch: 132 [576/918 (63%)] Loss: 8141097.500000\n",
      "Train Epoch: 132 [592/918 (64%)] Loss: 9202485.000000\n",
      "Train Epoch: 132 [608/918 (66%)] Loss: 6982037.000000\n",
      "Train Epoch: 132 [624/918 (68%)] Loss: 10498930.000000\n",
      "Train Epoch: 132 [640/918 (70%)] Loss: 6827605.000000\n",
      "Train Epoch: 132 [656/918 (71%)] Loss: 11065557.000000\n",
      "Train Epoch: 132 [672/918 (73%)] Loss: 7525526.500000\n",
      "Train Epoch: 132 [688/918 (75%)] Loss: 9472143.000000\n",
      "Train Epoch: 132 [704/918 (77%)] Loss: 10093100.000000\n",
      "Train Epoch: 132 [720/918 (78%)] Loss: 6098108.000000\n",
      "Train Epoch: 132 [736/918 (80%)] Loss: 6317691.500000\n",
      "Train Epoch: 132 [752/918 (82%)] Loss: 9182211.000000\n",
      "Train Epoch: 132 [768/918 (84%)] Loss: 7148497.500000\n",
      "Train Epoch: 132 [784/918 (85%)] Loss: 6923984.000000\n",
      "Train Epoch: 132 [800/918 (87%)] Loss: 9762605.000000\n",
      "Train Epoch: 132 [816/918 (89%)] Loss: 8582583.000000\n",
      "Train Epoch: 132 [832/918 (91%)] Loss: 9916643.000000\n",
      "Train Epoch: 132 [848/918 (92%)] Loss: 6590168.500000\n",
      "Train Epoch: 132 [864/918 (94%)] Loss: 8523615.000000\n",
      "Train Epoch: 132 [880/918 (96%)] Loss: 6981568.000000\n",
      "Train Epoch: 132 [896/918 (98%)] Loss: 6465832.500000\n",
      "Train Epoch: 132 [912/918 (99%)] Loss: 7212668.000000\n",
      "    epoch          : 132\n",
      "    loss           : 9068527.130434783\n",
      "    ess            : 8.017865676465242\n",
      "    log_marginal   : -9068524.591304347\n",
      "    val_loss       : 9018359.538461538\n",
      "    val_ess        : 7.499917965668899\n",
      "    val_log_marginal: -9018356.73076923\n",
      "Train Epoch: 133 [0/918 (0%)] Loss: 9187204.000000\n",
      "Train Epoch: 133 [16/918 (2%)] Loss: 10086732.000000\n",
      "Train Epoch: 133 [32/918 (3%)] Loss: 6897329.500000\n",
      "Train Epoch: 133 [48/918 (5%)] Loss: 6936276.000000\n",
      "Train Epoch: 133 [64/918 (7%)] Loss: 9249144.000000\n",
      "Train Epoch: 133 [80/918 (9%)] Loss: 10697179.000000\n",
      "Train Epoch: 133 [96/918 (10%)] Loss: 7689245.000000\n",
      "Train Epoch: 133 [112/918 (12%)] Loss: 10963002.000000\n",
      "Train Epoch: 133 [128/918 (14%)] Loss: 14947395.000000\n",
      "Train Epoch: 133 [144/918 (16%)] Loss: 13358251.000000\n",
      "Train Epoch: 133 [160/918 (17%)] Loss: 7322694.500000\n",
      "Train Epoch: 133 [176/918 (19%)] Loss: 5950663.500000\n",
      "Train Epoch: 133 [192/918 (21%)] Loss: 8854095.000000\n",
      "Train Epoch: 133 [208/918 (23%)] Loss: 9421280.000000\n",
      "Train Epoch: 133 [224/918 (24%)] Loss: 6000962.500000\n",
      "Train Epoch: 133 [240/918 (26%)] Loss: 11841839.000000\n",
      "Train Epoch: 133 [256/918 (28%)] Loss: 9241272.000000\n",
      "Train Epoch: 133 [272/918 (30%)] Loss: 7547025.500000\n",
      "Train Epoch: 133 [288/918 (31%)] Loss: 7400949.000000\n",
      "Train Epoch: 133 [304/918 (33%)] Loss: 10584514.000000\n",
      "Train Epoch: 133 [320/918 (35%)] Loss: 10268985.000000\n",
      "Train Epoch: 133 [336/918 (37%)] Loss: 12834319.000000\n",
      "Train Epoch: 133 [352/918 (38%)] Loss: 8853432.000000\n",
      "Train Epoch: 133 [368/918 (40%)] Loss: 7509238.500000\n",
      "Train Epoch: 133 [384/918 (42%)] Loss: 12742331.000000\n",
      "Train Epoch: 133 [400/918 (44%)] Loss: 12977767.000000\n",
      "Train Epoch: 133 [416/918 (45%)] Loss: 7667198.500000\n",
      "Train Epoch: 133 [432/918 (47%)] Loss: 11991931.000000\n",
      "Train Epoch: 133 [448/918 (49%)] Loss: 9715243.000000\n",
      "Train Epoch: 133 [464/918 (51%)] Loss: 9989180.000000\n",
      "Train Epoch: 133 [480/918 (52%)] Loss: 6401728.000000\n",
      "Train Epoch: 133 [496/918 (54%)] Loss: 13474861.000000\n",
      "Train Epoch: 133 [512/918 (56%)] Loss: 6740126.500000\n",
      "Train Epoch: 133 [528/918 (58%)] Loss: 11367787.000000\n",
      "Train Epoch: 133 [544/918 (59%)] Loss: 10088047.000000\n",
      "Train Epoch: 133 [560/918 (61%)] Loss: 12968218.000000\n",
      "Train Epoch: 133 [576/918 (63%)] Loss: 9340783.000000\n",
      "Train Epoch: 133 [592/918 (64%)] Loss: 9987178.000000\n",
      "Train Epoch: 133 [608/918 (66%)] Loss: 5620801.500000\n",
      "Train Epoch: 133 [624/918 (68%)] Loss: 16050605.000000\n",
      "Train Epoch: 133 [640/918 (70%)] Loss: 7824978.500000\n",
      "Train Epoch: 133 [656/918 (71%)] Loss: 9863500.000000\n",
      "Train Epoch: 133 [672/918 (73%)] Loss: 9145448.000000\n",
      "Train Epoch: 133 [688/918 (75%)] Loss: 8329625.000000\n",
      "Train Epoch: 133 [704/918 (77%)] Loss: 6074511.000000\n",
      "Train Epoch: 133 [720/918 (78%)] Loss: 8689751.000000\n",
      "Train Epoch: 133 [736/918 (80%)] Loss: 10201877.000000\n",
      "Train Epoch: 133 [752/918 (82%)] Loss: 8413324.000000\n",
      "Train Epoch: 133 [768/918 (84%)] Loss: 10029143.000000\n",
      "Train Epoch: 133 [784/918 (85%)] Loss: 6894608.000000\n",
      "Train Epoch: 133 [800/918 (87%)] Loss: 13206546.000000\n",
      "Train Epoch: 133 [816/918 (89%)] Loss: 11943475.000000\n",
      "Train Epoch: 133 [832/918 (91%)] Loss: 9470888.000000\n",
      "Train Epoch: 133 [848/918 (92%)] Loss: 9820458.000000\n",
      "Train Epoch: 133 [864/918 (94%)] Loss: 16099085.000000\n",
      "Train Epoch: 133 [880/918 (96%)] Loss: 10237940.000000\n",
      "Train Epoch: 133 [896/918 (98%)] Loss: 12978608.000000\n",
      "Train Epoch: 133 [912/918 (99%)] Loss: 8180494.500000\n",
      "    epoch          : 133\n",
      "    loss           : 9360654.765217392\n",
      "    ess            : 7.946841696034307\n",
      "    log_marginal   : -9360652.830434782\n",
      "    val_loss       : 9340918.423076924\n",
      "    val_ess        : 8.363680105942946\n",
      "    val_log_marginal: -9340916.26923077\n",
      "Train Epoch: 134 [0/918 (0%)] Loss: 7457570.500000\n",
      "Train Epoch: 134 [16/918 (2%)] Loss: 8753580.000000\n",
      "Train Epoch: 134 [32/918 (3%)] Loss: 10622480.000000\n",
      "Train Epoch: 134 [48/918 (5%)] Loss: 9964427.000000\n",
      "Train Epoch: 134 [64/918 (7%)] Loss: 13882119.000000\n",
      "Train Epoch: 134 [80/918 (9%)] Loss: 7569533.500000\n",
      "Train Epoch: 134 [96/918 (10%)] Loss: 10815954.000000\n",
      "Train Epoch: 134 [112/918 (12%)] Loss: 9624201.000000\n",
      "Train Epoch: 134 [128/918 (14%)] Loss: 6933901.000000\n",
      "Train Epoch: 134 [144/918 (16%)] Loss: 10509226.000000\n",
      "Train Epoch: 134 [160/918 (17%)] Loss: 6028713.500000\n",
      "Train Epoch: 134 [176/918 (19%)] Loss: 9264643.000000\n",
      "Train Epoch: 134 [192/918 (21%)] Loss: 14076408.000000\n",
      "Train Epoch: 134 [208/918 (23%)] Loss: 7244225.500000\n",
      "Train Epoch: 134 [224/918 (24%)] Loss: 8787319.000000\n",
      "Train Epoch: 134 [240/918 (26%)] Loss: 6622504.000000\n",
      "Train Epoch: 134 [256/918 (28%)] Loss: 7501177.500000\n",
      "Train Epoch: 134 [272/918 (30%)] Loss: 9827364.000000\n",
      "Train Epoch: 134 [288/918 (31%)] Loss: 6278128.000000\n",
      "Train Epoch: 134 [304/918 (33%)] Loss: 10013797.000000\n",
      "Train Epoch: 134 [320/918 (35%)] Loss: 5492673.000000\n",
      "Train Epoch: 134 [336/918 (37%)] Loss: 11280078.000000\n",
      "Train Epoch: 134 [352/918 (38%)] Loss: 8303280.000000\n",
      "Train Epoch: 134 [368/918 (40%)] Loss: 10578778.000000\n",
      "Train Epoch: 134 [384/918 (42%)] Loss: 9631103.000000\n",
      "Train Epoch: 134 [400/918 (44%)] Loss: 17996686.000000\n",
      "Train Epoch: 134 [416/918 (45%)] Loss: 9375804.000000\n",
      "Train Epoch: 134 [432/918 (47%)] Loss: 7907855.500000\n",
      "Train Epoch: 134 [448/918 (49%)] Loss: 8991650.000000\n",
      "Train Epoch: 134 [464/918 (51%)] Loss: 8788367.000000\n",
      "Train Epoch: 134 [480/918 (52%)] Loss: 10426987.000000\n",
      "Train Epoch: 134 [496/918 (54%)] Loss: 10482706.000000\n",
      "Train Epoch: 134 [512/918 (56%)] Loss: 12988097.000000\n",
      "Train Epoch: 134 [528/918 (58%)] Loss: 15828856.000000\n",
      "Train Epoch: 134 [544/918 (59%)] Loss: 6763471.500000\n",
      "Train Epoch: 134 [560/918 (61%)] Loss: 8273857.000000\n",
      "Train Epoch: 134 [576/918 (63%)] Loss: 6774033.500000\n",
      "Train Epoch: 134 [592/918 (64%)] Loss: 8044614.500000\n",
      "Train Epoch: 134 [608/918 (66%)] Loss: 8104192.000000\n",
      "Train Epoch: 134 [624/918 (68%)] Loss: 11822005.000000\n",
      "Train Epoch: 134 [640/918 (70%)] Loss: 12061315.000000\n",
      "Train Epoch: 134 [656/918 (71%)] Loss: 12393783.000000\n",
      "Train Epoch: 134 [672/918 (73%)] Loss: 9640010.000000\n",
      "Train Epoch: 134 [688/918 (75%)] Loss: 10727045.000000\n",
      "Train Epoch: 134 [704/918 (77%)] Loss: 7866238.500000\n",
      "Train Epoch: 134 [720/918 (78%)] Loss: 13721731.000000\n",
      "Train Epoch: 134 [736/918 (80%)] Loss: 6712280.000000\n",
      "Train Epoch: 134 [752/918 (82%)] Loss: 12750721.000000\n",
      "Train Epoch: 134 [768/918 (84%)] Loss: 10377675.000000\n",
      "Train Epoch: 134 [784/918 (85%)] Loss: 13932327.000000\n",
      "Train Epoch: 134 [800/918 (87%)] Loss: 7165471.500000\n",
      "Train Epoch: 134 [816/918 (89%)] Loss: 10012003.000000\n",
      "Train Epoch: 134 [832/918 (91%)] Loss: 9584657.000000\n",
      "Train Epoch: 134 [848/918 (92%)] Loss: 7544904.000000\n",
      "Train Epoch: 134 [864/918 (94%)] Loss: 9090261.000000\n",
      "Train Epoch: 134 [880/918 (96%)] Loss: 10508699.000000\n",
      "Train Epoch: 134 [896/918 (98%)] Loss: 9796242.000000\n",
      "Train Epoch: 134 [912/918 (99%)] Loss: 7205593.000000\n",
      "    epoch          : 134\n",
      "    loss           : 9150241.7\n",
      "    ess            : 7.930801072327987\n",
      "    log_marginal   : -9150239.143478261\n",
      "    val_loss       : 9595036.846153846\n",
      "    val_ess        : 7.943643148128803\n",
      "    val_log_marginal: -9595033.23076923\n",
      "Train Epoch: 135 [0/918 (0%)] Loss: 11190971.000000\n",
      "Train Epoch: 135 [16/918 (2%)] Loss: 11697887.000000\n",
      "Train Epoch: 135 [32/918 (3%)] Loss: 6786101.500000\n",
      "Train Epoch: 135 [48/918 (5%)] Loss: 9024483.000000\n",
      "Train Epoch: 135 [64/918 (7%)] Loss: 9975220.000000\n",
      "Train Epoch: 135 [80/918 (9%)] Loss: 11090800.000000\n",
      "Train Epoch: 135 [96/918 (10%)] Loss: 6715961.500000\n",
      "Train Epoch: 135 [112/918 (12%)] Loss: 8341969.500000\n",
      "Train Epoch: 135 [128/918 (14%)] Loss: 11657395.000000\n",
      "Train Epoch: 135 [144/918 (16%)] Loss: 8052591.500000\n",
      "Train Epoch: 135 [160/918 (17%)] Loss: 4941010.500000\n",
      "Train Epoch: 135 [176/918 (19%)] Loss: 5996821.500000\n",
      "Train Epoch: 135 [192/918 (21%)] Loss: 16771399.000000\n",
      "Train Epoch: 135 [208/918 (23%)] Loss: 14844850.000000\n",
      "Train Epoch: 135 [224/918 (24%)] Loss: 9542305.000000\n",
      "Train Epoch: 135 [240/918 (26%)] Loss: 12483827.000000\n",
      "Train Epoch: 135 [256/918 (28%)] Loss: 13440723.000000\n",
      "Train Epoch: 135 [272/918 (30%)] Loss: 7362557.000000\n",
      "Train Epoch: 135 [288/918 (31%)] Loss: 8878992.000000\n",
      "Train Epoch: 135 [304/918 (33%)] Loss: 7290953.500000\n",
      "Train Epoch: 135 [320/918 (35%)] Loss: 6448271.000000\n",
      "Train Epoch: 135 [336/918 (37%)] Loss: 7876437.000000\n",
      "Train Epoch: 135 [352/918 (38%)] Loss: 16716792.000000\n",
      "Train Epoch: 135 [368/918 (40%)] Loss: 14348618.000000\n",
      "Train Epoch: 135 [384/918 (42%)] Loss: 16121530.000000\n",
      "Train Epoch: 135 [400/918 (44%)] Loss: 15757037.000000\n",
      "Train Epoch: 135 [416/918 (45%)] Loss: 6598607.500000\n",
      "Train Epoch: 135 [432/918 (47%)] Loss: 7032043.500000\n",
      "Train Epoch: 135 [448/918 (49%)] Loss: 9809415.000000\n",
      "Train Epoch: 135 [464/918 (51%)] Loss: 10292462.000000\n",
      "Train Epoch: 135 [480/918 (52%)] Loss: 9074309.000000\n",
      "Train Epoch: 135 [496/918 (54%)] Loss: 11432724.000000\n",
      "Train Epoch: 135 [512/918 (56%)] Loss: 9035170.000000\n",
      "Train Epoch: 135 [528/918 (58%)] Loss: 8836392.000000\n",
      "Train Epoch: 135 [544/918 (59%)] Loss: 12468379.000000\n",
      "Train Epoch: 135 [560/918 (61%)] Loss: 10333666.000000\n",
      "Train Epoch: 135 [576/918 (63%)] Loss: 8219669.500000\n",
      "Train Epoch: 135 [592/918 (64%)] Loss: 14442128.000000\n",
      "Train Epoch: 135 [608/918 (66%)] Loss: 6586491.500000\n",
      "Train Epoch: 135 [624/918 (68%)] Loss: 10165719.000000\n",
      "Train Epoch: 135 [640/918 (70%)] Loss: 5606460.000000\n",
      "Train Epoch: 135 [656/918 (71%)] Loss: 16321968.000000\n",
      "Train Epoch: 135 [672/918 (73%)] Loss: 7820168.000000\n",
      "Train Epoch: 135 [688/918 (75%)] Loss: 6133682.000000\n",
      "Train Epoch: 135 [704/918 (77%)] Loss: 10444127.000000\n",
      "Train Epoch: 135 [720/918 (78%)] Loss: 12279351.000000\n",
      "Train Epoch: 135 [736/918 (80%)] Loss: 10797984.000000\n",
      "Train Epoch: 135 [752/918 (82%)] Loss: 10080812.000000\n",
      "Train Epoch: 135 [768/918 (84%)] Loss: 9279504.000000\n",
      "Train Epoch: 135 [784/918 (85%)] Loss: 6828681.000000\n",
      "Train Epoch: 135 [800/918 (87%)] Loss: 8582035.000000\n",
      "Train Epoch: 135 [816/918 (89%)] Loss: 8956553.000000\n",
      "Train Epoch: 135 [832/918 (91%)] Loss: 7002664.000000\n",
      "Train Epoch: 135 [848/918 (92%)] Loss: 7701550.500000\n",
      "Train Epoch: 135 [864/918 (94%)] Loss: 7541969.500000\n",
      "Train Epoch: 135 [880/918 (96%)] Loss: 4555804.500000\n",
      "Train Epoch: 135 [896/918 (98%)] Loss: 8226461.000000\n",
      "Train Epoch: 135 [912/918 (99%)] Loss: 9541899.000000\n",
      "    epoch          : 135\n",
      "    loss           : 9347304.130434783\n",
      "    ess            : 8.041796738168468\n",
      "    log_marginal   : -9347302.304347826\n",
      "    val_loss       : 9377350.384615384\n",
      "    val_ess        : 6.554565814825205\n",
      "    val_log_marginal: -9377349.615384616\n",
      "Train Epoch: 136 [0/918 (0%)] Loss: 5922268.000000\n",
      "Train Epoch: 136 [16/918 (2%)] Loss: 11862048.000000\n",
      "Train Epoch: 136 [32/918 (3%)] Loss: 7346085.500000\n",
      "Train Epoch: 136 [48/918 (5%)] Loss: 6191459.000000\n",
      "Train Epoch: 136 [64/918 (7%)] Loss: 8744426.000000\n",
      "Train Epoch: 136 [80/918 (9%)] Loss: 6339950.000000\n",
      "Train Epoch: 136 [96/918 (10%)] Loss: 9540730.000000\n",
      "Train Epoch: 136 [112/918 (12%)] Loss: 11696716.000000\n",
      "Train Epoch: 136 [128/918 (14%)] Loss: 6509095.500000\n",
      "Train Epoch: 136 [144/918 (16%)] Loss: 8644752.000000\n",
      "Train Epoch: 136 [160/918 (17%)] Loss: 7147969.500000\n",
      "Train Epoch: 136 [176/918 (19%)] Loss: 10295815.000000\n",
      "Train Epoch: 136 [192/918 (21%)] Loss: 9064336.000000\n",
      "Train Epoch: 136 [208/918 (23%)] Loss: 5711641.500000\n",
      "Train Epoch: 136 [224/918 (24%)] Loss: 10295717.000000\n",
      "Train Epoch: 136 [240/918 (26%)] Loss: 7233148.000000\n",
      "Train Epoch: 136 [256/918 (28%)] Loss: 10304136.000000\n",
      "Train Epoch: 136 [272/918 (30%)] Loss: 10682842.000000\n",
      "Train Epoch: 136 [288/918 (31%)] Loss: 5539885.500000\n",
      "Train Epoch: 136 [304/918 (33%)] Loss: 9020036.000000\n",
      "Train Epoch: 136 [320/918 (35%)] Loss: 9525453.000000\n",
      "Train Epoch: 136 [336/918 (37%)] Loss: 8784897.000000\n",
      "Train Epoch: 136 [352/918 (38%)] Loss: 7994634.500000\n",
      "Train Epoch: 136 [368/918 (40%)] Loss: 8146231.500000\n",
      "Train Epoch: 136 [384/918 (42%)] Loss: 9688498.000000\n",
      "Train Epoch: 136 [400/918 (44%)] Loss: 9177211.000000\n",
      "Train Epoch: 136 [416/918 (45%)] Loss: 14270691.000000\n",
      "Train Epoch: 136 [432/918 (47%)] Loss: 10962311.000000\n",
      "Train Epoch: 136 [448/918 (49%)] Loss: 9794450.000000\n",
      "Train Epoch: 136 [464/918 (51%)] Loss: 8019265.500000\n",
      "Train Epoch: 136 [480/918 (52%)] Loss: 7337309.500000\n",
      "Train Epoch: 136 [496/918 (54%)] Loss: 6041020.500000\n",
      "Train Epoch: 136 [512/918 (56%)] Loss: 9651385.000000\n",
      "Train Epoch: 136 [528/918 (58%)] Loss: 11693615.000000\n",
      "Train Epoch: 136 [544/918 (59%)] Loss: 8893099.000000\n",
      "Train Epoch: 136 [560/918 (61%)] Loss: 5025463.500000\n",
      "Train Epoch: 136 [576/918 (63%)] Loss: 8065051.500000\n",
      "Train Epoch: 136 [592/918 (64%)] Loss: 8973933.000000\n",
      "Train Epoch: 136 [608/918 (66%)] Loss: 7885947.500000\n",
      "Train Epoch: 136 [624/918 (68%)] Loss: 9989242.000000\n",
      "Train Epoch: 136 [640/918 (70%)] Loss: 8779075.000000\n",
      "Train Epoch: 136 [656/918 (71%)] Loss: 9035684.000000\n",
      "Train Epoch: 136 [672/918 (73%)] Loss: 6582328.000000\n",
      "Train Epoch: 136 [688/918 (75%)] Loss: 7895777.500000\n",
      "Train Epoch: 136 [704/918 (77%)] Loss: 12225838.000000\n",
      "Train Epoch: 136 [720/918 (78%)] Loss: 9626647.000000\n",
      "Train Epoch: 136 [736/918 (80%)] Loss: 7842483.500000\n",
      "Train Epoch: 136 [752/918 (82%)] Loss: 7810172.000000\n",
      "Train Epoch: 136 [768/918 (84%)] Loss: 11231855.000000\n",
      "Train Epoch: 136 [784/918 (85%)] Loss: 7322313.500000\n",
      "Train Epoch: 136 [800/918 (87%)] Loss: 6988185.000000\n",
      "Train Epoch: 136 [816/918 (89%)] Loss: 9469400.000000\n",
      "Train Epoch: 136 [832/918 (91%)] Loss: 7245221.000000\n",
      "Train Epoch: 136 [848/918 (92%)] Loss: 12002966.000000\n",
      "Train Epoch: 136 [864/918 (94%)] Loss: 12454441.000000\n",
      "Train Epoch: 136 [880/918 (96%)] Loss: 7346644.000000\n",
      "Train Epoch: 136 [896/918 (98%)] Loss: 7876248.000000\n",
      "Train Epoch: 136 [912/918 (99%)] Loss: 9657964.000000\n",
      "    epoch          : 136\n",
      "    loss           : 9146106.491304347\n",
      "    ess            : 8.051713130785071\n",
      "    log_marginal   : -9146104.704347827\n",
      "    val_loss       : 8457741.653846154\n",
      "    val_ess        : 8.815384498009315\n",
      "    val_log_marginal: -8457739.076923076\n",
      "Train Epoch: 137 [0/918 (0%)] Loss: 13005420.000000\n",
      "Train Epoch: 137 [16/918 (2%)] Loss: 10530243.000000\n",
      "Train Epoch: 137 [32/918 (3%)] Loss: 15151933.000000\n",
      "Train Epoch: 137 [48/918 (5%)] Loss: 9251360.000000\n",
      "Train Epoch: 137 [64/918 (7%)] Loss: 8454296.000000\n",
      "Train Epoch: 137 [80/918 (9%)] Loss: 5843109.500000\n",
      "Train Epoch: 137 [96/918 (10%)] Loss: 4928762.500000\n",
      "Train Epoch: 137 [112/918 (12%)] Loss: 6506007.500000\n",
      "Train Epoch: 137 [128/918 (14%)] Loss: 9346133.000000\n",
      "Train Epoch: 137 [144/918 (16%)] Loss: 9477507.000000\n",
      "Train Epoch: 137 [160/918 (17%)] Loss: 7456862.500000\n",
      "Train Epoch: 137 [176/918 (19%)] Loss: 9180570.000000\n",
      "Train Epoch: 137 [192/918 (21%)] Loss: 9373810.000000\n",
      "Train Epoch: 137 [208/918 (23%)] Loss: 9502955.000000\n",
      "Train Epoch: 137 [224/918 (24%)] Loss: 11463655.000000\n",
      "Train Epoch: 137 [240/918 (26%)] Loss: 8996392.000000\n",
      "Train Epoch: 137 [256/918 (28%)] Loss: 8055462.500000\n",
      "Train Epoch: 137 [272/918 (30%)] Loss: 6972953.000000\n",
      "Train Epoch: 137 [288/918 (31%)] Loss: 8961948.000000\n",
      "Train Epoch: 137 [304/918 (33%)] Loss: 8238465.500000\n",
      "Train Epoch: 137 [320/918 (35%)] Loss: 7909633.500000\n",
      "Train Epoch: 137 [336/918 (37%)] Loss: 7367370.500000\n",
      "Train Epoch: 137 [352/918 (38%)] Loss: 7524481.500000\n",
      "Train Epoch: 137 [368/918 (40%)] Loss: 9021170.000000\n",
      "Train Epoch: 137 [384/918 (42%)] Loss: 11266755.000000\n",
      "Train Epoch: 137 [400/918 (44%)] Loss: 8371121.000000\n",
      "Train Epoch: 137 [416/918 (45%)] Loss: 7306789.000000\n",
      "Train Epoch: 137 [432/918 (47%)] Loss: 7924417.500000\n",
      "Train Epoch: 137 [448/918 (49%)] Loss: 7854261.000000\n",
      "Train Epoch: 137 [464/918 (51%)] Loss: 15404634.000000\n",
      "Train Epoch: 137 [480/918 (52%)] Loss: 8080849.500000\n",
      "Train Epoch: 137 [496/918 (54%)] Loss: 8074417.500000\n",
      "Train Epoch: 137 [512/918 (56%)] Loss: 9564720.000000\n",
      "Train Epoch: 137 [528/918 (58%)] Loss: 6973459.500000\n",
      "Train Epoch: 137 [544/918 (59%)] Loss: 7973980.000000\n",
      "Train Epoch: 137 [560/918 (61%)] Loss: 12257482.000000\n",
      "Train Epoch: 137 [576/918 (63%)] Loss: 6605790.000000\n",
      "Train Epoch: 137 [592/918 (64%)] Loss: 7021347.500000\n",
      "Train Epoch: 137 [608/918 (66%)] Loss: 8405165.000000\n",
      "Train Epoch: 137 [624/918 (68%)] Loss: 11124628.000000\n",
      "Train Epoch: 137 [640/918 (70%)] Loss: 7026388.000000\n",
      "Train Epoch: 137 [656/918 (71%)] Loss: 11698400.000000\n",
      "Train Epoch: 137 [672/918 (73%)] Loss: 6853337.500000\n",
      "Train Epoch: 137 [688/918 (75%)] Loss: 5654886.000000\n",
      "Train Epoch: 137 [704/918 (77%)] Loss: 14189845.000000\n",
      "Train Epoch: 137 [720/918 (78%)] Loss: 8242360.000000\n",
      "Train Epoch: 137 [736/918 (80%)] Loss: 11007466.000000\n",
      "Train Epoch: 137 [752/918 (82%)] Loss: 8301629.000000\n",
      "Train Epoch: 137 [768/918 (84%)] Loss: 7825354.500000\n",
      "Train Epoch: 137 [784/918 (85%)] Loss: 8722277.000000\n",
      "Train Epoch: 137 [800/918 (87%)] Loss: 13407275.000000\n",
      "Train Epoch: 137 [816/918 (89%)] Loss: 9681491.000000\n",
      "Train Epoch: 137 [832/918 (91%)] Loss: 7104245.000000\n",
      "Train Epoch: 137 [848/918 (92%)] Loss: 7203638.500000\n",
      "Train Epoch: 137 [864/918 (94%)] Loss: 12097706.000000\n",
      "Train Epoch: 137 [880/918 (96%)] Loss: 9072018.000000\n",
      "Train Epoch: 137 [896/918 (98%)] Loss: 6739719.500000\n",
      "Train Epoch: 137 [912/918 (99%)] Loss: 8677129.000000\n",
      "    epoch          : 137\n",
      "    loss           : 9160118.217391305\n",
      "    ess            : 7.6889501343602715\n",
      "    log_marginal   : -9160115.795652173\n",
      "    val_loss       : 9000881.346153846\n",
      "    val_ess        : 10.832882110889141\n",
      "    val_log_marginal: -9000879.038461538\n",
      "Train Epoch: 138 [0/918 (0%)] Loss: 10568327.000000\n",
      "Train Epoch: 138 [16/918 (2%)] Loss: 7383121.500000\n",
      "Train Epoch: 138 [32/918 (3%)] Loss: 12838408.000000\n",
      "Train Epoch: 138 [48/918 (5%)] Loss: 10637288.000000\n",
      "Train Epoch: 138 [64/918 (7%)] Loss: 6610370.500000\n",
      "Train Epoch: 138 [80/918 (9%)] Loss: 9384442.000000\n",
      "Train Epoch: 138 [96/918 (10%)] Loss: 10297929.000000\n",
      "Train Epoch: 138 [112/918 (12%)] Loss: 14448951.000000\n",
      "Train Epoch: 138 [128/918 (14%)] Loss: 8785996.000000\n",
      "Train Epoch: 138 [144/918 (16%)] Loss: 8658675.000000\n",
      "Train Epoch: 138 [160/918 (17%)] Loss: 7411593.000000\n",
      "Train Epoch: 138 [176/918 (19%)] Loss: 7412901.000000\n",
      "Train Epoch: 138 [192/918 (21%)] Loss: 10417640.000000\n",
      "Train Epoch: 138 [208/918 (23%)] Loss: 9186250.000000\n",
      "Train Epoch: 138 [224/918 (24%)] Loss: 7384459.500000\n",
      "Train Epoch: 138 [240/918 (26%)] Loss: 13699167.000000\n",
      "Train Epoch: 138 [256/918 (28%)] Loss: 7749608.000000\n",
      "Train Epoch: 138 [272/918 (30%)] Loss: 10738725.000000\n",
      "Train Epoch: 138 [288/918 (31%)] Loss: 9226562.000000\n",
      "Train Epoch: 138 [304/918 (33%)] Loss: 9694531.000000\n",
      "Train Epoch: 138 [320/918 (35%)] Loss: 7279072.000000\n",
      "Train Epoch: 138 [336/918 (37%)] Loss: 9711528.000000\n",
      "Train Epoch: 138 [352/918 (38%)] Loss: 10201313.000000\n",
      "Train Epoch: 138 [368/918 (40%)] Loss: 11743240.000000\n",
      "Train Epoch: 138 [384/918 (42%)] Loss: 6326440.500000\n",
      "Train Epoch: 138 [400/918 (44%)] Loss: 8379864.000000\n",
      "Train Epoch: 138 [416/918 (45%)] Loss: 10316767.000000\n",
      "Train Epoch: 138 [432/918 (47%)] Loss: 7296528.000000\n",
      "Train Epoch: 138 [448/918 (49%)] Loss: 7023366.500000\n",
      "Train Epoch: 138 [464/918 (51%)] Loss: 11898779.000000\n",
      "Train Epoch: 138 [480/918 (52%)] Loss: 8633008.000000\n",
      "Train Epoch: 138 [496/918 (54%)] Loss: 10020378.000000\n",
      "Train Epoch: 138 [512/918 (56%)] Loss: 6788651.500000\n",
      "Train Epoch: 138 [528/918 (58%)] Loss: 9616389.000000\n",
      "Train Epoch: 138 [544/918 (59%)] Loss: 9526064.000000\n",
      "Train Epoch: 138 [560/918 (61%)] Loss: 10823674.000000\n",
      "Train Epoch: 138 [576/918 (63%)] Loss: 7068108.000000\n",
      "Train Epoch: 138 [592/918 (64%)] Loss: 6772524.000000\n",
      "Train Epoch: 138 [608/918 (66%)] Loss: 10689131.000000\n",
      "Train Epoch: 138 [624/918 (68%)] Loss: 9345423.000000\n",
      "Train Epoch: 138 [640/918 (70%)] Loss: 12939559.000000\n",
      "Train Epoch: 138 [656/918 (71%)] Loss: 7129451.500000\n",
      "Train Epoch: 138 [672/918 (73%)] Loss: 13194515.000000\n",
      "Train Epoch: 138 [688/918 (75%)] Loss: 9391559.000000\n",
      "Train Epoch: 138 [704/918 (77%)] Loss: 5837314.500000\n",
      "Train Epoch: 138 [720/918 (78%)] Loss: 7746557.000000\n",
      "Train Epoch: 138 [736/918 (80%)] Loss: 8141648.000000\n",
      "Train Epoch: 138 [752/918 (82%)] Loss: 5151473.000000\n",
      "Train Epoch: 138 [768/918 (84%)] Loss: 10386791.000000\n",
      "Train Epoch: 138 [784/918 (85%)] Loss: 16963168.000000\n",
      "Train Epoch: 138 [800/918 (87%)] Loss: 5943367.000000\n",
      "Train Epoch: 138 [816/918 (89%)] Loss: 13219877.000000\n",
      "Train Epoch: 138 [832/918 (91%)] Loss: 8603672.000000\n",
      "Train Epoch: 138 [848/918 (92%)] Loss: 8367677.000000\n",
      "Train Epoch: 138 [864/918 (94%)] Loss: 8780607.000000\n",
      "Train Epoch: 138 [880/918 (96%)] Loss: 8790131.000000\n",
      "Train Epoch: 138 [896/918 (98%)] Loss: 6994811.500000\n",
      "Train Epoch: 138 [912/918 (99%)] Loss: 10761858.000000\n",
      "    epoch          : 138\n",
      "    loss           : 9228836.886956522\n",
      "    ess            : 8.667171828643136\n",
      "    log_marginal   : -9228835.239130436\n",
      "    val_loss       : 8253966.692307692\n",
      "    val_ess        : 6.10992692067073\n",
      "    val_log_marginal: -8253963.538461538\n",
      "Train Epoch: 139 [0/918 (0%)] Loss: 7940466.500000\n",
      "Train Epoch: 139 [16/918 (2%)] Loss: 6185992.000000\n",
      "Train Epoch: 139 [32/918 (3%)] Loss: 6825670.500000\n",
      "Train Epoch: 139 [48/918 (5%)] Loss: 7748345.000000\n",
      "Train Epoch: 139 [64/918 (7%)] Loss: 6515332.500000\n",
      "Train Epoch: 139 [80/918 (9%)] Loss: 6785645.000000\n",
      "Train Epoch: 139 [96/918 (10%)] Loss: 8912677.000000\n",
      "Train Epoch: 139 [112/918 (12%)] Loss: 7747931.500000\n",
      "Train Epoch: 139 [128/918 (14%)] Loss: 14677616.000000\n",
      "Train Epoch: 139 [144/918 (16%)] Loss: 7844401.500000\n",
      "Train Epoch: 139 [160/918 (17%)] Loss: 6695419.500000\n",
      "Train Epoch: 139 [176/918 (19%)] Loss: 7927139.500000\n",
      "Train Epoch: 139 [192/918 (21%)] Loss: 10492521.000000\n",
      "Train Epoch: 139 [208/918 (23%)] Loss: 7357195.500000\n",
      "Train Epoch: 139 [224/918 (24%)] Loss: 12076592.000000\n",
      "Train Epoch: 139 [240/918 (26%)] Loss: 9660758.000000\n",
      "Train Epoch: 139 [256/918 (28%)] Loss: 6650395.500000\n",
      "Train Epoch: 139 [272/918 (30%)] Loss: 14767223.000000\n",
      "Train Epoch: 139 [288/918 (31%)] Loss: 7459363.500000\n",
      "Train Epoch: 139 [304/918 (33%)] Loss: 13026557.000000\n",
      "Train Epoch: 139 [320/918 (35%)] Loss: 6478253.500000\n",
      "Train Epoch: 139 [336/918 (37%)] Loss: 7104006.500000\n",
      "Train Epoch: 139 [352/918 (38%)] Loss: 7546966.500000\n",
      "Train Epoch: 139 [368/918 (40%)] Loss: 6968558.500000\n",
      "Train Epoch: 139 [384/918 (42%)] Loss: 5859357.000000\n",
      "Train Epoch: 139 [400/918 (44%)] Loss: 5834540.500000\n",
      "Train Epoch: 139 [416/918 (45%)] Loss: 14040637.000000\n",
      "Train Epoch: 139 [432/918 (47%)] Loss: 8419783.000000\n",
      "Train Epoch: 139 [448/918 (49%)] Loss: 7647182.500000\n",
      "Train Epoch: 139 [464/918 (51%)] Loss: 11795543.000000\n",
      "Train Epoch: 139 [480/918 (52%)] Loss: 9875397.000000\n",
      "Train Epoch: 139 [496/918 (54%)] Loss: 10164248.000000\n",
      "Train Epoch: 139 [512/918 (56%)] Loss: 13455339.000000\n",
      "Train Epoch: 139 [528/918 (58%)] Loss: 8301745.000000\n",
      "Train Epoch: 139 [544/918 (59%)] Loss: 7083414.500000\n",
      "Train Epoch: 139 [560/918 (61%)] Loss: 9021643.000000\n",
      "Train Epoch: 139 [576/918 (63%)] Loss: 11698427.000000\n",
      "Train Epoch: 139 [592/918 (64%)] Loss: 7680377.500000\n",
      "Train Epoch: 139 [608/918 (66%)] Loss: 8246577.000000\n",
      "Train Epoch: 139 [624/918 (68%)] Loss: 9599176.000000\n",
      "Train Epoch: 139 [640/918 (70%)] Loss: 11010288.000000\n",
      "Train Epoch: 139 [656/918 (71%)] Loss: 11865083.000000\n",
      "Train Epoch: 139 [672/918 (73%)] Loss: 5447888.000000\n",
      "Train Epoch: 139 [688/918 (75%)] Loss: 12687656.000000\n",
      "Train Epoch: 139 [704/918 (77%)] Loss: 9357763.000000\n",
      "Train Epoch: 139 [720/918 (78%)] Loss: 8295497.500000\n",
      "Train Epoch: 139 [736/918 (80%)] Loss: 11391573.000000\n",
      "Train Epoch: 139 [752/918 (82%)] Loss: 11119356.000000\n",
      "Train Epoch: 139 [768/918 (84%)] Loss: 6655385.500000\n",
      "Train Epoch: 139 [784/918 (85%)] Loss: 8412007.000000\n",
      "Train Epoch: 139 [800/918 (87%)] Loss: 7428643.500000\n",
      "Train Epoch: 139 [816/918 (89%)] Loss: 10035860.000000\n",
      "Train Epoch: 139 [832/918 (91%)] Loss: 7546701.500000\n",
      "Train Epoch: 139 [848/918 (92%)] Loss: 8468644.000000\n",
      "Train Epoch: 139 [864/918 (94%)] Loss: 14388544.000000\n",
      "Train Epoch: 139 [880/918 (96%)] Loss: 8189713.500000\n",
      "Train Epoch: 139 [896/918 (98%)] Loss: 5793421.000000\n",
      "Train Epoch: 139 [912/918 (99%)] Loss: 10100650.000000\n",
      "    epoch          : 139\n",
      "    loss           : 9227670.430434782\n",
      "    ess            : 7.790730098019475\n",
      "    log_marginal   : -9227668.695652174\n",
      "    val_loss       : 10334985.538461538\n",
      "    val_ess        : 8.741227920238789\n",
      "    val_log_marginal: -10334983.307692308\n",
      "Train Epoch: 140 [0/918 (0%)] Loss: 15641952.000000\n",
      "Train Epoch: 140 [16/918 (2%)] Loss: 8692669.000000\n",
      "Train Epoch: 140 [32/918 (3%)] Loss: 8472187.000000\n",
      "Train Epoch: 140 [48/918 (5%)] Loss: 7238127.500000\n",
      "Train Epoch: 140 [64/918 (7%)] Loss: 7550321.500000\n",
      "Train Epoch: 140 [80/918 (9%)] Loss: 8967321.000000\n",
      "Train Epoch: 140 [96/918 (10%)] Loss: 8780084.000000\n",
      "Train Epoch: 140 [112/918 (12%)] Loss: 12096611.000000\n",
      "Train Epoch: 140 [128/918 (14%)] Loss: 5887465.500000\n",
      "Train Epoch: 140 [144/918 (16%)] Loss: 9947637.000000\n",
      "Train Epoch: 140 [160/918 (17%)] Loss: 5657103.000000\n",
      "Train Epoch: 140 [176/918 (19%)] Loss: 9148194.000000\n",
      "Train Epoch: 140 [192/918 (21%)] Loss: 9658487.000000\n",
      "Train Epoch: 140 [208/918 (23%)] Loss: 8959343.000000\n",
      "Train Epoch: 140 [224/918 (24%)] Loss: 10058427.000000\n",
      "Train Epoch: 140 [240/918 (26%)] Loss: 15671717.000000\n",
      "Train Epoch: 140 [256/918 (28%)] Loss: 6730732.000000\n",
      "Train Epoch: 140 [272/918 (30%)] Loss: 11573910.000000\n",
      "Train Epoch: 140 [288/918 (31%)] Loss: 9839324.000000\n",
      "Train Epoch: 140 [304/918 (33%)] Loss: 9345112.000000\n",
      "Train Epoch: 140 [320/918 (35%)] Loss: 6249682.500000\n",
      "Train Epoch: 140 [336/918 (37%)] Loss: 12778160.000000\n",
      "Train Epoch: 140 [352/918 (38%)] Loss: 10259454.000000\n",
      "Train Epoch: 140 [368/918 (40%)] Loss: 14419442.000000\n",
      "Train Epoch: 140 [384/918 (42%)] Loss: 12468535.000000\n",
      "Train Epoch: 140 [400/918 (44%)] Loss: 10281496.000000\n",
      "Train Epoch: 140 [416/918 (45%)] Loss: 8544011.000000\n",
      "Train Epoch: 140 [432/918 (47%)] Loss: 9285916.000000\n",
      "Train Epoch: 140 [448/918 (49%)] Loss: 8505460.000000\n",
      "Train Epoch: 140 [464/918 (51%)] Loss: 9738691.000000\n",
      "Train Epoch: 140 [480/918 (52%)] Loss: 7964116.000000\n",
      "Train Epoch: 140 [496/918 (54%)] Loss: 15398419.000000\n",
      "Train Epoch: 140 [512/918 (56%)] Loss: 10788135.000000\n",
      "Train Epoch: 140 [528/918 (58%)] Loss: 11601576.000000\n",
      "Train Epoch: 140 [544/918 (59%)] Loss: 7899953.000000\n",
      "Train Epoch: 140 [560/918 (61%)] Loss: 11024919.000000\n",
      "Train Epoch: 140 [576/918 (63%)] Loss: 9872996.000000\n",
      "Train Epoch: 140 [592/918 (64%)] Loss: 7698216.000000\n",
      "Train Epoch: 140 [608/918 (66%)] Loss: 10857625.000000\n",
      "Train Epoch: 140 [624/918 (68%)] Loss: 7835618.500000\n",
      "Train Epoch: 140 [640/918 (70%)] Loss: 8669701.000000\n",
      "Train Epoch: 140 [656/918 (71%)] Loss: 8367896.000000\n",
      "Train Epoch: 140 [672/918 (73%)] Loss: 10108333.000000\n",
      "Train Epoch: 140 [688/918 (75%)] Loss: 6615497.500000\n",
      "Train Epoch: 140 [704/918 (77%)] Loss: 11240537.000000\n",
      "Train Epoch: 140 [720/918 (78%)] Loss: 9262129.000000\n",
      "Train Epoch: 140 [736/918 (80%)] Loss: 10289074.000000\n",
      "Train Epoch: 140 [752/918 (82%)] Loss: 10073936.000000\n",
      "Train Epoch: 140 [768/918 (84%)] Loss: 5789089.000000\n",
      "Train Epoch: 140 [784/918 (85%)] Loss: 11631613.000000\n",
      "Train Epoch: 140 [800/918 (87%)] Loss: 6840833.500000\n",
      "Train Epoch: 140 [816/918 (89%)] Loss: 9275391.000000\n",
      "Train Epoch: 140 [832/918 (91%)] Loss: 15775219.000000\n",
      "Train Epoch: 140 [848/918 (92%)] Loss: 12663139.000000\n",
      "Train Epoch: 140 [864/918 (94%)] Loss: 11401475.000000\n",
      "Train Epoch: 140 [880/918 (96%)] Loss: 12762837.000000\n",
      "Train Epoch: 140 [896/918 (98%)] Loss: 10571136.000000\n",
      "Train Epoch: 140 [912/918 (99%)] Loss: 6711733.000000\n",
      "    epoch          : 140\n",
      "    loss           : 9302687.013043478\n",
      "    ess            : 7.759808588027954\n",
      "    log_marginal   : -9302684.708695652\n",
      "    val_loss       : 8603912.615384616\n",
      "    val_ess        : 5.924107184776893\n",
      "    val_log_marginal: -8603910.923076924\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch140.pth ...\n",
      "Train Epoch: 141 [0/918 (0%)] Loss: 6442884.000000\n",
      "Train Epoch: 141 [16/918 (2%)] Loss: 9488050.000000\n",
      "Train Epoch: 141 [32/918 (3%)] Loss: 13020286.000000\n",
      "Train Epoch: 141 [48/918 (5%)] Loss: 10232709.000000\n",
      "Train Epoch: 141 [64/918 (7%)] Loss: 6912916.000000\n",
      "Train Epoch: 141 [80/918 (9%)] Loss: 10243247.000000\n",
      "Train Epoch: 141 [96/918 (10%)] Loss: 6451483.500000\n",
      "Train Epoch: 141 [112/918 (12%)] Loss: 7837437.000000\n",
      "Train Epoch: 141 [128/918 (14%)] Loss: 8792807.000000\n",
      "Train Epoch: 141 [144/918 (16%)] Loss: 6829605.000000\n",
      "Train Epoch: 141 [160/918 (17%)] Loss: 11420691.000000\n",
      "Train Epoch: 141 [176/918 (19%)] Loss: 8287990.500000\n",
      "Train Epoch: 141 [192/918 (21%)] Loss: 7983416.000000\n",
      "Train Epoch: 141 [208/918 (23%)] Loss: 9060847.000000\n",
      "Train Epoch: 141 [224/918 (24%)] Loss: 7003303.500000\n",
      "Train Epoch: 141 [240/918 (26%)] Loss: 9453658.000000\n",
      "Train Epoch: 141 [256/918 (28%)] Loss: 6975002.500000\n",
      "Train Epoch: 141 [272/918 (30%)] Loss: 7637013.000000\n",
      "Train Epoch: 141 [288/918 (31%)] Loss: 12076203.000000\n",
      "Train Epoch: 141 [304/918 (33%)] Loss: 9054330.000000\n",
      "Train Epoch: 141 [320/918 (35%)] Loss: 9291189.000000\n",
      "Train Epoch: 141 [336/918 (37%)] Loss: 10686787.000000\n",
      "Train Epoch: 141 [352/918 (38%)] Loss: 8981287.000000\n",
      "Train Epoch: 141 [368/918 (40%)] Loss: 7023691.500000\n",
      "Train Epoch: 141 [384/918 (42%)] Loss: 12275524.000000\n",
      "Train Epoch: 141 [400/918 (44%)] Loss: 9376543.000000\n",
      "Train Epoch: 141 [416/918 (45%)] Loss: 7381587.500000\n",
      "Train Epoch: 141 [432/918 (47%)] Loss: 10612250.000000\n",
      "Train Epoch: 141 [448/918 (49%)] Loss: 11593064.000000\n",
      "Train Epoch: 141 [464/918 (51%)] Loss: 8340129.500000\n",
      "Train Epoch: 141 [480/918 (52%)] Loss: 7993409.500000\n",
      "Train Epoch: 141 [496/918 (54%)] Loss: 8714237.000000\n",
      "Train Epoch: 141 [512/918 (56%)] Loss: 8725256.000000\n",
      "Train Epoch: 141 [528/918 (58%)] Loss: 6377971.000000\n",
      "Train Epoch: 141 [544/918 (59%)] Loss: 7387505.500000\n",
      "Train Epoch: 141 [560/918 (61%)] Loss: 7940425.500000\n",
      "Train Epoch: 141 [576/918 (63%)] Loss: 10215258.000000\n",
      "Train Epoch: 141 [592/918 (64%)] Loss: 8411984.000000\n",
      "Train Epoch: 141 [608/918 (66%)] Loss: 8533441.000000\n",
      "Train Epoch: 141 [624/918 (68%)] Loss: 7074273.000000\n",
      "Train Epoch: 141 [640/918 (70%)] Loss: 7253681.000000\n",
      "Train Epoch: 141 [656/918 (71%)] Loss: 8033626.500000\n",
      "Train Epoch: 141 [672/918 (73%)] Loss: 5707909.000000\n",
      "Train Epoch: 141 [688/918 (75%)] Loss: 11867436.000000\n",
      "Train Epoch: 141 [704/918 (77%)] Loss: 8477331.000000\n",
      "Train Epoch: 141 [720/918 (78%)] Loss: 12198688.000000\n",
      "Train Epoch: 141 [736/918 (80%)] Loss: 7631528.000000\n",
      "Train Epoch: 141 [752/918 (82%)] Loss: 10226827.000000\n",
      "Train Epoch: 141 [768/918 (84%)] Loss: 8981939.000000\n",
      "Train Epoch: 141 [784/918 (85%)] Loss: 7965521.500000\n",
      "Train Epoch: 141 [800/918 (87%)] Loss: 9179885.000000\n",
      "Train Epoch: 141 [816/918 (89%)] Loss: 9022688.000000\n",
      "Train Epoch: 141 [832/918 (91%)] Loss: 12046933.000000\n",
      "Train Epoch: 141 [848/918 (92%)] Loss: 7601939.500000\n",
      "Train Epoch: 141 [864/918 (94%)] Loss: 9773063.000000\n",
      "Train Epoch: 141 [880/918 (96%)] Loss: 8144274.500000\n",
      "Train Epoch: 141 [896/918 (98%)] Loss: 6501150.000000\n",
      "Train Epoch: 141 [912/918 (99%)] Loss: 9054322.000000\n",
      "    epoch          : 141\n",
      "    loss           : 9078645.960869566\n",
      "    ess            : 7.377109477830969\n",
      "    log_marginal   : -9078643.02173913\n",
      "    val_loss       : 9586576.26923077\n",
      "    val_ess        : 6.50275522011977\n",
      "    val_log_marginal: -9586572.384615384\n",
      "Train Epoch: 142 [0/918 (0%)] Loss: 9059359.000000\n",
      "Train Epoch: 142 [16/918 (2%)] Loss: 8120648.000000\n",
      "Train Epoch: 142 [32/918 (3%)] Loss: 7872819.500000\n",
      "Train Epoch: 142 [48/918 (5%)] Loss: 9042604.000000\n",
      "Train Epoch: 142 [64/918 (7%)] Loss: 6678965.500000\n",
      "Train Epoch: 142 [80/918 (9%)] Loss: 8212044.000000\n",
      "Train Epoch: 142 [96/918 (10%)] Loss: 7907457.500000\n",
      "Train Epoch: 142 [112/918 (12%)] Loss: 9028488.000000\n",
      "Train Epoch: 142 [128/918 (14%)] Loss: 7408924.000000\n",
      "Train Epoch: 142 [144/918 (16%)] Loss: 11359358.000000\n",
      "Train Epoch: 142 [160/918 (17%)] Loss: 9941735.000000\n",
      "Train Epoch: 142 [176/918 (19%)] Loss: 9021770.000000\n",
      "Train Epoch: 142 [192/918 (21%)] Loss: 7799585.500000\n",
      "Train Epoch: 142 [208/918 (23%)] Loss: 7020375.500000\n",
      "Train Epoch: 142 [224/918 (24%)] Loss: 11026628.000000\n",
      "Train Epoch: 142 [240/918 (26%)] Loss: 11702731.000000\n",
      "Train Epoch: 142 [256/918 (28%)] Loss: 11380329.000000\n",
      "Train Epoch: 142 [272/918 (30%)] Loss: 12347944.000000\n",
      "Train Epoch: 142 [288/918 (31%)] Loss: 9408650.000000\n",
      "Train Epoch: 142 [304/918 (33%)] Loss: 9124202.000000\n",
      "Train Epoch: 142 [320/918 (35%)] Loss: 8722855.000000\n",
      "Train Epoch: 142 [336/918 (37%)] Loss: 5659145.500000\n",
      "Train Epoch: 142 [352/918 (38%)] Loss: 6926036.000000\n",
      "Train Epoch: 142 [368/918 (40%)] Loss: 11218061.000000\n",
      "Train Epoch: 142 [384/918 (42%)] Loss: 7698862.500000\n",
      "Train Epoch: 142 [400/918 (44%)] Loss: 9023927.000000\n",
      "Train Epoch: 142 [416/918 (45%)] Loss: 14742251.000000\n",
      "Train Epoch: 142 [432/918 (47%)] Loss: 10583666.000000\n",
      "Train Epoch: 142 [448/918 (49%)] Loss: 9707316.000000\n",
      "Train Epoch: 142 [464/918 (51%)] Loss: 8071539.500000\n",
      "Train Epoch: 142 [480/918 (52%)] Loss: 7552610.500000\n",
      "Train Epoch: 142 [496/918 (54%)] Loss: 10731504.000000\n",
      "Train Epoch: 142 [512/918 (56%)] Loss: 7274147.500000\n",
      "Train Epoch: 142 [528/918 (58%)] Loss: 8425382.000000\n",
      "Train Epoch: 142 [544/918 (59%)] Loss: 8576655.000000\n",
      "Train Epoch: 142 [560/918 (61%)] Loss: 10406087.000000\n",
      "Train Epoch: 142 [576/918 (63%)] Loss: 5885429.500000\n",
      "Train Epoch: 142 [592/918 (64%)] Loss: 6835325.000000\n",
      "Train Epoch: 142 [608/918 (66%)] Loss: 14075051.000000\n",
      "Train Epoch: 142 [624/918 (68%)] Loss: 6024467.500000\n",
      "Train Epoch: 142 [640/918 (70%)] Loss: 7970105.500000\n",
      "Train Epoch: 142 [656/918 (71%)] Loss: 8280413.500000\n",
      "Train Epoch: 142 [672/918 (73%)] Loss: 6770800.000000\n",
      "Train Epoch: 142 [688/918 (75%)] Loss: 7884071.500000\n",
      "Train Epoch: 142 [704/918 (77%)] Loss: 8445029.000000\n",
      "Train Epoch: 142 [720/918 (78%)] Loss: 12450299.000000\n",
      "Train Epoch: 142 [736/918 (80%)] Loss: 12141531.000000\n",
      "Train Epoch: 142 [752/918 (82%)] Loss: 8508263.000000\n",
      "Train Epoch: 142 [768/918 (84%)] Loss: 10773997.000000\n",
      "Train Epoch: 142 [784/918 (85%)] Loss: 9331156.000000\n",
      "Train Epoch: 142 [800/918 (87%)] Loss: 8562671.000000\n",
      "Train Epoch: 142 [816/918 (89%)] Loss: 7569571.500000\n",
      "Train Epoch: 142 [832/918 (91%)] Loss: 7094387.500000\n",
      "Train Epoch: 142 [848/918 (92%)] Loss: 9700367.000000\n",
      "Train Epoch: 142 [864/918 (94%)] Loss: 10662844.000000\n",
      "Train Epoch: 142 [880/918 (96%)] Loss: 10393430.000000\n",
      "Train Epoch: 142 [896/918 (98%)] Loss: 5418268.000000\n",
      "Train Epoch: 142 [912/918 (99%)] Loss: 12970595.000000\n",
      "    epoch          : 142\n",
      "    loss           : 8938102.43478261\n",
      "    ess            : 7.61067943158357\n",
      "    log_marginal   : -8938100.204347827\n",
      "    val_loss       : 9354667.26923077\n",
      "    val_ess        : 8.580829216883732\n",
      "    val_log_marginal: -9354665.538461538\n",
      "Train Epoch: 143 [0/918 (0%)] Loss: 7431792.000000\n",
      "Train Epoch: 143 [16/918 (2%)] Loss: 11016165.000000\n",
      "Train Epoch: 143 [32/918 (3%)] Loss: 11949070.000000\n",
      "Train Epoch: 143 [48/918 (5%)] Loss: 8483799.000000\n",
      "Train Epoch: 143 [64/918 (7%)] Loss: 11237464.000000\n",
      "Train Epoch: 143 [80/918 (9%)] Loss: 8765467.000000\n",
      "Train Epoch: 143 [96/918 (10%)] Loss: 6959157.000000\n",
      "Train Epoch: 143 [112/918 (12%)] Loss: 5623595.500000\n",
      "Train Epoch: 143 [128/918 (14%)] Loss: 8565368.000000\n",
      "Train Epoch: 143 [144/918 (16%)] Loss: 14091715.000000\n",
      "Train Epoch: 143 [160/918 (17%)] Loss: 5932147.000000\n",
      "Train Epoch: 143 [176/918 (19%)] Loss: 10048189.000000\n",
      "Train Epoch: 143 [192/918 (21%)] Loss: 6301521.500000\n",
      "Train Epoch: 143 [208/918 (23%)] Loss: 10368978.000000\n",
      "Train Epoch: 143 [224/918 (24%)] Loss: 8448895.000000\n",
      "Train Epoch: 143 [240/918 (26%)] Loss: 6388033.500000\n",
      "Train Epoch: 143 [256/918 (28%)] Loss: 7279885.000000\n",
      "Train Epoch: 143 [272/918 (30%)] Loss: 9027896.000000\n",
      "Train Epoch: 143 [288/918 (31%)] Loss: 7899846.500000\n",
      "Train Epoch: 143 [304/918 (33%)] Loss: 6354250.500000\n",
      "Train Epoch: 143 [320/918 (35%)] Loss: 18524638.000000\n",
      "Train Epoch: 143 [336/918 (37%)] Loss: 6555199.500000\n",
      "Train Epoch: 143 [352/918 (38%)] Loss: 8202939.500000\n",
      "Train Epoch: 143 [368/918 (40%)] Loss: 7272397.000000\n",
      "Train Epoch: 143 [384/918 (42%)] Loss: 8236479.500000\n",
      "Train Epoch: 143 [400/918 (44%)] Loss: 7437472.000000\n",
      "Train Epoch: 143 [416/918 (45%)] Loss: 5416433.500000\n",
      "Train Epoch: 143 [432/918 (47%)] Loss: 9885380.000000\n",
      "Train Epoch: 143 [448/918 (49%)] Loss: 6850577.500000\n",
      "Train Epoch: 143 [464/918 (51%)] Loss: 12673048.000000\n",
      "Train Epoch: 143 [480/918 (52%)] Loss: 8228942.500000\n",
      "Train Epoch: 143 [496/918 (54%)] Loss: 6471840.500000\n",
      "Train Epoch: 143 [512/918 (56%)] Loss: 10649317.000000\n",
      "Train Epoch: 143 [528/918 (58%)] Loss: 8468267.000000\n",
      "Train Epoch: 143 [544/918 (59%)] Loss: 8020226.500000\n",
      "Train Epoch: 143 [560/918 (61%)] Loss: 8032089.500000\n",
      "Train Epoch: 143 [576/918 (63%)] Loss: 7499358.500000\n",
      "Train Epoch: 143 [592/918 (64%)] Loss: 7410876.000000\n",
      "Train Epoch: 143 [608/918 (66%)] Loss: 10690531.000000\n",
      "Train Epoch: 143 [624/918 (68%)] Loss: 9301944.000000\n",
      "Train Epoch: 143 [640/918 (70%)] Loss: 9790067.000000\n",
      "Train Epoch: 143 [656/918 (71%)] Loss: 8749808.000000\n",
      "Train Epoch: 143 [672/918 (73%)] Loss: 5741193.500000\n",
      "Train Epoch: 143 [688/918 (75%)] Loss: 8417802.000000\n",
      "Train Epoch: 143 [704/918 (77%)] Loss: 11308838.000000\n",
      "Train Epoch: 143 [720/918 (78%)] Loss: 6653751.500000\n",
      "Train Epoch: 143 [736/918 (80%)] Loss: 8663861.000000\n",
      "Train Epoch: 143 [752/918 (82%)] Loss: 9208288.000000\n",
      "Train Epoch: 143 [768/918 (84%)] Loss: 16232887.000000\n",
      "Train Epoch: 143 [784/918 (85%)] Loss: 5105988.000000\n",
      "Train Epoch: 143 [800/918 (87%)] Loss: 6576629.500000\n",
      "Train Epoch: 143 [816/918 (89%)] Loss: 5072252.000000\n",
      "Train Epoch: 143 [832/918 (91%)] Loss: 6635257.000000\n",
      "Train Epoch: 143 [848/918 (92%)] Loss: 7430830.500000\n",
      "Train Epoch: 143 [864/918 (94%)] Loss: 11151639.000000\n",
      "Train Epoch: 143 [880/918 (96%)] Loss: 8827845.000000\n",
      "Train Epoch: 143 [896/918 (98%)] Loss: 8245540.000000\n",
      "Train Epoch: 143 [912/918 (99%)] Loss: 16597873.000000\n",
      "    epoch          : 143\n",
      "    loss           : 8988872.456521738\n",
      "    ess            : 7.616482944073884\n",
      "    log_marginal   : -8988869.795652173\n",
      "    val_loss       : 8860393.5\n",
      "    val_ess        : 7.698647334025456\n",
      "    val_log_marginal: -8860391.961538462\n",
      "Train Epoch: 144 [0/918 (0%)] Loss: 7579952.000000\n",
      "Train Epoch: 144 [16/918 (2%)] Loss: 6626258.000000\n",
      "Train Epoch: 144 [32/918 (3%)] Loss: 9420939.000000\n",
      "Train Epoch: 144 [48/918 (5%)] Loss: 8902388.000000\n",
      "Train Epoch: 144 [64/918 (7%)] Loss: 9670586.000000\n",
      "Train Epoch: 144 [80/918 (9%)] Loss: 7531107.500000\n",
      "Train Epoch: 144 [96/918 (10%)] Loss: 6703897.500000\n",
      "Train Epoch: 144 [112/918 (12%)] Loss: 9452392.000000\n",
      "Train Epoch: 144 [128/918 (14%)] Loss: 9542903.000000\n",
      "Train Epoch: 144 [144/918 (16%)] Loss: 10749794.000000\n",
      "Train Epoch: 144 [160/918 (17%)] Loss: 6048689.500000\n",
      "Train Epoch: 144 [176/918 (19%)] Loss: 8267911.500000\n",
      "Train Epoch: 144 [192/918 (21%)] Loss: 19795498.000000\n",
      "Train Epoch: 144 [208/918 (23%)] Loss: 10524237.000000\n",
      "Train Epoch: 144 [224/918 (24%)] Loss: 9017103.000000\n",
      "Train Epoch: 144 [240/918 (26%)] Loss: 8227259.500000\n",
      "Train Epoch: 144 [256/918 (28%)] Loss: 7124061.500000\n",
      "Train Epoch: 144 [272/918 (30%)] Loss: 9218749.000000\n",
      "Train Epoch: 144 [288/918 (31%)] Loss: 5584195.500000\n",
      "Train Epoch: 144 [304/918 (33%)] Loss: 9906671.000000\n",
      "Train Epoch: 144 [320/918 (35%)] Loss: 10911386.000000\n",
      "Train Epoch: 144 [336/918 (37%)] Loss: 7319887.500000\n",
      "Train Epoch: 144 [352/918 (38%)] Loss: 15102055.000000\n",
      "Train Epoch: 144 [368/918 (40%)] Loss: 7555686.500000\n",
      "Train Epoch: 144 [384/918 (42%)] Loss: 7395928.000000\n",
      "Train Epoch: 144 [400/918 (44%)] Loss: 13582941.000000\n",
      "Train Epoch: 144 [416/918 (45%)] Loss: 6191675.000000\n",
      "Train Epoch: 144 [432/918 (47%)] Loss: 15747274.000000\n",
      "Train Epoch: 144 [448/918 (49%)] Loss: 5663258.500000\n",
      "Train Epoch: 144 [464/918 (51%)] Loss: 10324963.000000\n",
      "Train Epoch: 144 [480/918 (52%)] Loss: 11588670.000000\n",
      "Train Epoch: 144 [496/918 (54%)] Loss: 7139709.000000\n",
      "Train Epoch: 144 [512/918 (56%)] Loss: 8396834.000000\n",
      "Train Epoch: 144 [528/918 (58%)] Loss: 8784081.000000\n",
      "Train Epoch: 144 [544/918 (59%)] Loss: 9171771.000000\n",
      "Train Epoch: 144 [560/918 (61%)] Loss: 10716821.000000\n",
      "Train Epoch: 144 [576/918 (63%)] Loss: 9705767.000000\n",
      "Train Epoch: 144 [592/918 (64%)] Loss: 5352231.500000\n",
      "Train Epoch: 144 [608/918 (66%)] Loss: 8289254.500000\n",
      "Train Epoch: 144 [624/918 (68%)] Loss: 9902663.000000\n",
      "Train Epoch: 144 [640/918 (70%)] Loss: 10856898.000000\n",
      "Train Epoch: 144 [656/918 (71%)] Loss: 12249331.000000\n",
      "Train Epoch: 144 [672/918 (73%)] Loss: 6230395.500000\n",
      "Train Epoch: 144 [688/918 (75%)] Loss: 9733059.000000\n",
      "Train Epoch: 144 [704/918 (77%)] Loss: 5132135.500000\n",
      "Train Epoch: 144 [720/918 (78%)] Loss: 8454683.000000\n",
      "Train Epoch: 144 [736/918 (80%)] Loss: 10430241.000000\n",
      "Train Epoch: 144 [752/918 (82%)] Loss: 7973512.000000\n",
      "Train Epoch: 144 [768/918 (84%)] Loss: 6967737.000000\n",
      "Train Epoch: 144 [784/918 (85%)] Loss: 8606087.000000\n",
      "Train Epoch: 144 [800/918 (87%)] Loss: 9632542.000000\n",
      "Train Epoch: 144 [816/918 (89%)] Loss: 8111076.000000\n",
      "Train Epoch: 144 [832/918 (91%)] Loss: 6079287.000000\n",
      "Train Epoch: 144 [848/918 (92%)] Loss: 12203184.000000\n",
      "Train Epoch: 144 [864/918 (94%)] Loss: 11753131.000000\n",
      "Train Epoch: 144 [880/918 (96%)] Loss: 8977267.000000\n",
      "Train Epoch: 144 [896/918 (98%)] Loss: 9056720.000000\n",
      "Train Epoch: 144 [912/918 (99%)] Loss: 10873309.000000\n",
      "    epoch          : 144\n",
      "    loss           : 9062020.2\n",
      "    ess            : 8.672017935047979\n",
      "    log_marginal   : -9062017.882608695\n",
      "    val_loss       : 8888404.576923076\n",
      "    val_ess        : 5.431721613957332\n",
      "    val_log_marginal: -8888402.576923076\n",
      "Train Epoch: 145 [0/918 (0%)] Loss: 6918354.500000\n",
      "Train Epoch: 145 [16/918 (2%)] Loss: 7763500.000000\n",
      "Train Epoch: 145 [32/918 (3%)] Loss: 7518233.500000\n",
      "Train Epoch: 145 [48/918 (5%)] Loss: 11547752.000000\n",
      "Train Epoch: 145 [64/918 (7%)] Loss: 9569909.000000\n",
      "Train Epoch: 145 [80/918 (9%)] Loss: 13521015.000000\n",
      "Train Epoch: 145 [96/918 (10%)] Loss: 10352202.000000\n",
      "Train Epoch: 145 [112/918 (12%)] Loss: 9365350.000000\n",
      "Train Epoch: 145 [128/918 (14%)] Loss: 7617071.500000\n",
      "Train Epoch: 145 [144/918 (16%)] Loss: 7363078.500000\n",
      "Train Epoch: 145 [160/918 (17%)] Loss: 8109116.000000\n",
      "Train Epoch: 145 [176/918 (19%)] Loss: 7295449.000000\n",
      "Train Epoch: 145 [192/918 (21%)] Loss: 9256976.000000\n",
      "Train Epoch: 145 [208/918 (23%)] Loss: 12000863.000000\n",
      "Train Epoch: 145 [224/918 (24%)] Loss: 8578952.000000\n",
      "Train Epoch: 145 [240/918 (26%)] Loss: 11211037.000000\n",
      "Train Epoch: 145 [256/918 (28%)] Loss: 6837885.000000\n",
      "Train Epoch: 145 [272/918 (30%)] Loss: 6819203.500000\n",
      "Train Epoch: 145 [288/918 (31%)] Loss: 7064280.000000\n",
      "Train Epoch: 145 [304/918 (33%)] Loss: 8564641.000000\n",
      "Train Epoch: 145 [320/918 (35%)] Loss: 9060636.000000\n",
      "Train Epoch: 145 [336/918 (37%)] Loss: 13818003.000000\n",
      "Train Epoch: 145 [352/918 (38%)] Loss: 15435234.000000\n",
      "Train Epoch: 145 [368/918 (40%)] Loss: 8483452.000000\n",
      "Train Epoch: 145 [384/918 (42%)] Loss: 12791071.000000\n",
      "Train Epoch: 145 [400/918 (44%)] Loss: 10954740.000000\n",
      "Train Epoch: 145 [416/918 (45%)] Loss: 6905384.000000\n",
      "Train Epoch: 145 [432/918 (47%)] Loss: 6179791.500000\n",
      "Train Epoch: 145 [448/918 (49%)] Loss: 6083260.000000\n",
      "Train Epoch: 145 [464/918 (51%)] Loss: 13008027.000000\n",
      "Train Epoch: 145 [480/918 (52%)] Loss: 5342127.500000\n",
      "Train Epoch: 145 [496/918 (54%)] Loss: 16097146.000000\n",
      "Train Epoch: 145 [512/918 (56%)] Loss: 5337377.000000\n",
      "Train Epoch: 145 [528/918 (58%)] Loss: 8779396.000000\n",
      "Train Epoch: 145 [544/918 (59%)] Loss: 9911898.000000\n",
      "Train Epoch: 145 [560/918 (61%)] Loss: 8128431.500000\n",
      "Train Epoch: 145 [576/918 (63%)] Loss: 9419468.000000\n",
      "Train Epoch: 145 [592/918 (64%)] Loss: 11307531.000000\n",
      "Train Epoch: 145 [608/918 (66%)] Loss: 15503501.000000\n",
      "Train Epoch: 145 [624/918 (68%)] Loss: 10408205.000000\n",
      "Train Epoch: 145 [640/918 (70%)] Loss: 7894861.000000\n",
      "Train Epoch: 145 [656/918 (71%)] Loss: 10152711.000000\n",
      "Train Epoch: 145 [672/918 (73%)] Loss: 7948657.000000\n",
      "Train Epoch: 145 [688/918 (75%)] Loss: 10618270.000000\n",
      "Train Epoch: 145 [704/918 (77%)] Loss: 6897688.000000\n",
      "Train Epoch: 145 [720/918 (78%)] Loss: 9873736.000000\n",
      "Train Epoch: 145 [736/918 (80%)] Loss: 9092312.000000\n",
      "Train Epoch: 145 [752/918 (82%)] Loss: 7071081.000000\n",
      "Train Epoch: 145 [768/918 (84%)] Loss: 7358239.500000\n",
      "Train Epoch: 145 [784/918 (85%)] Loss: 9914552.000000\n",
      "Train Epoch: 145 [800/918 (87%)] Loss: 10401903.000000\n",
      "Train Epoch: 145 [816/918 (89%)] Loss: 16754656.000000\n",
      "Train Epoch: 145 [832/918 (91%)] Loss: 8202072.000000\n",
      "Train Epoch: 145 [848/918 (92%)] Loss: 14826288.000000\n",
      "Train Epoch: 145 [864/918 (94%)] Loss: 9518250.000000\n",
      "Train Epoch: 145 [880/918 (96%)] Loss: 7866360.000000\n",
      "Train Epoch: 145 [896/918 (98%)] Loss: 5741730.500000\n",
      "Train Epoch: 145 [912/918 (99%)] Loss: 10118333.000000\n",
      "    epoch          : 145\n",
      "    loss           : 9428374.482608696\n",
      "    ess            : 8.067719453314076\n",
      "    log_marginal   : -9428371.395652173\n",
      "    val_loss       : 9555412.884615384\n",
      "    val_ess        : 5.5773979883927565\n",
      "    val_log_marginal: -9555411.26923077\n",
      "Train Epoch: 146 [0/918 (0%)] Loss: 9570608.000000\n",
      "Train Epoch: 146 [16/918 (2%)] Loss: 9826248.000000\n",
      "Train Epoch: 146 [32/918 (3%)] Loss: 8917992.000000\n",
      "Train Epoch: 146 [48/918 (5%)] Loss: 12102216.000000\n",
      "Train Epoch: 146 [64/918 (7%)] Loss: 8849645.000000\n",
      "Train Epoch: 146 [80/918 (9%)] Loss: 8012175.500000\n",
      "Train Epoch: 146 [96/918 (10%)] Loss: 7312065.500000\n",
      "Train Epoch: 146 [112/918 (12%)] Loss: 11604074.000000\n",
      "Train Epoch: 146 [128/918 (14%)] Loss: 11755739.000000\n",
      "Train Epoch: 146 [144/918 (16%)] Loss: 7887575.500000\n",
      "Train Epoch: 146 [160/918 (17%)] Loss: 10201144.000000\n",
      "Train Epoch: 146 [176/918 (19%)] Loss: 12711771.000000\n",
      "Train Epoch: 146 [192/918 (21%)] Loss: 10047906.000000\n",
      "Train Epoch: 146 [208/918 (23%)] Loss: 7520080.000000\n",
      "Train Epoch: 146 [224/918 (24%)] Loss: 8613067.000000\n",
      "Train Epoch: 146 [240/918 (26%)] Loss: 6414679.500000\n",
      "Train Epoch: 146 [256/918 (28%)] Loss: 5286325.000000\n",
      "Train Epoch: 146 [272/918 (30%)] Loss: 6819835.500000\n",
      "Train Epoch: 146 [288/918 (31%)] Loss: 6733660.000000\n",
      "Train Epoch: 146 [304/918 (33%)] Loss: 8192222.500000\n",
      "Train Epoch: 146 [320/918 (35%)] Loss: 10118759.000000\n",
      "Train Epoch: 146 [336/918 (37%)] Loss: 11610192.000000\n",
      "Train Epoch: 146 [352/918 (38%)] Loss: 6138618.500000\n",
      "Train Epoch: 146 [368/918 (40%)] Loss: 6187893.500000\n",
      "Train Epoch: 146 [384/918 (42%)] Loss: 8711012.000000\n",
      "Train Epoch: 146 [400/918 (44%)] Loss: 10283439.000000\n",
      "Train Epoch: 146 [416/918 (45%)] Loss: 6539346.500000\n",
      "Train Epoch: 146 [432/918 (47%)] Loss: 6869101.000000\n",
      "Train Epoch: 146 [448/918 (49%)] Loss: 13822319.000000\n",
      "Train Epoch: 146 [464/918 (51%)] Loss: 11016188.000000\n",
      "Train Epoch: 146 [480/918 (52%)] Loss: 9413259.000000\n",
      "Train Epoch: 146 [496/918 (54%)] Loss: 7493352.000000\n",
      "Train Epoch: 146 [512/918 (56%)] Loss: 6925770.500000\n",
      "Train Epoch: 146 [528/918 (58%)] Loss: 9142129.000000\n",
      "Train Epoch: 146 [544/918 (59%)] Loss: 10956567.000000\n",
      "Train Epoch: 146 [560/918 (61%)] Loss: 5979347.000000\n",
      "Train Epoch: 146 [576/918 (63%)] Loss: 5935240.500000\n",
      "Train Epoch: 146 [592/918 (64%)] Loss: 7237153.000000\n",
      "Train Epoch: 146 [608/918 (66%)] Loss: 8590522.000000\n",
      "Train Epoch: 146 [624/918 (68%)] Loss: 8673968.000000\n",
      "Train Epoch: 146 [640/918 (70%)] Loss: 13045766.000000\n",
      "Train Epoch: 146 [656/918 (71%)] Loss: 8011701.500000\n",
      "Train Epoch: 146 [672/918 (73%)] Loss: 8432578.000000\n",
      "Train Epoch: 146 [688/918 (75%)] Loss: 11389915.000000\n",
      "Train Epoch: 146 [704/918 (77%)] Loss: 9854528.000000\n",
      "Train Epoch: 146 [720/918 (78%)] Loss: 6168777.000000\n",
      "Train Epoch: 146 [736/918 (80%)] Loss: 11336285.000000\n",
      "Train Epoch: 146 [752/918 (82%)] Loss: 7276222.500000\n",
      "Train Epoch: 146 [768/918 (84%)] Loss: 9081135.000000\n",
      "Train Epoch: 146 [784/918 (85%)] Loss: 6157754.500000\n",
      "Train Epoch: 146 [800/918 (87%)] Loss: 9849157.000000\n",
      "Train Epoch: 146 [816/918 (89%)] Loss: 7547869.000000\n",
      "Train Epoch: 146 [832/918 (91%)] Loss: 8643543.000000\n",
      "Train Epoch: 146 [848/918 (92%)] Loss: 9058906.000000\n",
      "Train Epoch: 146 [864/918 (94%)] Loss: 8747725.000000\n",
      "Train Epoch: 146 [880/918 (96%)] Loss: 6411646.500000\n",
      "Train Epoch: 146 [896/918 (98%)] Loss: 8301322.500000\n",
      "Train Epoch: 146 [912/918 (99%)] Loss: 10631661.000000\n",
      "    epoch          : 146\n",
      "    loss           : 8761043.247826086\n",
      "    ess            : 7.853801673391591\n",
      "    log_marginal   : -8761040.991304347\n",
      "    val_loss       : 9293797.576923076\n",
      "    val_ess        : 8.391120782265297\n",
      "    val_log_marginal: -9293795.115384616\n",
      "Train Epoch: 147 [0/918 (0%)] Loss: 6394212.000000\n",
      "Train Epoch: 147 [16/918 (2%)] Loss: 9641071.000000\n",
      "Train Epoch: 147 [32/918 (3%)] Loss: 8344872.000000\n",
      "Train Epoch: 147 [48/918 (5%)] Loss: 7156833.500000\n",
      "Train Epoch: 147 [64/918 (7%)] Loss: 10407003.000000\n",
      "Train Epoch: 147 [80/918 (9%)] Loss: 9081886.000000\n",
      "Train Epoch: 147 [96/918 (10%)] Loss: 14463933.000000\n",
      "Train Epoch: 147 [112/918 (12%)] Loss: 7670658.500000\n",
      "Train Epoch: 147 [128/918 (14%)] Loss: 10193995.000000\n",
      "Train Epoch: 147 [144/918 (16%)] Loss: 10913388.000000\n",
      "Train Epoch: 147 [160/918 (17%)] Loss: 6097385.500000\n",
      "Train Epoch: 147 [176/918 (19%)] Loss: 5601377.000000\n",
      "Train Epoch: 147 [192/918 (21%)] Loss: 5673768.000000\n",
      "Train Epoch: 147 [208/918 (23%)] Loss: 4568853.500000\n",
      "Train Epoch: 147 [224/918 (24%)] Loss: 6092916.500000\n",
      "Train Epoch: 147 [240/918 (26%)] Loss: 4918352.000000\n",
      "Train Epoch: 147 [256/918 (28%)] Loss: 7087105.500000\n",
      "Train Epoch: 147 [272/918 (30%)] Loss: 6842369.500000\n",
      "Train Epoch: 147 [288/918 (31%)] Loss: 8207365.000000\n",
      "Train Epoch: 147 [304/918 (33%)] Loss: 12692912.000000\n",
      "Train Epoch: 147 [320/918 (35%)] Loss: 6145674.500000\n",
      "Train Epoch: 147 [336/918 (37%)] Loss: 7000230.500000\n",
      "Train Epoch: 147 [352/918 (38%)] Loss: 8084857.500000\n",
      "Train Epoch: 147 [368/918 (40%)] Loss: 14789299.000000\n",
      "Train Epoch: 147 [384/918 (42%)] Loss: 7204268.000000\n",
      "Train Epoch: 147 [400/918 (44%)] Loss: 11327574.000000\n",
      "Train Epoch: 147 [416/918 (45%)] Loss: 7702427.500000\n",
      "Train Epoch: 147 [432/918 (47%)] Loss: 10564146.000000\n",
      "Train Epoch: 147 [448/918 (49%)] Loss: 9402327.000000\n",
      "Train Epoch: 147 [464/918 (51%)] Loss: 16121629.000000\n",
      "Train Epoch: 147 [480/918 (52%)] Loss: 12064856.000000\n",
      "Train Epoch: 147 [496/918 (54%)] Loss: 9731491.000000\n",
      "Train Epoch: 147 [512/918 (56%)] Loss: 7611609.500000\n",
      "Train Epoch: 147 [528/918 (58%)] Loss: 9125324.000000\n",
      "Train Epoch: 147 [544/918 (59%)] Loss: 8867274.000000\n",
      "Train Epoch: 147 [560/918 (61%)] Loss: 9451850.000000\n",
      "Train Epoch: 147 [576/918 (63%)] Loss: 9010143.000000\n",
      "Train Epoch: 147 [592/918 (64%)] Loss: 4499124.000000\n",
      "Train Epoch: 147 [608/918 (66%)] Loss: 10216613.000000\n",
      "Train Epoch: 147 [624/918 (68%)] Loss: 7667952.000000\n",
      "Train Epoch: 147 [640/918 (70%)] Loss: 7552575.500000\n",
      "Train Epoch: 147 [656/918 (71%)] Loss: 7045993.500000\n",
      "Train Epoch: 147 [672/918 (73%)] Loss: 6705676.000000\n",
      "Train Epoch: 147 [688/918 (75%)] Loss: 9944319.000000\n",
      "Train Epoch: 147 [704/918 (77%)] Loss: 7131936.000000\n",
      "Train Epoch: 147 [720/918 (78%)] Loss: 12342710.000000\n",
      "Train Epoch: 147 [736/918 (80%)] Loss: 10097072.000000\n",
      "Train Epoch: 147 [752/918 (82%)] Loss: 9290685.000000\n",
      "Train Epoch: 147 [768/918 (84%)] Loss: 11066931.000000\n",
      "Train Epoch: 147 [784/918 (85%)] Loss: 10318666.000000\n",
      "Train Epoch: 147 [800/918 (87%)] Loss: 9289219.000000\n",
      "Train Epoch: 147 [816/918 (89%)] Loss: 5811355.500000\n",
      "Train Epoch: 147 [832/918 (91%)] Loss: 7457817.000000\n",
      "Train Epoch: 147 [848/918 (92%)] Loss: 8882127.000000\n",
      "Train Epoch: 147 [864/918 (94%)] Loss: 10082863.000000\n",
      "Train Epoch: 147 [880/918 (96%)] Loss: 13022446.000000\n",
      "Train Epoch: 147 [896/918 (98%)] Loss: 9550290.000000\n",
      "Train Epoch: 147 [912/918 (99%)] Loss: 8156782.500000\n",
      "    epoch          : 147\n",
      "    loss           : 8872912.1\n",
      "    ess            : 7.9772825572801676\n",
      "    log_marginal   : -8872908.413043479\n",
      "    val_loss       : 9795074.807692308\n",
      "    val_ess        : 8.441674654300396\n",
      "    val_log_marginal: -9795073.884615384\n",
      "Train Epoch: 148 [0/918 (0%)] Loss: 5290532.500000\n",
      "Train Epoch: 148 [16/918 (2%)] Loss: 10147713.000000\n",
      "Train Epoch: 148 [32/918 (3%)] Loss: 7867537.500000\n",
      "Train Epoch: 148 [48/918 (5%)] Loss: 5676116.000000\n",
      "Train Epoch: 148 [64/918 (7%)] Loss: 8974093.000000\n",
      "Train Epoch: 148 [80/918 (9%)] Loss: 10924711.000000\n",
      "Train Epoch: 148 [96/918 (10%)] Loss: 9366711.000000\n",
      "Train Epoch: 148 [112/918 (12%)] Loss: 7444230.500000\n",
      "Train Epoch: 148 [128/918 (14%)] Loss: 8079413.500000\n",
      "Train Epoch: 148 [144/918 (16%)] Loss: 15426586.000000\n",
      "Train Epoch: 148 [160/918 (17%)] Loss: 9733602.000000\n",
      "Train Epoch: 148 [176/918 (19%)] Loss: 8511070.000000\n",
      "Train Epoch: 148 [192/918 (21%)] Loss: 10339381.000000\n",
      "Train Epoch: 148 [208/918 (23%)] Loss: 13520311.000000\n",
      "Train Epoch: 148 [224/918 (24%)] Loss: 5865801.500000\n",
      "Train Epoch: 148 [240/918 (26%)] Loss: 7321789.000000\n",
      "Train Epoch: 148 [256/918 (28%)] Loss: 9537599.000000\n",
      "Train Epoch: 148 [272/918 (30%)] Loss: 10282629.000000\n",
      "Train Epoch: 148 [288/918 (31%)] Loss: 7770129.500000\n",
      "Train Epoch: 148 [304/918 (33%)] Loss: 10228469.000000\n",
      "Train Epoch: 148 [320/918 (35%)] Loss: 9854353.000000\n",
      "Train Epoch: 148 [336/918 (37%)] Loss: 9404312.000000\n",
      "Train Epoch: 148 [352/918 (38%)] Loss: 17761198.000000\n",
      "Train Epoch: 148 [368/918 (40%)] Loss: 8852351.000000\n",
      "Train Epoch: 148 [384/918 (42%)] Loss: 5427693.500000\n",
      "Train Epoch: 148 [400/918 (44%)] Loss: 10090814.000000\n",
      "Train Epoch: 148 [416/918 (45%)] Loss: 15236263.000000\n",
      "Train Epoch: 148 [432/918 (47%)] Loss: 9078189.000000\n",
      "Train Epoch: 148 [448/918 (49%)] Loss: 9248183.000000\n",
      "Train Epoch: 148 [464/918 (51%)] Loss: 7825718.500000\n",
      "Train Epoch: 148 [480/918 (52%)] Loss: 10966440.000000\n",
      "Train Epoch: 148 [496/918 (54%)] Loss: 9702983.000000\n",
      "Train Epoch: 148 [512/918 (56%)] Loss: 9917820.000000\n",
      "Train Epoch: 148 [528/918 (58%)] Loss: 6640470.000000\n",
      "Train Epoch: 148 [544/918 (59%)] Loss: 10408994.000000\n",
      "Train Epoch: 148 [560/918 (61%)] Loss: 7909542.500000\n",
      "Train Epoch: 148 [576/918 (63%)] Loss: 5040624.000000\n",
      "Train Epoch: 148 [592/918 (64%)] Loss: 12084091.000000\n",
      "Train Epoch: 148 [608/918 (66%)] Loss: 6471946.500000\n",
      "Train Epoch: 148 [624/918 (68%)] Loss: 7187814.500000\n",
      "Train Epoch: 148 [640/918 (70%)] Loss: 7104758.500000\n",
      "Train Epoch: 148 [656/918 (71%)] Loss: 7086216.000000\n",
      "Train Epoch: 148 [672/918 (73%)] Loss: 9932876.000000\n",
      "Train Epoch: 148 [688/918 (75%)] Loss: 9481848.000000\n",
      "Train Epoch: 148 [704/918 (77%)] Loss: 6434057.000000\n",
      "Train Epoch: 148 [720/918 (78%)] Loss: 11521073.000000\n",
      "Train Epoch: 148 [736/918 (80%)] Loss: 8765634.000000\n",
      "Train Epoch: 148 [752/918 (82%)] Loss: 10276035.000000\n",
      "Train Epoch: 148 [768/918 (84%)] Loss: 8068281.500000\n",
      "Train Epoch: 148 [784/918 (85%)] Loss: 5490322.000000\n",
      "Train Epoch: 148 [800/918 (87%)] Loss: 5191909.000000\n",
      "Train Epoch: 148 [816/918 (89%)] Loss: 7003611.500000\n",
      "Train Epoch: 148 [832/918 (91%)] Loss: 8336929.500000\n",
      "Train Epoch: 148 [848/918 (92%)] Loss: 11399344.000000\n",
      "Train Epoch: 148 [864/918 (94%)] Loss: 8360601.500000\n",
      "Train Epoch: 148 [880/918 (96%)] Loss: 6206140.500000\n",
      "Train Epoch: 148 [896/918 (98%)] Loss: 5913053.500000\n",
      "Train Epoch: 148 [912/918 (99%)] Loss: 6643285.500000\n",
      "    epoch          : 148\n",
      "    loss           : 9170304.830434782\n",
      "    ess            : 7.9183388088060465\n",
      "    log_marginal   : -9170302.373913044\n",
      "    val_loss       : 8971106.0\n",
      "    val_ess        : 7.600907747562115\n",
      "    val_log_marginal: -8971102.923076924\n",
      "Train Epoch: 149 [0/918 (0%)] Loss: 11230659.000000\n",
      "Train Epoch: 149 [16/918 (2%)] Loss: 7776873.500000\n",
      "Train Epoch: 149 [32/918 (3%)] Loss: 7962793.000000\n",
      "Train Epoch: 149 [48/918 (5%)] Loss: 5021600.000000\n",
      "Train Epoch: 149 [64/918 (7%)] Loss: 9558256.000000\n",
      "Train Epoch: 149 [80/918 (9%)] Loss: 11561227.000000\n",
      "Train Epoch: 149 [96/918 (10%)] Loss: 10972796.000000\n",
      "Train Epoch: 149 [112/918 (12%)] Loss: 10471941.000000\n",
      "Train Epoch: 149 [128/918 (14%)] Loss: 13484663.000000\n",
      "Train Epoch: 149 [144/918 (16%)] Loss: 9283293.000000\n",
      "Train Epoch: 149 [160/918 (17%)] Loss: 7926569.500000\n",
      "Train Epoch: 149 [176/918 (19%)] Loss: 7563515.500000\n",
      "Train Epoch: 149 [192/918 (21%)] Loss: 7775625.500000\n",
      "Train Epoch: 149 [208/918 (23%)] Loss: 6427566.000000\n",
      "Train Epoch: 149 [224/918 (24%)] Loss: 10421546.000000\n",
      "Train Epoch: 149 [240/918 (26%)] Loss: 9089111.000000\n",
      "Train Epoch: 149 [256/918 (28%)] Loss: 5151721.000000\n",
      "Train Epoch: 149 [272/918 (30%)] Loss: 8482874.000000\n",
      "Train Epoch: 149 [288/918 (31%)] Loss: 7700598.500000\n",
      "Train Epoch: 149 [304/918 (33%)] Loss: 6985773.000000\n",
      "Train Epoch: 149 [320/918 (35%)] Loss: 7341937.500000\n",
      "Train Epoch: 149 [336/918 (37%)] Loss: 10981200.000000\n",
      "Train Epoch: 149 [352/918 (38%)] Loss: 14359443.000000\n",
      "Train Epoch: 149 [368/918 (40%)] Loss: 7396487.500000\n",
      "Train Epoch: 149 [384/918 (42%)] Loss: 11008067.000000\n",
      "Train Epoch: 149 [400/918 (44%)] Loss: 15363247.000000\n",
      "Train Epoch: 149 [416/918 (45%)] Loss: 9669908.000000\n",
      "Train Epoch: 149 [432/918 (47%)] Loss: 4872515.500000\n",
      "Train Epoch: 149 [448/918 (49%)] Loss: 8959899.000000\n",
      "Train Epoch: 149 [464/918 (51%)] Loss: 10041703.000000\n",
      "Train Epoch: 149 [480/918 (52%)] Loss: 6238918.500000\n",
      "Train Epoch: 149 [496/918 (54%)] Loss: 11313463.000000\n",
      "Train Epoch: 149 [512/918 (56%)] Loss: 9509687.000000\n",
      "Train Epoch: 149 [528/918 (58%)] Loss: 7686654.500000\n",
      "Train Epoch: 149 [544/918 (59%)] Loss: 8870824.000000\n",
      "Train Epoch: 149 [560/918 (61%)] Loss: 18620000.000000\n",
      "Train Epoch: 149 [576/918 (63%)] Loss: 5880341.500000\n",
      "Train Epoch: 149 [592/918 (64%)] Loss: 4885961.500000\n",
      "Train Epoch: 149 [608/918 (66%)] Loss: 16648807.000000\n",
      "Train Epoch: 149 [624/918 (68%)] Loss: 6397299.000000\n",
      "Train Epoch: 149 [640/918 (70%)] Loss: 9153835.000000\n",
      "Train Epoch: 149 [656/918 (71%)] Loss: 9003403.000000\n",
      "Train Epoch: 149 [672/918 (73%)] Loss: 5579843.500000\n",
      "Train Epoch: 149 [688/918 (75%)] Loss: 10847278.000000\n",
      "Train Epoch: 149 [704/918 (77%)] Loss: 10204728.000000\n",
      "Train Epoch: 149 [720/918 (78%)] Loss: 12544971.000000\n",
      "Train Epoch: 149 [736/918 (80%)] Loss: 9736345.000000\n",
      "Train Epoch: 149 [752/918 (82%)] Loss: 8531920.000000\n",
      "Train Epoch: 149 [768/918 (84%)] Loss: 9296311.000000\n",
      "Train Epoch: 149 [784/918 (85%)] Loss: 6814017.500000\n",
      "Train Epoch: 149 [800/918 (87%)] Loss: 5520901.500000\n",
      "Train Epoch: 149 [816/918 (89%)] Loss: 5437748.500000\n",
      "Train Epoch: 149 [832/918 (91%)] Loss: 7938512.000000\n",
      "Train Epoch: 149 [848/918 (92%)] Loss: 11719490.000000\n",
      "Train Epoch: 149 [864/918 (94%)] Loss: 7419453.500000\n",
      "Train Epoch: 149 [880/918 (96%)] Loss: 6639767.000000\n",
      "Train Epoch: 149 [896/918 (98%)] Loss: 10046192.000000\n",
      "Train Epoch: 149 [912/918 (99%)] Loss: 6599221.500000\n",
      "    epoch          : 149\n",
      "    loss           : 8823862.3\n",
      "    ess            : 7.833320010226706\n",
      "    log_marginal   : -8823860.369565217\n",
      "    val_loss       : 9406905.26923077\n",
      "    val_ess        : 7.946229201096755\n",
      "    val_log_marginal: -9406901.576923076\n",
      "Train Epoch: 150 [0/918 (0%)] Loss: 7150292.000000\n",
      "Train Epoch: 150 [16/918 (2%)] Loss: 9563002.000000\n",
      "Train Epoch: 150 [32/918 (3%)] Loss: 10249910.000000\n",
      "Train Epoch: 150 [48/918 (5%)] Loss: 6039373.000000\n",
      "Train Epoch: 150 [64/918 (7%)] Loss: 14506189.000000\n",
      "Train Epoch: 150 [80/918 (9%)] Loss: 11421317.000000\n",
      "Train Epoch: 150 [96/918 (10%)] Loss: 14900967.000000\n",
      "Train Epoch: 150 [112/918 (12%)] Loss: 9164417.000000\n",
      "Train Epoch: 150 [128/918 (14%)] Loss: 7680483.500000\n",
      "Train Epoch: 150 [144/918 (16%)] Loss: 14602643.000000\n",
      "Train Epoch: 150 [160/918 (17%)] Loss: 7455097.500000\n",
      "Train Epoch: 150 [176/918 (19%)] Loss: 7006630.500000\n",
      "Train Epoch: 150 [192/918 (21%)] Loss: 11876398.000000\n",
      "Train Epoch: 150 [208/918 (23%)] Loss: 8201161.500000\n",
      "Train Epoch: 150 [224/918 (24%)] Loss: 10105231.000000\n",
      "Train Epoch: 150 [240/918 (26%)] Loss: 9933037.000000\n",
      "Train Epoch: 150 [256/918 (28%)] Loss: 11068325.000000\n",
      "Train Epoch: 150 [272/918 (30%)] Loss: 7766353.500000\n",
      "Train Epoch: 150 [288/918 (31%)] Loss: 13932141.000000\n",
      "Train Epoch: 150 [304/918 (33%)] Loss: 6429194.500000\n",
      "Train Epoch: 150 [320/918 (35%)] Loss: 7512596.000000\n",
      "Train Epoch: 150 [336/918 (37%)] Loss: 10988997.000000\n",
      "Train Epoch: 150 [352/918 (38%)] Loss: 6729389.500000\n",
      "Train Epoch: 150 [368/918 (40%)] Loss: 19633652.000000\n",
      "Train Epoch: 150 [384/918 (42%)] Loss: 8117713.500000\n",
      "Train Epoch: 150 [400/918 (44%)] Loss: 7051917.000000\n",
      "Train Epoch: 150 [416/918 (45%)] Loss: 8734207.000000\n",
      "Train Epoch: 150 [432/918 (47%)] Loss: 9015187.000000\n",
      "Train Epoch: 150 [448/918 (49%)] Loss: 9400315.000000\n",
      "Train Epoch: 150 [464/918 (51%)] Loss: 7592331.500000\n",
      "Train Epoch: 150 [480/918 (52%)] Loss: 6278120.500000\n",
      "Train Epoch: 150 [496/918 (54%)] Loss: 11704675.000000\n",
      "Train Epoch: 150 [512/918 (56%)] Loss: 7722009.000000\n",
      "Train Epoch: 150 [528/918 (58%)] Loss: 15821885.000000\n",
      "Train Epoch: 150 [544/918 (59%)] Loss: 18309640.000000\n",
      "Train Epoch: 150 [560/918 (61%)] Loss: 8953821.000000\n",
      "Train Epoch: 150 [576/918 (63%)] Loss: 7247352.000000\n",
      "Train Epoch: 150 [592/918 (64%)] Loss: 6005841.500000\n",
      "Train Epoch: 150 [608/918 (66%)] Loss: 6187648.000000\n",
      "Train Epoch: 150 [624/918 (68%)] Loss: 7054217.000000\n",
      "Train Epoch: 150 [640/918 (70%)] Loss: 7612800.000000\n",
      "Train Epoch: 150 [656/918 (71%)] Loss: 14200256.000000\n",
      "Train Epoch: 150 [672/918 (73%)] Loss: 8887219.000000\n",
      "Train Epoch: 150 [688/918 (75%)] Loss: 6666981.500000\n",
      "Train Epoch: 150 [704/918 (77%)] Loss: 8753339.000000\n",
      "Train Epoch: 150 [720/918 (78%)] Loss: 9898693.000000\n",
      "Train Epoch: 150 [736/918 (80%)] Loss: 10768935.000000\n",
      "Train Epoch: 150 [752/918 (82%)] Loss: 8268851.500000\n",
      "Train Epoch: 150 [768/918 (84%)] Loss: 7886517.000000\n",
      "Train Epoch: 150 [784/918 (85%)] Loss: 7392417.500000\n",
      "Train Epoch: 150 [800/918 (87%)] Loss: 8902888.000000\n",
      "Train Epoch: 150 [816/918 (89%)] Loss: 9179097.000000\n",
      "Train Epoch: 150 [832/918 (91%)] Loss: 5541189.500000\n",
      "Train Epoch: 150 [848/918 (92%)] Loss: 8870203.000000\n",
      "Train Epoch: 150 [864/918 (94%)] Loss: 9172952.000000\n",
      "Train Epoch: 150 [880/918 (96%)] Loss: 15678807.000000\n",
      "Train Epoch: 150 [896/918 (98%)] Loss: 10328247.000000\n",
      "Train Epoch: 150 [912/918 (99%)] Loss: 7905468.000000\n",
      "    epoch          : 150\n",
      "    loss           : 9360831.786956523\n",
      "    ess            : 7.757943953638492\n",
      "    log_marginal   : -9360829.226086957\n",
      "    val_loss       : 9609515.807692308\n",
      "    val_ess        : 7.401049742331872\n",
      "    val_log_marginal: -9609514.461538462\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch150.pth ...\n",
      "Train Epoch: 151 [0/918 (0%)] Loss: 11098429.000000\n",
      "Train Epoch: 151 [16/918 (2%)] Loss: 7676873.500000\n",
      "Train Epoch: 151 [32/918 (3%)] Loss: 11299683.000000\n",
      "Train Epoch: 151 [48/918 (5%)] Loss: 8413383.000000\n",
      "Train Epoch: 151 [64/918 (7%)] Loss: 6431781.500000\n",
      "Train Epoch: 151 [80/918 (9%)] Loss: 5860731.500000\n",
      "Train Epoch: 151 [96/918 (10%)] Loss: 16133991.000000\n",
      "Train Epoch: 151 [112/918 (12%)] Loss: 9077509.000000\n",
      "Train Epoch: 151 [128/918 (14%)] Loss: 7831488.000000\n",
      "Train Epoch: 151 [144/918 (16%)] Loss: 8591403.000000\n",
      "Train Epoch: 151 [160/918 (17%)] Loss: 9281375.000000\n",
      "Train Epoch: 151 [176/918 (19%)] Loss: 10567373.000000\n",
      "Train Epoch: 151 [192/918 (21%)] Loss: 8509631.000000\n",
      "Train Epoch: 151 [208/918 (23%)] Loss: 7939025.500000\n",
      "Train Epoch: 151 [224/918 (24%)] Loss: 10387699.000000\n",
      "Train Epoch: 151 [240/918 (26%)] Loss: 8985667.000000\n",
      "Train Epoch: 151 [256/918 (28%)] Loss: 10537499.000000\n",
      "Train Epoch: 151 [272/918 (30%)] Loss: 12651533.000000\n",
      "Train Epoch: 151 [288/918 (31%)] Loss: 11491568.000000\n",
      "Train Epoch: 151 [304/918 (33%)] Loss: 8501734.000000\n",
      "Train Epoch: 151 [320/918 (35%)] Loss: 6682905.500000\n",
      "Train Epoch: 151 [336/918 (37%)] Loss: 9020854.000000\n",
      "Train Epoch: 151 [352/918 (38%)] Loss: 8360876.000000\n",
      "Train Epoch: 151 [368/918 (40%)] Loss: 9729112.000000\n",
      "Train Epoch: 151 [384/918 (42%)] Loss: 7881984.000000\n",
      "Train Epoch: 151 [400/918 (44%)] Loss: 7862813.500000\n",
      "Train Epoch: 151 [416/918 (45%)] Loss: 9201698.000000\n",
      "Train Epoch: 151 [432/918 (47%)] Loss: 7000310.500000\n",
      "Train Epoch: 151 [448/918 (49%)] Loss: 8381599.500000\n",
      "Train Epoch: 151 [464/918 (51%)] Loss: 12695459.000000\n",
      "Train Epoch: 151 [480/918 (52%)] Loss: 9151770.000000\n",
      "Train Epoch: 151 [496/918 (54%)] Loss: 5720267.000000\n",
      "Train Epoch: 151 [512/918 (56%)] Loss: 8868858.000000\n",
      "Train Epoch: 151 [528/918 (58%)] Loss: 7380747.500000\n",
      "Train Epoch: 151 [544/918 (59%)] Loss: 8993762.000000\n",
      "Train Epoch: 151 [560/918 (61%)] Loss: 7520188.000000\n",
      "Train Epoch: 151 [576/918 (63%)] Loss: 8882014.000000\n",
      "Train Epoch: 151 [592/918 (64%)] Loss: 9187120.000000\n",
      "Train Epoch: 151 [608/918 (66%)] Loss: 7330739.500000\n",
      "Train Epoch: 151 [624/918 (68%)] Loss: 9582283.000000\n",
      "Train Epoch: 151 [640/918 (70%)] Loss: 4502768.000000\n",
      "Train Epoch: 151 [656/918 (71%)] Loss: 14584765.000000\n",
      "Train Epoch: 151 [672/918 (73%)] Loss: 6911821.000000\n",
      "Train Epoch: 151 [688/918 (75%)] Loss: 8227755.500000\n",
      "Train Epoch: 151 [704/918 (77%)] Loss: 9326615.000000\n",
      "Train Epoch: 151 [720/918 (78%)] Loss: 11473312.000000\n",
      "Train Epoch: 151 [736/918 (80%)] Loss: 7726129.000000\n",
      "Train Epoch: 151 [752/918 (82%)] Loss: 13063640.000000\n",
      "Train Epoch: 151 [768/918 (84%)] Loss: 5002892.500000\n",
      "Train Epoch: 151 [784/918 (85%)] Loss: 5775461.500000\n",
      "Train Epoch: 151 [800/918 (87%)] Loss: 9709683.000000\n",
      "Train Epoch: 151 [816/918 (89%)] Loss: 8693018.000000\n",
      "Train Epoch: 151 [832/918 (91%)] Loss: 9588336.000000\n",
      "Train Epoch: 151 [848/918 (92%)] Loss: 5676849.500000\n",
      "Train Epoch: 151 [864/918 (94%)] Loss: 7337499.500000\n",
      "Train Epoch: 151 [880/918 (96%)] Loss: 11583066.000000\n",
      "Train Epoch: 151 [896/918 (98%)] Loss: 9862259.000000\n",
      "Train Epoch: 151 [912/918 (99%)] Loss: 7358465.000000\n",
      "    epoch          : 151\n",
      "    loss           : 9046170.626086956\n",
      "    ess            : 8.086936575433482\n",
      "    log_marginal   : -9046167.413043479\n",
      "    val_loss       : 8782855.153846154\n",
      "    val_ess        : 8.150997125185453\n",
      "    val_log_marginal: -8782853.23076923\n",
      "Train Epoch: 152 [0/918 (0%)] Loss: 12748600.000000\n",
      "Train Epoch: 152 [16/918 (2%)] Loss: 7464205.000000\n",
      "Train Epoch: 152 [32/918 (3%)] Loss: 9698710.000000\n",
      "Train Epoch: 152 [48/918 (5%)] Loss: 8249464.000000\n",
      "Train Epoch: 152 [64/918 (7%)] Loss: 8663530.000000\n",
      "Train Epoch: 152 [80/918 (9%)] Loss: 13462080.000000\n",
      "Train Epoch: 152 [96/918 (10%)] Loss: 5614884.000000\n",
      "Train Epoch: 152 [112/918 (12%)] Loss: 8507522.000000\n",
      "Train Epoch: 152 [128/918 (14%)] Loss: 6117581.500000\n",
      "Train Epoch: 152 [144/918 (16%)] Loss: 7809888.000000\n",
      "Train Epoch: 152 [160/918 (17%)] Loss: 11386435.000000\n",
      "Train Epoch: 152 [176/918 (19%)] Loss: 7228741.000000\n",
      "Train Epoch: 152 [192/918 (21%)] Loss: 7983297.500000\n",
      "Train Epoch: 152 [208/918 (23%)] Loss: 7287714.500000\n",
      "Train Epoch: 152 [224/918 (24%)] Loss: 5745772.000000\n",
      "Train Epoch: 152 [240/918 (26%)] Loss: 7690641.500000\n",
      "Train Epoch: 152 [256/918 (28%)] Loss: 17941626.000000\n",
      "Train Epoch: 152 [272/918 (30%)] Loss: 11821059.000000\n",
      "Train Epoch: 152 [288/918 (31%)] Loss: 13554706.000000\n",
      "Train Epoch: 152 [304/918 (33%)] Loss: 12756803.000000\n",
      "Train Epoch: 152 [320/918 (35%)] Loss: 8862220.000000\n",
      "Train Epoch: 152 [336/918 (37%)] Loss: 6134377.500000\n",
      "Train Epoch: 152 [352/918 (38%)] Loss: 13644754.000000\n",
      "Train Epoch: 152 [368/918 (40%)] Loss: 5179961.500000\n",
      "Train Epoch: 152 [384/918 (42%)] Loss: 10791656.000000\n",
      "Train Epoch: 152 [400/918 (44%)] Loss: 8158632.000000\n",
      "Train Epoch: 152 [416/918 (45%)] Loss: 7656163.500000\n",
      "Train Epoch: 152 [432/918 (47%)] Loss: 7972342.500000\n",
      "Train Epoch: 152 [448/918 (49%)] Loss: 13445848.000000\n",
      "Train Epoch: 152 [464/918 (51%)] Loss: 6275940.000000\n",
      "Train Epoch: 152 [480/918 (52%)] Loss: 8517831.000000\n",
      "Train Epoch: 152 [496/918 (54%)] Loss: 8141132.000000\n",
      "Train Epoch: 152 [512/918 (56%)] Loss: 11768286.000000\n",
      "Train Epoch: 152 [528/918 (58%)] Loss: 8440391.000000\n",
      "Train Epoch: 152 [544/918 (59%)] Loss: 7276663.500000\n",
      "Train Epoch: 152 [560/918 (61%)] Loss: 8521087.000000\n",
      "Train Epoch: 152 [576/918 (63%)] Loss: 9477395.000000\n",
      "Train Epoch: 152 [592/918 (64%)] Loss: 8229473.500000\n",
      "Train Epoch: 152 [608/918 (66%)] Loss: 9370567.000000\n",
      "Train Epoch: 152 [624/918 (68%)] Loss: 7166469.500000\n",
      "Train Epoch: 152 [640/918 (70%)] Loss: 13712173.000000\n",
      "Train Epoch: 152 [656/918 (71%)] Loss: 8120120.000000\n",
      "Train Epoch: 152 [672/918 (73%)] Loss: 10324317.000000\n",
      "Train Epoch: 152 [688/918 (75%)] Loss: 5341340.000000\n",
      "Train Epoch: 152 [704/918 (77%)] Loss: 9213288.000000\n",
      "Train Epoch: 152 [720/918 (78%)] Loss: 9043778.000000\n",
      "Train Epoch: 152 [736/918 (80%)] Loss: 11333327.000000\n",
      "Train Epoch: 152 [752/918 (82%)] Loss: 8756634.000000\n",
      "Train Epoch: 152 [768/918 (84%)] Loss: 6263606.500000\n",
      "Train Epoch: 152 [784/918 (85%)] Loss: 6450117.500000\n",
      "Train Epoch: 152 [800/918 (87%)] Loss: 10475377.000000\n",
      "Train Epoch: 152 [816/918 (89%)] Loss: 18148126.000000\n",
      "Train Epoch: 152 [832/918 (91%)] Loss: 9419619.000000\n",
      "Train Epoch: 152 [848/918 (92%)] Loss: 7849358.500000\n",
      "Train Epoch: 152 [864/918 (94%)] Loss: 8597503.000000\n",
      "Train Epoch: 152 [880/918 (96%)] Loss: 6548318.500000\n",
      "Train Epoch: 152 [896/918 (98%)] Loss: 10038362.000000\n",
      "Train Epoch: 152 [912/918 (99%)] Loss: 8328112.500000\n",
      "    epoch          : 152\n",
      "    loss           : 9229137.743478261\n",
      "    ess            : 8.181198567929476\n",
      "    log_marginal   : -9229135.595652174\n",
      "    val_loss       : 8216367.538461538\n",
      "    val_ess        : 8.087024542001577\n",
      "    val_log_marginal: -8216366.346153846\n",
      "Train Epoch: 153 [0/918 (0%)] Loss: 7751506.500000\n",
      "Train Epoch: 153 [16/918 (2%)] Loss: 7243181.000000\n",
      "Train Epoch: 153 [32/918 (3%)] Loss: 7751846.500000\n",
      "Train Epoch: 153 [48/918 (5%)] Loss: 8661046.000000\n",
      "Train Epoch: 153 [64/918 (7%)] Loss: 5366093.500000\n",
      "Train Epoch: 153 [80/918 (9%)] Loss: 6702075.500000\n",
      "Train Epoch: 153 [96/918 (10%)] Loss: 7227450.500000\n",
      "Train Epoch: 153 [112/918 (12%)] Loss: 8559253.000000\n",
      "Train Epoch: 153 [128/918 (14%)] Loss: 7340141.000000\n",
      "Train Epoch: 153 [144/918 (16%)] Loss: 8450834.000000\n",
      "Train Epoch: 153 [160/918 (17%)] Loss: 5797779.500000\n",
      "Train Epoch: 153 [176/918 (19%)] Loss: 6882083.500000\n",
      "Train Epoch: 153 [192/918 (21%)] Loss: 8901327.000000\n",
      "Train Epoch: 153 [208/918 (23%)] Loss: 6853773.000000\n",
      "Train Epoch: 153 [224/918 (24%)] Loss: 8517191.000000\n",
      "Train Epoch: 153 [240/918 (26%)] Loss: 7747389.000000\n",
      "Train Epoch: 153 [256/918 (28%)] Loss: 9131423.000000\n",
      "Train Epoch: 153 [272/918 (30%)] Loss: 8245965.000000\n",
      "Train Epoch: 153 [288/918 (31%)] Loss: 6807621.000000\n",
      "Train Epoch: 153 [304/918 (33%)] Loss: 18643882.000000\n",
      "Train Epoch: 153 [320/918 (35%)] Loss: 7347181.000000\n",
      "Train Epoch: 153 [336/918 (37%)] Loss: 9299155.000000\n",
      "Train Epoch: 153 [352/918 (38%)] Loss: 8998424.000000\n",
      "Train Epoch: 153 [368/918 (40%)] Loss: 8473941.000000\n",
      "Train Epoch: 153 [384/918 (42%)] Loss: 8420283.000000\n",
      "Train Epoch: 153 [400/918 (44%)] Loss: 9096583.000000\n",
      "Train Epoch: 153 [416/918 (45%)] Loss: 11938894.000000\n",
      "Train Epoch: 153 [432/918 (47%)] Loss: 7540952.000000\n",
      "Train Epoch: 153 [448/918 (49%)] Loss: 11028297.000000\n",
      "Train Epoch: 153 [464/918 (51%)] Loss: 6955475.500000\n",
      "Train Epoch: 153 [480/918 (52%)] Loss: 11892324.000000\n",
      "Train Epoch: 153 [496/918 (54%)] Loss: 16650058.000000\n",
      "Train Epoch: 153 [512/918 (56%)] Loss: 7417036.000000\n",
      "Train Epoch: 153 [528/918 (58%)] Loss: 8476438.000000\n",
      "Train Epoch: 153 [544/918 (59%)] Loss: 9205843.000000\n",
      "Train Epoch: 153 [560/918 (61%)] Loss: 10776391.000000\n",
      "Train Epoch: 153 [576/918 (63%)] Loss: 7354021.500000\n",
      "Train Epoch: 153 [592/918 (64%)] Loss: 10378479.000000\n",
      "Train Epoch: 153 [608/918 (66%)] Loss: 11339183.000000\n",
      "Train Epoch: 153 [624/918 (68%)] Loss: 8095609.000000\n",
      "Train Epoch: 153 [640/918 (70%)] Loss: 7192038.500000\n",
      "Train Epoch: 153 [656/918 (71%)] Loss: 12177584.000000\n",
      "Train Epoch: 153 [672/918 (73%)] Loss: 6731237.500000\n",
      "Train Epoch: 153 [688/918 (75%)] Loss: 11173746.000000\n",
      "Train Epoch: 153 [704/918 (77%)] Loss: 7612342.500000\n",
      "Train Epoch: 153 [720/918 (78%)] Loss: 7209096.000000\n",
      "Train Epoch: 153 [736/918 (80%)] Loss: 7815560.000000\n",
      "Train Epoch: 153 [752/918 (82%)] Loss: 12153911.000000\n",
      "Train Epoch: 153 [768/918 (84%)] Loss: 8197398.500000\n",
      "Train Epoch: 153 [784/918 (85%)] Loss: 5686035.500000\n",
      "Train Epoch: 153 [800/918 (87%)] Loss: 8038324.000000\n",
      "Train Epoch: 153 [816/918 (89%)] Loss: 7687562.500000\n",
      "Train Epoch: 153 [832/918 (91%)] Loss: 8865704.000000\n",
      "Train Epoch: 153 [848/918 (92%)] Loss: 7664058.500000\n",
      "Train Epoch: 153 [864/918 (94%)] Loss: 9625076.000000\n",
      "Train Epoch: 153 [880/918 (96%)] Loss: 8888400.000000\n",
      "Train Epoch: 153 [896/918 (98%)] Loss: 11752467.000000\n",
      "Train Epoch: 153 [912/918 (99%)] Loss: 9754505.000000\n",
      "    epoch          : 153\n",
      "    loss           : 8885287.926086957\n",
      "    ess            : 7.494304632103962\n",
      "    log_marginal   : -8885285.173913043\n",
      "    val_loss       : 9384433.615384616\n",
      "    val_ess        : 7.852833326046284\n",
      "    val_log_marginal: -9384432.038461538\n",
      "Train Epoch: 154 [0/918 (0%)] Loss: 10427712.000000\n",
      "Train Epoch: 154 [16/918 (2%)] Loss: 8687523.000000\n",
      "Train Epoch: 154 [32/918 (3%)] Loss: 8207709.000000\n",
      "Train Epoch: 154 [48/918 (5%)] Loss: 7047737.000000\n",
      "Train Epoch: 154 [64/918 (7%)] Loss: 8943512.000000\n",
      "Train Epoch: 154 [80/918 (9%)] Loss: 7883753.500000\n",
      "Train Epoch: 154 [96/918 (10%)] Loss: 10630039.000000\n",
      "Train Epoch: 154 [112/918 (12%)] Loss: 8226021.500000\n",
      "Train Epoch: 154 [128/918 (14%)] Loss: 6845149.000000\n",
      "Train Epoch: 154 [144/918 (16%)] Loss: 7795576.000000\n",
      "Train Epoch: 154 [160/918 (17%)] Loss: 12399731.000000\n",
      "Train Epoch: 154 [176/918 (19%)] Loss: 6355365.000000\n",
      "Train Epoch: 154 [192/918 (21%)] Loss: 7115059.500000\n",
      "Train Epoch: 154 [208/918 (23%)] Loss: 8479796.000000\n",
      "Train Epoch: 154 [224/918 (24%)] Loss: 13162222.000000\n",
      "Train Epoch: 154 [240/918 (26%)] Loss: 6787697.500000\n",
      "Train Epoch: 154 [256/918 (28%)] Loss: 9232405.000000\n",
      "Train Epoch: 154 [272/918 (30%)] Loss: 6844473.000000\n",
      "Train Epoch: 154 [288/918 (31%)] Loss: 8336100.000000\n",
      "Train Epoch: 154 [304/918 (33%)] Loss: 9882802.000000\n",
      "Train Epoch: 154 [320/918 (35%)] Loss: 7009341.000000\n",
      "Train Epoch: 154 [336/918 (37%)] Loss: 7726497.500000\n",
      "Train Epoch: 154 [352/918 (38%)] Loss: 5788181.500000\n",
      "Train Epoch: 154 [368/918 (40%)] Loss: 6999435.500000\n",
      "Train Epoch: 154 [384/918 (42%)] Loss: 7757981.000000\n",
      "Train Epoch: 154 [400/918 (44%)] Loss: 6508925.000000\n",
      "Train Epoch: 154 [416/918 (45%)] Loss: 8661699.000000\n",
      "Train Epoch: 154 [432/918 (47%)] Loss: 10305169.000000\n",
      "Train Epoch: 154 [448/918 (49%)] Loss: 12136449.000000\n",
      "Train Epoch: 154 [464/918 (51%)] Loss: 7341917.000000\n",
      "Train Epoch: 154 [480/918 (52%)] Loss: 5743520.000000\n",
      "Train Epoch: 154 [496/918 (54%)] Loss: 9539664.000000\n",
      "Train Epoch: 154 [512/918 (56%)] Loss: 9536269.000000\n",
      "Train Epoch: 154 [528/918 (58%)] Loss: 7477573.000000\n",
      "Train Epoch: 154 [544/918 (59%)] Loss: 10212065.000000\n",
      "Train Epoch: 154 [560/918 (61%)] Loss: 8728140.000000\n",
      "Train Epoch: 154 [576/918 (63%)] Loss: 6164695.500000\n",
      "Train Epoch: 154 [592/918 (64%)] Loss: 7184174.500000\n",
      "Train Epoch: 154 [608/918 (66%)] Loss: 7697311.500000\n",
      "Train Epoch: 154 [624/918 (68%)] Loss: 7542945.500000\n",
      "Train Epoch: 154 [640/918 (70%)] Loss: 9239511.000000\n",
      "Train Epoch: 154 [656/918 (71%)] Loss: 10377939.000000\n",
      "Train Epoch: 154 [672/918 (73%)] Loss: 7360110.500000\n",
      "Train Epoch: 154 [688/918 (75%)] Loss: 8251617.500000\n",
      "Train Epoch: 154 [704/918 (77%)] Loss: 13073691.000000\n",
      "Train Epoch: 154 [720/918 (78%)] Loss: 6083969.500000\n",
      "Train Epoch: 154 [736/918 (80%)] Loss: 8001145.500000\n",
      "Train Epoch: 154 [752/918 (82%)] Loss: 6860828.000000\n",
      "Train Epoch: 154 [768/918 (84%)] Loss: 9553499.000000\n",
      "Train Epoch: 154 [784/918 (85%)] Loss: 8409007.000000\n",
      "Train Epoch: 154 [800/918 (87%)] Loss: 11017295.000000\n",
      "Train Epoch: 154 [816/918 (89%)] Loss: 9299439.000000\n",
      "Train Epoch: 154 [832/918 (91%)] Loss: 11755060.000000\n",
      "Train Epoch: 154 [848/918 (92%)] Loss: 10246432.000000\n",
      "Train Epoch: 154 [864/918 (94%)] Loss: 9054799.000000\n",
      "Train Epoch: 154 [880/918 (96%)] Loss: 11711519.000000\n",
      "Train Epoch: 154 [896/918 (98%)] Loss: 14864215.000000\n",
      "Train Epoch: 154 [912/918 (99%)] Loss: 6290303.500000\n",
      "    epoch          : 154\n",
      "    loss           : 9121979.504347825\n",
      "    ess            : 7.37002011589382\n",
      "    log_marginal   : -9121977.508695653\n",
      "    val_loss       : 9393563.961538462\n",
      "    val_ess        : 7.7686785734616794\n",
      "    val_log_marginal: -9393561.76923077\n",
      "Train Epoch: 155 [0/918 (0%)] Loss: 7191007.500000\n",
      "Train Epoch: 155 [16/918 (2%)] Loss: 8336216.000000\n",
      "Train Epoch: 155 [32/918 (3%)] Loss: 10179065.000000\n",
      "Train Epoch: 155 [48/918 (5%)] Loss: 8026581.500000\n",
      "Train Epoch: 155 [64/918 (7%)] Loss: 10503975.000000\n",
      "Train Epoch: 155 [80/918 (9%)] Loss: 8872108.000000\n",
      "Train Epoch: 155 [96/918 (10%)] Loss: 6646981.000000\n",
      "Train Epoch: 155 [112/918 (12%)] Loss: 8715187.000000\n",
      "Train Epoch: 155 [128/918 (14%)] Loss: 13666784.000000\n",
      "Train Epoch: 155 [144/918 (16%)] Loss: 5888343.500000\n",
      "Train Epoch: 155 [160/918 (17%)] Loss: 11560923.000000\n",
      "Train Epoch: 155 [176/918 (19%)] Loss: 11042850.000000\n",
      "Train Epoch: 155 [192/918 (21%)] Loss: 8279440.000000\n",
      "Train Epoch: 155 [208/918 (23%)] Loss: 6427303.500000\n",
      "Train Epoch: 155 [224/918 (24%)] Loss: 7896137.500000\n",
      "Train Epoch: 155 [240/918 (26%)] Loss: 14160531.000000\n",
      "Train Epoch: 155 [256/918 (28%)] Loss: 7974714.500000\n",
      "Train Epoch: 155 [272/918 (30%)] Loss: 12433800.000000\n",
      "Train Epoch: 155 [288/918 (31%)] Loss: 9776600.000000\n",
      "Train Epoch: 155 [304/918 (33%)] Loss: 8022501.500000\n",
      "Train Epoch: 155 [320/918 (35%)] Loss: 13379415.000000\n",
      "Train Epoch: 155 [336/918 (37%)] Loss: 6072489.500000\n",
      "Train Epoch: 155 [352/918 (38%)] Loss: 9684192.000000\n",
      "Train Epoch: 155 [368/918 (40%)] Loss: 12092034.000000\n",
      "Train Epoch: 155 [384/918 (42%)] Loss: 10937430.000000\n",
      "Train Epoch: 155 [400/918 (44%)] Loss: 7208772.000000\n",
      "Train Epoch: 155 [416/918 (45%)] Loss: 12284160.000000\n",
      "Train Epoch: 155 [432/918 (47%)] Loss: 9545415.000000\n",
      "Train Epoch: 155 [448/918 (49%)] Loss: 7499110.500000\n",
      "Train Epoch: 155 [464/918 (51%)] Loss: 6126710.500000\n",
      "Train Epoch: 155 [480/918 (52%)] Loss: 10085051.000000\n",
      "Train Epoch: 155 [496/918 (54%)] Loss: 10214773.000000\n",
      "Train Epoch: 155 [512/918 (56%)] Loss: 6634842.000000\n",
      "Train Epoch: 155 [528/918 (58%)] Loss: 6672072.500000\n",
      "Train Epoch: 155 [544/918 (59%)] Loss: 6874901.000000\n",
      "Train Epoch: 155 [560/918 (61%)] Loss: 9469074.000000\n",
      "Train Epoch: 155 [576/918 (63%)] Loss: 6456383.500000\n",
      "Train Epoch: 155 [592/918 (64%)] Loss: 5722504.000000\n",
      "Train Epoch: 155 [608/918 (66%)] Loss: 10141727.000000\n",
      "Train Epoch: 155 [624/918 (68%)] Loss: 7707495.500000\n",
      "Train Epoch: 155 [640/918 (70%)] Loss: 9766890.000000\n",
      "Train Epoch: 155 [656/918 (71%)] Loss: 11822243.000000\n",
      "Train Epoch: 155 [672/918 (73%)] Loss: 7944192.000000\n",
      "Train Epoch: 155 [688/918 (75%)] Loss: 9107763.000000\n",
      "Train Epoch: 155 [704/918 (77%)] Loss: 6645917.500000\n",
      "Train Epoch: 155 [720/918 (78%)] Loss: 11339787.000000\n",
      "Train Epoch: 155 [736/918 (80%)] Loss: 7101572.000000\n",
      "Train Epoch: 155 [752/918 (82%)] Loss: 14118011.000000\n",
      "Train Epoch: 155 [768/918 (84%)] Loss: 7953261.000000\n",
      "Train Epoch: 155 [784/918 (85%)] Loss: 8205852.000000\n",
      "Train Epoch: 155 [800/918 (87%)] Loss: 10950154.000000\n",
      "Train Epoch: 155 [816/918 (89%)] Loss: 7578451.500000\n",
      "Train Epoch: 155 [832/918 (91%)] Loss: 10216023.000000\n",
      "Train Epoch: 155 [848/918 (92%)] Loss: 16427179.000000\n",
      "Train Epoch: 155 [864/918 (94%)] Loss: 8781799.000000\n",
      "Train Epoch: 155 [880/918 (96%)] Loss: 6300944.500000\n",
      "Train Epoch: 155 [896/918 (98%)] Loss: 11049107.000000\n",
      "Train Epoch: 155 [912/918 (99%)] Loss: 6417858.000000\n",
      "    epoch          : 155\n",
      "    loss           : 8862189.317391304\n",
      "    ess            : 7.397585192970608\n",
      "    log_marginal   : -8862187.034782609\n",
      "    val_loss       : 10039291.615384616\n",
      "    val_ess        : 6.454600279147808\n",
      "    val_log_marginal: -10039291.076923076\n",
      "Train Epoch: 156 [0/918 (0%)] Loss: 5308854.000000\n",
      "Train Epoch: 156 [16/918 (2%)] Loss: 10538669.000000\n",
      "Train Epoch: 156 [32/918 (3%)] Loss: 9600690.000000\n",
      "Train Epoch: 156 [48/918 (5%)] Loss: 7759400.000000\n",
      "Train Epoch: 156 [64/918 (7%)] Loss: 7032907.500000\n",
      "Train Epoch: 156 [80/918 (9%)] Loss: 10160042.000000\n",
      "Train Epoch: 156 [96/918 (10%)] Loss: 9751440.000000\n",
      "Train Epoch: 156 [112/918 (12%)] Loss: 5348953.000000\n",
      "Train Epoch: 156 [128/918 (14%)] Loss: 7903866.500000\n",
      "Train Epoch: 156 [144/918 (16%)] Loss: 7406578.500000\n",
      "Train Epoch: 156 [160/918 (17%)] Loss: 8091083.500000\n",
      "Train Epoch: 156 [176/918 (19%)] Loss: 8871159.000000\n",
      "Train Epoch: 156 [192/918 (21%)] Loss: 10216583.000000\n",
      "Train Epoch: 156 [208/918 (23%)] Loss: 6922445.000000\n",
      "Train Epoch: 156 [224/918 (24%)] Loss: 9952579.000000\n",
      "Train Epoch: 156 [240/918 (26%)] Loss: 5699945.000000\n",
      "Train Epoch: 156 [256/918 (28%)] Loss: 11838047.000000\n",
      "Train Epoch: 156 [272/918 (30%)] Loss: 12566619.000000\n",
      "Train Epoch: 156 [288/918 (31%)] Loss: 7495646.500000\n",
      "Train Epoch: 156 [304/918 (33%)] Loss: 6048004.000000\n",
      "Train Epoch: 156 [320/918 (35%)] Loss: 8450058.000000\n",
      "Train Epoch: 156 [336/918 (37%)] Loss: 15041315.000000\n",
      "Train Epoch: 156 [352/918 (38%)] Loss: 7793566.500000\n",
      "Train Epoch: 156 [368/918 (40%)] Loss: 15011898.000000\n",
      "Train Epoch: 156 [384/918 (42%)] Loss: 8008077.000000\n",
      "Train Epoch: 156 [400/918 (44%)] Loss: 6796384.000000\n",
      "Train Epoch: 156 [416/918 (45%)] Loss: 12811937.000000\n",
      "Train Epoch: 156 [432/918 (47%)] Loss: 11072011.000000\n",
      "Train Epoch: 156 [448/918 (49%)] Loss: 15679301.000000\n",
      "Train Epoch: 156 [464/918 (51%)] Loss: 8599543.000000\n",
      "Train Epoch: 156 [480/918 (52%)] Loss: 7136555.500000\n",
      "Train Epoch: 156 [496/918 (54%)] Loss: 6428486.000000\n",
      "Train Epoch: 156 [512/918 (56%)] Loss: 8784735.000000\n",
      "Train Epoch: 156 [528/918 (58%)] Loss: 13390413.000000\n",
      "Train Epoch: 156 [544/918 (59%)] Loss: 9420935.000000\n",
      "Train Epoch: 156 [560/918 (61%)] Loss: 9947836.000000\n",
      "Train Epoch: 156 [576/918 (63%)] Loss: 6280410.500000\n",
      "Train Epoch: 156 [592/918 (64%)] Loss: 7161902.500000\n",
      "Train Epoch: 156 [608/918 (66%)] Loss: 8506139.000000\n",
      "Train Epoch: 156 [624/918 (68%)] Loss: 10897647.000000\n",
      "Train Epoch: 156 [640/918 (70%)] Loss: 9891369.000000\n",
      "Train Epoch: 156 [656/918 (71%)] Loss: 10056435.000000\n",
      "Train Epoch: 156 [672/918 (73%)] Loss: 10976138.000000\n",
      "Train Epoch: 156 [688/918 (75%)] Loss: 7926728.000000\n",
      "Train Epoch: 156 [704/918 (77%)] Loss: 5760277.000000\n",
      "Train Epoch: 156 [720/918 (78%)] Loss: 5477657.500000\n",
      "Train Epoch: 156 [736/918 (80%)] Loss: 7520835.500000\n",
      "Train Epoch: 156 [752/918 (82%)] Loss: 6893126.500000\n",
      "Train Epoch: 156 [768/918 (84%)] Loss: 5915486.500000\n",
      "Train Epoch: 156 [784/918 (85%)] Loss: 12128155.000000\n",
      "Train Epoch: 156 [800/918 (87%)] Loss: 11432619.000000\n",
      "Train Epoch: 156 [816/918 (89%)] Loss: 6776926.500000\n",
      "Train Epoch: 156 [832/918 (91%)] Loss: 8571026.000000\n",
      "Train Epoch: 156 [848/918 (92%)] Loss: 9375335.000000\n",
      "Train Epoch: 156 [864/918 (94%)] Loss: 8531155.000000\n",
      "Train Epoch: 156 [880/918 (96%)] Loss: 11868228.000000\n",
      "Train Epoch: 156 [896/918 (98%)] Loss: 8386350.500000\n",
      "Train Epoch: 156 [912/918 (99%)] Loss: 6077033.000000\n",
      "    epoch          : 156\n",
      "    loss           : 9067210.830434782\n",
      "    ess            : 7.7420988456062645\n",
      "    log_marginal   : -9067208.2\n",
      "    val_loss       : 8465238.538461538\n",
      "    val_ess        : 7.631348389845628\n",
      "    val_log_marginal: -8465236.26923077\n",
      "Train Epoch: 157 [0/918 (0%)] Loss: 8520526.000000\n",
      "Train Epoch: 157 [16/918 (2%)] Loss: 6756990.500000\n",
      "Train Epoch: 157 [32/918 (3%)] Loss: 7179340.000000\n",
      "Train Epoch: 157 [48/918 (5%)] Loss: 11583716.000000\n",
      "Train Epoch: 157 [64/918 (7%)] Loss: 6163374.500000\n",
      "Train Epoch: 157 [80/918 (9%)] Loss: 10649831.000000\n",
      "Train Epoch: 157 [96/918 (10%)] Loss: 6248227.500000\n",
      "Train Epoch: 157 [112/918 (12%)] Loss: 9634178.000000\n",
      "Train Epoch: 157 [128/918 (14%)] Loss: 8010134.500000\n",
      "Train Epoch: 157 [144/918 (16%)] Loss: 7447634.500000\n",
      "Train Epoch: 157 [160/918 (17%)] Loss: 7409921.500000\n",
      "Train Epoch: 157 [176/918 (19%)] Loss: 6477536.000000\n",
      "Train Epoch: 157 [192/918 (21%)] Loss: 8901624.000000\n",
      "Train Epoch: 157 [208/918 (23%)] Loss: 10350838.000000\n",
      "Train Epoch: 157 [224/918 (24%)] Loss: 8455263.000000\n",
      "Train Epoch: 157 [240/918 (26%)] Loss: 5693166.000000\n",
      "Train Epoch: 157 [256/918 (28%)] Loss: 11793852.000000\n",
      "Train Epoch: 157 [272/918 (30%)] Loss: 5111818.500000\n",
      "Train Epoch: 157 [288/918 (31%)] Loss: 8702368.000000\n",
      "Train Epoch: 157 [304/918 (33%)] Loss: 9140467.000000\n",
      "Train Epoch: 157 [320/918 (35%)] Loss: 13980576.000000\n",
      "Train Epoch: 157 [336/918 (37%)] Loss: 5605760.500000\n",
      "Train Epoch: 157 [352/918 (38%)] Loss: 9731103.000000\n",
      "Train Epoch: 157 [368/918 (40%)] Loss: 9007915.000000\n",
      "Train Epoch: 157 [384/918 (42%)] Loss: 10598881.000000\n",
      "Train Epoch: 157 [400/918 (44%)] Loss: 5870172.500000\n",
      "Train Epoch: 157 [416/918 (45%)] Loss: 11502332.000000\n",
      "Train Epoch: 157 [432/918 (47%)] Loss: 7807171.500000\n",
      "Train Epoch: 157 [448/918 (49%)] Loss: 7904321.000000\n",
      "Train Epoch: 157 [464/918 (51%)] Loss: 11611905.000000\n",
      "Train Epoch: 157 [480/918 (52%)] Loss: 10103711.000000\n",
      "Train Epoch: 157 [496/918 (54%)] Loss: 7030301.000000\n",
      "Train Epoch: 157 [512/918 (56%)] Loss: 9029883.000000\n",
      "Train Epoch: 157 [528/918 (58%)] Loss: 10739874.000000\n",
      "Train Epoch: 157 [544/918 (59%)] Loss: 8151601.500000\n",
      "Train Epoch: 157 [560/918 (61%)] Loss: 10128920.000000\n",
      "Train Epoch: 157 [576/918 (63%)] Loss: 6070879.500000\n",
      "Train Epoch: 157 [592/918 (64%)] Loss: 12519082.000000\n",
      "Train Epoch: 157 [608/918 (66%)] Loss: 8829764.000000\n",
      "Train Epoch: 157 [624/918 (68%)] Loss: 7106345.500000\n",
      "Train Epoch: 157 [640/918 (70%)] Loss: 9593018.000000\n",
      "Train Epoch: 157 [656/918 (71%)] Loss: 9212975.000000\n",
      "Train Epoch: 157 [672/918 (73%)] Loss: 10832992.000000\n",
      "Train Epoch: 157 [688/918 (75%)] Loss: 12123792.000000\n",
      "Train Epoch: 157 [704/918 (77%)] Loss: 10087946.000000\n",
      "Train Epoch: 157 [720/918 (78%)] Loss: 10421199.000000\n",
      "Train Epoch: 157 [736/918 (80%)] Loss: 10241023.000000\n",
      "Train Epoch: 157 [752/918 (82%)] Loss: 12056962.000000\n",
      "Train Epoch: 157 [768/918 (84%)] Loss: 9793094.000000\n",
      "Train Epoch: 157 [784/918 (85%)] Loss: 5249646.500000\n",
      "Train Epoch: 157 [800/918 (87%)] Loss: 11008027.000000\n",
      "Train Epoch: 157 [816/918 (89%)] Loss: 9401259.000000\n",
      "Train Epoch: 157 [832/918 (91%)] Loss: 6883297.500000\n",
      "Train Epoch: 157 [848/918 (92%)] Loss: 7417163.500000\n",
      "Train Epoch: 157 [864/918 (94%)] Loss: 7558996.000000\n",
      "Train Epoch: 157 [880/918 (96%)] Loss: 8510031.000000\n",
      "Train Epoch: 157 [896/918 (98%)] Loss: 7607417.000000\n",
      "Train Epoch: 157 [912/918 (99%)] Loss: 12393746.000000\n",
      "    epoch          : 157\n",
      "    loss           : 9037789.017391304\n",
      "    ess            : 8.087263582063757\n",
      "    log_marginal   : -9037786.191304348\n",
      "    val_loss       : 9943609.076923076\n",
      "    val_ess        : 8.377138394575853\n",
      "    val_log_marginal: -9943605.115384616\n",
      "Train Epoch: 158 [0/918 (0%)] Loss: 8366363.500000\n",
      "Train Epoch: 158 [16/918 (2%)] Loss: 8098897.500000\n",
      "Train Epoch: 158 [32/918 (3%)] Loss: 10170991.000000\n",
      "Train Epoch: 158 [48/918 (5%)] Loss: 13390256.000000\n",
      "Train Epoch: 158 [64/918 (7%)] Loss: 8718747.000000\n",
      "Train Epoch: 158 [80/918 (9%)] Loss: 8096165.000000\n",
      "Train Epoch: 158 [96/918 (10%)] Loss: 5260507.500000\n",
      "Train Epoch: 158 [112/918 (12%)] Loss: 6498690.500000\n",
      "Train Epoch: 158 [128/918 (14%)] Loss: 11403059.000000\n",
      "Train Epoch: 158 [144/918 (16%)] Loss: 4177642.500000\n",
      "Train Epoch: 158 [160/918 (17%)] Loss: 9475064.000000\n",
      "Train Epoch: 158 [176/918 (19%)] Loss: 9211211.000000\n",
      "Train Epoch: 158 [192/918 (21%)] Loss: 8868995.000000\n",
      "Train Epoch: 158 [208/918 (23%)] Loss: 11749899.000000\n",
      "Train Epoch: 158 [224/918 (24%)] Loss: 8706746.000000\n",
      "Train Epoch: 158 [240/918 (26%)] Loss: 6199368.500000\n",
      "Train Epoch: 158 [256/918 (28%)] Loss: 6519798.000000\n",
      "Train Epoch: 158 [272/918 (30%)] Loss: 7529948.000000\n",
      "Train Epoch: 158 [288/918 (31%)] Loss: 6606963.500000\n",
      "Train Epoch: 158 [304/918 (33%)] Loss: 6670348.000000\n",
      "Train Epoch: 158 [320/918 (35%)] Loss: 7881979.500000\n",
      "Train Epoch: 158 [336/918 (37%)] Loss: 9848368.000000\n",
      "Train Epoch: 158 [352/918 (38%)] Loss: 7368267.500000\n",
      "Train Epoch: 158 [368/918 (40%)] Loss: 8961284.000000\n",
      "Train Epoch: 158 [384/918 (42%)] Loss: 7373795.500000\n",
      "Train Epoch: 158 [400/918 (44%)] Loss: 10918264.000000\n",
      "Train Epoch: 158 [416/918 (45%)] Loss: 7751641.500000\n",
      "Train Epoch: 158 [432/918 (47%)] Loss: 7211497.500000\n",
      "Train Epoch: 158 [448/918 (49%)] Loss: 5182300.000000\n",
      "Train Epoch: 158 [464/918 (51%)] Loss: 8864723.000000\n",
      "Train Epoch: 158 [480/918 (52%)] Loss: 7696120.000000\n",
      "Train Epoch: 158 [496/918 (54%)] Loss: 9864720.000000\n",
      "Train Epoch: 158 [512/918 (56%)] Loss: 10299020.000000\n",
      "Train Epoch: 158 [528/918 (58%)] Loss: 14165224.000000\n",
      "Train Epoch: 158 [544/918 (59%)] Loss: 8423143.000000\n",
      "Train Epoch: 158 [560/918 (61%)] Loss: 6507216.500000\n",
      "Train Epoch: 158 [576/918 (63%)] Loss: 11183067.000000\n",
      "Train Epoch: 158 [592/918 (64%)] Loss: 10689924.000000\n",
      "Train Epoch: 158 [608/918 (66%)] Loss: 9472861.000000\n",
      "Train Epoch: 158 [624/918 (68%)] Loss: 9167298.000000\n",
      "Train Epoch: 158 [640/918 (70%)] Loss: 6949340.000000\n",
      "Train Epoch: 158 [656/918 (71%)] Loss: 9191408.000000\n",
      "Train Epoch: 158 [672/918 (73%)] Loss: 7363193.500000\n",
      "Train Epoch: 158 [688/918 (75%)] Loss: 7607021.000000\n",
      "Train Epoch: 158 [704/918 (77%)] Loss: 11238243.000000\n",
      "Train Epoch: 158 [720/918 (78%)] Loss: 5950643.000000\n",
      "Train Epoch: 158 [736/918 (80%)] Loss: 8143493.500000\n",
      "Train Epoch: 158 [752/918 (82%)] Loss: 6281318.500000\n",
      "Train Epoch: 158 [768/918 (84%)] Loss: 8140152.000000\n",
      "Train Epoch: 158 [784/918 (85%)] Loss: 9393841.000000\n",
      "Train Epoch: 158 [800/918 (87%)] Loss: 14357650.000000\n",
      "Train Epoch: 158 [816/918 (89%)] Loss: 11194570.000000\n",
      "Train Epoch: 158 [832/918 (91%)] Loss: 8242889.500000\n",
      "Train Epoch: 158 [848/918 (92%)] Loss: 5008290.000000\n",
      "Train Epoch: 158 [864/918 (94%)] Loss: 9840852.000000\n",
      "Train Epoch: 158 [880/918 (96%)] Loss: 8771495.000000\n",
      "Train Epoch: 158 [896/918 (98%)] Loss: 12282939.000000\n",
      "Train Epoch: 158 [912/918 (99%)] Loss: 5903061.500000\n",
      "    epoch          : 158\n",
      "    loss           : 8888036.602173913\n",
      "    ess            : 7.682381540796031\n",
      "    log_marginal   : -8888033.991304347\n",
      "    val_loss       : 9564082.0\n",
      "    val_ess        : 6.080495265813974\n",
      "    val_log_marginal: -9564079.961538462\n",
      "Train Epoch: 159 [0/918 (0%)] Loss: 10762895.000000\n",
      "Train Epoch: 159 [16/918 (2%)] Loss: 7131561.000000\n",
      "Train Epoch: 159 [32/918 (3%)] Loss: 10257581.000000\n",
      "Train Epoch: 159 [48/918 (5%)] Loss: 15830541.000000\n",
      "Train Epoch: 159 [64/918 (7%)] Loss: 10050622.000000\n",
      "Train Epoch: 159 [80/918 (9%)] Loss: 8806741.000000\n",
      "Train Epoch: 159 [96/918 (10%)] Loss: 9738077.000000\n",
      "Train Epoch: 159 [112/918 (12%)] Loss: 12827809.000000\n",
      "Train Epoch: 159 [128/918 (14%)] Loss: 8197689.000000\n",
      "Train Epoch: 159 [144/918 (16%)] Loss: 8930937.000000\n",
      "Train Epoch: 159 [160/918 (17%)] Loss: 9270283.000000\n",
      "Train Epoch: 159 [176/918 (19%)] Loss: 8783902.000000\n",
      "Train Epoch: 159 [192/918 (21%)] Loss: 7967826.500000\n",
      "Train Epoch: 159 [208/918 (23%)] Loss: 8038906.500000\n",
      "Train Epoch: 159 [224/918 (24%)] Loss: 11155475.000000\n",
      "Train Epoch: 159 [240/918 (26%)] Loss: 6104135.500000\n",
      "Train Epoch: 159 [256/918 (28%)] Loss: 12396931.000000\n",
      "Train Epoch: 159 [272/918 (30%)] Loss: 9250858.000000\n",
      "Train Epoch: 159 [288/918 (31%)] Loss: 6982718.500000\n",
      "Train Epoch: 159 [304/918 (33%)] Loss: 5318652.000000\n",
      "Train Epoch: 159 [320/918 (35%)] Loss: 5074565.000000\n",
      "Train Epoch: 159 [336/918 (37%)] Loss: 10525266.000000\n",
      "Train Epoch: 159 [352/918 (38%)] Loss: 6305157.000000\n",
      "Train Epoch: 159 [368/918 (40%)] Loss: 6769637.000000\n",
      "Train Epoch: 159 [384/918 (42%)] Loss: 11989790.000000\n",
      "Train Epoch: 159 [400/918 (44%)] Loss: 7186430.500000\n",
      "Train Epoch: 159 [416/918 (45%)] Loss: 6732961.000000\n",
      "Train Epoch: 159 [432/918 (47%)] Loss: 11059432.000000\n",
      "Train Epoch: 159 [448/918 (49%)] Loss: 6029441.500000\n",
      "Train Epoch: 159 [464/918 (51%)] Loss: 6631747.500000\n",
      "Train Epoch: 159 [480/918 (52%)] Loss: 7655067.500000\n",
      "Train Epoch: 159 [496/918 (54%)] Loss: 9925964.000000\n",
      "Train Epoch: 159 [512/918 (56%)] Loss: 7434470.500000\n",
      "Train Epoch: 159 [528/918 (58%)] Loss: 8359406.500000\n",
      "Train Epoch: 159 [544/918 (59%)] Loss: 9040740.000000\n",
      "Train Epoch: 159 [560/918 (61%)] Loss: 6910969.500000\n",
      "Train Epoch: 159 [576/918 (63%)] Loss: 7330408.000000\n",
      "Train Epoch: 159 [592/918 (64%)] Loss: 9530530.000000\n",
      "Train Epoch: 159 [608/918 (66%)] Loss: 10275634.000000\n",
      "Train Epoch: 159 [624/918 (68%)] Loss: 6648072.000000\n",
      "Train Epoch: 159 [640/918 (70%)] Loss: 13795168.000000\n",
      "Train Epoch: 159 [656/918 (71%)] Loss: 9191176.000000\n",
      "Train Epoch: 159 [672/918 (73%)] Loss: 6609734.000000\n",
      "Train Epoch: 159 [688/918 (75%)] Loss: 10119867.000000\n",
      "Train Epoch: 159 [704/918 (77%)] Loss: 10711778.000000\n",
      "Train Epoch: 159 [720/918 (78%)] Loss: 7779468.000000\n",
      "Train Epoch: 159 [736/918 (80%)] Loss: 7992344.000000\n",
      "Train Epoch: 159 [752/918 (82%)] Loss: 8801424.000000\n",
      "Train Epoch: 159 [768/918 (84%)] Loss: 8398324.000000\n",
      "Train Epoch: 159 [784/918 (85%)] Loss: 11498069.000000\n",
      "Train Epoch: 159 [800/918 (87%)] Loss: 7454325.000000\n",
      "Train Epoch: 159 [816/918 (89%)] Loss: 12038784.000000\n",
      "Train Epoch: 159 [832/918 (91%)] Loss: 7146226.500000\n",
      "Train Epoch: 159 [848/918 (92%)] Loss: 10958464.000000\n",
      "Train Epoch: 159 [864/918 (94%)] Loss: 8479763.000000\n",
      "Train Epoch: 159 [880/918 (96%)] Loss: 11962806.000000\n",
      "Train Epoch: 159 [896/918 (98%)] Loss: 11554299.000000\n",
      "Train Epoch: 159 [912/918 (99%)] Loss: 8361887.000000\n",
      "    epoch          : 159\n",
      "    loss           : 9211441.339130435\n",
      "    ess            : 8.20687779965608\n",
      "    log_marginal   : -9211438.991304347\n",
      "    val_loss       : 7878069.923076923\n",
      "    val_ess        : 6.036124192751371\n",
      "    val_log_marginal: -7878068.115384615\n",
      "Train Epoch: 160 [0/918 (0%)] Loss: 8340061.000000\n",
      "Train Epoch: 160 [16/918 (2%)] Loss: 9888168.000000\n",
      "Train Epoch: 160 [32/918 (3%)] Loss: 9600207.000000\n",
      "Train Epoch: 160 [48/918 (5%)] Loss: 8576492.000000\n",
      "Train Epoch: 160 [64/918 (7%)] Loss: 19797604.000000\n",
      "Train Epoch: 160 [80/918 (9%)] Loss: 7433510.500000\n",
      "Train Epoch: 160 [96/918 (10%)] Loss: 23654848.000000\n",
      "Train Epoch: 160 [112/918 (12%)] Loss: 8745332.000000\n",
      "Train Epoch: 160 [128/918 (14%)] Loss: 10373669.000000\n",
      "Train Epoch: 160 [144/918 (16%)] Loss: 7307941.000000\n",
      "Train Epoch: 160 [160/918 (17%)] Loss: 7190800.000000\n",
      "Train Epoch: 160 [176/918 (19%)] Loss: 11005294.000000\n",
      "Train Epoch: 160 [192/918 (21%)] Loss: 5590233.500000\n",
      "Train Epoch: 160 [208/918 (23%)] Loss: 8254451.500000\n",
      "Train Epoch: 160 [224/918 (24%)] Loss: 5959085.500000\n",
      "Train Epoch: 160 [240/918 (26%)] Loss: 9647920.000000\n",
      "Train Epoch: 160 [256/918 (28%)] Loss: 9191267.000000\n",
      "Train Epoch: 160 [272/918 (30%)] Loss: 9169784.000000\n",
      "Train Epoch: 160 [288/918 (31%)] Loss: 9877716.000000\n",
      "Train Epoch: 160 [304/918 (33%)] Loss: 11356072.000000\n",
      "Train Epoch: 160 [320/918 (35%)] Loss: 6144812.000000\n",
      "Train Epoch: 160 [336/918 (37%)] Loss: 8880672.000000\n",
      "Train Epoch: 160 [352/918 (38%)] Loss: 7125138.500000\n",
      "Train Epoch: 160 [368/918 (40%)] Loss: 6583019.500000\n",
      "Train Epoch: 160 [384/918 (42%)] Loss: 7500024.000000\n",
      "Train Epoch: 160 [400/918 (44%)] Loss: 12614041.000000\n",
      "Train Epoch: 160 [416/918 (45%)] Loss: 9351129.000000\n",
      "Train Epoch: 160 [432/918 (47%)] Loss: 10539968.000000\n",
      "Train Epoch: 160 [448/918 (49%)] Loss: 12990339.000000\n",
      "Train Epoch: 160 [464/918 (51%)] Loss: 7887347.500000\n",
      "Train Epoch: 160 [480/918 (52%)] Loss: 4275868.000000\n",
      "Train Epoch: 160 [496/918 (54%)] Loss: 8821184.000000\n",
      "Train Epoch: 160 [512/918 (56%)] Loss: 7738851.500000\n",
      "Train Epoch: 160 [528/918 (58%)] Loss: 7602217.500000\n",
      "Train Epoch: 160 [544/918 (59%)] Loss: 12601811.000000\n",
      "Train Epoch: 160 [560/918 (61%)] Loss: 8841554.000000\n",
      "Train Epoch: 160 [576/918 (63%)] Loss: 13053153.000000\n",
      "Train Epoch: 160 [592/918 (64%)] Loss: 7555389.000000\n",
      "Train Epoch: 160 [608/918 (66%)] Loss: 9332799.000000\n",
      "Train Epoch: 160 [624/918 (68%)] Loss: 9037883.000000\n",
      "Train Epoch: 160 [640/918 (70%)] Loss: 11363040.000000\n",
      "Train Epoch: 160 [656/918 (71%)] Loss: 9186610.000000\n",
      "Train Epoch: 160 [672/918 (73%)] Loss: 9708672.000000\n",
      "Train Epoch: 160 [688/918 (75%)] Loss: 9741399.000000\n",
      "Train Epoch: 160 [704/918 (77%)] Loss: 10371619.000000\n",
      "Train Epoch: 160 [720/918 (78%)] Loss: 7383385.000000\n",
      "Train Epoch: 160 [736/918 (80%)] Loss: 10275314.000000\n",
      "Train Epoch: 160 [752/918 (82%)] Loss: 7041369.500000\n",
      "Train Epoch: 160 [768/918 (84%)] Loss: 7509261.500000\n",
      "Train Epoch: 160 [784/918 (85%)] Loss: 10829287.000000\n",
      "Train Epoch: 160 [800/918 (87%)] Loss: 10171023.000000\n",
      "Train Epoch: 160 [816/918 (89%)] Loss: 13414106.000000\n",
      "Train Epoch: 160 [832/918 (91%)] Loss: 7712361.500000\n",
      "Train Epoch: 160 [848/918 (92%)] Loss: 8241169.500000\n",
      "Train Epoch: 160 [864/918 (94%)] Loss: 8000005.500000\n",
      "Train Epoch: 160 [880/918 (96%)] Loss: 10802309.000000\n",
      "Train Epoch: 160 [896/918 (98%)] Loss: 12074444.000000\n",
      "Train Epoch: 160 [912/918 (99%)] Loss: 9702531.000000\n",
      "    epoch          : 160\n",
      "    loss           : 9366850.226086957\n",
      "    ess            : 7.85392978709677\n",
      "    log_marginal   : -9366848.17826087\n",
      "    val_loss       : 8953246.307692308\n",
      "    val_ess        : 8.782125638081478\n",
      "    val_log_marginal: -8953240.5\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch160.pth ...\n",
      "Train Epoch: 161 [0/918 (0%)] Loss: 7669933.000000\n",
      "Train Epoch: 161 [16/918 (2%)] Loss: 7483835.500000\n",
      "Train Epoch: 161 [32/918 (3%)] Loss: 8197388.000000\n",
      "Train Epoch: 161 [48/918 (5%)] Loss: 7875931.500000\n",
      "Train Epoch: 161 [64/918 (7%)] Loss: 6569583.500000\n",
      "Train Epoch: 161 [80/918 (9%)] Loss: 6684281.000000\n",
      "Train Epoch: 161 [96/918 (10%)] Loss: 6144671.500000\n",
      "Train Epoch: 161 [112/918 (12%)] Loss: 11756018.000000\n",
      "Train Epoch: 161 [128/918 (14%)] Loss: 8237185.500000\n",
      "Train Epoch: 161 [144/918 (16%)] Loss: 14093363.000000\n",
      "Train Epoch: 161 [160/918 (17%)] Loss: 9182517.000000\n",
      "Train Epoch: 161 [176/918 (19%)] Loss: 9066009.000000\n",
      "Train Epoch: 161 [192/918 (21%)] Loss: 8131431.500000\n",
      "Train Epoch: 161 [208/918 (23%)] Loss: 9302828.000000\n",
      "Train Epoch: 161 [224/918 (24%)] Loss: 10677136.000000\n",
      "Train Epoch: 161 [240/918 (26%)] Loss: 9155714.000000\n",
      "Train Epoch: 161 [256/918 (28%)] Loss: 5147224.000000\n",
      "Train Epoch: 161 [272/918 (30%)] Loss: 5538667.500000\n",
      "Train Epoch: 161 [288/918 (31%)] Loss: 8857487.000000\n",
      "Train Epoch: 161 [304/918 (33%)] Loss: 8399826.000000\n",
      "Train Epoch: 161 [320/918 (35%)] Loss: 9213544.000000\n",
      "Train Epoch: 161 [336/918 (37%)] Loss: 12912216.000000\n",
      "Train Epoch: 161 [352/918 (38%)] Loss: 8185598.500000\n",
      "Train Epoch: 161 [368/918 (40%)] Loss: 7534149.000000\n",
      "Train Epoch: 161 [384/918 (42%)] Loss: 7435929.500000\n",
      "Train Epoch: 161 [400/918 (44%)] Loss: 9152151.000000\n",
      "Train Epoch: 161 [416/918 (45%)] Loss: 11296375.000000\n",
      "Train Epoch: 161 [432/918 (47%)] Loss: 8152044.000000\n",
      "Train Epoch: 161 [448/918 (49%)] Loss: 7737758.500000\n",
      "Train Epoch: 161 [464/918 (51%)] Loss: 8296611.500000\n",
      "Train Epoch: 161 [480/918 (52%)] Loss: 10077098.000000\n",
      "Train Epoch: 161 [496/918 (54%)] Loss: 12594254.000000\n",
      "Train Epoch: 161 [512/918 (56%)] Loss: 9277135.000000\n",
      "Train Epoch: 161 [528/918 (58%)] Loss: 6421931.000000\n",
      "Train Epoch: 161 [544/918 (59%)] Loss: 11274824.000000\n",
      "Train Epoch: 161 [560/918 (61%)] Loss: 7981363.500000\n",
      "Train Epoch: 161 [576/918 (63%)] Loss: 8665172.000000\n",
      "Train Epoch: 161 [592/918 (64%)] Loss: 9723074.000000\n",
      "Train Epoch: 161 [608/918 (66%)] Loss: 6605574.000000\n",
      "Train Epoch: 161 [624/918 (68%)] Loss: 5868965.500000\n",
      "Train Epoch: 161 [640/918 (70%)] Loss: 9153270.000000\n",
      "Train Epoch: 161 [656/918 (71%)] Loss: 13771103.000000\n",
      "Train Epoch: 161 [672/918 (73%)] Loss: 10135975.000000\n",
      "Train Epoch: 161 [688/918 (75%)] Loss: 12031039.000000\n",
      "Train Epoch: 161 [704/918 (77%)] Loss: 14553643.000000\n",
      "Train Epoch: 161 [720/918 (78%)] Loss: 10269148.000000\n",
      "Train Epoch: 161 [736/918 (80%)] Loss: 6878587.500000\n",
      "Train Epoch: 161 [752/918 (82%)] Loss: 7537241.500000\n",
      "Train Epoch: 161 [768/918 (84%)] Loss: 10525760.000000\n",
      "Train Epoch: 161 [784/918 (85%)] Loss: 10309323.000000\n",
      "Train Epoch: 161 [800/918 (87%)] Loss: 8810559.000000\n",
      "Train Epoch: 161 [816/918 (89%)] Loss: 5870541.000000\n",
      "Train Epoch: 161 [832/918 (91%)] Loss: 7545195.500000\n",
      "Train Epoch: 161 [848/918 (92%)] Loss: 9786264.000000\n",
      "Train Epoch: 161 [864/918 (94%)] Loss: 7552336.000000\n",
      "Train Epoch: 161 [880/918 (96%)] Loss: 9924320.000000\n",
      "Train Epoch: 161 [896/918 (98%)] Loss: 6924107.500000\n",
      "Train Epoch: 161 [912/918 (99%)] Loss: 14300372.000000\n",
      "    epoch          : 161\n",
      "    loss           : 8867621.291304348\n",
      "    ess            : 7.956279590855474\n",
      "    log_marginal   : -8867619.634782609\n",
      "    val_loss       : 9856737.26923077\n",
      "    val_ess        : 8.395089369553785\n",
      "    val_log_marginal: -9856733.653846154\n",
      "Train Epoch: 162 [0/918 (0%)] Loss: 10883549.000000\n",
      "Train Epoch: 162 [16/918 (2%)] Loss: 7957146.500000\n",
      "Train Epoch: 162 [32/918 (3%)] Loss: 7400323.500000\n",
      "Train Epoch: 162 [48/918 (5%)] Loss: 6580814.500000\n",
      "Train Epoch: 162 [64/918 (7%)] Loss: 7702098.500000\n",
      "Train Epoch: 162 [80/918 (9%)] Loss: 9148172.000000\n",
      "Train Epoch: 162 [96/918 (10%)] Loss: 6659466.000000\n",
      "Train Epoch: 162 [112/918 (12%)] Loss: 11237220.000000\n",
      "Train Epoch: 162 [128/918 (14%)] Loss: 7527622.500000\n",
      "Train Epoch: 162 [144/918 (16%)] Loss: 14554739.000000\n",
      "Train Epoch: 162 [160/918 (17%)] Loss: 8341505.500000\n",
      "Train Epoch: 162 [176/918 (19%)] Loss: 9570346.000000\n",
      "Train Epoch: 162 [192/918 (21%)] Loss: 16327471.000000\n",
      "Train Epoch: 162 [208/918 (23%)] Loss: 8761834.000000\n",
      "Train Epoch: 162 [224/918 (24%)] Loss: 4768564.000000\n",
      "Train Epoch: 162 [240/918 (26%)] Loss: 13250270.000000\n",
      "Train Epoch: 162 [256/918 (28%)] Loss: 7568249.500000\n",
      "Train Epoch: 162 [272/918 (30%)] Loss: 9324415.000000\n",
      "Train Epoch: 162 [288/918 (31%)] Loss: 10723712.000000\n",
      "Train Epoch: 162 [304/918 (33%)] Loss: 7305398.500000\n",
      "Train Epoch: 162 [320/918 (35%)] Loss: 10378216.000000\n",
      "Train Epoch: 162 [336/918 (37%)] Loss: 8414643.000000\n",
      "Train Epoch: 162 [352/918 (38%)] Loss: 9640810.000000\n",
      "Train Epoch: 162 [368/918 (40%)] Loss: 9626189.000000\n",
      "Train Epoch: 162 [384/918 (42%)] Loss: 11821703.000000\n",
      "Train Epoch: 162 [400/918 (44%)] Loss: 8857108.000000\n",
      "Train Epoch: 162 [416/918 (45%)] Loss: 12416819.000000\n",
      "Train Epoch: 162 [432/918 (47%)] Loss: 11901987.000000\n",
      "Train Epoch: 162 [448/918 (49%)] Loss: 7764848.000000\n",
      "Train Epoch: 162 [464/918 (51%)] Loss: 8911664.000000\n",
      "Train Epoch: 162 [480/918 (52%)] Loss: 9132959.000000\n",
      "Train Epoch: 162 [496/918 (54%)] Loss: 7291192.000000\n",
      "Train Epoch: 162 [512/918 (56%)] Loss: 10526109.000000\n",
      "Train Epoch: 162 [528/918 (58%)] Loss: 10656379.000000\n",
      "Train Epoch: 162 [544/918 (59%)] Loss: 10006234.000000\n",
      "Train Epoch: 162 [560/918 (61%)] Loss: 9517155.000000\n",
      "Train Epoch: 162 [576/918 (63%)] Loss: 8630820.000000\n",
      "Train Epoch: 162 [592/918 (64%)] Loss: 10798709.000000\n",
      "Train Epoch: 162 [608/918 (66%)] Loss: 17289622.000000\n",
      "Train Epoch: 162 [624/918 (68%)] Loss: 7039016.000000\n",
      "Train Epoch: 162 [640/918 (70%)] Loss: 12650346.000000\n",
      "Train Epoch: 162 [656/918 (71%)] Loss: 15850789.000000\n",
      "Train Epoch: 162 [672/918 (73%)] Loss: 8929949.000000\n",
      "Train Epoch: 162 [688/918 (75%)] Loss: 12871877.000000\n",
      "Train Epoch: 162 [704/918 (77%)] Loss: 12417822.000000\n",
      "Train Epoch: 162 [720/918 (78%)] Loss: 10906439.000000\n",
      "Train Epoch: 162 [736/918 (80%)] Loss: 7010911.500000\n",
      "Train Epoch: 162 [752/918 (82%)] Loss: 8886154.000000\n",
      "Train Epoch: 162 [768/918 (84%)] Loss: 9798026.000000\n",
      "Train Epoch: 162 [784/918 (85%)] Loss: 8197104.000000\n",
      "Train Epoch: 162 [800/918 (87%)] Loss: 4800895.500000\n",
      "Train Epoch: 162 [816/918 (89%)] Loss: 12105740.000000\n",
      "Train Epoch: 162 [832/918 (91%)] Loss: 8298383.500000\n",
      "Train Epoch: 162 [848/918 (92%)] Loss: 9143199.000000\n",
      "Train Epoch: 162 [864/918 (94%)] Loss: 5608506.500000\n",
      "Train Epoch: 162 [880/918 (96%)] Loss: 11897758.000000\n",
      "Train Epoch: 162 [896/918 (98%)] Loss: 7154953.500000\n",
      "Train Epoch: 162 [912/918 (99%)] Loss: 5500430.000000\n",
      "    epoch          : 162\n",
      "    loss           : 9266137.852173913\n",
      "    ess            : 8.028484070819356\n",
      "    log_marginal   : -9266135.182608696\n",
      "    val_loss       : 9279549.076923076\n",
      "    val_ess        : 7.257585067015428\n",
      "    val_log_marginal: -9279546.384615384\n",
      "Train Epoch: 163 [0/918 (0%)] Loss: 9034455.000000\n",
      "Train Epoch: 163 [16/918 (2%)] Loss: 9948957.000000\n",
      "Train Epoch: 163 [32/918 (3%)] Loss: 7724997.500000\n",
      "Train Epoch: 163 [48/918 (5%)] Loss: 7163437.000000\n",
      "Train Epoch: 163 [64/918 (7%)] Loss: 9626093.000000\n",
      "Train Epoch: 163 [80/918 (9%)] Loss: 5421476.500000\n",
      "Train Epoch: 163 [96/918 (10%)] Loss: 6783769.500000\n",
      "Train Epoch: 163 [112/918 (12%)] Loss: 7133302.500000\n",
      "Train Epoch: 163 [128/918 (14%)] Loss: 9956428.000000\n",
      "Train Epoch: 163 [144/918 (16%)] Loss: 8679644.000000\n",
      "Train Epoch: 163 [160/918 (17%)] Loss: 11881535.000000\n",
      "Train Epoch: 163 [176/918 (19%)] Loss: 11575592.000000\n",
      "Train Epoch: 163 [192/918 (21%)] Loss: 7707109.000000\n",
      "Train Epoch: 163 [208/918 (23%)] Loss: 6709044.000000\n",
      "Train Epoch: 163 [224/918 (24%)] Loss: 8618692.000000\n",
      "Train Epoch: 163 [240/918 (26%)] Loss: 8692578.000000\n",
      "Train Epoch: 163 [256/918 (28%)] Loss: 9040527.000000\n",
      "Train Epoch: 163 [272/918 (30%)] Loss: 13683013.000000\n",
      "Train Epoch: 163 [288/918 (31%)] Loss: 10207315.000000\n",
      "Train Epoch: 163 [304/918 (33%)] Loss: 9266208.000000\n",
      "Train Epoch: 163 [320/918 (35%)] Loss: 8002061.000000\n",
      "Train Epoch: 163 [336/918 (37%)] Loss: 8324904.000000\n",
      "Train Epoch: 163 [352/918 (38%)] Loss: 10650691.000000\n",
      "Train Epoch: 163 [368/918 (40%)] Loss: 8094914.500000\n",
      "Train Epoch: 163 [384/918 (42%)] Loss: 9005339.000000\n",
      "Train Epoch: 163 [400/918 (44%)] Loss: 6070242.500000\n",
      "Train Epoch: 163 [416/918 (45%)] Loss: 13389896.000000\n",
      "Train Epoch: 163 [432/918 (47%)] Loss: 5795367.500000\n",
      "Train Epoch: 163 [448/918 (49%)] Loss: 10553082.000000\n",
      "Train Epoch: 163 [464/918 (51%)] Loss: 10227972.000000\n",
      "Train Epoch: 163 [480/918 (52%)] Loss: 15216311.000000\n",
      "Train Epoch: 163 [496/918 (54%)] Loss: 7608444.000000\n",
      "Train Epoch: 163 [512/918 (56%)] Loss: 9037743.000000\n",
      "Train Epoch: 163 [528/918 (58%)] Loss: 8812732.000000\n",
      "Train Epoch: 163 [544/918 (59%)] Loss: 8421957.000000\n",
      "Train Epoch: 163 [560/918 (61%)] Loss: 6300660.000000\n",
      "Train Epoch: 163 [576/918 (63%)] Loss: 6007964.000000\n",
      "Train Epoch: 163 [592/918 (64%)] Loss: 12117476.000000\n",
      "Train Epoch: 163 [608/918 (66%)] Loss: 7117062.500000\n",
      "Train Epoch: 163 [624/918 (68%)] Loss: 7171541.000000\n",
      "Train Epoch: 163 [640/918 (70%)] Loss: 15028720.000000\n",
      "Train Epoch: 163 [656/918 (71%)] Loss: 5741018.000000\n",
      "Train Epoch: 163 [672/918 (73%)] Loss: 9263334.000000\n",
      "Train Epoch: 163 [688/918 (75%)] Loss: 7613637.500000\n",
      "Train Epoch: 163 [704/918 (77%)] Loss: 7014463.500000\n",
      "Train Epoch: 163 [720/918 (78%)] Loss: 9936080.000000\n",
      "Train Epoch: 163 [736/918 (80%)] Loss: 8256246.500000\n",
      "Train Epoch: 163 [752/918 (82%)] Loss: 11619454.000000\n",
      "Train Epoch: 163 [768/918 (84%)] Loss: 10367443.000000\n",
      "Train Epoch: 163 [784/918 (85%)] Loss: 10009303.000000\n",
      "Train Epoch: 163 [800/918 (87%)] Loss: 8688031.000000\n",
      "Train Epoch: 163 [816/918 (89%)] Loss: 11578255.000000\n",
      "Train Epoch: 163 [832/918 (91%)] Loss: 8780907.000000\n",
      "Train Epoch: 163 [848/918 (92%)] Loss: 8469658.000000\n",
      "Train Epoch: 163 [864/918 (94%)] Loss: 13617698.000000\n",
      "Train Epoch: 163 [880/918 (96%)] Loss: 6326327.500000\n",
      "Train Epoch: 163 [896/918 (98%)] Loss: 8309597.000000\n",
      "Train Epoch: 163 [912/918 (99%)] Loss: 6058809.000000\n",
      "    epoch          : 163\n",
      "    loss           : 8904191.313043479\n",
      "    ess            : 7.638963599826979\n",
      "    log_marginal   : -8904188.917391304\n",
      "    val_loss       : 9357588.115384616\n",
      "    val_ess        : 7.562461522909311\n",
      "    val_log_marginal: -9357586.384615384\n",
      "Train Epoch: 164 [0/918 (0%)] Loss: 12853699.000000\n",
      "Train Epoch: 164 [16/918 (2%)] Loss: 6871561.500000\n",
      "Train Epoch: 164 [32/918 (3%)] Loss: 7908292.000000\n",
      "Train Epoch: 164 [48/918 (5%)] Loss: 9112466.000000\n",
      "Train Epoch: 164 [64/918 (7%)] Loss: 7707737.500000\n",
      "Train Epoch: 164 [80/918 (9%)] Loss: 11449912.000000\n",
      "Train Epoch: 164 [96/918 (10%)] Loss: 13984120.000000\n",
      "Train Epoch: 164 [112/918 (12%)] Loss: 8353704.000000\n",
      "Train Epoch: 164 [128/918 (14%)] Loss: 11844379.000000\n",
      "Train Epoch: 164 [144/918 (16%)] Loss: 8840727.000000\n",
      "Train Epoch: 164 [160/918 (17%)] Loss: 9015615.000000\n",
      "Train Epoch: 164 [176/918 (19%)] Loss: 8254205.000000\n",
      "Train Epoch: 164 [192/918 (21%)] Loss: 10648925.000000\n",
      "Train Epoch: 164 [208/918 (23%)] Loss: 8312832.000000\n",
      "Train Epoch: 164 [224/918 (24%)] Loss: 9924026.000000\n",
      "Train Epoch: 164 [240/918 (26%)] Loss: 6109115.000000\n",
      "Train Epoch: 164 [256/918 (28%)] Loss: 10159410.000000\n",
      "Train Epoch: 164 [272/918 (30%)] Loss: 9083698.000000\n",
      "Train Epoch: 164 [288/918 (31%)] Loss: 7226734.500000\n",
      "Train Epoch: 164 [304/918 (33%)] Loss: 6157817.000000\n",
      "Train Epoch: 164 [320/918 (35%)] Loss: 6848251.500000\n",
      "Train Epoch: 164 [336/918 (37%)] Loss: 8103845.500000\n",
      "Train Epoch: 164 [352/918 (38%)] Loss: 7596515.500000\n",
      "Train Epoch: 164 [368/918 (40%)] Loss: 8427882.000000\n",
      "Train Epoch: 164 [384/918 (42%)] Loss: 8163537.500000\n",
      "Train Epoch: 164 [400/918 (44%)] Loss: 10566015.000000\n",
      "Train Epoch: 164 [416/918 (45%)] Loss: 6743379.500000\n",
      "Train Epoch: 164 [432/918 (47%)] Loss: 7407563.500000\n",
      "Train Epoch: 164 [448/918 (49%)] Loss: 6972149.000000\n",
      "Train Epoch: 164 [464/918 (51%)] Loss: 7862021.000000\n",
      "Train Epoch: 164 [480/918 (52%)] Loss: 7237101.500000\n",
      "Train Epoch: 164 [496/918 (54%)] Loss: 14523347.000000\n",
      "Train Epoch: 164 [512/918 (56%)] Loss: 22415536.000000\n",
      "Train Epoch: 164 [528/918 (58%)] Loss: 8444192.000000\n",
      "Train Epoch: 164 [544/918 (59%)] Loss: 16313699.000000\n",
      "Train Epoch: 164 [560/918 (61%)] Loss: 7492043.500000\n",
      "Train Epoch: 164 [576/918 (63%)] Loss: 7347757.000000\n",
      "Train Epoch: 164 [592/918 (64%)] Loss: 8617077.000000\n",
      "Train Epoch: 164 [608/918 (66%)] Loss: 7909841.500000\n",
      "Train Epoch: 164 [624/918 (68%)] Loss: 5580373.000000\n",
      "Train Epoch: 164 [640/918 (70%)] Loss: 12617494.000000\n",
      "Train Epoch: 164 [656/918 (71%)] Loss: 9606263.000000\n",
      "Train Epoch: 164 [672/918 (73%)] Loss: 7774087.500000\n",
      "Train Epoch: 164 [688/918 (75%)] Loss: 9966472.000000\n",
      "Train Epoch: 164 [704/918 (77%)] Loss: 6626966.500000\n",
      "Train Epoch: 164 [720/918 (78%)] Loss: 6791063.500000\n",
      "Train Epoch: 164 [736/918 (80%)] Loss: 8545856.000000\n",
      "Train Epoch: 164 [752/918 (82%)] Loss: 8639767.000000\n",
      "Train Epoch: 164 [768/918 (84%)] Loss: 9265279.000000\n",
      "Train Epoch: 164 [784/918 (85%)] Loss: 12778690.000000\n",
      "Train Epoch: 164 [800/918 (87%)] Loss: 7832117.000000\n",
      "Train Epoch: 164 [816/918 (89%)] Loss: 9742599.000000\n",
      "Train Epoch: 164 [832/918 (91%)] Loss: 8776176.000000\n",
      "Train Epoch: 164 [848/918 (92%)] Loss: 13630112.000000\n",
      "Train Epoch: 164 [864/918 (94%)] Loss: 15858935.000000\n",
      "Train Epoch: 164 [880/918 (96%)] Loss: 7104196.000000\n",
      "Train Epoch: 164 [896/918 (98%)] Loss: 6637829.000000\n",
      "Train Epoch: 164 [912/918 (99%)] Loss: 6674533.500000\n",
      "    epoch          : 164\n",
      "    loss           : 9042212.421739131\n",
      "    ess            : 8.197763648240462\n",
      "    log_marginal   : -9042208.795652173\n",
      "    val_loss       : 8456041.423076924\n",
      "    val_ess        : 7.1167590251335735\n",
      "    val_log_marginal: -8456040.192307692\n",
      "Train Epoch: 165 [0/918 (0%)] Loss: 7118208.000000\n",
      "Train Epoch: 165 [16/918 (2%)] Loss: 11618208.000000\n",
      "Train Epoch: 165 [32/918 (3%)] Loss: 6697061.500000\n",
      "Train Epoch: 165 [48/918 (5%)] Loss: 14661440.000000\n",
      "Train Epoch: 165 [64/918 (7%)] Loss: 12550907.000000\n",
      "Train Epoch: 165 [80/918 (9%)] Loss: 9986647.000000\n",
      "Train Epoch: 165 [96/918 (10%)] Loss: 13578746.000000\n",
      "Train Epoch: 165 [112/918 (12%)] Loss: 13331343.000000\n",
      "Train Epoch: 165 [128/918 (14%)] Loss: 7424449.000000\n",
      "Train Epoch: 165 [144/918 (16%)] Loss: 5648107.500000\n",
      "Train Epoch: 165 [160/918 (17%)] Loss: 6453805.500000\n",
      "Train Epoch: 165 [176/918 (19%)] Loss: 9661635.000000\n",
      "Train Epoch: 165 [192/918 (21%)] Loss: 7057553.500000\n",
      "Train Epoch: 165 [208/918 (23%)] Loss: 10278396.000000\n",
      "Train Epoch: 165 [224/918 (24%)] Loss: 7361733.000000\n",
      "Train Epoch: 165 [240/918 (26%)] Loss: 9403938.000000\n",
      "Train Epoch: 165 [256/918 (28%)] Loss: 9212644.000000\n",
      "Train Epoch: 165 [272/918 (30%)] Loss: 9555038.000000\n",
      "Train Epoch: 165 [288/918 (31%)] Loss: 8990799.000000\n",
      "Train Epoch: 165 [304/918 (33%)] Loss: 14657389.000000\n",
      "Train Epoch: 165 [320/918 (35%)] Loss: 13169450.000000\n",
      "Train Epoch: 165 [336/918 (37%)] Loss: 7859513.500000\n",
      "Train Epoch: 165 [352/918 (38%)] Loss: 10444117.000000\n",
      "Train Epoch: 165 [368/918 (40%)] Loss: 8670793.000000\n",
      "Train Epoch: 165 [384/918 (42%)] Loss: 6902437.000000\n",
      "Train Epoch: 165 [400/918 (44%)] Loss: 9098464.000000\n",
      "Train Epoch: 165 [416/918 (45%)] Loss: 5740146.500000\n",
      "Train Epoch: 165 [432/918 (47%)] Loss: 11761454.000000\n",
      "Train Epoch: 165 [448/918 (49%)] Loss: 6227429.500000\n",
      "Train Epoch: 165 [464/918 (51%)] Loss: 10813068.000000\n",
      "Train Epoch: 165 [480/918 (52%)] Loss: 6773094.500000\n",
      "Train Epoch: 165 [496/918 (54%)] Loss: 8544646.000000\n",
      "Train Epoch: 165 [512/918 (56%)] Loss: 8215449.500000\n",
      "Train Epoch: 165 [528/918 (58%)] Loss: 8218697.500000\n",
      "Train Epoch: 165 [544/918 (59%)] Loss: 8458907.000000\n",
      "Train Epoch: 165 [560/918 (61%)] Loss: 5222888.000000\n",
      "Train Epoch: 165 [576/918 (63%)] Loss: 8100412.000000\n",
      "Train Epoch: 165 [592/918 (64%)] Loss: 8433115.000000\n",
      "Train Epoch: 165 [608/918 (66%)] Loss: 10837051.000000\n",
      "Train Epoch: 165 [624/918 (68%)] Loss: 8261470.500000\n",
      "Train Epoch: 165 [640/918 (70%)] Loss: 7063166.500000\n",
      "Train Epoch: 165 [656/918 (71%)] Loss: 5339825.000000\n",
      "Train Epoch: 165 [672/918 (73%)] Loss: 7951548.000000\n",
      "Train Epoch: 165 [688/918 (75%)] Loss: 9917993.000000\n",
      "Train Epoch: 165 [704/918 (77%)] Loss: 11374988.000000\n",
      "Train Epoch: 165 [720/918 (78%)] Loss: 11364064.000000\n",
      "Train Epoch: 165 [736/918 (80%)] Loss: 8714697.000000\n",
      "Train Epoch: 165 [752/918 (82%)] Loss: 8770357.000000\n",
      "Train Epoch: 165 [768/918 (84%)] Loss: 6534814.500000\n",
      "Train Epoch: 165 [784/918 (85%)] Loss: 5261795.500000\n",
      "Train Epoch: 165 [800/918 (87%)] Loss: 13432439.000000\n",
      "Train Epoch: 165 [816/918 (89%)] Loss: 12285800.000000\n",
      "Train Epoch: 165 [832/918 (91%)] Loss: 9126704.000000\n",
      "Train Epoch: 165 [848/918 (92%)] Loss: 11052879.000000\n",
      "Train Epoch: 165 [864/918 (94%)] Loss: 14147898.000000\n",
      "Train Epoch: 165 [880/918 (96%)] Loss: 12974028.000000\n",
      "Train Epoch: 165 [896/918 (98%)] Loss: 7192029.500000\n",
      "Train Epoch: 165 [912/918 (99%)] Loss: 6998057.500000\n",
      "    epoch          : 165\n",
      "    loss           : 9059342.808695652\n",
      "    ess            : 7.660976297959038\n",
      "    log_marginal   : -9059340.356521739\n",
      "    val_loss       : 9411880.5\n",
      "    val_ess        : 6.256799642856304\n",
      "    val_log_marginal: -9411877.26923077\n",
      "Train Epoch: 166 [0/918 (0%)] Loss: 11560883.000000\n",
      "Train Epoch: 166 [16/918 (2%)] Loss: 5949333.500000\n",
      "Train Epoch: 166 [32/918 (3%)] Loss: 7711026.500000\n",
      "Train Epoch: 166 [48/918 (5%)] Loss: 7731308.000000\n",
      "Train Epoch: 166 [64/918 (7%)] Loss: 6906625.500000\n",
      "Train Epoch: 166 [80/918 (9%)] Loss: 6330912.500000\n",
      "Train Epoch: 166 [96/918 (10%)] Loss: 7065562.500000\n",
      "Train Epoch: 166 [112/918 (12%)] Loss: 6906544.000000\n",
      "Train Epoch: 166 [128/918 (14%)] Loss: 11353358.000000\n",
      "Train Epoch: 166 [144/918 (16%)] Loss: 7446813.000000\n",
      "Train Epoch: 166 [160/918 (17%)] Loss: 13615277.000000\n",
      "Train Epoch: 166 [176/918 (19%)] Loss: 7740239.500000\n",
      "Train Epoch: 166 [192/918 (21%)] Loss: 8580848.000000\n",
      "Train Epoch: 166 [208/918 (23%)] Loss: 9528144.000000\n",
      "Train Epoch: 166 [224/918 (24%)] Loss: 9474256.000000\n",
      "Train Epoch: 166 [240/918 (26%)] Loss: 13507744.000000\n",
      "Train Epoch: 166 [256/918 (28%)] Loss: 6170394.000000\n",
      "Train Epoch: 166 [272/918 (30%)] Loss: 5784243.500000\n",
      "Train Epoch: 166 [288/918 (31%)] Loss: 9756642.000000\n",
      "Train Epoch: 166 [304/918 (33%)] Loss: 12159765.000000\n",
      "Train Epoch: 166 [320/918 (35%)] Loss: 6429889.500000\n",
      "Train Epoch: 166 [336/918 (37%)] Loss: 5505542.500000\n",
      "Train Epoch: 166 [352/918 (38%)] Loss: 8012808.000000\n",
      "Train Epoch: 166 [368/918 (40%)] Loss: 5994650.000000\n",
      "Train Epoch: 166 [384/918 (42%)] Loss: 9735426.000000\n",
      "Train Epoch: 166 [400/918 (44%)] Loss: 9907096.000000\n",
      "Train Epoch: 166 [416/918 (45%)] Loss: 11562075.000000\n",
      "Train Epoch: 166 [432/918 (47%)] Loss: 7735762.500000\n",
      "Train Epoch: 166 [448/918 (49%)] Loss: 5630366.000000\n",
      "Train Epoch: 166 [464/918 (51%)] Loss: 6771731.500000\n",
      "Train Epoch: 166 [480/918 (52%)] Loss: 9366677.000000\n",
      "Train Epoch: 166 [496/918 (54%)] Loss: 9998947.000000\n",
      "Train Epoch: 166 [512/918 (56%)] Loss: 15669149.000000\n",
      "Train Epoch: 166 [528/918 (58%)] Loss: 6944206.500000\n",
      "Train Epoch: 166 [544/918 (59%)] Loss: 9933807.000000\n",
      "Train Epoch: 166 [560/918 (61%)] Loss: 8610310.000000\n",
      "Train Epoch: 166 [576/918 (63%)] Loss: 6831517.500000\n",
      "Train Epoch: 166 [592/918 (64%)] Loss: 7676481.500000\n",
      "Train Epoch: 166 [608/918 (66%)] Loss: 9395832.000000\n",
      "Train Epoch: 166 [624/918 (68%)] Loss: 10383890.000000\n",
      "Train Epoch: 166 [640/918 (70%)] Loss: 8889706.000000\n",
      "Train Epoch: 166 [656/918 (71%)] Loss: 11654698.000000\n",
      "Train Epoch: 166 [672/918 (73%)] Loss: 8786341.000000\n",
      "Train Epoch: 166 [688/918 (75%)] Loss: 4986037.500000\n",
      "Train Epoch: 166 [704/918 (77%)] Loss: 8392635.000000\n",
      "Train Epoch: 166 [720/918 (78%)] Loss: 7938715.500000\n",
      "Train Epoch: 166 [736/918 (80%)] Loss: 8668511.000000\n",
      "Train Epoch: 166 [752/918 (82%)] Loss: 11807707.000000\n",
      "Train Epoch: 166 [768/918 (84%)] Loss: 10593991.000000\n",
      "Train Epoch: 166 [784/918 (85%)] Loss: 6395578.000000\n",
      "Train Epoch: 166 [800/918 (87%)] Loss: 8817263.000000\n",
      "Train Epoch: 166 [816/918 (89%)] Loss: 7306229.000000\n",
      "Train Epoch: 166 [832/918 (91%)] Loss: 8222976.000000\n",
      "Train Epoch: 166 [848/918 (92%)] Loss: 8281822.500000\n",
      "Train Epoch: 166 [864/918 (94%)] Loss: 8792168.000000\n",
      "Train Epoch: 166 [880/918 (96%)] Loss: 8836108.000000\n",
      "Train Epoch: 166 [896/918 (98%)] Loss: 7889697.500000\n",
      "Train Epoch: 166 [912/918 (99%)] Loss: 6927429.500000\n",
      "    epoch          : 166\n",
      "    loss           : 8905731.904347826\n",
      "    ess            : 7.366905231061189\n",
      "    log_marginal   : -8905729.752173914\n",
      "    val_loss       : 8672320.5\n",
      "    val_ess        : 7.903586240915152\n",
      "    val_log_marginal: -8672317.846153846\n",
      "Train Epoch: 167 [0/918 (0%)] Loss: 9684589.000000\n",
      "Train Epoch: 167 [16/918 (2%)] Loss: 6111232.000000\n",
      "Train Epoch: 167 [32/918 (3%)] Loss: 6672662.000000\n",
      "Train Epoch: 167 [48/918 (5%)] Loss: 7343705.000000\n",
      "Train Epoch: 167 [64/918 (7%)] Loss: 7397318.500000\n",
      "Train Epoch: 167 [80/918 (9%)] Loss: 6232263.500000\n",
      "Train Epoch: 167 [96/918 (10%)] Loss: 8822937.000000\n",
      "Train Epoch: 167 [112/918 (12%)] Loss: 9503340.000000\n",
      "Train Epoch: 167 [128/918 (14%)] Loss: 8932245.000000\n",
      "Train Epoch: 167 [144/918 (16%)] Loss: 12928802.000000\n",
      "Train Epoch: 167 [160/918 (17%)] Loss: 8492442.000000\n",
      "Train Epoch: 167 [176/918 (19%)] Loss: 6810161.500000\n",
      "Train Epoch: 167 [192/918 (21%)] Loss: 6237404.500000\n",
      "Train Epoch: 167 [208/918 (23%)] Loss: 8876071.000000\n",
      "Train Epoch: 167 [224/918 (24%)] Loss: 6941116.000000\n",
      "Train Epoch: 167 [240/918 (26%)] Loss: 7902891.500000\n",
      "Train Epoch: 167 [256/918 (28%)] Loss: 7356835.500000\n",
      "Train Epoch: 167 [272/918 (30%)] Loss: 7246304.000000\n",
      "Train Epoch: 167 [288/918 (31%)] Loss: 6503369.500000\n",
      "Train Epoch: 167 [304/918 (33%)] Loss: 6946478.500000\n",
      "Train Epoch: 167 [320/918 (35%)] Loss: 5104412.500000\n",
      "Train Epoch: 167 [336/918 (37%)] Loss: 11127146.000000\n",
      "Train Epoch: 167 [352/918 (38%)] Loss: 6643530.000000\n",
      "Train Epoch: 167 [368/918 (40%)] Loss: 10811978.000000\n",
      "Train Epoch: 167 [384/918 (42%)] Loss: 10117769.000000\n",
      "Train Epoch: 167 [400/918 (44%)] Loss: 8407813.000000\n",
      "Train Epoch: 167 [416/918 (45%)] Loss: 7211326.500000\n",
      "Train Epoch: 167 [432/918 (47%)] Loss: 4763356.000000\n",
      "Train Epoch: 167 [448/918 (49%)] Loss: 10322413.000000\n",
      "Train Epoch: 167 [464/918 (51%)] Loss: 12209239.000000\n",
      "Train Epoch: 167 [480/918 (52%)] Loss: 7077392.000000\n",
      "Train Epoch: 167 [496/918 (54%)] Loss: 8338965.000000\n",
      "Train Epoch: 167 [512/918 (56%)] Loss: 6930862.500000\n",
      "Train Epoch: 167 [528/918 (58%)] Loss: 11752052.000000\n",
      "Train Epoch: 167 [544/918 (59%)] Loss: 9688970.000000\n",
      "Train Epoch: 167 [560/918 (61%)] Loss: 7598355.500000\n",
      "Train Epoch: 167 [576/918 (63%)] Loss: 8957068.000000\n",
      "Train Epoch: 167 [592/918 (64%)] Loss: 4798236.000000\n",
      "Train Epoch: 167 [608/918 (66%)] Loss: 7567133.000000\n",
      "Train Epoch: 167 [624/918 (68%)] Loss: 11216187.000000\n",
      "Train Epoch: 167 [640/918 (70%)] Loss: 7877278.500000\n",
      "Train Epoch: 167 [656/918 (71%)] Loss: 7289057.000000\n",
      "Train Epoch: 167 [672/918 (73%)] Loss: 9782194.000000\n",
      "Train Epoch: 167 [688/918 (75%)] Loss: 8967663.000000\n",
      "Train Epoch: 167 [704/918 (77%)] Loss: 7080328.000000\n",
      "Train Epoch: 167 [720/918 (78%)] Loss: 8737742.000000\n",
      "Train Epoch: 167 [736/918 (80%)] Loss: 8328876.000000\n",
      "Train Epoch: 167 [752/918 (82%)] Loss: 7312406.500000\n",
      "Train Epoch: 167 [768/918 (84%)] Loss: 8105130.500000\n",
      "Train Epoch: 167 [784/918 (85%)] Loss: 8535355.000000\n",
      "Train Epoch: 167 [800/918 (87%)] Loss: 5552850.500000\n",
      "Train Epoch: 167 [816/918 (89%)] Loss: 7675883.500000\n",
      "Train Epoch: 167 [832/918 (91%)] Loss: 8681010.000000\n",
      "Train Epoch: 167 [848/918 (92%)] Loss: 9442480.000000\n",
      "Train Epoch: 167 [864/918 (94%)] Loss: 6921627.500000\n",
      "Train Epoch: 167 [880/918 (96%)] Loss: 7361484.000000\n",
      "Train Epoch: 167 [896/918 (98%)] Loss: 9137043.000000\n",
      "Train Epoch: 167 [912/918 (99%)] Loss: 9820358.000000\n",
      "    epoch          : 167\n",
      "    loss           : 9066149.308695652\n",
      "    ess            : 7.191927396732828\n",
      "    log_marginal   : -9066146.682608696\n",
      "    val_loss       : 8586001.807692308\n",
      "    val_ess        : 6.0207881560692424\n",
      "    val_log_marginal: -8585997.884615384\n",
      "Train Epoch: 168 [0/918 (0%)] Loss: 6559573.500000\n",
      "Train Epoch: 168 [16/918 (2%)] Loss: 7393182.500000\n",
      "Train Epoch: 168 [32/918 (3%)] Loss: 7286097.500000\n",
      "Train Epoch: 168 [48/918 (5%)] Loss: 8612142.000000\n",
      "Train Epoch: 168 [64/918 (7%)] Loss: 11218681.000000\n",
      "Train Epoch: 168 [80/918 (9%)] Loss: 6892973.000000\n",
      "Train Epoch: 168 [96/918 (10%)] Loss: 7867962.500000\n",
      "Train Epoch: 168 [112/918 (12%)] Loss: 8436767.000000\n",
      "Train Epoch: 168 [128/918 (14%)] Loss: 7537786.500000\n",
      "Train Epoch: 168 [144/918 (16%)] Loss: 8165084.000000\n",
      "Train Epoch: 168 [160/918 (17%)] Loss: 8639794.000000\n",
      "Train Epoch: 168 [176/918 (19%)] Loss: 5105893.500000\n",
      "Train Epoch: 168 [192/918 (21%)] Loss: 8643643.000000\n",
      "Train Epoch: 168 [208/918 (23%)] Loss: 5823860.000000\n",
      "Train Epoch: 168 [224/918 (24%)] Loss: 7731904.000000\n",
      "Train Epoch: 168 [240/918 (26%)] Loss: 9184999.000000\n",
      "Train Epoch: 168 [256/918 (28%)] Loss: 8908256.000000\n",
      "Train Epoch: 168 [272/918 (30%)] Loss: 8987111.000000\n",
      "Train Epoch: 168 [288/918 (31%)] Loss: 8262350.500000\n",
      "Train Epoch: 168 [304/918 (33%)] Loss: 10852494.000000\n",
      "Train Epoch: 168 [320/918 (35%)] Loss: 8397576.000000\n",
      "Train Epoch: 168 [336/918 (37%)] Loss: 8345989.000000\n",
      "Train Epoch: 168 [352/918 (38%)] Loss: 7566165.000000\n",
      "Train Epoch: 168 [368/918 (40%)] Loss: 14652050.000000\n",
      "Train Epoch: 168 [384/918 (42%)] Loss: 8316538.500000\n",
      "Train Epoch: 168 [400/918 (44%)] Loss: 8906461.000000\n",
      "Train Epoch: 168 [416/918 (45%)] Loss: 8454237.000000\n",
      "Train Epoch: 168 [432/918 (47%)] Loss: 9525186.000000\n",
      "Train Epoch: 168 [448/918 (49%)] Loss: 10035570.000000\n",
      "Train Epoch: 168 [464/918 (51%)] Loss: 10295160.000000\n",
      "Train Epoch: 168 [480/918 (52%)] Loss: 6219218.000000\n",
      "Train Epoch: 168 [496/918 (54%)] Loss: 5938065.000000\n",
      "Train Epoch: 168 [512/918 (56%)] Loss: 17041102.000000\n",
      "Train Epoch: 168 [528/918 (58%)] Loss: 9296623.000000\n",
      "Train Epoch: 168 [544/918 (59%)] Loss: 7312977.000000\n",
      "Train Epoch: 168 [560/918 (61%)] Loss: 7511515.500000\n",
      "Train Epoch: 168 [576/918 (63%)] Loss: 10392622.000000\n",
      "Train Epoch: 168 [592/918 (64%)] Loss: 10502862.000000\n",
      "Train Epoch: 168 [608/918 (66%)] Loss: 10538040.000000\n",
      "Train Epoch: 168 [624/918 (68%)] Loss: 11238806.000000\n",
      "Train Epoch: 168 [640/918 (70%)] Loss: 7655281.500000\n",
      "Train Epoch: 168 [656/918 (71%)] Loss: 10965434.000000\n",
      "Train Epoch: 168 [672/918 (73%)] Loss: 11809268.000000\n",
      "Train Epoch: 168 [688/918 (75%)] Loss: 7923731.500000\n",
      "Train Epoch: 168 [704/918 (77%)] Loss: 7777440.000000\n",
      "Train Epoch: 168 [720/918 (78%)] Loss: 9284352.000000\n",
      "Train Epoch: 168 [736/918 (80%)] Loss: 11203632.000000\n",
      "Train Epoch: 168 [752/918 (82%)] Loss: 5335641.000000\n",
      "Train Epoch: 168 [768/918 (84%)] Loss: 10363467.000000\n",
      "Train Epoch: 168 [784/918 (85%)] Loss: 7387743.500000\n",
      "Train Epoch: 168 [800/918 (87%)] Loss: 7825851.500000\n",
      "Train Epoch: 168 [816/918 (89%)] Loss: 7110172.000000\n",
      "Train Epoch: 168 [832/918 (91%)] Loss: 11542544.000000\n",
      "Train Epoch: 168 [848/918 (92%)] Loss: 4759841.000000\n",
      "Train Epoch: 168 [864/918 (94%)] Loss: 7006962.500000\n",
      "Train Epoch: 168 [880/918 (96%)] Loss: 6569729.000000\n",
      "Train Epoch: 168 [896/918 (98%)] Loss: 11612646.000000\n",
      "Train Epoch: 168 [912/918 (99%)] Loss: 6801141.500000\n",
      "    epoch          : 168\n",
      "    loss           : 8733034.395652173\n",
      "    ess            : 7.395243412515391\n",
      "    log_marginal   : -8733032.62173913\n",
      "    val_loss       : 9755465.692307692\n",
      "    val_ess        : 9.423922208639292\n",
      "    val_log_marginal: -9755462.115384616\n",
      "Train Epoch: 169 [0/918 (0%)] Loss: 11009075.000000\n",
      "Train Epoch: 169 [16/918 (2%)] Loss: 6746059.500000\n",
      "Train Epoch: 169 [32/918 (3%)] Loss: 18114324.000000\n",
      "Train Epoch: 169 [48/918 (5%)] Loss: 11072687.000000\n",
      "Train Epoch: 169 [64/918 (7%)] Loss: 7231046.500000\n",
      "Train Epoch: 169 [80/918 (9%)] Loss: 11525110.000000\n",
      "Train Epoch: 169 [96/918 (10%)] Loss: 8868651.000000\n",
      "Train Epoch: 169 [112/918 (12%)] Loss: 9380912.000000\n",
      "Train Epoch: 169 [128/918 (14%)] Loss: 5683045.000000\n",
      "Train Epoch: 169 [144/918 (16%)] Loss: 7948494.500000\n",
      "Train Epoch: 169 [160/918 (17%)] Loss: 11736317.000000\n",
      "Train Epoch: 169 [176/918 (19%)] Loss: 10692280.000000\n",
      "Train Epoch: 169 [192/918 (21%)] Loss: 8391889.000000\n",
      "Train Epoch: 169 [208/918 (23%)] Loss: 6316405.000000\n",
      "Train Epoch: 169 [224/918 (24%)] Loss: 7855651.500000\n",
      "Train Epoch: 169 [240/918 (26%)] Loss: 9660111.000000\n",
      "Train Epoch: 169 [256/918 (28%)] Loss: 5601759.500000\n",
      "Train Epoch: 169 [272/918 (30%)] Loss: 5684484.000000\n",
      "Train Epoch: 169 [288/918 (31%)] Loss: 6075047.500000\n",
      "Train Epoch: 169 [304/918 (33%)] Loss: 5241194.500000\n",
      "Train Epoch: 169 [320/918 (35%)] Loss: 9627251.000000\n",
      "Train Epoch: 169 [336/918 (37%)] Loss: 10143925.000000\n",
      "Train Epoch: 169 [352/918 (38%)] Loss: 5805966.500000\n",
      "Train Epoch: 169 [368/918 (40%)] Loss: 9382432.000000\n",
      "Train Epoch: 169 [384/918 (42%)] Loss: 11957007.000000\n",
      "Train Epoch: 169 [400/918 (44%)] Loss: 9283796.000000\n",
      "Train Epoch: 169 [416/918 (45%)] Loss: 8007167.500000\n",
      "Train Epoch: 169 [432/918 (47%)] Loss: 9069715.000000\n",
      "Train Epoch: 169 [448/918 (49%)] Loss: 9743683.000000\n",
      "Train Epoch: 169 [464/918 (51%)] Loss: 10143607.000000\n",
      "Train Epoch: 169 [480/918 (52%)] Loss: 6196813.500000\n",
      "Train Epoch: 169 [496/918 (54%)] Loss: 7371829.000000\n",
      "Train Epoch: 169 [512/918 (56%)] Loss: 6126261.500000\n",
      "Train Epoch: 169 [528/918 (58%)] Loss: 8982442.000000\n",
      "Train Epoch: 169 [544/918 (59%)] Loss: 13971827.000000\n",
      "Train Epoch: 169 [560/918 (61%)] Loss: 6979030.500000\n",
      "Train Epoch: 169 [576/918 (63%)] Loss: 10999874.000000\n",
      "Train Epoch: 169 [592/918 (64%)] Loss: 10962288.000000\n",
      "Train Epoch: 169 [608/918 (66%)] Loss: 11276713.000000\n",
      "Train Epoch: 169 [624/918 (68%)] Loss: 6447236.000000\n",
      "Train Epoch: 169 [640/918 (70%)] Loss: 8340910.500000\n",
      "Train Epoch: 169 [656/918 (71%)] Loss: 10566908.000000\n",
      "Train Epoch: 169 [672/918 (73%)] Loss: 14491223.000000\n",
      "Train Epoch: 169 [688/918 (75%)] Loss: 12939536.000000\n",
      "Train Epoch: 169 [704/918 (77%)] Loss: 11935412.000000\n",
      "Train Epoch: 169 [720/918 (78%)] Loss: 8996258.000000\n",
      "Train Epoch: 169 [736/918 (80%)] Loss: 6671245.500000\n",
      "Train Epoch: 169 [752/918 (82%)] Loss: 7001017.500000\n",
      "Train Epoch: 169 [768/918 (84%)] Loss: 7756446.500000\n",
      "Train Epoch: 169 [784/918 (85%)] Loss: 10582963.000000\n",
      "Train Epoch: 169 [800/918 (87%)] Loss: 8928384.000000\n",
      "Train Epoch: 169 [816/918 (89%)] Loss: 12987920.000000\n",
      "Train Epoch: 169 [832/918 (91%)] Loss: 6614421.500000\n",
      "Train Epoch: 169 [848/918 (92%)] Loss: 7944088.000000\n",
      "Train Epoch: 169 [864/918 (94%)] Loss: 9113608.000000\n",
      "Train Epoch: 169 [880/918 (96%)] Loss: 10764056.000000\n",
      "Train Epoch: 169 [896/918 (98%)] Loss: 13463501.000000\n",
      "Train Epoch: 169 [912/918 (99%)] Loss: 11984060.000000\n",
      "    epoch          : 169\n",
      "    loss           : 8946223.97826087\n",
      "    ess            : 7.591309586815212\n",
      "    log_marginal   : -8946219.991304347\n",
      "    val_loss       : 8848076.0\n",
      "    val_ess        : 6.54125112753648\n",
      "    val_log_marginal: -8848073.153846154\n",
      "Train Epoch: 170 [0/918 (0%)] Loss: 8281890.500000\n",
      "Train Epoch: 170 [16/918 (2%)] Loss: 13579303.000000\n",
      "Train Epoch: 170 [32/918 (3%)] Loss: 6835934.500000\n",
      "Train Epoch: 170 [48/918 (5%)] Loss: 6603190.000000\n",
      "Train Epoch: 170 [64/918 (7%)] Loss: 7508516.000000\n",
      "Train Epoch: 170 [80/918 (9%)] Loss: 13416230.000000\n",
      "Train Epoch: 170 [96/918 (10%)] Loss: 7803069.500000\n",
      "Train Epoch: 170 [112/918 (12%)] Loss: 7521804.000000\n",
      "Train Epoch: 170 [128/918 (14%)] Loss: 8282590.500000\n",
      "Train Epoch: 170 [144/918 (16%)] Loss: 5670767.000000\n",
      "Train Epoch: 170 [160/918 (17%)] Loss: 5358818.500000\n",
      "Train Epoch: 170 [176/918 (19%)] Loss: 6553791.500000\n",
      "Train Epoch: 170 [192/918 (21%)] Loss: 6723613.000000\n",
      "Train Epoch: 170 [208/918 (23%)] Loss: 6654985.000000\n",
      "Train Epoch: 170 [224/918 (24%)] Loss: 9154912.000000\n",
      "Train Epoch: 170 [240/918 (26%)] Loss: 14535615.000000\n",
      "Train Epoch: 170 [256/918 (28%)] Loss: 8200801.000000\n",
      "Train Epoch: 170 [272/918 (30%)] Loss: 9401178.000000\n",
      "Train Epoch: 170 [288/918 (31%)] Loss: 5949842.000000\n",
      "Train Epoch: 170 [304/918 (33%)] Loss: 7471577.000000\n",
      "Train Epoch: 170 [320/918 (35%)] Loss: 6841555.500000\n",
      "Train Epoch: 170 [336/918 (37%)] Loss: 7659215.500000\n",
      "Train Epoch: 170 [352/918 (38%)] Loss: 12349269.000000\n",
      "Train Epoch: 170 [368/918 (40%)] Loss: 9552661.000000\n",
      "Train Epoch: 170 [384/918 (42%)] Loss: 9149724.000000\n",
      "Train Epoch: 170 [400/918 (44%)] Loss: 8840309.000000\n",
      "Train Epoch: 170 [416/918 (45%)] Loss: 6349122.500000\n",
      "Train Epoch: 170 [432/918 (47%)] Loss: 7445554.500000\n",
      "Train Epoch: 170 [448/918 (49%)] Loss: 11507523.000000\n",
      "Train Epoch: 170 [464/918 (51%)] Loss: 11587365.000000\n",
      "Train Epoch: 170 [480/918 (52%)] Loss: 9381886.000000\n",
      "Train Epoch: 170 [496/918 (54%)] Loss: 7064112.000000\n",
      "Train Epoch: 170 [512/918 (56%)] Loss: 5105351.500000\n",
      "Train Epoch: 170 [528/918 (58%)] Loss: 5311108.000000\n",
      "Train Epoch: 170 [544/918 (59%)] Loss: 6476935.500000\n",
      "Train Epoch: 170 [560/918 (61%)] Loss: 10425791.000000\n",
      "Train Epoch: 170 [576/918 (63%)] Loss: 6407591.500000\n",
      "Train Epoch: 170 [592/918 (64%)] Loss: 5249122.000000\n",
      "Train Epoch: 170 [608/918 (66%)] Loss: 6169631.000000\n",
      "Train Epoch: 170 [624/918 (68%)] Loss: 7718186.500000\n",
      "Train Epoch: 170 [640/918 (70%)] Loss: 11180063.000000\n",
      "Train Epoch: 170 [656/918 (71%)] Loss: 10439934.000000\n",
      "Train Epoch: 170 [672/918 (73%)] Loss: 8046696.000000\n",
      "Train Epoch: 170 [688/918 (75%)] Loss: 8123924.000000\n",
      "Train Epoch: 170 [704/918 (77%)] Loss: 5606879.000000\n",
      "Train Epoch: 170 [720/918 (78%)] Loss: 7555779.500000\n",
      "Train Epoch: 170 [736/918 (80%)] Loss: 9503387.000000\n",
      "Train Epoch: 170 [752/918 (82%)] Loss: 9210162.000000\n",
      "Train Epoch: 170 [768/918 (84%)] Loss: 12212491.000000\n",
      "Train Epoch: 170 [784/918 (85%)] Loss: 9718528.000000\n",
      "Train Epoch: 170 [800/918 (87%)] Loss: 10456648.000000\n",
      "Train Epoch: 170 [816/918 (89%)] Loss: 7315633.500000\n",
      "Train Epoch: 170 [832/918 (91%)] Loss: 7340493.000000\n",
      "Train Epoch: 170 [848/918 (92%)] Loss: 5675079.000000\n",
      "Train Epoch: 170 [864/918 (94%)] Loss: 5677490.500000\n",
      "Train Epoch: 170 [880/918 (96%)] Loss: 10136247.000000\n",
      "Train Epoch: 170 [896/918 (98%)] Loss: 9148072.000000\n",
      "Train Epoch: 170 [912/918 (99%)] Loss: 9994893.000000\n",
      "    epoch          : 170\n",
      "    loss           : 8700958.169565218\n",
      "    ess            : 7.336136546342269\n",
      "    log_marginal   : -8700955.67826087\n",
      "    val_loss       : 9270630.5\n",
      "    val_ess        : 7.48798313507667\n",
      "    val_log_marginal: -9270625.346153846\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch170.pth ...\n",
      "Train Epoch: 171 [0/918 (0%)] Loss: 6288838.000000\n",
      "Train Epoch: 171 [16/918 (2%)] Loss: 17187182.000000\n",
      "Train Epoch: 171 [32/918 (3%)] Loss: 13144959.000000\n",
      "Train Epoch: 171 [48/918 (5%)] Loss: 8331284.000000\n",
      "Train Epoch: 171 [64/918 (7%)] Loss: 8941311.000000\n",
      "Train Epoch: 171 [80/918 (9%)] Loss: 7339433.500000\n",
      "Train Epoch: 171 [96/918 (10%)] Loss: 8379920.000000\n",
      "Train Epoch: 171 [112/918 (12%)] Loss: 10844368.000000\n",
      "Train Epoch: 171 [128/918 (14%)] Loss: 7582305.000000\n",
      "Train Epoch: 171 [144/918 (16%)] Loss: 7644238.500000\n",
      "Train Epoch: 171 [160/918 (17%)] Loss: 8489648.000000\n",
      "Train Epoch: 171 [176/918 (19%)] Loss: 4347847.500000\n",
      "Train Epoch: 171 [192/918 (21%)] Loss: 7886883.500000\n",
      "Train Epoch: 171 [208/918 (23%)] Loss: 6038097.000000\n",
      "Train Epoch: 171 [224/918 (24%)] Loss: 7866109.000000\n",
      "Train Epoch: 171 [240/918 (26%)] Loss: 9038732.000000\n",
      "Train Epoch: 171 [256/918 (28%)] Loss: 9255930.000000\n",
      "Train Epoch: 171 [272/918 (30%)] Loss: 6111797.500000\n",
      "Train Epoch: 171 [288/918 (31%)] Loss: 11067203.000000\n",
      "Train Epoch: 171 [304/918 (33%)] Loss: 7629987.500000\n",
      "Train Epoch: 171 [320/918 (35%)] Loss: 9355231.000000\n",
      "Train Epoch: 171 [336/918 (37%)] Loss: 11464872.000000\n",
      "Train Epoch: 171 [352/918 (38%)] Loss: 7058370.500000\n",
      "Train Epoch: 171 [368/918 (40%)] Loss: 9752023.000000\n",
      "Train Epoch: 171 [384/918 (42%)] Loss: 7608043.500000\n",
      "Train Epoch: 171 [400/918 (44%)] Loss: 5508835.500000\n",
      "Train Epoch: 171 [416/918 (45%)] Loss: 7048664.000000\n",
      "Train Epoch: 171 [432/918 (47%)] Loss: 7373476.000000\n",
      "Train Epoch: 171 [448/918 (49%)] Loss: 8496136.000000\n",
      "Train Epoch: 171 [464/918 (51%)] Loss: 12537691.000000\n",
      "Train Epoch: 171 [480/918 (52%)] Loss: 9734245.000000\n",
      "Train Epoch: 171 [496/918 (54%)] Loss: 9618354.000000\n",
      "Train Epoch: 171 [512/918 (56%)] Loss: 14101770.000000\n",
      "Train Epoch: 171 [528/918 (58%)] Loss: 7734247.500000\n",
      "Train Epoch: 171 [544/918 (59%)] Loss: 8851477.000000\n",
      "Train Epoch: 171 [560/918 (61%)] Loss: 5676185.000000\n",
      "Train Epoch: 171 [576/918 (63%)] Loss: 6720286.500000\n",
      "Train Epoch: 171 [592/918 (64%)] Loss: 7087381.000000\n",
      "Train Epoch: 171 [608/918 (66%)] Loss: 9070959.000000\n",
      "Train Epoch: 171 [624/918 (68%)] Loss: 6406813.000000\n",
      "Train Epoch: 171 [640/918 (70%)] Loss: 6829109.000000\n",
      "Train Epoch: 171 [656/918 (71%)] Loss: 5514157.000000\n",
      "Train Epoch: 171 [672/918 (73%)] Loss: 11601656.000000\n",
      "Train Epoch: 171 [688/918 (75%)] Loss: 10158007.000000\n",
      "Train Epoch: 171 [704/918 (77%)] Loss: 6037116.000000\n",
      "Train Epoch: 171 [720/918 (78%)] Loss: 10501791.000000\n",
      "Train Epoch: 171 [736/918 (80%)] Loss: 7539536.000000\n",
      "Train Epoch: 171 [752/918 (82%)] Loss: 8450927.000000\n",
      "Train Epoch: 171 [768/918 (84%)] Loss: 7188850.500000\n",
      "Train Epoch: 171 [784/918 (85%)] Loss: 9526114.000000\n",
      "Train Epoch: 171 [800/918 (87%)] Loss: 9617821.000000\n",
      "Train Epoch: 171 [816/918 (89%)] Loss: 10644018.000000\n",
      "Train Epoch: 171 [832/918 (91%)] Loss: 10911754.000000\n",
      "Train Epoch: 171 [848/918 (92%)] Loss: 6875631.500000\n",
      "Train Epoch: 171 [864/918 (94%)] Loss: 6300230.500000\n",
      "Train Epoch: 171 [880/918 (96%)] Loss: 10384045.000000\n",
      "Train Epoch: 171 [896/918 (98%)] Loss: 8250199.500000\n",
      "Train Epoch: 171 [912/918 (99%)] Loss: 22073812.000000\n",
      "    epoch          : 171\n",
      "    loss           : 8713040.326086957\n",
      "    ess            : 7.258096649335778\n",
      "    log_marginal   : -8713038.182608696\n",
      "    val_loss       : 8604577.923076924\n",
      "    val_ess        : 6.568170565825242\n",
      "    val_log_marginal: -8604574.576923076\n",
      "Train Epoch: 172 [0/918 (0%)] Loss: 5144307.500000\n",
      "Train Epoch: 172 [16/918 (2%)] Loss: 6493504.000000\n",
      "Train Epoch: 172 [32/918 (3%)] Loss: 10220615.000000\n",
      "Train Epoch: 172 [48/918 (5%)] Loss: 6437733.500000\n",
      "Train Epoch: 172 [64/918 (7%)] Loss: 6734310.500000\n",
      "Train Epoch: 172 [80/918 (9%)] Loss: 18112510.000000\n",
      "Train Epoch: 172 [96/918 (10%)] Loss: 6364326.000000\n",
      "Train Epoch: 172 [112/918 (12%)] Loss: 11071256.000000\n",
      "Train Epoch: 172 [128/918 (14%)] Loss: 7056070.500000\n",
      "Train Epoch: 172 [144/918 (16%)] Loss: 5882831.500000\n",
      "Train Epoch: 172 [160/918 (17%)] Loss: 11430192.000000\n",
      "Train Epoch: 172 [176/918 (19%)] Loss: 10814707.000000\n",
      "Train Epoch: 172 [192/918 (21%)] Loss: 10344841.000000\n",
      "Train Epoch: 172 [208/918 (23%)] Loss: 13699896.000000\n",
      "Train Epoch: 172 [224/918 (24%)] Loss: 9093736.000000\n",
      "Train Epoch: 172 [240/918 (26%)] Loss: 9993752.000000\n",
      "Train Epoch: 172 [256/918 (28%)] Loss: 5893640.000000\n",
      "Train Epoch: 172 [272/918 (30%)] Loss: 7682605.500000\n",
      "Train Epoch: 172 [288/918 (31%)] Loss: 6997589.500000\n",
      "Train Epoch: 172 [304/918 (33%)] Loss: 7829817.500000\n",
      "Train Epoch: 172 [320/918 (35%)] Loss: 6670816.500000\n",
      "Train Epoch: 172 [336/918 (37%)] Loss: 6805243.500000\n",
      "Train Epoch: 172 [352/918 (38%)] Loss: 8802319.000000\n",
      "Train Epoch: 172 [368/918 (40%)] Loss: 9932275.000000\n",
      "Train Epoch: 172 [384/918 (42%)] Loss: 7194782.500000\n",
      "Train Epoch: 172 [400/918 (44%)] Loss: 8290119.500000\n",
      "Train Epoch: 172 [416/918 (45%)] Loss: 7726839.500000\n",
      "Train Epoch: 172 [432/918 (47%)] Loss: 8519234.000000\n",
      "Train Epoch: 172 [448/918 (49%)] Loss: 7776413.000000\n",
      "Train Epoch: 172 [464/918 (51%)] Loss: 6404448.500000\n",
      "Train Epoch: 172 [480/918 (52%)] Loss: 12103691.000000\n",
      "Train Epoch: 172 [496/918 (54%)] Loss: 6771421.000000\n",
      "Train Epoch: 172 [512/918 (56%)] Loss: 7081856.000000\n",
      "Train Epoch: 172 [528/918 (58%)] Loss: 12074142.000000\n",
      "Train Epoch: 172 [544/918 (59%)] Loss: 9347138.000000\n",
      "Train Epoch: 172 [560/918 (61%)] Loss: 7871181.000000\n",
      "Train Epoch: 172 [576/918 (63%)] Loss: 7993363.500000\n",
      "Train Epoch: 172 [592/918 (64%)] Loss: 6710931.500000\n",
      "Train Epoch: 172 [608/918 (66%)] Loss: 7088333.000000\n",
      "Train Epoch: 172 [624/918 (68%)] Loss: 7920262.500000\n",
      "Train Epoch: 172 [640/918 (70%)] Loss: 7498594.500000\n",
      "Train Epoch: 172 [656/918 (71%)] Loss: 8975743.000000\n",
      "Train Epoch: 172 [672/918 (73%)] Loss: 8050429.000000\n",
      "Train Epoch: 172 [688/918 (75%)] Loss: 6616922.500000\n",
      "Train Epoch: 172 [704/918 (77%)] Loss: 12168089.000000\n",
      "Train Epoch: 172 [720/918 (78%)] Loss: 12481700.000000\n",
      "Train Epoch: 172 [736/918 (80%)] Loss: 16126599.000000\n",
      "Train Epoch: 172 [752/918 (82%)] Loss: 7659261.000000\n",
      "Train Epoch: 172 [768/918 (84%)] Loss: 7304500.000000\n",
      "Train Epoch: 172 [784/918 (85%)] Loss: 7376952.000000\n",
      "Train Epoch: 172 [800/918 (87%)] Loss: 10838018.000000\n",
      "Train Epoch: 172 [816/918 (89%)] Loss: 8597941.000000\n",
      "Train Epoch: 172 [832/918 (91%)] Loss: 5752729.500000\n",
      "Train Epoch: 172 [848/918 (92%)] Loss: 12387136.000000\n",
      "Train Epoch: 172 [864/918 (94%)] Loss: 9760961.000000\n",
      "Train Epoch: 172 [880/918 (96%)] Loss: 9146295.000000\n",
      "Train Epoch: 172 [896/918 (98%)] Loss: 6716422.500000\n",
      "Train Epoch: 172 [912/918 (99%)] Loss: 6112860.000000\n",
      "    epoch          : 172\n",
      "    loss           : 8845021.543478262\n",
      "    ess            : 7.412043693791265\n",
      "    log_marginal   : -8845019.465217391\n",
      "    val_loss       : 9675823.153846154\n",
      "    val_ess        : 8.975242302967953\n",
      "    val_log_marginal: -9675820.76923077\n",
      "Train Epoch: 173 [0/918 (0%)] Loss: 7920815.500000\n",
      "Train Epoch: 173 [16/918 (2%)] Loss: 6313797.000000\n",
      "Train Epoch: 173 [32/918 (3%)] Loss: 11132532.000000\n",
      "Train Epoch: 173 [48/918 (5%)] Loss: 7048369.500000\n",
      "Train Epoch: 173 [64/918 (7%)] Loss: 10237279.000000\n",
      "Train Epoch: 173 [80/918 (9%)] Loss: 12328604.000000\n",
      "Train Epoch: 173 [96/918 (10%)] Loss: 13129872.000000\n",
      "Train Epoch: 173 [112/918 (12%)] Loss: 6805591.500000\n",
      "Train Epoch: 173 [128/918 (14%)] Loss: 5574722.500000\n",
      "Train Epoch: 173 [144/918 (16%)] Loss: 8419107.000000\n",
      "Train Epoch: 173 [160/918 (17%)] Loss: 8813626.000000\n",
      "Train Epoch: 173 [176/918 (19%)] Loss: 8267352.000000\n",
      "Train Epoch: 173 [192/918 (21%)] Loss: 10477427.000000\n",
      "Train Epoch: 173 [208/918 (23%)] Loss: 7331701.000000\n",
      "Train Epoch: 173 [224/918 (24%)] Loss: 14545085.000000\n",
      "Train Epoch: 173 [240/918 (26%)] Loss: 5119811.500000\n",
      "Train Epoch: 173 [256/918 (28%)] Loss: 10906293.000000\n",
      "Train Epoch: 173 [272/918 (30%)] Loss: 9924050.000000\n",
      "Train Epoch: 173 [288/918 (31%)] Loss: 11451811.000000\n",
      "Train Epoch: 173 [304/918 (33%)] Loss: 8424278.000000\n",
      "Train Epoch: 173 [320/918 (35%)] Loss: 4444573.000000\n",
      "Train Epoch: 173 [336/918 (37%)] Loss: 8652443.000000\n",
      "Train Epoch: 173 [352/918 (38%)] Loss: 5791119.500000\n",
      "Train Epoch: 173 [368/918 (40%)] Loss: 8277209.500000\n",
      "Train Epoch: 173 [384/918 (42%)] Loss: 12754170.000000\n",
      "Train Epoch: 173 [400/918 (44%)] Loss: 7792590.500000\n",
      "Train Epoch: 173 [416/918 (45%)] Loss: 15028379.000000\n",
      "Train Epoch: 173 [432/918 (47%)] Loss: 12306398.000000\n",
      "Train Epoch: 173 [448/918 (49%)] Loss: 8282755.500000\n",
      "Train Epoch: 173 [464/918 (51%)] Loss: 9821485.000000\n",
      "Train Epoch: 173 [480/918 (52%)] Loss: 8039542.500000\n",
      "Train Epoch: 173 [496/918 (54%)] Loss: 15858707.000000\n",
      "Train Epoch: 173 [512/918 (56%)] Loss: 8806316.000000\n",
      "Train Epoch: 173 [528/918 (58%)] Loss: 5155950.000000\n",
      "Train Epoch: 173 [544/918 (59%)] Loss: 8241197.000000\n",
      "Train Epoch: 173 [560/918 (61%)] Loss: 8887067.000000\n",
      "Train Epoch: 173 [576/918 (63%)] Loss: 5973147.500000\n",
      "Train Epoch: 173 [592/918 (64%)] Loss: 9980641.000000\n",
      "Train Epoch: 173 [608/918 (66%)] Loss: 18336470.000000\n",
      "Train Epoch: 173 [624/918 (68%)] Loss: 5764761.500000\n",
      "Train Epoch: 173 [640/918 (70%)] Loss: 6292531.000000\n",
      "Train Epoch: 173 [656/918 (71%)] Loss: 11428004.000000\n",
      "Train Epoch: 173 [672/918 (73%)] Loss: 11106464.000000\n",
      "Train Epoch: 173 [688/918 (75%)] Loss: 9034515.000000\n",
      "Train Epoch: 173 [704/918 (77%)] Loss: 8122024.000000\n",
      "Train Epoch: 173 [720/918 (78%)] Loss: 6428570.000000\n",
      "Train Epoch: 173 [736/918 (80%)] Loss: 8091553.500000\n",
      "Train Epoch: 173 [752/918 (82%)] Loss: 5892139.500000\n",
      "Train Epoch: 173 [768/918 (84%)] Loss: 6547501.500000\n",
      "Train Epoch: 173 [784/918 (85%)] Loss: 8019019.500000\n",
      "Train Epoch: 173 [800/918 (87%)] Loss: 7186153.500000\n",
      "Train Epoch: 173 [816/918 (89%)] Loss: 11121015.000000\n",
      "Train Epoch: 173 [832/918 (91%)] Loss: 8105261.000000\n",
      "Train Epoch: 173 [848/918 (92%)] Loss: 9904676.000000\n",
      "Train Epoch: 173 [864/918 (94%)] Loss: 12676799.000000\n",
      "Train Epoch: 173 [880/918 (96%)] Loss: 11022458.000000\n",
      "Train Epoch: 173 [896/918 (98%)] Loss: 11412391.000000\n",
      "Train Epoch: 173 [912/918 (99%)] Loss: 4994998.000000\n",
      "    epoch          : 173\n",
      "    loss           : 8914987.760869564\n",
      "    ess            : 7.399578325644783\n",
      "    log_marginal   : -8914985.430434782\n",
      "    val_loss       : 9701053.307692308\n",
      "    val_ess        : 10.555136313805214\n",
      "    val_log_marginal: -9701050.884615384\n",
      "Train Epoch: 174 [0/918 (0%)] Loss: 10405168.000000\n",
      "Train Epoch: 174 [16/918 (2%)] Loss: 5300287.500000\n",
      "Train Epoch: 174 [32/918 (3%)] Loss: 7585492.000000\n",
      "Train Epoch: 174 [48/918 (5%)] Loss: 8680133.000000\n",
      "Train Epoch: 174 [64/918 (7%)] Loss: 4377941.000000\n",
      "Train Epoch: 174 [80/918 (9%)] Loss: 8595691.000000\n",
      "Train Epoch: 174 [96/918 (10%)] Loss: 7510136.000000\n",
      "Train Epoch: 174 [112/918 (12%)] Loss: 7585499.500000\n",
      "Train Epoch: 174 [128/918 (14%)] Loss: 8616523.000000\n",
      "Train Epoch: 174 [144/918 (16%)] Loss: 6701933.500000\n",
      "Train Epoch: 174 [160/918 (17%)] Loss: 12645976.000000\n",
      "Train Epoch: 174 [176/918 (19%)] Loss: 8330816.000000\n",
      "Train Epoch: 174 [192/918 (21%)] Loss: 8519343.000000\n",
      "Train Epoch: 174 [208/918 (23%)] Loss: 14783015.000000\n",
      "Train Epoch: 174 [224/918 (24%)] Loss: 6794217.000000\n",
      "Train Epoch: 174 [240/918 (26%)] Loss: 9450383.000000\n",
      "Train Epoch: 174 [256/918 (28%)] Loss: 8399445.000000\n",
      "Train Epoch: 174 [272/918 (30%)] Loss: 8226437.000000\n",
      "Train Epoch: 174 [288/918 (31%)] Loss: 4856115.500000\n",
      "Train Epoch: 174 [304/918 (33%)] Loss: 7722659.500000\n",
      "Train Epoch: 174 [320/918 (35%)] Loss: 9953715.000000\n",
      "Train Epoch: 174 [336/918 (37%)] Loss: 6361611.500000\n",
      "Train Epoch: 174 [352/918 (38%)] Loss: 10618584.000000\n",
      "Train Epoch: 174 [368/918 (40%)] Loss: 9758882.000000\n",
      "Train Epoch: 174 [384/918 (42%)] Loss: 10206412.000000\n",
      "Train Epoch: 174 [400/918 (44%)] Loss: 10146165.000000\n",
      "Train Epoch: 174 [416/918 (45%)] Loss: 7059515.500000\n",
      "Train Epoch: 174 [432/918 (47%)] Loss: 7053434.500000\n",
      "Train Epoch: 174 [448/918 (49%)] Loss: 8355825.500000\n",
      "Train Epoch: 174 [464/918 (51%)] Loss: 7863941.500000\n",
      "Train Epoch: 174 [480/918 (52%)] Loss: 13255731.000000\n",
      "Train Epoch: 174 [496/918 (54%)] Loss: 9638632.000000\n",
      "Train Epoch: 174 [512/918 (56%)] Loss: 5321137.000000\n",
      "Train Epoch: 174 [528/918 (58%)] Loss: 8370780.000000\n",
      "Train Epoch: 174 [544/918 (59%)] Loss: 6320801.500000\n",
      "Train Epoch: 174 [560/918 (61%)] Loss: 12753359.000000\n",
      "Train Epoch: 174 [576/918 (63%)] Loss: 11115190.000000\n",
      "Train Epoch: 174 [592/918 (64%)] Loss: 9408839.000000\n",
      "Train Epoch: 174 [608/918 (66%)] Loss: 10511840.000000\n",
      "Train Epoch: 174 [624/918 (68%)] Loss: 13718160.000000\n",
      "Train Epoch: 174 [640/918 (70%)] Loss: 4960013.500000\n",
      "Train Epoch: 174 [656/918 (71%)] Loss: 11596471.000000\n",
      "Train Epoch: 174 [672/918 (73%)] Loss: 12361405.000000\n",
      "Train Epoch: 174 [688/918 (75%)] Loss: 8269993.500000\n",
      "Train Epoch: 174 [704/918 (77%)] Loss: 9104008.000000\n",
      "Train Epoch: 174 [720/918 (78%)] Loss: 10825599.000000\n",
      "Train Epoch: 174 [736/918 (80%)] Loss: 9063320.000000\n",
      "Train Epoch: 174 [752/918 (82%)] Loss: 15823098.000000\n",
      "Train Epoch: 174 [768/918 (84%)] Loss: 6639389.000000\n",
      "Train Epoch: 174 [784/918 (85%)] Loss: 8345042.500000\n",
      "Train Epoch: 174 [800/918 (87%)] Loss: 9714543.000000\n",
      "Train Epoch: 174 [816/918 (89%)] Loss: 7050883.500000\n",
      "Train Epoch: 174 [832/918 (91%)] Loss: 9873176.000000\n",
      "Train Epoch: 174 [848/918 (92%)] Loss: 7354925.000000\n",
      "Train Epoch: 174 [864/918 (94%)] Loss: 8096717.000000\n",
      "Train Epoch: 174 [880/918 (96%)] Loss: 10152952.000000\n",
      "Train Epoch: 174 [896/918 (98%)] Loss: 5002735.500000\n",
      "Train Epoch: 174 [912/918 (99%)] Loss: 7854235.000000\n",
      "    epoch          : 174\n",
      "    loss           : 8726549.173913043\n",
      "    ess            : 7.201157364637956\n",
      "    log_marginal   : -8726546.152173912\n",
      "    val_loss       : 9444909.615384616\n",
      "    val_ess        : 6.196974460895245\n",
      "    val_log_marginal: -9444907.884615384\n",
      "Train Epoch: 175 [0/918 (0%)] Loss: 9199632.000000\n",
      "Train Epoch: 175 [16/918 (2%)] Loss: 8780262.000000\n",
      "Train Epoch: 175 [32/918 (3%)] Loss: 7967001.500000\n",
      "Train Epoch: 175 [48/918 (5%)] Loss: 10911978.000000\n",
      "Train Epoch: 175 [64/918 (7%)] Loss: 7314017.000000\n",
      "Train Epoch: 175 [80/918 (9%)] Loss: 8577834.000000\n",
      "Train Epoch: 175 [96/918 (10%)] Loss: 5734190.000000\n",
      "Train Epoch: 175 [112/918 (12%)] Loss: 7006604.000000\n",
      "Train Epoch: 175 [128/918 (14%)] Loss: 11786775.000000\n",
      "Train Epoch: 175 [144/918 (16%)] Loss: 7324158.500000\n",
      "Train Epoch: 175 [160/918 (17%)] Loss: 12415422.000000\n",
      "Train Epoch: 175 [176/918 (19%)] Loss: 6633371.500000\n",
      "Train Epoch: 175 [192/918 (21%)] Loss: 5849445.500000\n",
      "Train Epoch: 175 [208/918 (23%)] Loss: 5382636.000000\n",
      "Train Epoch: 175 [224/918 (24%)] Loss: 15674391.000000\n",
      "Train Epoch: 175 [240/918 (26%)] Loss: 5900345.000000\n",
      "Train Epoch: 175 [256/918 (28%)] Loss: 6928286.500000\n",
      "Train Epoch: 175 [272/918 (30%)] Loss: 10835568.000000\n",
      "Train Epoch: 175 [288/918 (31%)] Loss: 7060793.000000\n",
      "Train Epoch: 175 [304/918 (33%)] Loss: 8585962.000000\n",
      "Train Epoch: 175 [320/918 (35%)] Loss: 13226114.000000\n",
      "Train Epoch: 175 [336/918 (37%)] Loss: 7199121.500000\n",
      "Train Epoch: 175 [352/918 (38%)] Loss: 10044067.000000\n",
      "Train Epoch: 175 [368/918 (40%)] Loss: 8548703.000000\n",
      "Train Epoch: 175 [384/918 (42%)] Loss: 8454447.000000\n",
      "Train Epoch: 175 [400/918 (44%)] Loss: 9560064.000000\n",
      "Train Epoch: 175 [416/918 (45%)] Loss: 5866602.500000\n",
      "Train Epoch: 175 [432/918 (47%)] Loss: 9961055.000000\n",
      "Train Epoch: 175 [448/918 (49%)] Loss: 13688882.000000\n",
      "Train Epoch: 175 [464/918 (51%)] Loss: 6359245.500000\n",
      "Train Epoch: 175 [480/918 (52%)] Loss: 9395991.000000\n",
      "Train Epoch: 175 [496/918 (54%)] Loss: 5549769.500000\n",
      "Train Epoch: 175 [512/918 (56%)] Loss: 9279387.000000\n",
      "Train Epoch: 175 [528/918 (58%)] Loss: 9458311.000000\n",
      "Train Epoch: 175 [544/918 (59%)] Loss: 8009835.500000\n",
      "Train Epoch: 175 [560/918 (61%)] Loss: 8308389.000000\n",
      "Train Epoch: 175 [576/918 (63%)] Loss: 6849321.500000\n",
      "Train Epoch: 175 [592/918 (64%)] Loss: 6726193.500000\n",
      "Train Epoch: 175 [608/918 (66%)] Loss: 6850791.500000\n",
      "Train Epoch: 175 [624/918 (68%)] Loss: 6804673.500000\n",
      "Train Epoch: 175 [640/918 (70%)] Loss: 8119571.500000\n",
      "Train Epoch: 175 [656/918 (71%)] Loss: 6749969.000000\n",
      "Train Epoch: 175 [672/918 (73%)] Loss: 8367568.000000\n",
      "Train Epoch: 175 [688/918 (75%)] Loss: 6807764.000000\n",
      "Train Epoch: 175 [704/918 (77%)] Loss: 8478354.000000\n",
      "Train Epoch: 175 [720/918 (78%)] Loss: 6183589.500000\n",
      "Train Epoch: 175 [736/918 (80%)] Loss: 10614701.000000\n",
      "Train Epoch: 175 [752/918 (82%)] Loss: 11010270.000000\n",
      "Train Epoch: 175 [768/918 (84%)] Loss: 9787183.000000\n",
      "Train Epoch: 175 [784/918 (85%)] Loss: 12938635.000000\n",
      "Train Epoch: 175 [800/918 (87%)] Loss: 5336026.500000\n",
      "Train Epoch: 175 [816/918 (89%)] Loss: 10855210.000000\n",
      "Train Epoch: 175 [832/918 (91%)] Loss: 15968359.000000\n",
      "Train Epoch: 175 [848/918 (92%)] Loss: 6806713.500000\n",
      "Train Epoch: 175 [864/918 (94%)] Loss: 14229306.000000\n",
      "Train Epoch: 175 [880/918 (96%)] Loss: 9315436.000000\n",
      "Train Epoch: 175 [896/918 (98%)] Loss: 11755748.000000\n",
      "Train Epoch: 175 [912/918 (99%)] Loss: 7690074.500000\n",
      "    epoch          : 175\n",
      "    loss           : 9045487.3\n",
      "    ess            : 7.960865746373716\n",
      "    log_marginal   : -9045484.4\n",
      "    val_loss       : 8233114.846153846\n",
      "    val_ess        : 8.099838000077467\n",
      "    val_log_marginal: -8233113.653846154\n",
      "Train Epoch: 176 [0/918 (0%)] Loss: 5374947.500000\n",
      "Train Epoch: 176 [16/918 (2%)] Loss: 9358069.000000\n",
      "Train Epoch: 176 [32/918 (3%)] Loss: 9807571.000000\n",
      "Train Epoch: 176 [48/918 (5%)] Loss: 12167731.000000\n",
      "Train Epoch: 176 [64/918 (7%)] Loss: 8589275.000000\n",
      "Train Epoch: 176 [80/918 (9%)] Loss: 9340511.000000\n",
      "Train Epoch: 176 [96/918 (10%)] Loss: 12745075.000000\n",
      "Train Epoch: 176 [112/918 (12%)] Loss: 6331630.500000\n",
      "Train Epoch: 176 [128/918 (14%)] Loss: 6151818.500000\n",
      "Train Epoch: 176 [144/918 (16%)] Loss: 8976318.000000\n",
      "Train Epoch: 176 [160/918 (17%)] Loss: 13067400.000000\n",
      "Train Epoch: 176 [176/918 (19%)] Loss: 8947554.000000\n",
      "Train Epoch: 176 [192/918 (21%)] Loss: 7102773.000000\n",
      "Train Epoch: 176 [208/918 (23%)] Loss: 7395911.500000\n",
      "Train Epoch: 176 [224/918 (24%)] Loss: 12280385.000000\n",
      "Train Epoch: 176 [240/918 (26%)] Loss: 9364746.000000\n",
      "Train Epoch: 176 [256/918 (28%)] Loss: 9760018.000000\n",
      "Train Epoch: 176 [272/918 (30%)] Loss: 8187262.500000\n",
      "Train Epoch: 176 [288/918 (31%)] Loss: 15358058.000000\n",
      "Train Epoch: 176 [304/918 (33%)] Loss: 9301940.000000\n",
      "Train Epoch: 176 [320/918 (35%)] Loss: 6858328.000000\n",
      "Train Epoch: 176 [336/918 (37%)] Loss: 6402297.000000\n",
      "Train Epoch: 176 [352/918 (38%)] Loss: 5804365.500000\n",
      "Train Epoch: 176 [368/918 (40%)] Loss: 9061962.000000\n",
      "Train Epoch: 176 [384/918 (42%)] Loss: 14146928.000000\n",
      "Train Epoch: 176 [400/918 (44%)] Loss: 8653039.000000\n",
      "Train Epoch: 176 [416/918 (45%)] Loss: 8618671.000000\n",
      "Train Epoch: 176 [432/918 (47%)] Loss: 6538136.500000\n",
      "Train Epoch: 176 [448/918 (49%)] Loss: 7164614.500000\n",
      "Train Epoch: 176 [464/918 (51%)] Loss: 7956969.500000\n",
      "Train Epoch: 176 [480/918 (52%)] Loss: 11490000.000000\n",
      "Train Epoch: 176 [496/918 (54%)] Loss: 6377896.000000\n",
      "Train Epoch: 176 [512/918 (56%)] Loss: 10658373.000000\n",
      "Train Epoch: 176 [528/918 (58%)] Loss: 7351079.500000\n",
      "Train Epoch: 176 [544/918 (59%)] Loss: 13686285.000000\n",
      "Train Epoch: 176 [560/918 (61%)] Loss: 13753208.000000\n",
      "Train Epoch: 176 [576/918 (63%)] Loss: 5736689.000000\n",
      "Train Epoch: 176 [592/918 (64%)] Loss: 14249431.000000\n",
      "Train Epoch: 176 [608/918 (66%)] Loss: 6783253.000000\n",
      "Train Epoch: 176 [624/918 (68%)] Loss: 9560701.000000\n",
      "Train Epoch: 176 [640/918 (70%)] Loss: 8674197.000000\n",
      "Train Epoch: 176 [656/918 (71%)] Loss: 9858543.000000\n",
      "Train Epoch: 176 [672/918 (73%)] Loss: 8886728.000000\n",
      "Train Epoch: 176 [688/918 (75%)] Loss: 5653564.500000\n",
      "Train Epoch: 176 [704/918 (77%)] Loss: 9153507.000000\n",
      "Train Epoch: 176 [720/918 (78%)] Loss: 6182071.500000\n",
      "Train Epoch: 176 [736/918 (80%)] Loss: 11371159.000000\n",
      "Train Epoch: 176 [752/918 (82%)] Loss: 7238911.500000\n",
      "Train Epoch: 176 [768/918 (84%)] Loss: 13031429.000000\n",
      "Train Epoch: 176 [784/918 (85%)] Loss: 10997815.000000\n",
      "Train Epoch: 176 [800/918 (87%)] Loss: 9821867.000000\n",
      "Train Epoch: 176 [816/918 (89%)] Loss: 8369114.500000\n",
      "Train Epoch: 176 [832/918 (91%)] Loss: 6099539.500000\n",
      "Train Epoch: 176 [848/918 (92%)] Loss: 9954842.000000\n",
      "Train Epoch: 176 [864/918 (94%)] Loss: 8082297.500000\n",
      "Train Epoch: 176 [880/918 (96%)] Loss: 8436234.000000\n",
      "Train Epoch: 176 [896/918 (98%)] Loss: 8629561.000000\n",
      "Train Epoch: 176 [912/918 (99%)] Loss: 7175249.500000\n",
      "    epoch          : 176\n",
      "    loss           : 9036507.743478261\n",
      "    ess            : 7.948135682810908\n",
      "    log_marginal   : -9036505.469565218\n",
      "    val_loss       : 9500106.5\n",
      "    val_ess        : 5.209095037900484\n",
      "    val_log_marginal: -9500104.653846154\n",
      "Train Epoch: 177 [0/918 (0%)] Loss: 11750170.000000\n",
      "Train Epoch: 177 [16/918 (2%)] Loss: 8338392.000000\n",
      "Train Epoch: 177 [32/918 (3%)] Loss: 6280394.500000\n",
      "Train Epoch: 177 [48/918 (5%)] Loss: 6430954.500000\n",
      "Train Epoch: 177 [64/918 (7%)] Loss: 8011629.500000\n",
      "Train Epoch: 177 [80/918 (9%)] Loss: 9008359.000000\n",
      "Train Epoch: 177 [96/918 (10%)] Loss: 6979232.000000\n",
      "Train Epoch: 177 [112/918 (12%)] Loss: 11383097.000000\n",
      "Train Epoch: 177 [128/918 (14%)] Loss: 7436116.000000\n",
      "Train Epoch: 177 [144/918 (16%)] Loss: 8796527.000000\n",
      "Train Epoch: 177 [160/918 (17%)] Loss: 8711472.000000\n",
      "Train Epoch: 177 [176/918 (19%)] Loss: 11728804.000000\n",
      "Train Epoch: 177 [192/918 (21%)] Loss: 7154601.000000\n",
      "Train Epoch: 177 [208/918 (23%)] Loss: 8051008.000000\n",
      "Train Epoch: 177 [224/918 (24%)] Loss: 6327172.000000\n",
      "Train Epoch: 177 [240/918 (26%)] Loss: 8171296.000000\n",
      "Train Epoch: 177 [256/918 (28%)] Loss: 14065770.000000\n",
      "Train Epoch: 177 [272/918 (30%)] Loss: 7516477.000000\n",
      "Train Epoch: 177 [288/918 (31%)] Loss: 9819376.000000\n",
      "Train Epoch: 177 [304/918 (33%)] Loss: 8633368.000000\n",
      "Train Epoch: 177 [320/918 (35%)] Loss: 9679815.000000\n",
      "Train Epoch: 177 [336/918 (37%)] Loss: 9311225.000000\n",
      "Train Epoch: 177 [352/918 (38%)] Loss: 5983830.000000\n",
      "Train Epoch: 177 [368/918 (40%)] Loss: 7802750.500000\n",
      "Train Epoch: 177 [384/918 (42%)] Loss: 6647904.000000\n",
      "Train Epoch: 177 [400/918 (44%)] Loss: 3987600.000000\n",
      "Train Epoch: 177 [416/918 (45%)] Loss: 9001123.000000\n",
      "Train Epoch: 177 [432/918 (47%)] Loss: 10997999.000000\n",
      "Train Epoch: 177 [448/918 (49%)] Loss: 5967510.000000\n",
      "Train Epoch: 177 [464/918 (51%)] Loss: 11468298.000000\n",
      "Train Epoch: 177 [480/918 (52%)] Loss: 13908493.000000\n",
      "Train Epoch: 177 [496/918 (54%)] Loss: 6859485.000000\n",
      "Train Epoch: 177 [512/918 (56%)] Loss: 10872101.000000\n",
      "Train Epoch: 177 [528/918 (58%)] Loss: 7176661.000000\n",
      "Train Epoch: 177 [544/918 (59%)] Loss: 10717967.000000\n",
      "Train Epoch: 177 [560/918 (61%)] Loss: 8882347.000000\n",
      "Train Epoch: 177 [576/918 (63%)] Loss: 9396746.000000\n",
      "Train Epoch: 177 [592/918 (64%)] Loss: 9176329.000000\n",
      "Train Epoch: 177 [608/918 (66%)] Loss: 8387172.000000\n",
      "Train Epoch: 177 [624/918 (68%)] Loss: 12256942.000000\n",
      "Train Epoch: 177 [640/918 (70%)] Loss: 10961589.000000\n",
      "Train Epoch: 177 [656/918 (71%)] Loss: 8445346.000000\n",
      "Train Epoch: 177 [672/918 (73%)] Loss: 11328296.000000\n",
      "Train Epoch: 177 [688/918 (75%)] Loss: 12188096.000000\n",
      "Train Epoch: 177 [704/918 (77%)] Loss: 13036087.000000\n",
      "Train Epoch: 177 [720/918 (78%)] Loss: 7508012.000000\n",
      "Train Epoch: 177 [736/918 (80%)] Loss: 8003875.500000\n",
      "Train Epoch: 177 [752/918 (82%)] Loss: 10289984.000000\n",
      "Train Epoch: 177 [768/918 (84%)] Loss: 10576573.000000\n",
      "Train Epoch: 177 [784/918 (85%)] Loss: 9811408.000000\n",
      "Train Epoch: 177 [800/918 (87%)] Loss: 8695133.000000\n",
      "Train Epoch: 177 [816/918 (89%)] Loss: 9652716.000000\n",
      "Train Epoch: 177 [832/918 (91%)] Loss: 7053386.500000\n",
      "Train Epoch: 177 [848/918 (92%)] Loss: 9319066.000000\n",
      "Train Epoch: 177 [864/918 (94%)] Loss: 12073023.000000\n",
      "Train Epoch: 177 [880/918 (96%)] Loss: 8563618.000000\n",
      "Train Epoch: 177 [896/918 (98%)] Loss: 6988855.500000\n",
      "Train Epoch: 177 [912/918 (99%)] Loss: 5531984.500000\n",
      "    epoch          : 177\n",
      "    loss           : 8841411.686956521\n",
      "    ess            : 7.673235507633375\n",
      "    log_marginal   : -8841409.147826087\n",
      "    val_loss       : 9240885.884615384\n",
      "    val_ess        : 10.461129940473116\n",
      "    val_log_marginal: -9240884.153846154\n",
      "Train Epoch: 178 [0/918 (0%)] Loss: 5697846.000000\n",
      "Train Epoch: 178 [16/918 (2%)] Loss: 5858683.000000\n",
      "Train Epoch: 178 [32/918 (3%)] Loss: 7320706.500000\n",
      "Train Epoch: 178 [48/918 (5%)] Loss: 5993873.000000\n",
      "Train Epoch: 178 [64/918 (7%)] Loss: 8059931.500000\n",
      "Train Epoch: 178 [80/918 (9%)] Loss: 8904077.000000\n",
      "Train Epoch: 178 [96/918 (10%)] Loss: 9736016.000000\n",
      "Train Epoch: 178 [112/918 (12%)] Loss: 9635430.000000\n",
      "Train Epoch: 178 [128/918 (14%)] Loss: 7609398.500000\n",
      "Train Epoch: 178 [144/918 (16%)] Loss: 8072657.500000\n",
      "Train Epoch: 178 [160/918 (17%)] Loss: 9234323.000000\n",
      "Train Epoch: 178 [176/918 (19%)] Loss: 7930066.500000\n",
      "Train Epoch: 178 [192/918 (21%)] Loss: 12993760.000000\n",
      "Train Epoch: 178 [208/918 (23%)] Loss: 6982710.500000\n",
      "Train Epoch: 178 [224/918 (24%)] Loss: 9278176.000000\n",
      "Train Epoch: 178 [240/918 (26%)] Loss: 9091839.000000\n",
      "Train Epoch: 178 [256/918 (28%)] Loss: 12473283.000000\n",
      "Train Epoch: 178 [272/918 (30%)] Loss: 9299575.000000\n",
      "Train Epoch: 178 [288/918 (31%)] Loss: 9780513.000000\n",
      "Train Epoch: 178 [304/918 (33%)] Loss: 14870509.000000\n",
      "Train Epoch: 178 [320/918 (35%)] Loss: 12074319.000000\n",
      "Train Epoch: 178 [336/918 (37%)] Loss: 6815374.500000\n",
      "Train Epoch: 178 [352/918 (38%)] Loss: 10018743.000000\n",
      "Train Epoch: 178 [368/918 (40%)] Loss: 7800630.500000\n",
      "Train Epoch: 178 [384/918 (42%)] Loss: 8665663.000000\n",
      "Train Epoch: 178 [400/918 (44%)] Loss: 5496229.000000\n",
      "Train Epoch: 178 [416/918 (45%)] Loss: 9624539.000000\n",
      "Train Epoch: 178 [432/918 (47%)] Loss: 9314655.000000\n",
      "Train Epoch: 178 [448/918 (49%)] Loss: 6738687.500000\n",
      "Train Epoch: 178 [464/918 (51%)] Loss: 9883876.000000\n",
      "Train Epoch: 178 [480/918 (52%)] Loss: 7970536.000000\n",
      "Train Epoch: 178 [496/918 (54%)] Loss: 6085868.000000\n",
      "Train Epoch: 178 [512/918 (56%)] Loss: 7608565.000000\n",
      "Train Epoch: 178 [528/918 (58%)] Loss: 10322884.000000\n",
      "Train Epoch: 178 [544/918 (59%)] Loss: 9039992.000000\n",
      "Train Epoch: 178 [560/918 (61%)] Loss: 7763884.000000\n",
      "Train Epoch: 178 [576/918 (63%)] Loss: 9540349.000000\n",
      "Train Epoch: 178 [592/918 (64%)] Loss: 8647979.000000\n",
      "Train Epoch: 178 [608/918 (66%)] Loss: 7533733.000000\n",
      "Train Epoch: 178 [624/918 (68%)] Loss: 9923474.000000\n",
      "Train Epoch: 178 [640/918 (70%)] Loss: 11761746.000000\n",
      "Train Epoch: 178 [656/918 (71%)] Loss: 6123197.500000\n",
      "Train Epoch: 178 [672/918 (73%)] Loss: 8423207.000000\n",
      "Train Epoch: 178 [688/918 (75%)] Loss: 8994271.000000\n",
      "Train Epoch: 178 [704/918 (77%)] Loss: 8456035.000000\n",
      "Train Epoch: 178 [720/918 (78%)] Loss: 14135549.000000\n",
      "Train Epoch: 178 [736/918 (80%)] Loss: 6289496.000000\n",
      "Train Epoch: 178 [752/918 (82%)] Loss: 7480312.000000\n",
      "Train Epoch: 178 [768/918 (84%)] Loss: 7671221.000000\n",
      "Train Epoch: 178 [784/918 (85%)] Loss: 11701869.000000\n",
      "Train Epoch: 178 [800/918 (87%)] Loss: 9221385.000000\n",
      "Train Epoch: 178 [816/918 (89%)] Loss: 12440060.000000\n",
      "Train Epoch: 178 [832/918 (91%)] Loss: 12457620.000000\n",
      "Train Epoch: 178 [848/918 (92%)] Loss: 10272048.000000\n",
      "Train Epoch: 178 [864/918 (94%)] Loss: 8015450.500000\n",
      "Train Epoch: 178 [880/918 (96%)] Loss: 15244871.000000\n",
      "Train Epoch: 178 [896/918 (98%)] Loss: 9941914.000000\n",
      "Train Epoch: 178 [912/918 (99%)] Loss: 10301178.000000\n",
      "    epoch          : 178\n",
      "    loss           : 8910883.77826087\n",
      "    ess            : 7.796338519842728\n",
      "    log_marginal   : -8910881.352173913\n",
      "    val_loss       : 9912240.423076924\n",
      "    val_ess        : 7.4071299479557915\n",
      "    val_log_marginal: -9912238.76923077\n",
      "Train Epoch: 179 [0/918 (0%)] Loss: 10505039.000000\n",
      "Train Epoch: 179 [16/918 (2%)] Loss: 7706899.500000\n",
      "Train Epoch: 179 [32/918 (3%)] Loss: 10371989.000000\n",
      "Train Epoch: 179 [48/918 (5%)] Loss: 7375318.500000\n",
      "Train Epoch: 179 [64/918 (7%)] Loss: 8338480.000000\n",
      "Train Epoch: 179 [80/918 (9%)] Loss: 5864561.500000\n",
      "Train Epoch: 179 [96/918 (10%)] Loss: 10061130.000000\n",
      "Train Epoch: 179 [112/918 (12%)] Loss: 6655610.000000\n",
      "Train Epoch: 179 [128/918 (14%)] Loss: 6581391.000000\n",
      "Train Epoch: 179 [144/918 (16%)] Loss: 10114829.000000\n",
      "Train Epoch: 179 [160/918 (17%)] Loss: 10182298.000000\n",
      "Train Epoch: 179 [176/918 (19%)] Loss: 10938431.000000\n",
      "Train Epoch: 179 [192/918 (21%)] Loss: 6379307.000000\n",
      "Train Epoch: 179 [208/918 (23%)] Loss: 8953319.000000\n",
      "Train Epoch: 179 [224/918 (24%)] Loss: 7280162.500000\n",
      "Train Epoch: 179 [240/918 (26%)] Loss: 8535344.000000\n",
      "Train Epoch: 179 [256/918 (28%)] Loss: 9407586.000000\n",
      "Train Epoch: 179 [272/918 (30%)] Loss: 7541952.000000\n",
      "Train Epoch: 179 [288/918 (31%)] Loss: 6115913.500000\n",
      "Train Epoch: 179 [304/918 (33%)] Loss: 9913896.000000\n",
      "Train Epoch: 179 [320/918 (35%)] Loss: 6550431.500000\n",
      "Train Epoch: 179 [336/918 (37%)] Loss: 6370789.500000\n",
      "Train Epoch: 179 [352/918 (38%)] Loss: 12003259.000000\n",
      "Train Epoch: 179 [368/918 (40%)] Loss: 10255286.000000\n",
      "Train Epoch: 179 [384/918 (42%)] Loss: 9273829.000000\n",
      "Train Epoch: 179 [400/918 (44%)] Loss: 13429867.000000\n",
      "Train Epoch: 179 [416/918 (45%)] Loss: 5918741.000000\n",
      "Train Epoch: 179 [432/918 (47%)] Loss: 16632307.000000\n",
      "Train Epoch: 179 [448/918 (49%)] Loss: 10321623.000000\n",
      "Train Epoch: 179 [464/918 (51%)] Loss: 5701869.000000\n",
      "Train Epoch: 179 [480/918 (52%)] Loss: 11948301.000000\n",
      "Train Epoch: 179 [496/918 (54%)] Loss: 8006453.000000\n",
      "Train Epoch: 179 [512/918 (56%)] Loss: 9952490.000000\n",
      "Train Epoch: 179 [528/918 (58%)] Loss: 6366351.000000\n",
      "Train Epoch: 179 [544/918 (59%)] Loss: 9111591.000000\n",
      "Train Epoch: 179 [560/918 (61%)] Loss: 9298924.000000\n",
      "Train Epoch: 179 [576/918 (63%)] Loss: 6303109.500000\n",
      "Train Epoch: 179 [592/918 (64%)] Loss: 8282337.000000\n",
      "Train Epoch: 179 [608/918 (66%)] Loss: 7312241.500000\n",
      "Train Epoch: 179 [624/918 (68%)] Loss: 7490718.500000\n",
      "Train Epoch: 179 [640/918 (70%)] Loss: 6487109.500000\n",
      "Train Epoch: 179 [656/918 (71%)] Loss: 10317493.000000\n",
      "Train Epoch: 179 [672/918 (73%)] Loss: 7304565.000000\n",
      "Train Epoch: 179 [688/918 (75%)] Loss: 17202564.000000\n",
      "Train Epoch: 179 [704/918 (77%)] Loss: 8487551.000000\n",
      "Train Epoch: 179 [720/918 (78%)] Loss: 10314084.000000\n",
      "Train Epoch: 179 [736/918 (80%)] Loss: 4728716.000000\n",
      "Train Epoch: 179 [752/918 (82%)] Loss: 6801974.500000\n",
      "Train Epoch: 179 [768/918 (84%)] Loss: 8460975.000000\n",
      "Train Epoch: 179 [784/918 (85%)] Loss: 11233669.000000\n",
      "Train Epoch: 179 [800/918 (87%)] Loss: 7535363.500000\n",
      "Train Epoch: 179 [816/918 (89%)] Loss: 8207259.500000\n",
      "Train Epoch: 179 [832/918 (91%)] Loss: 10346262.000000\n",
      "Train Epoch: 179 [848/918 (92%)] Loss: 10542173.000000\n",
      "Train Epoch: 179 [864/918 (94%)] Loss: 13234723.000000\n",
      "Train Epoch: 179 [880/918 (96%)] Loss: 9678750.000000\n",
      "Train Epoch: 179 [896/918 (98%)] Loss: 11044595.000000\n",
      "Train Epoch: 179 [912/918 (99%)] Loss: 10016466.000000\n",
      "    epoch          : 179\n",
      "    loss           : 9177392.47826087\n",
      "    ess            : 7.400990295410156\n",
      "    log_marginal   : -9177389.591304347\n",
      "    val_loss       : 8407739.23076923\n",
      "    val_ess        : 7.003090216563298\n",
      "    val_log_marginal: -8407737.0\n",
      "Train Epoch: 180 [0/918 (0%)] Loss: 8493906.000000\n",
      "Train Epoch: 180 [16/918 (2%)] Loss: 16390479.000000\n",
      "Train Epoch: 180 [32/918 (3%)] Loss: 6028679.000000\n",
      "Train Epoch: 180 [48/918 (5%)] Loss: 8410535.000000\n",
      "Train Epoch: 180 [64/918 (7%)] Loss: 6925014.500000\n",
      "Train Epoch: 180 [80/918 (9%)] Loss: 8829522.000000\n",
      "Train Epoch: 180 [96/918 (10%)] Loss: 5921173.500000\n",
      "Train Epoch: 180 [112/918 (12%)] Loss: 6876945.500000\n",
      "Train Epoch: 180 [128/918 (14%)] Loss: 13782973.000000\n",
      "Train Epoch: 180 [144/918 (16%)] Loss: 6365300.000000\n",
      "Train Epoch: 180 [160/918 (17%)] Loss: 5782335.500000\n",
      "Train Epoch: 180 [176/918 (19%)] Loss: 12664944.000000\n",
      "Train Epoch: 180 [192/918 (21%)] Loss: 7658120.000000\n",
      "Train Epoch: 180 [208/918 (23%)] Loss: 8410832.000000\n",
      "Train Epoch: 180 [224/918 (24%)] Loss: 7618626.500000\n",
      "Train Epoch: 180 [240/918 (26%)] Loss: 7844435.500000\n",
      "Train Epoch: 180 [256/918 (28%)] Loss: 6745772.000000\n",
      "Train Epoch: 180 [272/918 (30%)] Loss: 8589410.000000\n",
      "Train Epoch: 180 [288/918 (31%)] Loss: 15093712.000000\n",
      "Train Epoch: 180 [304/918 (33%)] Loss: 8325414.500000\n",
      "Train Epoch: 180 [320/918 (35%)] Loss: 9479462.000000\n",
      "Train Epoch: 180 [336/918 (37%)] Loss: 8446447.000000\n",
      "Train Epoch: 180 [352/918 (38%)] Loss: 8812331.000000\n",
      "Train Epoch: 180 [368/918 (40%)] Loss: 6970109.000000\n",
      "Train Epoch: 180 [384/918 (42%)] Loss: 8309493.500000\n",
      "Train Epoch: 180 [400/918 (44%)] Loss: 7384971.500000\n",
      "Train Epoch: 180 [416/918 (45%)] Loss: 7969937.000000\n",
      "Train Epoch: 180 [432/918 (47%)] Loss: 6169707.500000\n",
      "Train Epoch: 180 [448/918 (49%)] Loss: 6972387.500000\n",
      "Train Epoch: 180 [464/918 (51%)] Loss: 9430759.000000\n",
      "Train Epoch: 180 [480/918 (52%)] Loss: 9702840.000000\n",
      "Train Epoch: 180 [496/918 (54%)] Loss: 8920487.000000\n",
      "Train Epoch: 180 [512/918 (56%)] Loss: 7953557.000000\n",
      "Train Epoch: 180 [528/918 (58%)] Loss: 11712275.000000\n",
      "Train Epoch: 180 [544/918 (59%)] Loss: 8415350.000000\n",
      "Train Epoch: 180 [560/918 (61%)] Loss: 7356817.500000\n",
      "Train Epoch: 180 [576/918 (63%)] Loss: 8961125.000000\n",
      "Train Epoch: 180 [592/918 (64%)] Loss: 6312333.000000\n",
      "Train Epoch: 180 [608/918 (66%)] Loss: 7014761.500000\n",
      "Train Epoch: 180 [624/918 (68%)] Loss: 7860953.000000\n",
      "Train Epoch: 180 [640/918 (70%)] Loss: 10903581.000000\n",
      "Train Epoch: 180 [656/918 (71%)] Loss: 6343037.000000\n",
      "Train Epoch: 180 [672/918 (73%)] Loss: 9460871.000000\n",
      "Train Epoch: 180 [688/918 (75%)] Loss: 9069415.000000\n",
      "Train Epoch: 180 [704/918 (77%)] Loss: 14307960.000000\n",
      "Train Epoch: 180 [720/918 (78%)] Loss: 13080053.000000\n",
      "Train Epoch: 180 [736/918 (80%)] Loss: 13757042.000000\n",
      "Train Epoch: 180 [752/918 (82%)] Loss: 8138277.500000\n",
      "Train Epoch: 180 [768/918 (84%)] Loss: 11709268.000000\n",
      "Train Epoch: 180 [784/918 (85%)] Loss: 6464150.000000\n",
      "Train Epoch: 180 [800/918 (87%)] Loss: 5126939.500000\n",
      "Train Epoch: 180 [816/918 (89%)] Loss: 4554725.500000\n",
      "Train Epoch: 180 [832/918 (91%)] Loss: 6566515.500000\n",
      "Train Epoch: 180 [848/918 (92%)] Loss: 7416065.500000\n",
      "Train Epoch: 180 [864/918 (94%)] Loss: 7046368.000000\n",
      "Train Epoch: 180 [880/918 (96%)] Loss: 7851138.500000\n",
      "Train Epoch: 180 [896/918 (98%)] Loss: 11534367.000000\n",
      "Train Epoch: 180 [912/918 (99%)] Loss: 6068045.500000\n",
      "    epoch          : 180\n",
      "    loss           : 9210915.439130435\n",
      "    ess            : 8.087325751263162\n",
      "    log_marginal   : -9210912.97826087\n",
      "    val_loss       : 8886295.461538462\n",
      "    val_ess        : 8.120132207870483\n",
      "    val_log_marginal: -8886291.846153846\n",
      "Saving checkpoint: saved/models/FlowersDiffusion_Ppc/0502_011314/checkpoint-epoch180.pth ...\n",
      "Train Epoch: 181 [0/918 (0%)] Loss: 9739330.000000\n",
      "Train Epoch: 181 [16/918 (2%)] Loss: 11021650.000000\n",
      "Train Epoch: 181 [32/918 (3%)] Loss: 12996422.000000\n",
      "Train Epoch: 181 [48/918 (5%)] Loss: 9760015.000000\n",
      "Train Epoch: 181 [64/918 (7%)] Loss: 10970939.000000\n",
      "Train Epoch: 181 [80/918 (9%)] Loss: 9436415.000000\n",
      "Train Epoch: 181 [96/918 (10%)] Loss: 6687283.500000\n",
      "Train Epoch: 181 [112/918 (12%)] Loss: 5565466.500000\n",
      "Train Epoch: 181 [128/918 (14%)] Loss: 9936092.000000\n",
      "Train Epoch: 181 [144/918 (16%)] Loss: 8465103.000000\n",
      "Train Epoch: 181 [160/918 (17%)] Loss: 5803627.500000\n",
      "Train Epoch: 181 [176/918 (19%)] Loss: 8517883.000000\n",
      "Train Epoch: 181 [192/918 (21%)] Loss: 13836499.000000\n",
      "Train Epoch: 181 [208/918 (23%)] Loss: 11059179.000000\n",
      "Train Epoch: 181 [224/918 (24%)] Loss: 7635008.000000\n",
      "Train Epoch: 181 [240/918 (26%)] Loss: 14414771.000000\n",
      "Train Epoch: 181 [256/918 (28%)] Loss: 10089659.000000\n",
      "Train Epoch: 181 [272/918 (30%)] Loss: 6929110.500000\n",
      "Train Epoch: 181 [288/918 (31%)] Loss: 7401405.000000\n",
      "Train Epoch: 181 [304/918 (33%)] Loss: 9310902.000000\n",
      "Train Epoch: 181 [320/918 (35%)] Loss: 5272235.000000\n",
      "Train Epoch: 181 [336/918 (37%)] Loss: 5287129.000000\n",
      "Train Epoch: 181 [352/918 (38%)] Loss: 6257952.000000\n",
      "Train Epoch: 181 [368/918 (40%)] Loss: 8402244.000000\n",
      "Train Epoch: 181 [384/918 (42%)] Loss: 8572755.000000\n",
      "Train Epoch: 181 [400/918 (44%)] Loss: 4902066.000000\n",
      "Train Epoch: 181 [416/918 (45%)] Loss: 9417367.000000\n",
      "Train Epoch: 181 [432/918 (47%)] Loss: 4953514.500000\n",
      "Train Epoch: 181 [448/918 (49%)] Loss: 6066007.000000\n",
      "Train Epoch: 181 [464/918 (51%)] Loss: 7856882.500000\n",
      "Train Epoch: 181 [480/918 (52%)] Loss: 10382433.000000\n",
      "Train Epoch: 181 [496/918 (54%)] Loss: 10017587.000000\n",
      "Train Epoch: 181 [512/918 (56%)] Loss: 7591844.000000\n",
      "Train Epoch: 181 [528/918 (58%)] Loss: 12915202.000000\n",
      "Train Epoch: 181 [544/918 (59%)] Loss: 6126645.000000\n",
      "Train Epoch: 181 [560/918 (61%)] Loss: 10210282.000000\n",
      "Train Epoch: 181 [576/918 (63%)] Loss: 7642558.500000\n",
      "Train Epoch: 181 [592/918 (64%)] Loss: 7468345.500000\n",
      "Train Epoch: 181 [608/918 (66%)] Loss: 9065161.000000\n",
      "Train Epoch: 181 [624/918 (68%)] Loss: 7080449.500000\n",
      "Train Epoch: 181 [640/918 (70%)] Loss: 14190821.000000\n",
      "Train Epoch: 181 [656/918 (71%)] Loss: 10981895.000000\n",
      "Train Epoch: 181 [672/918 (73%)] Loss: 8067906.500000\n",
      "Train Epoch: 181 [688/918 (75%)] Loss: 8675295.000000\n",
      "Train Epoch: 181 [704/918 (77%)] Loss: 6902769.000000\n",
      "Train Epoch: 181 [720/918 (78%)] Loss: 4859492.000000\n",
      "Train Epoch: 181 [736/918 (80%)] Loss: 11485079.000000\n",
      "Train Epoch: 181 [752/918 (82%)] Loss: 10514618.000000\n",
      "Train Epoch: 181 [768/918 (84%)] Loss: 5558019.500000\n",
      "Train Epoch: 181 [784/918 (85%)] Loss: 8719083.000000\n",
      "Train Epoch: 181 [800/918 (87%)] Loss: 13595546.000000\n",
      "Train Epoch: 181 [816/918 (89%)] Loss: 11280426.000000\n",
      "Train Epoch: 181 [832/918 (91%)] Loss: 12882519.000000\n",
      "Train Epoch: 181 [848/918 (92%)] Loss: 5631335.000000\n",
      "Train Epoch: 181 [864/918 (94%)] Loss: 10660487.000000\n",
      "Train Epoch: 181 [880/918 (96%)] Loss: 6557413.500000\n",
      "Train Epoch: 181 [896/918 (98%)] Loss: 8996183.000000\n",
      "Train Epoch: 181 [912/918 (99%)] Loss: 12243766.000000\n",
      "    epoch          : 181\n",
      "    loss           : 8755910.082608696\n",
      "    ess            : 8.234171015283335\n",
      "    log_marginal   : -8755908.226086957\n",
      "    val_loss       : 8396811.346153846\n",
      "    val_ess        : 6.737128973007202\n",
      "    val_log_marginal: -8396809.076923076\n",
      "Train Epoch: 182 [0/918 (0%)] Loss: 6121859.500000\n",
      "Train Epoch: 182 [16/918 (2%)] Loss: 13905675.000000\n",
      "Train Epoch: 182 [32/918 (3%)] Loss: 5403074.500000\n",
      "Train Epoch: 182 [48/918 (5%)] Loss: 10316890.000000\n",
      "Train Epoch: 182 [64/918 (7%)] Loss: 5536649.500000\n",
      "Train Epoch: 182 [80/918 (9%)] Loss: 9445322.000000\n",
      "Train Epoch: 182 [96/918 (10%)] Loss: 13821151.000000\n",
      "Train Epoch: 182 [112/918 (12%)] Loss: 10192587.000000\n",
      "Train Epoch: 182 [128/918 (14%)] Loss: 7303782.500000\n",
      "Train Epoch: 182 [144/918 (16%)] Loss: 7646814.500000\n",
      "Train Epoch: 182 [160/918 (17%)] Loss: 8684473.000000\n",
      "Train Epoch: 182 [176/918 (19%)] Loss: 8271310.500000\n",
      "Train Epoch: 182 [192/918 (21%)] Loss: 6058285.500000\n",
      "Train Epoch: 182 [208/918 (23%)] Loss: 8653255.000000\n",
      "Train Epoch: 182 [224/918 (24%)] Loss: 8200556.000000\n",
      "Train Epoch: 182 [240/918 (26%)] Loss: 7719705.500000\n",
      "Train Epoch: 182 [256/918 (28%)] Loss: 13740384.000000\n",
      "Train Epoch: 182 [272/918 (30%)] Loss: 6836037.000000\n",
      "Train Epoch: 182 [288/918 (31%)] Loss: 7793896.000000\n",
      "Train Epoch: 182 [304/918 (33%)] Loss: 9786109.000000\n",
      "Train Epoch: 182 [320/918 (35%)] Loss: 11820729.000000\n",
      "Train Epoch: 182 [336/918 (37%)] Loss: 9007951.000000\n",
      "Train Epoch: 182 [352/918 (38%)] Loss: 9580811.000000\n",
      "Train Epoch: 182 [368/918 (40%)] Loss: 8538716.000000\n",
      "Train Epoch: 182 [384/918 (42%)] Loss: 6429921.000000\n",
      "Train Epoch: 182 [400/918 (44%)] Loss: 7000594.500000\n",
      "Train Epoch: 182 [416/918 (45%)] Loss: 7490099.500000\n",
      "Train Epoch: 182 [432/918 (47%)] Loss: 8351685.000000\n",
      "Train Epoch: 182 [448/918 (49%)] Loss: 11367344.000000\n",
      "Train Epoch: 182 [464/918 (51%)] Loss: 5511729.500000\n",
      "Train Epoch: 182 [480/918 (52%)] Loss: 7923675.500000\n",
      "Train Epoch: 182 [496/918 (54%)] Loss: 6863723.500000\n",
      "Train Epoch: 182 [512/918 (56%)] Loss: 8301889.500000\n",
      "Train Epoch: 182 [528/918 (58%)] Loss: 5296244.500000\n",
      "Train Epoch: 182 [544/918 (59%)] Loss: 5410068.000000\n",
      "Train Epoch: 182 [560/918 (61%)] Loss: 5502189.500000\n",
      "Train Epoch: 182 [576/918 (63%)] Loss: 10495856.000000\n",
      "Train Epoch: 182 [592/918 (64%)] Loss: 5369797.000000\n",
      "Train Epoch: 182 [608/918 (66%)] Loss: 6531536.000000\n",
      "Train Epoch: 182 [624/918 (68%)] Loss: 8812152.000000\n",
      "Train Epoch: 182 [640/918 (70%)] Loss: 7754494.500000\n",
      "Train Epoch: 182 [656/918 (71%)] Loss: 6761569.500000\n",
      "Train Epoch: 182 [672/918 (73%)] Loss: 6867175.500000\n",
      "Train Epoch: 182 [688/918 (75%)] Loss: 11260478.000000\n",
      "Train Epoch: 182 [704/918 (77%)] Loss: 9170308.000000\n",
      "Train Epoch: 182 [720/918 (78%)] Loss: 11876287.000000\n",
      "Train Epoch: 182 [736/918 (80%)] Loss: 7418909.000000\n",
      "Train Epoch: 182 [752/918 (82%)] Loss: 7530183.500000\n",
      "Train Epoch: 182 [768/918 (84%)] Loss: 6785258.500000\n",
      "Train Epoch: 182 [784/918 (85%)] Loss: 6260558.500000\n",
      "Train Epoch: 182 [800/918 (87%)] Loss: 6641461.000000\n",
      "Train Epoch: 182 [816/918 (89%)] Loss: 8025765.000000\n",
      "Train Epoch: 182 [832/918 (91%)] Loss: 5151405.500000\n",
      "Train Epoch: 182 [848/918 (92%)] Loss: 18828448.000000\n",
      "Train Epoch: 182 [864/918 (94%)] Loss: 5263916.000000\n",
      "Train Epoch: 182 [880/918 (96%)] Loss: 11669744.000000\n",
      "Train Epoch: 182 [896/918 (98%)] Loss: 6076892.000000\n",
      "Train Epoch: 182 [912/918 (99%)] Loss: 8167046.000000\n",
      "    epoch          : 182\n",
      "    loss           : 9005329.630434783\n",
      "    ess            : 8.033699651386426\n",
      "    log_marginal   : -9005327.234782608\n",
      "    val_loss       : 10221172.384615384\n",
      "    val_ess        : 6.863733199926523\n",
      "    val_log_marginal: -10221170.346153846\n",
      "Train Epoch: 183 [0/918 (0%)] Loss: 11604488.000000\n",
      "Train Epoch: 183 [16/918 (2%)] Loss: 8492667.000000\n",
      "Train Epoch: 183 [32/918 (3%)] Loss: 9288330.000000\n",
      "Train Epoch: 183 [48/918 (5%)] Loss: 7393958.500000\n",
      "Train Epoch: 183 [64/918 (7%)] Loss: 9061063.000000\n",
      "Train Epoch: 183 [80/918 (9%)] Loss: 9007168.000000\n",
      "Train Epoch: 183 [96/918 (10%)] Loss: 5099350.000000\n",
      "Train Epoch: 183 [112/918 (12%)] Loss: 9285737.000000\n",
      "Train Epoch: 183 [128/918 (14%)] Loss: 9096543.000000\n",
      "Train Epoch: 183 [144/918 (16%)] Loss: 5106533.500000\n",
      "Train Epoch: 183 [160/918 (17%)] Loss: 7271444.000000\n",
      "Train Epoch: 183 [176/918 (19%)] Loss: 11925355.000000\n",
      "Train Epoch: 183 [192/918 (21%)] Loss: 5254885.000000\n",
      "Train Epoch: 183 [208/918 (23%)] Loss: 5558689.000000\n",
      "Train Epoch: 183 [224/918 (24%)] Loss: 10529371.000000\n",
      "Train Epoch: 183 [240/918 (26%)] Loss: 13929088.000000\n",
      "Train Epoch: 183 [256/918 (28%)] Loss: 6929070.500000\n",
      "Train Epoch: 183 [272/918 (30%)] Loss: 11312291.000000\n",
      "Train Epoch: 183 [288/918 (31%)] Loss: 12450606.000000\n",
      "Train Epoch: 183 [304/918 (33%)] Loss: 7368202.500000\n",
      "Train Epoch: 183 [320/918 (35%)] Loss: 6978826.500000\n",
      "Train Epoch: 183 [336/918 (37%)] Loss: 6915469.000000\n",
      "Train Epoch: 183 [352/918 (38%)] Loss: 7214340.000000\n",
      "Train Epoch: 183 [368/918 (40%)] Loss: 7566341.000000\n",
      "Train Epoch: 183 [384/918 (42%)] Loss: 8446511.000000\n",
      "Train Epoch: 183 [400/918 (44%)] Loss: 8101150.500000\n",
      "Train Epoch: 183 [416/918 (45%)] Loss: 8429507.000000\n",
      "Train Epoch: 183 [432/918 (47%)] Loss: 9228349.000000\n",
      "Train Epoch: 183 [448/918 (49%)] Loss: 12428886.000000\n",
      "Train Epoch: 183 [464/918 (51%)] Loss: 12646238.000000\n",
      "Train Epoch: 183 [480/918 (52%)] Loss: 8393856.000000\n",
      "Train Epoch: 183 [496/918 (54%)] Loss: 8216076.000000\n",
      "Train Epoch: 183 [512/918 (56%)] Loss: 5203839.500000\n",
      "Train Epoch: 183 [528/918 (58%)] Loss: 10039487.000000\n",
      "Train Epoch: 183 [544/918 (59%)] Loss: 6654500.000000\n",
      "Train Epoch: 183 [560/918 (61%)] Loss: 9418032.000000\n",
      "Train Epoch: 183 [576/918 (63%)] Loss: 11522774.000000\n",
      "Train Epoch: 183 [592/918 (64%)] Loss: 9394899.000000\n",
      "Train Epoch: 183 [608/918 (66%)] Loss: 8150447.500000\n",
      "Train Epoch: 183 [624/918 (68%)] Loss: 8113717.000000\n",
      "Train Epoch: 183 [640/918 (70%)] Loss: 9078296.000000\n",
      "Train Epoch: 183 [656/918 (71%)] Loss: 7202886.500000\n",
      "Train Epoch: 183 [672/918 (73%)] Loss: 8038338.500000\n",
      "Train Epoch: 183 [688/918 (75%)] Loss: 7288280.000000\n",
      "Train Epoch: 183 [704/918 (77%)] Loss: 7403365.000000\n",
      "Train Epoch: 183 [720/918 (78%)] Loss: 11039555.000000\n",
      "Train Epoch: 183 [736/918 (80%)] Loss: 8805599.000000\n",
      "Train Epoch: 183 [752/918 (82%)] Loss: 6271981.000000\n",
      "Train Epoch: 183 [768/918 (84%)] Loss: 6168245.000000\n",
      "Train Epoch: 183 [784/918 (85%)] Loss: 7200465.500000\n",
      "Train Epoch: 183 [800/918 (87%)] Loss: 6615311.000000\n",
      "Train Epoch: 183 [816/918 (89%)] Loss: 5908691.500000\n",
      "Train Epoch: 183 [832/918 (91%)] Loss: 7727425.500000\n",
      "Train Epoch: 183 [848/918 (92%)] Loss: 11966383.000000\n",
      "Train Epoch: 183 [864/918 (94%)] Loss: 5980007.000000\n",
      "Train Epoch: 183 [880/918 (96%)] Loss: 5739572.000000\n",
      "Train Epoch: 183 [896/918 (98%)] Loss: 5603883.500000\n",
      "Train Epoch: 183 [912/918 (99%)] Loss: 7169850.000000\n",
      "    epoch          : 183\n",
      "    loss           : 8938720.591304347\n",
      "    ess            : 7.2091657389765205\n",
      "    log_marginal   : -8938718.739130436\n",
      "    val_loss       : 8509394.076923076\n",
      "    val_ess        : 6.953909928982075\n",
      "    val_log_marginal: -8509391.038461538\n",
      "Train Epoch: 184 [0/918 (0%)] Loss: 16388973.000000\n",
      "Train Epoch: 184 [16/918 (2%)] Loss: 5789802.000000\n",
      "Train Epoch: 184 [32/918 (3%)] Loss: 6297482.500000\n",
      "Train Epoch: 184 [48/918 (5%)] Loss: 8758192.000000\n",
      "Train Epoch: 184 [64/918 (7%)] Loss: 9015572.000000\n",
      "Train Epoch: 184 [80/918 (9%)] Loss: 10239209.000000\n",
      "Train Epoch: 184 [96/918 (10%)] Loss: 5984249.500000\n",
      "Train Epoch: 184 [112/918 (12%)] Loss: 9305826.000000\n",
      "Train Epoch: 184 [128/918 (14%)] Loss: 10182932.000000\n",
      "Train Epoch: 184 [144/918 (16%)] Loss: 7707781.000000\n",
      "Train Epoch: 184 [160/918 (17%)] Loss: 10382519.000000\n",
      "Train Epoch: 184 [176/918 (19%)] Loss: 10144605.000000\n",
      "Train Epoch: 184 [192/918 (21%)] Loss: 5324078.500000\n",
      "Train Epoch: 184 [208/918 (23%)] Loss: 7224167.500000\n",
      "Train Epoch: 184 [224/918 (24%)] Loss: 8688011.000000\n",
      "Train Epoch: 184 [240/918 (26%)] Loss: 6957744.000000\n",
      "Train Epoch: 184 [256/918 (28%)] Loss: 6834835.500000\n",
      "Train Epoch: 184 [272/918 (30%)] Loss: 7455953.500000\n",
      "Train Epoch: 184 [288/918 (31%)] Loss: 8512312.000000\n",
      "Train Epoch: 184 [304/918 (33%)] Loss: 7879446.500000\n",
      "Train Epoch: 184 [320/918 (35%)] Loss: 7367185.500000\n",
      "Train Epoch: 184 [336/918 (37%)] Loss: 12949215.000000\n",
      "Train Epoch: 184 [352/918 (38%)] Loss: 8260384.000000\n",
      "Train Epoch: 184 [368/918 (40%)] Loss: 5602509.500000\n",
      "Train Epoch: 184 [384/918 (42%)] Loss: 11371125.000000\n",
      "Train Epoch: 184 [400/918 (44%)] Loss: 7441646.500000\n",
      "Train Epoch: 184 [416/918 (45%)] Loss: 11483128.000000\n",
      "Train Epoch: 184 [432/918 (47%)] Loss: 8854642.000000\n",
      "Train Epoch: 184 [448/918 (49%)] Loss: 10190997.000000\n",
      "Train Epoch: 184 [464/918 (51%)] Loss: 7717208.000000\n",
      "Train Epoch: 184 [480/918 (52%)] Loss: 5520613.000000\n",
      "Train Epoch: 184 [496/918 (54%)] Loss: 8426383.000000\n",
      "Train Epoch: 184 [512/918 (56%)] Loss: 5389626.500000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/trainer/trainer.py:188\u001b[0m, in \u001b[0;36mPpcTrainer.train\u001b[0;34m(self, profiler)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_particles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_particles\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_particles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_particles\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/base/base_trainer.py:86\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self, profiler)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profiler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     profiler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 86\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# save logged informations into log dict\u001b[39;00m\n\u001b[1;32m     89\u001b[0m log \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch}\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/trainer/trainer.py:242\u001b[0m, in \u001b[0;36mPpcTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target, batch_indices) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader):\n\u001b[1;32m    241\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 242\u001b[0m     loss, log_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ppc_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mset_step((epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen_epoch \u001b[38;5;241m+\u001b[39m batch_idx)\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_metrics\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/trainer/trainer.py:217\u001b[0m, in \u001b[0;36mPpcTrainer._ppc_step\u001b[0;34m(self, batch_indices, data, train)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_sweeps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    215\u001b[0m         utils\u001b[38;5;241m.\u001b[39mimportance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mguide, data,\n\u001b[1;32m    216\u001b[0m                          lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr)\n\u001b[0;32m--> 217\u001b[0m     trace, log_weight \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlog_weight\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/utils/util.py:106\u001b[0m, in \u001b[0;36mimportance\u001b[0;34m(model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimportance\u001b[39m(model, guide, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 106\u001b[0m     tq \u001b[38;5;241m=\u001b[39m \u001b[43mpyro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoutine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mguide\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m pyro\u001b[38;5;241m.\u001b[39mpoutine\u001b[38;5;241m.\u001b[39mreplay(trace\u001b[38;5;241m=\u001b[39mtq):\n\u001b[1;32m    108\u001b[0m         tp \u001b[38;5;241m=\u001b[39m pyro\u001b[38;5;241m.\u001b[39mpoutine\u001b[38;5;241m.\u001b[39mtrace(model)\u001b[38;5;241m.\u001b[39mget_trace(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/model/model.py:193\u001b[0m, in \u001b[0;36mDiffusionPpc.guide\u001b[0;34m(self, xs, lr)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mbatch_shape \u001b[38;5;241m=\u001b[39m (B,)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m clamp_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph, X__0\u001b[38;5;241m=\u001b[39mxs) \u001b[38;5;28;01mas\u001b[39;00m graph:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/model/inference.py:136\u001b[0m, in \u001b[0;36mPpcGraphicalModel.guide\u001b[0;34m(self, lr)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m site, kernel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msweep(forward\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes[site][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_observed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 136\u001b[0m         posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_posterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(site, pyro\u001b[38;5;241m.\u001b[39msample(site, posterior))\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_sites(site))) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/model/inference.py:117\u001b[0m, in \u001b[0;36mPpcGraphicalModel.get_posterior\u001b[0;34m(self, name, event_dim, lr)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_posterior\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, event_dim: \u001b[38;5;28mint\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Distribution:\n\u001b[1;32m    116\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes[name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 117\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_complete_conditional_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     proposal \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mNormal(z \u001b[38;5;241m+\u001b[39m lr \u001b[38;5;241m*\u001b[39m error, math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m lr))\n\u001b[1;32m    120\u001b[0m     proposal \u001b[38;5;241m=\u001b[39m proposal\u001b[38;5;241m.\u001b[39mto_event(event_dim)\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/model/inference.py:93\u001b[0m, in \u001b[0;36mPpcGraphicalModel._complete_conditional_error\u001b[0;34m(self, site)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_sites(site):\n\u001b[1;32m     92\u001b[0m     site_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_sites(child))\u001b[38;5;241m.\u001b[39mindex(site)\n\u001b[0;32m---> 93\u001b[0m     error \u001b[38;5;241m=\u001b[39m error \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_site_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m site_index]\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/model/inference.py:111\u001b[0m, in \u001b[0;36mPpcGraphicalModel._site_errors\u001b[0;34m(self, site)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_site_errors\u001b[39m(\u001b[38;5;28mself\u001b[39m, site):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes[site]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes[site][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_site_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes[site][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/model/inference.py:107\u001b[0m, in \u001b[0;36mPpcGraphicalModel._compute_site_errors\u001b[0;34m(self, site)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscrete prediction errors not implemented!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/apis.py:363\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meager_transforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/eager_transforms.py:1285\u001b[0m, in \u001b[0;36mgrad_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_impl\u001b[39m(func: Callable, argnums: argnums_t, has_aux: \u001b[38;5;28mbool\u001b[39m, args, kwargs):\n\u001b[0;32m-> 1285\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_and_value_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1287\u001b[0m         grad, (_, aux) \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/eager_transforms.py:1249\u001b[0m, in \u001b[0;36mgrad_and_value_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m diff_args \u001b[38;5;241m=\u001b[39m _slice_argnums(args, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1247\u001b[0m tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_args)\n\u001b[0;32m-> 1249\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/model/inference.py:100\u001b[0m, in \u001b[0;36mPpcGraphicalModel._compute_site_errors.<locals>.logprobsum\u001b[0;34m(value, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogprobsum\u001b[39m(value, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/model/generative.py:251\u001b[0m, in \u001b[0;36mGraphicalModel.log_prob\u001b[0;34m(self, site, value, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, site, value, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 251\u001b[0m     density \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m density\u001b[38;5;241m.\u001b[39mlog_prob(value)\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/base/base_model.py:87\u001b[0m, in \u001b[0;36mPartialMarkovKernel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mbatch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[1;32m     86\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_poutine\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pyro_context\u001b[38;5;241m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/shai_hulud/ppc_experiments/model/generative.py:209\u001b[0m, in \u001b[0;36mDiffusionStep.forward\u001b[0;34m(self, xs_prev, t)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, xs_prev: torch\u001b[38;5;241m.\u001b[39mTensor, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m dist\u001b[38;5;241m.\u001b[39mDistribution:\n\u001b[1;32m    208\u001b[0m     P, B, C, W, H \u001b[38;5;241m=\u001b[39m xs_prev\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 209\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m(xs_prev\u001b[38;5;241m.\u001b[39mview(P\u001b[38;5;241m*\u001b[39mB, C, W, H),\n\u001b[1;32m    210\u001b[0m                     torch\u001b[38;5;241m.\u001b[39mtensor(t, device\u001b[38;5;241m=\u001b[39mxs_prev\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    211\u001b[0m                                  dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mrepeat(P\u001b[38;5;241m*\u001b[39mB))\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mNormal(loc\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mxs_prev\u001b[38;5;241m.\u001b[39mshape),\n\u001b[1;32m    213\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbetas[t])\u001b[38;5;241m.\u001b[39mto_event(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/nn/module.py:550\u001b[0m, in \u001b[0;36mPyroModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;66;03m# Regular nn.Modules trigger pyro.module statements.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pyro_context\u001b[38;5;241m.\u001b[39mactive:\n\u001b[0;32m--> 550\u001b[0m             \u001b[43mpyro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pyro_get_fullname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/primitives.py:438\u001b[0m, in \u001b[0;36mmodule\u001b[0;34m(name, nn_module, update_module_params)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param_value\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;66;03m# register the parameter in the module with pyro\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# this only does something substantive if the parameter hasn't been seen before\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     full_param_name \u001b[38;5;241m=\u001b[39m param_with_module_name(name, param_name)\n\u001b[0;32m--> 438\u001b[0m     returned_param \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_param_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param_value\u001b[38;5;241m.\u001b[39m_cdata \u001b[38;5;241m!=\u001b[39m returned_param\u001b[38;5;241m.\u001b[39m_cdata:\n\u001b[1;32m    441\u001b[0m         target_state_dict[param_name] \u001b[38;5;241m=\u001b[39m returned_param\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/primitives.py:78\u001b[0m, in \u001b[0;36mparam\u001b[0;34m(name, init_tensor, constraint, event_dim)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Note effectful(-) requires the double passing of name below.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m args \u001b[38;5;241m=\u001b[39m (name,) \u001b[38;5;28;01mif\u001b[39;00m init_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (name, init_tensor)\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_param\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/poutine/runtime.py:281\u001b[0m, in \u001b[0;36meffectful.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m msg \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m\"\u001b[39m: infer,\n\u001b[1;32m    279\u001b[0m }\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# apply the stack and return its return value\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[43mapply_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/poutine/runtime.py:220\u001b[0m, in \u001b[0;36mapply_stack\u001b[0;34m(initial_msg)\u001b[0m\n\u001b[1;32m    217\u001b[0m default_process_message(msg)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m stack[\u001b[38;5;241m-\u001b[39mpointer:]:\n\u001b[0;32m--> 220\u001b[0m     \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_postprocess_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m cont \u001b[38;5;241m=\u001b[39m msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cont \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/poutine/messenger.py:168\u001b[0m, in \u001b[0;36mMessenger._postprocess_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    166\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pyro_post_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/poutine/trace_messenger.py:138\u001b[0m, in \u001b[0;36mTraceMessenger._pyro_post_param\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pyro_post_param\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyro/poutine/trace_struct.py:97\u001b[0m, in \u001b[0;36mTrace.add_node\u001b[0;34m(self, site_name, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m adj_node \u001b[38;5;129;01min\u001b[39;00m adj_nodes:\n\u001b[1;32m     95\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m site, adj_node\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, site_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    :param string site_name: the name of the site to be added\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    instead of silently overwriting.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m site_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5b900-0121-4cf6-91b6-2c9b0b12716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.eval()\n",
    "trainer.model.cpu()\n",
    "trainer.cpu()\n",
    "trainer.train_particles.cpu()\n",
    "trainer.valid_particles.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d528cb-d45e-4a37-be86-9622aec9ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.graph.clear()\n",
    "trainer._load_particles(range(trainer.data_loader.batch_size), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26726a6-74e5-4e0f-81d5-746dba00f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in trainer.model.graph.nodes:\n",
    "    trainer.model.graph.nodes[site]['is_observed'] = trainer.model.graph.nodes[site]['value'] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb94c06-7112-4c5e-b781-0ac215a7e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2eeb8-32e3-467e-9e9a-0ac1e2af9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate_stack(\"forward\", (trainer.num_particles, trainer.data_loader.batch_size)):\n",
    "    model = pyro.condition(trainer.model, data={k: v['value'] for k, v in trainer.model.graph.nodes.items()})\n",
    "    xs = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9ba59-7b26-4ef3-9bfd-23f7c8a26464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1509d2-9afc-444e-821f-b7ccda42aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(xs.mean(dim=0)[i].squeeze().detach().cpu().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2029315-afe9-4ae8-9f64-c342ef8b830b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34a71d-84a2-48f0-8150-3607e77ed6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
