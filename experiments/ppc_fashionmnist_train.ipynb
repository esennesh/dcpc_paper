{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ef93e3-8eb5-4883-8265-5fbe97d06e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/ppc_experiments\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94520ed3-45be-4735-a0f2-b8f380838c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import pyro\n",
    "import torch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "import trainer.trainer as module_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac4be4-19eb-4713-a88d-9bec118c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75ea7b9-6fe5-4f8a-a825-3572e421242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1445d1-45bb-43f9-893d-7a2b2bad1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "\n",
    "config = read_json(\"experiments/ppc_fashionmnist_config.json\")\n",
    "config = ConfigParser(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca35026-5f64-47f8-98c7-a5e228013d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26421880/26421880 [00:01<00:00, 14331758.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29515/29515 [00:00<00:00, 256047.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4422102/4422102 [00:04<00:00, 996011.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5148/5148 [00:00<00:00, 15302818.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "MnistPpc(\n",
      "  (prior): GaussianPrior()\n",
      "  (decoder1): ConditionalGaussian(\n",
      "    (decoder): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=20, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder2): ConditionalGaussian(\n",
      "    (decoder): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (likelihood): MlpBernoulliLikelihood(\n",
      "    (decoder): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=256, out_features=784, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (graph): PpcGraphicalModel()\n",
      ")\n",
      "Trainable parameters: 319540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize particles: train batch 0\n",
      "Initialize particles: train batch 1\n",
      "Initialize particles: train batch 2\n",
      "Initialize particles: train batch 3\n",
      "Initialize particles: train batch 4\n",
      "Initialize particles: train batch 5\n",
      "Initialize particles: train batch 6\n",
      "Initialize particles: train batch 7\n",
      "Initialize particles: train batch 8\n",
      "Initialize particles: train batch 9\n",
      "Initialize particles: train batch 10\n",
      "Initialize particles: train batch 11\n",
      "Initialize particles: train batch 12\n",
      "Initialize particles: train batch 13\n",
      "Initialize particles: train batch 14\n",
      "Initialize particles: train batch 15\n",
      "Initialize particles: train batch 16\n",
      "Initialize particles: train batch 17\n",
      "Initialize particles: train batch 18\n",
      "Initialize particles: train batch 19\n",
      "Initialize particles: train batch 20\n",
      "Initialize particles: train batch 21\n",
      "Initialize particles: train batch 22\n",
      "Initialize particles: train batch 23\n",
      "Initialize particles: train batch 24\n",
      "Initialize particles: train batch 25\n",
      "Initialize particles: train batch 26\n",
      "Initialize particles: train batch 27\n",
      "Initialize particles: train batch 28\n",
      "Initialize particles: train batch 29\n",
      "Initialize particles: train batch 30\n",
      "Initialize particles: train batch 31\n",
      "Initialize particles: train batch 32\n",
      "Initialize particles: train batch 33\n",
      "Initialize particles: train batch 34\n",
      "Initialize particles: train batch 35\n",
      "Initialize particles: train batch 36\n",
      "Initialize particles: train batch 37\n",
      "Initialize particles: train batch 38\n",
      "Initialize particles: train batch 39\n",
      "Initialize particles: train batch 40\n",
      "Initialize particles: train batch 41\n",
      "Initialize particles: train batch 42\n",
      "Initialize particles: train batch 43\n",
      "Initialize particles: train batch 44\n",
      "Initialize particles: train batch 45\n",
      "Initialize particles: train batch 46\n",
      "Initialize particles: train batch 47\n",
      "Initialize particles: train batch 48\n",
      "Initialize particles: train batch 49\n",
      "Initialize particles: train batch 50\n",
      "Initialize particles: train batch 51\n",
      "Initialize particles: train batch 52\n",
      "Initialize particles: train batch 53\n",
      "Initialize particles: train batch 54\n",
      "Initialize particles: train batch 55\n",
      "Initialize particles: train batch 56\n",
      "Initialize particles: train batch 57\n",
      "Initialize particles: train batch 58\n",
      "Initialize particles: train batch 59\n",
      "Initialize particles: train batch 60\n",
      "Initialize particles: train batch 61\n",
      "Initialize particles: train batch 62\n",
      "Initialize particles: train batch 63\n",
      "Initialize particles: train batch 64\n",
      "Initialize particles: train batch 65\n",
      "Initialize particles: train batch 66\n",
      "Initialize particles: train batch 67\n",
      "Initialize particles: train batch 68\n",
      "Initialize particles: train batch 69\n",
      "Initialize particles: train batch 70\n",
      "Initialize particles: train batch 71\n",
      "Initialize particles: train batch 72\n",
      "Initialize particles: train batch 73\n",
      "Initialize particles: train batch 74\n",
      "Initialize particles: train batch 75\n",
      "Initialize particles: train batch 76\n",
      "Initialize particles: train batch 77\n",
      "Initialize particles: train batch 78\n",
      "Initialize particles: train batch 79\n",
      "Initialize particles: train batch 80\n",
      "Initialize particles: train batch 81\n",
      "Initialize particles: train batch 82\n",
      "Initialize particles: train batch 83\n",
      "Initialize particles: train batch 84\n",
      "Initialize particles: train batch 85\n",
      "Initialize particles: train batch 86\n",
      "Initialize particles: train batch 87\n",
      "Initialize particles: train batch 88\n",
      "Initialize particles: train batch 89\n",
      "Initialize particles: train batch 90\n",
      "Initialize particles: train batch 91\n",
      "Initialize particles: train batch 92\n",
      "Initialize particles: train batch 93\n",
      "Initialize particles: train batch 94\n",
      "Initialize particles: train batch 95\n",
      "Initialize particles: train batch 96\n",
      "Initialize particles: train batch 97\n",
      "Initialize particles: train batch 98\n",
      "Initialize particles: train batch 99\n",
      "Initialize particles: train batch 100\n",
      "Initialize particles: train batch 101\n",
      "Initialize particles: train batch 102\n",
      "Initialize particles: train batch 103\n",
      "Initialize particles: train batch 104\n",
      "Initialize particles: train batch 105\n",
      "Initialize particles: valid batch 0\n",
      "Initialize particles: valid batch 1\n",
      "Initialize particles: valid batch 2\n",
      "Initialize particles: valid batch 3\n",
      "Initialize particles: valid batch 4\n",
      "Initialize particles: valid batch 5\n",
      "Initialize particles: valid batch 6\n",
      "Initialize particles: valid batch 7\n",
      "Initialize particles: valid batch 8\n",
      "Initialize particles: valid batch 9\n",
      "Initialize particles: valid batch 10\n",
      "Initialize particles: valid batch 11\n"
     ]
    }
   ],
   "source": [
    "logger = config.get_logger('train')\n",
    "\n",
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()\n",
    "\n",
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)\n",
    "logger.info(model)\n",
    "\n",
    "# get function handles of metrics\n",
    "metrics = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# build optimizer.\n",
    "if \"lr_scheduler\" in config:\n",
    "    lr_scheduler = getattr(pyro.optim, config[\"lr_scheduler\"][\"type\"])\n",
    "    lr_scheduler = optimizer = lr_scheduler({\n",
    "        \"optimizer\": getattr(torch.optim, config[\"optimizer\"][\"type\"]),\n",
    "        \"optim_args\": config[\"optimizer\"][\"args\"][\"optim_args\"],\n",
    "        **config[\"lr_scheduler\"][\"args\"]\n",
    "    })\n",
    "else:\n",
    "    optimizer = config.init_obj('optimizer', pyro.optim)\n",
    "    lr_scheduler = None\n",
    "\n",
    "# build trainer\n",
    "# kwargs = config['trainer'].pop('args')\n",
    "trainer = config.init_obj('trainer', module_trainer, model, metrics, optimizer,\n",
    "                          config=config, data_loader=data_loader,\n",
    "                          valid_data_loader=valid_data_loader,\n",
    "                          lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5cdd31-7fae-4e6f-8fe2-ef5c023919de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved/log/FashionMnist_Ppc/0505_172452\n"
     ]
    }
   ],
   "source": [
    "logger.info(trainer.config.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9820b982-1a39-4bde-850e-1a1d9a92557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/54000 (0%)] Loss: 792.443298\n",
      "Train Epoch: 1 [11264/54000 (21%)] Loss: 156.191406\n",
      "Train Epoch: 1 [22528/54000 (42%)] Loss: 129.377762\n",
      "Train Epoch: 1 [33792/54000 (63%)] Loss: 29.561356\n",
      "Train Epoch: 1 [45056/54000 (83%)] Loss: -22.605347\n",
      "    epoch          : 1\n",
      "    loss           : 111.93349627166424\n",
      "    ess            : 1.960248607509541\n",
      "    log_marginal   : -111.5255571390098\n",
      "    log_joint      : 103.76595657051735\n",
      "    val_loss       : -64.25297896067302\n",
      "    val_ess        : 1.9688660601774852\n",
      "    val_log_marginal: 64.54949156443278\n",
      "    val_log_joint  : 280.3544235229492\n",
      "Train Epoch: 2 [0/54000 (0%)] Loss: -84.455444\n",
      "Train Epoch: 2 [11264/54000 (21%)] Loss: -130.708771\n",
      "Train Epoch: 2 [22528/54000 (42%)] Loss: -148.939240\n",
      "Train Epoch: 2 [33792/54000 (63%)] Loss: -181.080353\n",
      "Train Epoch: 2 [45056/54000 (83%)] Loss: -173.225922\n",
      "    epoch          : 2\n",
      "    loss           : -142.5965965558898\n",
      "    ess            : 1.9816068500842687\n",
      "    log_marginal   : 142.62401336094118\n",
      "    log_joint      : 350.5584794530329\n",
      "    val_loss       : -182.63821919759116\n",
      "    val_ess        : 1.9797486464182537\n",
      "    val_log_marginal: 182.66564559936523\n",
      "    val_log_joint  : 390.0441182454427\n",
      "Train Epoch: 3 [0/54000 (0%)] Loss: -197.727921\n",
      "Train Epoch: 3 [11264/54000 (21%)] Loss: -205.773911\n",
      "Train Epoch: 3 [22528/54000 (42%)] Loss: -226.982941\n",
      "Train Epoch: 3 [33792/54000 (63%)] Loss: -195.510315\n",
      "Train Epoch: 3 [45056/54000 (83%)] Loss: -157.544479\n",
      "    epoch          : 3\n",
      "    loss           : -201.32215161593456\n",
      "    ess            : 1.980166383509366\n",
      "    log_marginal   : 201.3386434878943\n",
      "    log_joint      : 409.1559724627801\n",
      "    val_loss       : -209.10145950317383\n",
      "    val_ess        : 1.978678931792577\n",
      "    val_log_marginal: 209.11928685506186\n",
      "    val_log_joint  : 417.3566614786784\n",
      "Train Epoch: 4 [0/54000 (0%)] Loss: -245.215393\n",
      "Train Epoch: 4 [11264/54000 (21%)] Loss: -246.652954\n",
      "Train Epoch: 4 [22528/54000 (42%)] Loss: -229.394043\n",
      "Train Epoch: 4 [33792/54000 (63%)] Loss: -242.852112\n",
      "Train Epoch: 4 [45056/54000 (83%)] Loss: -247.016800\n",
      "    epoch          : 4\n",
      "    loss           : -242.21472858932782\n",
      "    ess            : 1.9805049513870816\n",
      "    log_marginal   : 242.22925682787624\n",
      "    log_joint      : 450.3996846900796\n",
      "    val_loss       : -269.5445925394694\n",
      "    val_ess        : 1.9796757400035858\n",
      "    val_log_marginal: 269.55869420369464\n",
      "    val_log_joint  : 477.5301818847656\n",
      "Train Epoch: 5 [0/54000 (0%)] Loss: -279.109222\n",
      "Train Epoch: 5 [11264/54000 (21%)] Loss: -282.214783\n",
      "Train Epoch: 5 [22528/54000 (42%)] Loss: -296.597137\n",
      "Train Epoch: 5 [33792/54000 (63%)] Loss: -297.229889\n",
      "Train Epoch: 5 [45056/54000 (83%)] Loss: -297.786560\n",
      "    epoch          : 5\n",
      "    loss           : -298.06027567161703\n",
      "    ess            : 1.9788582201273937\n",
      "    log_marginal   : 298.07603684911186\n",
      "    log_joint      : 505.7844341925855\n",
      "    val_loss       : -317.18933359781903\n",
      "    val_ess        : 1.9783151944478352\n",
      "    val_log_marginal: 317.20729064941406\n",
      "    val_log_joint  : 524.9096857706705\n",
      "Train Epoch: 6 [0/54000 (0%)] Loss: -322.987244\n",
      "Train Epoch: 6 [11264/54000 (21%)] Loss: -354.487366\n",
      "Train Epoch: 6 [22528/54000 (42%)] Loss: -330.923859\n",
      "Train Epoch: 6 [33792/54000 (63%)] Loss: -286.164459\n",
      "Train Epoch: 6 [45056/54000 (83%)] Loss: -305.549988\n",
      "    epoch          : 6\n",
      "    loss           : -317.1199418553766\n",
      "    ess            : 1.9796330478956115\n",
      "    log_marginal   : 317.13532645747347\n",
      "    log_joint      : 524.7975881324625\n",
      "    val_loss       : -304.4737955729167\n",
      "    val_ess        : 1.9786793390909831\n",
      "    val_log_marginal: 304.49083709716797\n",
      "    val_log_joint  : 512.8275858561198\n",
      "Train Epoch: 7 [0/54000 (0%)] Loss: -326.976868\n",
      "Train Epoch: 7 [11264/54000 (21%)] Loss: -315.137756\n",
      "Train Epoch: 7 [22528/54000 (42%)] Loss: -332.778015\n",
      "Train Epoch: 7 [33792/54000 (63%)] Loss: -326.264343\n",
      "Train Epoch: 7 [45056/54000 (83%)] Loss: -333.419586\n",
      "    epoch          : 7\n",
      "    loss           : -322.0688830681567\n",
      "    ess            : 1.9805979616237137\n",
      "    log_marginal   : 322.08363399865493\n",
      "    log_joint      : 529.9411171967129\n",
      "    val_loss       : -338.51438903808594\n",
      "    val_ess        : 1.979865938425064\n",
      "    val_log_marginal: 338.5290807088216\n",
      "    val_log_joint  : 546.5792083740234\n",
      "Train Epoch: 8 [0/54000 (0%)] Loss: -357.281555\n",
      "Train Epoch: 8 [11264/54000 (21%)] Loss: -351.164307\n",
      "Train Epoch: 8 [22528/54000 (42%)] Loss: -352.002930\n",
      "Train Epoch: 8 [33792/54000 (63%)] Loss: -346.049561\n",
      "Train Epoch: 8 [45056/54000 (83%)] Loss: -363.605774\n",
      "    epoch          : 8\n",
      "    loss           : -347.69165413334684\n",
      "    ess            : 1.979535992415446\n",
      "    log_marginal   : 347.7073323951577\n",
      "    log_joint      : 555.1926396207989\n",
      "    val_loss       : -357.6751200358073\n",
      "    val_ess        : 1.9814529816309612\n",
      "    val_log_marginal: 357.68775685628253\n",
      "    val_log_joint  : 565.3158518473307\n",
      "Train Epoch: 9 [0/54000 (0%)] Loss: -371.297455\n",
      "Train Epoch: 9 [11264/54000 (21%)] Loss: -355.720764\n",
      "Train Epoch: 9 [22528/54000 (42%)] Loss: -342.882690\n",
      "Train Epoch: 9 [33792/54000 (63%)] Loss: -338.229370\n",
      "Train Epoch: 9 [45056/54000 (83%)] Loss: -343.256775\n",
      "    epoch          : 9\n",
      "    loss           : -354.01983930479804\n",
      "    ess            : 1.9791056468801678\n",
      "    log_marginal   : 354.03531776284274\n",
      "    log_joint      : 561.5689472702314\n",
      "    val_loss       : -350.334721883138\n",
      "    val_ess        : 1.9796883165836334\n",
      "    val_log_marginal: 350.3489049275716\n",
      "    val_log_joint  : 558.0883992513021\n",
      "Train Epoch: 10 [0/54000 (0%)] Loss: -356.773254\n",
      "Train Epoch: 10 [11264/54000 (21%)] Loss: -339.772308\n",
      "Train Epoch: 10 [22528/54000 (42%)] Loss: -333.378387\n",
      "Train Epoch: 10 [33792/54000 (63%)] Loss: -360.570068\n",
      "Train Epoch: 10 [45056/54000 (83%)] Loss: -335.319916\n",
      "    epoch          : 10\n",
      "    loss           : -345.9310593515072\n",
      "    ess            : 1.9798657635472856\n",
      "    log_marginal   : 345.9458050997752\n",
      "    log_joint      : 553.8304696712854\n",
      "    val_loss       : -357.72223409016925\n",
      "    val_ess        : 1.9807885487874348\n",
      "    val_log_marginal: 357.7352066040039\n",
      "    val_log_joint  : 565.4398905436198\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [0/54000 (0%)] Loss: -342.616180\n",
      "Train Epoch: 11 [11264/54000 (21%)] Loss: -338.073273\n",
      "Train Epoch: 11 [22528/54000 (42%)] Loss: -354.536774\n",
      "Train Epoch: 11 [33792/54000 (63%)] Loss: -339.693451\n",
      "Train Epoch: 11 [45056/54000 (83%)] Loss: -343.849304\n",
      "    epoch          : 11\n",
      "    loss           : -359.8859457339881\n",
      "    ess            : 1.9789715319309595\n",
      "    log_marginal   : 359.9019925099499\n",
      "    log_joint      : 567.637842142357\n",
      "    val_loss       : -369.9590326944987\n",
      "    val_ess        : 1.9789849718411763\n",
      "    val_log_marginal: 369.9760335286458\n",
      "    val_log_joint  : 577.5260264078776\n",
      "Train Epoch: 12 [0/54000 (0%)] Loss: -377.148010\n",
      "Train Epoch: 12 [11264/54000 (21%)] Loss: -388.705017\n",
      "Train Epoch: 12 [22528/54000 (42%)] Loss: -392.551575\n",
      "Train Epoch: 12 [33792/54000 (63%)] Loss: -366.043457\n",
      "Train Epoch: 12 [45056/54000 (83%)] Loss: -361.517456\n",
      "    epoch          : 12\n",
      "    loss           : -373.67308965718973\n",
      "    ess            : 1.979590653248553\n",
      "    log_marginal   : 373.68776199052917\n",
      "    log_joint      : 581.1376872512529\n",
      "    val_loss       : -382.0581868489583\n",
      "    val_ess        : 1.977987547715505\n",
      "    val_log_marginal: 382.07533264160156\n",
      "    val_log_joint  : 589.4760996500651\n",
      "Train Epoch: 13 [0/54000 (0%)] Loss: -386.289978\n",
      "Train Epoch: 13 [11264/54000 (21%)] Loss: -376.726868\n",
      "Train Epoch: 13 [22528/54000 (42%)] Loss: -402.033905\n",
      "Train Epoch: 13 [33792/54000 (63%)] Loss: -392.878723\n",
      "Train Epoch: 13 [45056/54000 (83%)] Loss: -357.766571\n",
      "    epoch          : 13\n",
      "    loss           : -387.5303203654739\n",
      "    ess            : 1.9790436872896158\n",
      "    log_marginal   : 387.5457740639741\n",
      "    log_joint      : 594.6678161621094\n",
      "    val_loss       : -391.28018442789715\n",
      "    val_ess        : 1.9791147112846375\n",
      "    val_log_marginal: 391.29747772216797\n",
      "    val_log_joint  : 598.3040161132812\n",
      "Train Epoch: 14 [0/54000 (0%)] Loss: -402.683167\n",
      "Train Epoch: 14 [11264/54000 (21%)] Loss: -379.249725\n",
      "Train Epoch: 14 [22528/54000 (42%)] Loss: -364.631104\n",
      "Train Epoch: 14 [33792/54000 (63%)] Loss: -351.412628\n",
      "Train Epoch: 14 [45056/54000 (83%)] Loss: -369.689484\n",
      "    epoch          : 14\n",
      "    loss           : -378.1150089479842\n",
      "    ess            : 1.9787546936071143\n",
      "    log_marginal   : 378.13108825683594\n",
      "    log_joint      : 585.7495445395416\n",
      "    val_loss       : -371.2204869588216\n",
      "    val_ess        : 1.9805112381776173\n",
      "    val_log_marginal: 371.23473103841144\n",
      "    val_log_joint  : 579.1202494303385\n",
      "Train Epoch: 15 [0/54000 (0%)] Loss: -378.057220\n",
      "Train Epoch: 15 [11264/54000 (21%)] Loss: -376.891907\n",
      "Train Epoch: 15 [22528/54000 (42%)] Loss: -383.172882\n",
      "Train Epoch: 15 [33792/54000 (63%)] Loss: -348.359833\n",
      "Train Epoch: 15 [45056/54000 (83%)] Loss: -373.660583\n",
      "    epoch          : 15\n",
      "    loss           : -379.32804006900426\n",
      "    ess            : 1.9778380393981934\n",
      "    log_marginal   : 379.34449825646743\n",
      "    log_joint      : 586.9381218676297\n",
      "    val_loss       : -391.03087361653644\n",
      "    val_ess        : 1.9794306457042694\n",
      "    val_log_marginal: 391.04577891031903\n",
      "    val_log_joint  : 598.1423034667969\n",
      "Train Epoch: 16 [0/54000 (0%)] Loss: -409.971375\n",
      "Train Epoch: 16 [11264/54000 (21%)] Loss: -402.607849\n",
      "Train Epoch: 16 [22528/54000 (42%)] Loss: -386.742188\n",
      "Train Epoch: 16 [33792/54000 (63%)] Loss: -402.837372\n",
      "Train Epoch: 16 [45056/54000 (83%)] Loss: -376.152405\n",
      "    epoch          : 16\n",
      "    loss           : -391.2366278306493\n",
      "    ess            : 1.9788433954400837\n",
      "    log_marginal   : 391.2527022451725\n",
      "    log_joint      : 598.7389203917305\n",
      "    val_loss       : -396.8263168334961\n",
      "    val_ess        : 1.978130578994751\n",
      "    val_log_marginal: 396.84361267089844\n",
      "    val_log_joint  : 604.3966573079427\n",
      "Train Epoch: 17 [0/54000 (0%)] Loss: -439.883057\n",
      "Train Epoch: 17 [11264/54000 (21%)] Loss: -412.270294\n",
      "Train Epoch: 17 [22528/54000 (42%)] Loss: -388.246704\n",
      "Train Epoch: 17 [33792/54000 (63%)] Loss: -412.835785\n",
      "Train Epoch: 17 [45056/54000 (83%)] Loss: -388.383728\n",
      "    epoch          : 17\n",
      "    loss           : -402.8384917637087\n",
      "    ess            : 1.9783430571826\n",
      "    log_marginal   : 402.85469141546287\n",
      "    log_joint      : 610.0331046626253\n",
      "    val_loss       : -405.2648010253906\n",
      "    val_ess        : 1.9811350007851918\n",
      "    val_log_marginal: 405.27820841471356\n",
      "    val_log_joint  : 612.2924397786459\n",
      "Train Epoch: 18 [0/54000 (0%)] Loss: -438.324219\n",
      "Train Epoch: 18 [11264/54000 (21%)] Loss: -403.836365\n",
      "Train Epoch: 18 [22528/54000 (42%)] Loss: -417.547363\n",
      "Train Epoch: 18 [33792/54000 (63%)] Loss: -388.701965\n",
      "Train Epoch: 18 [45056/54000 (83%)] Loss: -395.055054\n",
      "    epoch          : 18\n",
      "    loss           : -405.60607535884066\n",
      "    ess            : 1.9790212500770137\n",
      "    log_marginal   : 405.62200754993364\n",
      "    log_joint      : 612.9709092626032\n",
      "    val_loss       : -405.8578516642253\n",
      "    val_ess        : 1.977255254983902\n",
      "    val_log_marginal: 405.87537638346356\n",
      "    val_log_joint  : 613.142567952474\n",
      "Train Epoch: 19 [0/54000 (0%)] Loss: -432.106415\n",
      "Train Epoch: 19 [11264/54000 (21%)] Loss: -417.536865\n",
      "Train Epoch: 19 [22528/54000 (42%)] Loss: -404.171753\n",
      "Train Epoch: 19 [33792/54000 (63%)] Loss: -420.100311\n",
      "Train Epoch: 19 [45056/54000 (83%)] Loss: -375.053650\n",
      "    epoch          : 19\n",
      "    loss           : -403.1052084868809\n",
      "    ess            : 1.978843849784923\n",
      "    log_marginal   : 403.12184632499265\n",
      "    log_joint      : 610.6211979704083\n",
      "    val_loss       : -405.2926737467448\n",
      "    val_ess        : 1.9787809252738953\n",
      "    val_log_marginal: 405.3081461588542\n",
      "    val_log_joint  : 612.9144236246744\n",
      "Train Epoch: 20 [0/54000 (0%)] Loss: -435.407867\n",
      "Train Epoch: 20 [11264/54000 (21%)] Loss: -409.637573\n",
      "Train Epoch: 20 [22528/54000 (42%)] Loss: -409.897583\n",
      "Train Epoch: 20 [33792/54000 (63%)] Loss: -432.562622\n",
      "Train Epoch: 20 [45056/54000 (83%)] Loss: -435.383759\n",
      "    epoch          : 20\n",
      "    loss           : -409.1960996231943\n",
      "    ess            : 1.9786084103134443\n",
      "    log_marginal   : 409.2122437099241\n",
      "    log_joint      : 616.6553523225605\n",
      "    val_loss       : -413.92600504557294\n",
      "    val_ess        : 1.9796226819356282\n",
      "    val_log_marginal: 413.94071197509766\n",
      "    val_log_joint  : 621.3914591471354\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [0/54000 (0%)] Loss: -438.198608\n",
      "Train Epoch: 21 [11264/54000 (21%)] Loss: -416.566681\n",
      "Train Epoch: 21 [22528/54000 (42%)] Loss: -420.378113\n",
      "Train Epoch: 21 [33792/54000 (63%)] Loss: -420.963470\n",
      "Train Epoch: 21 [45056/54000 (83%)] Loss: -439.101654\n",
      "    epoch          : 21\n",
      "    loss           : -420.13448866358345\n",
      "    ess            : 1.9781719974751741\n",
      "    log_marginal   : 420.1509169092718\n",
      "    log_joint      : 627.2526815162515\n",
      "    val_loss       : -425.3412373860677\n",
      "    val_ess        : 1.979593276977539\n",
      "    val_log_marginal: 425.358642578125\n",
      "    val_log_joint  : 632.242665608724\n",
      "Train Epoch: 22 [0/54000 (0%)] Loss: -417.089294\n",
      "Train Epoch: 22 [11264/54000 (21%)] Loss: -430.234375\n",
      "Train Epoch: 22 [22528/54000 (42%)] Loss: -422.403870\n",
      "Train Epoch: 22 [33792/54000 (63%)] Loss: -411.174988\n",
      "Train Epoch: 22 [45056/54000 (83%)] Loss: -429.617493\n",
      "    epoch          : 22\n",
      "    loss           : -422.2178186380638\n",
      "    ess            : 1.9781015369127382\n",
      "    log_marginal   : 422.23422126050264\n",
      "    log_joint      : 629.6269485185732\n",
      "    val_loss       : -425.68267822265625\n",
      "    val_ess        : 1.9796346127986908\n",
      "    val_log_marginal: 425.69754791259766\n",
      "    val_log_joint  : 633.1287333170573\n",
      "Train Epoch: 23 [0/54000 (0%)] Loss: -414.147400\n",
      "Train Epoch: 23 [11264/54000 (21%)] Loss: -418.970947\n",
      "Train Epoch: 23 [22528/54000 (42%)] Loss: -383.444763\n",
      "Train Epoch: 23 [33792/54000 (63%)] Loss: -436.161316\n",
      "Train Epoch: 23 [45056/54000 (83%)] Loss: -443.164124\n",
      "    epoch          : 23\n",
      "    loss           : -427.90948457537957\n",
      "    ess            : 1.9788079610410727\n",
      "    log_marginal   : 427.92535400390625\n",
      "    log_joint      : 634.9810174906029\n",
      "    val_loss       : -430.8895899454753\n",
      "    val_ess        : 1.9761713941891987\n",
      "    val_log_marginal: 430.90699513753253\n",
      "    val_log_joint  : 637.8646341959635\n",
      "Train Epoch: 24 [0/54000 (0%)] Loss: -420.189087\n",
      "Train Epoch: 24 [11264/54000 (21%)] Loss: -428.141296\n",
      "Train Epoch: 24 [22528/54000 (42%)] Loss: -402.069519\n",
      "Train Epoch: 24 [33792/54000 (63%)] Loss: -398.028320\n",
      "Train Epoch: 24 [45056/54000 (83%)] Loss: -421.306213\n",
      "    epoch          : 24\n",
      "    loss           : -423.1188360250221\n",
      "    ess            : 1.9771835860216393\n",
      "    log_marginal   : 423.13596185648214\n",
      "    log_joint      : 630.5787837190448\n",
      "    val_loss       : -416.8241831461589\n",
      "    val_ess        : 1.9800445040067036\n",
      "    val_log_marginal: 416.8377405802409\n",
      "    val_log_joint  : 624.3658243815104\n",
      "Train Epoch: 25 [0/54000 (0%)] Loss: -417.342163\n",
      "Train Epoch: 25 [11264/54000 (21%)] Loss: -423.077789\n",
      "Train Epoch: 25 [22528/54000 (42%)] Loss: -422.770233\n",
      "Train Epoch: 25 [33792/54000 (63%)] Loss: -429.754242\n",
      "Train Epoch: 25 [45056/54000 (83%)] Loss: -440.080078\n",
      "    epoch          : 25\n",
      "    loss           : -418.99880635963297\n",
      "    ess            : 1.978035960557326\n",
      "    log_marginal   : 419.0153019743146\n",
      "    log_joint      : 626.8198196123232\n",
      "    val_loss       : -423.8253580729167\n",
      "    val_ess        : 1.981112043062846\n",
      "    val_log_marginal: 423.84046173095703\n",
      "    val_log_joint  : 631.5766092936198\n",
      "Train Epoch: 26 [0/54000 (0%)] Loss: -428.291138\n",
      "Train Epoch: 26 [11264/54000 (21%)] Loss: -415.107544\n",
      "Train Epoch: 26 [22528/54000 (42%)] Loss: -402.775452\n",
      "Train Epoch: 26 [33792/54000 (63%)] Loss: -439.971832\n",
      "Train Epoch: 26 [45056/54000 (83%)] Loss: -422.204407\n",
      "    epoch          : 26\n",
      "    loss           : -425.4157616957179\n",
      "    ess            : 1.9791566493376247\n",
      "    log_marginal   : 425.4313532991229\n",
      "    log_joint      : 632.9880411399985\n",
      "    val_loss       : -432.2944564819336\n",
      "    val_ess        : 1.979158639907837\n",
      "    val_log_marginal: 432.3081283569336\n",
      "    val_log_joint  : 639.6064249674479\n",
      "Train Epoch: 27 [0/54000 (0%)] Loss: -431.235596\n",
      "Train Epoch: 27 [11264/54000 (21%)] Loss: -443.585327\n",
      "Train Epoch: 27 [22528/54000 (42%)] Loss: -439.238098\n",
      "Train Epoch: 27 [33792/54000 (63%)] Loss: -471.064575\n",
      "Train Epoch: 27 [45056/54000 (83%)] Loss: -450.912537\n",
      "    epoch          : 27\n",
      "    loss           : -437.082888909106\n",
      "    ess            : 1.9770779778372567\n",
      "    log_marginal   : 437.1005335393942\n",
      "    log_joint      : 644.4366167176445\n",
      "    val_loss       : -441.0771306355794\n",
      "    val_ess        : 1.974973052740097\n",
      "    val_log_marginal: 441.09754435221356\n",
      "    val_log_joint  : 648.0918172200521\n",
      "Train Epoch: 28 [0/54000 (0%)] Loss: -444.920868\n",
      "Train Epoch: 28 [11264/54000 (21%)] Loss: -444.372498\n",
      "Train Epoch: 28 [22528/54000 (42%)] Loss: -414.517303\n",
      "Train Epoch: 28 [33792/54000 (63%)] Loss: -413.525604\n",
      "Train Epoch: 28 [45056/54000 (83%)] Loss: -418.532776\n",
      "    epoch          : 28\n",
      "    loss           : -439.82692272258254\n",
      "    ess            : 1.976847840929931\n",
      "    log_marginal   : 439.84441303757\n",
      "    log_joint      : 647.1327169166422\n",
      "    val_loss       : -442.2603073120117\n",
      "    val_ess        : 1.9796492258707683\n",
      "    val_log_marginal: 442.2751642862956\n",
      "    val_log_joint  : 649.6400502522787\n",
      "Train Epoch: 29 [0/54000 (0%)] Loss: -454.112793\n",
      "Train Epoch: 29 [11264/54000 (21%)] Loss: -450.633240\n",
      "Train Epoch: 29 [22528/54000 (42%)] Loss: -439.706055\n",
      "Train Epoch: 29 [33792/54000 (63%)] Loss: -428.824951\n",
      "Train Epoch: 29 [45056/54000 (83%)] Loss: -443.571594\n",
      "    epoch          : 29\n",
      "    loss           : -443.71844943064565\n",
      "    ess            : 1.9781645120314832\n",
      "    log_marginal   : 443.73471558768796\n",
      "    log_joint      : 650.9139461877211\n",
      "    val_loss       : -447.66995493570965\n",
      "    val_ess        : 1.9775222142537434\n",
      "    val_log_marginal: 447.6875584920247\n",
      "    val_log_joint  : 654.8382008870443\n",
      "Train Epoch: 30 [0/54000 (0%)] Loss: -449.455841\n",
      "Train Epoch: 30 [11264/54000 (21%)] Loss: -428.241089\n",
      "Train Epoch: 30 [22528/54000 (42%)] Loss: -446.884583\n",
      "Train Epoch: 30 [33792/54000 (63%)] Loss: -425.230011\n",
      "Train Epoch: 30 [45056/54000 (83%)] Loss: -420.360718\n",
      "    epoch          : 30\n",
      "    loss           : -441.0376756776054\n",
      "    ess            : 1.9765915634497158\n",
      "    log_marginal   : 441.05551464152785\n",
      "    log_joint      : 648.5615372567806\n",
      "    val_loss       : -441.5488560994466\n",
      "    val_ess        : 1.9780127306779225\n",
      "    val_log_marginal: 441.56751505533856\n",
      "    val_log_joint  : 649.3374328613281\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch30.pth ...\n",
      "Train Epoch: 31 [0/54000 (0%)] Loss: -457.188812\n",
      "Train Epoch: 31 [11264/54000 (21%)] Loss: -444.170959\n",
      "Train Epoch: 31 [22528/54000 (42%)] Loss: -456.168091\n",
      "Train Epoch: 31 [33792/54000 (63%)] Loss: -446.620300\n",
      "Train Epoch: 31 [45056/54000 (83%)] Loss: -429.765320\n",
      "    epoch          : 31\n",
      "    loss           : -441.88745203558005\n",
      "    ess            : 1.9776365577049975\n",
      "    log_marginal   : 441.9044978303729\n",
      "    log_joint      : 649.4798376695165\n",
      "    val_loss       : -448.44549051920575\n",
      "    val_ess        : 1.978284329175949\n",
      "    val_log_marginal: 448.46180216471356\n",
      "    val_log_joint  : 655.4755045572916\n",
      "Train Epoch: 32 [0/54000 (0%)] Loss: -472.289124\n",
      "Train Epoch: 32 [11264/54000 (21%)] Loss: -432.262878\n",
      "Train Epoch: 32 [22528/54000 (42%)] Loss: -447.745178\n",
      "Train Epoch: 32 [33792/54000 (63%)] Loss: -437.719574\n",
      "Train Epoch: 32 [45056/54000 (83%)] Loss: -449.579803\n",
      "    epoch          : 32\n",
      "    loss           : -441.8126203429024\n",
      "    ess            : 1.977486662144931\n",
      "    log_marginal   : 441.83011756753024\n",
      "    log_joint      : 649.3694521346182\n",
      "    val_loss       : -449.71492258707684\n",
      "    val_ess        : 1.977284441391627\n",
      "    val_log_marginal: 449.73029073079425\n",
      "    val_log_joint  : 656.9112904866537\n",
      "Train Epoch: 33 [0/54000 (0%)] Loss: -466.487915\n",
      "Train Epoch: 33 [11264/54000 (21%)] Loss: -443.357727\n",
      "Train Epoch: 33 [22528/54000 (42%)] Loss: -440.205811\n",
      "Train Epoch: 33 [33792/54000 (63%)] Loss: -440.379150\n",
      "Train Epoch: 33 [45056/54000 (83%)] Loss: -473.337830\n",
      "    epoch          : 33\n",
      "    loss           : -453.1554789992998\n",
      "    ess            : 1.9765475549787845\n",
      "    log_marginal   : 453.17326671672316\n",
      "    log_joint      : 660.3901102317953\n",
      "    val_loss       : -457.2648696899414\n",
      "    val_ess        : 1.9762764871120453\n",
      "    val_log_marginal: 457.2837168375651\n",
      "    val_log_joint  : 664.4603678385416\n",
      "Train Epoch: 34 [0/54000 (0%)] Loss: -450.250793\n",
      "Train Epoch: 34 [11264/54000 (21%)] Loss: -449.089294\n",
      "Train Epoch: 34 [22528/54000 (42%)] Loss: -451.900909\n",
      "Train Epoch: 34 [33792/54000 (63%)] Loss: -451.685303\n",
      "Train Epoch: 34 [45056/54000 (83%)] Loss: -437.329834\n",
      "    epoch          : 34\n",
      "    loss           : -451.9613592759618\n",
      "    ess            : 1.9775058233513023\n",
      "    log_marginal   : 451.97858702461673\n",
      "    log_joint      : 659.404660782724\n",
      "    val_loss       : -445.6587905883789\n",
      "    val_ess        : 1.9772352476914723\n",
      "    val_log_marginal: 445.6766840616862\n",
      "    val_log_joint  : 653.2382303873698\n",
      "Train Epoch: 35 [0/54000 (0%)] Loss: -438.327332\n",
      "Train Epoch: 35 [11264/54000 (21%)] Loss: -436.545807\n",
      "Train Epoch: 35 [22528/54000 (42%)] Loss: -434.071106\n",
      "Train Epoch: 35 [33792/54000 (63%)] Loss: -439.630127\n",
      "Train Epoch: 35 [45056/54000 (83%)] Loss: -427.758606\n",
      "    epoch          : 35\n",
      "    loss           : -435.81260191719485\n",
      "    ess            : 1.9783034302153677\n",
      "    log_marginal   : 435.82873333625076\n",
      "    log_joint      : 643.6607452968382\n",
      "    val_loss       : -447.5353266398112\n",
      "    val_ess        : 1.9785174826780956\n",
      "    val_log_marginal: 447.55171966552734\n",
      "    val_log_joint  : 654.7834065755209\n",
      "Train Epoch: 36 [0/54000 (0%)] Loss: -459.081787\n",
      "Train Epoch: 36 [11264/54000 (21%)] Loss: -460.821136\n",
      "Train Epoch: 36 [22528/54000 (42%)] Loss: -445.079834\n",
      "Train Epoch: 36 [33792/54000 (63%)] Loss: -441.786224\n",
      "Train Epoch: 36 [45056/54000 (83%)] Loss: -467.250153\n",
      "    epoch          : 36\n",
      "    loss           : -450.3958196100199\n",
      "    ess            : 1.9776350338503998\n",
      "    log_marginal   : 450.4125035124005\n",
      "    log_joint      : 657.8163578825177\n",
      "    val_loss       : -457.2714080810547\n",
      "    val_ess        : 1.977442592382431\n",
      "    val_log_marginal: 457.28613026936847\n",
      "    val_log_joint  : 664.3917694091797\n",
      "Train Epoch: 37 [0/54000 (0%)] Loss: -443.999664\n",
      "Train Epoch: 37 [11264/54000 (21%)] Loss: -447.973083\n",
      "Train Epoch: 37 [22528/54000 (42%)] Loss: -439.169373\n",
      "Train Epoch: 37 [33792/54000 (63%)] Loss: -446.338196\n",
      "Train Epoch: 37 [45056/54000 (83%)] Loss: -459.809021\n",
      "    epoch          : 37\n",
      "    loss           : -458.9595524050155\n",
      "    ess            : 1.9775019063139863\n",
      "    log_marginal   : 458.976834567088\n",
      "    log_joint      : 666.1363611761129\n",
      "    val_loss       : -461.47457122802734\n",
      "    val_ess        : 1.9756790101528168\n",
      "    val_log_marginal: 461.49320220947266\n",
      "    val_log_joint  : 668.9355316162109\n",
      "Train Epoch: 38 [0/54000 (0%)] Loss: -444.935272\n",
      "Train Epoch: 38 [11264/54000 (21%)] Loss: -448.237427\n",
      "Train Epoch: 38 [22528/54000 (42%)] Loss: -445.884277\n",
      "Train Epoch: 38 [33792/54000 (63%)] Loss: -462.455444\n",
      "Train Epoch: 38 [45056/54000 (83%)] Loss: -467.927795\n",
      "    epoch          : 38\n",
      "    loss           : -462.1216367325693\n",
      "    ess            : 1.9773135533872641\n",
      "    log_marginal   : 462.13885238935364\n",
      "    log_joint      : 669.2509995946344\n",
      "    val_loss       : -465.1353251139323\n",
      "    val_ess        : 1.9784464240074158\n",
      "    val_log_marginal: 465.1522267659505\n",
      "    val_log_joint  : 672.3748982747396\n",
      "Train Epoch: 39 [0/54000 (0%)] Loss: -479.417358\n",
      "Train Epoch: 39 [11264/54000 (21%)] Loss: -452.611694\n",
      "Train Epoch: 39 [22528/54000 (42%)] Loss: -464.733765\n",
      "Train Epoch: 39 [33792/54000 (63%)] Loss: -451.096466\n",
      "Train Epoch: 39 [45056/54000 (83%)] Loss: -477.019958\n",
      "    epoch          : 39\n",
      "    loss           : -462.46359310510024\n",
      "    ess            : 1.9765183689459316\n",
      "    log_marginal   : 462.4819629597214\n",
      "    log_joint      : 669.689022424086\n",
      "    val_loss       : -463.1630147298177\n",
      "    val_ess        : 1.9780901074409485\n",
      "    val_log_marginal: 463.1801122029622\n",
      "    val_log_joint  : 670.4289042154948\n",
      "Train Epoch: 40 [0/54000 (0%)] Loss: -471.718353\n",
      "Train Epoch: 40 [11264/54000 (21%)] Loss: -460.114197\n",
      "Train Epoch: 40 [22528/54000 (42%)] Loss: -457.842560\n",
      "Train Epoch: 40 [33792/54000 (63%)] Loss: -460.288086\n",
      "Train Epoch: 40 [45056/54000 (83%)] Loss: -481.512787\n",
      "    epoch          : 40\n",
      "    loss           : -464.74732971191406\n",
      "    ess            : 1.9774437344299172\n",
      "    log_marginal   : 464.76453010990934\n",
      "    log_joint      : 671.94168378722\n",
      "    val_loss       : -467.44958750406903\n",
      "    val_ess        : 1.9757898549238841\n",
      "    val_log_marginal: 467.46760813395184\n",
      "    val_log_joint  : 674.9616394042969\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [0/54000 (0%)] Loss: -450.104004\n",
      "Train Epoch: 41 [11264/54000 (21%)] Loss: -463.922882\n",
      "Train Epoch: 41 [22528/54000 (42%)] Loss: -458.509369\n",
      "Train Epoch: 41 [33792/54000 (63%)] Loss: -465.022675\n",
      "Train Epoch: 41 [45056/54000 (83%)] Loss: -463.956879\n",
      "    epoch          : 41\n",
      "    loss           : -464.1744413555793\n",
      "    ess            : 1.9772463789526022\n",
      "    log_marginal   : 464.19173791273585\n",
      "    log_joint      : 671.527476184773\n",
      "    val_loss       : -467.08575948079425\n",
      "    val_ess        : 1.9765355388323467\n",
      "    val_log_marginal: 467.10274505615234\n",
      "    val_log_joint  : 674.3536834716797\n",
      "Train Epoch: 42 [0/54000 (0%)] Loss: -479.447296\n",
      "Train Epoch: 42 [11264/54000 (21%)] Loss: -454.484070\n",
      "Train Epoch: 42 [22528/54000 (42%)] Loss: -480.189362\n",
      "Train Epoch: 42 [33792/54000 (63%)] Loss: -459.497253\n",
      "Train Epoch: 42 [45056/54000 (83%)] Loss: -471.945892\n",
      "    epoch          : 42\n",
      "    loss           : -469.26202651689636\n",
      "    ess            : 1.9775375858792719\n",
      "    log_marginal   : 469.27925225023955\n",
      "    log_joint      : 676.2980214244915\n",
      "    val_loss       : -472.67115529378253\n",
      "    val_ess        : 1.9766481320063274\n",
      "    val_log_marginal: 472.69012451171875\n",
      "    val_log_joint  : 680.0758972167969\n",
      "Train Epoch: 43 [0/54000 (0%)] Loss: -454.029388\n",
      "Train Epoch: 43 [11264/54000 (21%)] Loss: -464.271729\n",
      "Train Epoch: 43 [22528/54000 (42%)] Loss: -461.618164\n",
      "Train Epoch: 43 [33792/54000 (63%)] Loss: -461.084076\n",
      "Train Epoch: 43 [45056/54000 (83%)] Loss: -482.291687\n",
      "    epoch          : 43\n",
      "    loss           : -465.5116182723135\n",
      "    ess            : 1.977295751841563\n",
      "    log_marginal   : 465.5288782659567\n",
      "    log_joint      : 672.8323738529997\n",
      "    val_loss       : -465.46812947591144\n",
      "    val_ess        : 1.9771700501441956\n",
      "    val_log_marginal: 465.4853286743164\n",
      "    val_log_joint  : 672.8722330729166\n",
      "Train Epoch: 44 [0/54000 (0%)] Loss: -477.549316\n",
      "Train Epoch: 44 [11264/54000 (21%)] Loss: -467.787048\n",
      "Train Epoch: 44 [22528/54000 (42%)] Loss: -476.018127\n",
      "Train Epoch: 44 [33792/54000 (63%)] Loss: -464.467163\n",
      "Train Epoch: 44 [45056/54000 (83%)] Loss: -456.290405\n",
      "    epoch          : 44\n",
      "    loss           : -466.46799310648214\n",
      "    ess            : 1.9775610026323571\n",
      "    log_marginal   : 466.48488890449954\n",
      "    log_joint      : 673.712814043153\n",
      "    val_loss       : -464.7016906738281\n",
      "    val_ess        : 1.9757257103919983\n",
      "    val_log_marginal: 464.72052001953125\n",
      "    val_log_joint  : 672.1553599039713\n",
      "Train Epoch: 45 [0/54000 (0%)] Loss: -455.349121\n",
      "Train Epoch: 45 [11264/54000 (21%)] Loss: -469.691406\n",
      "Train Epoch: 45 [22528/54000 (42%)] Loss: -474.063477\n",
      "Train Epoch: 45 [33792/54000 (63%)] Loss: -474.673187\n",
      "Train Epoch: 45 [45056/54000 (83%)] Loss: -444.962372\n",
      "    epoch          : 45\n",
      "    loss           : -464.2998648589512\n",
      "    ess            : 1.9767111978440914\n",
      "    log_marginal   : 464.3180985360775\n",
      "    log_joint      : 671.9478892200398\n",
      "    val_loss       : -469.84671274820965\n",
      "    val_ess        : 1.974050650993983\n",
      "    val_log_marginal: 469.8670476277669\n",
      "    val_log_joint  : 677.2266591389974\n",
      "Train Epoch: 46 [0/54000 (0%)] Loss: -471.230042\n",
      "Train Epoch: 46 [11264/54000 (21%)] Loss: -473.863678\n",
      "Train Epoch: 46 [22528/54000 (42%)] Loss: -437.671814\n",
      "Train Epoch: 46 [33792/54000 (63%)] Loss: -459.594055\n",
      "Train Epoch: 46 [45056/54000 (83%)] Loss: -486.128540\n",
      "    epoch          : 46\n",
      "    loss           : -464.09875862553434\n",
      "    ess            : 1.9765412931172353\n",
      "    log_marginal   : 464.1171636041605\n",
      "    log_joint      : 671.6913475180572\n",
      "    val_loss       : -472.38858286539715\n",
      "    val_ess        : 1.976132333278656\n",
      "    val_log_marginal: 472.4066467285156\n",
      "    val_log_joint  : 679.7088267008463\n",
      "Train Epoch: 47 [0/54000 (0%)] Loss: -488.195923\n",
      "Train Epoch: 47 [11264/54000 (21%)] Loss: -483.575073\n",
      "Train Epoch: 47 [22528/54000 (42%)] Loss: -467.805359\n",
      "Train Epoch: 47 [33792/54000 (63%)] Loss: -482.098022\n",
      "Train Epoch: 47 [45056/54000 (83%)] Loss: -482.009949\n",
      "    epoch          : 47\n",
      "    loss           : -475.2910565070386\n",
      "    ess            : 1.9762521521100458\n",
      "    log_marginal   : 475.30958326807564\n",
      "    log_joint      : 682.539118352926\n",
      "    val_loss       : -480.6331253051758\n",
      "    val_ess        : 1.9780576924482982\n",
      "    val_log_marginal: 480.6486409505208\n",
      "    val_log_joint  : 687.9738057454427\n",
      "Train Epoch: 48 [0/54000 (0%)] Loss: -471.623840\n",
      "Train Epoch: 48 [11264/54000 (21%)] Loss: -487.187164\n",
      "Train Epoch: 48 [22528/54000 (42%)] Loss: -473.741028\n",
      "Train Epoch: 48 [33792/54000 (63%)] Loss: -480.978882\n",
      "Train Epoch: 48 [45056/54000 (83%)] Loss: -458.180542\n",
      "    epoch          : 48\n",
      "    loss           : -477.2809528854658\n",
      "    ess            : 1.9766796231269836\n",
      "    log_marginal   : 477.2986720822892\n",
      "    log_joint      : 684.4283113299675\n",
      "    val_loss       : -479.0753428141276\n",
      "    val_ess        : 1.977263589700063\n",
      "    val_log_marginal: 479.09176381429035\n",
      "    val_log_joint  : 686.3593292236328\n",
      "Train Epoch: 49 [0/54000 (0%)] Loss: -488.152161\n",
      "Train Epoch: 49 [11264/54000 (21%)] Loss: -447.497406\n",
      "Train Epoch: 49 [22528/54000 (42%)] Loss: -463.224792\n",
      "Train Epoch: 49 [33792/54000 (63%)] Loss: -470.020325\n",
      "Train Epoch: 49 [45056/54000 (83%)] Loss: -483.855835\n",
      "    epoch          : 49\n",
      "    loss           : -479.45748066452313\n",
      "    ess            : 1.9763515827790745\n",
      "    log_marginal   : 479.4754762469598\n",
      "    log_joint      : 686.6979024635172\n",
      "    val_loss       : -482.9551467895508\n",
      "    val_ess        : 1.9724406500657399\n",
      "    val_log_marginal: 482.97681427001953\n",
      "    val_log_joint  : 690.0292053222656\n",
      "Train Epoch: 50 [0/54000 (0%)] Loss: -488.262451\n",
      "Train Epoch: 50 [11264/54000 (21%)] Loss: -475.007202\n",
      "Train Epoch: 50 [22528/54000 (42%)] Loss: -476.070801\n",
      "Train Epoch: 50 [33792/54000 (63%)] Loss: -469.504150\n",
      "Train Epoch: 50 [45056/54000 (83%)] Loss: -500.544769\n",
      "    epoch          : 50\n",
      "    loss           : -479.73357664864017\n",
      "    ess            : 1.9759722925582022\n",
      "    log_marginal   : 479.7521540803729\n",
      "    log_joint      : 686.9571026496168\n",
      "    val_loss       : -482.2310969034831\n",
      "    val_ess        : 1.9756707747777302\n",
      "    val_log_marginal: 482.25036366780597\n",
      "    val_log_joint  : 689.4751230875651\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch50.pth ...\n",
      "Train Epoch: 51 [0/54000 (0%)] Loss: -486.145020\n",
      "Train Epoch: 51 [11264/54000 (21%)] Loss: -469.784149\n",
      "Train Epoch: 51 [22528/54000 (42%)] Loss: -472.807526\n",
      "Train Epoch: 51 [33792/54000 (63%)] Loss: -472.598297\n",
      "Train Epoch: 51 [45056/54000 (83%)] Loss: -467.706451\n",
      "    epoch          : 51\n",
      "    loss           : -473.0534610388414\n",
      "    ess            : 1.976130096417553\n",
      "    log_marginal   : 473.07213520553876\n",
      "    log_joint      : 680.7343220260908\n",
      "    val_loss       : -478.59510548909503\n",
      "    val_ess        : 1.975621332724889\n",
      "    val_log_marginal: 478.6137161254883\n",
      "    val_log_joint  : 686.2483062744141\n",
      "Train Epoch: 52 [0/54000 (0%)] Loss: -483.967957\n",
      "Train Epoch: 52 [11264/54000 (21%)] Loss: -474.637329\n",
      "Train Epoch: 52 [22528/54000 (42%)] Loss: -489.792725\n",
      "Train Epoch: 52 [33792/54000 (63%)] Loss: -478.070557\n",
      "Train Epoch: 52 [45056/54000 (83%)] Loss: -486.200806\n",
      "    epoch          : 52\n",
      "    loss           : -472.71314282687206\n",
      "    ess            : 1.9766526076028932\n",
      "    log_marginal   : 472.7309745932525\n",
      "    log_joint      : 680.4357581948334\n",
      "    val_loss       : -481.7865626017253\n",
      "    val_ess        : 1.9757007559140523\n",
      "    val_log_marginal: 481.8044204711914\n",
      "    val_log_joint  : 689.1087290445963\n",
      "Train Epoch: 53 [0/54000 (0%)] Loss: -489.293915\n",
      "Train Epoch: 53 [11264/54000 (21%)] Loss: -500.420624\n",
      "Train Epoch: 53 [22528/54000 (42%)] Loss: -499.069366\n",
      "Train Epoch: 53 [33792/54000 (63%)] Loss: -467.150055\n",
      "Train Epoch: 53 [45056/54000 (83%)] Loss: -486.324280\n",
      "    epoch          : 53\n",
      "    loss           : -484.55910189646596\n",
      "    ess            : 1.9763021401639254\n",
      "    log_marginal   : 484.57715045281174\n",
      "    log_joint      : 691.762842142357\n",
      "    val_loss       : -490.1062825520833\n",
      "    val_ess        : 1.9762789905071259\n",
      "    val_log_marginal: 490.12477620442706\n",
      "    val_log_joint  : 697.095947265625\n",
      "Train Epoch: 54 [0/54000 (0%)] Loss: -490.356873\n",
      "Train Epoch: 54 [11264/54000 (21%)] Loss: -478.792847\n",
      "Train Epoch: 54 [22528/54000 (42%)] Loss: -497.772644\n",
      "Train Epoch: 54 [33792/54000 (63%)] Loss: -473.529480\n",
      "Train Epoch: 54 [45056/54000 (83%)] Loss: -489.199127\n",
      "    epoch          : 54\n",
      "    loss           : -484.4538004173423\n",
      "    ess            : 1.9766463772305902\n",
      "    log_marginal   : 484.4718178803066\n",
      "    log_joint      : 691.7760170990566\n",
      "    val_loss       : -482.9112014770508\n",
      "    val_ess        : 1.9746495982011159\n",
      "    val_log_marginal: 482.93238830566406\n",
      "    val_log_joint  : 690.6994832356771\n",
      "Train Epoch: 55 [0/54000 (0%)] Loss: -487.259003\n",
      "Train Epoch: 55 [11264/54000 (21%)] Loss: -477.224701\n",
      "Train Epoch: 55 [22528/54000 (42%)] Loss: -462.328552\n",
      "Train Epoch: 55 [33792/54000 (63%)] Loss: -478.549072\n",
      "Train Epoch: 55 [45056/54000 (83%)] Loss: -463.738983\n",
      "    epoch          : 55\n",
      "    loss           : -474.0044590212264\n",
      "    ess            : 1.9763792393342503\n",
      "    log_marginal   : 474.0221782180498\n",
      "    log_joint      : 681.500390970482\n",
      "    val_loss       : -476.8231684366862\n",
      "    val_ess        : 1.9753799438476562\n",
      "    val_log_marginal: 476.84166463216144\n",
      "    val_log_joint  : 684.6630249023438\n",
      "Train Epoch: 56 [0/54000 (0%)] Loss: -476.544128\n",
      "Train Epoch: 56 [11264/54000 (21%)] Loss: -482.532623\n",
      "Train Epoch: 56 [22528/54000 (42%)] Loss: -476.558228\n",
      "Train Epoch: 56 [33792/54000 (63%)] Loss: -469.928497\n",
      "Train Epoch: 56 [45056/54000 (83%)] Loss: -482.451660\n",
      "    epoch          : 56\n",
      "    loss           : -480.9828096785635\n",
      "    ess            : 1.9749443621005651\n",
      "    log_marginal   : 481.0022205856611\n",
      "    log_joint      : 688.3880684330778\n",
      "    val_loss       : -485.686030069987\n",
      "    val_ess        : 1.9771180947621663\n",
      "    val_log_marginal: 485.70336659749347\n",
      "    val_log_joint  : 693.2118886311849\n",
      "Train Epoch: 57 [0/54000 (0%)] Loss: -474.592224\n",
      "Train Epoch: 57 [11264/54000 (21%)] Loss: -489.912567\n",
      "Train Epoch: 57 [22528/54000 (42%)] Loss: -496.693848\n",
      "Train Epoch: 57 [33792/54000 (63%)] Loss: -476.881866\n",
      "Train Epoch: 57 [45056/54000 (83%)] Loss: -508.986389\n",
      "    epoch          : 57\n",
      "    loss           : -488.1561777366782\n",
      "    ess            : 1.9764811857691351\n",
      "    log_marginal   : 488.17407341723174\n",
      "    log_joint      : 695.3565086508697\n",
      "    val_loss       : -491.99386342366535\n",
      "    val_ess        : 1.974007745583852\n",
      "    val_log_marginal: 492.0156936645508\n",
      "    val_log_joint  : 699.2861531575521\n",
      "Train Epoch: 58 [0/54000 (0%)] Loss: -503.496399\n",
      "Train Epoch: 58 [11264/54000 (21%)] Loss: -494.551361\n",
      "Train Epoch: 58 [22528/54000 (42%)] Loss: -501.265869\n",
      "Train Epoch: 58 [33792/54000 (63%)] Loss: -498.714752\n",
      "Train Epoch: 58 [45056/54000 (83%)] Loss: -489.837952\n",
      "    epoch          : 58\n",
      "    loss           : -491.1573336619251\n",
      "    ess            : 1.974757043820507\n",
      "    log_marginal   : 491.17610974581737\n",
      "    log_joint      : 698.264006992556\n",
      "    val_loss       : -495.05443572998047\n",
      "    val_ess        : 1.9762894809246063\n",
      "    val_log_marginal: 495.07228597005206\n",
      "    val_log_joint  : 702.1897125244141\n",
      "Train Epoch: 59 [0/54000 (0%)] Loss: -507.746399\n",
      "Train Epoch: 59 [11264/54000 (21%)] Loss: -493.220459\n",
      "Train Epoch: 59 [22528/54000 (42%)] Loss: -482.459137\n",
      "Train Epoch: 59 [33792/54000 (63%)] Loss: -501.968750\n",
      "Train Epoch: 59 [45056/54000 (83%)] Loss: -498.588531\n",
      "    epoch          : 59\n",
      "    loss           : -489.59667421736805\n",
      "    ess            : 1.9751149326000574\n",
      "    log_marginal   : 489.6162538348504\n",
      "    log_joint      : 696.844035598467\n",
      "    val_loss       : -492.1866811116536\n",
      "    val_ess        : 1.9754811426003773\n",
      "    val_log_marginal: 492.2061004638672\n",
      "    val_log_joint  : 699.5797119140625\n",
      "Train Epoch: 60 [0/54000 (0%)] Loss: -494.912598\n",
      "Train Epoch: 60 [11264/54000 (21%)] Loss: -496.692627\n",
      "Train Epoch: 60 [22528/54000 (42%)] Loss: -489.656494\n",
      "Train Epoch: 60 [33792/54000 (63%)] Loss: -499.899048\n",
      "Train Epoch: 60 [45056/54000 (83%)] Loss: -509.297913\n",
      "    epoch          : 60\n",
      "    loss           : -492.5672610300892\n",
      "    ess            : 1.9752967447604772\n",
      "    log_marginal   : 492.586551018481\n",
      "    log_joint      : 699.7516807700104\n",
      "    val_loss       : -495.74515533447266\n",
      "    val_ess        : 1.9752324322859447\n",
      "    val_log_marginal: 495.7672983805339\n",
      "    val_log_joint  : 702.9646453857422\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch60.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 61 [0/54000 (0%)] Loss: -498.896179\n",
      "Train Epoch: 61 [11264/54000 (21%)] Loss: -478.257416\n",
      "Train Epoch: 61 [22528/54000 (42%)] Loss: -488.168213\n",
      "Train Epoch: 61 [33792/54000 (63%)] Loss: -523.353760\n",
      "Train Epoch: 61 [45056/54000 (83%)] Loss: -509.403015\n",
      "    epoch          : 61\n",
      "    loss           : -493.10626249493293\n",
      "    ess            : 1.9745231731882635\n",
      "    log_marginal   : 493.1261300140957\n",
      "    log_joint      : 700.357016509434\n",
      "    val_loss       : -495.2804412841797\n",
      "    val_ess        : 1.9760165214538574\n",
      "    val_log_marginal: 495.3000030517578\n",
      "    val_log_joint  : 702.7564544677734\n",
      "Train Epoch: 62 [0/54000 (0%)] Loss: -507.763306\n",
      "Train Epoch: 62 [11264/54000 (21%)] Loss: -509.926971\n",
      "Train Epoch: 62 [22528/54000 (42%)] Loss: -479.741394\n",
      "Train Epoch: 62 [33792/54000 (63%)] Loss: -509.257446\n",
      "Train Epoch: 62 [45056/54000 (83%)] Loss: -483.366150\n",
      "    epoch          : 62\n",
      "    loss           : -493.1012823716649\n",
      "    ess            : 1.974556749721743\n",
      "    log_marginal   : 493.1209319492556\n",
      "    log_joint      : 700.3803440309921\n",
      "    val_loss       : -495.6756820678711\n",
      "    val_ess        : 1.9735348025957744\n",
      "    val_log_marginal: 495.6972071329753\n",
      "    val_log_joint  : 703.1230316162109\n",
      "Train Epoch: 63 [0/54000 (0%)] Loss: -501.015839\n",
      "Train Epoch: 63 [11264/54000 (21%)] Loss: -480.311005\n",
      "Train Epoch: 63 [22528/54000 (42%)] Loss: -480.961914\n",
      "Train Epoch: 63 [33792/54000 (63%)] Loss: -518.797729\n",
      "Train Epoch: 63 [45056/54000 (83%)] Loss: -515.433289\n",
      "    epoch          : 63\n",
      "    loss           : -494.4104965497863\n",
      "    ess            : 1.9747437294924035\n",
      "    log_marginal   : 494.430643333579\n",
      "    log_joint      : 701.6253322385392\n",
      "    val_loss       : -494.8909428914388\n",
      "    val_ess        : 1.977798879146576\n",
      "    val_log_marginal: 494.9078725179036\n",
      "    val_log_joint  : 702.190907796224\n",
      "Train Epoch: 64 [0/54000 (0%)] Loss: -512.164612\n",
      "Train Epoch: 64 [11264/54000 (21%)] Loss: -500.718262\n",
      "Train Epoch: 64 [22528/54000 (42%)] Loss: -486.649353\n",
      "Train Epoch: 64 [33792/54000 (63%)] Loss: -507.962463\n",
      "Train Epoch: 64 [45056/54000 (83%)] Loss: -471.261902\n",
      "    epoch          : 64\n",
      "    loss           : -494.92198872116376\n",
      "    ess            : 1.9749259442653295\n",
      "    log_marginal   : 494.9407812154518\n",
      "    log_joint      : 702.1744154444281\n",
      "    val_loss       : -498.6867955525716\n",
      "    val_ess        : 1.9752200444539387\n",
      "    val_log_marginal: 498.70642852783203\n",
      "    val_log_joint  : 706.1885579427084\n",
      "Train Epoch: 65 [0/54000 (0%)] Loss: -504.412811\n",
      "Train Epoch: 65 [11264/54000 (21%)] Loss: -510.750061\n",
      "Train Epoch: 65 [22528/54000 (42%)] Loss: -508.105835\n",
      "Train Epoch: 65 [33792/54000 (63%)] Loss: -470.673279\n",
      "Train Epoch: 65 [45056/54000 (83%)] Loss: -478.901642\n",
      "    epoch          : 65\n",
      "    loss           : -495.0485315862692\n",
      "    ess            : 1.975056120809519\n",
      "    log_marginal   : 495.0675140956663\n",
      "    log_joint      : 702.4447107854879\n",
      "    val_loss       : -497.9189682006836\n",
      "    val_ess        : 1.9768067200978596\n",
      "    val_log_marginal: 497.9361979166667\n",
      "    val_log_joint  : 705.5357513427734\n",
      "Train Epoch: 66 [0/54000 (0%)] Loss: -502.675690\n",
      "Train Epoch: 66 [11264/54000 (21%)] Loss: -518.153137\n",
      "Train Epoch: 66 [22528/54000 (42%)] Loss: -493.138916\n",
      "Train Epoch: 66 [33792/54000 (63%)] Loss: -483.281982\n",
      "Train Epoch: 66 [45056/54000 (83%)] Loss: -501.237549\n",
      "    epoch          : 66\n",
      "    loss           : -498.64911896327754\n",
      "    ess            : 1.9745918669790592\n",
      "    log_marginal   : 498.6691036584242\n",
      "    log_joint      : 705.7887331404776\n",
      "    val_loss       : -502.57249450683594\n",
      "    val_ess        : 1.9758417407671611\n",
      "    val_log_marginal: 502.592046101888\n",
      "    val_log_joint  : 709.8567606608073\n",
      "Train Epoch: 67 [0/54000 (0%)] Loss: -487.873962\n",
      "Train Epoch: 67 [11264/54000 (21%)] Loss: -502.988708\n",
      "Train Epoch: 67 [22528/54000 (42%)] Loss: -512.620117\n",
      "Train Epoch: 67 [33792/54000 (63%)] Loss: -497.905334\n",
      "Train Epoch: 67 [45056/54000 (83%)] Loss: -476.965698\n",
      "    epoch          : 67\n",
      "    loss           : -493.5284084104142\n",
      "    ess            : 1.9747410304141495\n",
      "    log_marginal   : 493.54756855514813\n",
      "    log_joint      : 700.8923380149985\n",
      "    val_loss       : -496.74440511067706\n",
      "    val_ess        : 1.9727910459041595\n",
      "    val_log_marginal: 496.7651087443034\n",
      "    val_log_joint  : 704.3839670817057\n",
      "Train Epoch: 68 [0/54000 (0%)] Loss: -523.098877\n",
      "Train Epoch: 68 [11264/54000 (21%)] Loss: -488.482788\n",
      "Train Epoch: 68 [22528/54000 (42%)] Loss: -509.396759\n",
      "Train Epoch: 68 [33792/54000 (63%)] Loss: -488.649231\n",
      "Train Epoch: 68 [45056/54000 (83%)] Loss: -493.333069\n",
      "    epoch          : 68\n",
      "    loss           : -497.2841693230395\n",
      "    ess            : 1.9743754312677204\n",
      "    log_marginal   : 497.3040155374779\n",
      "    log_joint      : 704.6542703880453\n",
      "    val_loss       : -500.0381851196289\n",
      "    val_ess        : 1.976924479007721\n",
      "    val_log_marginal: 500.05506134033203\n",
      "    val_log_joint  : 707.3818105061849\n",
      "Train Epoch: 69 [0/54000 (0%)] Loss: -504.207581\n",
      "Train Epoch: 69 [11264/54000 (21%)] Loss: -498.962402\n",
      "Train Epoch: 69 [22528/54000 (42%)] Loss: -482.688782\n",
      "Train Epoch: 69 [33792/54000 (63%)] Loss: -525.398926\n",
      "Train Epoch: 69 [45056/54000 (83%)] Loss: -520.763977\n",
      "    epoch          : 69\n",
      "    loss           : -499.77878297050046\n",
      "    ess            : 1.974116766227866\n",
      "    log_marginal   : 499.79904923349056\n",
      "    log_joint      : 707.0500586167822\n",
      "    val_loss       : -502.8729476928711\n",
      "    val_ess        : 1.972319781780243\n",
      "    val_log_marginal: 502.89645131429035\n",
      "    val_log_joint  : 710.0388743082682\n",
      "Train Epoch: 70 [0/54000 (0%)] Loss: -494.250183\n",
      "Train Epoch: 70 [11264/54000 (21%)] Loss: -509.270233\n",
      "Train Epoch: 70 [22528/54000 (42%)] Loss: -506.287720\n",
      "Train Epoch: 70 [33792/54000 (63%)] Loss: -499.290802\n",
      "Train Epoch: 70 [45056/54000 (83%)] Loss: -517.125793\n",
      "    epoch          : 70\n",
      "    loss           : -501.23008987138854\n",
      "    ess            : 1.9747577185900707\n",
      "    log_marginal   : 501.24912852161333\n",
      "    log_joint      : 708.5261990529186\n",
      "    val_loss       : -505.59915924072266\n",
      "    val_ess        : 1.9740559856096904\n",
      "    val_log_marginal: 505.61874135335285\n",
      "    val_log_joint  : 712.6337076822916\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch70.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 71 [0/54000 (0%)] Loss: -493.683472\n",
      "Train Epoch: 71 [11264/54000 (21%)] Loss: -500.987366\n",
      "Train Epoch: 71 [22528/54000 (42%)] Loss: -486.767578\n",
      "Train Epoch: 71 [33792/54000 (63%)] Loss: -492.513000\n",
      "Train Epoch: 71 [45056/54000 (83%)] Loss: -519.005981\n",
      "    epoch          : 71\n",
      "    loss           : -500.7993071933962\n",
      "    ess            : 1.9744886587250907\n",
      "    log_marginal   : 500.81893057193395\n",
      "    log_joint      : 708.050977598946\n",
      "    val_loss       : -501.91651662190753\n",
      "    val_ess        : 1.9746133089065552\n",
      "    val_log_marginal: 501.9346008300781\n",
      "    val_log_joint  : 709.1024119059244\n",
      "Train Epoch: 72 [0/54000 (0%)] Loss: -506.764374\n",
      "Train Epoch: 72 [11264/54000 (21%)] Loss: -488.539154\n",
      "Train Epoch: 72 [22528/54000 (42%)] Loss: -500.572205\n",
      "Train Epoch: 72 [33792/54000 (63%)] Loss: -511.918823\n",
      "Train Epoch: 72 [45056/54000 (83%)] Loss: -504.162415\n",
      "    epoch          : 72\n",
      "    loss           : -502.59088825729657\n",
      "    ess            : 1.9739775511453737\n",
      "    log_marginal   : 502.6106190231611\n",
      "    log_joint      : 709.8463307506634\n",
      "    val_loss       : -507.43214925130206\n",
      "    val_ess        : 1.9739778737227123\n",
      "    val_log_marginal: 507.45190175374347\n",
      "    val_log_joint  : 714.6471761067709\n",
      "Train Epoch: 73 [0/54000 (0%)] Loss: -501.930176\n",
      "Train Epoch: 73 [11264/54000 (21%)] Loss: -518.036926\n",
      "Train Epoch: 73 [22528/54000 (42%)] Loss: -487.871216\n",
      "Train Epoch: 73 [33792/54000 (63%)] Loss: -490.321350\n",
      "Train Epoch: 73 [45056/54000 (83%)] Loss: -504.375305\n",
      "    epoch          : 73\n",
      "    loss           : -501.6081643734338\n",
      "    ess            : 1.9733685896081745\n",
      "    log_marginal   : 501.6287199776128\n",
      "    log_joint      : 708.914751736623\n",
      "    val_loss       : -503.24811299641925\n",
      "    val_ess        : 1.9740969439347584\n",
      "    val_log_marginal: 503.2673873901367\n",
      "    val_log_joint  : 710.6953328450521\n",
      "Train Epoch: 74 [0/54000 (0%)] Loss: -494.453796\n",
      "Train Epoch: 74 [11264/54000 (21%)] Loss: -506.928558\n",
      "Train Epoch: 74 [22528/54000 (42%)] Loss: -501.245178\n",
      "Train Epoch: 74 [33792/54000 (63%)] Loss: -505.181213\n",
      "Train Epoch: 74 [45056/54000 (83%)] Loss: -523.046326\n",
      "    epoch          : 74\n",
      "    loss           : -504.34589083689565\n",
      "    ess            : 1.9747486395655938\n",
      "    log_marginal   : 504.365276696547\n",
      "    log_joint      : 711.5209350585938\n",
      "    val_loss       : -508.64229583740234\n",
      "    val_ess        : 1.9756482541561127\n",
      "    val_log_marginal: 508.6609115600586\n",
      "    val_log_joint  : 716.0567016601562\n",
      "Train Epoch: 75 [0/54000 (0%)] Loss: -483.710144\n",
      "Train Epoch: 75 [11264/54000 (21%)] Loss: -501.976440\n",
      "Train Epoch: 75 [22528/54000 (42%)] Loss: -508.911743\n",
      "Train Epoch: 75 [33792/54000 (63%)] Loss: -502.444183\n",
      "Train Epoch: 75 [45056/54000 (83%)] Loss: -497.508545\n",
      "    epoch          : 75\n",
      "    loss           : -503.41453264344415\n",
      "    ess            : 1.9745858300406978\n",
      "    log_marginal   : 503.433754111236\n",
      "    log_joint      : 710.7173392817659\n",
      "    val_loss       : -507.6654103597005\n",
      "    val_ess        : 1.9725211262702942\n",
      "    val_log_marginal: 507.6878890991211\n",
      "    val_log_joint  : 715.0741068522135\n",
      "Train Epoch: 76 [0/54000 (0%)] Loss: -511.051086\n",
      "Train Epoch: 76 [11264/54000 (21%)] Loss: -503.343475\n",
      "Train Epoch: 76 [22528/54000 (42%)] Loss: -529.336670\n",
      "Train Epoch: 76 [33792/54000 (63%)] Loss: -497.957947\n",
      "Train Epoch: 76 [45056/54000 (83%)] Loss: -508.326141\n",
      "    epoch          : 76\n",
      "    loss           : -506.2921128183041\n",
      "    ess            : 1.9733321700456008\n",
      "    log_marginal   : 506.31295517255677\n",
      "    log_joint      : 713.635127805314\n",
      "    val_loss       : -511.4925282796224\n",
      "    val_ess        : 1.973972847064336\n",
      "    val_log_marginal: 511.5141347249349\n",
      "    val_log_joint  : 718.5857645670573\n",
      "Train Epoch: 77 [0/54000 (0%)] Loss: -493.118286\n",
      "Train Epoch: 77 [11264/54000 (21%)] Loss: -518.581909\n",
      "Train Epoch: 77 [22528/54000 (42%)] Loss: -509.040955\n",
      "Train Epoch: 77 [33792/54000 (63%)] Loss: -509.325500\n",
      "Train Epoch: 77 [45056/54000 (83%)] Loss: -505.966797\n",
      "    epoch          : 77\n",
      "    loss           : -505.71359051398514\n",
      "    ess            : 1.9738008492397812\n",
      "    log_marginal   : 505.73356081404773\n",
      "    log_joint      : 713.0024638625811\n",
      "    val_loss       : -508.98081970214844\n",
      "    val_ess        : 1.973330557346344\n",
      "    val_log_marginal: 509.0017445882161\n",
      "    val_log_joint  : 716.1250406901041\n",
      "Train Epoch: 78 [0/54000 (0%)] Loss: -509.605896\n",
      "Train Epoch: 78 [11264/54000 (21%)] Loss: -506.609772\n",
      "Train Epoch: 78 [22528/54000 (42%)] Loss: -502.790192\n",
      "Train Epoch: 78 [33792/54000 (63%)] Loss: -518.937134\n",
      "Train Epoch: 78 [45056/54000 (83%)] Loss: -516.428772\n",
      "    epoch          : 78\n",
      "    loss           : -506.72680117049305\n",
      "    ess            : 1.9752046904473934\n",
      "    log_marginal   : 506.745528886903\n",
      "    log_joint      : 714.0724706109964\n",
      "    val_loss       : -508.2372741699219\n",
      "    val_ess        : 1.9736012121041615\n",
      "    val_log_marginal: 508.2563934326172\n",
      "    val_log_joint  : 715.651621500651\n",
      "Train Epoch: 79 [0/54000 (0%)] Loss: -505.882935\n",
      "Train Epoch: 79 [11264/54000 (21%)] Loss: -512.871460\n",
      "Train Epoch: 79 [22528/54000 (42%)] Loss: -503.892334\n",
      "Train Epoch: 79 [33792/54000 (63%)] Loss: -492.173218\n",
      "Train Epoch: 79 [45056/54000 (83%)] Loss: -504.291504\n",
      "    epoch          : 79\n",
      "    loss           : -507.07667570294075\n",
      "    ess            : 1.9737424693017636\n",
      "    log_marginal   : 507.09726729482975\n",
      "    log_joint      : 714.3662552743588\n",
      "    val_loss       : -511.48814392089844\n",
      "    val_ess        : 1.975586195786794\n",
      "    val_log_marginal: 511.5084711710612\n",
      "    val_log_joint  : 718.4826711018881\n",
      "Train Epoch: 80 [0/54000 (0%)] Loss: -517.082825\n",
      "Train Epoch: 80 [11264/54000 (21%)] Loss: -504.001068\n",
      "Train Epoch: 80 [22528/54000 (42%)] Loss: -514.296082\n",
      "Train Epoch: 80 [33792/54000 (63%)] Loss: -501.335693\n",
      "Train Epoch: 80 [45056/54000 (83%)] Loss: -496.799164\n",
      "    epoch          : 80\n",
      "    loss           : -507.9797599360628\n",
      "    ess            : 1.9732848439576491\n",
      "    log_marginal   : 508.0002608389225\n",
      "    log_joint      : 715.2762963636866\n",
      "    val_loss       : -512.4108937581381\n",
      "    val_ess        : 1.972305913766225\n",
      "    val_log_marginal: 512.4327621459961\n",
      "    val_log_joint  : 719.3804372151693\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch80.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 81 [0/54000 (0%)] Loss: -526.131226\n",
      "Train Epoch: 81 [11264/54000 (21%)] Loss: -502.237915\n",
      "Train Epoch: 81 [22528/54000 (42%)] Loss: -515.875244\n",
      "Train Epoch: 81 [33792/54000 (63%)] Loss: -503.809692\n",
      "Train Epoch: 81 [45056/54000 (83%)] Loss: -510.265320\n",
      "    epoch          : 81\n",
      "    loss           : -509.5360709136387\n",
      "    ess            : 1.973688209956547\n",
      "    log_marginal   : 509.5564687476968\n",
      "    log_joint      : 716.8067500276386\n",
      "    val_loss       : -513.3123321533203\n",
      "    val_ess        : 1.9732516407966614\n",
      "    val_log_marginal: 513.3347676595052\n",
      "    val_log_joint  : 720.6184946695963\n",
      "Train Epoch: 82 [0/54000 (0%)] Loss: -516.796875\n",
      "Train Epoch: 82 [11264/54000 (21%)] Loss: -501.569458\n",
      "Train Epoch: 82 [22528/54000 (42%)] Loss: -508.309814\n",
      "Train Epoch: 82 [33792/54000 (63%)] Loss: -516.406921\n",
      "Train Epoch: 82 [45056/54000 (83%)] Loss: -511.824432\n",
      "    epoch          : 82\n",
      "    loss           : -510.0949874014225\n",
      "    ess            : 1.973583774746589\n",
      "    log_marginal   : 510.1160430908203\n",
      "    log_joint      : 717.3747742850826\n",
      "    val_loss       : -511.6634826660156\n",
      "    val_ess        : 1.9749943415323894\n",
      "    val_log_marginal: 511.68218485514325\n",
      "    val_log_joint  : 718.748769124349\n",
      "Train Epoch: 83 [0/54000 (0%)] Loss: -533.541443\n",
      "Train Epoch: 83 [11264/54000 (21%)] Loss: -503.057220\n",
      "Train Epoch: 83 [22528/54000 (42%)] Loss: -519.690735\n",
      "Train Epoch: 83 [33792/54000 (63%)] Loss: -499.653687\n",
      "Train Epoch: 83 [45056/54000 (83%)] Loss: -516.948547\n",
      "    epoch          : 83\n",
      "    loss           : -508.5519535856427\n",
      "    ess            : 1.9719255038027494\n",
      "    log_marginal   : 508.5740186583321\n",
      "    log_joint      : 715.9475500718603\n",
      "    val_loss       : -513.1573053995768\n",
      "    val_ess        : 1.970309962828954\n",
      "    val_log_marginal: 513.1801986694336\n",
      "    val_log_joint  : 720.5437571207682\n",
      "Train Epoch: 84 [0/54000 (0%)] Loss: -494.463196\n",
      "Train Epoch: 84 [11264/54000 (21%)] Loss: -508.827698\n",
      "Train Epoch: 84 [22528/54000 (42%)] Loss: -520.999390\n",
      "Train Epoch: 84 [33792/54000 (63%)] Loss: -525.717896\n",
      "Train Epoch: 84 [45056/54000 (83%)] Loss: -504.229187\n",
      "    epoch          : 84\n",
      "    loss           : -510.58490940309923\n",
      "    ess            : 1.973141557765457\n",
      "    log_marginal   : 510.605754348467\n",
      "    log_joint      : 717.9368539486292\n",
      "    val_loss       : -516.1796112060547\n",
      "    val_ess        : 1.9726591904958088\n",
      "    val_log_marginal: 516.2003580729166\n",
      "    val_log_joint  : 723.5592753092448\n",
      "Train Epoch: 85 [0/54000 (0%)] Loss: -495.080841\n",
      "Train Epoch: 85 [11264/54000 (21%)] Loss: -482.047424\n",
      "Train Epoch: 85 [22528/54000 (42%)] Loss: -505.540863\n",
      "Train Epoch: 85 [33792/54000 (63%)] Loss: -478.312469\n",
      "Train Epoch: 85 [45056/54000 (83%)] Loss: -530.001587\n",
      "    epoch          : 85\n",
      "    loss           : -510.8135557354621\n",
      "    ess            : 1.9733827676413194\n",
      "    log_marginal   : 510.83393341640254\n",
      "    log_joint      : 718.1754282825398\n",
      "    val_loss       : -515.1074752807617\n",
      "    val_ess        : 1.9733730753262837\n",
      "    val_log_marginal: 515.1281687418619\n",
      "    val_log_joint  : 722.2893829345703\n",
      "Train Epoch: 86 [0/54000 (0%)] Loss: -513.086182\n",
      "Train Epoch: 86 [11264/54000 (21%)] Loss: -500.222961\n",
      "Train Epoch: 86 [22528/54000 (42%)] Loss: -508.610962\n",
      "Train Epoch: 86 [33792/54000 (63%)] Loss: -505.164948\n",
      "Train Epoch: 86 [45056/54000 (83%)] Loss: -507.244537\n",
      "    epoch          : 86\n",
      "    loss           : -513.7649927679098\n",
      "    ess            : 1.973001775876531\n",
      "    log_marginal   : 513.7860257130749\n",
      "    log_joint      : 721.0511653108417\n",
      "    val_loss       : -518.0363642374674\n",
      "    val_ess        : 1.9740330080191295\n",
      "    val_log_marginal: 518.0546671549479\n",
      "    val_log_joint  : 725.3034057617188\n",
      "Train Epoch: 87 [0/54000 (0%)] Loss: -501.883057\n",
      "Train Epoch: 87 [11264/54000 (21%)] Loss: -504.267242\n",
      "Train Epoch: 87 [22528/54000 (42%)] Loss: -519.328369\n",
      "Train Epoch: 87 [33792/54000 (63%)] Loss: -514.761536\n",
      "Train Epoch: 87 [45056/54000 (83%)] Loss: -499.903992\n",
      "    epoch          : 87\n",
      "    loss           : -513.1513101829672\n",
      "    ess            : 1.9734111551968556\n",
      "    log_marginal   : 513.1726445611918\n",
      "    log_joint      : 720.3890737857458\n",
      "    val_loss       : -517.1432495117188\n",
      "    val_ess        : 1.975638637940089\n",
      "    val_log_marginal: 517.1631622314453\n",
      "    val_log_joint  : 724.1862335205078\n",
      "Train Epoch: 88 [0/54000 (0%)] Loss: -525.242676\n",
      "Train Epoch: 88 [11264/54000 (21%)] Loss: -489.345886\n",
      "Train Epoch: 88 [22528/54000 (42%)] Loss: -531.642578\n",
      "Train Epoch: 88 [33792/54000 (63%)] Loss: -504.121948\n",
      "Train Epoch: 88 [45056/54000 (83%)] Loss: -510.374329\n",
      "    epoch          : 88\n",
      "    loss           : -514.0234236807194\n",
      "    ess            : 1.972187950926007\n",
      "    log_marginal   : 514.0447410727447\n",
      "    log_joint      : 721.3763231961233\n",
      "    val_loss       : -515.849978129069\n",
      "    val_ess        : 1.9726206064224243\n",
      "    val_log_marginal: 515.871213277181\n",
      "    val_log_joint  : 723.3035329182943\n",
      "Train Epoch: 89 [0/54000 (0%)] Loss: -515.514709\n",
      "Train Epoch: 89 [11264/54000 (21%)] Loss: -487.413788\n",
      "Train Epoch: 89 [22528/54000 (42%)] Loss: -511.498230\n",
      "Train Epoch: 89 [33792/54000 (63%)] Loss: -531.287598\n",
      "Train Epoch: 89 [45056/54000 (83%)] Loss: -534.231750\n",
      "    epoch          : 89\n",
      "    loss           : -514.1624839350862\n",
      "    ess            : 1.9728864847489123\n",
      "    log_marginal   : 514.1835085311026\n",
      "    log_joint      : 721.4052273732311\n",
      "    val_loss       : -517.4444376627604\n",
      "    val_ess        : 1.9703137675921123\n",
      "    val_log_marginal: 517.4668655395508\n",
      "    val_log_joint  : 724.715565999349\n",
      "Train Epoch: 90 [0/54000 (0%)] Loss: -535.345459\n",
      "Train Epoch: 90 [11264/54000 (21%)] Loss: -508.537201\n",
      "Train Epoch: 90 [22528/54000 (42%)] Loss: -505.365631\n",
      "Train Epoch: 90 [33792/54000 (63%)] Loss: -500.974945\n",
      "Train Epoch: 90 [45056/54000 (83%)] Loss: -500.970032\n",
      "    epoch          : 90\n",
      "    loss           : -515.3273076471293\n",
      "    ess            : 1.9736377776793714\n",
      "    log_marginal   : 515.3474858122052\n",
      "    log_joint      : 722.6974308805645\n",
      "    val_loss       : -520.7442779541016\n",
      "    val_ess        : 1.9695818324883778\n",
      "    val_log_marginal: 520.7673136393229\n",
      "    val_log_joint  : 728.1794179280599\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch90.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 91 [0/54000 (0%)] Loss: -522.252075\n",
      "Train Epoch: 91 [11264/54000 (21%)] Loss: -514.515686\n",
      "Train Epoch: 91 [22528/54000 (42%)] Loss: -530.746277\n",
      "Train Epoch: 91 [33792/54000 (63%)] Loss: -507.967651\n",
      "Train Epoch: 91 [45056/54000 (83%)] Loss: -523.573914\n",
      "    epoch          : 91\n",
      "    loss           : -516.9523142688679\n",
      "    ess            : 1.9727082140040848\n",
      "    log_marginal   : 516.9741766587744\n",
      "    log_joint      : 724.197112461306\n",
      "    val_loss       : -521.0151621500651\n",
      "    val_ess        : 1.9742399553457897\n",
      "    val_log_marginal: 521.033945719401\n",
      "    val_log_joint  : 728.3613586425781\n",
      "Train Epoch: 92 [0/54000 (0%)] Loss: -532.327881\n",
      "Train Epoch: 92 [11264/54000 (21%)] Loss: -507.135437\n",
      "Train Epoch: 92 [22528/54000 (42%)] Loss: -520.883179\n",
      "Train Epoch: 92 [33792/54000 (63%)] Loss: -530.686768\n",
      "Train Epoch: 92 [45056/54000 (83%)] Loss: -530.709778\n",
      "    epoch          : 92\n",
      "    loss           : -518.4741518992298\n",
      "    ess            : 1.9713449860518832\n",
      "    log_marginal   : 518.4970372038067\n",
      "    log_joint      : 725.8016265293337\n",
      "    val_loss       : -523.348378499349\n",
      "    val_ess        : 1.9724804759025574\n",
      "    val_log_marginal: 523.3686472574869\n",
      "    val_log_joint  : 730.6057840983073\n",
      "Train Epoch: 93 [0/54000 (0%)] Loss: -520.294678\n",
      "Train Epoch: 93 [11264/54000 (21%)] Loss: -512.556519\n",
      "Train Epoch: 93 [22528/54000 (42%)] Loss: -500.632050\n",
      "Train Epoch: 93 [33792/54000 (63%)] Loss: -514.593506\n",
      "Train Epoch: 93 [45056/54000 (83%)] Loss: -525.018372\n",
      "    epoch          : 93\n",
      "    loss           : -513.8132825167673\n",
      "    ess            : 1.972884235517034\n",
      "    log_marginal   : 513.8337454166052\n",
      "    log_joint      : 721.2670172925266\n",
      "    val_loss       : -516.399658203125\n",
      "    val_ess        : 1.9745784004529316\n",
      "    val_log_marginal: 516.4174957275391\n",
      "    val_log_joint  : 724.2780609130859\n",
      "Train Epoch: 94 [0/54000 (0%)] Loss: -518.712280\n",
      "Train Epoch: 94 [11264/54000 (21%)] Loss: -516.763550\n",
      "Train Epoch: 94 [22528/54000 (42%)] Loss: -528.051147\n",
      "Train Epoch: 94 [33792/54000 (63%)] Loss: -510.025146\n",
      "Train Epoch: 94 [45056/54000 (83%)] Loss: -524.078125\n",
      "    epoch          : 94\n",
      "    loss           : -517.3861009129938\n",
      "    ess            : 1.9717077815307762\n",
      "    log_marginal   : 517.4085866100384\n",
      "    log_joint      : 724.7724102668043\n",
      "    val_loss       : -522.7751998901367\n",
      "    val_ess        : 1.9716551303863525\n",
      "    val_log_marginal: 522.7964172363281\n",
      "    val_log_joint  : 729.937978108724\n",
      "Train Epoch: 95 [0/54000 (0%)] Loss: -506.950195\n",
      "Train Epoch: 95 [11264/54000 (21%)] Loss: -524.349365\n",
      "Train Epoch: 95 [22528/54000 (42%)] Loss: -523.913086\n",
      "Train Epoch: 95 [33792/54000 (63%)] Loss: -507.859131\n",
      "Train Epoch: 95 [45056/54000 (83%)] Loss: -520.692261\n",
      "    epoch          : 95\n",
      "    loss           : -518.4860410870247\n",
      "    ess            : 1.970926894331878\n",
      "    log_marginal   : 518.508767469874\n",
      "    log_joint      : 725.865234375\n",
      "    val_loss       : -522.5656433105469\n",
      "    val_ess        : 1.9730397661526997\n",
      "    val_log_marginal: 522.5866877237955\n",
      "    val_log_joint  : 729.7266693115234\n",
      "Train Epoch: 96 [0/54000 (0%)] Loss: -518.180847\n",
      "Train Epoch: 96 [11264/54000 (21%)] Loss: -522.249634\n",
      "Train Epoch: 96 [22528/54000 (42%)] Loss: -538.661865\n",
      "Train Epoch: 96 [33792/54000 (63%)] Loss: -497.052460\n",
      "Train Epoch: 96 [45056/54000 (83%)] Loss: -550.292358\n",
      "    epoch          : 96\n",
      "    loss           : -520.8164785133218\n",
      "    ess            : 1.971517195116799\n",
      "    log_marginal   : 520.8383578894274\n",
      "    log_joint      : 728.1242140284124\n",
      "    val_loss       : -526.5261917114258\n",
      "    val_ess        : 1.9719123740990956\n",
      "    val_log_marginal: 526.5462036132812\n",
      "    val_log_joint  : 734.0378570556641\n",
      "Train Epoch: 97 [0/54000 (0%)] Loss: -503.523285\n",
      "Train Epoch: 97 [11264/54000 (21%)] Loss: -521.882263\n",
      "Train Epoch: 97 [22528/54000 (42%)] Loss: -517.492981\n",
      "Train Epoch: 97 [33792/54000 (63%)] Loss: -499.616943\n",
      "Train Epoch: 97 [45056/54000 (83%)] Loss: -522.571716\n",
      "    epoch          : 97\n",
      "    loss           : -518.1376391716723\n",
      "    ess            : 1.972184696287479\n",
      "    log_marginal   : 518.1588425546322\n",
      "    log_joint      : 725.580686173349\n",
      "    val_loss       : -520.0388768513998\n",
      "    val_ess        : 1.9722152352333069\n",
      "    val_log_marginal: 520.058723449707\n",
      "    val_log_joint  : 727.224619547526\n",
      "Train Epoch: 98 [0/54000 (0%)] Loss: -522.918945\n",
      "Train Epoch: 98 [11264/54000 (21%)] Loss: -533.749939\n",
      "Train Epoch: 98 [22528/54000 (42%)] Loss: -533.212585\n",
      "Train Epoch: 98 [33792/54000 (63%)] Loss: -523.922119\n",
      "Train Epoch: 98 [45056/54000 (83%)] Loss: -521.890869\n",
      "    epoch          : 98\n",
      "    loss           : -520.420731742427\n",
      "    ess            : 1.9711216890586998\n",
      "    log_marginal   : 520.443742284235\n",
      "    log_joint      : 727.7054097877359\n",
      "    val_loss       : -525.6735178629557\n",
      "    val_ess        : 1.9698644975821178\n",
      "    val_log_marginal: 525.6972401936849\n",
      "    val_log_joint  : 733.1266428629557\n",
      "Train Epoch: 99 [0/54000 (0%)] Loss: -531.234131\n",
      "Train Epoch: 99 [11264/54000 (21%)] Loss: -512.545166\n",
      "Train Epoch: 99 [22528/54000 (42%)] Loss: -521.364990\n",
      "Train Epoch: 99 [33792/54000 (63%)] Loss: -510.406982\n",
      "Train Epoch: 99 [45056/54000 (83%)] Loss: -532.857788\n",
      "    epoch          : 99\n",
      "    loss           : -520.4425454769495\n",
      "    ess            : 1.9718846881164696\n",
      "    log_marginal   : 520.4638853253059\n",
      "    log_joint      : 727.8419460080704\n",
      "    val_loss       : -525.5243275960287\n",
      "    val_ess        : 1.9705968896547954\n",
      "    val_log_marginal: 525.5494893391927\n",
      "    val_log_joint  : 733.0797424316406\n",
      "Train Epoch: 100 [0/54000 (0%)] Loss: -517.113037\n",
      "Train Epoch: 100 [11264/54000 (21%)] Loss: -512.081726\n",
      "Train Epoch: 100 [22528/54000 (42%)] Loss: -521.960388\n",
      "Train Epoch: 100 [33792/54000 (63%)] Loss: -511.331940\n",
      "Train Epoch: 100 [45056/54000 (83%)] Loss: -525.557922\n",
      "    epoch          : 100\n",
      "    loss           : -523.4585516587744\n",
      "    ess            : 1.9716036578394331\n",
      "    log_marginal   : 523.4806296870394\n",
      "    log_joint      : 730.7311752607237\n",
      "    val_loss       : -529.2712554931641\n",
      "    val_ess        : 1.9729532301425934\n",
      "    val_log_marginal: 529.2908935546875\n",
      "    val_log_joint  : 736.5477752685547\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 101 [0/54000 (0%)] Loss: -518.707642\n",
      "Train Epoch: 101 [11264/54000 (21%)] Loss: -521.715393\n",
      "Train Epoch: 101 [22528/54000 (42%)] Loss: -518.440430\n",
      "Train Epoch: 101 [33792/54000 (63%)] Loss: -482.891937\n",
      "Train Epoch: 101 [45056/54000 (83%)] Loss: -523.310974\n",
      "    epoch          : 101\n",
      "    loss           : -520.6208032572044\n",
      "    ess            : 1.9708678643658477\n",
      "    log_marginal   : 520.6440458477668\n",
      "    log_joint      : 728.1017076024469\n",
      "    val_loss       : -522.490712483724\n",
      "    val_ess        : 1.9718245367209117\n",
      "    val_log_marginal: 522.5122197469076\n",
      "    val_log_joint  : 729.8668823242188\n",
      "Train Epoch: 102 [0/54000 (0%)] Loss: -527.551453\n",
      "Train Epoch: 102 [11264/54000 (21%)] Loss: -514.386108\n",
      "Train Epoch: 102 [22528/54000 (42%)] Loss: -508.953186\n",
      "Train Epoch: 102 [33792/54000 (63%)] Loss: -536.267090\n",
      "Train Epoch: 102 [45056/54000 (83%)] Loss: -514.560059\n",
      "    epoch          : 102\n",
      "    loss           : -523.2313888837706\n",
      "    ess            : 1.9705752977785074\n",
      "    log_marginal   : 523.255246720224\n",
      "    log_joint      : 730.5494430829893\n",
      "    val_loss       : -529.0282236735026\n",
      "    val_ess        : 1.972765604654948\n",
      "    val_log_marginal: 529.0506896972656\n",
      "    val_log_joint  : 736.3907521565756\n",
      "Train Epoch: 103 [0/54000 (0%)] Loss: -533.242920\n",
      "Train Epoch: 103 [11264/54000 (21%)] Loss: -508.277832\n",
      "Train Epoch: 103 [22528/54000 (42%)] Loss: -520.152039\n",
      "Train Epoch: 103 [33792/54000 (63%)] Loss: -523.531921\n",
      "Train Epoch: 103 [45056/54000 (83%)] Loss: -517.521973\n",
      "    epoch          : 103\n",
      "    loss           : -523.1896581109964\n",
      "    ess            : 1.971187506081923\n",
      "    log_marginal   : 523.2113325011055\n",
      "    log_joint      : 730.5431443700251\n",
      "    val_loss       : -528.6598968505859\n",
      "    val_ess        : 1.9714975655078888\n",
      "    val_log_marginal: 528.6822102864584\n",
      "    val_log_joint  : 735.9883931477865\n",
      "Train Epoch: 104 [0/54000 (0%)] Loss: -534.235291\n",
      "Train Epoch: 104 [11264/54000 (21%)] Loss: -517.010803\n",
      "Train Epoch: 104 [22528/54000 (42%)] Loss: -514.652222\n",
      "Train Epoch: 104 [33792/54000 (63%)] Loss: -556.047485\n",
      "Train Epoch: 104 [45056/54000 (83%)] Loss: -516.197388\n",
      "    epoch          : 104\n",
      "    loss           : -525.644579905384\n",
      "    ess            : 1.9699809832392998\n",
      "    log_marginal   : 525.6684843819096\n",
      "    log_joint      : 732.9255463222288\n",
      "    val_loss       : -530.5205052693685\n",
      "    val_ess        : 1.9716352025667827\n",
      "    val_log_marginal: 530.5422922770182\n",
      "    val_log_joint  : 737.7953440348307\n",
      "Train Epoch: 105 [0/54000 (0%)] Loss: -537.589111\n",
      "Train Epoch: 105 [11264/54000 (21%)] Loss: -532.948853\n",
      "Train Epoch: 105 [22528/54000 (42%)] Loss: -510.375458\n",
      "Train Epoch: 105 [33792/54000 (63%)] Loss: -495.665405\n",
      "Train Epoch: 105 [45056/54000 (83%)] Loss: -523.383789\n",
      "    epoch          : 105\n",
      "    loss           : -525.0764606403854\n",
      "    ess            : 1.9705478605234399\n",
      "    log_marginal   : 525.1001134908424\n",
      "    log_joint      : 732.455552011166\n",
      "    val_loss       : -528.615956624349\n",
      "    val_ess        : 1.9716721872488658\n",
      "    val_log_marginal: 528.6387278238932\n",
      "    val_log_joint  : 736.0153961181641\n",
      "Train Epoch: 106 [0/54000 (0%)] Loss: -540.546387\n",
      "Train Epoch: 106 [11264/54000 (21%)] Loss: -517.973633\n",
      "Train Epoch: 106 [22528/54000 (42%)] Loss: -523.526367\n",
      "Train Epoch: 106 [33792/54000 (63%)] Loss: -523.262390\n",
      "Train Epoch: 106 [45056/54000 (83%)] Loss: -524.238953\n",
      "    epoch          : 106\n",
      "    loss           : -526.3744149837854\n",
      "    ess            : 1.9701816507105558\n",
      "    log_marginal   : 526.3982840484043\n",
      "    log_joint      : 733.6451611788767\n",
      "    val_loss       : -529.6952489217123\n",
      "    val_ess        : 1.967430740594864\n",
      "    val_log_marginal: 529.722401936849\n",
      "    val_log_joint  : 737.2081451416016\n",
      "Train Epoch: 107 [0/54000 (0%)] Loss: -519.078674\n",
      "Train Epoch: 107 [11264/54000 (21%)] Loss: -524.589355\n",
      "Train Epoch: 107 [22528/54000 (42%)] Loss: -504.010040\n",
      "Train Epoch: 107 [33792/54000 (63%)] Loss: -538.978210\n",
      "Train Epoch: 107 [45056/54000 (83%)] Loss: -562.744629\n",
      "    epoch          : 107\n",
      "    loss           : -525.6780438693064\n",
      "    ess            : 1.9697233629676532\n",
      "    log_marginal   : 525.7017042052071\n",
      "    log_joint      : 733.1800790462854\n",
      "    val_loss       : -530.0218454996744\n",
      "    val_ess        : 1.973773290713628\n",
      "    val_log_marginal: 530.0410741170248\n",
      "    val_log_joint  : 737.2838083902994\n",
      "Train Epoch: 108 [0/54000 (0%)] Loss: -524.638428\n",
      "Train Epoch: 108 [11264/54000 (21%)] Loss: -546.215820\n",
      "Train Epoch: 108 [22528/54000 (42%)] Loss: -507.774689\n",
      "Train Epoch: 108 [33792/54000 (63%)] Loss: -532.968689\n",
      "Train Epoch: 108 [45056/54000 (83%)] Loss: -531.341675\n",
      "    epoch          : 108\n",
      "    loss           : -527.0286182907392\n",
      "    ess            : 1.969670739938628\n",
      "    log_marginal   : 527.0524692175524\n",
      "    log_joint      : 734.3855164725826\n",
      "    val_loss       : -531.9427490234375\n",
      "    val_ess        : 1.9672459463278453\n",
      "    val_log_marginal: 531.9680302937826\n",
      "    val_log_joint  : 739.1862436930338\n",
      "Train Epoch: 109 [0/54000 (0%)] Loss: -544.877930\n",
      "Train Epoch: 109 [11264/54000 (21%)] Loss: -519.058960\n",
      "Train Epoch: 109 [22528/54000 (42%)] Loss: -523.320374\n",
      "Train Epoch: 109 [33792/54000 (63%)] Loss: -533.491943\n",
      "Train Epoch: 109 [45056/54000 (83%)] Loss: -504.839600\n",
      "    epoch          : 109\n",
      "    loss           : -528.4727685316553\n",
      "    ess            : 1.969913588379914\n",
      "    log_marginal   : 528.4964614004459\n",
      "    log_joint      : 735.7723434736143\n",
      "    val_loss       : -532.6045532226562\n",
      "    val_ess        : 1.9722961088021596\n",
      "    val_log_marginal: 532.6280568440756\n",
      "    val_log_joint  : 740.2087961832682\n",
      "Train Epoch: 110 [0/54000 (0%)] Loss: -531.588989\n",
      "Train Epoch: 110 [11264/54000 (21%)] Loss: -514.989807\n",
      "Train Epoch: 110 [22528/54000 (42%)] Loss: -506.228699\n",
      "Train Epoch: 110 [33792/54000 (63%)] Loss: -523.718689\n",
      "Train Epoch: 110 [45056/54000 (83%)] Loss: -502.131592\n",
      "    epoch          : 110\n",
      "    loss           : -529.6761045635872\n",
      "    ess            : 1.9695981043689657\n",
      "    log_marginal   : 529.701116885779\n",
      "    log_joint      : 737.0256693138266\n",
      "    val_loss       : -533.5569152832031\n",
      "    val_ess        : 1.9719324906667073\n",
      "    val_log_marginal: 533.5786844889323\n",
      "    val_log_joint  : 740.6287485758463\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch110.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 111 [0/54000 (0%)] Loss: -533.917419\n",
      "Train Epoch: 111 [11264/54000 (21%)] Loss: -514.920288\n",
      "Train Epoch: 111 [22528/54000 (42%)] Loss: -522.290894\n",
      "Train Epoch: 111 [33792/54000 (63%)] Loss: -511.201904\n",
      "Train Epoch: 111 [45056/54000 (83%)] Loss: -518.674561\n",
      "    epoch          : 111\n",
      "    loss           : -526.1336192005085\n",
      "    ess            : 1.969983364051243\n",
      "    log_marginal   : 526.1571542991782\n",
      "    log_joint      : 733.5718297418558\n",
      "    val_loss       : -530.8964767456055\n",
      "    val_ess        : 1.9702630937099457\n",
      "    val_log_marginal: 530.9202372233073\n",
      "    val_log_joint  : 738.284901936849\n",
      "Train Epoch: 112 [0/54000 (0%)] Loss: -543.233643\n",
      "Train Epoch: 112 [11264/54000 (21%)] Loss: -533.419495\n",
      "Train Epoch: 112 [22528/54000 (42%)] Loss: -513.318726\n",
      "Train Epoch: 112 [33792/54000 (63%)] Loss: -542.468750\n",
      "Train Epoch: 112 [45056/54000 (83%)] Loss: -521.963013\n",
      "    epoch          : 112\n",
      "    loss           : -529.0180540264778\n",
      "    ess            : 1.9705683510258514\n",
      "    log_marginal   : 529.0412735849056\n",
      "    log_joint      : 736.381089120541\n",
      "    val_loss       : -534.5168100992838\n",
      "    val_ess        : 1.9684181610743205\n",
      "    val_log_marginal: 534.5407206217448\n",
      "    val_log_joint  : 741.9113159179688\n",
      "Train Epoch: 113 [0/54000 (0%)] Loss: -537.996460\n",
      "Train Epoch: 113 [11264/54000 (21%)] Loss: -543.801025\n",
      "Train Epoch: 113 [22528/54000 (42%)] Loss: -552.694336\n",
      "Train Epoch: 113 [33792/54000 (63%)] Loss: -526.337402\n",
      "Train Epoch: 113 [45056/54000 (83%)] Loss: -529.975403\n",
      "    epoch          : 113\n",
      "    loss           : -529.9253007420954\n",
      "    ess            : 1.9701419551417512\n",
      "    log_marginal   : 529.948633157982\n",
      "    log_joint      : 737.2803033792748\n",
      "    val_loss       : -534.071055094401\n",
      "    val_ess        : 1.9688428541024525\n",
      "    val_log_marginal: 534.0957692464193\n",
      "    val_log_joint  : 741.2226206461588\n",
      "Train Epoch: 114 [0/54000 (0%)] Loss: -529.933472\n",
      "Train Epoch: 114 [11264/54000 (21%)] Loss: -532.683533\n",
      "Train Epoch: 114 [22528/54000 (42%)] Loss: -553.987183\n",
      "Train Epoch: 114 [33792/54000 (63%)] Loss: -517.932129\n",
      "Train Epoch: 114 [45056/54000 (83%)] Loss: -527.152222\n",
      "    epoch          : 114\n",
      "    loss           : -531.4328950126217\n",
      "    ess            : 1.9689840584431055\n",
      "    log_marginal   : 531.4572632987545\n",
      "    log_joint      : 738.761147553066\n",
      "    val_loss       : -536.0621185302734\n",
      "    val_ess        : 1.970982313156128\n",
      "    val_log_marginal: 536.083740234375\n",
      "    val_log_joint  : 743.2455139160156\n",
      "Train Epoch: 115 [0/54000 (0%)] Loss: -524.110291\n",
      "Train Epoch: 115 [11264/54000 (21%)] Loss: -519.038269\n",
      "Train Epoch: 115 [22528/54000 (42%)] Loss: -547.950073\n",
      "Train Epoch: 115 [33792/54000 (63%)] Loss: -547.451538\n",
      "Train Epoch: 115 [45056/54000 (83%)] Loss: -541.809204\n",
      "    epoch          : 115\n",
      "    loss           : -531.4044405379385\n",
      "    ess            : 1.9695704725553405\n",
      "    log_marginal   : 531.4284737065153\n",
      "    log_joint      : 738.7759445478331\n",
      "    val_loss       : -536.6297403971354\n",
      "    val_ess        : 1.9709907074769337\n",
      "    val_log_marginal: 536.6521250406901\n",
      "    val_log_joint  : 743.9148661295573\n",
      "Train Epoch: 116 [0/54000 (0%)] Loss: -550.070923\n",
      "Train Epoch: 116 [11264/54000 (21%)] Loss: -551.045105\n",
      "Train Epoch: 116 [22528/54000 (42%)] Loss: -513.959167\n",
      "Train Epoch: 116 [33792/54000 (63%)] Loss: -525.642151\n",
      "Train Epoch: 116 [45056/54000 (83%)] Loss: -555.396667\n",
      "    epoch          : 116\n",
      "    loss           : -532.4962140929024\n",
      "    ess            : 1.9682395435729116\n",
      "    log_marginal   : 532.5214397502396\n",
      "    log_joint      : 739.8857283682194\n",
      "    val_loss       : -536.2456919352213\n",
      "    val_ess        : 1.9702761868635814\n",
      "    val_log_marginal: 536.2696736653646\n",
      "    val_log_joint  : 743.8345387776693\n",
      "Train Epoch: 117 [0/54000 (0%)] Loss: -551.908447\n",
      "Train Epoch: 117 [11264/54000 (21%)] Loss: -513.644409\n",
      "Train Epoch: 117 [22528/54000 (42%)] Loss: -517.714478\n",
      "Train Epoch: 117 [33792/54000 (63%)] Loss: -533.963867\n",
      "Train Epoch: 117 [45056/54000 (83%)] Loss: -522.772278\n",
      "    epoch          : 117\n",
      "    loss           : -531.6106619205115\n",
      "    ess            : 1.970260443552485\n",
      "    log_marginal   : 531.6335383001364\n",
      "    log_joint      : 739.0341716262529\n",
      "    val_loss       : -533.6441752115885\n",
      "    val_ess        : 1.9704390962918599\n",
      "    val_log_marginal: 533.6680908203125\n",
      "    val_log_joint  : 741.0733947753906\n",
      "Train Epoch: 118 [0/54000 (0%)] Loss: -527.137390\n",
      "Train Epoch: 118 [11264/54000 (21%)] Loss: -519.777100\n",
      "Train Epoch: 118 [22528/54000 (42%)] Loss: -533.076416\n",
      "Train Epoch: 118 [33792/54000 (63%)] Loss: -535.751831\n",
      "Train Epoch: 118 [45056/54000 (83%)] Loss: -522.669067\n",
      "    epoch          : 118\n",
      "    loss           : -533.2279265781618\n",
      "    ess            : 1.9701808736009419\n",
      "    log_marginal   : 533.2512045806309\n",
      "    log_joint      : 740.5746816959021\n",
      "    val_loss       : -538.8643239339193\n",
      "    val_ess        : 1.967479447523753\n",
      "    val_log_marginal: 538.8902486165365\n",
      "    val_log_joint  : 745.8616994222006\n",
      "Train Epoch: 119 [0/54000 (0%)] Loss: -520.042358\n",
      "Train Epoch: 119 [11264/54000 (21%)] Loss: -533.263123\n",
      "Train Epoch: 119 [22528/54000 (42%)] Loss: -524.830261\n",
      "Train Epoch: 119 [33792/54000 (63%)] Loss: -541.805786\n",
      "Train Epoch: 119 [45056/54000 (83%)] Loss: -527.426025\n",
      "    epoch          : 119\n",
      "    loss           : -534.4359669235517\n",
      "    ess            : 1.9690940267634842\n",
      "    log_marginal   : 534.4606444160893\n",
      "    log_joint      : 741.7937800569355\n",
      "    val_loss       : -539.2797800699869\n",
      "    val_ess        : 1.9694229165712993\n",
      "    val_log_marginal: 539.3048197428385\n",
      "    val_log_joint  : 746.6695404052734\n",
      "Train Epoch: 120 [0/54000 (0%)] Loss: -543.431274\n",
      "Train Epoch: 120 [11264/54000 (21%)] Loss: -550.713257\n",
      "Train Epoch: 120 [22528/54000 (42%)] Loss: -551.252991\n",
      "Train Epoch: 120 [33792/54000 (63%)] Loss: -527.733887\n",
      "Train Epoch: 120 [45056/54000 (83%)] Loss: -539.332886\n",
      "    epoch          : 120\n",
      "    loss           : -535.4128484186136\n",
      "    ess            : 1.9687550562732625\n",
      "    log_marginal   : 535.4378935615971\n",
      "    log_joint      : 742.7809171856575\n",
      "    val_loss       : -541.4590555826823\n",
      "    val_ess        : 1.9679023027420044\n",
      "    val_log_marginal: 541.4838663736979\n",
      "    val_log_joint  : 748.6420644124349\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch120.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 121 [0/54000 (0%)] Loss: -516.841492\n",
      "Train Epoch: 121 [11264/54000 (21%)] Loss: -522.758179\n",
      "Train Epoch: 121 [22528/54000 (42%)] Loss: -558.040894\n",
      "Train Epoch: 121 [33792/54000 (63%)] Loss: -559.708069\n",
      "Train Epoch: 121 [45056/54000 (83%)] Loss: -549.478149\n",
      "    epoch          : 121\n",
      "    loss           : -533.2278577696602\n",
      "    ess            : 1.9687122286490675\n",
      "    log_marginal   : 533.2529239294664\n",
      "    log_joint      : 740.7512074596477\n",
      "    val_loss       : -533.1247024536133\n",
      "    val_ess        : 1.9698740939299266\n",
      "    val_log_marginal: 533.1477177937826\n",
      "    val_log_joint  : 740.7796071370443\n",
      "Train Epoch: 122 [0/54000 (0%)] Loss: -531.658325\n",
      "Train Epoch: 122 [11264/54000 (21%)] Loss: -554.140991\n",
      "Train Epoch: 122 [22528/54000 (42%)] Loss: -523.793762\n",
      "Train Epoch: 122 [33792/54000 (63%)] Loss: -529.205688\n",
      "Train Epoch: 122 [45056/54000 (83%)] Loss: -520.641296\n",
      "    epoch          : 122\n",
      "    loss           : -535.4241379072081\n",
      "    ess            : 1.9688859829362833\n",
      "    log_marginal   : 535.4479634986734\n",
      "    log_joint      : 742.7106415370725\n",
      "    val_loss       : -540.6981455485026\n",
      "    val_ess        : 1.967613826195399\n",
      "    val_log_marginal: 540.7245279947916\n",
      "    val_log_joint  : 747.9521484375\n",
      "Train Epoch: 123 [0/54000 (0%)] Loss: -531.003296\n",
      "Train Epoch: 123 [11264/54000 (21%)] Loss: -542.707825\n",
      "Train Epoch: 123 [22528/54000 (42%)] Loss: -526.868286\n",
      "Train Epoch: 123 [33792/54000 (63%)] Loss: -530.306152\n",
      "Train Epoch: 123 [45056/54000 (83%)] Loss: -557.815308\n",
      "    epoch          : 123\n",
      "    loss           : -536.2038597250885\n",
      "    ess            : 1.969020223842477\n",
      "    log_marginal   : 536.2287050643057\n",
      "    log_joint      : 743.5196515929024\n",
      "    val_loss       : -540.4497273763021\n",
      "    val_ess        : 1.9683416684468586\n",
      "    val_log_marginal: 540.477284749349\n",
      "    val_log_joint  : 747.6426289876302\n",
      "Train Epoch: 124 [0/54000 (0%)] Loss: -528.462646\n",
      "Train Epoch: 124 [11264/54000 (21%)] Loss: -524.149658\n",
      "Train Epoch: 124 [22528/54000 (42%)] Loss: -557.926880\n",
      "Train Epoch: 124 [33792/54000 (63%)] Loss: -546.718018\n",
      "Train Epoch: 124 [45056/54000 (83%)] Loss: -524.121216\n",
      "    epoch          : 124\n",
      "    loss           : -538.1016624018831\n",
      "    ess            : 1.9683125480166022\n",
      "    log_marginal   : 538.1263632144568\n",
      "    log_joint      : 745.2954009433962\n",
      "    val_loss       : -543.1518096923828\n",
      "    val_ess        : 1.970027933518092\n",
      "    val_log_marginal: 543.1749827067057\n",
      "    val_log_joint  : 750.3321940104166\n",
      "Train Epoch: 125 [0/54000 (0%)] Loss: -549.091919\n",
      "Train Epoch: 125 [11264/54000 (21%)] Loss: -538.628540\n",
      "Train Epoch: 125 [22528/54000 (42%)] Loss: -526.234680\n",
      "Train Epoch: 125 [33792/54000 (63%)] Loss: -531.104614\n",
      "Train Epoch: 125 [45056/54000 (83%)] Loss: -545.766602\n",
      "    epoch          : 125\n",
      "    loss           : -535.070425069557\n",
      "    ess            : 1.9679144868310892\n",
      "    log_marginal   : 535.0963100217423\n",
      "    log_joint      : 742.5586547851562\n",
      "    val_loss       : -538.0879923502604\n",
      "    val_ess        : 1.9691136280695598\n",
      "    val_log_marginal: 538.1128743489584\n",
      "    val_log_joint  : 745.4432017008463\n",
      "Train Epoch: 126 [0/54000 (0%)] Loss: -530.040405\n",
      "Train Epoch: 126 [11264/54000 (21%)] Loss: -541.085938\n",
      "Train Epoch: 126 [22528/54000 (42%)] Loss: -526.047546\n",
      "Train Epoch: 126 [33792/54000 (63%)] Loss: -553.020569\n",
      "Train Epoch: 126 [45056/54000 (83%)] Loss: -520.230896\n",
      "    epoch          : 126\n",
      "    loss           : -537.2932025261645\n",
      "    ess            : 1.9680553652205557\n",
      "    log_marginal   : 537.3189757724978\n",
      "    log_joint      : 744.6264325987618\n",
      "    val_loss       : -541.6451085408529\n",
      "    val_ess        : 1.9671380718549092\n",
      "    val_log_marginal: 541.6721776326498\n",
      "    val_log_joint  : 749.0435689290365\n",
      "Train Epoch: 127 [0/54000 (0%)] Loss: -545.055054\n",
      "Train Epoch: 127 [11264/54000 (21%)] Loss: -535.173340\n",
      "Train Epoch: 127 [22528/54000 (42%)] Loss: -532.568665\n",
      "Train Epoch: 127 [33792/54000 (63%)] Loss: -512.569580\n",
      "Train Epoch: 127 [45056/54000 (83%)] Loss: -545.204163\n",
      "    epoch          : 127\n",
      "    loss           : -537.8515170115345\n",
      "    ess            : 1.9678299483263268\n",
      "    log_marginal   : 537.8776348761793\n",
      "    log_joint      : 745.3683742307267\n",
      "    val_loss       : -542.6215515136719\n",
      "    val_ess        : 1.9692554672559102\n",
      "    val_log_marginal: 542.645009358724\n",
      "    val_log_joint  : 749.9828033447266\n",
      "Train Epoch: 128 [0/54000 (0%)] Loss: -541.631470\n",
      "Train Epoch: 128 [11264/54000 (21%)] Loss: -553.132080\n",
      "Train Epoch: 128 [22528/54000 (42%)] Loss: -534.497803\n",
      "Train Epoch: 128 [33792/54000 (63%)] Loss: -536.920532\n",
      "Train Epoch: 128 [45056/54000 (83%)] Loss: -547.158203\n",
      "    epoch          : 128\n",
      "    loss           : -538.8200335232717\n",
      "    ess            : 1.9675908414822705\n",
      "    log_marginal   : 538.8459357495578\n",
      "    log_joint      : 746.1527577526165\n",
      "    val_loss       : -543.4205017089844\n",
      "    val_ess        : 1.9698776205380757\n",
      "    val_log_marginal: 543.4443766276041\n",
      "    val_log_joint  : 750.2977498372396\n",
      "Train Epoch: 129 [0/54000 (0%)] Loss: -543.984131\n",
      "Train Epoch: 129 [11264/54000 (21%)] Loss: -532.617981\n",
      "Train Epoch: 129 [22528/54000 (42%)] Loss: -525.951416\n",
      "Train Epoch: 129 [33792/54000 (63%)] Loss: -559.073364\n",
      "Train Epoch: 129 [45056/54000 (83%)] Loss: -570.111938\n",
      "    epoch          : 129\n",
      "    loss           : -540.1103521383034\n",
      "    ess            : 1.9670244792722307\n",
      "    log_marginal   : 540.1371431170769\n",
      "    log_joint      : 747.4762774773363\n",
      "    val_loss       : -545.4117584228516\n",
      "    val_ess        : 1.9668826560179393\n",
      "    val_log_marginal: 545.4393412272135\n",
      "    val_log_joint  : 752.2665710449219\n",
      "Train Epoch: 130 [0/54000 (0%)] Loss: -547.591309\n",
      "Train Epoch: 130 [11264/54000 (21%)] Loss: -541.635376\n",
      "Train Epoch: 130 [22528/54000 (42%)] Loss: -531.213806\n",
      "Train Epoch: 130 [33792/54000 (63%)] Loss: -547.529297\n",
      "Train Epoch: 130 [45056/54000 (83%)] Loss: -541.768005\n",
      "    epoch          : 130\n",
      "    loss           : -541.0577930954267\n",
      "    ess            : 1.9675873529236272\n",
      "    log_marginal   : 541.084060956847\n",
      "    log_joint      : 748.4141834187058\n",
      "    val_loss       : -546.60302734375\n",
      "    val_ess        : 1.9654269119103749\n",
      "    val_log_marginal: 546.6301523844401\n",
      "    val_log_joint  : 753.7512664794922\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch130.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 131 [0/54000 (0%)] Loss: -545.756592\n",
      "Train Epoch: 131 [11264/54000 (21%)] Loss: -543.749146\n",
      "Train Epoch: 131 [22528/54000 (42%)] Loss: -552.450195\n",
      "Train Epoch: 131 [33792/54000 (63%)] Loss: -525.091309\n",
      "Train Epoch: 131 [45056/54000 (83%)] Loss: -539.461487\n",
      "    epoch          : 131\n",
      "    loss           : -537.2746671280771\n",
      "    ess            : 1.9678612227709789\n",
      "    log_marginal   : 537.3000563135687\n",
      "    log_joint      : 744.8276252026828\n",
      "    val_loss       : -539.0167948404948\n",
      "    val_ess        : 1.96821528673172\n",
      "    val_log_marginal: 539.042226155599\n",
      "    val_log_joint  : 746.7056325276693\n",
      "Train Epoch: 132 [0/54000 (0%)] Loss: -543.351440\n",
      "Train Epoch: 132 [11264/54000 (21%)] Loss: -534.477783\n",
      "Train Epoch: 132 [22528/54000 (42%)] Loss: -534.580261\n",
      "Train Epoch: 132 [33792/54000 (63%)] Loss: -529.237305\n",
      "Train Epoch: 132 [45056/54000 (83%)] Loss: -550.682800\n",
      "    epoch          : 132\n",
      "    loss           : -540.6626008231685\n",
      "    ess            : 1.9668211768258292\n",
      "    log_marginal   : 540.6892222278523\n",
      "    log_joint      : 748.0124252607237\n",
      "    val_loss       : -545.9927062988281\n",
      "    val_ess        : 1.9663602610429127\n",
      "    val_log_marginal: 546.0210774739584\n",
      "    val_log_joint  : 753.4957580566406\n",
      "Train Epoch: 133 [0/54000 (0%)] Loss: -542.446289\n",
      "Train Epoch: 133 [11264/54000 (21%)] Loss: -538.659302\n",
      "Train Epoch: 133 [22528/54000 (42%)] Loss: -537.900696\n",
      "Train Epoch: 133 [33792/54000 (63%)] Loss: -554.525024\n",
      "Train Epoch: 133 [45056/54000 (83%)] Loss: -531.320801\n",
      "    epoch          : 133\n",
      "    loss           : -541.8872047280365\n",
      "    ess            : 1.9674340171634026\n",
      "    log_marginal   : 541.9129298947892\n",
      "    log_joint      : 749.2444786215729\n",
      "    val_loss       : -546.6105448404948\n",
      "    val_ess        : 1.9689970115820568\n",
      "    val_log_marginal: 546.6334686279297\n",
      "    val_log_joint  : 754.0925038655599\n",
      "Train Epoch: 134 [0/54000 (0%)] Loss: -536.408875\n",
      "Train Epoch: 134 [11264/54000 (21%)] Loss: -540.019897\n",
      "Train Epoch: 134 [22528/54000 (42%)] Loss: -536.778931\n",
      "Train Epoch: 134 [33792/54000 (63%)] Loss: -571.246765\n",
      "Train Epoch: 134 [45056/54000 (83%)] Loss: -564.255005\n",
      "    epoch          : 134\n",
      "    loss           : -543.4022847301555\n",
      "    ess            : 1.9666113504823648\n",
      "    log_marginal   : 543.4294663915094\n",
      "    log_joint      : 750.6528832777491\n",
      "    val_loss       : -547.6941375732422\n",
      "    val_ess        : 1.9680429100990295\n",
      "    val_log_marginal: 547.7188466389974\n",
      "    val_log_joint  : 755.2817433675131\n",
      "Train Epoch: 135 [0/54000 (0%)] Loss: -538.484863\n",
      "Train Epoch: 135 [11264/54000 (21%)] Loss: -560.637573\n",
      "Train Epoch: 135 [22528/54000 (42%)] Loss: -549.082336\n",
      "Train Epoch: 135 [33792/54000 (63%)] Loss: -528.255249\n",
      "Train Epoch: 135 [45056/54000 (83%)] Loss: -526.879883\n",
      "    epoch          : 135\n",
      "    loss           : -541.8876429143942\n",
      "    ess            : 1.967146486606238\n",
      "    log_marginal   : 541.9141773727705\n",
      "    log_joint      : 749.2891632655882\n",
      "    val_loss       : -545.9295501708984\n",
      "    val_ess        : 1.9639809727668762\n",
      "    val_log_marginal: 545.9596099853516\n",
      "    val_log_joint  : 753.4851481119791\n",
      "Train Epoch: 136 [0/54000 (0%)] Loss: -535.771423\n",
      "Train Epoch: 136 [11264/54000 (21%)] Loss: -529.163696\n",
      "Train Epoch: 136 [22528/54000 (42%)] Loss: -538.959656\n",
      "Train Epoch: 136 [33792/54000 (63%)] Loss: -551.966492\n",
      "Train Epoch: 136 [45056/54000 (83%)] Loss: -558.828491\n",
      "    epoch          : 136\n",
      "    loss           : -543.3381226737545\n",
      "    ess            : 1.9669126710801754\n",
      "    log_marginal   : 543.3652951222546\n",
      "    log_joint      : 750.6962084500295\n",
      "    val_loss       : -546.6165466308594\n",
      "    val_ess        : 1.9666211704413097\n",
      "    val_log_marginal: 546.6422119140625\n",
      "    val_log_joint  : 753.9210561116537\n",
      "Train Epoch: 137 [0/54000 (0%)] Loss: -552.369385\n",
      "Train Epoch: 137 [11264/54000 (21%)] Loss: -555.428650\n",
      "Train Epoch: 137 [22528/54000 (42%)] Loss: -518.956970\n",
      "Train Epoch: 137 [33792/54000 (63%)] Loss: -533.276306\n",
      "Train Epoch: 137 [45056/54000 (83%)] Loss: -538.319214\n",
      "    epoch          : 137\n",
      "    loss           : -543.5671317622347\n",
      "    ess            : 1.9665042757987976\n",
      "    log_marginal   : 543.5939883825914\n",
      "    log_joint      : 750.9997316756338\n",
      "    val_loss       : -547.4756215413412\n",
      "    val_ess        : 1.9670775334040325\n",
      "    val_log_marginal: 547.5015665690104\n",
      "    val_log_joint  : 754.8491973876953\n",
      "Train Epoch: 138 [0/54000 (0%)] Loss: -553.994934\n",
      "Train Epoch: 138 [11264/54000 (21%)] Loss: -525.396667\n",
      "Train Epoch: 138 [22528/54000 (42%)] Loss: -540.999329\n",
      "Train Epoch: 138 [33792/54000 (63%)] Loss: -525.387634\n",
      "Train Epoch: 138 [45056/54000 (83%)] Loss: -536.989014\n",
      "    epoch          : 138\n",
      "    loss           : -543.8817176099094\n",
      "    ess            : 1.9675422524506192\n",
      "    log_marginal   : 543.9084242334906\n",
      "    log_joint      : 751.3477581671949\n",
      "    val_loss       : -549.0504913330078\n",
      "    val_ess        : 1.9684637387593586\n",
      "    val_log_marginal: 549.0748952229818\n",
      "    val_log_joint  : 756.5259653727213\n",
      "Train Epoch: 139 [0/54000 (0%)] Loss: -538.403503\n",
      "Train Epoch: 139 [11264/54000 (21%)] Loss: -548.043457\n",
      "Train Epoch: 139 [22528/54000 (42%)] Loss: -528.613953\n",
      "Train Epoch: 139 [33792/54000 (63%)] Loss: -578.334534\n",
      "Train Epoch: 139 [45056/54000 (83%)] Loss: -535.423340\n",
      "    epoch          : 139\n",
      "    loss           : -545.620702779518\n",
      "    ess            : 1.9670925275334772\n",
      "    log_marginal   : 545.6475294580999\n",
      "    log_joint      : 753.0385540656324\n",
      "    val_loss       : -550.7353312174479\n",
      "    val_ess        : 1.967799295981725\n",
      "    val_log_marginal: 550.7603556315104\n",
      "    val_log_joint  : 757.8353525797526\n",
      "Train Epoch: 140 [0/54000 (0%)] Loss: -557.004883\n",
      "Train Epoch: 140 [11264/54000 (21%)] Loss: -562.491699\n",
      "Train Epoch: 140 [22528/54000 (42%)] Loss: -539.995605\n",
      "Train Epoch: 140 [33792/54000 (63%)] Loss: -554.065491\n",
      "Train Epoch: 140 [45056/54000 (83%)] Loss: -524.915710\n",
      "    epoch          : 140\n",
      "    loss           : -546.2239305028376\n",
      "    ess            : 1.9669164587866586\n",
      "    log_marginal   : 546.2515109080189\n",
      "    log_joint      : 753.5820583127579\n",
      "    val_loss       : -549.7019500732422\n",
      "    val_ess        : 1.9686523973941803\n",
      "    val_log_marginal: 549.7261657714844\n",
      "    val_log_joint  : 756.7725067138672\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch140.pth ...\n",
      "Train Epoch: 141 [0/54000 (0%)] Loss: -538.796875\n",
      "Train Epoch: 141 [11264/54000 (21%)] Loss: -543.432129\n",
      "Train Epoch: 141 [22528/54000 (42%)] Loss: -547.772583\n",
      "Train Epoch: 141 [33792/54000 (63%)] Loss: -521.742065\n",
      "Train Epoch: 141 [45056/54000 (83%)] Loss: -551.872681\n",
      "    epoch          : 141\n",
      "    loss           : -545.5243115695017\n",
      "    ess            : 1.9659599628088609\n",
      "    log_marginal   : 545.5527804392689\n",
      "    log_joint      : 752.932017200398\n",
      "    val_loss       : -549.3296661376953\n",
      "    val_ess        : 1.9649344782034557\n",
      "    val_log_marginal: 549.3594106038412\n",
      "    val_log_joint  : 756.8682047526041\n",
      "Train Epoch: 142 [0/54000 (0%)] Loss: -557.973328\n",
      "Train Epoch: 142 [11264/54000 (21%)] Loss: -552.867432\n",
      "Train Epoch: 142 [22528/54000 (42%)] Loss: -542.147217\n",
      "Train Epoch: 142 [33792/54000 (63%)] Loss: -543.626953\n",
      "Train Epoch: 142 [45056/54000 (83%)] Loss: -533.920654\n",
      "    epoch          : 142\n",
      "    loss           : -546.6808981265661\n",
      "    ess            : 1.9669387160607104\n",
      "    log_marginal   : 546.7075987042122\n",
      "    log_joint      : 754.139782599683\n",
      "    val_loss       : -551.5302937825521\n",
      "    val_ess        : 1.9673430621623993\n",
      "    val_log_marginal: 551.5556945800781\n",
      "    val_log_joint  : 759.1327362060547\n",
      "Train Epoch: 143 [0/54000 (0%)] Loss: -539.845337\n",
      "Train Epoch: 143 [11264/54000 (21%)] Loss: -554.211914\n",
      "Train Epoch: 143 [22528/54000 (42%)] Loss: -545.436768\n",
      "Train Epoch: 143 [33792/54000 (63%)] Loss: -549.921082\n",
      "Train Epoch: 143 [45056/54000 (83%)] Loss: -534.543152\n",
      "    epoch          : 143\n",
      "    loss           : -546.5512896843676\n",
      "    ess            : 1.9660028252961501\n",
      "    log_marginal   : 546.5782931345814\n",
      "    log_joint      : 753.9490805571934\n",
      "    val_loss       : -549.6322174072266\n",
      "    val_ess        : 1.9633685648441315\n",
      "    val_log_marginal: 549.6628926595052\n",
      "    val_log_joint  : 757.1818695068359\n",
      "Train Epoch: 144 [0/54000 (0%)] Loss: -575.977417\n",
      "Train Epoch: 144 [11264/54000 (21%)] Loss: -546.001282\n",
      "Train Epoch: 144 [22528/54000 (42%)] Loss: -551.589111\n",
      "Train Epoch: 144 [33792/54000 (63%)] Loss: -543.413818\n",
      "Train Epoch: 144 [45056/54000 (83%)] Loss: -570.270752\n",
      "    epoch          : 144\n",
      "    loss           : -547.7599567917158\n",
      "    ess            : 1.9662825397725374\n",
      "    log_marginal   : 547.7876494785525\n",
      "    log_joint      : 755.1596483914358\n",
      "    val_loss       : -552.7221069335938\n",
      "    val_ess        : 1.9671931664148967\n",
      "    val_log_marginal: 552.7481180826823\n",
      "    val_log_joint  : 759.7598215738932\n",
      "Train Epoch: 145 [0/54000 (0%)] Loss: -547.599487\n",
      "Train Epoch: 145 [11264/54000 (21%)] Loss: -542.370483\n",
      "Train Epoch: 145 [22528/54000 (42%)] Loss: -536.363892\n",
      "Train Epoch: 145 [33792/54000 (63%)] Loss: -553.631592\n",
      "Train Epoch: 145 [45056/54000 (83%)] Loss: -564.751221\n",
      "    epoch          : 145\n",
      "    loss           : -548.5318615031692\n",
      "    ess            : 1.965814674800297\n",
      "    log_marginal   : 548.5600626243735\n",
      "    log_joint      : 755.8459766315964\n",
      "    val_loss       : -553.7459665934244\n",
      "    val_ess        : 1.9653323491414387\n",
      "    val_log_marginal: 553.7754567464193\n",
      "    val_log_joint  : 761.3171590169271\n",
      "Train Epoch: 146 [0/54000 (0%)] Loss: -537.085327\n",
      "Train Epoch: 146 [11264/54000 (21%)] Loss: -554.449585\n",
      "Train Epoch: 146 [22528/54000 (42%)] Loss: -548.183716\n",
      "Train Epoch: 146 [33792/54000 (63%)] Loss: -564.078735\n",
      "Train Epoch: 146 [45056/54000 (83%)] Loss: -545.367188\n",
      "    epoch          : 146\n",
      "    loss           : -549.493784778523\n",
      "    ess            : 1.9663320566123386\n",
      "    log_marginal   : 549.5203845905808\n",
      "    log_joint      : 756.8673326024469\n",
      "    val_loss       : -553.8349812825521\n",
      "    val_ess        : 1.9654971261819203\n",
      "    val_log_marginal: 553.8616383870443\n",
      "    val_log_joint  : 761.3960011800131\n",
      "Train Epoch: 147 [0/54000 (0%)] Loss: -543.425171\n",
      "Train Epoch: 147 [11264/54000 (21%)] Loss: -551.311768\n",
      "Train Epoch: 147 [22528/54000 (42%)] Loss: -522.927307\n",
      "Train Epoch: 147 [33792/54000 (63%)] Loss: -561.733948\n",
      "Train Epoch: 147 [45056/54000 (83%)] Loss: -534.284790\n",
      "    epoch          : 147\n",
      "    loss           : -547.6354387391289\n",
      "    ess            : 1.9664963135179483\n",
      "    log_marginal   : 547.662487677808\n",
      "    log_joint      : 755.2499406922539\n",
      "    val_loss       : -548.8217213948568\n",
      "    val_ess        : 1.9626891414324443\n",
      "    val_log_marginal: 548.8500061035156\n",
      "    val_log_joint  : 756.2229207356771\n",
      "Train Epoch: 148 [0/54000 (0%)] Loss: -541.643799\n",
      "Train Epoch: 148 [11264/54000 (21%)] Loss: -532.740234\n",
      "Train Epoch: 148 [22528/54000 (42%)] Loss: -548.111572\n",
      "Train Epoch: 148 [33792/54000 (63%)] Loss: -573.705444\n",
      "Train Epoch: 148 [45056/54000 (83%)] Loss: -555.405884\n",
      "    epoch          : 148\n",
      "    loss           : -549.120737903523\n",
      "    ess            : 1.9657596743331764\n",
      "    log_marginal   : 549.1491163721624\n",
      "    log_joint      : 756.5719489331516\n",
      "    val_loss       : -555.4396616617838\n",
      "    val_ess        : 1.967635969320933\n",
      "    val_log_marginal: 555.4655100504557\n",
      "    val_log_joint  : 762.6160837809244\n",
      "Train Epoch: 149 [0/54000 (0%)] Loss: -550.674194\n",
      "Train Epoch: 149 [11264/54000 (21%)] Loss: -524.032593\n",
      "Train Epoch: 149 [22528/54000 (42%)] Loss: -563.848389\n",
      "Train Epoch: 149 [33792/54000 (63%)] Loss: -548.746033\n",
      "Train Epoch: 149 [45056/54000 (83%)] Loss: -516.776855\n",
      "    epoch          : 149\n",
      "    loss           : -550.7262757499263\n",
      "    ess            : 1.965702862109778\n",
      "    log_marginal   : 550.7541515422317\n",
      "    log_joint      : 758.1550304484817\n",
      "    val_loss       : -555.0754852294922\n",
      "    val_ess        : 1.9647498925526936\n",
      "    val_log_marginal: 555.1028493245443\n",
      "    val_log_joint  : 762.7390492757162\n",
      "Train Epoch: 150 [0/54000 (0%)] Loss: -563.548706\n",
      "Train Epoch: 150 [11264/54000 (21%)] Loss: -546.547974\n",
      "Train Epoch: 150 [22528/54000 (42%)] Loss: -547.704102\n",
      "Train Epoch: 150 [33792/54000 (63%)] Loss: -552.213379\n",
      "Train Epoch: 150 [45056/54000 (83%)] Loss: -557.563843\n",
      "    epoch          : 150\n",
      "    loss           : -551.5255040582621\n",
      "    ess            : 1.965261995792389\n",
      "    log_marginal   : 551.5528558695091\n",
      "    log_joint      : 758.9077373000811\n",
      "    val_loss       : -556.5660502115885\n",
      "    val_ess        : 1.9681623975435893\n",
      "    val_log_marginal: 556.5911204020182\n",
      "    val_log_joint  : 763.6691945393881\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch150.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 151 [0/54000 (0%)] Loss: -555.711792\n",
      "Train Epoch: 151 [11264/54000 (21%)] Loss: -561.400391\n",
      "Train Epoch: 151 [22528/54000 (42%)] Loss: -551.391541\n",
      "Train Epoch: 151 [33792/54000 (63%)] Loss: -551.013306\n",
      "Train Epoch: 151 [45056/54000 (83%)] Loss: -556.783691\n",
      "    epoch          : 151\n",
      "    loss           : -550.1000590774248\n",
      "    ess            : 1.964952493613621\n",
      "    log_marginal   : 550.1297210117556\n",
      "    log_joint      : 757.6072537404186\n",
      "    val_loss       : -553.7607167561849\n",
      "    val_ess        : 1.965632975101471\n",
      "    val_log_marginal: 553.7888946533203\n",
      "    val_log_joint  : 760.8880411783854\n",
      "Train Epoch: 152 [0/54000 (0%)] Loss: -542.385010\n",
      "Train Epoch: 152 [11264/54000 (21%)] Loss: -562.922791\n",
      "Train Epoch: 152 [22528/54000 (42%)] Loss: -554.663757\n",
      "Train Epoch: 152 [33792/54000 (63%)] Loss: -539.193359\n",
      "Train Epoch: 152 [45056/54000 (83%)] Loss: -530.076416\n",
      "    epoch          : 152\n",
      "    loss           : -551.8924940577093\n",
      "    ess            : 1.9654848024530231\n",
      "    log_marginal   : 551.9208477668043\n",
      "    log_joint      : 759.3586846117703\n",
      "    val_loss       : -556.0251820882162\n",
      "    val_ess        : 1.966706206401189\n",
      "    val_log_marginal: 556.0519104003906\n",
      "    val_log_joint  : 763.3873443603516\n",
      "Train Epoch: 153 [0/54000 (0%)] Loss: -564.601929\n",
      "Train Epoch: 153 [11264/54000 (21%)] Loss: -545.696411\n",
      "Train Epoch: 153 [22528/54000 (42%)] Loss: -562.283691\n",
      "Train Epoch: 153 [33792/54000 (63%)] Loss: -549.906128\n",
      "Train Epoch: 153 [45056/54000 (83%)] Loss: -571.278564\n",
      "    epoch          : 153\n",
      "    loss           : -551.7158709831957\n",
      "    ess            : 1.96513255024856\n",
      "    log_marginal   : 551.7446542415979\n",
      "    log_joint      : 759.1897266315964\n",
      "    val_loss       : -556.6682790120443\n",
      "    val_ess        : 1.9636347989241283\n",
      "    val_log_marginal: 556.6976877848307\n",
      "    val_log_joint  : 764.0549723307291\n",
      "Train Epoch: 154 [0/54000 (0%)] Loss: -545.248352\n",
      "Train Epoch: 154 [11264/54000 (21%)] Loss: -562.965454\n",
      "Train Epoch: 154 [22528/54000 (42%)] Loss: -550.921387\n",
      "Train Epoch: 154 [33792/54000 (63%)] Loss: -507.808502\n",
      "Train Epoch: 154 [45056/54000 (83%)] Loss: -552.147827\n",
      "    epoch          : 154\n",
      "    loss           : -552.8445817479547\n",
      "    ess            : 1.9645812252782426\n",
      "    log_marginal   : 552.8737176859154\n",
      "    log_joint      : 760.2662658691406\n",
      "    val_loss       : -557.7688598632812\n",
      "    val_ess        : 1.9636996587117512\n",
      "    val_log_marginal: 557.7982432047526\n",
      "    val_log_joint  : 764.9560699462891\n",
      "Train Epoch: 155 [0/54000 (0%)] Loss: -565.591675\n",
      "Train Epoch: 155 [11264/54000 (21%)] Loss: -555.295715\n",
      "Train Epoch: 155 [22528/54000 (42%)] Loss: -557.802307\n",
      "Train Epoch: 155 [33792/54000 (63%)] Loss: -557.465454\n",
      "Train Epoch: 155 [45056/54000 (83%)] Loss: -568.380249\n",
      "    epoch          : 155\n",
      "    loss           : -554.2437508061247\n",
      "    ess            : 1.9648975100157395\n",
      "    log_marginal   : 554.2717544267763\n",
      "    log_joint      : 761.638944805793\n",
      "    val_loss       : -558.7013702392578\n",
      "    val_ess        : 1.9653600653012593\n",
      "    val_log_marginal: 558.7298685709635\n",
      "    val_log_joint  : 766.2018432617188\n",
      "Train Epoch: 156 [0/54000 (0%)] Loss: -564.663940\n",
      "Train Epoch: 156 [11264/54000 (21%)] Loss: -557.893738\n",
      "Train Epoch: 156 [22528/54000 (42%)] Loss: -547.973511\n",
      "Train Epoch: 156 [33792/54000 (63%)] Loss: -544.774536\n",
      "Train Epoch: 156 [45056/54000 (83%)] Loss: -552.442261\n",
      "    epoch          : 156\n",
      "    loss           : -555.017515938237\n",
      "    ess            : 1.9642163953691159\n",
      "    log_marginal   : 555.0477778596698\n",
      "    log_joint      : 762.4066052706736\n",
      "    val_loss       : -559.8045043945312\n",
      "    val_ess        : 1.9661062558492024\n",
      "    val_log_marginal: 559.8330230712891\n",
      "    val_log_joint  : 767.1205088297526\n",
      "Train Epoch: 157 [0/54000 (0%)] Loss: -562.631165\n",
      "Train Epoch: 157 [11264/54000 (21%)] Loss: -544.834839\n",
      "Train Epoch: 157 [22528/54000 (42%)] Loss: -556.729858\n",
      "Train Epoch: 157 [33792/54000 (63%)] Loss: -547.277954\n",
      "Train Epoch: 157 [45056/54000 (83%)] Loss: -557.004150\n",
      "    epoch          : 157\n",
      "    loss           : -552.4547890717129\n",
      "    ess            : 1.9647698559851017\n",
      "    log_marginal   : 552.4836143637604\n",
      "    log_joint      : 760.1463473338001\n",
      "    val_loss       : -554.0483194986979\n",
      "    val_ess        : 1.9652361969153087\n",
      "    val_log_marginal: 554.0787556966146\n",
      "    val_log_joint  : 761.4682312011719\n",
      "Train Epoch: 158 [0/54000 (0%)] Loss: -569.497375\n",
      "Train Epoch: 158 [11264/54000 (21%)] Loss: -561.723877\n",
      "Train Epoch: 158 [22528/54000 (42%)] Loss: -570.601562\n",
      "Train Epoch: 158 [33792/54000 (63%)] Loss: -545.373291\n",
      "Train Epoch: 158 [45056/54000 (83%)] Loss: -535.445251\n",
      "    epoch          : 158\n",
      "    loss           : -554.7299044627064\n",
      "    ess            : 1.9640204816494349\n",
      "    log_marginal   : 554.7589537422612\n",
      "    log_joint      : 762.2286279066553\n",
      "    val_loss       : -559.4678599039713\n",
      "    val_ess        : 1.9635817607243855\n",
      "    val_log_marginal: 559.4973754882812\n",
      "    val_log_joint  : 766.7934265136719\n",
      "Train Epoch: 159 [0/54000 (0%)] Loss: -551.417847\n",
      "Train Epoch: 159 [11264/54000 (21%)] Loss: -548.349792\n",
      "Train Epoch: 159 [22528/54000 (42%)] Loss: -541.055298\n",
      "Train Epoch: 159 [33792/54000 (63%)] Loss: -556.966309\n",
      "Train Epoch: 159 [45056/54000 (83%)] Loss: -550.165405\n",
      "    epoch          : 159\n",
      "    loss           : -555.6416211398142\n",
      "    ess            : 1.9647911370925184\n",
      "    log_marginal   : 555.6703404840433\n",
      "    log_joint      : 763.1389666863207\n",
      "    val_loss       : -560.3429819742838\n",
      "    val_ess        : 1.9641122023264568\n",
      "    val_log_marginal: 560.3739369710287\n",
      "    val_log_joint  : 768.1659393310547\n",
      "Train Epoch: 160 [0/54000 (0%)] Loss: -568.021912\n",
      "Train Epoch: 160 [11264/54000 (21%)] Loss: -548.637207\n",
      "Train Epoch: 160 [22528/54000 (42%)] Loss: -555.478027\n",
      "Train Epoch: 160 [33792/54000 (63%)] Loss: -550.245239\n",
      "Train Epoch: 160 [45056/54000 (83%)] Loss: -539.281982\n",
      "    epoch          : 160\n",
      "    loss           : -556.3959972453567\n",
      "    ess            : 1.9651816476066157\n",
      "    log_marginal   : 556.4245231196566\n",
      "    log_joint      : 763.8680212632665\n",
      "    val_loss       : -561.0230916341146\n",
      "    val_ess        : 1.9664006332556407\n",
      "    val_log_marginal: 561.0494232177734\n",
      "    val_log_joint  : 768.4776051839193\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch160.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 161 [0/54000 (0%)] Loss: -579.171753\n",
      "Train Epoch: 161 [11264/54000 (21%)] Loss: -538.064331\n",
      "Train Epoch: 161 [22528/54000 (42%)] Loss: -562.403564\n",
      "Train Epoch: 161 [33792/54000 (63%)] Loss: -529.589722\n",
      "Train Epoch: 161 [45056/54000 (83%)] Loss: -573.231934\n",
      "    epoch          : 161\n",
      "    loss           : -556.3197366966391\n",
      "    ess            : 1.9641548237710629\n",
      "    log_marginal   : 556.3490180249485\n",
      "    log_joint      : 763.7409057617188\n",
      "    val_loss       : -560.8193664550781\n",
      "    val_ess        : 1.9635040163993835\n",
      "    val_log_marginal: 560.8482716878256\n",
      "    val_log_joint  : 767.916005452474\n",
      "Train Epoch: 162 [0/54000 (0%)] Loss: -552.102051\n",
      "Train Epoch: 162 [11264/54000 (21%)] Loss: -526.186890\n",
      "Train Epoch: 162 [22528/54000 (42%)] Loss: -557.775513\n",
      "Train Epoch: 162 [33792/54000 (63%)] Loss: -540.646851\n",
      "Train Epoch: 162 [45056/54000 (83%)] Loss: -568.520752\n",
      "    epoch          : 162\n",
      "    loss           : -557.4158843418337\n",
      "    ess            : 1.9641316814242669\n",
      "    log_marginal   : 557.4457334122568\n",
      "    log_joint      : 764.8713614985628\n",
      "    val_loss       : -561.7753194173177\n",
      "    val_ess        : 1.9641919533411663\n",
      "    val_log_marginal: 561.8025105794271\n",
      "    val_log_joint  : 768.9283142089844\n",
      "Train Epoch: 163 [0/54000 (0%)] Loss: -539.822876\n",
      "Train Epoch: 163 [11264/54000 (21%)] Loss: -566.127563\n",
      "Train Epoch: 163 [22528/54000 (42%)] Loss: -587.652832\n",
      "Train Epoch: 163 [33792/54000 (63%)] Loss: -556.375366\n",
      "Train Epoch: 163 [45056/54000 (83%)] Loss: -565.816772\n",
      "    epoch          : 163\n",
      "    loss           : -557.7058433676666\n",
      "    ess            : 1.9635889518935725\n",
      "    log_marginal   : 557.7358358131265\n",
      "    log_joint      : 765.1774211379717\n",
      "    val_loss       : -561.3202463785807\n",
      "    val_ess        : 1.9649437566598256\n",
      "    val_log_marginal: 561.3485565185547\n",
      "    val_log_joint  : 768.8290201822916\n",
      "Train Epoch: 164 [0/54000 (0%)] Loss: -544.624023\n",
      "Train Epoch: 164 [11264/54000 (21%)] Loss: -556.952881\n",
      "Train Epoch: 164 [22528/54000 (42%)] Loss: -571.438782\n",
      "Train Epoch: 164 [33792/54000 (63%)] Loss: -551.050598\n",
      "Train Epoch: 164 [45056/54000 (83%)] Loss: -534.185913\n",
      "    epoch          : 164\n",
      "    loss           : -556.4243883816702\n",
      "    ess            : 1.963696741832877\n",
      "    log_marginal   : 556.4556706266583\n",
      "    log_joint      : 763.9419607486365\n",
      "    val_loss       : -560.7135874430338\n",
      "    val_ess        : 1.9648275276025136\n",
      "    val_log_marginal: 560.7426147460938\n",
      "    val_log_joint  : 768.2836405436198\n",
      "Train Epoch: 165 [0/54000 (0%)] Loss: -548.067505\n",
      "Train Epoch: 165 [11264/54000 (21%)] Loss: -562.418335\n",
      "Train Epoch: 165 [22528/54000 (42%)] Loss: -558.384888\n",
      "Train Epoch: 165 [33792/54000 (63%)] Loss: -542.856506\n",
      "Train Epoch: 165 [45056/54000 (83%)] Loss: -558.443115\n",
      "    epoch          : 165\n",
      "    loss           : -558.3756472029776\n",
      "    ess            : 1.9643862618590302\n",
      "    log_marginal   : 558.4058354215802\n",
      "    log_joint      : 765.9020063292305\n",
      "    val_loss       : -563.3854166666666\n",
      "    val_ess        : 1.965614140033722\n",
      "    val_log_marginal: 563.4153035481771\n",
      "    val_log_joint  : 770.7141927083334\n",
      "Train Epoch: 166 [0/54000 (0%)] Loss: -544.865356\n",
      "Train Epoch: 166 [11264/54000 (21%)] Loss: -562.424988\n",
      "Train Epoch: 166 [22528/54000 (42%)] Loss: -561.907227\n",
      "Train Epoch: 166 [33792/54000 (63%)] Loss: -552.803101\n",
      "Train Epoch: 166 [45056/54000 (83%)] Loss: -564.763550\n",
      "    epoch          : 166\n",
      "    loss           : -558.4658899847067\n",
      "    ess            : 1.9641307569899649\n",
      "    log_marginal   : 558.4951621001621\n",
      "    log_joint      : 766.0622299482237\n",
      "    val_loss       : -561.851796468099\n",
      "    val_ess        : 1.9653020203113556\n",
      "    val_log_marginal: 561.8825734456381\n",
      "    val_log_joint  : 769.3029225667318\n",
      "Train Epoch: 167 [0/54000 (0%)] Loss: -571.449036\n",
      "Train Epoch: 167 [11264/54000 (21%)] Loss: -568.739868\n",
      "Train Epoch: 167 [22528/54000 (42%)] Loss: -556.227539\n",
      "Train Epoch: 167 [33792/54000 (63%)] Loss: -562.755493\n",
      "Train Epoch: 167 [45056/54000 (83%)] Loss: -543.981934\n",
      "    epoch          : 167\n",
      "    loss           : -559.4075720445165\n",
      "    ess            : 1.9628018511916108\n",
      "    log_marginal   : 559.4389395084021\n",
      "    log_joint      : 766.9886589770047\n",
      "    val_loss       : -564.5931294759115\n",
      "    val_ess        : 1.9629202485084534\n",
      "    val_log_marginal: 564.6246287027994\n",
      "    val_log_joint  : 772.1952463785807\n",
      "Train Epoch: 168 [0/54000 (0%)] Loss: -557.451294\n",
      "Train Epoch: 168 [11264/54000 (21%)] Loss: -552.590454\n",
      "Train Epoch: 168 [22528/54000 (42%)] Loss: -551.679443\n",
      "Train Epoch: 168 [33792/54000 (63%)] Loss: -559.082520\n",
      "Train Epoch: 168 [45056/54000 (83%)] Loss: -552.743286\n",
      "    epoch          : 168\n",
      "    loss           : -560.121687403265\n",
      "    ess            : 1.96406918314268\n",
      "    log_marginal   : 560.1512813927992\n",
      "    log_joint      : 767.5571260272332\n",
      "    val_loss       : -564.7671457926432\n",
      "    val_ess        : 1.9618613918622334\n",
      "    val_log_marginal: 564.7977244059244\n",
      "    val_log_joint  : 772.3060913085938\n",
      "Train Epoch: 169 [0/54000 (0%)] Loss: -565.649353\n",
      "Train Epoch: 169 [11264/54000 (21%)] Loss: -555.336975\n",
      "Train Epoch: 169 [22528/54000 (42%)] Loss: -575.348083\n",
      "Train Epoch: 169 [33792/54000 (63%)] Loss: -571.013184\n",
      "Train Epoch: 169 [45056/54000 (83%)] Loss: -539.079712\n",
      "    epoch          : 169\n",
      "    loss           : -561.2164508171801\n",
      "    ess            : 1.9629112988148096\n",
      "    log_marginal   : 561.2468163832178\n",
      "    log_joint      : 768.6605610397627\n",
      "    val_loss       : -566.3860524495443\n",
      "    val_ess        : 1.9647394518057506\n",
      "    val_log_marginal: 566.4159240722656\n",
      "    val_log_joint  : 773.7928314208984\n",
      "Train Epoch: 170 [0/54000 (0%)] Loss: -577.386475\n",
      "Train Epoch: 170 [11264/54000 (21%)] Loss: -549.169006\n",
      "Train Epoch: 170 [22528/54000 (42%)] Loss: -558.813477\n",
      "Train Epoch: 170 [33792/54000 (63%)] Loss: -563.153381\n",
      "Train Epoch: 170 [45056/54000 (83%)] Loss: -569.932190\n",
      "    epoch          : 170\n",
      "    loss           : -559.7026666605248\n",
      "    ess            : 1.9633733866349705\n",
      "    log_marginal   : 559.733404771337\n",
      "    log_joint      : 767.2763896438311\n",
      "    val_loss       : -561.0304260253906\n",
      "    val_ess        : 1.9594159026940663\n",
      "    val_log_marginal: 561.0654958089193\n",
      "    val_log_joint  : 768.6926727294922\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch170.pth ...\n",
      "Train Epoch: 171 [0/54000 (0%)] Loss: -525.852722\n",
      "Train Epoch: 171 [11264/54000 (21%)] Loss: -517.917175\n",
      "Train Epoch: 171 [22528/54000 (42%)] Loss: -561.872803\n",
      "Train Epoch: 171 [33792/54000 (63%)] Loss: -578.327026\n",
      "Train Epoch: 171 [45056/54000 (83%)] Loss: -550.281982\n",
      "    epoch          : 171\n",
      "    loss           : -560.8399790637898\n",
      "    ess            : 1.9631155751786142\n",
      "    log_marginal   : 560.8715935473172\n",
      "    log_joint      : 768.4450798754422\n",
      "    val_loss       : -566.1429443359375\n",
      "    val_ess        : 1.96448415517807\n",
      "    val_log_marginal: 566.1706288655599\n",
      "    val_log_joint  : 773.5257670084635\n",
      "Train Epoch: 172 [0/54000 (0%)] Loss: -541.311768\n",
      "Train Epoch: 172 [11264/54000 (21%)] Loss: -567.878723\n",
      "Train Epoch: 172 [22528/54000 (42%)] Loss: -577.461304\n",
      "Train Epoch: 172 [33792/54000 (63%)] Loss: -565.214172\n",
      "Train Epoch: 172 [45056/54000 (83%)] Loss: -575.968994\n",
      "    epoch          : 172\n",
      "    loss           : -562.0583570948187\n",
      "    ess            : 1.9642030315579109\n",
      "    log_marginal   : 562.0893548929466\n",
      "    log_joint      : 769.6069140164358\n",
      "    val_loss       : -566.3878784179688\n",
      "    val_ess        : 1.962246298789978\n",
      "    val_log_marginal: 566.4187672932943\n",
      "    val_log_joint  : 773.9400024414062\n",
      "Train Epoch: 173 [0/54000 (0%)] Loss: -561.373352\n",
      "Train Epoch: 173 [11264/54000 (21%)] Loss: -568.511047\n",
      "Train Epoch: 173 [22528/54000 (42%)] Loss: -551.126831\n",
      "Train Epoch: 173 [33792/54000 (63%)] Loss: -547.177734\n",
      "Train Epoch: 173 [45056/54000 (83%)] Loss: -559.603149\n",
      "    epoch          : 173\n",
      "    loss           : -562.5206759470814\n",
      "    ess            : 1.9637034119300123\n",
      "    log_marginal   : 562.5512798957105\n",
      "    log_joint      : 770.0257838986954\n",
      "    val_loss       : -566.3914540608724\n",
      "    val_ess        : 1.9622845550378163\n",
      "    val_log_marginal: 566.4209187825521\n",
      "    val_log_joint  : 773.7670745849609\n",
      "Train Epoch: 174 [0/54000 (0%)] Loss: -549.469238\n",
      "Train Epoch: 174 [11264/54000 (21%)] Loss: -549.870728\n",
      "Train Epoch: 174 [22528/54000 (42%)] Loss: -553.498230\n",
      "Train Epoch: 174 [33792/54000 (63%)] Loss: -577.666138\n",
      "Train Epoch: 174 [45056/54000 (83%)] Loss: -573.037842\n",
      "    epoch          : 174\n",
      "    loss           : -562.7194991201725\n",
      "    ess            : 1.9617761587196927\n",
      "    log_marginal   : 562.7518160838001\n",
      "    log_joint      : 770.2691604326357\n",
      "    val_loss       : -566.8577168782552\n",
      "    val_ess        : 1.9649981061617534\n",
      "    val_log_marginal: 566.8871815999349\n",
      "    val_log_joint  : 774.2980702718099\n",
      "Train Epoch: 175 [0/54000 (0%)] Loss: -575.097046\n",
      "Train Epoch: 175 [11264/54000 (21%)] Loss: -557.027466\n",
      "Train Epoch: 175 [22528/54000 (42%)] Loss: -560.327148\n",
      "Train Epoch: 175 [33792/54000 (63%)] Loss: -540.189087\n",
      "Train Epoch: 175 [45056/54000 (83%)] Loss: -579.628418\n",
      "    epoch          : 175\n",
      "    loss           : -563.8356530531397\n",
      "    ess            : 1.9632456943673908\n",
      "    log_marginal   : 563.8669358739313\n",
      "    log_joint      : 771.3236936173349\n",
      "    val_loss       : -568.5300649007162\n",
      "    val_ess        : 1.962434599796931\n",
      "    val_log_marginal: 568.5610097249349\n",
      "    val_log_joint  : 775.8330891927084\n",
      "Train Epoch: 176 [0/54000 (0%)] Loss: -579.667847\n",
      "Train Epoch: 176 [11264/54000 (21%)] Loss: -580.508850\n",
      "Train Epoch: 176 [22528/54000 (42%)] Loss: -566.325134\n",
      "Train Epoch: 176 [33792/54000 (63%)] Loss: -579.453735\n",
      "Train Epoch: 176 [45056/54000 (83%)] Loss: -580.860474\n",
      "    epoch          : 176\n",
      "    loss           : -563.8542509258918\n",
      "    ess            : 1.9629777073860168\n",
      "    log_marginal   : 563.8859638717939\n",
      "    log_joint      : 771.4641810003317\n",
      "    val_loss       : -567.4575042724609\n",
      "    val_ess        : 1.963057428598404\n",
      "    val_log_marginal: 567.4855550130209\n",
      "    val_log_joint  : 774.9693756103516\n",
      "Train Epoch: 177 [0/54000 (0%)] Loss: -544.640015\n",
      "Train Epoch: 177 [11264/54000 (21%)] Loss: -566.299194\n",
      "Train Epoch: 177 [22528/54000 (42%)] Loss: -572.644714\n",
      "Train Epoch: 177 [33792/54000 (63%)] Loss: -573.923828\n",
      "Train Epoch: 177 [45056/54000 (83%)] Loss: -560.317383\n",
      "    epoch          : 177\n",
      "    loss           : -562.344608522811\n",
      "    ess            : 1.9631518541641955\n",
      "    log_marginal   : 562.3754301251106\n",
      "    log_joint      : 769.8539802983122\n",
      "    val_loss       : -567.2830607096354\n",
      "    val_ess        : 1.9609545767307281\n",
      "    val_log_marginal: 567.3155415852865\n",
      "    val_log_joint  : 774.9813741048177\n",
      "Train Epoch: 178 [0/54000 (0%)] Loss: -586.013611\n",
      "Train Epoch: 178 [11264/54000 (21%)] Loss: -550.135193\n",
      "Train Epoch: 178 [22528/54000 (42%)] Loss: -550.083130\n",
      "Train Epoch: 178 [33792/54000 (63%)] Loss: -563.376831\n",
      "Train Epoch: 178 [45056/54000 (83%)] Loss: -555.779907\n",
      "    epoch          : 178\n",
      "    loss           : -564.519781724462\n",
      "    ess            : 1.962082511973831\n",
      "    log_marginal   : 564.5511854639593\n",
      "    log_joint      : 772.0685079322672\n",
      "    val_loss       : -568.7131195068359\n",
      "    val_ess        : 1.9624155859152477\n",
      "    val_log_marginal: 568.7433471679688\n",
      "    val_log_joint  : 776.7592366536459\n",
      "Train Epoch: 179 [0/54000 (0%)] Loss: -566.914062\n",
      "Train Epoch: 179 [11264/54000 (21%)] Loss: -562.987915\n",
      "Train Epoch: 179 [22528/54000 (42%)] Loss: -590.689453\n",
      "Train Epoch: 179 [33792/54000 (63%)] Loss: -520.338257\n",
      "Train Epoch: 179 [45056/54000 (83%)] Loss: -562.876892\n",
      "    epoch          : 179\n",
      "    loss           : -564.9095073196123\n",
      "    ess            : 1.9630018765071653\n",
      "    log_marginal   : 564.9408937850088\n",
      "    log_joint      : 772.5344537698998\n",
      "    val_loss       : -567.8811543782552\n",
      "    val_ess        : 1.9601792792479198\n",
      "    val_log_marginal: 567.9149169921875\n",
      "    val_log_joint  : 775.5245412190756\n",
      "Train Epoch: 180 [0/54000 (0%)] Loss: -574.578735\n",
      "Train Epoch: 180 [11264/54000 (21%)] Loss: -569.742676\n",
      "Train Epoch: 180 [22528/54000 (42%)] Loss: -549.075684\n",
      "Train Epoch: 180 [33792/54000 (63%)] Loss: -554.177673\n",
      "Train Epoch: 180 [45056/54000 (83%)] Loss: -571.671814\n",
      "    epoch          : 180\n",
      "    loss           : -565.7874427651459\n",
      "    ess            : 1.9616826514028154\n",
      "    log_marginal   : 565.8202658599278\n",
      "    log_joint      : 773.3909917867409\n",
      "    val_loss       : -569.7870432535807\n",
      "    val_ess        : 1.962496042251587\n",
      "    val_log_marginal: 569.8175252278646\n",
      "    val_log_joint  : 777.2565002441406\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch180.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 181 [0/54000 (0%)] Loss: -568.141846\n",
      "Train Epoch: 181 [11264/54000 (21%)] Loss: -578.361206\n",
      "Train Epoch: 181 [22528/54000 (42%)] Loss: -571.082886\n",
      "Train Epoch: 181 [33792/54000 (63%)] Loss: -570.931885\n",
      "Train Epoch: 181 [45056/54000 (83%)] Loss: -565.268860\n",
      "    epoch          : 181\n",
      "    loss           : -566.2711930184994\n",
      "    ess            : 1.961800385196254\n",
      "    log_marginal   : 566.3040967257517\n",
      "    log_joint      : 773.8271501649101\n",
      "    val_loss       : -571.3072916666666\n",
      "    val_ess        : 1.9626937508583069\n",
      "    val_log_marginal: 571.3408610026041\n",
      "    val_log_joint  : 778.7391357421875\n",
      "Train Epoch: 182 [0/54000 (0%)] Loss: -556.728027\n",
      "Train Epoch: 182 [11264/54000 (21%)] Loss: -577.263855\n",
      "Train Epoch: 182 [22528/54000 (42%)] Loss: -572.738953\n",
      "Train Epoch: 182 [33792/54000 (63%)] Loss: -567.914307\n",
      "Train Epoch: 182 [45056/54000 (83%)] Loss: -546.270691\n",
      "    epoch          : 182\n",
      "    loss           : -567.598750852189\n",
      "    ess            : 1.9620224619811435\n",
      "    log_marginal   : 567.6316344063237\n",
      "    log_joint      : 775.0451297400133\n",
      "    val_loss       : -572.4066721598307\n",
      "    val_ess        : 1.9617637892564137\n",
      "    val_log_marginal: 572.4384002685547\n",
      "    val_log_joint  : 779.9143269856771\n",
      "Train Epoch: 183 [0/54000 (0%)] Loss: -562.895020\n",
      "Train Epoch: 183 [11264/54000 (21%)] Loss: -583.924683\n",
      "Train Epoch: 183 [22528/54000 (42%)] Loss: -560.302673\n",
      "Train Epoch: 183 [33792/54000 (63%)] Loss: -548.855591\n",
      "Train Epoch: 183 [45056/54000 (83%)] Loss: -573.862610\n",
      "    epoch          : 183\n",
      "    loss           : -565.822878279776\n",
      "    ess            : 1.961637796096082\n",
      "    log_marginal   : 565.8556662505528\n",
      "    log_joint      : 773.5054137031987\n",
      "    val_loss       : -567.1355743408203\n",
      "    val_ess        : 1.9600804646809895\n",
      "    val_log_marginal: 567.171641031901\n",
      "    val_log_joint  : 774.9262390136719\n",
      "Train Epoch: 184 [0/54000 (0%)] Loss: -573.785522\n",
      "Train Epoch: 184 [11264/54000 (21%)] Loss: -578.346130\n",
      "Train Epoch: 184 [22528/54000 (42%)] Loss: -574.242310\n",
      "Train Epoch: 184 [33792/54000 (63%)] Loss: -571.593445\n",
      "Train Epoch: 184 [45056/54000 (83%)] Loss: -537.952637\n",
      "    epoch          : 184\n",
      "    loss           : -567.428061431309\n",
      "    ess            : 1.9617077865690555\n",
      "    log_marginal   : 567.4605695616524\n",
      "    log_joint      : 774.9532787394974\n",
      "    val_loss       : -571.8522898356119\n",
      "    val_ess        : 1.9608194927374523\n",
      "    val_log_marginal: 571.8890584309896\n",
      "    val_log_joint  : 779.3783162434896\n",
      "Train Epoch: 185 [0/54000 (0%)] Loss: -593.444458\n",
      "Train Epoch: 185 [11264/54000 (21%)] Loss: -556.211792\n",
      "Train Epoch: 185 [22528/54000 (42%)] Loss: -588.036499\n",
      "Train Epoch: 185 [33792/54000 (63%)] Loss: -549.257568\n",
      "Train Epoch: 185 [45056/54000 (83%)] Loss: -554.534058\n",
      "    epoch          : 185\n",
      "    loss           : -568.322635866561\n",
      "    ess            : 1.9620950829307988\n",
      "    log_marginal   : 568.3538582279997\n",
      "    log_joint      : 775.8425811191775\n",
      "    val_loss       : -572.6629384358724\n",
      "    val_ess        : 1.9614109893639882\n",
      "    val_log_marginal: 572.6933848063151\n",
      "    val_log_joint  : 780.4344329833984\n",
      "Train Epoch: 186 [0/54000 (0%)] Loss: -592.877014\n",
      "Train Epoch: 186 [11264/54000 (21%)] Loss: -565.052734\n",
      "Train Epoch: 186 [22528/54000 (42%)] Loss: -543.855469\n",
      "Train Epoch: 186 [33792/54000 (63%)] Loss: -566.608887\n",
      "Train Epoch: 186 [45056/54000 (83%)] Loss: -596.314941\n",
      "    epoch          : 186\n",
      "    loss           : -569.2732566977447\n",
      "    ess            : 1.9614426336198483\n",
      "    log_marginal   : 569.3054325895489\n",
      "    log_joint      : 776.7892185427108\n",
      "    val_loss       : -573.4138997395834\n",
      "    val_ess        : 1.9567458430926006\n",
      "    val_log_marginal: 573.4488016764323\n",
      "    val_log_joint  : 780.7492370605469\n",
      "Train Epoch: 187 [0/54000 (0%)] Loss: -574.708862\n",
      "Train Epoch: 187 [11264/54000 (21%)] Loss: -552.997681\n",
      "Train Epoch: 187 [22528/54000 (42%)] Loss: -584.090454\n",
      "Train Epoch: 187 [33792/54000 (63%)] Loss: -567.211060\n",
      "Train Epoch: 187 [45056/54000 (83%)] Loss: -572.766846\n",
      "    epoch          : 187\n",
      "    loss           : -568.2331042019827\n",
      "    ess            : 1.9628859184822947\n",
      "    log_marginal   : 568.2640576632517\n",
      "    log_joint      : 775.8346286989608\n",
      "    val_loss       : -571.8242238362631\n",
      "    val_ess        : 1.9622261722882588\n",
      "    val_log_marginal: 571.8552398681641\n",
      "    val_log_joint  : 779.4454193115234\n",
      "Train Epoch: 188 [0/54000 (0%)] Loss: -566.803223\n",
      "Train Epoch: 188 [11264/54000 (21%)] Loss: -567.178589\n",
      "Train Epoch: 188 [22528/54000 (42%)] Loss: -555.384216\n",
      "Train Epoch: 188 [33792/54000 (63%)] Loss: -568.196106\n",
      "Train Epoch: 188 [45056/54000 (83%)] Loss: -568.353516\n",
      "    epoch          : 188\n",
      "    loss           : -569.5726306843308\n",
      "    ess            : 1.961487035706358\n",
      "    log_marginal   : 569.6050679908609\n",
      "    log_joint      : 777.015548418153\n",
      "    val_loss       : -573.7761586507162\n",
      "    val_ess        : 1.958535800377528\n",
      "    val_log_marginal: 573.8130086263021\n",
      "    val_log_joint  : 781.6354064941406\n",
      "Train Epoch: 189 [0/54000 (0%)] Loss: -581.775391\n",
      "Train Epoch: 189 [11264/54000 (21%)] Loss: -561.497192\n",
      "Train Epoch: 189 [22528/54000 (42%)] Loss: -546.786011\n",
      "Train Epoch: 189 [33792/54000 (63%)] Loss: -572.719666\n",
      "Train Epoch: 189 [45056/54000 (83%)] Loss: -562.245728\n",
      "    epoch          : 189\n",
      "    loss           : -570.0184550735186\n",
      "    ess            : 1.9613554815076433\n",
      "    log_marginal   : 570.0517647221403\n",
      "    log_joint      : 777.6596501188458\n",
      "    val_loss       : -574.0068359375\n",
      "    val_ess        : 1.9623657961686451\n",
      "    val_log_marginal: 574.0376536051432\n",
      "    val_log_joint  : 781.4540456136068\n",
      "Train Epoch: 190 [0/54000 (0%)] Loss: -574.396973\n",
      "Train Epoch: 190 [11264/54000 (21%)] Loss: -574.799255\n",
      "Train Epoch: 190 [22528/54000 (42%)] Loss: -580.347229\n",
      "Train Epoch: 190 [33792/54000 (63%)] Loss: -549.089966\n",
      "Train Epoch: 190 [45056/54000 (83%)] Loss: -551.967834\n",
      "    epoch          : 190\n",
      "    loss           : -569.9320051085274\n",
      "    ess            : 1.9610282340139713\n",
      "    log_marginal   : 569.9653268490198\n",
      "    log_joint      : 777.5582286906692\n",
      "    val_loss       : -573.6712799072266\n",
      "    val_ess        : 1.9602170685927074\n",
      "    val_log_marginal: 573.7056528727213\n",
      "    val_log_joint  : 781.5026346842448\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch190.pth ...\n",
      "Train Epoch: 191 [0/54000 (0%)] Loss: -555.598877\n",
      "Train Epoch: 191 [11264/54000 (21%)] Loss: -584.607544\n",
      "Train Epoch: 191 [22528/54000 (42%)] Loss: -570.972534\n",
      "Train Epoch: 191 [33792/54000 (63%)] Loss: -571.816528\n",
      "Train Epoch: 191 [45056/54000 (83%)] Loss: -588.384155\n",
      "    epoch          : 191\n",
      "    loss           : -570.9174539817953\n",
      "    ess            : 1.9618151041696656\n",
      "    log_marginal   : 570.9505361880896\n",
      "    log_joint      : 778.582687090028\n",
      "    val_loss       : -576.1043192545573\n",
      "    val_ess        : 1.96097527941068\n",
      "    val_log_marginal: 576.1372833251953\n",
      "    val_log_joint  : 783.5631917317709\n",
      "Train Epoch: 192 [0/54000 (0%)] Loss: -567.953857\n",
      "Train Epoch: 192 [11264/54000 (21%)] Loss: -570.610596\n",
      "Train Epoch: 192 [22528/54000 (42%)] Loss: -576.378174\n",
      "Train Epoch: 192 [33792/54000 (63%)] Loss: -558.903809\n",
      "Train Epoch: 192 [45056/54000 (83%)] Loss: -584.408997\n",
      "    epoch          : 192\n",
      "    loss           : -571.8804724351415\n",
      "    ess            : 1.9618467283698748\n",
      "    log_marginal   : 571.9129454414799\n",
      "    log_joint      : 779.5091535460274\n",
      "    val_loss       : -577.2455647786459\n",
      "    val_ess        : 1.9631346662839253\n",
      "    val_log_marginal: 577.2752838134766\n",
      "    val_log_joint  : 784.6100819905599\n",
      "Train Epoch: 193 [0/54000 (0%)] Loss: -591.251770\n",
      "Train Epoch: 193 [11264/54000 (21%)] Loss: -578.095276\n",
      "Train Epoch: 193 [22528/54000 (42%)] Loss: -589.310120\n",
      "Train Epoch: 193 [33792/54000 (63%)] Loss: -564.718140\n",
      "Train Epoch: 193 [45056/54000 (83%)] Loss: -555.691284\n",
      "    epoch          : 193\n",
      "    loss           : -570.1998302531692\n",
      "    ess            : 1.9597469129652347\n",
      "    log_marginal   : 570.235330833579\n",
      "    log_joint      : 777.8212136322597\n",
      "    val_loss       : -572.9587046305338\n",
      "    val_ess        : 1.9630402028560638\n",
      "    val_log_marginal: 572.9893747965494\n",
      "    val_log_joint  : 780.5375315348307\n",
      "Train Epoch: 194 [0/54000 (0%)] Loss: -563.957520\n",
      "Train Epoch: 194 [11264/54000 (21%)] Loss: -575.892456\n",
      "Train Epoch: 194 [22528/54000 (42%)] Loss: -593.509827\n",
      "Train Epoch: 194 [33792/54000 (63%)] Loss: -564.737366\n",
      "Train Epoch: 194 [45056/54000 (83%)] Loss: -554.249878\n",
      "    epoch          : 194\n",
      "    loss           : -571.9840272147701\n",
      "    ess            : 1.9610806883506056\n",
      "    log_marginal   : 572.017453751474\n",
      "    log_joint      : 779.6404770185362\n",
      "    val_loss       : -576.1430409749349\n",
      "    val_ess        : 1.9570823510487874\n",
      "    val_log_marginal: 576.1809234619141\n",
      "    val_log_joint  : 783.9840393066406\n",
      "Train Epoch: 195 [0/54000 (0%)] Loss: -564.457642\n",
      "Train Epoch: 195 [11264/54000 (21%)] Loss: -567.166504\n",
      "Train Epoch: 195 [22528/54000 (42%)] Loss: -586.407227\n",
      "Train Epoch: 195 [33792/54000 (63%)] Loss: -579.815491\n",
      "Train Epoch: 195 [45056/54000 (83%)] Loss: -547.641296\n",
      "    epoch          : 195\n",
      "    loss           : -572.8328304650648\n",
      "    ess            : 1.9614018303043437\n",
      "    log_marginal   : 572.8657975106869\n",
      "    log_joint      : 780.4680745826578\n",
      "    val_loss       : -576.7387898763021\n",
      "    val_ess        : 1.9612220923105876\n",
      "    val_log_marginal: 576.770497639974\n",
      "    val_log_joint  : 784.4027709960938\n",
      "Train Epoch: 196 [0/54000 (0%)] Loss: -555.190186\n",
      "Train Epoch: 196 [11264/54000 (21%)] Loss: -570.812988\n",
      "Train Epoch: 196 [22528/54000 (42%)] Loss: -576.070435\n",
      "Train Epoch: 196 [33792/54000 (63%)] Loss: -568.391968\n",
      "Train Epoch: 196 [45056/54000 (83%)] Loss: -581.602417\n",
      "    epoch          : 196\n",
      "    loss           : -573.5226181318175\n",
      "    ess            : 1.961215467947834\n",
      "    log_marginal   : 573.5558419857385\n",
      "    log_joint      : 781.0452817521005\n",
      "    val_loss       : -578.1083017985026\n",
      "    val_ess        : 1.9610355099042256\n",
      "    val_log_marginal: 578.1417897542318\n",
      "    val_log_joint  : 785.6540934244791\n",
      "Train Epoch: 197 [0/54000 (0%)] Loss: -583.407104\n",
      "Train Epoch: 197 [11264/54000 (21%)] Loss: -580.975525\n",
      "Train Epoch: 197 [22528/54000 (42%)] Loss: -585.063110\n",
      "Train Epoch: 197 [33792/54000 (63%)] Loss: -546.535156\n",
      "Train Epoch: 197 [45056/54000 (83%)] Loss: -586.173462\n",
      "    epoch          : 197\n",
      "    loss           : -573.491175813495\n",
      "    ess            : 1.9617695009933327\n",
      "    log_marginal   : 573.5237052485628\n",
      "    log_joint      : 781.0154793217497\n",
      "    val_loss       : -576.3174845377604\n",
      "    val_ess        : 1.9669503966967266\n",
      "    val_log_marginal: 576.344472249349\n",
      "    val_log_joint  : 783.6565653483073\n",
      "Train Epoch: 198 [0/54000 (0%)] Loss: -574.229370\n",
      "Train Epoch: 198 [11264/54000 (21%)] Loss: -575.984436\n",
      "Train Epoch: 198 [22528/54000 (42%)] Loss: -590.005615\n",
      "Train Epoch: 198 [33792/54000 (63%)] Loss: -582.821594\n",
      "Train Epoch: 198 [45056/54000 (83%)] Loss: -584.712463\n",
      "    epoch          : 198\n",
      "    loss           : -574.5036223789431\n",
      "    ess            : 1.962278109676433\n",
      "    log_marginal   : 574.5350169055866\n",
      "    log_joint      : 782.0951468989534\n",
      "    val_loss       : -577.907704671224\n",
      "    val_ess        : 1.9609389106432598\n",
      "    val_log_marginal: 577.9405568440756\n",
      "    val_log_joint  : 785.8132019042969\n",
      "Train Epoch: 199 [0/54000 (0%)] Loss: -581.160400\n",
      "Train Epoch: 199 [11264/54000 (21%)] Loss: -577.753479\n",
      "Train Epoch: 199 [22528/54000 (42%)] Loss: -595.805115\n",
      "Train Epoch: 199 [33792/54000 (63%)] Loss: -559.662720\n",
      "Train Epoch: 199 [45056/54000 (83%)] Loss: -575.838562\n",
      "    epoch          : 199\n",
      "    loss           : -574.6320426509066\n",
      "    ess            : 1.9606039209185906\n",
      "    log_marginal   : 574.6653879993366\n",
      "    log_joint      : 782.2124449531987\n",
      "    val_loss       : -578.3130289713541\n",
      "    val_ess        : 1.9588846961657207\n",
      "    val_log_marginal: 578.3471628824869\n",
      "    val_log_joint  : 786.0006612141927\n",
      "Train Epoch: 200 [0/54000 (0%)] Loss: -571.552124\n",
      "Train Epoch: 200 [11264/54000 (21%)] Loss: -607.638672\n",
      "Train Epoch: 200 [22528/54000 (42%)] Loss: -572.889954\n",
      "Train Epoch: 200 [33792/54000 (63%)] Loss: -580.459534\n",
      "Train Epoch: 200 [45056/54000 (83%)] Loss: -575.947083\n",
      "    epoch          : 200\n",
      "    loss           : -573.8618440448113\n",
      "    ess            : 1.961360144165327\n",
      "    log_marginal   : 573.8952596412515\n",
      "    log_joint      : 781.4846865096182\n",
      "    val_loss       : -576.4827219645182\n",
      "    val_ess        : 1.9588546752929688\n",
      "    val_log_marginal: 576.5187327067057\n",
      "    val_log_joint  : 784.2433369954427\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [0/54000 (0%)] Loss: -574.674072\n",
      "Train Epoch: 201 [11264/54000 (21%)] Loss: -574.912354\n",
      "Train Epoch: 201 [22528/54000 (42%)] Loss: -569.549500\n",
      "Train Epoch: 201 [33792/54000 (63%)] Loss: -568.246216\n",
      "Train Epoch: 201 [45056/54000 (83%)] Loss: -592.160339\n",
      "    epoch          : 201\n",
      "    loss           : -575.3241283488724\n",
      "    ess            : 1.9620090250699025\n",
      "    log_marginal   : 575.3564913767689\n",
      "    log_joint      : 782.8735437933004\n",
      "    val_loss       : -578.9472351074219\n",
      "    val_ess        : 1.9611399074395497\n",
      "    val_log_marginal: 578.9803924560547\n",
      "    val_log_joint  : 786.7614949544271\n",
      "Train Epoch: 202 [0/54000 (0%)] Loss: -581.111938\n",
      "Train Epoch: 202 [11264/54000 (21%)] Loss: -576.958130\n",
      "Train Epoch: 202 [22528/54000 (42%)] Loss: -569.203125\n",
      "Train Epoch: 202 [33792/54000 (63%)] Loss: -586.594971\n",
      "Train Epoch: 202 [45056/54000 (83%)] Loss: -580.155273\n",
      "    epoch          : 202\n",
      "    loss           : -575.9686204442438\n",
      "    ess            : 1.9601715274576872\n",
      "    log_marginal   : 576.002383825914\n",
      "    log_joint      : 783.5933786068323\n",
      "    val_loss       : -579.5486399332682\n",
      "    val_ess        : 1.958578844865163\n",
      "    val_log_marginal: 579.5813242594401\n",
      "    val_log_joint  : 787.0033569335938\n",
      "Train Epoch: 203 [0/54000 (0%)] Loss: -573.523987\n",
      "Train Epoch: 203 [11264/54000 (21%)] Loss: -569.208496\n",
      "Train Epoch: 203 [22528/54000 (42%)] Loss: -580.582031\n",
      "Train Epoch: 203 [33792/54000 (63%)] Loss: -593.927734\n",
      "Train Epoch: 203 [45056/54000 (83%)] Loss: -575.476685\n",
      "    epoch          : 203\n",
      "    loss           : -575.6011640440743\n",
      "    ess            : 1.9614223410498421\n",
      "    log_marginal   : 575.633224199403\n",
      "    log_joint      : 783.3436377183447\n",
      "    val_loss       : -578.9888356526693\n",
      "    val_ess        : 1.9615716934204102\n",
      "    val_log_marginal: 579.0210520426432\n",
      "    val_log_joint  : 786.5409444173177\n",
      "Train Epoch: 204 [0/54000 (0%)] Loss: -554.417969\n",
      "Train Epoch: 204 [11264/54000 (21%)] Loss: -584.333374\n",
      "Train Epoch: 204 [22528/54000 (42%)] Loss: -600.193115\n",
      "Train Epoch: 204 [33792/54000 (63%)] Loss: -566.402771\n",
      "Train Epoch: 204 [45056/54000 (83%)] Loss: -590.602905\n",
      "    epoch          : 204\n",
      "    loss           : -576.8436768729732\n",
      "    ess            : 1.9603781891318988\n",
      "    log_marginal   : 576.8763571685215\n",
      "    log_joint      : 784.3953863179909\n",
      "    val_loss       : -580.8209788004557\n",
      "    val_ess        : 1.9606671929359436\n",
      "    val_log_marginal: 580.8547210693359\n",
      "    val_log_joint  : 788.4368693033854\n",
      "Train Epoch: 205 [0/54000 (0%)] Loss: -580.293945\n",
      "Train Epoch: 205 [11264/54000 (21%)] Loss: -573.190796\n",
      "Train Epoch: 205 [22528/54000 (42%)] Loss: -574.882385\n",
      "Train Epoch: 205 [33792/54000 (63%)] Loss: -579.777710\n",
      "Train Epoch: 205 [45056/54000 (83%)] Loss: -594.918945\n",
      "    epoch          : 205\n",
      "    loss           : -577.5946281001253\n",
      "    ess            : 1.9600873825685032\n",
      "    log_marginal   : 577.6284427282945\n",
      "    log_joint      : 785.1351191682636\n",
      "    val_loss       : -581.1832631429037\n",
      "    val_ess        : 1.9583208660284679\n",
      "    val_log_marginal: 581.2168782552084\n",
      "    val_log_joint  : 788.6043955485026\n",
      "Train Epoch: 206 [0/54000 (0%)] Loss: -573.275513\n",
      "Train Epoch: 206 [11264/54000 (21%)] Loss: -567.038452\n",
      "Train Epoch: 206 [22528/54000 (42%)] Loss: -564.448364\n",
      "Train Epoch: 206 [33792/54000 (63%)] Loss: -558.666748\n",
      "Train Epoch: 206 [45056/54000 (83%)] Loss: -594.056641\n",
      "    epoch          : 206\n",
      "    loss           : -576.8702098918411\n",
      "    ess            : 1.9601528127238435\n",
      "    log_marginal   : 576.9046371747862\n",
      "    log_joint      : 784.4908021171138\n",
      "    val_loss       : -579.9163869222006\n",
      "    val_ess        : 1.9614306390285492\n",
      "    val_log_marginal: 579.948486328125\n",
      "    val_log_joint  : 787.3017730712891\n",
      "Train Epoch: 207 [0/54000 (0%)] Loss: -577.203125\n",
      "Train Epoch: 207 [11264/54000 (21%)] Loss: -562.508667\n",
      "Train Epoch: 207 [22528/54000 (42%)] Loss: -575.543213\n",
      "Train Epoch: 207 [33792/54000 (63%)] Loss: -587.730530\n",
      "Train Epoch: 207 [45056/54000 (83%)] Loss: -570.731445\n",
      "    epoch          : 207\n",
      "    loss           : -578.0783731712485\n",
      "    ess            : 1.96000489086475\n",
      "    log_marginal   : 578.113233458321\n",
      "    log_joint      : 785.77601767486\n",
      "    val_loss       : -582.4138387044271\n",
      "    val_ess        : 1.9593879183133442\n",
      "    val_log_marginal: 582.4476267496744\n",
      "    val_log_joint  : 790.1951344807943\n",
      "Train Epoch: 208 [0/54000 (0%)] Loss: -580.441162\n",
      "Train Epoch: 208 [11264/54000 (21%)] Loss: -573.047485\n",
      "Train Epoch: 208 [22528/54000 (42%)] Loss: -572.236206\n",
      "Train Epoch: 208 [33792/54000 (63%)] Loss: -557.499634\n",
      "Train Epoch: 208 [45056/54000 (83%)] Loss: -559.494507\n",
      "    epoch          : 208\n",
      "    loss           : -578.6194475281914\n",
      "    ess            : 1.960140218149941\n",
      "    log_marginal   : 578.6539128141583\n",
      "    log_joint      : 786.3010789403376\n",
      "    val_loss       : -582.1912434895834\n",
      "    val_ess        : 1.9614859422047932\n",
      "    val_log_marginal: 582.2226003011068\n",
      "    val_log_joint  : 789.8363698323568\n",
      "Train Epoch: 209 [0/54000 (0%)] Loss: -539.174927\n",
      "Train Epoch: 209 [11264/54000 (21%)] Loss: -583.187256\n",
      "Train Epoch: 209 [22528/54000 (42%)] Loss: -600.388550\n",
      "Train Epoch: 209 [33792/54000 (63%)] Loss: -561.143921\n",
      "Train Epoch: 209 [45056/54000 (83%)] Loss: -556.049927\n",
      "    epoch          : 209\n",
      "    loss           : -578.6531803922833\n",
      "    ess            : 1.9603065645919655\n",
      "    log_marginal   : 578.6870537523953\n",
      "    log_joint      : 786.2514803904407\n",
      "    val_loss       : -582.3983815511068\n",
      "    val_ess        : 1.9598797659079235\n",
      "    val_log_marginal: 582.4331715901693\n",
      "    val_log_joint  : 789.9155120849609\n",
      "Train Epoch: 210 [0/54000 (0%)] Loss: -580.576538\n",
      "Train Epoch: 210 [11264/54000 (21%)] Loss: -549.278687\n",
      "Train Epoch: 210 [22528/54000 (42%)] Loss: -597.735962\n",
      "Train Epoch: 210 [33792/54000 (63%)] Loss: -587.624268\n",
      "Train Epoch: 210 [45056/54000 (83%)] Loss: -571.075256\n",
      "    epoch          : 210\n",
      "    loss           : -578.9778045078493\n",
      "    ess            : 1.961851917347818\n",
      "    log_marginal   : 579.010427798865\n",
      "    log_joint      : 786.638442129459\n",
      "    val_loss       : -583.5683135986328\n",
      "    val_ess        : 1.9614028533299763\n",
      "    val_log_marginal: 583.6010284423828\n",
      "    val_log_joint  : 791.1472218831381\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch210.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 211 [0/54000 (0%)] Loss: -591.023376\n",
      "Train Epoch: 211 [11264/54000 (21%)] Loss: -570.670654\n",
      "Train Epoch: 211 [22528/54000 (42%)] Loss: -582.059082\n",
      "Train Epoch: 211 [33792/54000 (63%)] Loss: -586.811951\n",
      "Train Epoch: 211 [45056/54000 (83%)] Loss: -573.365356\n",
      "    epoch          : 211\n",
      "    loss           : -579.9630616385982\n",
      "    ess            : 1.9612366995721493\n",
      "    log_marginal   : 579.9958956736439\n",
      "    log_joint      : 787.5871754772259\n",
      "    val_loss       : -584.6677652994791\n",
      "    val_ess        : 1.9602884550889332\n",
      "    val_log_marginal: 584.6998647054037\n",
      "    val_log_joint  : 792.395009358724\n",
      "Train Epoch: 212 [0/54000 (0%)] Loss: -604.393921\n",
      "Train Epoch: 212 [11264/54000 (21%)] Loss: -600.865845\n",
      "Train Epoch: 212 [22528/54000 (42%)] Loss: -580.860535\n",
      "Train Epoch: 212 [33792/54000 (63%)] Loss: -581.943604\n",
      "Train Epoch: 212 [45056/54000 (83%)] Loss: -528.951172\n",
      "    epoch          : 212\n",
      "    loss           : -579.305628938495\n",
      "    ess            : 1.9611797962548598\n",
      "    log_marginal   : 579.3389092211453\n",
      "    log_joint      : 787.0391972379864\n",
      "    val_loss       : -580.4765319824219\n",
      "    val_ess        : 1.9556150337060292\n",
      "    val_log_marginal: 580.5168965657552\n",
      "    val_log_joint  : 788.3163096110026\n",
      "Train Epoch: 213 [0/54000 (0%)] Loss: -567.384277\n",
      "Train Epoch: 213 [11264/54000 (21%)] Loss: -599.815796\n",
      "Train Epoch: 213 [22528/54000 (42%)] Loss: -597.555908\n",
      "Train Epoch: 213 [33792/54000 (63%)] Loss: -560.855103\n",
      "Train Epoch: 213 [45056/54000 (83%)] Loss: -571.337402\n",
      "    epoch          : 213\n",
      "    loss           : -579.6019718961895\n",
      "    ess            : 1.9605723135876205\n",
      "    log_marginal   : 579.6366698067143\n",
      "    log_joint      : 787.3649666264372\n",
      "    val_loss       : -584.5209808349609\n",
      "    val_ess        : 1.9648643533388774\n",
      "    val_log_marginal: 584.5502115885416\n",
      "    val_log_joint  : 792.0754089355469\n",
      "Train Epoch: 214 [0/54000 (0%)] Loss: -571.803040\n",
      "Train Epoch: 214 [11264/54000 (21%)] Loss: -611.197876\n",
      "Train Epoch: 214 [22528/54000 (42%)] Loss: -567.357422\n",
      "Train Epoch: 214 [33792/54000 (63%)] Loss: -594.667236\n",
      "Train Epoch: 214 [45056/54000 (83%)] Loss: -604.319092\n",
      "    epoch          : 214\n",
      "    loss           : -581.4025988308889\n",
      "    ess            : 1.9610200378130067\n",
      "    log_marginal   : 581.4364301573555\n",
      "    log_joint      : 789.0577565319134\n",
      "    val_loss       : -585.3348388671875\n",
      "    val_ess        : 1.9603423873583476\n",
      "    val_log_marginal: 585.3703206380209\n",
      "    val_log_joint  : 792.9379577636719\n",
      "Train Epoch: 215 [0/54000 (0%)] Loss: -604.450073\n",
      "Train Epoch: 215 [11264/54000 (21%)] Loss: -595.076294\n",
      "Train Epoch: 215 [22528/54000 (42%)] Loss: -591.961548\n",
      "Train Epoch: 215 [33792/54000 (63%)] Loss: -582.222839\n",
      "Train Epoch: 215 [45056/54000 (83%)] Loss: -574.755371\n",
      "    epoch          : 215\n",
      "    loss           : -581.2880577231354\n",
      "    ess            : 1.9599091545590814\n",
      "    log_marginal   : 581.3233032226562\n",
      "    log_joint      : 788.9340509378685\n",
      "    val_loss       : -583.8297119140625\n",
      "    val_ess        : 1.963744431734085\n",
      "    val_log_marginal: 583.8593139648438\n",
      "    val_log_joint  : 791.2706146240234\n",
      "Train Epoch: 216 [0/54000 (0%)] Loss: -561.730225\n",
      "Train Epoch: 216 [11264/54000 (21%)] Loss: -581.739136\n",
      "Train Epoch: 216 [22528/54000 (42%)] Loss: -574.980408\n",
      "Train Epoch: 216 [33792/54000 (63%)] Loss: -584.956543\n",
      "Train Epoch: 216 [45056/54000 (83%)] Loss: -591.386475\n",
      "    epoch          : 216\n",
      "    loss           : -581.3468501252948\n",
      "    ess            : 1.9606062949828382\n",
      "    log_marginal   : 581.3802893296728\n",
      "    log_joint      : 789.0432900482754\n",
      "    val_loss       : -585.6004638671875\n",
      "    val_ess        : 1.961090753475825\n",
      "    val_log_marginal: 585.6311696370443\n",
      "    val_log_joint  : 793.3329060872396\n",
      "Train Epoch: 217 [0/54000 (0%)] Loss: -578.612671\n",
      "Train Epoch: 217 [11264/54000 (21%)] Loss: -570.769043\n",
      "Train Epoch: 217 [22528/54000 (42%)] Loss: -564.406189\n",
      "Train Epoch: 217 [33792/54000 (63%)] Loss: -567.107056\n",
      "Train Epoch: 217 [45056/54000 (83%)] Loss: -580.099487\n",
      "    epoch          : 217\n",
      "    loss           : -582.5903907631928\n",
      "    ess            : 1.9593745560016271\n",
      "    log_marginal   : 582.6253253288988\n",
      "    log_joint      : 790.2790158829599\n",
      "    val_loss       : -586.7240041097006\n",
      "    val_ess        : 1.957899808883667\n",
      "    val_log_marginal: 586.7578582763672\n",
      "    val_log_joint  : 794.2028859456381\n",
      "Train Epoch: 218 [0/54000 (0%)] Loss: -593.510437\n",
      "Train Epoch: 218 [11264/54000 (21%)] Loss: -573.845337\n",
      "Train Epoch: 218 [22528/54000 (42%)] Loss: -600.523682\n",
      "Train Epoch: 218 [33792/54000 (63%)] Loss: -565.076843\n",
      "Train Epoch: 218 [45056/54000 (83%)] Loss: -586.335083\n",
      "    epoch          : 218\n",
      "    loss           : -582.4619324882076\n",
      "    ess            : 1.9607942396739744\n",
      "    log_marginal   : 582.4951672823923\n",
      "    log_joint      : 790.1958790905071\n",
      "    val_loss       : -585.1343078613281\n",
      "    val_ess        : 1.959168980518977\n",
      "    val_log_marginal: 585.1680196126302\n",
      "    val_log_joint  : 793.0226033528646\n",
      "Train Epoch: 219 [0/54000 (0%)] Loss: -580.201660\n",
      "Train Epoch: 219 [11264/54000 (21%)] Loss: -575.461670\n",
      "Train Epoch: 219 [22528/54000 (42%)] Loss: -558.469666\n",
      "Train Epoch: 219 [33792/54000 (63%)] Loss: -595.694763\n",
      "Train Epoch: 219 [45056/54000 (83%)] Loss: -580.044250\n",
      "    epoch          : 219\n",
      "    loss           : -582.7710479160525\n",
      "    ess            : 1.9591539434666903\n",
      "    log_marginal   : 582.8071219966097\n",
      "    log_joint      : 790.4831496904482\n",
      "    val_loss       : -587.1994272867838\n",
      "    val_ess        : 1.956274300813675\n",
      "    val_log_marginal: 587.2373606363932\n",
      "    val_log_joint  : 794.8803456624349\n",
      "Train Epoch: 220 [0/54000 (0%)] Loss: -588.106567\n",
      "Train Epoch: 220 [11264/54000 (21%)] Loss: -586.660645\n",
      "Train Epoch: 220 [22528/54000 (42%)] Loss: -586.677734\n",
      "Train Epoch: 220 [33792/54000 (63%)] Loss: -586.151245\n",
      "Train Epoch: 220 [45056/54000 (83%)] Loss: -589.031494\n",
      "    epoch          : 220\n",
      "    loss           : -583.8941984356575\n",
      "    ess            : 1.9601961531729069\n",
      "    log_marginal   : 583.9284034585053\n",
      "    log_joint      : 791.5120112581073\n",
      "    val_loss       : -588.1711171468099\n",
      "    val_ess        : 1.9621445536613464\n",
      "    val_log_marginal: 588.2029876708984\n",
      "    val_log_joint  : 795.6629587809244\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch220.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 221 [0/54000 (0%)] Loss: -568.478577\n",
      "Train Epoch: 221 [11264/54000 (21%)] Loss: -609.902466\n",
      "Train Epoch: 221 [22528/54000 (42%)] Loss: -583.323242\n",
      "Train Epoch: 221 [33792/54000 (63%)] Loss: -569.393188\n",
      "Train Epoch: 221 [45056/54000 (83%)] Loss: -608.975708\n",
      "    epoch          : 221\n",
      "    loss           : -584.0609015698703\n",
      "    ess            : 1.9600591175961044\n",
      "    log_marginal   : 584.0955505371094\n",
      "    log_joint      : 791.7470622512529\n",
      "    val_loss       : -587.4885965983073\n",
      "    val_ess        : 1.9558728138605754\n",
      "    val_log_marginal: 587.5269470214844\n",
      "    val_log_joint  : 794.9635874430338\n",
      "Train Epoch: 222 [0/54000 (0%)] Loss: -596.263184\n",
      "Train Epoch: 222 [11264/54000 (21%)] Loss: -604.135437\n",
      "Train Epoch: 222 [22528/54000 (42%)] Loss: -587.025757\n",
      "Train Epoch: 222 [33792/54000 (63%)] Loss: -574.834473\n",
      "Train Epoch: 222 [45056/54000 (83%)] Loss: -576.644653\n",
      "    epoch          : 222\n",
      "    loss           : -584.0523025224794\n",
      "    ess            : 1.959267092200945\n",
      "    log_marginal   : 584.0876182700104\n",
      "    log_joint      : 791.7185749557783\n",
      "    val_loss       : -587.2826283772787\n",
      "    val_ess        : 1.9597082833449047\n",
      "    val_log_marginal: 587.3161315917969\n",
      "    val_log_joint  : 794.9267120361328\n",
      "Train Epoch: 223 [0/54000 (0%)] Loss: -586.547668\n",
      "Train Epoch: 223 [11264/54000 (21%)] Loss: -593.172485\n",
      "Train Epoch: 223 [22528/54000 (42%)] Loss: -587.162720\n",
      "Train Epoch: 223 [33792/54000 (63%)] Loss: -572.876465\n",
      "Train Epoch: 223 [45056/54000 (83%)] Loss: -582.787109\n",
      "    epoch          : 223\n",
      "    loss           : -584.8421199006855\n",
      "    ess            : 1.960481494102838\n",
      "    log_marginal   : 584.875871190485\n",
      "    log_joint      : 792.5648959177845\n",
      "    val_loss       : -588.6660817464193\n",
      "    val_ess        : 1.9584544400374095\n",
      "    val_log_marginal: 588.7013244628906\n",
      "    val_log_joint  : 796.4682362874349\n",
      "Train Epoch: 224 [0/54000 (0%)] Loss: -603.014038\n",
      "Train Epoch: 224 [11264/54000 (21%)] Loss: -581.126343\n",
      "Train Epoch: 224 [22528/54000 (42%)] Loss: -580.335083\n",
      "Train Epoch: 224 [33792/54000 (63%)] Loss: -574.550415\n",
      "Train Epoch: 224 [45056/54000 (83%)] Loss: -591.989380\n",
      "    epoch          : 224\n",
      "    loss           : -585.6633559892763\n",
      "    ess            : 1.9597037232147072\n",
      "    log_marginal   : 585.6988162634508\n",
      "    log_joint      : 793.3810810592939\n",
      "    val_loss       : -589.3360900878906\n",
      "    val_ess        : 1.9578455885251362\n",
      "    val_log_marginal: 589.3704477945963\n",
      "    val_log_joint  : 797.0592905680338\n",
      "Train Epoch: 225 [0/54000 (0%)] Loss: -598.287354\n",
      "Train Epoch: 225 [11264/54000 (21%)] Loss: -604.590210\n",
      "Train Epoch: 225 [22528/54000 (42%)] Loss: -582.397766\n",
      "Train Epoch: 225 [33792/54000 (63%)] Loss: -588.214844\n",
      "Train Epoch: 225 [45056/54000 (83%)] Loss: -566.091919\n",
      "    epoch          : 225\n",
      "    loss           : -583.6786061412884\n",
      "    ess            : 1.9599733138984103\n",
      "    log_marginal   : 583.7124898658609\n",
      "    log_joint      : 791.4406611604511\n",
      "    val_loss       : -586.6068522135416\n",
      "    val_ess        : 1.9564715027809143\n",
      "    val_log_marginal: 586.6464538574219\n",
      "    val_log_joint  : 794.4930114746094\n",
      "Train Epoch: 226 [0/54000 (0%)] Loss: -596.422302\n",
      "Train Epoch: 226 [11264/54000 (21%)] Loss: -575.631958\n",
      "Train Epoch: 226 [22528/54000 (42%)] Loss: -588.550293\n",
      "Train Epoch: 226 [33792/54000 (63%)] Loss: -579.886780\n",
      "Train Epoch: 226 [45056/54000 (83%)] Loss: -576.456360\n",
      "    epoch          : 226\n",
      "    loss           : -585.513107011903\n",
      "    ess            : 1.9589739599317875\n",
      "    log_marginal   : 585.549539817954\n",
      "    log_joint      : 793.2413900123453\n",
      "    val_loss       : -589.8249918619791\n",
      "    val_ess        : 1.9591665367285411\n",
      "    val_log_marginal: 589.8623708089193\n",
      "    val_log_joint  : 797.3012542724609\n",
      "Train Epoch: 227 [0/54000 (0%)] Loss: -576.815552\n",
      "Train Epoch: 227 [11264/54000 (21%)] Loss: -570.127197\n",
      "Train Epoch: 227 [22528/54000 (42%)] Loss: -592.792786\n",
      "Train Epoch: 227 [33792/54000 (63%)] Loss: -613.429077\n",
      "Train Epoch: 227 [45056/54000 (83%)] Loss: -569.013855\n",
      "    epoch          : 227\n",
      "    loss           : -586.4511879974941\n",
      "    ess            : 1.9590066356478997\n",
      "    log_marginal   : 586.4862002966539\n",
      "    log_joint      : 794.1473544138782\n",
      "    val_loss       : -589.4424692789713\n",
      "    val_ess        : 1.9569319784641266\n",
      "    val_log_marginal: 589.4789632161459\n",
      "    val_log_joint  : 797.0140329996744\n",
      "Train Epoch: 228 [0/54000 (0%)] Loss: -565.583618\n",
      "Train Epoch: 228 [11264/54000 (21%)] Loss: -571.833984\n",
      "Train Epoch: 228 [22528/54000 (42%)] Loss: -594.427246\n",
      "Train Epoch: 228 [33792/54000 (63%)] Loss: -589.657715\n",
      "Train Epoch: 228 [45056/54000 (83%)] Loss: -607.284363\n",
      "    epoch          : 228\n",
      "    loss           : -586.6341990344929\n",
      "    ess            : 1.9599102364396148\n",
      "    log_marginal   : 586.669147995283\n",
      "    log_joint      : 794.3899311569502\n",
      "    val_loss       : -590.4960581461588\n",
      "    val_ess        : 1.9627139071623485\n",
      "    val_log_marginal: 590.5271911621094\n",
      "    val_log_joint  : 798.1760813395182\n",
      "Train Epoch: 229 [0/54000 (0%)] Loss: -588.980042\n",
      "Train Epoch: 229 [11264/54000 (21%)] Loss: -599.659302\n",
      "Train Epoch: 229 [22528/54000 (42%)] Loss: -587.556519\n",
      "Train Epoch: 229 [33792/54000 (63%)] Loss: -596.461731\n",
      "Train Epoch: 229 [45056/54000 (83%)] Loss: -572.817139\n",
      "    epoch          : 229\n",
      "    loss           : -587.434382024801\n",
      "    ess            : 1.959881969217984\n",
      "    log_marginal   : 587.4686405973614\n",
      "    log_joint      : 795.1276406342129\n",
      "    val_loss       : -591.6710408528646\n",
      "    val_ess        : 1.960190047820409\n",
      "    val_log_marginal: 591.7070465087891\n",
      "    val_log_joint  : 799.1748860677084\n",
      "Train Epoch: 230 [0/54000 (0%)] Loss: -593.868408\n",
      "Train Epoch: 230 [11264/54000 (21%)] Loss: -577.329163\n",
      "Train Epoch: 230 [22528/54000 (42%)] Loss: -585.335205\n",
      "Train Epoch: 230 [33792/54000 (63%)] Loss: -609.655884\n",
      "Train Epoch: 230 [45056/54000 (83%)] Loss: -588.270081\n",
      "    epoch          : 230\n",
      "    loss           : -587.980545331847\n",
      "    ess            : 1.9599372081036837\n",
      "    log_marginal   : 588.0150278919148\n",
      "    log_joint      : 795.726067884913\n",
      "    val_loss       : -591.9351552327474\n",
      "    val_ess        : 1.9558637241522472\n",
      "    val_log_marginal: 591.9751637776693\n",
      "    val_log_joint  : 799.9444173177084\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch230.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 231 [0/54000 (0%)] Loss: -592.391357\n",
      "Train Epoch: 231 [11264/54000 (21%)] Loss: -596.313354\n",
      "Train Epoch: 231 [22528/54000 (42%)] Loss: -581.205566\n",
      "Train Epoch: 231 [33792/54000 (63%)] Loss: -583.484497\n",
      "Train Epoch: 231 [45056/54000 (83%)] Loss: -616.943176\n",
      "    epoch          : 231\n",
      "    loss           : -587.7558254026017\n",
      "    ess            : 1.9596249427435533\n",
      "    log_marginal   : 587.7903471172981\n",
      "    log_joint      : 795.4854459942512\n",
      "    val_loss       : -590.1497650146484\n",
      "    val_ess        : 1.9590482314427693\n",
      "    val_log_marginal: 590.1855010986328\n",
      "    val_log_joint  : 797.9297332763672\n",
      "Train Epoch: 232 [0/54000 (0%)] Loss: -571.748413\n",
      "Train Epoch: 232 [11264/54000 (21%)] Loss: -581.485413\n",
      "Train Epoch: 232 [22528/54000 (42%)] Loss: -573.495239\n",
      "Train Epoch: 232 [33792/54000 (63%)] Loss: -585.183533\n",
      "Train Epoch: 232 [45056/54000 (83%)] Loss: -597.803589\n",
      "    epoch          : 232\n",
      "    loss           : -588.138030430056\n",
      "    ess            : 1.9601404082100347\n",
      "    log_marginal   : 588.172565964033\n",
      "    log_joint      : 795.8653385954083\n",
      "    val_loss       : -592.7822214762369\n",
      "    val_ess        : 1.957716276248296\n",
      "    val_log_marginal: 592.8186391194662\n",
      "    val_log_joint  : 800.2779337565104\n",
      "Train Epoch: 233 [0/54000 (0%)] Loss: -596.575012\n",
      "Train Epoch: 233 [11264/54000 (21%)] Loss: -587.553711\n",
      "Train Epoch: 233 [22528/54000 (42%)] Loss: -589.643433\n",
      "Train Epoch: 233 [33792/54000 (63%)] Loss: -588.126831\n",
      "Train Epoch: 233 [45056/54000 (83%)] Loss: -596.429688\n",
      "    epoch          : 233\n",
      "    loss           : -589.0529842736586\n",
      "    ess            : 1.9601251269286533\n",
      "    log_marginal   : 589.0870965921654\n",
      "    log_joint      : 796.7660125156618\n",
      "    val_loss       : -593.999521891276\n",
      "    val_ess        : 1.9614564975102742\n",
      "    val_log_marginal: 594.0333353678385\n",
      "    val_log_joint  : 801.5477447509766\n",
      "Train Epoch: 234 [0/54000 (0%)] Loss: -576.508667\n",
      "Train Epoch: 234 [11264/54000 (21%)] Loss: -588.649048\n",
      "Train Epoch: 234 [22528/54000 (42%)] Loss: -575.534790\n",
      "Train Epoch: 234 [33792/54000 (63%)] Loss: -573.963989\n",
      "Train Epoch: 234 [45056/54000 (83%)] Loss: -585.913696\n",
      "    epoch          : 234\n",
      "    loss           : -588.5830665444428\n",
      "    ess            : 1.9595258966931757\n",
      "    log_marginal   : 588.6174719468603\n",
      "    log_joint      : 796.3274939195165\n",
      "    val_loss       : -591.5076853434244\n",
      "    val_ess        : 1.9600965678691864\n",
      "    val_log_marginal: 591.5419972737631\n",
      "    val_log_joint  : 799.5002644856771\n",
      "Train Epoch: 235 [0/54000 (0%)] Loss: -586.951050\n",
      "Train Epoch: 235 [11264/54000 (21%)] Loss: -565.171997\n",
      "Train Epoch: 235 [22528/54000 (42%)] Loss: -590.555359\n",
      "Train Epoch: 235 [33792/54000 (63%)] Loss: -611.744995\n",
      "Train Epoch: 235 [45056/54000 (83%)] Loss: -627.565979\n",
      "    epoch          : 235\n",
      "    loss           : -588.9932452507738\n",
      "    ess            : 1.9593073017192337\n",
      "    log_marginal   : 589.027699596477\n",
      "    log_joint      : 796.7812995190891\n",
      "    val_loss       : -594.2340799967448\n",
      "    val_ess        : 1.9586641987164815\n",
      "    val_log_marginal: 594.2692209879557\n",
      "    val_log_joint  : 801.8563232421875\n",
      "Train Epoch: 236 [0/54000 (0%)] Loss: -597.061035\n",
      "Train Epoch: 236 [11264/54000 (21%)] Loss: -578.107300\n",
      "Train Epoch: 236 [22528/54000 (42%)] Loss: -593.063538\n",
      "Train Epoch: 236 [33792/54000 (63%)] Loss: -587.749878\n",
      "Train Epoch: 236 [45056/54000 (83%)] Loss: -592.045044\n",
      "    epoch          : 236\n",
      "    loss           : -590.4157611199145\n",
      "    ess            : 1.9596367129739725\n",
      "    log_marginal   : 590.4506674712559\n",
      "    log_joint      : 798.1047121443838\n",
      "    val_loss       : -594.3702494303385\n",
      "    val_ess        : 1.9644288619359334\n",
      "    val_log_marginal: 594.4021352132162\n",
      "    val_log_joint  : 801.9870147705078\n",
      "Train Epoch: 237 [0/54000 (0%)] Loss: -602.201904\n",
      "Train Epoch: 237 [11264/54000 (21%)] Loss: -603.926147\n",
      "Train Epoch: 237 [22528/54000 (42%)] Loss: -585.172729\n",
      "Train Epoch: 237 [33792/54000 (63%)] Loss: -607.254944\n",
      "Train Epoch: 237 [45056/54000 (83%)] Loss: -604.388428\n",
      "    epoch          : 237\n",
      "    loss           : -590.0739820948187\n",
      "    ess            : 1.9607375500337132\n",
      "    log_marginal   : 590.1082314545254\n",
      "    log_joint      : 797.6616579451651\n",
      "    val_loss       : -593.4795227050781\n",
      "    val_ess        : 1.9600863754749298\n",
      "    val_log_marginal: 593.5150451660156\n",
      "    val_log_joint  : 801.2034200032552\n",
      "Train Epoch: 238 [0/54000 (0%)] Loss: -581.402649\n",
      "Train Epoch: 238 [11264/54000 (21%)] Loss: -584.742920\n",
      "Train Epoch: 238 [22528/54000 (42%)] Loss: -586.854614\n",
      "Train Epoch: 238 [33792/54000 (63%)] Loss: -593.336060\n",
      "Train Epoch: 238 [45056/54000 (83%)] Loss: -567.543701\n",
      "    epoch          : 238\n",
      "    loss           : -590.4238494297243\n",
      "    ess            : 1.9592362327395745\n",
      "    log_marginal   : 590.4593747696787\n",
      "    log_joint      : 798.1878984559257\n",
      "    val_loss       : -594.1760915120443\n",
      "    val_ess        : 1.9595965147018433\n",
      "    val_log_marginal: 594.209238688151\n",
      "    val_log_joint  : 801.8024190266927\n",
      "Train Epoch: 239 [0/54000 (0%)] Loss: -570.934753\n",
      "Train Epoch: 239 [11264/54000 (21%)] Loss: -598.496582\n",
      "Train Epoch: 239 [22528/54000 (42%)] Loss: -581.346802\n",
      "Train Epoch: 239 [33792/54000 (63%)] Loss: -579.885193\n",
      "Train Epoch: 239 [45056/54000 (83%)] Loss: -605.528931\n",
      "    epoch          : 239\n",
      "    loss           : -591.7112064001695\n",
      "    ess            : 1.9593658469757944\n",
      "    log_marginal   : 591.747154955594\n",
      "    log_joint      : 799.4085595472803\n",
      "    val_loss       : -596.3435363769531\n",
      "    val_ess        : 1.9593853155771892\n",
      "    val_log_marginal: 596.3769378662109\n",
      "    val_log_joint  : 803.9684092203776\n",
      "Train Epoch: 240 [0/54000 (0%)] Loss: -583.492432\n",
      "Train Epoch: 240 [11264/54000 (21%)] Loss: -618.401794\n",
      "Train Epoch: 240 [22528/54000 (42%)] Loss: -581.774780\n",
      "Train Epoch: 240 [33792/54000 (63%)] Loss: -605.076721\n",
      "Train Epoch: 240 [45056/54000 (83%)] Loss: -596.223511\n",
      "    epoch          : 240\n",
      "    loss           : -591.3528833929098\n",
      "    ess            : 1.9595579887336154\n",
      "    log_marginal   : 591.3879918512308\n",
      "    log_joint      : 799.0359779213959\n",
      "    val_loss       : -593.3091837565104\n",
      "    val_ess        : 1.9587997794151306\n",
      "    val_log_marginal: 593.3443298339844\n",
      "    val_log_joint  : 800.9662272135416\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch240.pth ...\n",
      "Train Epoch: 241 [0/54000 (0%)] Loss: -611.431580\n",
      "Train Epoch: 241 [11264/54000 (21%)] Loss: -594.525391\n",
      "Train Epoch: 241 [22528/54000 (42%)] Loss: -583.770264\n",
      "Train Epoch: 241 [33792/54000 (63%)] Loss: -600.269958\n",
      "Train Epoch: 241 [45056/54000 (83%)] Loss: -596.416504\n",
      "    epoch          : 241\n",
      "    loss           : -591.6628291292011\n",
      "    ess            : 1.9597603183872294\n",
      "    log_marginal   : 591.6977279950987\n",
      "    log_joint      : 799.333063665426\n",
      "    val_loss       : -595.9969838460287\n",
      "    val_ess        : 1.9589946667353313\n",
      "    val_log_marginal: 596.0336252848307\n",
      "    val_log_joint  : 803.7604726155599\n",
      "Train Epoch: 242 [0/54000 (0%)] Loss: -608.390076\n",
      "Train Epoch: 242 [11264/54000 (21%)] Loss: -577.145020\n",
      "Train Epoch: 242 [22528/54000 (42%)] Loss: -592.884155\n",
      "Train Epoch: 242 [33792/54000 (63%)] Loss: -591.086121\n",
      "Train Epoch: 242 [45056/54000 (83%)] Loss: -573.302612\n",
      "    epoch          : 242\n",
      "    loss           : -592.784285059515\n",
      "    ess            : 1.9585503497213688\n",
      "    log_marginal   : 592.8209821593086\n",
      "    log_joint      : 800.4887499539358\n",
      "    val_loss       : -596.9913991292318\n",
      "    val_ess        : 1.9602365295092266\n",
      "    val_log_marginal: 597.0251617431641\n",
      "    val_log_joint  : 804.8120524088541\n",
      "Train Epoch: 243 [0/54000 (0%)] Loss: -588.931458\n",
      "Train Epoch: 243 [11264/54000 (21%)] Loss: -580.632812\n",
      "Train Epoch: 243 [22528/54000 (42%)] Loss: -565.287903\n",
      "Train Epoch: 243 [33792/54000 (63%)] Loss: -612.977051\n",
      "Train Epoch: 243 [45056/54000 (83%)] Loss: -604.564392\n",
      "    epoch          : 243\n",
      "    loss           : -592.4337584297612\n",
      "    ess            : 1.9584917729755618\n",
      "    log_marginal   : 592.4704774100826\n",
      "    log_joint      : 800.2657660718235\n",
      "    val_loss       : -595.5507761637369\n",
      "    val_ess        : 1.9581391910711925\n",
      "    val_log_marginal: 595.5874837239584\n",
      "    val_log_joint  : 803.2380523681641\n",
      "Train Epoch: 244 [0/54000 (0%)] Loss: -592.360474\n",
      "Train Epoch: 244 [11264/54000 (21%)] Loss: -597.217651\n",
      "Train Epoch: 244 [22528/54000 (42%)] Loss: -606.516357\n",
      "Train Epoch: 244 [33792/54000 (63%)] Loss: -594.468872\n",
      "Train Epoch: 244 [45056/54000 (83%)] Loss: -593.239197\n",
      "    epoch          : 244\n",
      "    loss           : -592.9692342506265\n",
      "    ess            : 1.9585481184833455\n",
      "    log_marginal   : 593.0053664873232\n",
      "    log_joint      : 800.7279496102963\n",
      "    val_loss       : -597.5376332600912\n",
      "    val_ess        : 1.9590010046958923\n",
      "    val_log_marginal: 597.5723571777344\n",
      "    val_log_joint  : 805.1804911295573\n",
      "Train Epoch: 245 [0/54000 (0%)] Loss: -593.251770\n",
      "Train Epoch: 245 [11264/54000 (21%)] Loss: -580.208313\n",
      "Train Epoch: 245 [22528/54000 (42%)] Loss: -601.500549\n",
      "Train Epoch: 245 [33792/54000 (63%)] Loss: -597.697998\n",
      "Train Epoch: 245 [45056/54000 (83%)] Loss: -595.865234\n",
      "    epoch          : 245\n",
      "    loss           : -593.9500467552328\n",
      "    ess            : 1.9602948303492564\n",
      "    log_marginal   : 593.9844032143646\n",
      "    log_joint      : 801.6288164246757\n",
      "    val_loss       : -598.2516428629557\n",
      "    val_ess        : 1.9564560850461323\n",
      "    val_log_marginal: 598.2908172607422\n",
      "    val_log_joint  : 806.2279510498047\n",
      "Train Epoch: 246 [0/54000 (0%)] Loss: -614.191833\n",
      "Train Epoch: 246 [11264/54000 (21%)] Loss: -589.913635\n",
      "Train Epoch: 246 [22528/54000 (42%)] Loss: -594.117126\n",
      "Train Epoch: 246 [33792/54000 (63%)] Loss: -586.908813\n",
      "Train Epoch: 246 [45056/54000 (83%)] Loss: -589.456543\n",
      "    epoch          : 246\n",
      "    loss           : -593.877910685989\n",
      "    ess            : 1.9588356895266839\n",
      "    log_marginal   : 593.9142058750368\n",
      "    log_joint      : 801.4986382250515\n",
      "    val_loss       : -596.8898874918619\n",
      "    val_ess        : 1.959379533926646\n",
      "    val_log_marginal: 596.9275258382162\n",
      "    val_log_joint  : 804.7982432047526\n",
      "Train Epoch: 247 [0/54000 (0%)] Loss: -602.343140\n",
      "Train Epoch: 247 [11264/54000 (21%)] Loss: -577.449951\n",
      "Train Epoch: 247 [22528/54000 (42%)] Loss: -589.432312\n",
      "Train Epoch: 247 [33792/54000 (63%)] Loss: -613.098816\n",
      "Train Epoch: 247 [45056/54000 (83%)] Loss: -581.894531\n",
      "    epoch          : 247\n",
      "    loss           : -594.0880472435141\n",
      "    ess            : 1.9586605047279935\n",
      "    log_marginal   : 594.1240597131117\n",
      "    log_joint      : 801.7973385217055\n",
      "    val_loss       : -598.2779693603516\n",
      "    val_ess        : 1.9596963822841644\n",
      "    val_log_marginal: 598.3124338785807\n",
      "    val_log_joint  : 806.068593343099\n",
      "Train Epoch: 248 [0/54000 (0%)] Loss: -608.690308\n",
      "Train Epoch: 248 [11264/54000 (21%)] Loss: -606.879883\n",
      "Train Epoch: 248 [22528/54000 (42%)] Loss: -592.994629\n",
      "Train Epoch: 248 [33792/54000 (63%)] Loss: -567.755371\n",
      "Train Epoch: 248 [45056/54000 (83%)] Loss: -595.651855\n",
      "    epoch          : 248\n",
      "    loss           : -594.853550749005\n",
      "    ess            : 1.9593927376675155\n",
      "    log_marginal   : 594.8890783921728\n",
      "    log_joint      : 802.6115210191259\n",
      "    val_loss       : -599.3738861083984\n",
      "    val_ess        : 1.9562462270259857\n",
      "    val_log_marginal: 599.4132385253906\n",
      "    val_log_joint  : 807.0268046061198\n",
      "Train Epoch: 249 [0/54000 (0%)] Loss: -577.044067\n",
      "Train Epoch: 249 [11264/54000 (21%)] Loss: -580.663818\n",
      "Train Epoch: 249 [22528/54000 (42%)] Loss: -579.010132\n",
      "Train Epoch: 249 [33792/54000 (63%)] Loss: -582.788696\n",
      "Train Epoch: 249 [45056/54000 (83%)] Loss: -600.882080\n",
      "    epoch          : 249\n",
      "    loss           : -595.103563416679\n",
      "    ess            : 1.9581247871776797\n",
      "    log_marginal   : 595.1405253860186\n",
      "    log_joint      : 802.833850212817\n",
      "    val_loss       : -598.0614369710287\n",
      "    val_ess        : 1.961338718732198\n",
      "    val_log_marginal: 598.0925598144531\n",
      "    val_log_joint  : 805.6292622884115\n",
      "Train Epoch: 250 [0/54000 (0%)] Loss: -581.528687\n",
      "Train Epoch: 250 [11264/54000 (21%)] Loss: -610.118835\n",
      "Train Epoch: 250 [22528/54000 (42%)] Loss: -594.717896\n",
      "Train Epoch: 250 [33792/54000 (63%)] Loss: -610.419189\n",
      "Train Epoch: 250 [45056/54000 (83%)] Loss: -604.844177\n",
      "    epoch          : 250\n",
      "    loss           : -594.6153979031545\n",
      "    ess            : 1.9585408118535887\n",
      "    log_marginal   : 594.6523633273142\n",
      "    log_joint      : 802.3968661326282\n",
      "    val_loss       : -599.0389912923177\n",
      "    val_ess        : 1.9579905172189076\n",
      "    val_log_marginal: 599.0765838623047\n",
      "    val_log_joint  : 806.4800313313802\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch250.pth ...\n",
      "Train Epoch: 251 [0/54000 (0%)] Loss: -621.810120\n",
      "Train Epoch: 251 [11264/54000 (21%)] Loss: -605.173340\n",
      "Train Epoch: 251 [22528/54000 (42%)] Loss: -582.077942\n",
      "Train Epoch: 251 [33792/54000 (63%)] Loss: -591.667603\n",
      "Train Epoch: 251 [45056/54000 (83%)] Loss: -587.428955\n",
      "    epoch          : 251\n",
      "    loss           : -595.8588619592055\n",
      "    ess            : 1.9588841604736615\n",
      "    log_marginal   : 595.8955728782797\n",
      "    log_joint      : 803.6261343326208\n",
      "    val_loss       : -600.4699503580729\n",
      "    val_ess        : 1.9592185616493225\n",
      "    val_log_marginal: 600.5093587239584\n",
      "    val_log_joint  : 808.3714803059896\n",
      "Train Epoch: 252 [0/54000 (0%)] Loss: -599.857239\n",
      "Train Epoch: 252 [11264/54000 (21%)] Loss: -626.653198\n",
      "Train Epoch: 252 [22528/54000 (42%)] Loss: -587.435181\n",
      "Train Epoch: 252 [33792/54000 (63%)] Loss: -605.166077\n",
      "Train Epoch: 252 [45056/54000 (83%)] Loss: -596.115112\n",
      "    epoch          : 252\n",
      "    loss           : -596.0251764261498\n",
      "    ess            : 1.9599570699457853\n",
      "    log_marginal   : 596.0594384535303\n",
      "    log_joint      : 803.8070074117409\n",
      "    val_loss       : -599.0770975748698\n",
      "    val_ess        : 1.958004782597224\n",
      "    val_log_marginal: 599.1148783365885\n",
      "    val_log_joint  : 807.1437021891276\n",
      "Train Epoch: 253 [0/54000 (0%)] Loss: -588.136963\n",
      "Train Epoch: 253 [11264/54000 (21%)] Loss: -605.325317\n",
      "Train Epoch: 253 [22528/54000 (42%)] Loss: -594.935913\n",
      "Train Epoch: 253 [33792/54000 (63%)] Loss: -568.012451\n",
      "Train Epoch: 253 [45056/54000 (83%)] Loss: -594.658142\n",
      "    epoch          : 253\n",
      "    loss           : -595.7633166043264\n",
      "    ess            : 1.958489350552829\n",
      "    log_marginal   : 595.7989375276386\n",
      "    log_joint      : 803.4927782742483\n",
      "    val_loss       : -600.7489013671875\n",
      "    val_ess        : 1.9614606102307637\n",
      "    val_log_marginal: 600.7811228434244\n",
      "    val_log_joint  : 808.2778727213541\n",
      "Train Epoch: 254 [0/54000 (0%)] Loss: -592.654541\n",
      "Train Epoch: 254 [11264/54000 (21%)] Loss: -597.633545\n",
      "Train Epoch: 254 [22528/54000 (42%)] Loss: -579.989868\n",
      "Train Epoch: 254 [33792/54000 (63%)] Loss: -610.671509\n",
      "Train Epoch: 254 [45056/54000 (83%)] Loss: -612.848267\n",
      "    epoch          : 254\n",
      "    loss           : -597.0343270931604\n",
      "    ess            : 1.9595350814315509\n",
      "    log_marginal   : 597.0690745227741\n",
      "    log_joint      : 804.8477443479142\n",
      "    val_loss       : -601.6567586263021\n",
      "    val_ess        : 1.9601815442244213\n",
      "    val_log_marginal: 601.6913604736328\n",
      "    val_log_joint  : 809.2154795328776\n",
      "Train Epoch: 255 [0/54000 (0%)] Loss: -611.441467\n",
      "Train Epoch: 255 [11264/54000 (21%)] Loss: -605.291260\n",
      "Train Epoch: 255 [22528/54000 (42%)] Loss: -605.640503\n",
      "Train Epoch: 255 [33792/54000 (63%)] Loss: -586.996460\n",
      "Train Epoch: 255 [45056/54000 (83%)] Loss: -603.932434\n",
      "    epoch          : 255\n",
      "    loss           : -597.1076003740419\n",
      "    ess            : 1.9585173602374095\n",
      "    log_marginal   : 597.1446032254202\n",
      "    log_joint      : 804.8384445478331\n",
      "    val_loss       : -599.7858022054037\n",
      "    val_ess        : 1.9607758422692616\n",
      "    val_log_marginal: 599.8216705322266\n",
      "    val_log_joint  : 807.7761840820312\n",
      "Train Epoch: 256 [0/54000 (0%)] Loss: -613.468384\n",
      "Train Epoch: 256 [11264/54000 (21%)] Loss: -588.053589\n",
      "Train Epoch: 256 [22528/54000 (42%)] Loss: -601.080383\n",
      "Train Epoch: 256 [33792/54000 (63%)] Loss: -582.458252\n",
      "Train Epoch: 256 [45056/54000 (83%)] Loss: -575.827026\n",
      "    epoch          : 256\n",
      "    loss           : -597.3296059662441\n",
      "    ess            : 1.9591853461175595\n",
      "    log_marginal   : 597.3649182589548\n",
      "    log_joint      : 805.1002214539726\n",
      "    val_loss       : -601.4705047607422\n",
      "    val_ess        : 1.9577357769012451\n",
      "    val_log_marginal: 601.5101165771484\n",
      "    val_log_joint  : 809.2499338785807\n",
      "Train Epoch: 257 [0/54000 (0%)] Loss: -601.134033\n",
      "Train Epoch: 257 [11264/54000 (21%)] Loss: -592.045837\n",
      "Train Epoch: 257 [22528/54000 (42%)] Loss: -585.099060\n",
      "Train Epoch: 257 [33792/54000 (63%)] Loss: -588.148621\n",
      "Train Epoch: 257 [45056/54000 (83%)] Loss: -585.395508\n",
      "    epoch          : 257\n",
      "    loss           : -598.28864446676\n",
      "    ess            : 1.9594945907592773\n",
      "    log_marginal   : 598.3230251096329\n",
      "    log_joint      : 806.1179959279186\n",
      "    val_loss       : -602.7724253336588\n",
      "    val_ess        : 1.9604335526625316\n",
      "    val_log_marginal: 602.8127034505209\n",
      "    val_log_joint  : 810.4314168294271\n",
      "Train Epoch: 258 [0/54000 (0%)] Loss: -574.964233\n",
      "Train Epoch: 258 [11264/54000 (21%)] Loss: -583.621338\n",
      "Train Epoch: 258 [22528/54000 (42%)] Loss: -607.314758\n",
      "Train Epoch: 258 [33792/54000 (63%)] Loss: -611.818787\n",
      "Train Epoch: 258 [45056/54000 (83%)] Loss: -603.293335\n",
      "    epoch          : 258\n",
      "    loss           : -598.4663327774912\n",
      "    ess            : 1.958320920197469\n",
      "    log_marginal   : 598.5034634572155\n",
      "    log_joint      : 806.2084246941332\n",
      "    val_loss       : -602.4203338623047\n",
      "    val_ess        : 1.9612326423327129\n",
      "    val_log_marginal: 602.4554850260416\n",
      "    val_log_joint  : 810.0256754557291\n",
      "Train Epoch: 259 [0/54000 (0%)] Loss: -604.737183\n",
      "Train Epoch: 259 [11264/54000 (21%)] Loss: -601.293579\n",
      "Train Epoch: 259 [22528/54000 (42%)] Loss: -606.543701\n",
      "Train Epoch: 259 [33792/54000 (63%)] Loss: -603.147583\n",
      "Train Epoch: 259 [45056/54000 (83%)] Loss: -585.939331\n",
      "    epoch          : 259\n",
      "    loss           : -598.2211994674971\n",
      "    ess            : 1.9588052956563122\n",
      "    log_marginal   : 598.258216138156\n",
      "    log_joint      : 806.0279362516583\n",
      "    val_loss       : -602.1883850097656\n",
      "    val_ess        : 1.9561987221240997\n",
      "    val_log_marginal: 602.2284596761068\n",
      "    val_log_joint  : 810.1011912027994\n",
      "Train Epoch: 260 [0/54000 (0%)] Loss: -582.123169\n",
      "Train Epoch: 260 [11264/54000 (21%)] Loss: -601.778687\n",
      "Train Epoch: 260 [22528/54000 (42%)] Loss: -576.878296\n",
      "Train Epoch: 260 [33792/54000 (63%)] Loss: -593.687622\n",
      "Train Epoch: 260 [45056/54000 (83%)] Loss: -581.683167\n",
      "    epoch          : 260\n",
      "    loss           : -599.1862482034935\n",
      "    ess            : 1.9601530871301327\n",
      "    log_marginal   : 599.2209881476637\n",
      "    log_joint      : 806.8979595832105\n",
      "    val_loss       : -603.0924631754557\n",
      "    val_ess        : 1.9597365657488506\n",
      "    val_log_marginal: 603.1292877197266\n",
      "    val_log_joint  : 810.7065480550131\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch260.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 261 [0/54000 (0%)] Loss: -606.274963\n",
      "Train Epoch: 261 [11264/54000 (21%)] Loss: -607.491943\n",
      "Train Epoch: 261 [22528/54000 (42%)] Loss: -599.037109\n",
      "Train Epoch: 261 [33792/54000 (63%)] Loss: -589.147217\n",
      "Train Epoch: 261 [45056/54000 (83%)] Loss: -606.551758\n",
      "    epoch          : 261\n",
      "    loss           : -599.8236521594929\n",
      "    ess            : 1.9593523077245028\n",
      "    log_marginal   : 599.8581018987692\n",
      "    log_joint      : 807.5436188319944\n",
      "    val_loss       : -603.4996337890625\n",
      "    val_ess        : 1.9589568674564362\n",
      "    val_log_marginal: 603.5369008382162\n",
      "    val_log_joint  : 811.3179473876953\n",
      "Train Epoch: 262 [0/54000 (0%)] Loss: -584.782837\n",
      "Train Epoch: 262 [11264/54000 (21%)] Loss: -583.073242\n",
      "Train Epoch: 262 [22528/54000 (42%)] Loss: -586.801392\n",
      "Train Epoch: 262 [33792/54000 (63%)] Loss: -603.274048\n",
      "Train Epoch: 262 [45056/54000 (83%)] Loss: -596.396179\n",
      "    epoch          : 262\n",
      "    loss           : -599.2432527362175\n",
      "    ess            : 1.9585629251768004\n",
      "    log_marginal   : 599.2795231657208\n",
      "    log_joint      : 807.014385295364\n",
      "    val_loss       : -602.592519124349\n",
      "    val_ess        : 1.9581296642621357\n",
      "    val_log_marginal: 602.6310272216797\n",
      "    val_log_joint  : 810.2382049560547\n",
      "Train Epoch: 263 [0/54000 (0%)] Loss: -623.618835\n",
      "Train Epoch: 263 [11264/54000 (21%)] Loss: -598.093201\n",
      "Train Epoch: 263 [22528/54000 (42%)] Loss: -610.598999\n",
      "Train Epoch: 263 [33792/54000 (63%)] Loss: -580.656860\n",
      "Train Epoch: 263 [45056/54000 (83%)] Loss: -619.730042\n",
      "    epoch          : 263\n",
      "    loss           : -600.1180287487102\n",
      "    ess            : 1.9595196190870032\n",
      "    log_marginal   : 600.153961757444\n",
      "    log_joint      : 807.9173083035452\n",
      "    val_loss       : -604.0575307210287\n",
      "    val_ess        : 1.9575208127498627\n",
      "    val_log_marginal: 604.0973866780599\n",
      "    val_log_joint  : 811.7831878662109\n",
      "Train Epoch: 264 [0/54000 (0%)] Loss: -572.986084\n",
      "Train Epoch: 264 [11264/54000 (21%)] Loss: -606.966980\n",
      "Train Epoch: 264 [22528/54000 (42%)] Loss: -601.788086\n",
      "Train Epoch: 264 [33792/54000 (63%)] Loss: -611.677490\n",
      "Train Epoch: 264 [45056/54000 (83%)] Loss: -613.095154\n",
      "    epoch          : 264\n",
      "    loss           : -600.9440635825104\n",
      "    ess            : 1.9585818131014985\n",
      "    log_marginal   : 600.9805436044369\n",
      "    log_joint      : 808.7850059653229\n",
      "    val_loss       : -604.2994486490885\n",
      "    val_ess        : 1.95980371038119\n",
      "    val_log_marginal: 604.3341115315756\n",
      "    val_log_joint  : 812.0841725667318\n",
      "Train Epoch: 265 [0/54000 (0%)] Loss: -598.392151\n",
      "Train Epoch: 265 [11264/54000 (21%)] Loss: -604.180420\n",
      "Train Epoch: 265 [22528/54000 (42%)] Loss: -595.301270\n",
      "Train Epoch: 265 [33792/54000 (63%)] Loss: -598.276855\n",
      "Train Epoch: 265 [45056/54000 (83%)] Loss: -597.057495\n",
      "    epoch          : 265\n",
      "    loss           : -600.3879999124779\n",
      "    ess            : 1.958444963086326\n",
      "    log_marginal   : 600.4248052633034\n",
      "    log_joint      : 808.1353201236365\n",
      "    val_loss       : -604.4628448486328\n",
      "    val_ess        : 1.962037165959676\n",
      "    val_log_marginal: 604.4955088297526\n",
      "    val_log_joint  : 812.2181193033854\n",
      "Train Epoch: 266 [0/54000 (0%)] Loss: -600.981812\n",
      "Train Epoch: 266 [11264/54000 (21%)] Loss: -587.847473\n",
      "Train Epoch: 266 [22528/54000 (42%)] Loss: -596.391235\n",
      "Train Epoch: 266 [33792/54000 (63%)] Loss: -596.590820\n",
      "Train Epoch: 266 [45056/54000 (83%)] Loss: -593.376099\n",
      "    epoch          : 266\n",
      "    loss           : -601.3606527076578\n",
      "    ess            : 1.9586104896833312\n",
      "    log_marginal   : 601.3961832298422\n",
      "    log_joint      : 809.1877815678434\n",
      "    val_loss       : -605.3018290201823\n",
      "    val_ess        : 1.9619948863983154\n",
      "    val_log_marginal: 605.3361867268881\n",
      "    val_log_joint  : 813.0425567626953\n",
      "Train Epoch: 267 [0/54000 (0%)] Loss: -582.523071\n",
      "Train Epoch: 267 [11264/54000 (21%)] Loss: -601.791260\n",
      "Train Epoch: 267 [22528/54000 (42%)] Loss: -603.310669\n",
      "Train Epoch: 267 [33792/54000 (63%)] Loss: -611.010498\n",
      "Train Epoch: 267 [45056/54000 (83%)] Loss: -594.639343\n",
      "    epoch          : 267\n",
      "    loss           : -601.966393236844\n",
      "    ess            : 1.9594635884716827\n",
      "    log_marginal   : 602.0013663813753\n",
      "    log_joint      : 809.7375229169737\n",
      "    val_loss       : -605.4918416341146\n",
      "    val_ess        : 1.9592849810918171\n",
      "    val_log_marginal: 605.5281270345052\n",
      "    val_log_joint  : 813.4838663736979\n",
      "Train Epoch: 268 [0/54000 (0%)] Loss: -613.880737\n",
      "Train Epoch: 268 [11264/54000 (21%)] Loss: -591.357300\n",
      "Train Epoch: 268 [22528/54000 (42%)] Loss: -580.391968\n",
      "Train Epoch: 268 [33792/54000 (63%)] Loss: -594.764221\n",
      "Train Epoch: 268 [45056/54000 (83%)] Loss: -595.463623\n",
      "    epoch          : 268\n",
      "    loss           : -601.8613258217865\n",
      "    ess            : 1.9598455057953887\n",
      "    log_marginal   : 601.8975012437353\n",
      "    log_joint      : 809.6591077120798\n",
      "    val_loss       : -605.2347869873047\n",
      "    val_ess        : 1.9597297012805939\n",
      "    val_log_marginal: 605.2703959147135\n",
      "    val_log_joint  : 813.2854461669922\n",
      "Train Epoch: 269 [0/54000 (0%)] Loss: -603.513977\n",
      "Train Epoch: 269 [11264/54000 (21%)] Loss: -610.309326\n",
      "Train Epoch: 269 [22528/54000 (42%)] Loss: -591.647095\n",
      "Train Epoch: 269 [33792/54000 (63%)] Loss: -599.556030\n",
      "Train Epoch: 269 [45056/54000 (83%)] Loss: -587.938660\n",
      "    epoch          : 269\n",
      "    loss           : -602.4614488133844\n",
      "    ess            : 1.9590539628604673\n",
      "    log_marginal   : 602.497231537441\n",
      "    log_joint      : 810.2047297639667\n",
      "    val_loss       : -607.1913299560547\n",
      "    val_ess        : 1.9599855641523998\n",
      "    val_log_marginal: 607.2268931070963\n",
      "    val_log_joint  : 814.8559773763021\n",
      "Train Epoch: 270 [0/54000 (0%)] Loss: -590.123779\n",
      "Train Epoch: 270 [11264/54000 (21%)] Loss: -603.902039\n",
      "Train Epoch: 270 [22528/54000 (42%)] Loss: -619.566101\n",
      "Train Epoch: 270 [33792/54000 (63%)] Loss: -599.086304\n",
      "Train Epoch: 270 [45056/54000 (83%)] Loss: -604.750000\n",
      "    epoch          : 270\n",
      "    loss           : -603.3419488870873\n",
      "    ess            : 1.9586954780344694\n",
      "    log_marginal   : 603.3776527260834\n",
      "    log_joint      : 811.1373072210348\n",
      "    val_loss       : -607.2164154052734\n",
      "    val_ess        : 1.9608981609344482\n",
      "    val_log_marginal: 607.2512359619141\n",
      "    val_log_joint  : 815.1907552083334\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch270.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 271 [0/54000 (0%)] Loss: -602.867310\n",
      "Train Epoch: 271 [11264/54000 (21%)] Loss: -609.947021\n",
      "Train Epoch: 271 [22528/54000 (42%)] Loss: -591.348816\n",
      "Train Epoch: 271 [33792/54000 (63%)] Loss: -635.197998\n",
      "Train Epoch: 271 [45056/54000 (83%)] Loss: -618.522095\n",
      "    epoch          : 271\n",
      "    loss           : -602.6739225567512\n",
      "    ess            : 1.9591124001538978\n",
      "    log_marginal   : 602.7100841594192\n",
      "    log_joint      : 810.5034697910525\n",
      "    val_loss       : -606.0204060872396\n",
      "    val_ess        : 1.9543404976526897\n",
      "    val_log_marginal: 606.0614878336588\n",
      "    val_log_joint  : 813.7854207356771\n",
      "Train Epoch: 272 [0/54000 (0%)] Loss: -591.567261\n",
      "Train Epoch: 272 [11264/54000 (21%)] Loss: -600.691040\n",
      "Train Epoch: 272 [22528/54000 (42%)] Loss: -640.926880\n",
      "Train Epoch: 272 [33792/54000 (63%)] Loss: -602.393982\n",
      "Train Epoch: 272 [45056/54000 (83%)] Loss: -630.075562\n",
      "    epoch          : 272\n",
      "    loss           : -603.7662549288767\n",
      "    ess            : 1.9593156936033718\n",
      "    log_marginal   : 603.8016973531471\n",
      "    log_joint      : 811.5745797787073\n",
      "    val_loss       : -607.5859680175781\n",
      "    val_ess        : 1.958958774805069\n",
      "    val_log_marginal: 607.6212768554688\n",
      "    val_log_joint  : 815.3268330891927\n",
      "Train Epoch: 273 [0/54000 (0%)] Loss: -606.824219\n",
      "Train Epoch: 273 [11264/54000 (21%)] Loss: -606.194153\n",
      "Train Epoch: 273 [22528/54000 (42%)] Loss: -630.316040\n",
      "Train Epoch: 273 [33792/54000 (63%)] Loss: -634.208374\n",
      "Train Epoch: 273 [45056/54000 (83%)] Loss: -597.633423\n",
      "    epoch          : 273\n",
      "    loss           : -604.2442811210201\n",
      "    ess            : 1.959051454966923\n",
      "    log_marginal   : 604.2799722923422\n",
      "    log_joint      : 811.9630000276386\n",
      "    val_loss       : -608.4341023763021\n",
      "    val_ess        : 1.959993879000346\n",
      "    val_log_marginal: 608.4720408121744\n",
      "    val_log_joint  : 816.1846974690756\n",
      "Train Epoch: 274 [0/54000 (0%)] Loss: -612.363953\n",
      "Train Epoch: 274 [11264/54000 (21%)] Loss: -604.955444\n",
      "Train Epoch: 274 [22528/54000 (42%)] Loss: -589.951050\n",
      "Train Epoch: 274 [33792/54000 (63%)] Loss: -611.354126\n",
      "Train Epoch: 274 [45056/54000 (83%)] Loss: -591.335083\n",
      "    epoch          : 274\n",
      "    loss           : -603.869343307783\n",
      "    ess            : 1.958704873076025\n",
      "    log_marginal   : 603.9062430903597\n",
      "    log_joint      : 811.6512756347656\n",
      "    val_loss       : -606.7783406575521\n",
      "    val_ess        : 1.9568537970383961\n",
      "    val_log_marginal: 606.8149668375651\n",
      "    val_log_joint  : 814.6198120117188\n",
      "Train Epoch: 275 [0/54000 (0%)] Loss: -593.397400\n",
      "Train Epoch: 275 [11264/54000 (21%)] Loss: -603.803162\n",
      "Train Epoch: 275 [22528/54000 (42%)] Loss: -589.323120\n",
      "Train Epoch: 275 [33792/54000 (63%)] Loss: -593.939819\n",
      "Train Epoch: 275 [45056/54000 (83%)] Loss: -614.167297\n",
      "    epoch          : 275\n",
      "    loss           : -604.5822535100973\n",
      "    ess            : 1.9593627587804254\n",
      "    log_marginal   : 604.6178537044885\n",
      "    log_joint      : 812.3866243182488\n",
      "    val_loss       : -608.5168914794922\n",
      "    val_ess        : 1.9557840625445049\n",
      "    val_log_marginal: 608.5530751546224\n",
      "    val_log_joint  : 816.3712768554688\n",
      "Train Epoch: 276 [0/54000 (0%)] Loss: -624.818909\n",
      "Train Epoch: 276 [11264/54000 (21%)] Loss: -592.992432\n",
      "Train Epoch: 276 [22528/54000 (42%)] Loss: -613.420532\n",
      "Train Epoch: 276 [33792/54000 (63%)] Loss: -604.454346\n",
      "Train Epoch: 276 [45056/54000 (83%)] Loss: -596.653320\n",
      "    epoch          : 276\n",
      "    loss           : -605.6505737304688\n",
      "    ess            : 1.9579803572510772\n",
      "    log_marginal   : 605.6873151671211\n",
      "    log_joint      : 813.4330524948408\n",
      "    val_loss       : -609.193359375\n",
      "    val_ess        : 1.9603503048419952\n",
      "    val_log_marginal: 609.2284749348959\n",
      "    val_log_joint  : 816.8019561767578\n",
      "Train Epoch: 277 [0/54000 (0%)] Loss: -623.479980\n",
      "Train Epoch: 277 [11264/54000 (21%)] Loss: -595.240906\n",
      "Train Epoch: 277 [22528/54000 (42%)] Loss: -602.158875\n",
      "Train Epoch: 277 [33792/54000 (63%)] Loss: -586.809448\n",
      "Train Epoch: 277 [45056/54000 (83%)] Loss: -614.102051\n",
      "    epoch          : 277\n",
      "    loss           : -604.9000963894827\n",
      "    ess            : 1.959981493230136\n",
      "    log_marginal   : 604.9353004311615\n",
      "    log_joint      : 812.7035752782282\n",
      "    val_loss       : -607.4151000976562\n",
      "    val_ess        : 1.9576061169306438\n",
      "    val_log_marginal: 607.4531402587891\n",
      "    val_log_joint  : 815.2757263183594\n",
      "Train Epoch: 278 [0/54000 (0%)] Loss: -592.982971\n",
      "Train Epoch: 278 [11264/54000 (21%)] Loss: -611.251282\n",
      "Train Epoch: 278 [22528/54000 (42%)] Loss: -601.878174\n",
      "Train Epoch: 278 [33792/54000 (63%)] Loss: -595.553772\n",
      "Train Epoch: 278 [45056/54000 (83%)] Loss: -597.054382\n",
      "    epoch          : 278\n",
      "    loss           : -605.797071348946\n",
      "    ess            : 1.959528460817517\n",
      "    log_marginal   : 605.8319189683447\n",
      "    log_joint      : 813.4821247604658\n",
      "    val_loss       : -609.4486083984375\n",
      "    val_ess        : 1.9587137500445049\n",
      "    val_log_marginal: 609.4861145019531\n",
      "    val_log_joint  : 817.2632141113281\n",
      "Train Epoch: 279 [0/54000 (0%)] Loss: -606.058228\n",
      "Train Epoch: 279 [11264/54000 (21%)] Loss: -601.063354\n",
      "Train Epoch: 279 [22528/54000 (42%)] Loss: -591.875610\n",
      "Train Epoch: 279 [33792/54000 (63%)] Loss: -602.651611\n",
      "Train Epoch: 279 [45056/54000 (83%)] Loss: -602.359863\n",
      "    epoch          : 279\n",
      "    loss           : -606.7300743246979\n",
      "    ess            : 1.9583175688419703\n",
      "    log_marginal   : 606.7671836996979\n",
      "    log_joint      : 814.4682507784861\n",
      "    val_loss       : -609.8959350585938\n",
      "    val_ess        : 1.9572158753871918\n",
      "    val_log_marginal: 609.9334615071615\n",
      "    val_log_joint  : 817.6732838948568\n",
      "Train Epoch: 280 [0/54000 (0%)] Loss: -584.690063\n",
      "Train Epoch: 280 [11264/54000 (21%)] Loss: -626.076416\n",
      "Train Epoch: 280 [22528/54000 (42%)] Loss: -595.958008\n",
      "Train Epoch: 280 [33792/54000 (63%)] Loss: -602.012207\n",
      "Train Epoch: 280 [45056/54000 (83%)] Loss: -604.099609\n",
      "    epoch          : 280\n",
      "    loss           : -606.0901114985628\n",
      "    ess            : 1.9593574753347434\n",
      "    log_marginal   : 606.1254612184921\n",
      "    log_joint      : 813.9064043153007\n",
      "    val_loss       : -609.2353006998698\n",
      "    val_ess        : 1.960478236277898\n",
      "    val_log_marginal: 609.2701110839844\n",
      "    val_log_joint  : 817.0650787353516\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch280.pth ...\n",
      "Train Epoch: 281 [0/54000 (0%)] Loss: -597.993774\n",
      "Train Epoch: 281 [11264/54000 (21%)] Loss: -596.393188\n",
      "Train Epoch: 281 [22528/54000 (42%)] Loss: -604.950195\n",
      "Train Epoch: 281 [33792/54000 (63%)] Loss: -600.186218\n",
      "Train Epoch: 281 [45056/54000 (83%)] Loss: -612.447510\n",
      "    epoch          : 281\n",
      "    loss           : -606.8403187877727\n",
      "    ess            : 1.9592382615467288\n",
      "    log_marginal   : 606.8768563900354\n",
      "    log_joint      : 814.697147585311\n",
      "    val_loss       : -610.8607482910156\n",
      "    val_ess        : 1.9549343089262645\n",
      "    val_log_marginal: 610.9024912516276\n",
      "    val_log_joint  : 818.6845753987631\n",
      "Train Epoch: 282 [0/54000 (0%)] Loss: -604.209167\n",
      "Train Epoch: 282 [11264/54000 (21%)] Loss: -615.543640\n",
      "Train Epoch: 282 [22528/54000 (42%)] Loss: -601.429199\n",
      "Train Epoch: 282 [33792/54000 (63%)] Loss: -615.713684\n",
      "Train Epoch: 282 [45056/54000 (83%)] Loss: -603.490479\n",
      "    epoch          : 282\n",
      "    loss           : -607.570695409235\n",
      "    ess            : 1.9591798759856314\n",
      "    log_marginal   : 607.6058620236954\n",
      "    log_joint      : 815.2908826144236\n",
      "    val_loss       : -611.0014088948568\n",
      "    val_ess        : 1.9612815876801808\n",
      "    val_log_marginal: 611.0334981282552\n",
      "    val_log_joint  : 818.6113739013672\n",
      "Train Epoch: 283 [0/54000 (0%)] Loss: -632.374878\n",
      "Train Epoch: 283 [11264/54000 (21%)] Loss: -612.236694\n",
      "Train Epoch: 283 [22528/54000 (42%)] Loss: -600.509644\n",
      "Train Epoch: 283 [33792/54000 (63%)] Loss: -613.864746\n",
      "Train Epoch: 283 [45056/54000 (83%)] Loss: -620.977112\n",
      "    epoch          : 283\n",
      "    loss           : -607.1130837494472\n",
      "    ess            : 1.9574844319865388\n",
      "    log_marginal   : 607.1514403145268\n",
      "    log_joint      : 815.0370897976858\n",
      "    val_loss       : -610.5358479817709\n",
      "    val_ess        : 1.958697239557902\n",
      "    val_log_marginal: 610.5737813313802\n",
      "    val_log_joint  : 818.0623423258463\n",
      "Train Epoch: 284 [0/54000 (0%)] Loss: -609.436829\n",
      "Train Epoch: 284 [11264/54000 (21%)] Loss: -612.797607\n",
      "Train Epoch: 284 [22528/54000 (42%)] Loss: -609.569092\n",
      "Train Epoch: 284 [33792/54000 (63%)] Loss: -597.142334\n",
      "Train Epoch: 284 [45056/54000 (83%)] Loss: -575.676208\n",
      "    epoch          : 284\n",
      "    loss           : -607.6436571804983\n",
      "    ess            : 1.9589356892513778\n",
      "    log_marginal   : 607.6792210992777\n",
      "    log_joint      : 815.4420436643204\n",
      "    val_loss       : -612.5093943277994\n",
      "    val_ess        : 1.9612775643666585\n",
      "    val_log_marginal: 612.5425160725912\n",
      "    val_log_joint  : 820.4176584879557\n",
      "Train Epoch: 285 [0/54000 (0%)] Loss: -594.140137\n",
      "Train Epoch: 285 [11264/54000 (21%)] Loss: -607.978577\n",
      "Train Epoch: 285 [22528/54000 (42%)] Loss: -625.939392\n",
      "Train Epoch: 285 [33792/54000 (63%)] Loss: -602.556519\n",
      "Train Epoch: 285 [45056/54000 (83%)] Loss: -630.007324\n",
      "    epoch          : 285\n",
      "    loss           : -608.7578723835495\n",
      "    ess            : 1.9588198965450503\n",
      "    log_marginal   : 608.7937748747052\n",
      "    log_joint      : 816.5602825812574\n",
      "    val_loss       : -613.06689453125\n",
      "    val_ess        : 1.9604475597540538\n",
      "    val_log_marginal: 613.1015574137369\n",
      "    val_log_joint  : 820.9039713541666\n",
      "Train Epoch: 286 [0/54000 (0%)] Loss: -618.567993\n",
      "Train Epoch: 286 [11264/54000 (21%)] Loss: -612.022705\n",
      "Train Epoch: 286 [22528/54000 (42%)] Loss: -609.169983\n",
      "Train Epoch: 286 [33792/54000 (63%)] Loss: -615.131958\n",
      "Train Epoch: 286 [45056/54000 (83%)] Loss: -593.138000\n",
      "    epoch          : 286\n",
      "    loss           : -608.3174444234596\n",
      "    ess            : 1.958876631169949\n",
      "    log_marginal   : 608.353068801592\n",
      "    log_joint      : 816.10721285838\n",
      "    val_loss       : -610.8090871175131\n",
      "    val_ess        : 1.9560626745224\n",
      "    val_log_marginal: 610.8520914713541\n",
      "    val_log_joint  : 818.8194274902344\n",
      "Train Epoch: 287 [0/54000 (0%)] Loss: -597.606445\n",
      "Train Epoch: 287 [11264/54000 (21%)] Loss: -606.757202\n",
      "Train Epoch: 287 [22528/54000 (42%)] Loss: -621.341064\n",
      "Train Epoch: 287 [33792/54000 (63%)] Loss: -600.606689\n",
      "Train Epoch: 287 [45056/54000 (83%)] Loss: -611.871887\n",
      "    epoch          : 287\n",
      "    loss           : -608.8365616708431\n",
      "    ess            : 1.9570711806135357\n",
      "    log_marginal   : 608.8742744877653\n",
      "    log_joint      : 816.586396991082\n",
      "    val_loss       : -612.9228515625\n",
      "    val_ess        : 1.9551397462685902\n",
      "    val_log_marginal: 612.9634602864584\n",
      "    val_log_joint  : 820.7567545572916\n",
      "Train Epoch: 288 [0/54000 (0%)] Loss: -594.956299\n",
      "Train Epoch: 288 [11264/54000 (21%)] Loss: -607.429321\n",
      "Train Epoch: 288 [22528/54000 (42%)] Loss: -597.313354\n",
      "Train Epoch: 288 [33792/54000 (63%)] Loss: -584.394287\n",
      "Train Epoch: 288 [45056/54000 (83%)] Loss: -611.393311\n",
      "    epoch          : 288\n",
      "    loss           : -609.7113365317291\n",
      "    ess            : 1.9584409448335756\n",
      "    log_marginal   : 609.7487004118145\n",
      "    log_joint      : 817.5512994730248\n",
      "    val_loss       : -613.8533121744791\n",
      "    val_ess        : 1.957894206047058\n",
      "    val_log_marginal: 613.8880767822266\n",
      "    val_log_joint  : 821.8303985595703\n",
      "Train Epoch: 289 [0/54000 (0%)] Loss: -623.462646\n",
      "Train Epoch: 289 [11264/54000 (21%)] Loss: -612.314758\n",
      "Train Epoch: 289 [22528/54000 (42%)] Loss: -615.675293\n",
      "Train Epoch: 289 [33792/54000 (63%)] Loss: -615.921692\n",
      "Train Epoch: 289 [45056/54000 (83%)] Loss: -624.757812\n",
      "    epoch          : 289\n",
      "    loss           : -609.5154044673128\n",
      "    ess            : 1.9584599485937155\n",
      "    log_marginal   : 609.5520762317585\n",
      "    log_joint      : 817.2971824789947\n",
      "    val_loss       : -612.4173278808594\n",
      "    val_ess        : 1.9633540709813435\n",
      "    val_log_marginal: 612.4482828776041\n",
      "    val_log_joint  : 820.3523864746094\n",
      "Train Epoch: 290 [0/54000 (0%)] Loss: -594.256958\n",
      "Train Epoch: 290 [11264/54000 (21%)] Loss: -604.363525\n",
      "Train Epoch: 290 [22528/54000 (42%)] Loss: -590.680847\n",
      "Train Epoch: 290 [33792/54000 (63%)] Loss: -628.577271\n",
      "Train Epoch: 290 [45056/54000 (83%)] Loss: -606.567505\n",
      "    epoch          : 290\n",
      "    loss           : -609.749470260908\n",
      "    ess            : 1.9576097321960162\n",
      "    log_marginal   : 609.7866084260761\n",
      "    log_joint      : 817.6747545926077\n",
      "    val_loss       : -613.5640157063802\n",
      "    val_ess        : 1.9569110174973805\n",
      "    val_log_marginal: 613.6014709472656\n",
      "    val_log_joint  : 821.3606923421224\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch290.pth ...\n",
      "Train Epoch: 291 [0/54000 (0%)] Loss: -610.635559\n",
      "Train Epoch: 291 [11264/54000 (21%)] Loss: -588.054321\n",
      "Train Epoch: 291 [22528/54000 (42%)] Loss: -595.003052\n",
      "Train Epoch: 291 [33792/54000 (63%)] Loss: -614.684998\n",
      "Train Epoch: 291 [45056/54000 (83%)] Loss: -629.544189\n",
      "    epoch          : 291\n",
      "    loss           : -610.2750468703936\n",
      "    ess            : 1.9588306366272692\n",
      "    log_marginal   : 610.3116645093235\n",
      "    log_joint      : 818.1141518646816\n",
      "    val_loss       : -614.7082112630209\n",
      "    val_ess        : 1.9581805964310963\n",
      "    val_log_marginal: 614.7448933919271\n",
      "    val_log_joint  : 822.5190989176432\n",
      "Train Epoch: 292 [0/54000 (0%)] Loss: -610.924561\n",
      "Train Epoch: 292 [11264/54000 (21%)] Loss: -617.239929\n",
      "Train Epoch: 292 [22528/54000 (42%)] Loss: -611.277649\n",
      "Train Epoch: 292 [33792/54000 (63%)] Loss: -624.028381\n",
      "Train Epoch: 292 [45056/54000 (83%)] Loss: -596.512451\n",
      "    epoch          : 292\n",
      "    loss           : -610.9799171303803\n",
      "    ess            : 1.959750698422486\n",
      "    log_marginal   : 611.0156618514151\n",
      "    log_joint      : 818.6793782935953\n",
      "    val_loss       : -613.4272613525391\n",
      "    val_ess        : 1.9618677993615468\n",
      "    val_log_marginal: 613.4621836344401\n",
      "    val_log_joint  : 821.2927703857422\n",
      "Train Epoch: 293 [0/54000 (0%)] Loss: -619.621643\n",
      "Train Epoch: 293 [11264/54000 (21%)] Loss: -614.808960\n",
      "Train Epoch: 293 [22528/54000 (42%)] Loss: -629.742798\n",
      "Train Epoch: 293 [33792/54000 (63%)] Loss: -616.872742\n",
      "Train Epoch: 293 [45056/54000 (83%)] Loss: -610.275513\n",
      "    epoch          : 293\n",
      "    loss           : -610.4577832491892\n",
      "    ess            : 1.959052802256818\n",
      "    log_marginal   : 610.4926890247273\n",
      "    log_joint      : 818.2665641352816\n",
      "    val_loss       : -613.7046559651693\n",
      "    val_ess        : 1.958629568417867\n",
      "    val_log_marginal: 613.7419840494791\n",
      "    val_log_joint  : 821.4727121988932\n",
      "Train Epoch: 294 [0/54000 (0%)] Loss: -618.296814\n",
      "Train Epoch: 294 [11264/54000 (21%)] Loss: -605.222168\n",
      "Train Epoch: 294 [22528/54000 (42%)] Loss: -610.965515\n",
      "Train Epoch: 294 [33792/54000 (63%)] Loss: -606.359741\n",
      "Train Epoch: 294 [45056/54000 (83%)] Loss: -607.794373\n",
      "    epoch          : 294\n",
      "    loss           : -611.6076320432267\n",
      "    ess            : 1.959290717007979\n",
      "    log_marginal   : 611.6440349075029\n",
      "    log_joint      : 819.3713453760687\n",
      "    val_loss       : -615.1272837320963\n",
      "    val_ess        : 1.9588230152924855\n",
      "    val_log_marginal: 615.1659189860026\n",
      "    val_log_joint  : 823.0193939208984\n",
      "Train Epoch: 295 [0/54000 (0%)] Loss: -639.010986\n",
      "Train Epoch: 295 [11264/54000 (21%)] Loss: -623.060059\n",
      "Train Epoch: 295 [22528/54000 (42%)] Loss: -613.687622\n",
      "Train Epoch: 295 [33792/54000 (63%)] Loss: -626.585327\n",
      "Train Epoch: 295 [45056/54000 (83%)] Loss: -597.762207\n",
      "    epoch          : 295\n",
      "    loss           : -611.458963646079\n",
      "    ess            : 1.9578500063914173\n",
      "    log_marginal   : 611.4961985462116\n",
      "    log_joint      : 819.3155569400427\n",
      "    val_loss       : -614.4401194254557\n",
      "    val_ess        : 1.957092970609665\n",
      "    val_log_marginal: 614.4777170817057\n",
      "    val_log_joint  : 822.2462717692057\n",
      "Train Epoch: 296 [0/54000 (0%)] Loss: -641.369507\n",
      "Train Epoch: 296 [11264/54000 (21%)] Loss: -608.442627\n",
      "Train Epoch: 296 [22528/54000 (42%)] Loss: -609.459106\n",
      "Train Epoch: 296 [33792/54000 (63%)] Loss: -607.983826\n",
      "Train Epoch: 296 [45056/54000 (83%)] Loss: -603.365540\n",
      "    epoch          : 296\n",
      "    loss           : -611.7250884433962\n",
      "    ess            : 1.958712491224397\n",
      "    log_marginal   : 611.760560233638\n",
      "    log_joint      : 819.4866926085274\n",
      "    val_loss       : -614.4585673014323\n",
      "    val_ess        : 1.9577877918879192\n",
      "    val_log_marginal: 614.4952443440756\n",
      "    val_log_joint  : 822.2525736490885\n",
      "Train Epoch: 297 [0/54000 (0%)] Loss: -599.147949\n",
      "Train Epoch: 297 [11264/54000 (21%)] Loss: -619.710205\n",
      "Train Epoch: 297 [22528/54000 (42%)] Loss: -594.799072\n",
      "Train Epoch: 297 [33792/54000 (63%)] Loss: -609.358459\n",
      "Train Epoch: 297 [45056/54000 (83%)] Loss: -610.031616\n",
      "    epoch          : 297\n",
      "    loss           : -612.26248629588\n",
      "    ess            : 1.9585027503517438\n",
      "    log_marginal   : 612.2991263911409\n",
      "    log_joint      : 820.0644548524101\n",
      "    val_loss       : -616.0533091227213\n",
      "    val_ess        : 1.9595330953598022\n",
      "    val_log_marginal: 616.0891825358073\n",
      "    val_log_joint  : 823.7845306396484\n",
      "Train Epoch: 298 [0/54000 (0%)] Loss: -616.810059\n",
      "Train Epoch: 298 [11264/54000 (21%)] Loss: -596.770996\n",
      "Train Epoch: 298 [22528/54000 (42%)] Loss: -628.879944\n",
      "Train Epoch: 298 [33792/54000 (63%)] Loss: -609.573303\n",
      "Train Epoch: 298 [45056/54000 (83%)] Loss: -611.256470\n",
      "    epoch          : 298\n",
      "    loss           : -612.9027151431677\n",
      "    ess            : 1.9579934230390585\n",
      "    log_marginal   : 612.9388047704157\n",
      "    log_joint      : 820.7539753464033\n",
      "    val_loss       : -616.3849080403646\n",
      "    val_ess        : 1.9588240385055542\n",
      "    val_log_marginal: 616.4217580159506\n",
      "    val_log_joint  : 824.0922139485677\n",
      "Train Epoch: 299 [0/54000 (0%)] Loss: -628.161743\n",
      "Train Epoch: 299 [11264/54000 (21%)] Loss: -612.629822\n",
      "Train Epoch: 299 [22528/54000 (42%)] Loss: -606.938416\n",
      "Train Epoch: 299 [33792/54000 (63%)] Loss: -619.891968\n",
      "Train Epoch: 299 [45056/54000 (83%)] Loss: -616.170898\n",
      "    epoch          : 299\n",
      "    loss           : -612.7146134286556\n",
      "    ess            : 1.959411583981424\n",
      "    log_marginal   : 612.7502712033829\n",
      "    log_joint      : 820.4902522249042\n",
      "    val_loss       : -615.8132934570312\n",
      "    val_ess        : 1.958708385626475\n",
      "    val_log_marginal: 615.8504333496094\n",
      "    val_log_joint  : 823.6896921793619\n",
      "Train Epoch: 300 [0/54000 (0%)] Loss: -635.208923\n",
      "Train Epoch: 300 [11264/54000 (21%)] Loss: -623.209473\n",
      "Train Epoch: 300 [22528/54000 (42%)] Loss: -627.235352\n",
      "Train Epoch: 300 [33792/54000 (63%)] Loss: -630.913086\n",
      "Train Epoch: 300 [45056/54000 (83%)] Loss: -624.998901\n",
      "    epoch          : 300\n",
      "    loss           : -613.2734029517984\n",
      "    ess            : 1.9573955637104106\n",
      "    log_marginal   : 613.311126133181\n",
      "    log_joint      : 821.0929277528007\n",
      "    val_loss       : -618.0041758219401\n",
      "    val_ess        : 1.962370902299881\n",
      "    val_log_marginal: 618.0382486979166\n",
      "    val_log_joint  : 825.9914042154948\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch300.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 301 [0/54000 (0%)] Loss: -615.561157\n",
      "Train Epoch: 301 [11264/54000 (21%)] Loss: -610.507812\n",
      "Train Epoch: 301 [22528/54000 (42%)] Loss: -614.558838\n",
      "Train Epoch: 301 [33792/54000 (63%)] Loss: -613.817810\n",
      "Train Epoch: 301 [45056/54000 (83%)] Loss: -588.662720\n",
      "    epoch          : 301\n",
      "    loss           : -614.0550968961895\n",
      "    ess            : 1.9592209784489758\n",
      "    log_marginal   : 614.0911894024543\n",
      "    log_joint      : 821.8483506688532\n",
      "    val_loss       : -617.7602844238281\n",
      "    val_ess        : 1.954745223124822\n",
      "    val_log_marginal: 617.8005167643229\n",
      "    val_log_joint  : 825.5606638590494\n",
      "Train Epoch: 302 [0/54000 (0%)] Loss: -628.390137\n",
      "Train Epoch: 302 [11264/54000 (21%)] Loss: -619.785706\n",
      "Train Epoch: 302 [22528/54000 (42%)] Loss: -623.890747\n",
      "Train Epoch: 302 [33792/54000 (63%)] Loss: -617.129700\n",
      "Train Epoch: 302 [45056/54000 (83%)] Loss: -606.386902\n",
      "    epoch          : 302\n",
      "    loss           : -612.8972133420548\n",
      "    ess            : 1.9590283632278442\n",
      "    log_marginal   : 612.933148654002\n",
      "    log_joint      : 820.7811826310068\n",
      "    val_loss       : -616.5620168050131\n",
      "    val_ess        : 1.9607493082682292\n",
      "    val_log_marginal: 616.5978495279948\n",
      "    val_log_joint  : 824.4469146728516\n",
      "Train Epoch: 303 [0/54000 (0%)] Loss: -621.091919\n",
      "Train Epoch: 303 [11264/54000 (21%)] Loss: -618.142822\n",
      "Train Epoch: 303 [22528/54000 (42%)] Loss: -606.205200\n",
      "Train Epoch: 303 [33792/54000 (63%)] Loss: -620.360474\n",
      "Train Epoch: 303 [45056/54000 (83%)] Loss: -624.502441\n",
      "    epoch          : 303\n",
      "    loss           : -614.287171561763\n",
      "    ess            : 1.9578532857714959\n",
      "    log_marginal   : 614.3247294875811\n",
      "    log_joint      : 822.1173959408167\n",
      "    val_loss       : -618.6368916829427\n",
      "    val_ess        : 1.9569464524586995\n",
      "    val_log_marginal: 618.6763509114584\n",
      "    val_log_joint  : 826.5746866861979\n",
      "Train Epoch: 304 [0/54000 (0%)] Loss: -614.473572\n",
      "Train Epoch: 304 [11264/54000 (21%)] Loss: -617.150513\n",
      "Train Epoch: 304 [22528/54000 (42%)] Loss: -627.960876\n",
      "Train Epoch: 304 [33792/54000 (63%)] Loss: -602.246765\n",
      "Train Epoch: 304 [45056/54000 (83%)] Loss: -609.497620\n",
      "    epoch          : 304\n",
      "    loss           : -614.8011209739828\n",
      "    ess            : 1.9586002489305891\n",
      "    log_marginal   : 614.83719332713\n",
      "    log_joint      : 822.6531688762161\n",
      "    val_loss       : -618.2581227620443\n",
      "    val_ess        : 1.955436795949936\n",
      "    val_log_marginal: 618.2967325846354\n",
      "    val_log_joint  : 826.0088653564453\n",
      "Train Epoch: 305 [0/54000 (0%)] Loss: -603.888367\n",
      "Train Epoch: 305 [11264/54000 (21%)] Loss: -618.557495\n",
      "Train Epoch: 305 [22528/54000 (42%)] Loss: -633.324036\n",
      "Train Epoch: 305 [33792/54000 (63%)] Loss: -618.077698\n",
      "Train Epoch: 305 [45056/54000 (83%)] Loss: -631.314819\n",
      "    epoch          : 305\n",
      "    loss           : -614.7931587651091\n",
      "    ess            : 1.9588148076579255\n",
      "    log_marginal   : 614.8295149893131\n",
      "    log_joint      : 822.7283187002506\n",
      "    val_loss       : -618.4527791341146\n",
      "    val_ess        : 1.959871878226598\n",
      "    val_log_marginal: 618.4891052246094\n",
      "    val_log_joint  : 826.1508636474609\n",
      "Train Epoch: 306 [0/54000 (0%)] Loss: -615.611084\n",
      "Train Epoch: 306 [11264/54000 (21%)] Loss: -608.395325\n",
      "Train Epoch: 306 [22528/54000 (42%)] Loss: -602.041626\n",
      "Train Epoch: 306 [33792/54000 (63%)] Loss: -614.732971\n",
      "Train Epoch: 306 [45056/54000 (83%)] Loss: -622.736206\n",
      "    epoch          : 306\n",
      "    loss           : -615.2853255361881\n",
      "    ess            : 1.958891973180591\n",
      "    log_marginal   : 615.3214865630528\n",
      "    log_joint      : 823.1271725060805\n",
      "    val_loss       : -619.3304189046224\n",
      "    val_ess        : 1.9600080649058025\n",
      "    val_log_marginal: 619.3664703369141\n",
      "    val_log_joint  : 827.0614166259766\n",
      "Train Epoch: 307 [0/54000 (0%)] Loss: -595.391235\n",
      "Train Epoch: 307 [11264/54000 (21%)] Loss: -609.944275\n",
      "Train Epoch: 307 [22528/54000 (42%)] Loss: -630.795288\n",
      "Train Epoch: 307 [33792/54000 (63%)] Loss: -618.228760\n",
      "Train Epoch: 307 [45056/54000 (83%)] Loss: -633.229187\n",
      "    epoch          : 307\n",
      "    loss           : -615.9884787505528\n",
      "    ess            : 1.9588099223262858\n",
      "    log_marginal   : 616.0240818239608\n",
      "    log_joint      : 823.7909977750958\n",
      "    val_loss       : -619.8328857421875\n",
      "    val_ess        : 1.9576947589715321\n",
      "    val_log_marginal: 619.8708750406901\n",
      "    val_log_joint  : 827.4502410888672\n",
      "Train Epoch: 308 [0/54000 (0%)] Loss: -612.776794\n",
      "Train Epoch: 308 [11264/54000 (21%)] Loss: -632.675903\n",
      "Train Epoch: 308 [22528/54000 (42%)] Loss: -625.266663\n",
      "Train Epoch: 308 [33792/54000 (63%)] Loss: -613.727844\n",
      "Train Epoch: 308 [45056/54000 (83%)] Loss: -605.258667\n",
      "    epoch          : 308\n",
      "    loss           : -615.916484904739\n",
      "    ess            : 1.9588347324785196\n",
      "    log_marginal   : 615.9530449633328\n",
      "    log_joint      : 823.7591742749485\n",
      "    val_loss       : -619.6518961588541\n",
      "    val_ess        : 1.958061049381892\n",
      "    val_log_marginal: 619.6888427734375\n",
      "    val_log_joint  : 827.3587900797526\n",
      "Train Epoch: 309 [0/54000 (0%)] Loss: -610.267578\n",
      "Train Epoch: 309 [11264/54000 (21%)] Loss: -632.849487\n",
      "Train Epoch: 309 [22528/54000 (42%)] Loss: -617.864624\n",
      "Train Epoch: 309 [33792/54000 (63%)] Loss: -632.375732\n",
      "Train Epoch: 309 [45056/54000 (83%)] Loss: -627.214722\n",
      "    epoch          : 309\n",
      "    loss           : -616.5030719109301\n",
      "    ess            : 1.957764303909158\n",
      "    log_marginal   : 616.5403494205115\n",
      "    log_joint      : 824.2868439296507\n",
      "    val_loss       : -620.6437733968099\n",
      "    val_ess        : 1.9589463373025258\n",
      "    val_log_marginal: 620.6844685872396\n",
      "    val_log_joint  : 828.3631083170573\n",
      "Train Epoch: 310 [0/54000 (0%)] Loss: -615.643677\n",
      "Train Epoch: 310 [11264/54000 (21%)] Loss: -620.099731\n",
      "Train Epoch: 310 [22528/54000 (42%)] Loss: -606.722595\n",
      "Train Epoch: 310 [33792/54000 (63%)] Loss: -629.986694\n",
      "Train Epoch: 310 [45056/54000 (83%)] Loss: -613.937500\n",
      "    epoch          : 310\n",
      "    loss           : -617.0568127902048\n",
      "    ess            : 1.9590820321496927\n",
      "    log_marginal   : 617.0924912938532\n",
      "    log_joint      : 824.8218919286188\n",
      "    val_loss       : -620.8306681315104\n",
      "    val_ess        : 1.9573964178562164\n",
      "    val_log_marginal: 620.8699595133463\n",
      "    val_log_joint  : 828.8253682454427\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch310.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 311 [0/54000 (0%)] Loss: -616.976501\n",
      "Train Epoch: 311 [11264/54000 (21%)] Loss: -621.047852\n",
      "Train Epoch: 311 [22528/54000 (42%)] Loss: -623.442932\n",
      "Train Epoch: 311 [33792/54000 (63%)] Loss: -612.339600\n",
      "Train Epoch: 311 [45056/54000 (83%)] Loss: -619.896545\n",
      "    epoch          : 311\n",
      "    loss           : -616.8482804208431\n",
      "    ess            : 1.9586123318042394\n",
      "    log_marginal   : 616.8843136193617\n",
      "    log_joint      : 824.7005465525501\n",
      "    val_loss       : -620.1264038085938\n",
      "    val_ess        : 1.958425501982371\n",
      "    val_log_marginal: 620.1638997395834\n",
      "    val_log_joint  : 827.9510396321615\n",
      "Train Epoch: 312 [0/54000 (0%)] Loss: -617.634705\n",
      "Train Epoch: 312 [11264/54000 (21%)] Loss: -621.418640\n",
      "Train Epoch: 312 [22528/54000 (42%)] Loss: -618.253906\n",
      "Train Epoch: 312 [33792/54000 (63%)] Loss: -628.658203\n",
      "Train Epoch: 312 [45056/54000 (83%)] Loss: -598.830566\n",
      "    epoch          : 312\n",
      "    loss           : -617.0316519107458\n",
      "    ess            : 1.958831692641636\n",
      "    log_marginal   : 617.0676068000074\n",
      "    log_joint      : 824.8919240123821\n",
      "    val_loss       : -621.4229838053385\n",
      "    val_ess        : 1.958368718624115\n",
      "    val_log_marginal: 621.4571431477865\n",
      "    val_log_joint  : 829.2047170003256\n",
      "Train Epoch: 313 [0/54000 (0%)] Loss: -626.857788\n",
      "Train Epoch: 313 [11264/54000 (21%)] Loss: -622.625183\n",
      "Train Epoch: 313 [22528/54000 (42%)] Loss: -615.967712\n",
      "Train Epoch: 313 [33792/54000 (63%)] Loss: -617.039795\n",
      "Train Epoch: 313 [45056/54000 (83%)] Loss: -621.285828\n",
      "    epoch          : 313\n",
      "    loss           : -617.9776340700546\n",
      "    ess            : 1.9582079097909748\n",
      "    log_marginal   : 618.013897014114\n",
      "    log_joint      : 825.7125837218086\n",
      "    val_loss       : -622.3159332275391\n",
      "    val_ess        : 1.9596816798051198\n",
      "    val_log_marginal: 622.3543904622396\n",
      "    val_log_joint  : 830.2747701009115\n",
      "Train Epoch: 314 [0/54000 (0%)] Loss: -620.170837\n",
      "Train Epoch: 314 [11264/54000 (21%)] Loss: -636.274292\n",
      "Train Epoch: 314 [22528/54000 (42%)] Loss: -622.399902\n",
      "Train Epoch: 314 [33792/54000 (63%)] Loss: -599.443970\n",
      "Train Epoch: 314 [45056/54000 (83%)] Loss: -601.217102\n",
      "    epoch          : 314\n",
      "    loss           : -617.7509397110849\n",
      "    ess            : 1.958354005273783\n",
      "    log_marginal   : 617.7867207077314\n",
      "    log_joint      : 825.5811675449587\n",
      "    val_loss       : -620.6292317708334\n",
      "    val_ess        : 1.960277299086253\n",
      "    val_log_marginal: 620.6637929280599\n",
      "    val_log_joint  : 828.5663452148438\n",
      "Train Epoch: 315 [0/54000 (0%)] Loss: -616.237488\n",
      "Train Epoch: 315 [11264/54000 (21%)] Loss: -597.314087\n",
      "Train Epoch: 315 [22528/54000 (42%)] Loss: -594.445740\n",
      "Train Epoch: 315 [33792/54000 (63%)] Loss: -627.236206\n",
      "Train Epoch: 315 [45056/54000 (83%)] Loss: -634.400269\n",
      "    epoch          : 315\n",
      "    loss           : -618.3410419967939\n",
      "    ess            : 1.9595683891818207\n",
      "    log_marginal   : 618.3768039919296\n",
      "    log_joint      : 826.2553267568912\n",
      "    val_loss       : -622.2993570963541\n",
      "    val_ess        : 1.9593489170074463\n",
      "    val_log_marginal: 622.335194905599\n",
      "    val_log_joint  : 830.1791483561198\n",
      "Train Epoch: 316 [0/54000 (0%)] Loss: -632.369385\n",
      "Train Epoch: 316 [11264/54000 (21%)] Loss: -610.297913\n",
      "Train Epoch: 316 [22528/54000 (42%)] Loss: -605.763245\n",
      "Train Epoch: 316 [33792/54000 (63%)] Loss: -602.414673\n",
      "Train Epoch: 316 [45056/54000 (83%)] Loss: -630.286621\n",
      "    epoch          : 316\n",
      "    loss           : -619.0686110010687\n",
      "    ess            : 1.958285762453979\n",
      "    log_marginal   : 619.1056530070755\n",
      "    log_joint      : 826.9263484163105\n",
      "    val_loss       : -623.1306610107422\n",
      "    val_ess        : 1.9585950374603271\n",
      "    val_log_marginal: 623.1639099121094\n",
      "    val_log_joint  : 831.1432342529297\n",
      "Train Epoch: 317 [0/54000 (0%)] Loss: -643.077271\n",
      "Train Epoch: 317 [11264/54000 (21%)] Loss: -616.142334\n",
      "Train Epoch: 317 [22528/54000 (42%)] Loss: -623.327332\n",
      "Train Epoch: 317 [33792/54000 (63%)] Loss: -625.143616\n",
      "Train Epoch: 317 [45056/54000 (83%)] Loss: -606.997803\n",
      "    epoch          : 317\n",
      "    loss           : -619.2172200904703\n",
      "    ess            : 1.958646170373233\n",
      "    log_marginal   : 619.2530799721771\n",
      "    log_joint      : 827.0100402832031\n",
      "    val_loss       : -622.1926879882812\n",
      "    val_ess        : 1.9581759174664815\n",
      "    val_log_marginal: 622.2301177978516\n",
      "    val_log_joint  : 829.9971110026041\n",
      "Train Epoch: 318 [0/54000 (0%)] Loss: -630.611145\n",
      "Train Epoch: 318 [11264/54000 (21%)] Loss: -618.983154\n",
      "Train Epoch: 318 [22528/54000 (42%)] Loss: -613.725586\n",
      "Train Epoch: 318 [33792/54000 (63%)] Loss: -640.827026\n",
      "Train Epoch: 318 [45056/54000 (83%)] Loss: -599.274109\n",
      "    epoch          : 318\n",
      "    loss           : -619.2289250211895\n",
      "    ess            : 1.9593852510992087\n",
      "    log_marginal   : 619.264104303324\n",
      "    log_joint      : 827.1589159695608\n",
      "    val_loss       : -623.2048390706381\n",
      "    val_ess        : 1.9604676465193431\n",
      "    val_log_marginal: 623.2375081380209\n",
      "    val_log_joint  : 830.9463907877604\n",
      "Train Epoch: 319 [0/54000 (0%)] Loss: -604.890564\n",
      "Train Epoch: 319 [11264/54000 (21%)] Loss: -620.679932\n",
      "Train Epoch: 319 [22528/54000 (42%)] Loss: -626.077576\n",
      "Train Epoch: 319 [33792/54000 (63%)] Loss: -628.867554\n",
      "Train Epoch: 319 [45056/54000 (83%)] Loss: -627.323120\n",
      "    epoch          : 319\n",
      "    loss           : -620.0171658497936\n",
      "    ess            : 1.9579214026343148\n",
      "    log_marginal   : 620.0543138036188\n",
      "    log_joint      : 827.9034228054983\n",
      "    val_loss       : -624.2908223470052\n",
      "    val_ess        : 1.956845800081889\n",
      "    val_log_marginal: 624.3300221761068\n",
      "    val_log_joint  : 832.2358144124349\n",
      "Train Epoch: 320 [0/54000 (0%)] Loss: -608.347290\n",
      "Train Epoch: 320 [11264/54000 (21%)] Loss: -613.233215\n",
      "Train Epoch: 320 [22528/54000 (42%)] Loss: -649.639038\n",
      "Train Epoch: 320 [33792/54000 (63%)] Loss: -624.243652\n",
      "Train Epoch: 320 [45056/54000 (83%)] Loss: -638.907959\n",
      "    epoch          : 320\n",
      "    loss           : -619.9947705538767\n",
      "    ess            : 1.9593634571669236\n",
      "    log_marginal   : 620.0295934137308\n",
      "    log_joint      : 827.8843717755012\n",
      "    val_loss       : -623.0205281575521\n",
      "    val_ess        : 1.9614430765310924\n",
      "    val_log_marginal: 623.0529073079427\n",
      "    val_log_joint  : 830.8599853515625\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch320.pth ...\n",
      "Train Epoch: 321 [0/54000 (0%)] Loss: -617.537476\n",
      "Train Epoch: 321 [11264/54000 (21%)] Loss: -626.653198\n",
      "Train Epoch: 321 [22528/54000 (42%)] Loss: -623.710022\n",
      "Train Epoch: 321 [33792/54000 (63%)] Loss: -620.218018\n",
      "Train Epoch: 321 [45056/54000 (83%)] Loss: -620.570618\n",
      "    epoch          : 321\n",
      "    loss           : -620.1397895093235\n",
      "    ess            : 1.960211918039142\n",
      "    log_marginal   : 620.1742075794148\n",
      "    log_joint      : 827.884794415168\n",
      "    val_loss       : -624.1057891845703\n",
      "    val_ess        : 1.9596868852774303\n",
      "    val_log_marginal: 624.1404825846354\n",
      "    val_log_joint  : 832.0128122965494\n",
      "Train Epoch: 322 [0/54000 (0%)] Loss: -609.306519\n",
      "Train Epoch: 322 [11264/54000 (21%)] Loss: -632.501343\n",
      "Train Epoch: 322 [22528/54000 (42%)] Loss: -629.053955\n",
      "Train Epoch: 322 [33792/54000 (63%)] Loss: -617.910706\n",
      "Train Epoch: 322 [45056/54000 (83%)] Loss: -636.643433\n",
      "    epoch          : 322\n",
      "    loss           : -621.1158142089844\n",
      "    ess            : 1.9588488554054837\n",
      "    log_marginal   : 621.1515428075251\n",
      "    log_joint      : 828.8895822201135\n",
      "    val_loss       : -625.2041880289713\n",
      "    val_ess        : 1.957169810930888\n",
      "    val_log_marginal: 625.2416687011719\n",
      "    val_log_joint  : 833.0103556315104\n",
      "Train Epoch: 323 [0/54000 (0%)] Loss: -623.632324\n",
      "Train Epoch: 323 [11264/54000 (21%)] Loss: -619.713806\n",
      "Train Epoch: 323 [22528/54000 (42%)] Loss: -631.868225\n",
      "Train Epoch: 323 [33792/54000 (63%)] Loss: -614.240967\n",
      "Train Epoch: 323 [45056/54000 (83%)] Loss: -620.245605\n",
      "    epoch          : 323\n",
      "    loss           : -621.2109864432857\n",
      "    ess            : 1.958757387017304\n",
      "    log_marginal   : 621.2472280826208\n",
      "    log_joint      : 829.0936164136203\n",
      "    val_loss       : -624.4666035970052\n",
      "    val_ess        : 1.9606728752454121\n",
      "    val_log_marginal: 624.4988505045573\n",
      "    val_log_joint  : 832.4473368326823\n",
      "Train Epoch: 324 [0/54000 (0%)] Loss: -645.990601\n",
      "Train Epoch: 324 [11264/54000 (21%)] Loss: -618.483643\n",
      "Train Epoch: 324 [22528/54000 (42%)] Loss: -627.646606\n",
      "Train Epoch: 324 [33792/54000 (63%)] Loss: -619.431030\n",
      "Train Epoch: 324 [45056/54000 (83%)] Loss: -627.888794\n",
      "    epoch          : 324\n",
      "    loss           : -621.1415641352816\n",
      "    ess            : 1.9587678808086324\n",
      "    log_marginal   : 621.1778719920032\n",
      "    log_joint      : 828.9836546699955\n",
      "    val_loss       : -624.9954681396484\n",
      "    val_ess        : 1.960503230492274\n",
      "    val_log_marginal: 625.0313517252604\n",
      "    val_log_joint  : 832.6977081298828\n",
      "Train Epoch: 325 [0/54000 (0%)] Loss: -632.449524\n",
      "Train Epoch: 325 [11264/54000 (21%)] Loss: -635.420593\n",
      "Train Epoch: 325 [22528/54000 (42%)] Loss: -639.391907\n",
      "Train Epoch: 325 [33792/54000 (63%)] Loss: -642.792664\n",
      "Train Epoch: 325 [45056/54000 (83%)] Loss: -605.867920\n",
      "    epoch          : 325\n",
      "    loss           : -621.7559244407797\n",
      "    ess            : 1.9580036986548945\n",
      "    log_marginal   : 621.7918620559404\n",
      "    log_joint      : 829.6533819234596\n",
      "    val_loss       : -625.5648956298828\n",
      "    val_ess        : 1.9577206869920094\n",
      "    val_log_marginal: 625.6038157145182\n",
      "    val_log_joint  : 833.5105997721354\n",
      "Train Epoch: 326 [0/54000 (0%)] Loss: -612.147827\n",
      "Train Epoch: 326 [11264/54000 (21%)] Loss: -624.870605\n",
      "Train Epoch: 326 [22528/54000 (42%)] Loss: -635.433838\n",
      "Train Epoch: 326 [33792/54000 (63%)] Loss: -641.874634\n",
      "Train Epoch: 326 [45056/54000 (83%)] Loss: -627.344971\n",
      "    epoch          : 326\n",
      "    loss           : -622.0403505721182\n",
      "    ess            : 1.958387683022697\n",
      "    log_marginal   : 622.0762283037294\n",
      "    log_joint      : 829.9485358472141\n",
      "    val_loss       : -625.6255086263021\n",
      "    val_ess        : 1.9575142165025075\n",
      "    val_log_marginal: 625.6625264485677\n",
      "    val_log_joint  : 833.5346984863281\n",
      "Train Epoch: 327 [0/54000 (0%)] Loss: -643.863037\n",
      "Train Epoch: 327 [11264/54000 (21%)] Loss: -601.806152\n",
      "Train Epoch: 327 [22528/54000 (42%)] Loss: -632.607971\n",
      "Train Epoch: 327 [33792/54000 (63%)] Loss: -618.272095\n",
      "Train Epoch: 327 [45056/54000 (83%)] Loss: -643.770264\n",
      "    epoch          : 327\n",
      "    loss           : -622.1675040766878\n",
      "    ess            : 1.9596766919459936\n",
      "    log_marginal   : 622.2029747153229\n",
      "    log_joint      : 830.0304692106427\n",
      "    val_loss       : -625.7005666097006\n",
      "    val_ess        : 1.9583163857460022\n",
      "    val_log_marginal: 625.7376556396484\n",
      "    val_log_joint  : 833.4140268961588\n",
      "Train Epoch: 328 [0/54000 (0%)] Loss: -616.719849\n",
      "Train Epoch: 328 [11264/54000 (21%)] Loss: -646.975342\n",
      "Train Epoch: 328 [22528/54000 (42%)] Loss: -619.741577\n",
      "Train Epoch: 328 [33792/54000 (63%)] Loss: -640.436157\n",
      "Train Epoch: 328 [45056/54000 (83%)] Loss: -634.135254\n",
      "    epoch          : 328\n",
      "    loss           : -622.7169454322672\n",
      "    ess            : 1.9590014196791738\n",
      "    log_marginal   : 622.7526774856279\n",
      "    log_joint      : 830.5067109881707\n",
      "    val_loss       : -626.6850789388021\n",
      "    val_ess        : 1.9560761253039043\n",
      "    val_log_marginal: 626.7269287109375\n",
      "    val_log_joint  : 834.4987640380859\n",
      "Train Epoch: 329 [0/54000 (0%)] Loss: -602.679749\n",
      "Train Epoch: 329 [11264/54000 (21%)] Loss: -628.110596\n",
      "Train Epoch: 329 [22528/54000 (42%)] Loss: -622.728882\n",
      "Train Epoch: 329 [33792/54000 (63%)] Loss: -630.106689\n",
      "Train Epoch: 329 [45056/54000 (83%)] Loss: -608.408203\n",
      "    epoch          : 329\n",
      "    loss           : -623.6261481519016\n",
      "    ess            : 1.9588865547809962\n",
      "    log_marginal   : 623.6626926638046\n",
      "    log_joint      : 831.381188158719\n",
      "    val_loss       : -627.8264109293619\n",
      "    val_ess        : 1.9585795799891155\n",
      "    val_log_marginal: 627.8637034098307\n",
      "    val_log_joint  : 835.661855061849\n",
      "Train Epoch: 330 [0/54000 (0%)] Loss: -612.767944\n",
      "Train Epoch: 330 [11264/54000 (21%)] Loss: -642.107239\n",
      "Train Epoch: 330 [22528/54000 (42%)] Loss: -634.395142\n",
      "Train Epoch: 330 [33792/54000 (63%)] Loss: -623.309448\n",
      "Train Epoch: 330 [45056/54000 (83%)] Loss: -615.882935\n",
      "    epoch          : 330\n",
      "    loss           : -623.1983515901386\n",
      "    ess            : 1.9590007572803858\n",
      "    log_marginal   : 623.2346554162367\n",
      "    log_joint      : 830.9753302808078\n",
      "    val_loss       : -626.0959625244141\n",
      "    val_ess        : 1.9601400196552277\n",
      "    val_log_marginal: 626.1328837076823\n",
      "    val_log_joint  : 833.8980356852213\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch330.pth ...\n",
      "Train Epoch: 331 [0/54000 (0%)] Loss: -634.842407\n",
      "Train Epoch: 331 [11264/54000 (21%)] Loss: -638.212036\n",
      "Train Epoch: 331 [22528/54000 (42%)] Loss: -604.446960\n",
      "Train Epoch: 331 [33792/54000 (63%)] Loss: -611.908264\n",
      "Train Epoch: 331 [45056/54000 (83%)] Loss: -633.033447\n",
      "    epoch          : 331\n",
      "    loss           : -623.3850126446418\n",
      "    ess            : 1.958324782128604\n",
      "    log_marginal   : 623.4207256964918\n",
      "    log_joint      : 831.2601139860333\n",
      "    val_loss       : -627.1214396158854\n",
      "    val_ess        : 1.9591532349586487\n",
      "    val_log_marginal: 627.1592864990234\n",
      "    val_log_joint  : 835.050791422526\n",
      "Train Epoch: 332 [0/54000 (0%)] Loss: -621.275146\n",
      "Train Epoch: 332 [11264/54000 (21%)] Loss: -611.595337\n",
      "Train Epoch: 332 [22528/54000 (42%)] Loss: -606.734131\n",
      "Train Epoch: 332 [33792/54000 (63%)] Loss: -624.364929\n",
      "Train Epoch: 332 [45056/54000 (83%)] Loss: -618.999878\n",
      "    epoch          : 332\n",
      "    loss           : -624.4349561007517\n",
      "    ess            : 1.9589700968760364\n",
      "    log_marginal   : 624.4713422667305\n",
      "    log_joint      : 832.2287476737545\n",
      "    val_loss       : -628.1844635009766\n",
      "    val_ess        : 1.95582448442777\n",
      "    val_log_marginal: 628.2278696695963\n",
      "    val_log_joint  : 836.2407073974609\n",
      "Train Epoch: 333 [0/54000 (0%)] Loss: -601.376343\n",
      "Train Epoch: 333 [11264/54000 (21%)] Loss: -636.087646\n",
      "Train Epoch: 333 [22528/54000 (42%)] Loss: -629.469971\n",
      "Train Epoch: 333 [33792/54000 (63%)] Loss: -609.390259\n",
      "Train Epoch: 333 [45056/54000 (83%)] Loss: -607.421997\n",
      "    epoch          : 333\n",
      "    loss           : -624.1267700195312\n",
      "    ess            : 1.958493559990289\n",
      "    log_marginal   : 624.163220099683\n",
      "    log_joint      : 831.997300058041\n",
      "    val_loss       : -626.8422037760416\n",
      "    val_ess        : 1.9586304028828938\n",
      "    val_log_marginal: 626.8786570231119\n",
      "    val_log_joint  : 834.6515401204427\n",
      "Train Epoch: 334 [0/54000 (0%)] Loss: -621.794067\n",
      "Train Epoch: 334 [11264/54000 (21%)] Loss: -640.753174\n",
      "Train Epoch: 334 [22528/54000 (42%)] Loss: -627.716614\n",
      "Train Epoch: 334 [33792/54000 (63%)] Loss: -656.722107\n",
      "Train Epoch: 334 [45056/54000 (83%)] Loss: -637.083496\n",
      "    epoch          : 334\n",
      "    loss           : -624.4875321298275\n",
      "    ess            : 1.9591608384870134\n",
      "    log_marginal   : 624.523919447413\n",
      "    log_joint      : 832.4282946316702\n",
      "    val_loss       : -629.7337544759115\n",
      "    val_ess        : 1.9583771725495656\n",
      "    val_log_marginal: 629.7708384195963\n",
      "    val_log_joint  : 837.3067474365234\n",
      "Train Epoch: 335 [0/54000 (0%)] Loss: -642.937988\n",
      "Train Epoch: 335 [11264/54000 (21%)] Loss: -618.571899\n",
      "Train Epoch: 335 [22528/54000 (42%)] Loss: -624.766479\n",
      "Train Epoch: 335 [33792/54000 (63%)] Loss: -620.763550\n",
      "Train Epoch: 335 [45056/54000 (83%)] Loss: -607.128601\n",
      "    epoch          : 335\n",
      "    loss           : -625.4348927623821\n",
      "    ess            : 1.9585972945645171\n",
      "    log_marginal   : 625.4711557064417\n",
      "    log_joint      : 833.2674618127211\n",
      "    val_loss       : -629.1379648844401\n",
      "    val_ess        : 1.9556137323379517\n",
      "    val_log_marginal: 629.1776529947916\n",
      "    val_log_joint  : 836.9448394775391\n",
      "Train Epoch: 336 [0/54000 (0%)] Loss: -622.009399\n",
      "Train Epoch: 336 [11264/54000 (21%)] Loss: -617.950317\n",
      "Train Epoch: 336 [22528/54000 (42%)] Loss: -626.939575\n",
      "Train Epoch: 336 [33792/54000 (63%)] Loss: -623.648926\n",
      "Train Epoch: 336 [45056/54000 (83%)] Loss: -655.603271\n",
      "    epoch          : 336\n",
      "    loss           : -625.4813560629791\n",
      "    ess            : 1.9580583369956825\n",
      "    log_marginal   : 625.5184291623673\n",
      "    log_joint      : 833.3279459251547\n",
      "    val_loss       : -628.5007934570312\n",
      "    val_ess        : 1.9583376844724019\n",
      "    val_log_marginal: 628.5393015543619\n",
      "    val_log_joint  : 836.4697011311849\n",
      "Train Epoch: 337 [0/54000 (0%)] Loss: -626.303711\n",
      "Train Epoch: 337 [11264/54000 (21%)] Loss: -605.586548\n",
      "Train Epoch: 337 [22528/54000 (42%)] Loss: -653.558044\n",
      "Train Epoch: 337 [33792/54000 (63%)] Loss: -614.894226\n",
      "Train Epoch: 337 [45056/54000 (83%)] Loss: -627.476868\n",
      "    epoch          : 337\n",
      "    loss           : -625.3566975143721\n",
      "    ess            : 1.9584400069038823\n",
      "    log_marginal   : 625.3920224747568\n",
      "    log_joint      : 833.2724649681235\n",
      "    val_loss       : -629.251210530599\n",
      "    val_ess        : 1.9595752954483032\n",
      "    val_log_marginal: 629.2839304606119\n",
      "    val_log_joint  : 837.0787353515625\n",
      "Train Epoch: 338 [0/54000 (0%)] Loss: -636.137207\n",
      "Train Epoch: 338 [11264/54000 (21%)] Loss: -625.374756\n",
      "Train Epoch: 338 [22528/54000 (42%)] Loss: -607.767944\n",
      "Train Epoch: 338 [33792/54000 (63%)] Loss: -617.441711\n",
      "Train Epoch: 338 [45056/54000 (83%)] Loss: -615.865906\n",
      "    epoch          : 338\n",
      "    loss           : -626.2174538666347\n",
      "    ess            : 1.958341586139967\n",
      "    log_marginal   : 626.2537340847952\n",
      "    log_joint      : 834.0586052660672\n",
      "    val_loss       : -630.4308471679688\n",
      "    val_ess        : 1.9572785993417103\n",
      "    val_log_marginal: 630.4694315592448\n",
      "    val_log_joint  : 838.2414855957031\n",
      "Train Epoch: 339 [0/54000 (0%)] Loss: -629.557129\n",
      "Train Epoch: 339 [11264/54000 (21%)] Loss: -641.181519\n",
      "Train Epoch: 339 [22528/54000 (42%)] Loss: -629.707397\n",
      "Train Epoch: 339 [33792/54000 (63%)] Loss: -630.705505\n",
      "Train Epoch: 339 [45056/54000 (83%)] Loss: -645.719360\n",
      "    epoch          : 339\n",
      "    loss           : -626.2876368108786\n",
      "    ess            : 1.9581361986556143\n",
      "    log_marginal   : 626.324135834316\n",
      "    log_joint      : 834.124267578125\n",
      "    val_loss       : -629.9473063151041\n",
      "    val_ess        : 1.957047740618388\n",
      "    val_log_marginal: 629.987070719401\n",
      "    val_log_joint  : 837.6018371582031\n",
      "Train Epoch: 340 [0/54000 (0%)] Loss: -613.351196\n",
      "Train Epoch: 340 [11264/54000 (21%)] Loss: -641.758911\n",
      "Train Epoch: 340 [22528/54000 (42%)] Loss: -622.123901\n",
      "Train Epoch: 340 [33792/54000 (63%)] Loss: -641.482910\n",
      "Train Epoch: 340 [45056/54000 (83%)] Loss: -620.169495\n",
      "    epoch          : 340\n",
      "    loss           : -626.3056870946344\n",
      "    ess            : 1.959220808631969\n",
      "    log_marginal   : 626.3408899847067\n",
      "    log_joint      : 834.2350757526901\n",
      "    val_loss       : -630.1798553466797\n",
      "    val_ess        : 1.9586481352647145\n",
      "    val_log_marginal: 630.2179209391276\n",
      "    val_log_joint  : 837.9529825846354\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch340.pth ...\n",
      "Train Epoch: 341 [0/54000 (0%)] Loss: -636.046875\n",
      "Train Epoch: 341 [11264/54000 (21%)] Loss: -615.356873\n",
      "Train Epoch: 341 [22528/54000 (42%)] Loss: -622.823730\n",
      "Train Epoch: 341 [33792/54000 (63%)] Loss: -625.087585\n",
      "Train Epoch: 341 [45056/54000 (83%)] Loss: -633.313660\n",
      "    epoch          : 341\n",
      "    loss           : -627.1949221053213\n",
      "    ess            : 1.9591727504190408\n",
      "    log_marginal   : 627.2306259443175\n",
      "    log_joint      : 835.0539660183889\n",
      "    val_loss       : -631.3966929117838\n",
      "    val_ess        : 1.9578686555226643\n",
      "    val_log_marginal: 631.4321543375651\n",
      "    val_log_joint  : 839.1936492919922\n",
      "Train Epoch: 342 [0/54000 (0%)] Loss: -633.315063\n",
      "Train Epoch: 342 [11264/54000 (21%)] Loss: -634.856079\n",
      "Train Epoch: 342 [22528/54000 (42%)] Loss: -634.771362\n",
      "Train Epoch: 342 [33792/54000 (63%)] Loss: -642.957886\n",
      "Train Epoch: 342 [45056/54000 (83%)] Loss: -614.942688\n",
      "    epoch          : 342\n",
      "    loss           : -627.2564829700398\n",
      "    ess            : 1.9575801637937438\n",
      "    log_marginal   : 627.2949932746168\n",
      "    log_joint      : 835.1834924086085\n",
      "    val_loss       : -631.1832478841146\n",
      "    val_ess        : 1.955903838078181\n",
      "    val_log_marginal: 631.2217508951823\n",
      "    val_log_joint  : 838.7327016194662\n",
      "Train Epoch: 343 [0/54000 (0%)] Loss: -650.429199\n",
      "Train Epoch: 343 [11264/54000 (21%)] Loss: -609.904236\n",
      "Train Epoch: 343 [22528/54000 (42%)] Loss: -612.987183\n",
      "Train Epoch: 343 [33792/54000 (63%)] Loss: -637.084412\n",
      "Train Epoch: 343 [45056/54000 (83%)] Loss: -657.437317\n",
      "    epoch          : 343\n",
      "    loss           : -627.2582622024248\n",
      "    ess            : 1.9581285827564743\n",
      "    log_marginal   : 627.2944220776828\n",
      "    log_joint      : 835.2503644835274\n",
      "    val_loss       : -630.928944905599\n",
      "    val_ess        : 1.962123990058899\n",
      "    val_log_marginal: 630.9613087972006\n",
      "    val_log_joint  : 838.7329762776693\n",
      "Train Epoch: 344 [0/54000 (0%)] Loss: -628.147095\n",
      "Train Epoch: 344 [11264/54000 (21%)] Loss: -634.668213\n",
      "Train Epoch: 344 [22528/54000 (42%)] Loss: -623.093323\n",
      "Train Epoch: 344 [33792/54000 (63%)] Loss: -629.135742\n",
      "Train Epoch: 344 [45056/54000 (83%)] Loss: -628.399719\n",
      "    epoch          : 344\n",
      "    loss           : -627.7720475106869\n",
      "    ess            : 1.9585646121007092\n",
      "    log_marginal   : 627.8079903080778\n",
      "    log_joint      : 835.7470490077757\n",
      "    val_loss       : -632.5414072672526\n",
      "    val_ess        : 1.958884100119273\n",
      "    val_log_marginal: 632.5776723225912\n",
      "    val_log_joint  : 840.2222391764323\n",
      "Train Epoch: 345 [0/54000 (0%)] Loss: -613.363098\n",
      "Train Epoch: 345 [11264/54000 (21%)] Loss: -627.997681\n",
      "Train Epoch: 345 [22528/54000 (42%)] Loss: -621.010864\n",
      "Train Epoch: 345 [33792/54000 (63%)] Loss: -640.400757\n",
      "Train Epoch: 345 [45056/54000 (83%)] Loss: -612.936401\n",
      "    epoch          : 345\n",
      "    loss           : -628.5531696823408\n",
      "    ess            : 1.9586502459813964\n",
      "    log_marginal   : 628.5892443387014\n",
      "    log_joint      : 836.3732265256485\n",
      "    val_loss       : -632.0625762939453\n",
      "    val_ess        : 1.95887953042984\n",
      "    val_log_marginal: 632.0982767740885\n",
      "    val_log_joint  : 839.9206085205078\n",
      "Train Epoch: 346 [0/54000 (0%)] Loss: -616.923523\n",
      "Train Epoch: 346 [11264/54000 (21%)] Loss: -628.739258\n",
      "Train Epoch: 346 [22528/54000 (42%)] Loss: -638.336670\n",
      "Train Epoch: 346 [33792/54000 (63%)] Loss: -650.957581\n",
      "Train Epoch: 346 [45056/54000 (83%)] Loss: -623.820190\n",
      "    epoch          : 346\n",
      "    loss           : -628.3589817263046\n",
      "    ess            : 1.95845812784051\n",
      "    log_marginal   : 628.3945876787294\n",
      "    log_joint      : 836.2422318368588\n",
      "    val_loss       : -631.2900187174479\n",
      "    val_ess        : 1.955944796403249\n",
      "    val_log_marginal: 631.3272145589193\n",
      "    val_log_joint  : 839.1220703125\n",
      "Train Epoch: 347 [0/54000 (0%)] Loss: -614.519409\n",
      "Train Epoch: 347 [11264/54000 (21%)] Loss: -652.744385\n",
      "Train Epoch: 347 [22528/54000 (42%)] Loss: -633.989990\n",
      "Train Epoch: 347 [33792/54000 (63%)] Loss: -621.781067\n",
      "Train Epoch: 347 [45056/54000 (83%)] Loss: -617.573425\n",
      "    epoch          : 347\n",
      "    loss           : -628.9116700370357\n",
      "    ess            : 1.9593993526584697\n",
      "    log_marginal   : 628.9467145811836\n",
      "    log_joint      : 836.8457958293411\n",
      "    val_loss       : -631.9953308105469\n",
      "    val_ess        : 1.9588531653086345\n",
      "    val_log_marginal: 632.0332489013672\n",
      "    val_log_joint  : 840.2424265543619\n",
      "Train Epoch: 348 [0/54000 (0%)] Loss: -625.020508\n",
      "Train Epoch: 348 [11264/54000 (21%)] Loss: -636.529480\n",
      "Train Epoch: 348 [22528/54000 (42%)] Loss: -623.986816\n",
      "Train Epoch: 348 [33792/54000 (63%)] Loss: -635.789917\n",
      "Train Epoch: 348 [45056/54000 (83%)] Loss: -627.942322\n",
      "    epoch          : 348\n",
      "    loss           : -629.5713362783756\n",
      "    ess            : 1.9593190472081023\n",
      "    log_marginal   : 629.6076291642099\n",
      "    log_joint      : 837.4413578825177\n",
      "    val_loss       : -633.2085113525391\n",
      "    val_ess        : 1.9609752297401428\n",
      "    val_log_marginal: 633.2413279215494\n",
      "    val_log_joint  : 841.1918131510416\n",
      "Train Epoch: 349 [0/54000 (0%)] Loss: -637.161987\n",
      "Train Epoch: 349 [11264/54000 (21%)] Loss: -628.877930\n",
      "Train Epoch: 349 [22528/54000 (42%)] Loss: -634.597046\n",
      "Train Epoch: 349 [33792/54000 (63%)] Loss: -627.086182\n",
      "Train Epoch: 349 [45056/54000 (83%)] Loss: -637.037964\n",
      "    epoch          : 349\n",
      "    loss           : -629.58963300597\n",
      "    ess            : 1.9581389922016073\n",
      "    log_marginal   : 629.6266876796507\n",
      "    log_joint      : 837.3952227898363\n",
      "    val_loss       : -632.9572194417318\n",
      "    val_ess        : 1.9552799860636394\n",
      "    val_log_marginal: 632.9975280761719\n",
      "    val_log_joint  : 840.7397918701172\n",
      "Train Epoch: 350 [0/54000 (0%)] Loss: -625.390015\n",
      "Train Epoch: 350 [11264/54000 (21%)] Loss: -637.062012\n",
      "Train Epoch: 350 [22528/54000 (42%)] Loss: -616.738281\n",
      "Train Epoch: 350 [33792/54000 (63%)] Loss: -629.706177\n",
      "Train Epoch: 350 [45056/54000 (83%)] Loss: -603.233459\n",
      "    epoch          : 350\n",
      "    loss           : -629.8732679834906\n",
      "    ess            : 1.9597234264859613\n",
      "    log_marginal   : 629.909634572155\n",
      "    log_joint      : 837.6996724830484\n",
      "    val_loss       : -633.9243316650391\n",
      "    val_ess        : 1.95831694205602\n",
      "    val_log_marginal: 633.9589792887369\n",
      "    val_log_joint  : 841.6199289957682\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch350.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 351 [0/54000 (0%)] Loss: -650.653809\n",
      "Train Epoch: 351 [11264/54000 (21%)] Loss: -608.762939\n",
      "Train Epoch: 351 [22528/54000 (42%)] Loss: -633.630920\n",
      "Train Epoch: 351 [33792/54000 (63%)] Loss: -623.079468\n",
      "Train Epoch: 351 [45056/54000 (83%)] Loss: -650.150452\n",
      "    epoch          : 351\n",
      "    loss           : -630.4908228460348\n",
      "    ess            : 1.9594127805727832\n",
      "    log_marginal   : 630.5254228699882\n",
      "    log_joint      : 838.3586402749115\n",
      "    val_loss       : -634.1140441894531\n",
      "    val_ess        : 1.9597364862759907\n",
      "    val_log_marginal: 634.1457010904948\n",
      "    val_log_joint  : 841.8068186442057\n",
      "Train Epoch: 352 [0/54000 (0%)] Loss: -629.718628\n",
      "Train Epoch: 352 [11264/54000 (21%)] Loss: -639.431519\n",
      "Train Epoch: 352 [22528/54000 (42%)] Loss: -630.931152\n",
      "Train Epoch: 352 [33792/54000 (63%)] Loss: -612.108887\n",
      "Train Epoch: 352 [45056/54000 (83%)] Loss: -629.234619\n",
      "    epoch          : 352\n",
      "    loss           : -630.5239994840802\n",
      "    ess            : 1.958492046257235\n",
      "    log_marginal   : 630.5604829608269\n",
      "    log_joint      : 838.4160962374705\n",
      "    val_loss       : -633.7767232259115\n",
      "    val_ess        : 1.958927144606908\n",
      "    val_log_marginal: 633.8110911051432\n",
      "    val_log_joint  : 841.7417195638021\n",
      "Train Epoch: 353 [0/54000 (0%)] Loss: -649.081177\n",
      "Train Epoch: 353 [11264/54000 (21%)] Loss: -636.018433\n",
      "Train Epoch: 353 [22528/54000 (42%)] Loss: -622.797424\n",
      "Train Epoch: 353 [33792/54000 (63%)] Loss: -620.136353\n",
      "Train Epoch: 353 [45056/54000 (83%)] Loss: -608.703918\n",
      "    epoch          : 353\n",
      "    loss           : -630.7367386727963\n",
      "    ess            : 1.9579774028850052\n",
      "    log_marginal   : 630.773542872015\n",
      "    log_joint      : 838.6128459426592\n",
      "    val_loss       : -634.6522318522135\n",
      "    val_ess        : 1.9563646515210469\n",
      "    val_log_marginal: 634.6928965250651\n",
      "    val_log_joint  : 842.5956522623698\n",
      "Train Epoch: 354 [0/54000 (0%)] Loss: -617.832153\n",
      "Train Epoch: 354 [11264/54000 (21%)] Loss: -643.651001\n",
      "Train Epoch: 354 [22528/54000 (42%)] Loss: -608.966431\n",
      "Train Epoch: 354 [33792/54000 (63%)] Loss: -606.527527\n",
      "Train Epoch: 354 [45056/54000 (83%)] Loss: -648.611328\n",
      "    epoch          : 354\n",
      "    loss           : -631.4312594431751\n",
      "    ess            : 1.9581655050223727\n",
      "    log_marginal   : 631.4679859089401\n",
      "    log_joint      : 839.3811754910452\n",
      "    val_loss       : -635.5793050130209\n",
      "    val_ess        : 1.9631151755650837\n",
      "    val_log_marginal: 635.6128540039062\n",
      "    val_log_joint  : 843.5052235921224\n",
      "Train Epoch: 355 [0/54000 (0%)] Loss: -625.811279\n",
      "Train Epoch: 355 [11264/54000 (21%)] Loss: -649.629761\n",
      "Train Epoch: 355 [22528/54000 (42%)] Loss: -614.048096\n",
      "Train Epoch: 355 [33792/54000 (63%)] Loss: -645.737427\n",
      "Train Epoch: 355 [45056/54000 (83%)] Loss: -632.423950\n",
      "    epoch          : 355\n",
      "    loss           : -631.6049188577904\n",
      "    ess            : 1.957787368657454\n",
      "    log_marginal   : 631.6414345795254\n",
      "    log_joint      : 839.5708508761423\n",
      "    val_loss       : -635.2531433105469\n",
      "    val_ess        : 1.956900914510091\n",
      "    val_log_marginal: 635.2915954589844\n",
      "    val_log_joint  : 842.9694976806641\n",
      "Train Epoch: 356 [0/54000 (0%)] Loss: -621.963013\n",
      "Train Epoch: 356 [11264/54000 (21%)] Loss: -626.096069\n",
      "Train Epoch: 356 [22528/54000 (42%)] Loss: -640.778931\n",
      "Train Epoch: 356 [33792/54000 (63%)] Loss: -647.990356\n",
      "Train Epoch: 356 [45056/54000 (83%)] Loss: -636.528320\n",
      "    epoch          : 356\n",
      "    loss           : -631.77664472472\n",
      "    ess            : 1.9583942519043975\n",
      "    log_marginal   : 631.8136395148512\n",
      "    log_joint      : 839.7692744417011\n",
      "    val_loss       : -635.4684193929037\n",
      "    val_ess        : 1.9610507090886433\n",
      "    val_log_marginal: 635.5035705566406\n",
      "    val_log_joint  : 843.6853586832682\n",
      "Train Epoch: 357 [0/54000 (0%)] Loss: -637.534546\n",
      "Train Epoch: 357 [11264/54000 (21%)] Loss: -628.957275\n",
      "Train Epoch: 357 [22528/54000 (42%)] Loss: -621.570740\n",
      "Train Epoch: 357 [33792/54000 (63%)] Loss: -622.533630\n",
      "Train Epoch: 357 [45056/54000 (83%)] Loss: -634.901428\n",
      "    epoch          : 357\n",
      "    loss           : -632.5090873286409\n",
      "    ess            : 1.9570858208638318\n",
      "    log_marginal   : 632.5472521512014\n",
      "    log_joint      : 840.362275897332\n",
      "    val_loss       : -636.5661926269531\n",
      "    val_ess        : 1.9583273033301036\n",
      "    val_log_marginal: 636.6027679443359\n",
      "    val_log_joint  : 844.2890777587891\n",
      "Train Epoch: 358 [0/54000 (0%)] Loss: -633.493530\n",
      "Train Epoch: 358 [11264/54000 (21%)] Loss: -642.713501\n",
      "Train Epoch: 358 [22528/54000 (42%)] Loss: -644.824036\n",
      "Train Epoch: 358 [33792/54000 (63%)] Loss: -641.133545\n",
      "Train Epoch: 358 [45056/54000 (83%)] Loss: -632.743164\n",
      "    epoch          : 358\n",
      "    loss           : -632.6872667996389\n",
      "    ess            : 1.9576465318787772\n",
      "    log_marginal   : 632.7244383614018\n",
      "    log_joint      : 840.6283857237618\n",
      "    val_loss       : -635.6733347574869\n",
      "    val_ess        : 1.9576763113339741\n",
      "    val_log_marginal: 635.7128550211588\n",
      "    val_log_joint  : 843.7291158040365\n",
      "Train Epoch: 359 [0/54000 (0%)] Loss: -616.137451\n",
      "Train Epoch: 359 [11264/54000 (21%)] Loss: -621.417480\n",
      "Train Epoch: 359 [22528/54000 (42%)] Loss: -635.773926\n",
      "Train Epoch: 359 [33792/54000 (63%)] Loss: -624.238770\n",
      "Train Epoch: 359 [45056/54000 (83%)] Loss: -632.577271\n",
      "    epoch          : 359\n",
      "    loss           : -632.764863787957\n",
      "    ess            : 1.9592966920924637\n",
      "    log_marginal   : 632.8009505361881\n",
      "    log_joint      : 840.6427399257444\n",
      "    val_loss       : -636.584726969401\n",
      "    val_ess        : 1.9588059782981873\n",
      "    val_log_marginal: 636.624033610026\n",
      "    val_log_joint  : 844.4500071207682\n",
      "Train Epoch: 360 [0/54000 (0%)] Loss: -636.611694\n",
      "Train Epoch: 360 [11264/54000 (21%)] Loss: -631.399048\n",
      "Train Epoch: 360 [22528/54000 (42%)] Loss: -666.892944\n",
      "Train Epoch: 360 [33792/54000 (63%)] Loss: -632.708496\n",
      "Train Epoch: 360 [45056/54000 (83%)] Loss: -652.000977\n",
      "    epoch          : 360\n",
      "    loss           : -633.3411439139888\n",
      "    ess            : 1.9593876589019343\n",
      "    log_marginal   : 633.3766629201061\n",
      "    log_joint      : 841.3331805535082\n",
      "    val_loss       : -637.4679819742838\n",
      "    val_ess        : 1.9575291872024536\n",
      "    val_log_marginal: 637.5060017903646\n",
      "    val_log_joint  : 845.1231638590494\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch360.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 361 [0/54000 (0%)] Loss: -653.586670\n",
      "Train Epoch: 361 [11264/54000 (21%)] Loss: -641.240845\n",
      "Train Epoch: 361 [22528/54000 (42%)] Loss: -655.120850\n",
      "Train Epoch: 361 [33792/54000 (63%)] Loss: -637.135864\n",
      "Train Epoch: 361 [45056/54000 (83%)] Loss: -637.770386\n",
      "    epoch          : 361\n",
      "    loss           : -633.7852552881781\n",
      "    ess            : 1.9582662346228115\n",
      "    log_marginal   : 633.8219425993145\n",
      "    log_joint      : 841.6377194962412\n",
      "    val_loss       : -637.6051127115885\n",
      "    val_ess        : 1.9600701828797658\n",
      "    val_log_marginal: 637.6395772298177\n",
      "    val_log_joint  : 845.6080169677734\n",
      "Train Epoch: 362 [0/54000 (0%)] Loss: -657.532898\n",
      "Train Epoch: 362 [11264/54000 (21%)] Loss: -630.023926\n",
      "Train Epoch: 362 [22528/54000 (42%)] Loss: -615.035583\n",
      "Train Epoch: 362 [33792/54000 (63%)] Loss: -628.312500\n",
      "Train Epoch: 362 [45056/54000 (83%)] Loss: -617.661804\n",
      "    epoch          : 362\n",
      "    loss           : -633.9764899487766\n",
      "    ess            : 1.9571505863711518\n",
      "    log_marginal   : 634.0138342515478\n",
      "    log_joint      : 841.8759569851858\n",
      "    val_loss       : -637.4651997884115\n",
      "    val_ess        : 1.9591935674349468\n",
      "    val_log_marginal: 637.5006256103516\n",
      "    val_log_joint  : 845.3539326985677\n",
      "Train Epoch: 363 [0/54000 (0%)] Loss: -628.139526\n",
      "Train Epoch: 363 [11264/54000 (21%)] Loss: -627.463989\n",
      "Train Epoch: 363 [22528/54000 (42%)] Loss: -620.664062\n",
      "Train Epoch: 363 [33792/54000 (63%)] Loss: -623.842957\n",
      "Train Epoch: 363 [45056/54000 (83%)] Loss: -654.012573\n",
      "    epoch          : 363\n",
      "    loss           : -634.2382167600235\n",
      "    ess            : 1.9589952185468853\n",
      "    log_marginal   : 634.2730868357532\n",
      "    log_joint      : 842.0899197560436\n",
      "    val_loss       : -638.7454630533854\n",
      "    val_ess        : 1.9572975039482117\n",
      "    val_log_marginal: 638.7806193033854\n",
      "    val_log_joint  : 846.6567738850912\n",
      "Train Epoch: 364 [0/54000 (0%)] Loss: -648.520752\n",
      "Train Epoch: 364 [11264/54000 (21%)] Loss: -637.700806\n",
      "Train Epoch: 364 [22528/54000 (42%)] Loss: -641.955383\n",
      "Train Epoch: 364 [33792/54000 (63%)] Loss: -623.790405\n",
      "Train Epoch: 364 [45056/54000 (83%)] Loss: -635.680725\n",
      "    epoch          : 364\n",
      "    loss           : -634.7344636737175\n",
      "    ess            : 1.9580454533954836\n",
      "    log_marginal   : 634.7718419488871\n",
      "    log_joint      : 842.7061825158461\n",
      "    val_loss       : -638.5474141438802\n",
      "    val_ess        : 1.9648852149645488\n",
      "    val_log_marginal: 638.5744018554688\n",
      "    val_log_joint  : 846.4799092610677\n",
      "Train Epoch: 365 [0/54000 (0%)] Loss: -624.111694\n",
      "Train Epoch: 365 [11264/54000 (21%)] Loss: -638.449707\n",
      "Train Epoch: 365 [22528/54000 (42%)] Loss: -638.445435\n",
      "Train Epoch: 365 [33792/54000 (63%)] Loss: -626.236450\n",
      "Train Epoch: 365 [45056/54000 (83%)] Loss: -642.973022\n",
      "    epoch          : 365\n",
      "    loss           : -634.9122942078789\n",
      "    ess            : 1.9584146366929107\n",
      "    log_marginal   : 634.9488300827314\n",
      "    log_joint      : 842.829966419148\n",
      "    val_loss       : -638.3119201660156\n",
      "    val_ess        : 1.9620149334271748\n",
      "    val_log_marginal: 638.3463134765625\n",
      "    val_log_joint  : 846.2801920572916\n",
      "Train Epoch: 366 [0/54000 (0%)] Loss: -660.356201\n",
      "Train Epoch: 366 [11264/54000 (21%)] Loss: -627.333923\n",
      "Train Epoch: 366 [22528/54000 (42%)] Loss: -634.800049\n",
      "Train Epoch: 366 [33792/54000 (63%)] Loss: -619.120605\n",
      "Train Epoch: 366 [45056/54000 (83%)] Loss: -655.160156\n",
      "    epoch          : 366\n",
      "    loss           : -635.0605509056235\n",
      "    ess            : 1.9590914991666686\n",
      "    log_marginal   : 635.0959927540905\n",
      "    log_joint      : 842.9896643296728\n",
      "    val_loss       : -639.3582356770834\n",
      "    val_ess        : 1.9596311549345653\n",
      "    val_log_marginal: 639.3896026611328\n",
      "    val_log_joint  : 847.0443115234375\n",
      "Train Epoch: 367 [0/54000 (0%)] Loss: -638.464783\n",
      "Train Epoch: 367 [11264/54000 (21%)] Loss: -639.963928\n",
      "Train Epoch: 367 [22528/54000 (42%)] Loss: -636.677063\n",
      "Train Epoch: 367 [33792/54000 (63%)] Loss: -626.931641\n",
      "Train Epoch: 367 [45056/54000 (83%)] Loss: -639.451599\n",
      "    epoch          : 367\n",
      "    loss           : -635.8485257130749\n",
      "    ess            : 1.9583144142942608\n",
      "    log_marginal   : 635.8852446933962\n",
      "    log_joint      : 843.7137589364681\n",
      "    val_loss       : -639.416005452474\n",
      "    val_ess        : 1.9576257566610973\n",
      "    val_log_marginal: 639.4512074788412\n",
      "    val_log_joint  : 847.3840179443359\n",
      "Train Epoch: 368 [0/54000 (0%)] Loss: -644.982178\n",
      "Train Epoch: 368 [11264/54000 (21%)] Loss: -628.631714\n",
      "Train Epoch: 368 [22528/54000 (42%)] Loss: -646.195129\n",
      "Train Epoch: 368 [33792/54000 (63%)] Loss: -621.187622\n",
      "Train Epoch: 368 [45056/54000 (83%)] Loss: -638.249390\n",
      "    epoch          : 368\n",
      "    loss           : -636.1271880527712\n",
      "    ess            : 1.9574137363793715\n",
      "    log_marginal   : 636.1642208459242\n",
      "    log_joint      : 844.0592806834095\n",
      "    val_loss       : -639.6660105387369\n",
      "    val_ess        : 1.957750529050827\n",
      "    val_log_marginal: 639.7020416259766\n",
      "    val_log_joint  : 847.7500559488932\n",
      "Train Epoch: 369 [0/54000 (0%)] Loss: -623.054810\n",
      "Train Epoch: 369 [11264/54000 (21%)] Loss: -657.630005\n",
      "Train Epoch: 369 [22528/54000 (42%)] Loss: -615.886108\n",
      "Train Epoch: 369 [33792/54000 (63%)] Loss: -628.133972\n",
      "Train Epoch: 369 [45056/54000 (83%)] Loss: -656.209534\n",
      "    epoch          : 369\n",
      "    loss           : -635.937862180314\n",
      "    ess            : 1.9586483285112202\n",
      "    log_marginal   : 635.9731387732164\n",
      "    log_joint      : 843.8826316977447\n",
      "    val_loss       : -639.9102376302084\n",
      "    val_ess        : 1.9552143116792042\n",
      "    val_log_marginal: 639.9474182128906\n",
      "    val_log_joint  : 847.8162231445312\n",
      "Train Epoch: 370 [0/54000 (0%)] Loss: -639.324585\n",
      "Train Epoch: 370 [11264/54000 (21%)] Loss: -625.656555\n",
      "Train Epoch: 370 [22528/54000 (42%)] Loss: -653.471680\n",
      "Train Epoch: 370 [33792/54000 (63%)] Loss: -626.222046\n",
      "Train Epoch: 370 [45056/54000 (83%)] Loss: -653.726318\n",
      "    epoch          : 370\n",
      "    loss           : -636.6893005371094\n",
      "    ess            : 1.9588482874744344\n",
      "    log_marginal   : 636.7254166513119\n",
      "    log_joint      : 844.6608489414431\n",
      "    val_loss       : -641.1744283040365\n",
      "    val_ess        : 1.957384963830312\n",
      "    val_log_marginal: 641.2150421142578\n",
      "    val_log_joint  : 848.9631856282552\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch370.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 371 [0/54000 (0%)] Loss: -649.249084\n",
      "Train Epoch: 371 [11264/54000 (21%)] Loss: -658.033508\n",
      "Train Epoch: 371 [22528/54000 (42%)] Loss: -622.931641\n",
      "Train Epoch: 371 [33792/54000 (63%)] Loss: -642.628906\n",
      "Train Epoch: 371 [45056/54000 (83%)] Loss: -636.985962\n",
      "    epoch          : 371\n",
      "    loss           : -637.1075923127948\n",
      "    ess            : 1.9574560466802344\n",
      "    log_marginal   : 637.1461112544222\n",
      "    log_joint      : 845.0522293954525\n",
      "    val_loss       : -640.5565897623698\n",
      "    val_ess        : 1.9597718914349873\n",
      "    val_log_marginal: 640.5885264078776\n",
      "    val_log_joint  : 848.4525197347006\n",
      "Train Epoch: 372 [0/54000 (0%)] Loss: -647.268005\n",
      "Train Epoch: 372 [11264/54000 (21%)] Loss: -628.072388\n",
      "Train Epoch: 372 [22528/54000 (42%)] Loss: -644.318848\n",
      "Train Epoch: 372 [33792/54000 (63%)] Loss: -620.074951\n",
      "Train Epoch: 372 [45056/54000 (83%)] Loss: -654.630554\n",
      "    epoch          : 372\n",
      "    loss           : -636.9894455243956\n",
      "    ess            : 1.958057147152019\n",
      "    log_marginal   : 637.026387916421\n",
      "    log_joint      : 844.8824871711012\n",
      "    val_loss       : -640.6690979003906\n",
      "    val_ess        : 1.961108793814977\n",
      "    val_log_marginal: 640.7034962972006\n",
      "    val_log_joint  : 848.4963328043619\n",
      "Train Epoch: 373 [0/54000 (0%)] Loss: -651.589355\n",
      "Train Epoch: 373 [11264/54000 (21%)] Loss: -646.112122\n",
      "Train Epoch: 373 [22528/54000 (42%)] Loss: -641.652100\n",
      "Train Epoch: 373 [33792/54000 (63%)] Loss: -636.746460\n",
      "Train Epoch: 373 [45056/54000 (83%)] Loss: -637.915894\n",
      "    epoch          : 373\n",
      "    loss           : -637.6717805682488\n",
      "    ess            : 1.9589174839685548\n",
      "    log_marginal   : 637.7078586794296\n",
      "    log_joint      : 845.542648027528\n",
      "    val_loss       : -641.0581563313802\n",
      "    val_ess        : 1.9544516106446583\n",
      "    val_log_marginal: 641.1006469726562\n",
      "    val_log_joint  : 849.1357269287109\n",
      "Train Epoch: 374 [0/54000 (0%)] Loss: -655.645020\n",
      "Train Epoch: 374 [11264/54000 (21%)] Loss: -655.177856\n",
      "Train Epoch: 374 [22528/54000 (42%)] Loss: -626.225708\n",
      "Train Epoch: 374 [33792/54000 (63%)] Loss: -644.103821\n",
      "Train Epoch: 374 [45056/54000 (83%)] Loss: -633.247314\n",
      "    epoch          : 374\n",
      "    loss           : -638.1820425357458\n",
      "    ess            : 1.95783376581264\n",
      "    log_marginal   : 638.2192497973172\n",
      "    log_joint      : 846.0548222379864\n",
      "    val_loss       : -641.496826171875\n",
      "    val_ess        : 1.9576630393664043\n",
      "    val_log_marginal: 641.5360056559244\n",
      "    val_log_joint  : 849.5300750732422\n",
      "Train Epoch: 375 [0/54000 (0%)] Loss: -629.312622\n",
      "Train Epoch: 375 [11264/54000 (21%)] Loss: -630.308472\n",
      "Train Epoch: 375 [22528/54000 (42%)] Loss: -634.355469\n",
      "Train Epoch: 375 [33792/54000 (63%)] Loss: -661.676514\n",
      "Train Epoch: 375 [45056/54000 (83%)] Loss: -647.069519\n",
      "    epoch          : 375\n",
      "    loss           : -638.066741367556\n",
      "    ess            : 1.959224616581539\n",
      "    log_marginal   : 638.1012953272406\n",
      "    log_joint      : 846.0194926711748\n",
      "    val_loss       : -641.8050740559896\n",
      "    val_ess        : 1.9575431843598683\n",
      "    val_log_marginal: 641.8411458333334\n",
      "    val_log_joint  : 849.5696919759115\n",
      "Train Epoch: 376 [0/54000 (0%)] Loss: -642.029785\n",
      "Train Epoch: 376 [11264/54000 (21%)] Loss: -653.865784\n",
      "Train Epoch: 376 [22528/54000 (42%)] Loss: -635.185730\n",
      "Train Epoch: 376 [33792/54000 (63%)] Loss: -629.697754\n",
      "Train Epoch: 376 [45056/54000 (83%)] Loss: -636.086670\n",
      "    epoch          : 376\n",
      "    loss           : -638.5622472223246\n",
      "    ess            : 1.959243022045999\n",
      "    log_marginal   : 638.5968449430645\n",
      "    log_joint      : 846.517133029002\n",
      "    val_loss       : -642.4091339111328\n",
      "    val_ess        : 1.9588709572951\n",
      "    val_log_marginal: 642.4465484619141\n",
      "    val_log_joint  : 850.2263590494791\n",
      "Train Epoch: 377 [0/54000 (0%)] Loss: -631.452515\n",
      "Train Epoch: 377 [11264/54000 (21%)] Loss: -636.652588\n",
      "Train Epoch: 377 [22528/54000 (42%)] Loss: -639.780457\n",
      "Train Epoch: 377 [33792/54000 (63%)] Loss: -642.203186\n",
      "Train Epoch: 377 [45056/54000 (83%)] Loss: -623.520752\n",
      "    epoch          : 377\n",
      "    loss           : -639.3566508742998\n",
      "    ess            : 1.9583344898133908\n",
      "    log_marginal   : 639.3927163178066\n",
      "    log_joint      : 847.125850461564\n",
      "    val_loss       : -643.2579803466797\n",
      "    val_ess        : 1.9599986970424652\n",
      "    val_log_marginal: 643.2946421305338\n",
      "    val_log_joint  : 851.0782063802084\n",
      "Train Epoch: 378 [0/54000 (0%)] Loss: -645.695801\n",
      "Train Epoch: 378 [11264/54000 (21%)] Loss: -633.860779\n",
      "Train Epoch: 378 [22528/54000 (42%)] Loss: -613.948975\n",
      "Train Epoch: 378 [33792/54000 (63%)] Loss: -646.519043\n",
      "Train Epoch: 378 [45056/54000 (83%)] Loss: -639.971008\n",
      "    epoch          : 378\n",
      "    loss           : -638.8124562389446\n",
      "    ess            : 1.9590249421461574\n",
      "    log_marginal   : 638.8479090276754\n",
      "    log_joint      : 846.7350014740566\n",
      "    val_loss       : -642.4153696695963\n",
      "    val_ess        : 1.9604151844978333\n",
      "    val_log_marginal: 642.4501037597656\n",
      "    val_log_joint  : 850.5741831461588\n",
      "Train Epoch: 379 [0/54000 (0%)] Loss: -650.454834\n",
      "Train Epoch: 379 [11264/54000 (21%)] Loss: -640.958618\n",
      "Train Epoch: 379 [22528/54000 (42%)] Loss: -624.722351\n",
      "Train Epoch: 379 [33792/54000 (63%)] Loss: -651.812500\n",
      "Train Epoch: 379 [45056/54000 (83%)] Loss: -622.545532\n",
      "    epoch          : 379\n",
      "    loss           : -639.324735821418\n",
      "    ess            : 1.9583474858751837\n",
      "    log_marginal   : 639.3596698113207\n",
      "    log_joint      : 847.3395535451061\n",
      "    val_loss       : -643.1133677164713\n",
      "    val_ess        : 1.9618150889873505\n",
      "    val_log_marginal: 643.1431732177734\n",
      "    val_log_joint  : 850.7704060872396\n",
      "Train Epoch: 380 [0/54000 (0%)] Loss: -664.500305\n",
      "Train Epoch: 380 [11264/54000 (21%)] Loss: -631.779541\n",
      "Train Epoch: 380 [22528/54000 (42%)] Loss: -619.768677\n",
      "Train Epoch: 380 [33792/54000 (63%)] Loss: -645.518372\n",
      "Train Epoch: 380 [45056/54000 (83%)] Loss: -656.265198\n",
      "    epoch          : 380\n",
      "    loss           : -639.9784165868219\n",
      "    ess            : 1.9577826396474298\n",
      "    log_marginal   : 640.0140110231796\n",
      "    log_joint      : 847.9745322173496\n",
      "    val_loss       : -644.5628865559896\n",
      "    val_ess        : 1.956794003645579\n",
      "    val_log_marginal: 644.6048889160156\n",
      "    val_log_joint  : 851.9756825764974\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch380.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 381 [0/54000 (0%)] Loss: -658.699951\n",
      "Train Epoch: 381 [11264/54000 (21%)] Loss: -628.210754\n",
      "Train Epoch: 381 [22528/54000 (42%)] Loss: -632.452332\n",
      "Train Epoch: 381 [33792/54000 (63%)] Loss: -632.411926\n",
      "Train Epoch: 381 [45056/54000 (83%)] Loss: -660.606934\n",
      "    epoch          : 381\n",
      "    loss           : -640.3321239543411\n",
      "    ess            : 1.958438568520096\n",
      "    log_marginal   : 640.3674155181309\n",
      "    log_joint      : 848.2063431649838\n",
      "    val_loss       : -643.6663411458334\n",
      "    val_ess        : 1.9592404166857402\n",
      "    val_log_marginal: 643.7013041178385\n",
      "    val_log_joint  : 851.6194966634115\n",
      "Train Epoch: 382 [0/54000 (0%)] Loss: -637.168945\n",
      "Train Epoch: 382 [11264/54000 (21%)] Loss: -659.769470\n",
      "Train Epoch: 382 [22528/54000 (42%)] Loss: -634.922607\n",
      "Train Epoch: 382 [33792/54000 (63%)] Loss: -635.560242\n",
      "Train Epoch: 382 [45056/54000 (83%)] Loss: -635.788940\n",
      "    epoch          : 382\n",
      "    loss           : -640.2053585412367\n",
      "    ess            : 1.9578347768423692\n",
      "    log_marginal   : 640.2415218713148\n",
      "    log_joint      : 848.2176260318396\n",
      "    val_loss       : -643.8718617757162\n",
      "    val_ess        : 1.9578384359677632\n",
      "    val_log_marginal: 643.9083557128906\n",
      "    val_log_joint  : 851.8942311604818\n",
      "Train Epoch: 383 [0/54000 (0%)] Loss: -623.577393\n",
      "Train Epoch: 383 [11264/54000 (21%)] Loss: -648.378906\n",
      "Train Epoch: 383 [22528/54000 (42%)] Loss: -649.082336\n",
      "Train Epoch: 383 [33792/54000 (63%)] Loss: -634.263367\n",
      "Train Epoch: 383 [45056/54000 (83%)] Loss: -632.090820\n",
      "    epoch          : 383\n",
      "    loss           : -640.9334641942438\n",
      "    ess            : 1.958971916504626\n",
      "    log_marginal   : 640.9679801509066\n",
      "    log_joint      : 848.9159758945681\n",
      "    val_loss       : -644.5008494059244\n",
      "    val_ess        : 1.9566995700200398\n",
      "    val_log_marginal: 644.5407104492188\n",
      "    val_log_joint  : 852.3845977783203\n",
      "Train Epoch: 384 [0/54000 (0%)] Loss: -657.585327\n",
      "Train Epoch: 384 [11264/54000 (21%)] Loss: -638.393677\n",
      "Train Epoch: 384 [22528/54000 (42%)] Loss: -643.383057\n",
      "Train Epoch: 384 [33792/54000 (63%)] Loss: -635.265808\n",
      "Train Epoch: 384 [45056/54000 (83%)] Loss: -635.958984\n",
      "    epoch          : 384\n",
      "    loss           : -641.1678403458505\n",
      "    ess            : 1.9575611105505026\n",
      "    log_marginal   : 641.2042564536041\n",
      "    log_joint      : 849.1355072597288\n",
      "    val_loss       : -643.8357645670573\n",
      "    val_ess        : 1.9596943159898121\n",
      "    val_log_marginal: 643.8715515136719\n",
      "    val_log_joint  : 851.7162780761719\n",
      "Train Epoch: 385 [0/54000 (0%)] Loss: -641.049011\n",
      "Train Epoch: 385 [11264/54000 (21%)] Loss: -660.510742\n",
      "Train Epoch: 385 [22528/54000 (42%)] Loss: -657.825012\n",
      "Train Epoch: 385 [33792/54000 (63%)] Loss: -638.557190\n",
      "Train Epoch: 385 [45056/54000 (83%)] Loss: -628.828369\n",
      "    epoch          : 385\n",
      "    loss           : -641.1738776440891\n",
      "    ess            : 1.9578736559400018\n",
      "    log_marginal   : 641.210854584316\n",
      "    log_joint      : 849.1122361669001\n",
      "    val_loss       : -644.7208658854166\n",
      "    val_ess        : 1.958709826072057\n",
      "    val_log_marginal: 644.7564595540365\n",
      "    val_log_joint  : 852.4834899902344\n",
      "Train Epoch: 386 [0/54000 (0%)] Loss: -640.233765\n",
      "Train Epoch: 386 [11264/54000 (21%)] Loss: -637.792114\n",
      "Train Epoch: 386 [22528/54000 (42%)] Loss: -644.984131\n",
      "Train Epoch: 386 [33792/54000 (63%)] Loss: -640.852661\n",
      "Train Epoch: 386 [45056/54000 (83%)] Loss: -650.056152\n",
      "    epoch          : 386\n",
      "    loss           : -641.8197361208358\n",
      "    ess            : 1.957324613940041\n",
      "    log_marginal   : 641.856745306051\n",
      "    log_joint      : 849.731075070939\n",
      "    val_loss       : -645.4263966878256\n",
      "    val_ess        : 1.96157701810201\n",
      "    val_log_marginal: 645.4601338704427\n",
      "    val_log_joint  : 853.0971171061198\n",
      "Train Epoch: 387 [0/54000 (0%)] Loss: -635.514526\n",
      "Train Epoch: 387 [11264/54000 (21%)] Loss: -650.305664\n",
      "Train Epoch: 387 [22528/54000 (42%)] Loss: -638.495850\n",
      "Train Epoch: 387 [33792/54000 (63%)] Loss: -657.288574\n",
      "Train Epoch: 387 [45056/54000 (83%)] Loss: -655.621948\n",
      "    epoch          : 387\n",
      "    loss           : -642.3732178885982\n",
      "    ess            : 1.9586971930737764\n",
      "    log_marginal   : 642.407965318212\n",
      "    log_joint      : 850.3496992003243\n",
      "    val_loss       : -645.9146779378256\n",
      "    val_ess        : 1.9556345343589783\n",
      "    val_log_marginal: 645.9532877604166\n",
      "    val_log_joint  : 853.8885142008463\n",
      "Train Epoch: 388 [0/54000 (0%)] Loss: -634.889282\n",
      "Train Epoch: 388 [11264/54000 (21%)] Loss: -633.228271\n",
      "Train Epoch: 388 [22528/54000 (42%)] Loss: -638.827332\n",
      "Train Epoch: 388 [33792/54000 (63%)] Loss: -637.836243\n",
      "Train Epoch: 388 [45056/54000 (83%)] Loss: -658.643799\n",
      "    epoch          : 388\n",
      "    loss           : -642.0135578659346\n",
      "    ess            : 1.9584443591675669\n",
      "    log_marginal   : 642.0489300421949\n",
      "    log_joint      : 850.0756473181383\n",
      "    val_loss       : -645.6527353922526\n",
      "    val_ess        : 1.9552034139633179\n",
      "    val_log_marginal: 645.6922403971354\n",
      "    val_log_joint  : 853.6105194091797\n",
      "Train Epoch: 389 [0/54000 (0%)] Loss: -631.082092\n",
      "Train Epoch: 389 [11264/54000 (21%)] Loss: -639.115967\n",
      "Train Epoch: 389 [22528/54000 (42%)] Loss: -660.388062\n",
      "Train Epoch: 389 [33792/54000 (63%)] Loss: -644.424072\n",
      "Train Epoch: 389 [45056/54000 (83%)] Loss: -600.138428\n",
      "    epoch          : 389\n",
      "    loss           : -642.5879988760319\n",
      "    ess            : 1.9581414090012603\n",
      "    log_marginal   : 642.6245071123232\n",
      "    log_joint      : 850.5815343316996\n",
      "    val_loss       : -646.9829711914062\n",
      "    val_ess        : 1.9550019403298695\n",
      "    val_log_marginal: 647.0252787272135\n",
      "    val_log_joint  : 854.698974609375\n",
      "Train Epoch: 390 [0/54000 (0%)] Loss: -648.412231\n",
      "Train Epoch: 390 [11264/54000 (21%)] Loss: -640.799377\n",
      "Train Epoch: 390 [22528/54000 (42%)] Loss: -632.393677\n",
      "Train Epoch: 390 [33792/54000 (63%)] Loss: -639.476807\n",
      "Train Epoch: 390 [45056/54000 (83%)] Loss: -647.989258\n",
      "    epoch          : 390\n",
      "    loss           : -643.0919598273512\n",
      "    ess            : 1.9585605218725384\n",
      "    log_marginal   : 643.1282008908829\n",
      "    log_joint      : 851.0151309607164\n",
      "    val_loss       : -647.0545603434244\n",
      "    val_ess        : 1.957615574200948\n",
      "    val_log_marginal: 647.0929463704427\n",
      "    val_log_joint  : 855.0564168294271\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch390.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 391 [0/54000 (0%)] Loss: -650.568726\n",
      "Train Epoch: 391 [11264/54000 (21%)] Loss: -636.351440\n",
      "Train Epoch: 391 [22528/54000 (42%)] Loss: -641.578918\n",
      "Train Epoch: 391 [33792/54000 (63%)] Loss: -634.910278\n",
      "Train Epoch: 391 [45056/54000 (83%)] Loss: -633.412842\n",
      "    epoch          : 391\n",
      "    loss           : -643.0126503998379\n",
      "    ess            : 1.9584778805948653\n",
      "    log_marginal   : 643.0485707408977\n",
      "    log_joint      : 851.1136347932636\n",
      "    val_loss       : -646.7374471028646\n",
      "    val_ess        : 1.960017442703247\n",
      "    val_log_marginal: 646.7736206054688\n",
      "    val_log_joint  : 854.6417897542318\n",
      "Train Epoch: 392 [0/54000 (0%)] Loss: -626.945312\n",
      "Train Epoch: 392 [11264/54000 (21%)] Loss: -628.181763\n",
      "Train Epoch: 392 [22528/54000 (42%)] Loss: -632.009277\n",
      "Train Epoch: 392 [33792/54000 (63%)] Loss: -632.841919\n",
      "Train Epoch: 392 [45056/54000 (83%)] Loss: -643.415039\n",
      "    epoch          : 392\n",
      "    loss           : -643.4094416780292\n",
      "    ess            : 1.9591996107461318\n",
      "    log_marginal   : 643.4440134876179\n",
      "    log_joint      : 851.3431431032577\n",
      "    val_loss       : -647.3845011393229\n",
      "    val_ess        : 1.9583850502967834\n",
      "    val_log_marginal: 647.4227854410807\n",
      "    val_log_joint  : 855.3182373046875\n",
      "Train Epoch: 393 [0/54000 (0%)] Loss: -638.082703\n",
      "Train Epoch: 393 [11264/54000 (21%)] Loss: -642.891968\n",
      "Train Epoch: 393 [22528/54000 (42%)] Loss: -634.287354\n",
      "Train Epoch: 393 [33792/54000 (63%)] Loss: -620.785889\n",
      "Train Epoch: 393 [45056/54000 (83%)] Loss: -631.044128\n",
      "    epoch          : 393\n",
      "    loss           : -643.9196834924086\n",
      "    ess            : 1.958233286749642\n",
      "    log_marginal   : 643.9557783018868\n",
      "    log_joint      : 851.8132980634581\n",
      "    val_loss       : -648.0402221679688\n",
      "    val_ess        : 1.957506815592448\n",
      "    val_log_marginal: 648.0764516194662\n",
      "    val_log_joint  : 856.0336405436198\n",
      "Train Epoch: 394 [0/54000 (0%)] Loss: -636.962891\n",
      "Train Epoch: 394 [11264/54000 (21%)] Loss: -664.359741\n",
      "Train Epoch: 394 [22528/54000 (42%)] Loss: -636.245972\n",
      "Train Epoch: 394 [33792/54000 (63%)] Loss: -620.430908\n",
      "Train Epoch: 394 [45056/54000 (83%)] Loss: -649.927246\n",
      "    epoch          : 394\n",
      "    loss           : -644.3022973402491\n",
      "    ess            : 1.9585402225548367\n",
      "    log_marginal   : 644.3382159538988\n",
      "    log_joint      : 852.1153449292453\n",
      "    val_loss       : -647.3906911214193\n",
      "    val_ess        : 1.9568081895510356\n",
      "    val_log_marginal: 647.4303639729818\n",
      "    val_log_joint  : 855.2397715250651\n",
      "Train Epoch: 395 [0/54000 (0%)] Loss: -647.156128\n",
      "Train Epoch: 395 [11264/54000 (21%)] Loss: -644.832397\n",
      "Train Epoch: 395 [22528/54000 (42%)] Loss: -667.904785\n",
      "Train Epoch: 395 [33792/54000 (63%)] Loss: -630.635803\n",
      "Train Epoch: 395 [45056/54000 (83%)] Loss: -634.386841\n",
      "    epoch          : 395\n",
      "    loss           : -644.2036921663105\n",
      "    ess            : 1.9599855620906037\n",
      "    log_marginal   : 644.2375327056309\n",
      "    log_joint      : 852.0899220592571\n",
      "    val_loss       : -647.9333902994791\n",
      "    val_ess        : 1.9555028975009918\n",
      "    val_log_marginal: 647.9703114827474\n",
      "    val_log_joint  : 855.9841766357422\n",
      "Train Epoch: 396 [0/54000 (0%)] Loss: -658.905640\n",
      "Train Epoch: 396 [11264/54000 (21%)] Loss: -659.213501\n",
      "Train Epoch: 396 [22528/54000 (42%)] Loss: -641.173340\n",
      "Train Epoch: 396 [33792/54000 (63%)] Loss: -643.741577\n",
      "Train Epoch: 396 [45056/54000 (83%)] Loss: -625.948364\n",
      "    epoch          : 396\n",
      "    loss           : -644.9302114810583\n",
      "    ess            : 1.9571950525607702\n",
      "    log_marginal   : 644.9676053029186\n",
      "    log_joint      : 852.840059100457\n",
      "    val_loss       : -648.1344604492188\n",
      "    val_ess        : 1.956903298695882\n",
      "    val_log_marginal: 648.1694386800131\n",
      "    val_log_joint  : 856.2429402669271\n",
      "Train Epoch: 397 [0/54000 (0%)] Loss: -639.156738\n",
      "Train Epoch: 397 [11264/54000 (21%)] Loss: -628.834106\n",
      "Train Epoch: 397 [22528/54000 (42%)] Loss: -655.284180\n",
      "Train Epoch: 397 [33792/54000 (63%)] Loss: -658.426819\n",
      "Train Epoch: 397 [45056/54000 (83%)] Loss: -640.082764\n",
      "    epoch          : 397\n",
      "    loss           : -645.2001066387825\n",
      "    ess            : 1.957885869269101\n",
      "    log_marginal   : 645.2365037450251\n",
      "    log_joint      : 853.1160462577388\n",
      "    val_loss       : -649.0049489339193\n",
      "    val_ess        : 1.9599143067995708\n",
      "    val_log_marginal: 649.0367279052734\n",
      "    val_log_joint  : 856.8897552490234\n",
      "Train Epoch: 398 [0/54000 (0%)] Loss: -643.019409\n",
      "Train Epoch: 398 [11264/54000 (21%)] Loss: -666.295654\n",
      "Train Epoch: 398 [22528/54000 (42%)] Loss: -657.034424\n",
      "Train Epoch: 398 [33792/54000 (63%)] Loss: -650.903992\n",
      "Train Epoch: 398 [45056/54000 (83%)] Loss: -649.619629\n",
      "    epoch          : 398\n",
      "    loss           : -645.1487593740787\n",
      "    ess            : 1.9593996653017007\n",
      "    log_marginal   : 645.1822060639004\n",
      "    log_joint      : 853.1464694041126\n",
      "    val_loss       : -648.5765787760416\n",
      "    val_ess        : 1.9576659401257832\n",
      "    val_log_marginal: 648.6132965087891\n",
      "    val_log_joint  : 856.5869496663412\n",
      "Train Epoch: 399 [0/54000 (0%)] Loss: -653.271484\n",
      "Train Epoch: 399 [11264/54000 (21%)] Loss: -648.040527\n",
      "Train Epoch: 399 [22528/54000 (42%)] Loss: -647.923706\n",
      "Train Epoch: 399 [33792/54000 (63%)] Loss: -633.352600\n",
      "Train Epoch: 399 [45056/54000 (83%)] Loss: -646.856934\n",
      "    epoch          : 399\n",
      "    loss           : -645.7885863106205\n",
      "    ess            : 1.958495095091046\n",
      "    log_marginal   : 645.8247928259508\n",
      "    log_joint      : 853.7602636949072\n",
      "    val_loss       : -650.0564270019531\n",
      "    val_ess        : 1.958285649617513\n",
      "    val_log_marginal: 650.094482421875\n",
      "    val_log_joint  : 858.1295369466146\n",
      "Train Epoch: 400 [0/54000 (0%)] Loss: -640.221741\n",
      "Train Epoch: 400 [11264/54000 (21%)] Loss: -652.084045\n",
      "Train Epoch: 400 [22528/54000 (42%)] Loss: -638.495850\n",
      "Train Epoch: 400 [33792/54000 (63%)] Loss: -641.508423\n",
      "Train Epoch: 400 [45056/54000 (83%)] Loss: -660.217651\n",
      "    epoch          : 400\n",
      "    loss           : -646.1425395461748\n",
      "    ess            : 1.9577992884617932\n",
      "    log_marginal   : 646.1792994085348\n",
      "    log_joint      : 854.0477784354732\n",
      "    val_loss       : -649.6248372395834\n",
      "    val_ess        : 1.9594486554463704\n",
      "    val_log_marginal: 649.6587778727213\n",
      "    val_log_joint  : 857.6675567626953\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [0/54000 (0%)] Loss: -649.879517\n",
      "Train Epoch: 401 [11264/54000 (21%)] Loss: -628.981628\n",
      "Train Epoch: 401 [22528/54000 (42%)] Loss: -639.689209\n",
      "Train Epoch: 401 [33792/54000 (63%)] Loss: -664.745239\n",
      "Train Epoch: 401 [45056/54000 (83%)] Loss: -674.583435\n",
      "    epoch          : 401\n",
      "    loss           : -646.2580497309847\n",
      "    ess            : 1.9595090724387259\n",
      "    log_marginal   : 646.29261923736\n",
      "    log_joint      : 854.2229136341023\n",
      "    val_loss       : -649.8066914876302\n",
      "    val_ess        : 1.9587046603361766\n",
      "    val_log_marginal: 649.8417663574219\n",
      "    val_log_joint  : 857.8971252441406\n",
      "Train Epoch: 402 [0/54000 (0%)] Loss: -619.880737\n",
      "Train Epoch: 402 [11264/54000 (21%)] Loss: -634.312500\n",
      "Train Epoch: 402 [22528/54000 (42%)] Loss: -653.577026\n",
      "Train Epoch: 402 [33792/54000 (63%)] Loss: -643.456970\n",
      "Train Epoch: 402 [45056/54000 (83%)] Loss: -645.881592\n",
      "    epoch          : 402\n",
      "    loss           : -646.367489220961\n",
      "    ess            : 1.9589830726947424\n",
      "    log_marginal   : 646.4029748304835\n",
      "    log_joint      : 854.3332179807267\n",
      "    val_loss       : -650.8390655517578\n",
      "    val_ess        : 1.959443986415863\n",
      "    val_log_marginal: 650.8768717447916\n",
      "    val_log_joint  : 858.5469004313151\n",
      "Train Epoch: 403 [0/54000 (0%)] Loss: -641.656006\n",
      "Train Epoch: 403 [11264/54000 (21%)] Loss: -624.207764\n",
      "Train Epoch: 403 [22528/54000 (42%)] Loss: -661.467102\n",
      "Train Epoch: 403 [33792/54000 (63%)] Loss: -678.376465\n",
      "Train Epoch: 403 [45056/54000 (83%)] Loss: -635.114929\n",
      "    epoch          : 403\n",
      "    loss           : -647.1748288712412\n",
      "    ess            : 1.9577894289538544\n",
      "    log_marginal   : 647.2112766481796\n",
      "    log_joint      : 855.1598366791347\n",
      "    val_loss       : -651.7791188557943\n",
      "    val_ess        : 1.9586285650730133\n",
      "    val_log_marginal: 651.8161671956381\n",
      "    val_log_joint  : 859.8275502522787\n",
      "Train Epoch: 404 [0/54000 (0%)] Loss: -626.345947\n",
      "Train Epoch: 404 [11264/54000 (21%)] Loss: -674.956177\n",
      "Train Epoch: 404 [22528/54000 (42%)] Loss: -637.753235\n",
      "Train Epoch: 404 [33792/54000 (63%)] Loss: -653.685974\n",
      "Train Epoch: 404 [45056/54000 (83%)] Loss: -641.454102\n",
      "    epoch          : 404\n",
      "    loss           : -647.2505412551592\n",
      "    ess            : 1.9580410865117919\n",
      "    log_marginal   : 647.286927421138\n",
      "    log_joint      : 855.2311487737692\n",
      "    val_loss       : -650.6429239908854\n",
      "    val_ess        : 1.9577081203460693\n",
      "    val_log_marginal: 650.6778004964193\n",
      "    val_log_joint  : 858.3647613525391\n",
      "Train Epoch: 405 [0/54000 (0%)] Loss: -630.242065\n",
      "Train Epoch: 405 [11264/54000 (21%)] Loss: -669.552490\n",
      "Train Epoch: 405 [22528/54000 (42%)] Loss: -651.873047\n",
      "Train Epoch: 405 [33792/54000 (63%)] Loss: -644.844482\n",
      "Train Epoch: 405 [45056/54000 (83%)] Loss: -639.008179\n",
      "    epoch          : 405\n",
      "    loss           : -647.6748760871168\n",
      "    ess            : 1.9590366032888304\n",
      "    log_marginal   : 647.710043853184\n",
      "    log_joint      : 855.5385765219635\n",
      "    val_loss       : -650.9815826416016\n",
      "    val_ess        : 1.9594439466794331\n",
      "    val_log_marginal: 651.0147450764974\n",
      "    val_log_joint  : 858.7039133707682\n",
      "Train Epoch: 406 [0/54000 (0%)] Loss: -656.209106\n",
      "Train Epoch: 406 [11264/54000 (21%)] Loss: -639.569336\n",
      "Train Epoch: 406 [22528/54000 (42%)] Loss: -666.079529\n",
      "Train Epoch: 406 [33792/54000 (63%)] Loss: -648.969910\n",
      "Train Epoch: 406 [45056/54000 (83%)] Loss: -671.145203\n",
      "    epoch          : 406\n",
      "    loss           : -647.9983652942585\n",
      "    ess            : 1.9578770309124354\n",
      "    log_marginal   : 648.0344601037367\n",
      "    log_joint      : 855.9531359402639\n",
      "    val_loss       : -652.2473907470703\n",
      "    val_ess        : 1.9604851007461548\n",
      "    val_log_marginal: 652.2839864095052\n",
      "    val_log_joint  : 860.0110677083334\n",
      "Train Epoch: 407 [0/54000 (0%)] Loss: -645.459717\n",
      "Train Epoch: 407 [11264/54000 (21%)] Loss: -655.235413\n",
      "Train Epoch: 407 [22528/54000 (42%)] Loss: -643.765381\n",
      "Train Epoch: 407 [33792/54000 (63%)] Loss: -647.035889\n",
      "Train Epoch: 407 [45056/54000 (83%)] Loss: -639.162354\n",
      "    epoch          : 407\n",
      "    loss           : -648.5276011341023\n",
      "    ess            : 1.958137404243901\n",
      "    log_marginal   : 648.5628662109375\n",
      "    log_joint      : 856.539180539689\n",
      "    val_loss       : -652.3620045979818\n",
      "    val_ess        : 1.9559311866760254\n",
      "    val_log_marginal: 652.4022318522135\n",
      "    val_log_joint  : 860.599365234375\n",
      "Train Epoch: 408 [0/54000 (0%)] Loss: -678.644226\n",
      "Train Epoch: 408 [11264/54000 (21%)] Loss: -648.721558\n",
      "Train Epoch: 408 [22528/54000 (42%)] Loss: -656.573242\n",
      "Train Epoch: 408 [33792/54000 (63%)] Loss: -650.383789\n",
      "Train Epoch: 408 [45056/54000 (83%)] Loss: -669.555725\n",
      "    epoch          : 408\n",
      "    loss           : -648.4967801076061\n",
      "    ess            : 1.9588431389826648\n",
      "    log_marginal   : 648.5320820358564\n",
      "    log_joint      : 856.4400749926297\n",
      "    val_loss       : -652.0579935709635\n",
      "    val_ess        : 1.9575799107551575\n",
      "    val_log_marginal: 652.0927530924479\n",
      "    val_log_joint  : 859.9625396728516\n",
      "Train Epoch: 409 [0/54000 (0%)] Loss: -680.256592\n",
      "Train Epoch: 409 [11264/54000 (21%)] Loss: -667.820740\n",
      "Train Epoch: 409 [22528/54000 (42%)] Loss: -673.769897\n",
      "Train Epoch: 409 [33792/54000 (63%)] Loss: -656.109741\n",
      "Train Epoch: 409 [45056/54000 (83%)] Loss: -662.246216\n",
      "    epoch          : 409\n",
      "    loss           : -648.7296649285082\n",
      "    ess            : 1.9580040551581472\n",
      "    log_marginal   : 648.7661748922096\n",
      "    log_joint      : 856.6935298127948\n",
      "    val_loss       : -652.1869506835938\n",
      "    val_ess        : 1.9545119106769562\n",
      "    val_log_marginal: 652.2303517659506\n",
      "    val_log_joint  : 860.2208709716797\n",
      "Train Epoch: 410 [0/54000 (0%)] Loss: -653.713501\n",
      "Train Epoch: 410 [11264/54000 (21%)] Loss: -655.780518\n",
      "Train Epoch: 410 [22528/54000 (42%)] Loss: -673.514954\n",
      "Train Epoch: 410 [33792/54000 (63%)] Loss: -654.334473\n",
      "Train Epoch: 410 [45056/54000 (83%)] Loss: -638.976257\n",
      "    epoch          : 410\n",
      "    loss           : -649.3252477106058\n",
      "    ess            : 1.9583887390370638\n",
      "    log_marginal   : 649.3599594404112\n",
      "    log_joint      : 857.17703534972\n",
      "    val_loss       : -653.4459330240885\n",
      "    val_ess        : 1.9597632388273876\n",
      "    val_log_marginal: 653.4813791910807\n",
      "    val_log_joint  : 861.3765207926432\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch410.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 411 [0/54000 (0%)] Loss: -650.868469\n",
      "Train Epoch: 411 [11264/54000 (21%)] Loss: -636.551147\n",
      "Train Epoch: 411 [22528/54000 (42%)] Loss: -661.877258\n",
      "Train Epoch: 411 [33792/54000 (63%)] Loss: -656.716919\n",
      "Train Epoch: 411 [45056/54000 (83%)] Loss: -682.472290\n",
      "    epoch          : 411\n",
      "    loss           : -649.6996891813458\n",
      "    ess            : 1.958921156964212\n",
      "    log_marginal   : 649.7342391104069\n",
      "    log_joint      : 857.6268368127211\n",
      "    val_loss       : -652.4472198486328\n",
      "    val_ess        : 1.9603856305281322\n",
      "    val_log_marginal: 652.4813334147135\n",
      "    val_log_joint  : 860.2845916748047\n",
      "Train Epoch: 412 [0/54000 (0%)] Loss: -642.101990\n",
      "Train Epoch: 412 [11264/54000 (21%)] Loss: -657.810974\n",
      "Train Epoch: 412 [22528/54000 (42%)] Loss: -640.100098\n",
      "Train Epoch: 412 [33792/54000 (63%)] Loss: -641.828857\n",
      "Train Epoch: 412 [45056/54000 (83%)] Loss: -634.468018\n",
      "    epoch          : 412\n",
      "    loss           : -649.709199725457\n",
      "    ess            : 1.9585436076488134\n",
      "    log_marginal   : 649.7443490658167\n",
      "    log_joint      : 857.6826350374042\n",
      "    val_loss       : -653.1357828776041\n",
      "    val_ess        : 1.9576918482780457\n",
      "    val_log_marginal: 653.1739196777344\n",
      "    val_log_joint  : 861.1126047770182\n",
      "Train Epoch: 413 [0/54000 (0%)] Loss: -666.782959\n",
      "Train Epoch: 413 [11264/54000 (21%)] Loss: -637.672791\n",
      "Train Epoch: 413 [22528/54000 (42%)] Loss: -629.849792\n",
      "Train Epoch: 413 [33792/54000 (63%)] Loss: -655.264038\n",
      "Train Epoch: 413 [45056/54000 (83%)] Loss: -655.523193\n",
      "    epoch          : 413\n",
      "    loss           : -650.2140456865419\n",
      "    ess            : 1.9589870414643917\n",
      "    log_marginal   : 650.2486434072819\n",
      "    log_joint      : 858.2544141085642\n",
      "    val_loss       : -654.1085866292318\n",
      "    val_ess        : 1.9613091846307118\n",
      "    val_log_marginal: 654.1380564371744\n",
      "    val_log_joint  : 861.8023376464844\n",
      "Train Epoch: 414 [0/54000 (0%)] Loss: -640.628906\n",
      "Train Epoch: 414 [11264/54000 (21%)] Loss: -643.958374\n",
      "Train Epoch: 414 [22528/54000 (42%)] Loss: -658.790039\n",
      "Train Epoch: 414 [33792/54000 (63%)] Loss: -669.187500\n",
      "Train Epoch: 414 [45056/54000 (83%)] Loss: -637.246582\n",
      "    epoch          : 414\n",
      "    loss           : -650.5412067917158\n",
      "    ess            : 1.9579323181566202\n",
      "    log_marginal   : 650.5773131172612\n",
      "    log_joint      : 858.5258040518131\n",
      "    val_loss       : -653.9861450195312\n",
      "    val_ess        : 1.9563549260298412\n",
      "    val_log_marginal: 654.0247701009115\n",
      "    val_log_joint  : 862.0427449544271\n",
      "Train Epoch: 415 [0/54000 (0%)] Loss: -673.825439\n",
      "Train Epoch: 415 [11264/54000 (21%)] Loss: -647.789246\n",
      "Train Epoch: 415 [22528/54000 (42%)] Loss: -649.836670\n",
      "Train Epoch: 415 [33792/54000 (63%)] Loss: -651.022522\n",
      "Train Epoch: 415 [45056/54000 (83%)] Loss: -636.823120\n",
      "    epoch          : 415\n",
      "    loss           : -650.7077527316111\n",
      "    ess            : 1.957649955209696\n",
      "    log_marginal   : 650.7453970279333\n",
      "    log_joint      : 858.6924691830042\n",
      "    val_loss       : -653.8375040690104\n",
      "    val_ess        : 1.9599053859710693\n",
      "    val_log_marginal: 653.8711140950521\n",
      "    val_log_joint  : 861.5920918782552\n",
      "Train Epoch: 416 [0/54000 (0%)] Loss: -667.028931\n",
      "Train Epoch: 416 [11264/54000 (21%)] Loss: -649.776123\n",
      "Train Epoch: 416 [22528/54000 (42%)] Loss: -627.845459\n",
      "Train Epoch: 416 [33792/54000 (63%)] Loss: -647.445129\n",
      "Train Epoch: 416 [45056/54000 (83%)] Loss: -642.540405\n",
      "    epoch          : 416\n",
      "    loss           : -651.0878848669664\n",
      "    ess            : 1.9587991732471395\n",
      "    log_marginal   : 651.1226023548054\n",
      "    log_joint      : 859.0539775344561\n",
      "    val_loss       : -655.2427266438802\n",
      "    val_ess        : 1.9648853143056233\n",
      "    val_log_marginal: 655.2721608479818\n",
      "    val_log_joint  : 862.8261667887369\n",
      "Train Epoch: 417 [0/54000 (0%)] Loss: -652.133179\n",
      "Train Epoch: 417 [11264/54000 (21%)] Loss: -642.728027\n",
      "Train Epoch: 417 [22528/54000 (42%)] Loss: -635.214111\n",
      "Train Epoch: 417 [33792/54000 (63%)] Loss: -643.422424\n",
      "Train Epoch: 417 [45056/54000 (83%)] Loss: -661.905151\n",
      "    epoch          : 417\n",
      "    loss           : -651.645402440485\n",
      "    ess            : 1.9587532236890972\n",
      "    log_marginal   : 651.6805350825472\n",
      "    log_joint      : 859.6341115123821\n",
      "    val_loss       : -654.4505767822266\n",
      "    val_ess        : 1.9558005432287853\n",
      "    val_log_marginal: 654.4880218505859\n",
      "    val_log_joint  : 862.6713205973307\n",
      "Train Epoch: 418 [0/54000 (0%)] Loss: -648.334595\n",
      "Train Epoch: 418 [11264/54000 (21%)] Loss: -648.039185\n",
      "Train Epoch: 418 [22528/54000 (42%)] Loss: -646.972595\n",
      "Train Epoch: 418 [33792/54000 (63%)] Loss: -647.248779\n",
      "Train Epoch: 418 [45056/54000 (83%)] Loss: -634.758667\n",
      "    epoch          : 418\n",
      "    loss           : -651.4457552927845\n",
      "    ess            : 1.95815978972417\n",
      "    log_marginal   : 651.4805994573629\n",
      "    log_joint      : 859.3929892485996\n",
      "    val_loss       : -654.6801198323568\n",
      "    val_ess        : 1.9594741761684418\n",
      "    val_log_marginal: 654.7116190592448\n",
      "    val_log_joint  : 862.7127227783203\n",
      "Train Epoch: 419 [0/54000 (0%)] Loss: -662.205200\n",
      "Train Epoch: 419 [11264/54000 (21%)] Loss: -650.929077\n",
      "Train Epoch: 419 [22528/54000 (42%)] Loss: -659.483765\n",
      "Train Epoch: 419 [33792/54000 (63%)] Loss: -650.299194\n",
      "Train Epoch: 419 [45056/54000 (83%)] Loss: -663.806519\n",
      "    epoch          : 419\n",
      "    loss           : -651.9444534013857\n",
      "    ess            : 1.959191474149812\n",
      "    log_marginal   : 651.9788184975678\n",
      "    log_joint      : 859.8882210209684\n",
      "    val_loss       : -655.4749145507812\n",
      "    val_ess        : 1.9577567875385284\n",
      "    val_log_marginal: 655.5118052164713\n",
      "    val_log_joint  : 863.5336405436198\n",
      "Train Epoch: 420 [0/54000 (0%)] Loss: -650.325378\n",
      "Train Epoch: 420 [11264/54000 (21%)] Loss: -649.148193\n",
      "Train Epoch: 420 [22528/54000 (42%)] Loss: -633.732361\n",
      "Train Epoch: 420 [33792/54000 (63%)] Loss: -637.881409\n",
      "Train Epoch: 420 [45056/54000 (83%)] Loss: -649.638489\n",
      "    epoch          : 420\n",
      "    loss           : -652.6084842322008\n",
      "    ess            : 1.9593705546181157\n",
      "    log_marginal   : 652.643047404739\n",
      "    log_joint      : 860.6503411059109\n",
      "    val_loss       : -655.4827677408854\n",
      "    val_ess        : 1.9592362542947133\n",
      "    val_log_marginal: 655.5157725016276\n",
      "    val_log_joint  : 863.4567515055338\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch420.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 421 [0/54000 (0%)] Loss: -656.136475\n",
      "Train Epoch: 421 [11264/54000 (21%)] Loss: -625.831116\n",
      "Train Epoch: 421 [22528/54000 (42%)] Loss: -631.504517\n",
      "Train Epoch: 421 [33792/54000 (63%)] Loss: -627.007690\n",
      "Train Epoch: 421 [45056/54000 (83%)] Loss: -653.880249\n",
      "    epoch          : 421\n",
      "    loss           : -652.6408034990419\n",
      "    ess            : 1.9582493012806155\n",
      "    log_marginal   : 652.6763547501474\n",
      "    log_joint      : 860.6464106721698\n",
      "    val_loss       : -656.085205078125\n",
      "    val_ess        : 1.9588739275932312\n",
      "    val_log_marginal: 656.1202392578125\n",
      "    val_log_joint  : 863.8245340983073\n",
      "Train Epoch: 422 [0/54000 (0%)] Loss: -644.485840\n",
      "Train Epoch: 422 [11264/54000 (21%)] Loss: -625.764832\n",
      "Train Epoch: 422 [22528/54000 (42%)] Loss: -661.738159\n",
      "Train Epoch: 422 [33792/54000 (63%)] Loss: -659.911560\n",
      "Train Epoch: 422 [45056/54000 (83%)] Loss: -635.051758\n",
      "    epoch          : 422\n",
      "    loss           : -652.7959145599941\n",
      "    ess            : 1.9584643942005229\n",
      "    log_marginal   : 652.8318233849867\n",
      "    log_joint      : 860.6967502809921\n",
      "    val_loss       : -656.0696258544922\n",
      "    val_ess        : 1.9538357655207317\n",
      "    val_log_marginal: 656.1095886230469\n",
      "    val_log_joint  : 864.1951904296875\n",
      "Train Epoch: 423 [0/54000 (0%)] Loss: -652.159180\n",
      "Train Epoch: 423 [11264/54000 (21%)] Loss: -658.474487\n",
      "Train Epoch: 423 [22528/54000 (42%)] Loss: -669.730103\n",
      "Train Epoch: 423 [33792/54000 (63%)] Loss: -668.928833\n",
      "Train Epoch: 423 [45056/54000 (83%)] Loss: -643.831604\n",
      "    epoch          : 423\n",
      "    loss           : -653.4011028937574\n",
      "    ess            : 1.9578415706472576\n",
      "    log_marginal   : 653.4376019171949\n",
      "    log_joint      : 861.4242853128685\n",
      "    val_loss       : -656.7964579264323\n",
      "    val_ess        : 1.9607249995072682\n",
      "    val_log_marginal: 656.8275909423828\n",
      "    val_log_joint  : 864.8636118570963\n",
      "Train Epoch: 424 [0/54000 (0%)] Loss: -658.002563\n",
      "Train Epoch: 424 [11264/54000 (21%)] Loss: -665.361877\n",
      "Train Epoch: 424 [22528/54000 (42%)] Loss: -677.979675\n",
      "Train Epoch: 424 [33792/54000 (63%)] Loss: -653.447205\n",
      "Train Epoch: 424 [45056/54000 (83%)] Loss: -644.077637\n",
      "    epoch          : 424\n",
      "    loss           : -653.8355758954893\n",
      "    ess            : 1.957667056119667\n",
      "    log_marginal   : 653.871087416163\n",
      "    log_joint      : 861.7891857219192\n",
      "    val_loss       : -656.9099578857422\n",
      "    val_ess        : 1.9624187648296356\n",
      "    val_log_marginal: 656.9381815592448\n",
      "    val_log_joint  : 864.967529296875\n",
      "Train Epoch: 425 [0/54000 (0%)] Loss: -655.616150\n",
      "Train Epoch: 425 [11264/54000 (21%)] Loss: -642.539062\n",
      "Train Epoch: 425 [22528/54000 (42%)] Loss: -643.064819\n",
      "Train Epoch: 425 [33792/54000 (63%)] Loss: -663.292114\n",
      "Train Epoch: 425 [45056/54000 (83%)] Loss: -625.339783\n",
      "    epoch          : 425\n",
      "    loss           : -653.9377896290905\n",
      "    ess            : 1.957309585697246\n",
      "    log_marginal   : 653.9746433473983\n",
      "    log_joint      : 861.8867106887529\n",
      "    val_loss       : -657.5836995442709\n",
      "    val_ess        : 1.959785521030426\n",
      "    val_log_marginal: 657.6166839599609\n",
      "    val_log_joint  : 865.4517822265625\n",
      "Train Epoch: 426 [0/54000 (0%)] Loss: -647.408325\n",
      "Train Epoch: 426 [11264/54000 (21%)] Loss: -651.636719\n",
      "Train Epoch: 426 [22528/54000 (42%)] Loss: -651.391479\n",
      "Train Epoch: 426 [33792/54000 (63%)] Loss: -646.491577\n",
      "Train Epoch: 426 [45056/54000 (83%)] Loss: -631.464355\n",
      "    epoch          : 426\n",
      "    loss           : -654.3028374438015\n",
      "    ess            : 1.958885741683672\n",
      "    log_marginal   : 654.337793314232\n",
      "    log_joint      : 862.3168260106501\n",
      "    val_loss       : -657.2979278564453\n",
      "    val_ess        : 1.9608780244986217\n",
      "    val_log_marginal: 657.3323822021484\n",
      "    val_log_joint  : 865.2109680175781\n",
      "Train Epoch: 427 [0/54000 (0%)] Loss: -664.230164\n",
      "Train Epoch: 427 [11264/54000 (21%)] Loss: -663.895996\n",
      "Train Epoch: 427 [22528/54000 (42%)] Loss: -638.228455\n",
      "Train Epoch: 427 [33792/54000 (63%)] Loss: -645.583374\n",
      "Train Epoch: 427 [45056/54000 (83%)] Loss: -662.444519\n",
      "    epoch          : 427\n",
      "    loss           : -654.7986196841833\n",
      "    ess            : 1.960660364267961\n",
      "    log_marginal   : 654.8320813448923\n",
      "    log_joint      : 862.7257926509066\n",
      "    val_loss       : -658.2359619140625\n",
      "    val_ess        : 1.9606141944726307\n",
      "    val_log_marginal: 658.2699940999349\n",
      "    val_log_joint  : 866.2062581380209\n",
      "Train Epoch: 428 [0/54000 (0%)] Loss: -645.105713\n",
      "Train Epoch: 428 [11264/54000 (21%)] Loss: -654.595825\n",
      "Train Epoch: 428 [22528/54000 (42%)] Loss: -649.315552\n",
      "Train Epoch: 428 [33792/54000 (63%)] Loss: -653.600220\n",
      "Train Epoch: 428 [45056/54000 (83%)] Loss: -645.669678\n",
      "    epoch          : 428\n",
      "    loss           : -654.8736474379053\n",
      "    ess            : 1.9584404702456493\n",
      "    log_marginal   : 654.908712135171\n",
      "    log_joint      : 862.8234178075251\n",
      "    val_loss       : -657.5386301676432\n",
      "    val_ess        : 1.9620173871517181\n",
      "    val_log_marginal: 657.5713806152344\n",
      "    val_log_joint  : 865.6268208821615\n",
      "Train Epoch: 429 [0/54000 (0%)] Loss: -624.101074\n",
      "Train Epoch: 429 [11264/54000 (21%)] Loss: -648.270508\n",
      "Train Epoch: 429 [22528/54000 (42%)] Loss: -648.886353\n",
      "Train Epoch: 429 [33792/54000 (63%)] Loss: -665.443359\n",
      "Train Epoch: 429 [45056/54000 (83%)] Loss: -652.673340\n",
      "    epoch          : 429\n",
      "    loss           : -655.2719565337559\n",
      "    ess            : 1.9593239898951549\n",
      "    log_marginal   : 655.3067989709242\n",
      "    log_joint      : 863.3161010742188\n",
      "    val_loss       : -659.396962483724\n",
      "    val_ess        : 1.9559923112392426\n",
      "    val_log_marginal: 659.4338785807291\n",
      "    val_log_joint  : 867.4468027750651\n",
      "Train Epoch: 430 [0/54000 (0%)] Loss: -667.165161\n",
      "Train Epoch: 430 [11264/54000 (21%)] Loss: -668.628174\n",
      "Train Epoch: 430 [22528/54000 (42%)] Loss: -656.998535\n",
      "Train Epoch: 430 [33792/54000 (63%)] Loss: -631.611084\n",
      "Train Epoch: 430 [45056/54000 (83%)] Loss: -657.518494\n",
      "    epoch          : 430\n",
      "    loss           : -655.9894887096477\n",
      "    ess            : 1.957857537944362\n",
      "    log_marginal   : 656.0254677826504\n",
      "    log_joint      : 863.9278011681898\n",
      "    val_loss       : -658.7132008870443\n",
      "    val_ess        : 1.9597124457359314\n",
      "    val_log_marginal: 658.7465413411459\n",
      "    val_log_joint  : 866.6729176839193\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch430.pth ...\n",
      "Train Epoch: 431 [0/54000 (0%)] Loss: -644.595398\n",
      "Train Epoch: 431 [11264/54000 (21%)] Loss: -674.463928\n",
      "Train Epoch: 431 [22528/54000 (42%)] Loss: -649.809570\n",
      "Train Epoch: 431 [33792/54000 (63%)] Loss: -645.989136\n",
      "Train Epoch: 431 [45056/54000 (83%)] Loss: -638.514099\n",
      "    epoch          : 431\n",
      "    loss           : -655.6269537008034\n",
      "    ess            : 1.9573444240498092\n",
      "    log_marginal   : 655.6638177835716\n",
      "    log_joint      : 863.7522899699661\n",
      "    val_loss       : -658.7332865397135\n",
      "    val_ess        : 1.9600928624471028\n",
      "    val_log_marginal: 658.7702331542969\n",
      "    val_log_joint  : 866.6686553955078\n",
      "Train Epoch: 432 [0/54000 (0%)] Loss: -645.199829\n",
      "Train Epoch: 432 [11264/54000 (21%)] Loss: -665.353394\n",
      "Train Epoch: 432 [22528/54000 (42%)] Loss: -656.048584\n",
      "Train Epoch: 432 [33792/54000 (63%)] Loss: -648.755554\n",
      "Train Epoch: 432 [45056/54000 (83%)] Loss: -654.854858\n",
      "    epoch          : 432\n",
      "    loss           : -655.9625612654776\n",
      "    ess            : 1.959119073624881\n",
      "    log_marginal   : 655.9977100300339\n",
      "    log_joint      : 864.0318925965507\n",
      "    val_loss       : -659.5239512125651\n",
      "    val_ess        : 1.9581103920936584\n",
      "    val_log_marginal: 659.55810546875\n",
      "    val_log_joint  : 867.7703806559244\n",
      "Train Epoch: 433 [0/54000 (0%)] Loss: -654.970703\n",
      "Train Epoch: 433 [11264/54000 (21%)] Loss: -675.893188\n",
      "Train Epoch: 433 [22528/54000 (42%)] Loss: -649.663574\n",
      "Train Epoch: 433 [33792/54000 (63%)] Loss: -666.101868\n",
      "Train Epoch: 433 [45056/54000 (83%)] Loss: -663.576721\n",
      "    epoch          : 433\n",
      "    loss           : -656.5405641951651\n",
      "    ess            : 1.9585283421120554\n",
      "    log_marginal   : 656.5765945146669\n",
      "    log_joint      : 864.5878894733933\n",
      "    val_loss       : -660.2734069824219\n",
      "    val_ess        : 1.959268569946289\n",
      "    val_log_marginal: 660.3085581461588\n",
      "    val_log_joint  : 868.2237294514974\n",
      "Train Epoch: 434 [0/54000 (0%)] Loss: -673.013428\n",
      "Train Epoch: 434 [11264/54000 (21%)] Loss: -665.512024\n",
      "Train Epoch: 434 [22528/54000 (42%)] Loss: -663.067871\n",
      "Train Epoch: 434 [33792/54000 (63%)] Loss: -656.385864\n",
      "Train Epoch: 434 [45056/54000 (83%)] Loss: -645.888123\n",
      "    epoch          : 434\n",
      "    loss           : -656.6495297989755\n",
      "    ess            : 1.958463025542925\n",
      "    log_marginal   : 656.6841332777491\n",
      "    log_joint      : 864.7019492095371\n",
      "    val_loss       : -660.1041310628256\n",
      "    val_ess        : 1.9594170153141022\n",
      "    val_log_marginal: 660.1373748779297\n",
      "    val_log_joint  : 868.2023162841797\n",
      "Train Epoch: 435 [0/54000 (0%)] Loss: -662.493469\n",
      "Train Epoch: 435 [11264/54000 (21%)] Loss: -653.252441\n",
      "Train Epoch: 435 [22528/54000 (42%)] Loss: -669.619751\n",
      "Train Epoch: 435 [33792/54000 (63%)] Loss: -658.405518\n",
      "Train Epoch: 435 [45056/54000 (83%)] Loss: -637.331543\n",
      "    epoch          : 435\n",
      "    loss           : -657.0004664007223\n",
      "    ess            : 1.9584930505392686\n",
      "    log_marginal   : 657.0356571989239\n",
      "    log_joint      : 864.9906437711895\n",
      "    val_loss       : -661.0894826253256\n",
      "    val_ess        : 1.9557696878910065\n",
      "    val_log_marginal: 661.1274820963541\n",
      "    val_log_joint  : 868.8707682291666\n",
      "Train Epoch: 436 [0/54000 (0%)] Loss: -629.799683\n",
      "Train Epoch: 436 [11264/54000 (21%)] Loss: -657.756531\n",
      "Train Epoch: 436 [22528/54000 (42%)] Loss: -652.686768\n",
      "Train Epoch: 436 [33792/54000 (63%)] Loss: -664.750732\n",
      "Train Epoch: 436 [45056/54000 (83%)] Loss: -662.576294\n",
      "    epoch          : 436\n",
      "    loss           : -657.3685124235333\n",
      "    ess            : 1.9594131651914344\n",
      "    log_marginal   : 657.4022982615345\n",
      "    log_joint      : 865.3913706653523\n",
      "    val_loss       : -661.1910451253256\n",
      "    val_ess        : 1.9593557020028431\n",
      "    val_log_marginal: 661.2271270751953\n",
      "    val_log_joint  : 869.1632130940756\n",
      "Train Epoch: 437 [0/54000 (0%)] Loss: -664.374023\n",
      "Train Epoch: 437 [11264/54000 (21%)] Loss: -668.301514\n",
      "Train Epoch: 437 [22528/54000 (42%)] Loss: -676.150391\n",
      "Train Epoch: 437 [33792/54000 (63%)] Loss: -678.979614\n",
      "Train Epoch: 437 [45056/54000 (83%)] Loss: -658.861938\n",
      "    epoch          : 437\n",
      "    loss           : -657.8237995651533\n",
      "    ess            : 1.9574270844459534\n",
      "    log_marginal   : 657.8605974305351\n",
      "    log_joint      : 865.9082106104437\n",
      "    val_loss       : -661.2740020751953\n",
      "    val_ess        : 1.9612361987431843\n",
      "    val_log_marginal: 661.3035990397135\n",
      "    val_log_joint  : 869.2895100911459\n",
      "Train Epoch: 438 [0/54000 (0%)] Loss: -657.410645\n",
      "Train Epoch: 438 [11264/54000 (21%)] Loss: -671.643433\n",
      "Train Epoch: 438 [22528/54000 (42%)] Loss: -652.620972\n",
      "Train Epoch: 438 [33792/54000 (63%)] Loss: -666.092285\n",
      "Train Epoch: 438 [45056/54000 (83%)] Loss: -668.681152\n",
      "    epoch          : 438\n",
      "    loss           : -657.8162208413178\n",
      "    ess            : 1.9595194492699965\n",
      "    log_marginal   : 657.8504212577388\n",
      "    log_joint      : 865.771722181788\n",
      "    val_loss       : -661.2505900065104\n",
      "    val_ess        : 1.9565819303194683\n",
      "    val_log_marginal: 661.2927602132162\n",
      "    val_log_joint  : 869.5095825195312\n",
      "Train Epoch: 439 [0/54000 (0%)] Loss: -650.222900\n",
      "Train Epoch: 439 [11264/54000 (21%)] Loss: -652.360840\n",
      "Train Epoch: 439 [22528/54000 (42%)] Loss: -644.850708\n",
      "Train Epoch: 439 [33792/54000 (63%)] Loss: -653.373596\n",
      "Train Epoch: 439 [45056/54000 (83%)] Loss: -657.574341\n",
      "    epoch          : 439\n",
      "    loss           : -658.1714483297096\n",
      "    ess            : 1.958195871901962\n",
      "    log_marginal   : 658.2075632923054\n",
      "    log_joint      : 866.12702337301\n",
      "    val_loss       : -661.4186401367188\n",
      "    val_ess        : 1.959082027276357\n",
      "    val_log_marginal: 661.4529062906901\n",
      "    val_log_joint  : 869.7419077555338\n",
      "Train Epoch: 440 [0/54000 (0%)] Loss: -658.633850\n",
      "Train Epoch: 440 [11264/54000 (21%)] Loss: -655.248291\n",
      "Train Epoch: 440 [22528/54000 (42%)] Loss: -652.640991\n",
      "Train Epoch: 440 [33792/54000 (63%)] Loss: -657.154541\n",
      "Train Epoch: 440 [45056/54000 (83%)] Loss: -669.008423\n",
      "    epoch          : 440\n",
      "    loss           : -658.3693588544737\n",
      "    ess            : 1.957944001791612\n",
      "    log_marginal   : 658.4044736466318\n",
      "    log_joint      : 866.4482790389151\n",
      "    val_loss       : -662.4456939697266\n",
      "    val_ess        : 1.9585035343964894\n",
      "    val_log_marginal: 662.4826100667318\n",
      "    val_log_joint  : 870.5379435221354\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch440.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 441 [0/54000 (0%)] Loss: -651.358032\n",
      "Train Epoch: 441 [11264/54000 (21%)] Loss: -656.209351\n",
      "Train Epoch: 441 [22528/54000 (42%)] Loss: -658.292114\n",
      "Train Epoch: 441 [33792/54000 (63%)] Loss: -641.368164\n",
      "Train Epoch: 441 [45056/54000 (83%)] Loss: -656.911377\n",
      "    epoch          : 441\n",
      "    loss           : -658.8867262354437\n",
      "    ess            : 1.958346833597939\n",
      "    log_marginal   : 658.9233087503685\n",
      "    log_joint      : 866.7786185786409\n",
      "    val_loss       : -662.0169881184896\n",
      "    val_ess        : 1.9569137692451477\n",
      "    val_log_marginal: 662.0535430908203\n",
      "    val_log_joint  : 870.2995249430338\n",
      "Train Epoch: 442 [0/54000 (0%)] Loss: -651.890747\n",
      "Train Epoch: 442 [11264/54000 (21%)] Loss: -655.216064\n",
      "Train Epoch: 442 [22528/54000 (42%)] Loss: -658.518372\n",
      "Train Epoch: 442 [33792/54000 (63%)] Loss: -665.830200\n",
      "Train Epoch: 442 [45056/54000 (83%)] Loss: -657.722229\n",
      "    epoch          : 442\n",
      "    loss           : -658.9267468722361\n",
      "    ess            : 1.9584248313363992\n",
      "    log_marginal   : 658.9629862083578\n",
      "    log_joint      : 866.9957413583431\n",
      "    val_loss       : -663.6322733561198\n",
      "    val_ess        : 1.9625208377838135\n",
      "    val_log_marginal: 663.660898844401\n",
      "    val_log_joint  : 871.4073384602865\n",
      "Train Epoch: 443 [0/54000 (0%)] Loss: -651.481201\n",
      "Train Epoch: 443 [11264/54000 (21%)] Loss: -646.152954\n",
      "Train Epoch: 443 [22528/54000 (42%)] Loss: -675.563110\n",
      "Train Epoch: 443 [33792/54000 (63%)] Loss: -677.394836\n",
      "Train Epoch: 443 [45056/54000 (83%)] Loss: -691.452942\n",
      "    epoch          : 443\n",
      "    loss           : -659.6818611576872\n",
      "    ess            : 1.9583218086440608\n",
      "    log_marginal   : 659.7166891997715\n",
      "    log_joint      : 867.6715168503096\n",
      "    val_loss       : -663.5760854085287\n",
      "    val_ess        : 1.9595741232236226\n",
      "    val_log_marginal: 663.6112314860026\n",
      "    val_log_joint  : 871.4788208007812\n",
      "Train Epoch: 444 [0/54000 (0%)] Loss: -649.313049\n",
      "Train Epoch: 444 [11264/54000 (21%)] Loss: -655.982788\n",
      "Train Epoch: 444 [22528/54000 (42%)] Loss: -644.993408\n",
      "Train Epoch: 444 [33792/54000 (63%)] Loss: -657.064514\n",
      "Train Epoch: 444 [45056/54000 (83%)] Loss: -663.051208\n",
      "    epoch          : 444\n",
      "    loss           : -659.7628185344192\n",
      "    ess            : 1.9577106867196425\n",
      "    log_marginal   : 659.8003856730911\n",
      "    log_joint      : 867.768122259176\n",
      "    val_loss       : -662.9600931803385\n",
      "    val_ess        : 1.9617848893006642\n",
      "    val_log_marginal: 662.9905954996744\n",
      "    val_log_joint  : 870.9259033203125\n",
      "Train Epoch: 445 [0/54000 (0%)] Loss: -660.805176\n",
      "Train Epoch: 445 [11264/54000 (21%)] Loss: -669.351074\n",
      "Train Epoch: 445 [22528/54000 (42%)] Loss: -691.064819\n",
      "Train Epoch: 445 [33792/54000 (63%)] Loss: -648.649841\n",
      "Train Epoch: 445 [45056/54000 (83%)] Loss: -660.329346\n",
      "    epoch          : 445\n",
      "    loss           : -660.0008510373673\n",
      "    ess            : 1.9591012169729989\n",
      "    log_marginal   : 660.0354573951578\n",
      "    log_joint      : 868.0001168880823\n",
      "    val_loss       : -663.8695017496744\n",
      "    val_ess        : 1.9597279528776805\n",
      "    val_log_marginal: 663.9047597249349\n",
      "    val_log_joint  : 872.0265909830729\n",
      "Train Epoch: 446 [0/54000 (0%)] Loss: -668.608643\n",
      "Train Epoch: 446 [11264/54000 (21%)] Loss: -687.408447\n",
      "Train Epoch: 446 [22528/54000 (42%)] Loss: -663.678162\n",
      "Train Epoch: 446 [33792/54000 (63%)] Loss: -662.107788\n",
      "Train Epoch: 446 [45056/54000 (83%)] Loss: -658.522949\n",
      "    epoch          : 446\n",
      "    loss           : -660.3617283083358\n",
      "    ess            : 1.9588266138760548\n",
      "    log_marginal   : 660.3966300532503\n",
      "    log_joint      : 868.2797926416937\n",
      "    val_loss       : -664.4235788981119\n",
      "    val_ess        : 1.9578024744987488\n",
      "    val_log_marginal: 664.4600982666016\n",
      "    val_log_joint  : 872.4449920654297\n",
      "Train Epoch: 447 [0/54000 (0%)] Loss: -656.780823\n",
      "Train Epoch: 447 [11264/54000 (21%)] Loss: -646.147156\n",
      "Train Epoch: 447 [22528/54000 (42%)] Loss: -645.700073\n",
      "Train Epoch: 447 [33792/54000 (63%)] Loss: -653.756958\n",
      "Train Epoch: 447 [45056/54000 (83%)] Loss: -649.602173\n",
      "    epoch          : 447\n",
      "    loss           : -660.5795892679466\n",
      "    ess            : 1.9580317060902435\n",
      "    log_marginal   : 660.615947795364\n",
      "    log_joint      : 868.5453853967055\n",
      "    val_loss       : -664.3856404622396\n",
      "    val_ess        : 1.9601860642433167\n",
      "    val_log_marginal: 664.4176381429037\n",
      "    val_log_joint  : 872.385508219401\n",
      "Train Epoch: 448 [0/54000 (0%)] Loss: -663.600159\n",
      "Train Epoch: 448 [11264/54000 (21%)] Loss: -663.611633\n",
      "Train Epoch: 448 [22528/54000 (42%)] Loss: -664.122253\n",
      "Train Epoch: 448 [33792/54000 (63%)] Loss: -666.468872\n",
      "Train Epoch: 448 [45056/54000 (83%)] Loss: -647.513367\n",
      "    epoch          : 448\n",
      "    loss           : -660.9486158838812\n",
      "    ess            : 1.9592437642925191\n",
      "    log_marginal   : 660.9824166927698\n",
      "    log_joint      : 868.9415277445091\n",
      "    val_loss       : -665.5393371582031\n",
      "    val_ess        : 1.9580442905426025\n",
      "    val_log_marginal: 665.5754547119141\n",
      "    val_log_joint  : 873.5992431640625\n",
      "Train Epoch: 449 [0/54000 (0%)] Loss: -662.965576\n",
      "Train Epoch: 449 [11264/54000 (21%)] Loss: -662.713013\n",
      "Train Epoch: 449 [22528/54000 (42%)] Loss: -666.884705\n",
      "Train Epoch: 449 [33792/54000 (63%)] Loss: -642.558472\n",
      "Train Epoch: 449 [45056/54000 (83%)] Loss: -662.258545\n",
      "    epoch          : 449\n",
      "    loss           : -661.0459951724646\n",
      "    ess            : 1.9593764611010283\n",
      "    log_marginal   : 661.0796670014004\n",
      "    log_joint      : 869.0790197984228\n",
      "    val_loss       : -665.1172993977865\n",
      "    val_ess        : 1.958344578742981\n",
      "    val_log_marginal: 665.1507975260416\n",
      "    val_log_joint  : 872.9757181803385\n",
      "Train Epoch: 450 [0/54000 (0%)] Loss: -654.849487\n",
      "Train Epoch: 450 [11264/54000 (21%)] Loss: -668.241211\n",
      "Train Epoch: 450 [22528/54000 (42%)] Loss: -656.217773\n",
      "Train Epoch: 450 [33792/54000 (63%)] Loss: -659.049316\n",
      "Train Epoch: 450 [45056/54000 (83%)] Loss: -669.361938\n",
      "    epoch          : 450\n",
      "    loss           : -661.4428025731501\n",
      "    ess            : 1.9587410216061574\n",
      "    log_marginal   : 661.4771279389004\n",
      "    log_joint      : 869.4899338056456\n",
      "    val_loss       : -666.0501607259115\n",
      "    val_ess        : 1.9571757912635803\n",
      "    val_log_marginal: 666.0841522216797\n",
      "    val_log_joint  : 874.1140289306641\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch450.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 451 [0/54000 (0%)] Loss: -646.302246\n",
      "Train Epoch: 451 [11264/54000 (21%)] Loss: -667.258484\n",
      "Train Epoch: 451 [22528/54000 (42%)] Loss: -671.066040\n",
      "Train Epoch: 451 [33792/54000 (63%)] Loss: -660.245483\n",
      "Train Epoch: 451 [45056/54000 (83%)] Loss: -663.988525\n",
      "    epoch          : 451\n",
      "    loss           : -661.7221288141214\n",
      "    ess            : 1.9580957158556525\n",
      "    log_marginal   : 661.7575533884876\n",
      "    log_joint      : 869.7416076660156\n",
      "    val_loss       : -665.9371134440104\n",
      "    val_ess        : 1.9597458740075429\n",
      "    val_log_marginal: 665.9712677001953\n",
      "    val_log_joint  : 873.9965159098307\n",
      "Train Epoch: 452 [0/54000 (0%)] Loss: -658.792175\n",
      "Train Epoch: 452 [11264/54000 (21%)] Loss: -688.635498\n",
      "Train Epoch: 452 [22528/54000 (42%)] Loss: -683.517578\n",
      "Train Epoch: 452 [33792/54000 (63%)] Loss: -666.062927\n",
      "Train Epoch: 452 [45056/54000 (83%)] Loss: -667.264404\n",
      "    epoch          : 452\n",
      "    loss           : -662.0212782373968\n",
      "    ess            : 1.9585218294611517\n",
      "    log_marginal   : 662.0556427577757\n",
      "    log_joint      : 870.1660449909714\n",
      "    val_loss       : -665.1589304606119\n",
      "    val_ess        : 1.9553470611572266\n",
      "    val_log_marginal: 665.1974080403646\n",
      "    val_log_joint  : 873.3601430257162\n",
      "Train Epoch: 453 [0/54000 (0%)] Loss: -670.321289\n",
      "Train Epoch: 453 [11264/54000 (21%)] Loss: -639.259521\n",
      "Train Epoch: 453 [22528/54000 (42%)] Loss: -648.657043\n",
      "Train Epoch: 453 [33792/54000 (63%)] Loss: -652.313354\n",
      "Train Epoch: 453 [45056/54000 (83%)] Loss: -644.875000\n",
      "    epoch          : 453\n",
      "    loss           : -662.6368137575546\n",
      "    ess            : 1.958370587735806\n",
      "    log_marginal   : 662.6718876676739\n",
      "    log_joint      : 870.6011312232828\n",
      "    val_loss       : -666.5450744628906\n",
      "    val_ess        : 1.9616239766279857\n",
      "    val_log_marginal: 666.5791168212891\n",
      "    val_log_joint  : 874.3673960367838\n",
      "Train Epoch: 454 [0/54000 (0%)] Loss: -678.934753\n",
      "Train Epoch: 454 [11264/54000 (21%)] Loss: -641.261841\n",
      "Train Epoch: 454 [22528/54000 (42%)] Loss: -662.829956\n",
      "Train Epoch: 454 [33792/54000 (63%)] Loss: -689.242798\n",
      "Train Epoch: 454 [45056/54000 (83%)] Loss: -659.784790\n",
      "    epoch          : 454\n",
      "    loss           : -662.7915079368735\n",
      "    ess            : 1.958875813574161\n",
      "    log_marginal   : 662.8269820303287\n",
      "    log_joint      : 870.8314393241451\n",
      "    val_loss       : -667.0793151855469\n",
      "    val_ess        : 1.9593055248260498\n",
      "    val_log_marginal: 667.1169942220052\n",
      "    val_log_joint  : 874.8423360188802\n",
      "Train Epoch: 455 [0/54000 (0%)] Loss: -689.426941\n",
      "Train Epoch: 455 [11264/54000 (21%)] Loss: -655.294556\n",
      "Train Epoch: 455 [22528/54000 (42%)] Loss: -655.407837\n",
      "Train Epoch: 455 [33792/54000 (63%)] Loss: -676.386353\n",
      "Train Epoch: 455 [45056/54000 (83%)] Loss: -663.554688\n",
      "    epoch          : 455\n",
      "    loss           : -662.6051238437868\n",
      "    ess            : 1.959429088628517\n",
      "    log_marginal   : 662.6392344348835\n",
      "    log_joint      : 870.6968303176592\n",
      "    val_loss       : -666.6851348876953\n",
      "    val_ess        : 1.960403859615326\n",
      "    val_log_marginal: 666.7199350992838\n",
      "    val_log_joint  : 874.7191162109375\n",
      "Train Epoch: 456 [0/54000 (0%)] Loss: -646.352905\n",
      "Train Epoch: 456 [11264/54000 (21%)] Loss: -672.054321\n",
      "Train Epoch: 456 [22528/54000 (42%)] Loss: -661.549438\n",
      "Train Epoch: 456 [33792/54000 (63%)] Loss: -644.005493\n",
      "Train Epoch: 456 [45056/54000 (83%)] Loss: -648.759644\n",
      "    epoch          : 456\n",
      "    loss           : -663.2096914615271\n",
      "    ess            : 1.9588943056340486\n",
      "    log_marginal   : 663.2438544507297\n",
      "    log_joint      : 871.27134560639\n",
      "    val_loss       : -666.9133453369141\n",
      "    val_ess        : 1.9586466352144878\n",
      "    val_log_marginal: 666.946767171224\n",
      "    val_log_joint  : 875.0818481445312\n",
      "Train Epoch: 457 [0/54000 (0%)] Loss: -658.350708\n",
      "Train Epoch: 457 [11264/54000 (21%)] Loss: -674.846313\n",
      "Train Epoch: 457 [22528/54000 (42%)] Loss: -681.163818\n",
      "Train Epoch: 457 [33792/54000 (63%)] Loss: -634.592590\n",
      "Train Epoch: 457 [45056/54000 (83%)] Loss: -635.156494\n",
      "    epoch          : 457\n",
      "    loss           : -663.6351122586233\n",
      "    ess            : 1.9596165261178646\n",
      "    log_marginal   : 663.6689504947302\n",
      "    log_joint      : 871.5645158875664\n",
      "    val_loss       : -667.533437093099\n",
      "    val_ess        : 1.9573581119378407\n",
      "    val_log_marginal: 667.5699513753256\n",
      "    val_log_joint  : 875.5512390136719\n",
      "Train Epoch: 458 [0/54000 (0%)] Loss: -665.087891\n",
      "Train Epoch: 458 [11264/54000 (21%)] Loss: -650.283875\n",
      "Train Epoch: 458 [22528/54000 (42%)] Loss: -645.646057\n",
      "Train Epoch: 458 [33792/54000 (63%)] Loss: -669.498657\n",
      "Train Epoch: 458 [45056/54000 (83%)] Loss: -677.008667\n",
      "    epoch          : 458\n",
      "    loss           : -663.8664850198998\n",
      "    ess            : 1.958930589118094\n",
      "    log_marginal   : 663.9009946427255\n",
      "    log_joint      : 871.867369453862\n",
      "    val_loss       : -667.3502756754557\n",
      "    val_ess        : 1.9544800519943237\n",
      "    val_log_marginal: 667.3902893066406\n",
      "    val_log_joint  : 875.3413441975912\n",
      "Train Epoch: 459 [0/54000 (0%)] Loss: -650.619690\n",
      "Train Epoch: 459 [11264/54000 (21%)] Loss: -667.039795\n",
      "Train Epoch: 459 [22528/54000 (42%)] Loss: -650.724182\n",
      "Train Epoch: 459 [33792/54000 (63%)] Loss: -645.088623\n",
      "Train Epoch: 459 [45056/54000 (83%)] Loss: -686.484924\n",
      "    epoch          : 459\n",
      "    loss           : -663.9871192788178\n",
      "    ess            : 1.9570266885577507\n",
      "    log_marginal   : 664.0242764454968\n",
      "    log_joint      : 872.0559329626695\n",
      "    val_loss       : -668.7197265625\n",
      "    val_ess        : 1.956420252720515\n",
      "    val_log_marginal: 668.7597096761068\n",
      "    val_log_joint  : 876.5220998128256\n",
      "Train Epoch: 460 [0/54000 (0%)] Loss: -671.241333\n",
      "Train Epoch: 460 [11264/54000 (21%)] Loss: -679.193481\n",
      "Train Epoch: 460 [22528/54000 (42%)] Loss: -709.010132\n",
      "Train Epoch: 460 [33792/54000 (63%)] Loss: -643.238403\n",
      "Train Epoch: 460 [45056/54000 (83%)] Loss: -683.535767\n",
      "    epoch          : 460\n",
      "    loss           : -664.4768187324955\n",
      "    ess            : 1.958012857527103\n",
      "    log_marginal   : 664.5137490326504\n",
      "    log_joint      : 872.5143415343086\n",
      "    val_loss       : -668.829844156901\n",
      "    val_ess        : 1.9606406390666962\n",
      "    val_log_marginal: 668.8656972249349\n",
      "    val_log_joint  : 876.6934712727865\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch460.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 461 [0/54000 (0%)] Loss: -661.089233\n",
      "Train Epoch: 461 [11264/54000 (21%)] Loss: -677.243835\n",
      "Train Epoch: 461 [22528/54000 (42%)] Loss: -651.514771\n",
      "Train Epoch: 461 [33792/54000 (63%)] Loss: -668.597168\n",
      "Train Epoch: 461 [45056/54000 (83%)] Loss: -663.761597\n",
      "    epoch          : 461\n",
      "    loss           : -664.6452579138414\n",
      "    ess            : 1.9588580648854095\n",
      "    log_marginal   : 664.6801671441996\n",
      "    log_joint      : 872.614572201135\n",
      "    val_loss       : -667.6523691813151\n",
      "    val_ess        : 1.9606308142344158\n",
      "    val_log_marginal: 667.6835784912109\n",
      "    val_log_joint  : 875.7425181070963\n",
      "Train Epoch: 462 [0/54000 (0%)] Loss: -660.294983\n",
      "Train Epoch: 462 [11264/54000 (21%)] Loss: -662.407898\n",
      "Train Epoch: 462 [22528/54000 (42%)] Loss: -651.944458\n",
      "Train Epoch: 462 [33792/54000 (63%)] Loss: -671.523193\n",
      "Train Epoch: 462 [45056/54000 (83%)] Loss: -676.185608\n",
      "    epoch          : 462\n",
      "    loss           : -664.5791338074882\n",
      "    ess            : 1.9581066055117913\n",
      "    log_marginal   : 664.614446100199\n",
      "    log_joint      : 872.6259984430277\n",
      "    val_loss       : -668.8658040364584\n",
      "    val_ess        : 1.9574394226074219\n",
      "    val_log_marginal: 668.9026845296224\n",
      "    val_log_joint  : 877.1656748453776\n",
      "Train Epoch: 463 [0/54000 (0%)] Loss: -662.560364\n",
      "Train Epoch: 463 [11264/54000 (21%)] Loss: -632.794434\n",
      "Train Epoch: 463 [22528/54000 (42%)] Loss: -664.334717\n",
      "Train Epoch: 463 [33792/54000 (63%)] Loss: -670.208679\n",
      "Train Epoch: 463 [45056/54000 (83%)] Loss: -689.186279\n",
      "    epoch          : 463\n",
      "    loss           : -665.367340663694\n",
      "    ess            : 1.9600784328748595\n",
      "    log_marginal   : 665.4002472499632\n",
      "    log_joint      : 873.3347628611439\n",
      "    val_loss       : -669.1087290445963\n",
      "    val_ess        : 1.955236981312434\n",
      "    val_log_marginal: 669.1457672119141\n",
      "    val_log_joint  : 877.1236826578776\n",
      "Train Epoch: 464 [0/54000 (0%)] Loss: -669.626343\n",
      "Train Epoch: 464 [11264/54000 (21%)] Loss: -667.405212\n",
      "Train Epoch: 464 [22528/54000 (42%)] Loss: -658.882812\n",
      "Train Epoch: 464 [33792/54000 (63%)] Loss: -659.377197\n",
      "Train Epoch: 464 [45056/54000 (83%)] Loss: -690.765930\n",
      "    epoch          : 464\n",
      "    loss           : -665.3629881660893\n",
      "    ess            : 1.9575791156516884\n",
      "    log_marginal   : 665.3988992942953\n",
      "    log_joint      : 873.410700384176\n",
      "    val_loss       : -669.2869466145834\n",
      "    val_ess        : 1.959897667169571\n",
      "    val_log_marginal: 669.3215281168619\n",
      "    val_log_joint  : 877.337646484375\n",
      "Train Epoch: 465 [0/54000 (0%)] Loss: -672.160645\n",
      "Train Epoch: 465 [11264/54000 (21%)] Loss: -636.762756\n",
      "Train Epoch: 465 [22528/54000 (42%)] Loss: -669.755432\n",
      "Train Epoch: 465 [33792/54000 (63%)] Loss: -690.103394\n",
      "Train Epoch: 465 [45056/54000 (83%)] Loss: -665.444702\n",
      "    epoch          : 465\n",
      "    loss           : -665.640912325877\n",
      "    ess            : 1.9584147345344975\n",
      "    log_marginal   : 665.6765879505085\n",
      "    log_joint      : 873.6944384304983\n",
      "    val_loss       : -669.3243865966797\n",
      "    val_ess        : 1.96077757080396\n",
      "    val_log_marginal: 669.3541717529297\n",
      "    val_log_joint  : 877.2585805257162\n",
      "Train Epoch: 466 [0/54000 (0%)] Loss: -679.286011\n",
      "Train Epoch: 466 [11264/54000 (21%)] Loss: -648.929565\n",
      "Train Epoch: 466 [22528/54000 (42%)] Loss: -672.063965\n",
      "Train Epoch: 466 [33792/54000 (63%)] Loss: -656.107910\n",
      "Train Epoch: 466 [45056/54000 (83%)] Loss: -664.498352\n",
      "    epoch          : 466\n",
      "    loss           : -666.0783887179392\n",
      "    ess            : 1.9591957206995982\n",
      "    log_marginal   : 666.1122977778597\n",
      "    log_joint      : 874.1421750626474\n",
      "    val_loss       : -669.8457082112631\n",
      "    val_ess        : 1.9608547389507294\n",
      "    val_log_marginal: 669.8762003580729\n",
      "    val_log_joint  : 877.9678548177084\n",
      "Train Epoch: 467 [0/54000 (0%)] Loss: -659.505371\n",
      "Train Epoch: 467 [11264/54000 (21%)] Loss: -667.975159\n",
      "Train Epoch: 467 [22528/54000 (42%)] Loss: -677.020996\n",
      "Train Epoch: 467 [33792/54000 (63%)] Loss: -679.783936\n",
      "Train Epoch: 467 [45056/54000 (83%)] Loss: -660.492676\n",
      "    epoch          : 467\n",
      "    loss           : -666.2056809911188\n",
      "    ess            : 1.9592566164034717\n",
      "    log_marginal   : 666.2406691065374\n",
      "    log_joint      : 874.270584394347\n",
      "    val_loss       : -670.4211374918619\n",
      "    val_ess        : 1.9567431807518005\n",
      "    val_log_marginal: 670.456309000651\n",
      "    val_log_joint  : 878.3741505940756\n",
      "Train Epoch: 468 [0/54000 (0%)] Loss: -654.283447\n",
      "Train Epoch: 468 [11264/54000 (21%)] Loss: -663.090454\n",
      "Train Epoch: 468 [22528/54000 (42%)] Loss: -658.789490\n",
      "Train Epoch: 468 [33792/54000 (63%)] Loss: -667.793701\n",
      "Train Epoch: 468 [45056/54000 (83%)] Loss: -676.324036\n",
      "    epoch          : 468\n",
      "    loss           : -666.6595551112913\n",
      "    ess            : 1.9590671242408033\n",
      "    log_marginal   : 666.6937388294148\n",
      "    log_joint      : 874.8105365105395\n",
      "    val_loss       : -669.6332448323568\n",
      "    val_ess        : 1.9575698673725128\n",
      "    val_log_marginal: 669.6683095296224\n",
      "    val_log_joint  : 877.7342325846354\n",
      "Train Epoch: 469 [0/54000 (0%)] Loss: -665.181274\n",
      "Train Epoch: 469 [11264/54000 (21%)] Loss: -659.905396\n",
      "Train Epoch: 469 [22528/54000 (42%)] Loss: -670.259277\n",
      "Train Epoch: 469 [33792/54000 (63%)] Loss: -653.865601\n",
      "Train Epoch: 469 [45056/54000 (83%)] Loss: -683.125244\n",
      "    epoch          : 469\n",
      "    loss           : -666.8018119380159\n",
      "    ess            : 1.9588025515934206\n",
      "    log_marginal   : 666.8363797169811\n",
      "    log_joint      : 874.867158709832\n",
      "    val_loss       : -670.3054351806641\n",
      "    val_ess        : 1.9589435656865437\n",
      "    val_log_marginal: 670.3399098714193\n",
      "    val_log_joint  : 878.4635670979818\n",
      "Train Epoch: 470 [0/54000 (0%)] Loss: -686.539795\n",
      "Train Epoch: 470 [11264/54000 (21%)] Loss: -674.551880\n",
      "Train Epoch: 470 [22528/54000 (42%)] Loss: -682.033142\n",
      "Train Epoch: 470 [33792/54000 (63%)] Loss: -685.026978\n",
      "Train Epoch: 470 [45056/54000 (83%)] Loss: -669.412354\n",
      "    epoch          : 470\n",
      "    loss           : -667.1674775897332\n",
      "    ess            : 1.9594571702885177\n",
      "    log_marginal   : 667.2019094791052\n",
      "    log_joint      : 875.3127913565006\n",
      "    val_loss       : -671.0374348958334\n",
      "    val_ess        : 1.9570450286070507\n",
      "    val_log_marginal: 671.0754648844401\n",
      "    val_log_joint  : 879.1806335449219\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch470.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 471 [0/54000 (0%)] Loss: -683.299072\n",
      "Train Epoch: 471 [11264/54000 (21%)] Loss: -669.312744\n",
      "Train Epoch: 471 [22528/54000 (42%)] Loss: -666.669678\n",
      "Train Epoch: 471 [33792/54000 (63%)] Loss: -661.207642\n",
      "Train Epoch: 471 [45056/54000 (83%)] Loss: -650.709656\n",
      "    epoch          : 471\n",
      "    loss           : -667.5271232173128\n",
      "    ess            : 1.959535337843985\n",
      "    log_marginal   : 667.5612556889372\n",
      "    log_joint      : 875.6162408792748\n",
      "    val_loss       : -670.8155059814453\n",
      "    val_ess        : 1.9615578452746074\n",
      "    val_log_marginal: 670.8485565185547\n",
      "    val_log_joint  : 878.7493947347006\n",
      "Train Epoch: 472 [0/54000 (0%)] Loss: -666.705322\n",
      "Train Epoch: 472 [11264/54000 (21%)] Loss: -688.878296\n",
      "Train Epoch: 472 [22528/54000 (42%)] Loss: -678.749023\n",
      "Train Epoch: 472 [33792/54000 (63%)] Loss: -662.626038\n",
      "Train Epoch: 472 [45056/54000 (83%)] Loss: -671.006958\n",
      "    epoch          : 472\n",
      "    loss           : -667.8532496038473\n",
      "    ess            : 1.9589463427381695\n",
      "    log_marginal   : 667.8885112258623\n",
      "    log_joint      : 875.9195458754053\n",
      "    val_loss       : -670.9597117106119\n",
      "    val_ess        : 1.9546836614608765\n",
      "    val_log_marginal: 671.0004831949869\n",
      "    val_log_joint  : 879.2099253336588\n",
      "Train Epoch: 473 [0/54000 (0%)] Loss: -678.542725\n",
      "Train Epoch: 473 [11264/54000 (21%)] Loss: -643.157837\n",
      "Train Epoch: 473 [22528/54000 (42%)] Loss: -648.137695\n",
      "Train Epoch: 473 [33792/54000 (63%)] Loss: -686.199707\n",
      "Train Epoch: 473 [45056/54000 (83%)] Loss: -690.484619\n",
      "    epoch          : 473\n",
      "    loss           : -668.0789098199808\n",
      "    ess            : 1.9591117546243488\n",
      "    log_marginal   : 668.1137044654703\n",
      "    log_joint      : 876.1747580474278\n",
      "    val_loss       : -672.0897572835287\n",
      "    val_ess        : 1.9590895175933838\n",
      "    val_log_marginal: 672.1253000895182\n",
      "    val_log_joint  : 880.3531799316406\n",
      "Train Epoch: 474 [0/54000 (0%)] Loss: -653.264587\n",
      "Train Epoch: 474 [11264/54000 (21%)] Loss: -659.535706\n",
      "Train Epoch: 474 [22528/54000 (42%)] Loss: -679.200989\n",
      "Train Epoch: 474 [33792/54000 (63%)] Loss: -653.551453\n",
      "Train Epoch: 474 [45056/54000 (83%)] Loss: -669.415771\n",
      "    epoch          : 474\n",
      "    loss           : -668.6530496849203\n",
      "    ess            : 1.9590415324804917\n",
      "    log_marginal   : 668.6875898253243\n",
      "    log_joint      : 876.7394708597435\n",
      "    val_loss       : -672.6794840494791\n",
      "    val_ess        : 1.961245874563853\n",
      "    val_log_marginal: 672.7135772705078\n",
      "    val_log_joint  : 880.7003428141276\n",
      "Train Epoch: 475 [0/54000 (0%)] Loss: -666.159241\n",
      "Train Epoch: 475 [11264/54000 (21%)] Loss: -660.756958\n",
      "Train Epoch: 475 [22528/54000 (42%)] Loss: -650.810059\n",
      "Train Epoch: 475 [33792/54000 (63%)] Loss: -672.694336\n",
      "Train Epoch: 475 [45056/54000 (83%)] Loss: -688.509888\n",
      "    epoch          : 475\n",
      "    loss           : -668.8364770277491\n",
      "    ess            : 1.9592633089929257\n",
      "    log_marginal   : 668.8702962623453\n",
      "    log_joint      : 876.838693294885\n",
      "    val_loss       : -672.7601928710938\n",
      "    val_ess        : 1.9592321117719014\n",
      "    val_log_marginal: 672.7958323160807\n",
      "    val_log_joint  : 880.6726379394531\n",
      "Train Epoch: 476 [0/54000 (0%)] Loss: -674.317871\n",
      "Train Epoch: 476 [11264/54000 (21%)] Loss: -664.361084\n",
      "Train Epoch: 476 [22528/54000 (42%)] Loss: -680.983948\n",
      "Train Epoch: 476 [33792/54000 (63%)] Loss: -680.519653\n",
      "Train Epoch: 476 [45056/54000 (83%)] Loss: -666.763184\n",
      "    epoch          : 476\n",
      "    loss           : -668.9635303425339\n",
      "    ess            : 1.9592051922150377\n",
      "    log_marginal   : 668.9971843215654\n",
      "    log_joint      : 877.0650629007591\n",
      "    val_loss       : -672.8566284179688\n",
      "    val_ess        : 1.9633509417374928\n",
      "    val_log_marginal: 672.8839823404948\n",
      "    val_log_joint  : 880.8349202473959\n",
      "Train Epoch: 477 [0/54000 (0%)] Loss: -696.594238\n",
      "Train Epoch: 477 [11264/54000 (21%)] Loss: -664.727905\n",
      "Train Epoch: 477 [22528/54000 (42%)] Loss: -674.416626\n",
      "Train Epoch: 477 [33792/54000 (63%)] Loss: -675.572815\n",
      "Train Epoch: 477 [45056/54000 (83%)] Loss: -663.094177\n",
      "    epoch          : 477\n",
      "    loss           : -669.383642232643\n",
      "    ess            : 1.9589724259556465\n",
      "    log_marginal   : 669.4178558925413\n",
      "    log_joint      : 877.4569575471698\n",
      "    val_loss       : -673.1656392415365\n",
      "    val_ess        : 1.961598426103592\n",
      "    val_log_marginal: 673.1973164876302\n",
      "    val_log_joint  : 881.3345133463541\n",
      "Train Epoch: 478 [0/54000 (0%)] Loss: -689.590759\n",
      "Train Epoch: 478 [11264/54000 (21%)] Loss: -673.286255\n",
      "Train Epoch: 478 [22528/54000 (42%)] Loss: -655.553894\n",
      "Train Epoch: 478 [33792/54000 (63%)] Loss: -667.130493\n",
      "Train Epoch: 478 [45056/54000 (83%)] Loss: -651.908508\n",
      "    epoch          : 478\n",
      "    loss           : -669.7538688227816\n",
      "    ess            : 1.9585514405988298\n",
      "    log_marginal   : 669.7892864875074\n",
      "    log_joint      : 877.8463871793927\n",
      "    val_loss       : -673.7692464192709\n",
      "    val_ess        : 1.9577831427256267\n",
      "    val_log_marginal: 673.8023478190104\n",
      "    val_log_joint  : 881.8290252685547\n",
      "Train Epoch: 479 [0/54000 (0%)] Loss: -660.556885\n",
      "Train Epoch: 479 [11264/54000 (21%)] Loss: -669.333496\n",
      "Train Epoch: 479 [22528/54000 (42%)] Loss: -676.662659\n",
      "Train Epoch: 479 [33792/54000 (63%)] Loss: -654.353149\n",
      "Train Epoch: 479 [45056/54000 (83%)] Loss: -693.302185\n",
      "    epoch          : 479\n",
      "    loss           : -669.7295025519605\n",
      "    ess            : 1.9590800775671906\n",
      "    log_marginal   : 669.7633200591465\n",
      "    log_joint      : 877.8151619389372\n",
      "    val_loss       : -673.5295257568359\n",
      "    val_ess        : 1.9622344076633453\n",
      "    val_log_marginal: 673.5600179036459\n",
      "    val_log_joint  : 881.3443552652994\n",
      "Train Epoch: 480 [0/54000 (0%)] Loss: -660.865295\n",
      "Train Epoch: 480 [11264/54000 (21%)] Loss: -672.919434\n",
      "Train Epoch: 480 [22528/54000 (42%)] Loss: -692.776855\n",
      "Train Epoch: 480 [33792/54000 (63%)] Loss: -662.904053\n",
      "Train Epoch: 480 [45056/54000 (83%)] Loss: -699.913452\n",
      "    epoch          : 480\n",
      "    loss           : -670.2160431484007\n",
      "    ess            : 1.9588236932484608\n",
      "    log_marginal   : 670.2502976903376\n",
      "    log_joint      : 878.1885560233638\n",
      "    val_loss       : -674.0343424479166\n",
      "    val_ess        : 1.9627995391686757\n",
      "    val_log_marginal: 674.0636138916016\n",
      "    val_log_joint  : 882.1266021728516\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch480.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 481 [0/54000 (0%)] Loss: -649.578064\n",
      "Train Epoch: 481 [11264/54000 (21%)] Loss: -664.650269\n",
      "Train Epoch: 481 [22528/54000 (42%)] Loss: -682.158203\n",
      "Train Epoch: 481 [33792/54000 (63%)] Loss: -686.174438\n",
      "Train Epoch: 481 [45056/54000 (83%)] Loss: -692.451721\n",
      "    epoch          : 481\n",
      "    loss           : -670.5858649487766\n",
      "    ess            : 1.9603172574403152\n",
      "    log_marginal   : 670.620164979179\n",
      "    log_joint      : 878.6709168632076\n",
      "    val_loss       : -674.6932830810547\n",
      "    val_ess        : 1.958843429883321\n",
      "    val_log_marginal: 674.7320098876953\n",
      "    val_log_joint  : 882.7728373209635\n",
      "Train Epoch: 482 [0/54000 (0%)] Loss: -676.594849\n",
      "Train Epoch: 482 [11264/54000 (21%)] Loss: -681.392456\n",
      "Train Epoch: 482 [22528/54000 (42%)] Loss: -673.184082\n",
      "Train Epoch: 482 [33792/54000 (63%)] Loss: -676.929321\n",
      "Train Epoch: 482 [45056/54000 (83%)] Loss: -653.992065\n",
      "    epoch          : 482\n",
      "    loss           : -670.6564952922317\n",
      "    ess            : 1.9589251943354338\n",
      "    log_marginal   : 670.6916290859007\n",
      "    log_joint      : 878.7894413786114\n",
      "    val_loss       : -674.1428426106771\n",
      "    val_ess        : 1.9570912718772888\n",
      "    val_log_marginal: 674.1776072184244\n",
      "    val_log_joint  : 882.3397979736328\n",
      "Train Epoch: 483 [0/54000 (0%)] Loss: -683.664795\n",
      "Train Epoch: 483 [11264/54000 (21%)] Loss: -674.405334\n",
      "Train Epoch: 483 [22528/54000 (42%)] Loss: -678.500244\n",
      "Train Epoch: 483 [33792/54000 (63%)] Loss: -660.290527\n",
      "Train Epoch: 483 [45056/54000 (83%)] Loss: -646.615845\n",
      "    epoch          : 483\n",
      "    loss           : -670.8292040554983\n",
      "    ess            : 1.9581872719638753\n",
      "    log_marginal   : 670.8644052181604\n",
      "    log_joint      : 878.9146089373894\n",
      "    val_loss       : -675.1623026529948\n",
      "    val_ess        : 1.9601120948791504\n",
      "    val_log_marginal: 675.1930185953776\n",
      "    val_log_joint  : 883.2788899739584\n",
      "Train Epoch: 484 [0/54000 (0%)] Loss: -680.328674\n",
      "Train Epoch: 484 [11264/54000 (21%)] Loss: -673.849854\n",
      "Train Epoch: 484 [22528/54000 (42%)] Loss: -665.580200\n",
      "Train Epoch: 484 [33792/54000 (63%)] Loss: -660.800659\n",
      "Train Epoch: 484 [45056/54000 (83%)] Loss: -673.084473\n",
      "    epoch          : 484\n",
      "    loss           : -671.2124322855248\n",
      "    ess            : 1.958715166685716\n",
      "    log_marginal   : 671.2479933252874\n",
      "    log_joint      : 879.2735601461159\n",
      "    val_loss       : -674.5791269938151\n",
      "    val_ess        : 1.9600183467070262\n",
      "    val_log_marginal: 674.6101125081381\n",
      "    val_log_joint  : 882.8922271728516\n",
      "Train Epoch: 485 [0/54000 (0%)] Loss: -688.273926\n",
      "Train Epoch: 485 [11264/54000 (21%)] Loss: -667.458618\n",
      "Train Epoch: 485 [22528/54000 (42%)] Loss: -643.163818\n",
      "Train Epoch: 485 [33792/54000 (63%)] Loss: -665.499268\n",
      "Train Epoch: 485 [45056/54000 (83%)] Loss: -670.913086\n",
      "    epoch          : 485\n",
      "    loss           : -671.827477221219\n",
      "    ess            : 1.9591414208682079\n",
      "    log_marginal   : 671.8627313577904\n",
      "    log_joint      : 879.9220748037662\n",
      "    val_loss       : -675.2026418050131\n",
      "    val_ess        : 1.958994299173355\n",
      "    val_log_marginal: 675.2389831542969\n",
      "    val_log_joint  : 883.3485819498698\n",
      "Train Epoch: 486 [0/54000 (0%)] Loss: -665.610046\n",
      "Train Epoch: 486 [11264/54000 (21%)] Loss: -661.368530\n",
      "Train Epoch: 486 [22528/54000 (42%)] Loss: -688.201904\n",
      "Train Epoch: 486 [33792/54000 (63%)] Loss: -680.864624\n",
      "Train Epoch: 486 [45056/54000 (83%)] Loss: -674.345215\n",
      "    epoch          : 486\n",
      "    loss           : -671.6783925182415\n",
      "    ess            : 1.9600866774343095\n",
      "    log_marginal   : 671.7112363419443\n",
      "    log_joint      : 879.7726515284124\n",
      "    val_loss       : -674.9089711507162\n",
      "    val_ess        : 1.958973268667857\n",
      "    val_log_marginal: 674.9438781738281\n",
      "    val_log_joint  : 883.3274688720703\n",
      "Train Epoch: 487 [0/54000 (0%)] Loss: -679.009705\n",
      "Train Epoch: 487 [11264/54000 (21%)] Loss: -666.564941\n",
      "Train Epoch: 487 [22528/54000 (42%)] Loss: -671.350403\n",
      "Train Epoch: 487 [33792/54000 (63%)] Loss: -679.637329\n",
      "Train Epoch: 487 [45056/54000 (83%)] Loss: -686.424072\n",
      "    epoch          : 487\n",
      "    loss           : -671.985729865308\n",
      "    ess            : 1.958435613029408\n",
      "    log_marginal   : 672.0201018711306\n",
      "    log_joint      : 880.1534078346109\n",
      "    val_loss       : -676.1106007893881\n",
      "    val_ess        : 1.9632047315438588\n",
      "    val_log_marginal: 676.1400197347006\n",
      "    val_log_joint  : 884.2246246337891\n",
      "Train Epoch: 488 [0/54000 (0%)] Loss: -696.788940\n",
      "Train Epoch: 488 [11264/54000 (21%)] Loss: -670.376770\n",
      "Train Epoch: 488 [22528/54000 (42%)] Loss: -662.019653\n",
      "Train Epoch: 488 [33792/54000 (63%)] Loss: -682.257324\n",
      "Train Epoch: 488 [45056/54000 (83%)] Loss: -649.697266\n",
      "    epoch          : 488\n",
      "    loss           : -672.6142215368883\n",
      "    ess            : 1.9587067894215853\n",
      "    log_marginal   : 672.6496455354511\n",
      "    log_joint      : 880.7545327240566\n",
      "    val_loss       : -676.8064117431641\n",
      "    val_ess        : 1.9612849454085033\n",
      "    val_log_marginal: 676.8401692708334\n",
      "    val_log_joint  : 884.7825673421224\n",
      "Train Epoch: 489 [0/54000 (0%)] Loss: -708.487549\n",
      "Train Epoch: 489 [11264/54000 (21%)] Loss: -685.214539\n",
      "Train Epoch: 489 [22528/54000 (42%)] Loss: -668.184692\n",
      "Train Epoch: 489 [33792/54000 (63%)] Loss: -673.029846\n",
      "Train Epoch: 489 [45056/54000 (83%)] Loss: -659.546631\n",
      "    epoch          : 489\n",
      "    loss           : -672.6275548395121\n",
      "    ess            : 1.9594699999071516\n",
      "    log_marginal   : 672.6616435500811\n",
      "    log_joint      : 880.7147890486807\n",
      "    val_loss       : -676.0543060302734\n",
      "    val_ess        : 1.960357129573822\n",
      "    val_log_marginal: 676.0891723632812\n",
      "    val_log_joint  : 884.3153076171875\n",
      "Train Epoch: 490 [0/54000 (0%)] Loss: -671.284424\n",
      "Train Epoch: 490 [11264/54000 (21%)] Loss: -659.642883\n",
      "Train Epoch: 490 [22528/54000 (42%)] Loss: -658.156738\n",
      "Train Epoch: 490 [33792/54000 (63%)] Loss: -666.952820\n",
      "Train Epoch: 490 [45056/54000 (83%)] Loss: -678.527405\n",
      "    epoch          : 490\n",
      "    loss           : -672.9233715129349\n",
      "    ess            : 1.9593902702601451\n",
      "    log_marginal   : 672.9570439176739\n",
      "    log_joint      : 881.034585053066\n",
      "    val_loss       : -677.0211029052734\n",
      "    val_ess        : 1.9632411201794941\n",
      "    val_log_marginal: 677.0499725341797\n",
      "    val_log_joint  : 884.9099731445312\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch490.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 491 [0/54000 (0%)] Loss: -675.437988\n",
      "Train Epoch: 491 [11264/54000 (21%)] Loss: -663.056213\n",
      "Train Epoch: 491 [22528/54000 (42%)] Loss: -684.213135\n",
      "Train Epoch: 491 [33792/54000 (63%)] Loss: -692.551636\n",
      "Train Epoch: 491 [45056/54000 (83%)] Loss: -691.212646\n",
      "    epoch          : 491\n",
      "    loss           : -673.3210276477741\n",
      "    ess            : 1.9593662844513946\n",
      "    log_marginal   : 673.3555522414873\n",
      "    log_joint      : 881.4529056189195\n",
      "    val_loss       : -677.3009236653646\n",
      "    val_ess        : 1.963047355413437\n",
      "    val_log_marginal: 677.3297983805338\n",
      "    val_log_joint  : 885.2604420979818\n",
      "Train Epoch: 492 [0/54000 (0%)] Loss: -683.369812\n",
      "Train Epoch: 492 [11264/54000 (21%)] Loss: -695.315491\n",
      "Train Epoch: 492 [22528/54000 (42%)] Loss: -670.682861\n",
      "Train Epoch: 492 [33792/54000 (63%)] Loss: -675.040283\n",
      "Train Epoch: 492 [45056/54000 (83%)] Loss: -654.971191\n",
      "    epoch          : 492\n",
      "    loss           : -673.6418238225973\n",
      "    ess            : 1.9587728482372355\n",
      "    log_marginal   : 673.6770624124779\n",
      "    log_joint      : 881.7890987756117\n",
      "    val_loss       : -676.7450510660807\n",
      "    val_ess        : 1.9587633907794952\n",
      "    val_log_marginal: 676.7821553548177\n",
      "    val_log_joint  : 884.8937835693359\n",
      "Train Epoch: 493 [0/54000 (0%)] Loss: -697.798157\n",
      "Train Epoch: 493 [11264/54000 (21%)] Loss: -668.154663\n",
      "Train Epoch: 493 [22528/54000 (42%)] Loss: -674.777832\n",
      "Train Epoch: 493 [33792/54000 (63%)] Loss: -663.805786\n",
      "Train Epoch: 493 [45056/54000 (83%)] Loss: -663.268677\n",
      "    epoch          : 493\n",
      "    loss           : -673.7919392135908\n",
      "    ess            : 1.9585032373104456\n",
      "    log_marginal   : 673.8270332768278\n",
      "    log_joint      : 881.9408344772627\n",
      "    val_loss       : -678.2609659830729\n",
      "    val_ess        : 1.9604821403821309\n",
      "    val_log_marginal: 678.2915598551432\n",
      "    val_log_joint  : 886.2653401692709\n",
      "Train Epoch: 494 [0/54000 (0%)] Loss: -647.511047\n",
      "Train Epoch: 494 [11264/54000 (21%)] Loss: -679.895081\n",
      "Train Epoch: 494 [22528/54000 (42%)] Loss: -673.377075\n",
      "Train Epoch: 494 [33792/54000 (63%)] Loss: -676.505615\n",
      "Train Epoch: 494 [45056/54000 (83%)] Loss: -674.668335\n",
      "    epoch          : 494\n",
      "    loss           : -674.6062385990934\n",
      "    ess            : 1.9592009276713964\n",
      "    log_marginal   : 674.6398142688679\n",
      "    log_joint      : 882.6231539744251\n",
      "    val_loss       : -678.2533009847006\n",
      "    val_ess        : 1.9594061374664307\n",
      "    val_log_marginal: 678.2869466145834\n",
      "    val_log_joint  : 886.1746470133463\n",
      "Train Epoch: 495 [0/54000 (0%)] Loss: -655.320190\n",
      "Train Epoch: 495 [11264/54000 (21%)] Loss: -682.895081\n",
      "Train Epoch: 495 [22528/54000 (42%)] Loss: -679.156921\n",
      "Train Epoch: 495 [33792/54000 (63%)] Loss: -652.723755\n",
      "Train Epoch: 495 [45056/54000 (83%)] Loss: -675.593506\n",
      "    epoch          : 495\n",
      "    loss           : -674.3696012676887\n",
      "    ess            : 1.9601746448930704\n",
      "    log_marginal   : 674.401836467239\n",
      "    log_joint      : 882.410122853405\n",
      "    val_loss       : -677.7157491048177\n",
      "    val_ess        : 1.963318834702174\n",
      "    val_log_marginal: 677.7442677815756\n",
      "    val_log_joint  : 885.7606353759766\n",
      "Train Epoch: 496 [0/54000 (0%)] Loss: -681.391602\n",
      "Train Epoch: 496 [11264/54000 (21%)] Loss: -679.135864\n",
      "Train Epoch: 496 [22528/54000 (42%)] Loss: -663.447083\n",
      "Train Epoch: 496 [33792/54000 (63%)] Loss: -678.625610\n",
      "Train Epoch: 496 [45056/54000 (83%)] Loss: -669.870483\n",
      "    epoch          : 496\n",
      "    loss           : -674.7964679070238\n",
      "    ess            : 1.958936316787072\n",
      "    log_marginal   : 674.8315660008844\n",
      "    log_joint      : 882.8943999668337\n",
      "    val_loss       : -678.1547597249349\n",
      "    val_ess        : 1.9620885054270427\n",
      "    val_log_marginal: 678.1841227213541\n",
      "    val_log_joint  : 886.4875996907552\n",
      "Train Epoch: 497 [0/54000 (0%)] Loss: -693.185181\n",
      "Train Epoch: 497 [11264/54000 (21%)] Loss: -671.015503\n",
      "Train Epoch: 497 [22528/54000 (42%)] Loss: -690.869141\n",
      "Train Epoch: 497 [33792/54000 (63%)] Loss: -662.899170\n",
      "Train Epoch: 497 [45056/54000 (83%)] Loss: -683.932251\n",
      "    epoch          : 497\n",
      "    loss           : -675.097985033719\n",
      "    ess            : 1.9594364121275127\n",
      "    log_marginal   : 675.1324128924675\n",
      "    log_joint      : 883.1326196058741\n",
      "    val_loss       : -679.0106964111328\n",
      "    val_ess        : 1.9604120254516602\n",
      "    val_log_marginal: 679.047108968099\n",
      "    val_log_joint  : 886.8670501708984\n",
      "Train Epoch: 498 [0/54000 (0%)] Loss: -674.896912\n",
      "Train Epoch: 498 [11264/54000 (21%)] Loss: -678.944824\n",
      "Train Epoch: 498 [22528/54000 (42%)] Loss: -698.543762\n",
      "Train Epoch: 498 [33792/54000 (63%)] Loss: -670.127869\n",
      "Train Epoch: 498 [45056/54000 (83%)] Loss: -656.535645\n",
      "    epoch          : 498\n",
      "    loss           : -675.4143152776754\n",
      "    ess            : 1.959428127081889\n",
      "    log_marginal   : 675.4479479519827\n",
      "    log_joint      : 883.4600496112175\n",
      "    val_loss       : -678.7292836507162\n",
      "    val_ess        : 1.9617321987946827\n",
      "    val_log_marginal: 678.7592163085938\n",
      "    val_log_joint  : 886.8351440429688\n",
      "Train Epoch: 499 [0/54000 (0%)] Loss: -674.392700\n",
      "Train Epoch: 499 [11264/54000 (21%)] Loss: -643.995361\n",
      "Train Epoch: 499 [22528/54000 (42%)] Loss: -682.181458\n",
      "Train Epoch: 499 [33792/54000 (63%)] Loss: -696.487061\n",
      "Train Epoch: 499 [45056/54000 (83%)] Loss: -696.696411\n",
      "    epoch          : 499\n",
      "    loss           : -675.4450810270489\n",
      "    ess            : 1.9588836060380035\n",
      "    log_marginal   : 675.4797633908829\n",
      "    log_joint      : 883.5320428812279\n",
      "    val_loss       : -679.7145334879557\n",
      "    val_ess        : 1.9587639272212982\n",
      "    val_log_marginal: 679.7479451497396\n",
      "    val_log_joint  : 887.7878468831381\n",
      "Train Epoch: 500 [0/54000 (0%)] Loss: -675.731323\n",
      "Train Epoch: 500 [11264/54000 (21%)] Loss: -687.922058\n",
      "Train Epoch: 500 [22528/54000 (42%)] Loss: -680.581909\n",
      "Train Epoch: 500 [33792/54000 (63%)] Loss: -656.198730\n",
      "Train Epoch: 500 [45056/54000 (83%)] Loss: -685.874817\n",
      "    epoch          : 500\n",
      "    loss           : -675.8713407696418\n",
      "    ess            : 1.9600129599841136\n",
      "    log_marginal   : 675.9046774810215\n",
      "    log_joint      : 883.9908337862986\n",
      "    val_loss       : -680.3456471761068\n",
      "    val_ess        : 1.958566854397456\n",
      "    val_log_marginal: 680.37939453125\n",
      "    val_log_joint  : 888.1741841634115\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch500.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 501 [0/54000 (0%)] Loss: -648.520569\n",
      "Train Epoch: 501 [11264/54000 (21%)] Loss: -668.393555\n",
      "Train Epoch: 501 [22528/54000 (42%)] Loss: -668.356934\n",
      "Train Epoch: 501 [33792/54000 (63%)] Loss: -693.466797\n",
      "Train Epoch: 501 [45056/54000 (83%)] Loss: -677.679749\n",
      "    epoch          : 501\n",
      "    loss           : -676.0231657208137\n",
      "    ess            : 1.9598991668449257\n",
      "    log_marginal   : 676.0569365879275\n",
      "    log_joint      : 884.1524992169075\n",
      "    val_loss       : -679.9131215413412\n",
      "    val_ess        : 1.9561547835667927\n",
      "    val_log_marginal: 679.9501953125\n",
      "    val_log_joint  : 888.2195383707682\n",
      "Train Epoch: 502 [0/54000 (0%)] Loss: -656.864685\n",
      "Train Epoch: 502 [11264/54000 (21%)] Loss: -672.255859\n",
      "Train Epoch: 502 [22528/54000 (42%)] Loss: -668.685181\n",
      "Train Epoch: 502 [33792/54000 (63%)] Loss: -643.047729\n",
      "Train Epoch: 502 [45056/54000 (83%)] Loss: -684.166260\n",
      "    epoch          : 502\n",
      "    loss           : -676.4422837743219\n",
      "    ess            : 1.9587900076272353\n",
      "    log_marginal   : 676.477251736623\n",
      "    log_joint      : 884.464258157982\n",
      "    val_loss       : -681.0702972412109\n",
      "    val_ess        : 1.957576721906662\n",
      "    val_log_marginal: 681.1055297851562\n",
      "    val_log_joint  : 888.9238942464193\n",
      "Train Epoch: 503 [0/54000 (0%)] Loss: -685.003418\n",
      "Train Epoch: 503 [11264/54000 (21%)] Loss: -700.404785\n",
      "Train Epoch: 503 [22528/54000 (42%)] Loss: -676.808472\n",
      "Train Epoch: 503 [33792/54000 (63%)] Loss: -692.868042\n",
      "Train Epoch: 503 [45056/54000 (83%)] Loss: -662.992188\n",
      "    epoch          : 503\n",
      "    loss           : -676.818737677808\n",
      "    ess            : 1.9595466087449271\n",
      "    log_marginal   : 676.8531545962927\n",
      "    log_joint      : 884.8826714281765\n",
      "    val_loss       : -680.3870391845703\n",
      "    val_ess        : 1.9609789351622264\n",
      "    val_log_marginal: 680.4197591145834\n",
      "    val_log_joint  : 888.500742594401\n",
      "Train Epoch: 504 [0/54000 (0%)] Loss: -690.348511\n",
      "Train Epoch: 504 [11264/54000 (21%)] Loss: -648.753540\n",
      "Train Epoch: 504 [22528/54000 (42%)] Loss: -696.647705\n",
      "Train Epoch: 504 [33792/54000 (63%)] Loss: -676.522644\n",
      "Train Epoch: 504 [45056/54000 (83%)] Loss: -671.600952\n",
      "    epoch          : 504\n",
      "    loss           : -676.9629942696049\n",
      "    ess            : 1.9599137621105842\n",
      "    log_marginal   : 676.9964403836233\n",
      "    log_joint      : 885.1278957151017\n",
      "    val_loss       : -680.6773681640625\n",
      "    val_ess        : 1.9615642825762432\n",
      "    val_log_marginal: 680.7099863688151\n",
      "    val_log_joint  : 888.6559041341146\n",
      "Train Epoch: 505 [0/54000 (0%)] Loss: -664.022583\n",
      "Train Epoch: 505 [11264/54000 (21%)] Loss: -702.845825\n",
      "Train Epoch: 505 [22528/54000 (42%)] Loss: -684.410400\n",
      "Train Epoch: 505 [33792/54000 (63%)] Loss: -681.884094\n",
      "Train Epoch: 505 [45056/54000 (83%)] Loss: -673.510010\n",
      "    epoch          : 505\n",
      "    loss           : -677.2249047621241\n",
      "    ess            : 1.959493542617222\n",
      "    log_marginal   : 677.2586030780144\n",
      "    log_joint      : 885.3595402555645\n",
      "    val_loss       : -681.2992299397787\n",
      "    val_ess        : 1.958015153805415\n",
      "    val_log_marginal: 681.3368581136068\n",
      "    val_log_joint  : 889.0554809570312\n",
      "Train Epoch: 506 [0/54000 (0%)] Loss: -681.346313\n",
      "Train Epoch: 506 [11264/54000 (21%)] Loss: -675.522339\n",
      "Train Epoch: 506 [22528/54000 (42%)] Loss: -665.803833\n",
      "Train Epoch: 506 [33792/54000 (63%)] Loss: -697.347778\n",
      "Train Epoch: 506 [45056/54000 (83%)] Loss: -672.834351\n",
      "    epoch          : 506\n",
      "    loss           : -677.8505824826798\n",
      "    ess            : 1.9602324411554157\n",
      "    log_marginal   : 677.8840902076578\n",
      "    log_joint      : 885.9418162219929\n",
      "    val_loss       : -681.5083974202474\n",
      "    val_ess        : 1.9591939846674602\n",
      "    val_log_marginal: 681.5401865641276\n",
      "    val_log_joint  : 889.4437459309896\n",
      "Train Epoch: 507 [0/54000 (0%)] Loss: -670.334595\n",
      "Train Epoch: 507 [11264/54000 (21%)] Loss: -680.779419\n",
      "Train Epoch: 507 [22528/54000 (42%)] Loss: -671.824707\n",
      "Train Epoch: 507 [33792/54000 (63%)] Loss: -657.560181\n",
      "Train Epoch: 507 [45056/54000 (83%)] Loss: -661.004272\n",
      "    epoch          : 507\n",
      "    loss           : -677.8155736383402\n",
      "    ess            : 1.9593689869034965\n",
      "    log_marginal   : 677.8509055083653\n",
      "    log_joint      : 886.0430539688974\n",
      "    val_loss       : -682.3462880452474\n",
      "    val_ess        : 1.9612899521986644\n",
      "    val_log_marginal: 682.3807118733724\n",
      "    val_log_joint  : 890.2593587239584\n",
      "Train Epoch: 508 [0/54000 (0%)] Loss: -682.653931\n",
      "Train Epoch: 508 [11264/54000 (21%)] Loss: -661.159912\n",
      "Train Epoch: 508 [22528/54000 (42%)] Loss: -672.947998\n",
      "Train Epoch: 508 [33792/54000 (63%)] Loss: -679.568604\n",
      "Train Epoch: 508 [45056/54000 (83%)] Loss: -686.612061\n",
      "    epoch          : 508\n",
      "    loss           : -678.1824922381707\n",
      "    ess            : 1.9599222462132293\n",
      "    log_marginal   : 678.2163730837265\n",
      "    log_joint      : 886.2351385152565\n",
      "    val_loss       : -682.6546986897787\n",
      "    val_ess        : 1.956484983364741\n",
      "    val_log_marginal: 682.6951497395834\n",
      "    val_log_joint  : 890.7482554117838\n",
      "Train Epoch: 509 [0/54000 (0%)] Loss: -678.267212\n",
      "Train Epoch: 509 [11264/54000 (21%)] Loss: -684.828125\n",
      "Train Epoch: 509 [22528/54000 (42%)] Loss: -693.800598\n",
      "Train Epoch: 509 [33792/54000 (63%)] Loss: -668.869080\n",
      "Train Epoch: 509 [45056/54000 (83%)] Loss: -689.569580\n",
      "    epoch          : 509\n",
      "    loss           : -678.5875641444944\n",
      "    ess            : 1.9598287051578738\n",
      "    log_marginal   : 678.6219672436985\n",
      "    log_joint      : 886.7669194059552\n",
      "    val_loss       : -681.4800872802734\n",
      "    val_ess        : 1.958355963230133\n",
      "    val_log_marginal: 681.5170644124349\n",
      "    val_log_joint  : 889.6460622151693\n",
      "Train Epoch: 510 [0/54000 (0%)] Loss: -681.525146\n",
      "Train Epoch: 510 [11264/54000 (21%)] Loss: -673.190125\n",
      "Train Epoch: 510 [22528/54000 (42%)] Loss: -683.857422\n",
      "Train Epoch: 510 [33792/54000 (63%)] Loss: -678.357666\n",
      "Train Epoch: 510 [45056/54000 (83%)] Loss: -677.437866\n",
      "    epoch          : 510\n",
      "    loss           : -678.6672081137604\n",
      "    ess            : 1.9609023478795897\n",
      "    log_marginal   : 678.6987874732828\n",
      "    log_joint      : 886.7951216787662\n",
      "    val_loss       : -682.5169372558594\n",
      "    val_ess        : 1.9581304291884105\n",
      "    val_log_marginal: 682.5530242919922\n",
      "    val_log_joint  : 890.7675323486328\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch510.pth ...\n",
      "Train Epoch: 511 [0/54000 (0%)] Loss: -686.159668\n",
      "Train Epoch: 511 [11264/54000 (21%)] Loss: -681.313416\n",
      "Train Epoch: 511 [22528/54000 (42%)] Loss: -685.058105\n",
      "Train Epoch: 511 [33792/54000 (63%)] Loss: -662.026245\n",
      "Train Epoch: 511 [45056/54000 (83%)] Loss: -672.052368\n",
      "    epoch          : 511\n",
      "    loss           : -678.7562658921728\n",
      "    ess            : 1.9592722609358013\n",
      "    log_marginal   : 678.7902060454746\n",
      "    log_joint      : 886.8607390781618\n",
      "    val_loss       : -682.9620920817057\n",
      "    val_ess        : 1.959829439719518\n",
      "    val_log_marginal: 682.9972025553385\n",
      "    val_log_joint  : 890.9168548583984\n",
      "Train Epoch: 512 [0/54000 (0%)] Loss: -675.955261\n",
      "Train Epoch: 512 [11264/54000 (21%)] Loss: -675.776550\n",
      "Train Epoch: 512 [22528/54000 (42%)] Loss: -677.835999\n",
      "Train Epoch: 512 [33792/54000 (63%)] Loss: -672.604492\n",
      "Train Epoch: 512 [45056/54000 (83%)] Loss: -695.648743\n",
      "    epoch          : 512\n",
      "    loss           : -679.2386215497862\n",
      "    ess            : 1.9601573460506942\n",
      "    log_marginal   : 679.2722191000885\n",
      "    log_joint      : 887.3152794028229\n",
      "    val_loss       : -683.5288950602213\n",
      "    val_ess        : 1.9625833829243977\n",
      "    val_log_marginal: 683.5594940185547\n",
      "    val_log_joint  : 891.5079701741537\n",
      "Train Epoch: 513 [0/54000 (0%)] Loss: -669.037231\n",
      "Train Epoch: 513 [11264/54000 (21%)] Loss: -681.182007\n",
      "Train Epoch: 513 [22528/54000 (42%)] Loss: -677.999634\n",
      "Train Epoch: 513 [33792/54000 (63%)] Loss: -658.208008\n",
      "Train Epoch: 513 [45056/54000 (83%)] Loss: -688.105469\n",
      "    epoch          : 513\n",
      "    loss           : -679.6676439969045\n",
      "    ess            : 1.9598160768454929\n",
      "    log_marginal   : 679.7014885668484\n",
      "    log_joint      : 887.7289509323408\n",
      "    val_loss       : -683.9195200602213\n",
      "    val_ess        : 1.95928959051768\n",
      "    val_log_marginal: 683.9538523356119\n",
      "    val_log_joint  : 892.0420583089193\n",
      "Train Epoch: 514 [0/54000 (0%)] Loss: -661.419678\n",
      "Train Epoch: 514 [11264/54000 (21%)] Loss: -679.044189\n",
      "Train Epoch: 514 [22528/54000 (42%)] Loss: -697.017334\n",
      "Train Epoch: 514 [33792/54000 (63%)] Loss: -677.331665\n",
      "Train Epoch: 514 [45056/54000 (83%)] Loss: -660.571655\n",
      "    epoch          : 514\n",
      "    loss           : -679.7570760475015\n",
      "    ess            : 1.9588302902455599\n",
      "    log_marginal   : 679.7917227115271\n",
      "    log_joint      : 887.8702743818175\n",
      "    val_loss       : -682.9514363606771\n",
      "    val_ess        : 1.958470235268275\n",
      "    val_log_marginal: 682.9863637288412\n",
      "    val_log_joint  : 891.1348876953125\n",
      "Train Epoch: 515 [0/54000 (0%)] Loss: -692.485962\n",
      "Train Epoch: 515 [11264/54000 (21%)] Loss: -682.314392\n",
      "Train Epoch: 515 [22528/54000 (42%)] Loss: -662.169067\n",
      "Train Epoch: 515 [33792/54000 (63%)] Loss: -689.160889\n",
      "Train Epoch: 515 [45056/54000 (83%)] Loss: -664.101440\n",
      "    epoch          : 515\n",
      "    loss           : -680.0479747844192\n",
      "    ess            : 1.9596832810707812\n",
      "    log_marginal   : 680.0820047630453\n",
      "    log_joint      : 888.0181032576651\n",
      "    val_loss       : -684.0154673258463\n",
      "    val_ess        : 1.9585512677828472\n",
      "    val_log_marginal: 684.0489705403646\n",
      "    val_log_joint  : 891.9339447021484\n",
      "Train Epoch: 516 [0/54000 (0%)] Loss: -675.199768\n",
      "Train Epoch: 516 [11264/54000 (21%)] Loss: -690.511353\n",
      "Train Epoch: 516 [22528/54000 (42%)] Loss: -663.303528\n",
      "Train Epoch: 516 [33792/54000 (63%)] Loss: -687.177368\n",
      "Train Epoch: 516 [45056/54000 (83%)] Loss: -679.926025\n",
      "    epoch          : 516\n",
      "    loss           : -680.1312261617409\n",
      "    ess            : 1.9596642694383297\n",
      "    log_marginal   : 680.1646935804835\n",
      "    log_joint      : 888.2948280190521\n",
      "    val_loss       : -683.6197458902994\n",
      "    val_ess        : 1.9579603274663289\n",
      "    val_log_marginal: 683.6506398518881\n",
      "    val_log_joint  : 891.6878000895182\n",
      "Train Epoch: 517 [0/54000 (0%)] Loss: -668.711182\n",
      "Train Epoch: 517 [11264/54000 (21%)] Loss: -674.371704\n",
      "Train Epoch: 517 [22528/54000 (42%)] Loss: -671.083008\n",
      "Train Epoch: 517 [33792/54000 (63%)] Loss: -672.545776\n",
      "Train Epoch: 517 [45056/54000 (83%)] Loss: -680.127747\n",
      "    epoch          : 517\n",
      "    loss           : -680.4374919387529\n",
      "    ess            : 1.9589484862561495\n",
      "    log_marginal   : 680.4727380140772\n",
      "    log_joint      : 888.671993039689\n",
      "    val_loss       : -684.3061879475912\n",
      "    val_ess        : 1.9600456257661183\n",
      "    val_log_marginal: 684.3435821533203\n",
      "    val_log_joint  : 892.1130574544271\n",
      "Train Epoch: 518 [0/54000 (0%)] Loss: -667.278076\n",
      "Train Epoch: 518 [11264/54000 (21%)] Loss: -668.459961\n",
      "Train Epoch: 518 [22528/54000 (42%)] Loss: -679.517944\n",
      "Train Epoch: 518 [33792/54000 (63%)] Loss: -678.504028\n",
      "Train Epoch: 518 [45056/54000 (83%)] Loss: -697.202148\n",
      "    epoch          : 518\n",
      "    loss           : -680.8349206312647\n",
      "    ess            : 1.9593979030285242\n",
      "    log_marginal   : 680.8694112525797\n",
      "    log_joint      : 888.9516279112618\n",
      "    val_loss       : -684.5064290364584\n",
      "    val_ess        : 1.9584594070911407\n",
      "    val_log_marginal: 684.5400899251302\n",
      "    val_log_joint  : 892.5630645751953\n",
      "Train Epoch: 519 [0/54000 (0%)] Loss: -696.664551\n",
      "Train Epoch: 519 [11264/54000 (21%)] Loss: -691.844971\n",
      "Train Epoch: 519 [22528/54000 (42%)] Loss: -671.415527\n",
      "Train Epoch: 519 [33792/54000 (63%)] Loss: -681.626099\n",
      "Train Epoch: 519 [45056/54000 (83%)] Loss: -668.263672\n",
      "    epoch          : 519\n",
      "    loss           : -681.1388924076872\n",
      "    ess            : 1.9588924084069594\n",
      "    log_marginal   : 681.173437154518\n",
      "    log_joint      : 889.2904663085938\n",
      "    val_loss       : -685.7137654622396\n",
      "    val_ess        : 1.9568465451399486\n",
      "    val_log_marginal: 685.7527567545573\n",
      "    val_log_joint  : 893.7501932779948\n",
      "Train Epoch: 520 [0/54000 (0%)] Loss: -681.134460\n",
      "Train Epoch: 520 [11264/54000 (21%)] Loss: -681.995605\n",
      "Train Epoch: 520 [22528/54000 (42%)] Loss: -703.293030\n",
      "Train Epoch: 520 [33792/54000 (63%)] Loss: -684.876953\n",
      "Train Epoch: 520 [45056/54000 (83%)] Loss: -685.576111\n",
      "    epoch          : 520\n",
      "    loss           : -681.298793000995\n",
      "    ess            : 1.9608598362724736\n",
      "    log_marginal   : 681.3313299215065\n",
      "    log_joint      : 889.4044114598688\n",
      "    val_loss       : -684.9492238362631\n",
      "    val_ess        : 1.9600733816623688\n",
      "    val_log_marginal: 684.9820607503256\n",
      "    val_log_joint  : 893.3201904296875\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch520.pth ...\n",
      "Train Epoch: 521 [0/54000 (0%)] Loss: -667.131226\n",
      "Train Epoch: 521 [11264/54000 (21%)] Loss: -666.300415\n",
      "Train Epoch: 521 [22528/54000 (42%)] Loss: -683.153564\n",
      "Train Epoch: 521 [33792/54000 (63%)] Loss: -680.548279\n",
      "Train Epoch: 521 [45056/54000 (83%)] Loss: -681.268433\n",
      "    epoch          : 521\n",
      "    loss           : -681.6364642449145\n",
      "    ess            : 1.960094598104369\n",
      "    log_marginal   : 681.669859688237\n",
      "    log_joint      : 889.8136095730764\n",
      "    val_loss       : -685.3152364095052\n",
      "    val_ess        : 1.9594186941782634\n",
      "    val_log_marginal: 685.3481750488281\n",
      "    val_log_joint  : 893.374745686849\n",
      "Train Epoch: 522 [0/54000 (0%)] Loss: -680.734253\n",
      "Train Epoch: 522 [11264/54000 (21%)] Loss: -681.836304\n",
      "Train Epoch: 522 [22528/54000 (42%)] Loss: -667.298828\n",
      "Train Epoch: 522 [33792/54000 (63%)] Loss: -706.315308\n",
      "Train Epoch: 522 [45056/54000 (83%)] Loss: -663.395630\n",
      "    epoch          : 522\n",
      "    loss           : -682.1820598098467\n",
      "    ess            : 1.9603538355737362\n",
      "    log_marginal   : 682.2141493311468\n",
      "    log_joint      : 890.2632636304172\n",
      "    val_loss       : -686.2882741292318\n",
      "    val_ess        : 1.960493226846059\n",
      "    val_log_marginal: 686.3242340087891\n",
      "    val_log_joint  : 894.2139180501302\n",
      "Train Epoch: 523 [0/54000 (0%)] Loss: -701.551819\n",
      "Train Epoch: 523 [11264/54000 (21%)] Loss: -691.331909\n",
      "Train Epoch: 523 [22528/54000 (42%)] Loss: -698.332520\n",
      "Train Epoch: 523 [33792/54000 (63%)] Loss: -672.266113\n",
      "Train Epoch: 523 [45056/54000 (83%)] Loss: -693.137939\n",
      "    epoch          : 523\n",
      "    loss           : -681.9014927126327\n",
      "    ess            : 1.9601173074740283\n",
      "    log_marginal   : 681.9350545631265\n",
      "    log_joint      : 890.1461331349499\n",
      "    val_loss       : -685.9445088704427\n",
      "    val_ess        : 1.965034951766332\n",
      "    val_log_marginal: 685.9720052083334\n",
      "    val_log_joint  : 894.1952667236328\n",
      "Train Epoch: 524 [0/54000 (0%)] Loss: -689.446045\n",
      "Train Epoch: 524 [11264/54000 (21%)] Loss: -693.841003\n",
      "Train Epoch: 524 [22528/54000 (42%)] Loss: -678.028809\n",
      "Train Epoch: 524 [33792/54000 (63%)] Loss: -686.668335\n",
      "Train Epoch: 524 [45056/54000 (83%)] Loss: -681.592285\n",
      "    epoch          : 524\n",
      "    loss           : -682.4142484844856\n",
      "    ess            : 1.959997093902444\n",
      "    log_marginal   : 682.4488876630675\n",
      "    log_joint      : 890.5415528495357\n",
      "    val_loss       : -686.3394521077474\n",
      "    val_ess        : 1.9564720590909321\n",
      "    val_log_marginal: 686.3794555664062\n",
      "    val_log_joint  : 894.4043680826823\n",
      "Train Epoch: 525 [0/54000 (0%)] Loss: -694.749939\n",
      "Train Epoch: 525 [11264/54000 (21%)] Loss: -695.236084\n",
      "Train Epoch: 525 [22528/54000 (42%)] Loss: -681.347595\n",
      "Train Epoch: 525 [33792/54000 (63%)] Loss: -671.501099\n",
      "Train Epoch: 525 [45056/54000 (83%)] Loss: -670.407959\n",
      "    epoch          : 525\n",
      "    loss           : -682.7834069593897\n",
      "    ess            : 1.9603418651616797\n",
      "    log_marginal   : 682.8164275547243\n",
      "    log_joint      : 890.9448230671433\n",
      "    val_loss       : -686.2409057617188\n",
      "    val_ess        : 1.9570005238056183\n",
      "    val_log_marginal: 686.2771708170573\n",
      "    val_log_joint  : 894.7656453450521\n",
      "Train Epoch: 526 [0/54000 (0%)] Loss: -681.529968\n",
      "Train Epoch: 526 [11264/54000 (21%)] Loss: -679.505920\n",
      "Train Epoch: 526 [22528/54000 (42%)] Loss: -678.447937\n",
      "Train Epoch: 526 [33792/54000 (63%)] Loss: -691.341431\n",
      "Train Epoch: 526 [45056/54000 (83%)] Loss: -695.771423\n",
      "    epoch          : 526\n",
      "    loss           : -682.8716827968382\n",
      "    ess            : 1.9593769941689834\n",
      "    log_marginal   : 682.9066484559257\n",
      "    log_joint      : 891.1003803757002\n",
      "    val_loss       : -686.4152272542318\n",
      "    val_ess        : 1.960351179043452\n",
      "    val_log_marginal: 686.4476420084635\n",
      "    val_log_joint  : 894.6090901692709\n",
      "Train Epoch: 527 [0/54000 (0%)] Loss: -676.221497\n",
      "Train Epoch: 527 [11264/54000 (21%)] Loss: -667.608032\n",
      "Train Epoch: 527 [22528/54000 (42%)] Loss: -698.163330\n",
      "Train Epoch: 527 [33792/54000 (63%)] Loss: -680.549927\n",
      "Train Epoch: 527 [45056/54000 (83%)] Loss: -687.196045\n",
      "    epoch          : 527\n",
      "    loss           : -683.1713590801887\n",
      "    ess            : 1.9598669769628994\n",
      "    log_marginal   : 683.2041533848025\n",
      "    log_joint      : 891.2553037247568\n",
      "    val_loss       : -687.738271077474\n",
      "    val_ess        : 1.9589279095331829\n",
      "    val_log_marginal: 687.7755025227865\n",
      "    val_log_joint  : 895.9670766194662\n",
      "Train Epoch: 528 [0/54000 (0%)] Loss: -686.523926\n",
      "Train Epoch: 528 [11264/54000 (21%)] Loss: -647.063293\n",
      "Train Epoch: 528 [22528/54000 (42%)] Loss: -677.763428\n",
      "Train Epoch: 528 [33792/54000 (63%)] Loss: -665.035522\n",
      "Train Epoch: 528 [45056/54000 (83%)] Loss: -680.579346\n",
      "    epoch          : 528\n",
      "    loss           : -683.4579283516362\n",
      "    ess            : 1.9591562196893513\n",
      "    log_marginal   : 683.4918852032356\n",
      "    log_joint      : 891.625430700914\n",
      "    val_loss       : -687.8848978678385\n",
      "    val_ess        : 1.9605785608291626\n",
      "    val_log_marginal: 687.920420328776\n",
      "    val_log_joint  : 896.2210184733073\n",
      "Train Epoch: 529 [0/54000 (0%)] Loss: -671.963501\n",
      "Train Epoch: 529 [11264/54000 (21%)] Loss: -686.207886\n",
      "Train Epoch: 529 [22528/54000 (42%)] Loss: -667.763916\n",
      "Train Epoch: 529 [33792/54000 (63%)] Loss: -674.901367\n",
      "Train Epoch: 529 [45056/54000 (83%)] Loss: -692.695068\n",
      "    epoch          : 529\n",
      "    loss           : -683.8572284050707\n",
      "    ess            : 1.9587102757309967\n",
      "    log_marginal   : 683.8917190263857\n",
      "    log_joint      : 891.9890309459759\n",
      "    val_loss       : -687.9128468831381\n",
      "    val_ess        : 1.9615272879600525\n",
      "    val_log_marginal: 687.9458669026693\n",
      "    val_log_joint  : 896.1371815999349\n",
      "Train Epoch: 530 [0/54000 (0%)] Loss: -676.598633\n",
      "Train Epoch: 530 [11264/54000 (21%)] Loss: -672.172974\n",
      "Train Epoch: 530 [22528/54000 (42%)] Loss: -679.824707\n",
      "Train Epoch: 530 [33792/54000 (63%)] Loss: -682.629089\n",
      "Train Epoch: 530 [45056/54000 (83%)] Loss: -701.695435\n",
      "    epoch          : 530\n",
      "    loss           : -683.8826057865934\n",
      "    ess            : 1.9607817834278323\n",
      "    log_marginal   : 683.9155394356205\n",
      "    log_joint      : 892.0275297344856\n",
      "    val_loss       : -687.8016153971354\n",
      "    val_ess        : 1.9589024186134338\n",
      "    val_log_marginal: 687.8374532063802\n",
      "    val_log_joint  : 896.0518493652344\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch530.pth ...\n",
      "Train Epoch: 531 [0/54000 (0%)] Loss: -675.672852\n",
      "Train Epoch: 531 [11264/54000 (21%)] Loss: -705.735229\n",
      "Train Epoch: 531 [22528/54000 (42%)] Loss: -686.168335\n",
      "Train Epoch: 531 [33792/54000 (63%)] Loss: -669.288574\n",
      "Train Epoch: 531 [45056/54000 (83%)] Loss: -664.874390\n",
      "    epoch          : 531\n",
      "    loss           : -684.3916021383034\n",
      "    ess            : 1.9584309076363187\n",
      "    log_marginal   : 684.4281414679762\n",
      "    log_joint      : 892.5407116008255\n",
      "    val_loss       : -688.9712270100912\n",
      "    val_ess        : 1.9609568615754445\n",
      "    val_log_marginal: 689.0036214192709\n",
      "    val_log_joint  : 897.0670827229818\n",
      "Train Epoch: 532 [0/54000 (0%)] Loss: -704.374512\n",
      "Train Epoch: 532 [11264/54000 (21%)] Loss: -672.096619\n",
      "Train Epoch: 532 [22528/54000 (42%)] Loss: -674.546692\n",
      "Train Epoch: 532 [33792/54000 (63%)] Loss: -713.430420\n",
      "Train Epoch: 532 [45056/54000 (83%)] Loss: -691.621826\n",
      "    epoch          : 532\n",
      "    loss           : -684.4541706589033\n",
      "    ess            : 1.9596918731365565\n",
      "    log_marginal   : 684.4877831800928\n",
      "    log_joint      : 892.6088654140257\n",
      "    val_loss       : -689.4288024902344\n",
      "    val_ess        : 1.961552808682124\n",
      "    val_log_marginal: 689.4649149576823\n",
      "    val_log_joint  : 897.0094197591146\n",
      "Train Epoch: 533 [0/54000 (0%)] Loss: -705.990906\n",
      "Train Epoch: 533 [11264/54000 (21%)] Loss: -704.009888\n",
      "Train Epoch: 533 [22528/54000 (42%)] Loss: -700.529297\n",
      "Train Epoch: 533 [33792/54000 (63%)] Loss: -693.259583\n",
      "Train Epoch: 533 [45056/54000 (83%)] Loss: -690.992126\n",
      "    epoch          : 533\n",
      "    loss           : -684.6315123360112\n",
      "    ess            : 1.9604383909477379\n",
      "    log_marginal   : 684.6648104685657\n",
      "    log_joint      : 892.7634041264372\n",
      "    val_loss       : -689.0042978922526\n",
      "    val_ess        : 1.9594100614388783\n",
      "    val_log_marginal: 689.0350392659506\n",
      "    val_log_joint  : 897.1946360270182\n",
      "Train Epoch: 534 [0/54000 (0%)] Loss: -726.341492\n",
      "Train Epoch: 534 [11264/54000 (21%)] Loss: -692.441528\n",
      "Train Epoch: 534 [22528/54000 (42%)] Loss: -689.837646\n",
      "Train Epoch: 534 [33792/54000 (63%)] Loss: -677.081848\n",
      "Train Epoch: 534 [45056/54000 (83%)] Loss: -684.460938\n",
      "    epoch          : 534\n",
      "    loss           : -684.921547943691\n",
      "    ess            : 1.9585464945379294\n",
      "    log_marginal   : 684.9567226193985\n",
      "    log_joint      : 893.0970539596846\n",
      "    val_loss       : -689.5006357828776\n",
      "    val_ess        : 1.9594735602537792\n",
      "    val_log_marginal: 689.5322062174479\n",
      "    val_log_joint  : 897.3839772542318\n",
      "Train Epoch: 535 [0/54000 (0%)] Loss: -717.879761\n",
      "Train Epoch: 535 [11264/54000 (21%)] Loss: -687.485352\n",
      "Train Epoch: 535 [22528/54000 (42%)] Loss: -692.061646\n",
      "Train Epoch: 535 [33792/54000 (63%)] Loss: -689.455322\n",
      "Train Epoch: 535 [45056/54000 (83%)] Loss: -683.367920\n",
      "    epoch          : 535\n",
      "    loss           : -685.3737574163473\n",
      "    ess            : 1.958519771413983\n",
      "    log_marginal   : 685.4086269162735\n",
      "    log_joint      : 893.5284504440596\n",
      "    val_loss       : -689.7043100992838\n",
      "    val_ess        : 1.9613967736562092\n",
      "    val_log_marginal: 689.7358856201172\n",
      "    val_log_joint  : 898.0653584798177\n",
      "Train Epoch: 536 [0/54000 (0%)] Loss: -682.746216\n",
      "Train Epoch: 536 [11264/54000 (21%)] Loss: -675.700317\n",
      "Train Epoch: 536 [22528/54000 (42%)] Loss: -681.123901\n",
      "Train Epoch: 536 [33792/54000 (63%)] Loss: -674.880981\n",
      "Train Epoch: 536 [45056/54000 (83%)] Loss: -665.443115\n",
      "    epoch          : 536\n",
      "    loss           : -685.7192929825693\n",
      "    ess            : 1.958079438164549\n",
      "    log_marginal   : 685.7556307810657\n",
      "    log_joint      : 893.8559178766214\n",
      "    val_loss       : -690.1258392333984\n",
      "    val_ess        : 1.9601256946722667\n",
      "    val_log_marginal: 690.1584116617838\n",
      "    val_log_joint  : 898.2724202473959\n",
      "Train Epoch: 537 [0/54000 (0%)] Loss: -673.162476\n",
      "Train Epoch: 537 [11264/54000 (21%)] Loss: -678.255920\n",
      "Train Epoch: 537 [22528/54000 (42%)] Loss: -686.144653\n",
      "Train Epoch: 537 [33792/54000 (63%)] Loss: -680.658569\n",
      "Train Epoch: 537 [45056/54000 (83%)] Loss: -677.913086\n",
      "    epoch          : 537\n",
      "    loss           : -685.9447176951282\n",
      "    ess            : 1.9586354010509994\n",
      "    log_marginal   : 685.9811061643204\n",
      "    log_joint      : 894.0212655697229\n",
      "    val_loss       : -690.2877756754557\n",
      "    val_ess        : 1.9641981224219005\n",
      "    val_log_marginal: 690.3174235026041\n",
      "    val_log_joint  : 898.4882049560547\n",
      "Train Epoch: 538 [0/54000 (0%)] Loss: -699.837402\n",
      "Train Epoch: 538 [11264/54000 (21%)] Loss: -698.395996\n",
      "Train Epoch: 538 [22528/54000 (42%)] Loss: -679.064514\n",
      "Train Epoch: 538 [33792/54000 (63%)] Loss: -675.882812\n",
      "Train Epoch: 538 [45056/54000 (83%)] Loss: -701.155151\n",
      "    epoch          : 538\n",
      "    loss           : -686.0454654333727\n",
      "    ess            : 1.960047739856648\n",
      "    log_marginal   : 686.0796364838222\n",
      "    log_joint      : 894.1939939103037\n",
      "    val_loss       : -690.5249481201172\n",
      "    val_ess        : 1.959545244773229\n",
      "    val_log_marginal: 690.5578206380209\n",
      "    val_log_joint  : 898.9459686279297\n",
      "Train Epoch: 539 [0/54000 (0%)] Loss: -695.329956\n",
      "Train Epoch: 539 [11264/54000 (21%)] Loss: -693.023682\n",
      "Train Epoch: 539 [22528/54000 (42%)] Loss: -704.077576\n",
      "Train Epoch: 539 [33792/54000 (63%)] Loss: -684.109009\n",
      "Train Epoch: 539 [45056/54000 (83%)] Loss: -673.551453\n",
      "    epoch          : 539\n",
      "    loss           : -686.1497036915905\n",
      "    ess            : 1.960245539557259\n",
      "    log_marginal   : 686.1831624732828\n",
      "    log_joint      : 894.3240897700472\n",
      "    val_loss       : -690.0775400797526\n",
      "    val_ess        : 1.9585777421792347\n",
      "    val_log_marginal: 690.111806233724\n",
      "    val_log_joint  : 898.0422414143881\n",
      "Train Epoch: 540 [0/54000 (0%)] Loss: -697.752319\n",
      "Train Epoch: 540 [11264/54000 (21%)] Loss: -688.270142\n",
      "Train Epoch: 540 [22528/54000 (42%)] Loss: -680.385498\n",
      "Train Epoch: 540 [33792/54000 (63%)] Loss: -692.896362\n",
      "Train Epoch: 540 [45056/54000 (83%)] Loss: -690.342834\n",
      "    epoch          : 540\n",
      "    loss           : -686.5289467865566\n",
      "    ess            : 1.960400124765792\n",
      "    log_marginal   : 686.5615723807857\n",
      "    log_joint      : 894.6679146244841\n",
      "    val_loss       : -690.104726155599\n",
      "    val_ess        : 1.9584973752498627\n",
      "    val_log_marginal: 690.1384531656901\n",
      "    val_log_joint  : 898.3876495361328\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch540.pth ...\n",
      "Train Epoch: 541 [0/54000 (0%)] Loss: -669.737915\n",
      "Train Epoch: 541 [11264/54000 (21%)] Loss: -689.981201\n",
      "Train Epoch: 541 [22528/54000 (42%)] Loss: -681.421631\n",
      "Train Epoch: 541 [33792/54000 (63%)] Loss: -680.443970\n",
      "Train Epoch: 541 [45056/54000 (83%)] Loss: -679.673950\n",
      "    epoch          : 541\n",
      "    loss           : -686.7395255610628\n",
      "    ess            : 1.9592699419777349\n",
      "    log_marginal   : 686.774240169885\n",
      "    log_joint      : 894.9324617205925\n",
      "    val_loss       : -692.0179036458334\n",
      "    val_ess        : 1.958951900402705\n",
      "    val_log_marginal: 692.0535990397135\n",
      "    val_log_joint  : 899.8840281168619\n",
      "Train Epoch: 542 [0/54000 (0%)] Loss: -671.298950\n",
      "Train Epoch: 542 [11264/54000 (21%)] Loss: -692.252686\n",
      "Train Epoch: 542 [22528/54000 (42%)] Loss: -685.245483\n",
      "Train Epoch: 542 [33792/54000 (63%)] Loss: -697.190063\n",
      "Train Epoch: 542 [45056/54000 (83%)] Loss: -700.712646\n",
      "    epoch          : 542\n",
      "    loss           : -687.1151071224573\n",
      "    ess            : 1.9602297195848428\n",
      "    log_marginal   : 687.1496628095518\n",
      "    log_joint      : 895.3231546653891\n",
      "    val_loss       : -691.427988688151\n",
      "    val_ess        : 1.9596269925435383\n",
      "    val_log_marginal: 691.4624074300131\n",
      "    val_log_joint  : 899.6593933105469\n",
      "Train Epoch: 543 [0/54000 (0%)] Loss: -671.309509\n",
      "Train Epoch: 543 [11264/54000 (21%)] Loss: -692.949158\n",
      "Train Epoch: 543 [22528/54000 (42%)] Loss: -694.850342\n",
      "Train Epoch: 543 [33792/54000 (63%)] Loss: -707.837158\n",
      "Train Epoch: 543 [45056/54000 (83%)] Loss: -686.656982\n",
      "    epoch          : 543\n",
      "    loss           : -687.3756328078936\n",
      "    ess            : 1.9603910547382426\n",
      "    log_marginal   : 687.4079008282356\n",
      "    log_joint      : 895.4861075923128\n",
      "    val_loss       : -690.8881225585938\n",
      "    val_ess        : 1.9589235285917919\n",
      "    val_log_marginal: 690.9213205973307\n",
      "    val_log_joint  : 899.2109680175781\n",
      "Train Epoch: 544 [0/54000 (0%)] Loss: -682.472229\n",
      "Train Epoch: 544 [11264/54000 (21%)] Loss: -694.585449\n",
      "Train Epoch: 544 [22528/54000 (42%)] Loss: -699.249878\n",
      "Train Epoch: 544 [33792/54000 (63%)] Loss: -713.353638\n",
      "Train Epoch: 544 [45056/54000 (83%)] Loss: -660.620483\n",
      "    epoch          : 544\n",
      "    loss           : -687.5386398603331\n",
      "    ess            : 1.9605380600353457\n",
      "    log_marginal   : 687.5724562159124\n",
      "    log_joint      : 895.7396165379938\n",
      "    val_loss       : -692.0199635823568\n",
      "    val_ess        : 1.9619839489459991\n",
      "    val_log_marginal: 692.0501963297526\n",
      "    val_log_joint  : 899.8917490641276\n",
      "Train Epoch: 545 [0/54000 (0%)] Loss: -690.618774\n",
      "Train Epoch: 545 [11264/54000 (21%)] Loss: -698.318237\n",
      "Train Epoch: 545 [22528/54000 (42%)] Loss: -675.419189\n",
      "Train Epoch: 545 [33792/54000 (63%)] Loss: -666.265625\n",
      "Train Epoch: 545 [45056/54000 (83%)] Loss: -695.457520\n",
      "    epoch          : 545\n",
      "    loss           : -687.7832584021227\n",
      "    ess            : 1.958995153319161\n",
      "    log_marginal   : 687.8171363686615\n",
      "    log_joint      : 895.9572874824955\n",
      "    val_loss       : -691.5968882242838\n",
      "    val_ess        : 1.962686449289322\n",
      "    val_log_marginal: 691.6270853678385\n",
      "    val_log_joint  : 899.9561818440756\n",
      "Train Epoch: 546 [0/54000 (0%)] Loss: -694.078308\n",
      "Train Epoch: 546 [11264/54000 (21%)] Loss: -679.050171\n",
      "Train Epoch: 546 [22528/54000 (42%)] Loss: -678.414368\n",
      "Train Epoch: 546 [33792/54000 (63%)] Loss: -668.484131\n",
      "Train Epoch: 546 [45056/54000 (83%)] Loss: -698.792542\n",
      "    epoch          : 546\n",
      "    loss           : -688.0177474111881\n",
      "    ess            : 1.9583981903094165\n",
      "    log_marginal   : 688.054387506449\n",
      "    log_joint      : 896.1691261147553\n",
      "    val_loss       : -691.6493886311849\n",
      "    val_ess        : 1.9625581403573353\n",
      "    val_log_marginal: 691.6782989501953\n",
      "    val_log_joint  : 899.703369140625\n",
      "Train Epoch: 547 [0/54000 (0%)] Loss: -698.938965\n",
      "Train Epoch: 547 [11264/54000 (21%)] Loss: -693.026489\n",
      "Train Epoch: 547 [22528/54000 (42%)] Loss: -678.090759\n",
      "Train Epoch: 547 [33792/54000 (63%)] Loss: -703.143738\n",
      "Train Epoch: 547 [45056/54000 (83%)] Loss: -685.440369\n",
      "    epoch          : 547\n",
      "    loss           : -688.2801317898733\n",
      "    ess            : 1.9600012009998538\n",
      "    log_marginal   : 688.3134109209169\n",
      "    log_joint      : 896.3684974526459\n",
      "    val_loss       : -691.5020497639974\n",
      "    val_ess        : 1.9652785658836365\n",
      "    val_log_marginal: 691.5291392008463\n",
      "    val_log_joint  : 899.6912536621094\n",
      "Train Epoch: 548 [0/54000 (0%)] Loss: -664.794861\n",
      "Train Epoch: 548 [11264/54000 (21%)] Loss: -692.461975\n",
      "Train Epoch: 548 [22528/54000 (42%)] Loss: -689.271179\n",
      "Train Epoch: 548 [33792/54000 (63%)] Loss: -676.229065\n",
      "Train Epoch: 548 [45056/54000 (83%)] Loss: -704.202881\n",
      "    epoch          : 548\n",
      "    loss           : -688.4602661132812\n",
      "    ess            : 1.960890823940061\n",
      "    log_marginal   : 688.4923089945091\n",
      "    log_joint      : 896.6556154646963\n",
      "    val_loss       : -692.1500905354818\n",
      "    val_ess        : 1.9606404999891918\n",
      "    val_log_marginal: 692.1829732259115\n",
      "    val_log_joint  : 900.2332255045573\n",
      "Train Epoch: 549 [0/54000 (0%)] Loss: -705.635803\n",
      "Train Epoch: 549 [11264/54000 (21%)] Loss: -698.782043\n",
      "Train Epoch: 549 [22528/54000 (42%)] Loss: -707.010742\n",
      "Train Epoch: 549 [33792/54000 (63%)] Loss: -688.246094\n",
      "Train Epoch: 549 [45056/54000 (83%)] Loss: -674.713623\n",
      "    epoch          : 549\n",
      "    loss           : -688.7825346172981\n",
      "    ess            : 1.9589081530301076\n",
      "    log_marginal   : 688.8168830151828\n",
      "    log_joint      : 896.816273815227\n",
      "    val_loss       : -692.9660085042318\n",
      "    val_ess        : 1.960806022087733\n",
      "    val_log_marginal: 692.9983571370443\n",
      "    val_log_joint  : 901.0126546223959\n",
      "Train Epoch: 550 [0/54000 (0%)] Loss: -695.834106\n",
      "Train Epoch: 550 [11264/54000 (21%)] Loss: -688.550171\n",
      "Train Epoch: 550 [22528/54000 (42%)] Loss: -688.695557\n",
      "Train Epoch: 550 [33792/54000 (63%)] Loss: -715.294556\n",
      "Train Epoch: 550 [45056/54000 (83%)] Loss: -682.633057\n",
      "    epoch          : 550\n",
      "    loss           : -689.2238464355469\n",
      "    ess            : 1.9602398433775272\n",
      "    log_marginal   : 689.2569896769974\n",
      "    log_joint      : 897.3094177246094\n",
      "    val_loss       : -693.1542460123698\n",
      "    val_ess        : 1.9563276668389638\n",
      "    val_log_marginal: 693.1885579427084\n",
      "    val_log_joint  : 901.2981313069662\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch550.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 551 [0/54000 (0%)] Loss: -669.680847\n",
      "Train Epoch: 551 [11264/54000 (21%)] Loss: -683.504028\n",
      "Train Epoch: 551 [22528/54000 (42%)] Loss: -707.209778\n",
      "Train Epoch: 551 [33792/54000 (63%)] Loss: -674.752563\n",
      "Train Epoch: 551 [45056/54000 (83%)] Loss: -671.932861\n",
      "    epoch          : 551\n",
      "    loss           : -689.3295161409198\n",
      "    ess            : 1.9612215003877316\n",
      "    log_marginal   : 689.3617916467055\n",
      "    log_joint      : 897.5001445266436\n",
      "    val_loss       : -692.9206034342448\n",
      "    val_ess        : 1.9591425855954487\n",
      "    val_log_marginal: 692.9577280680338\n",
      "    val_log_joint  : 901.3575134277344\n",
      "Train Epoch: 552 [0/54000 (0%)] Loss: -705.303528\n",
      "Train Epoch: 552 [11264/54000 (21%)] Loss: -692.351379\n",
      "Train Epoch: 552 [22528/54000 (42%)] Loss: -689.955566\n",
      "Train Epoch: 552 [33792/54000 (63%)] Loss: -680.859375\n",
      "Train Epoch: 552 [45056/54000 (83%)] Loss: -691.871948\n",
      "    epoch          : 552\n",
      "    loss           : -689.4710106039947\n",
      "    ess            : 1.9608347415924072\n",
      "    log_marginal   : 689.5038601857311\n",
      "    log_joint      : 897.7061767578125\n",
      "    val_loss       : -693.6941274007162\n",
      "    val_ess        : 1.9575187265872955\n",
      "    val_log_marginal: 693.7270762125651\n",
      "    val_log_joint  : 901.971934000651\n",
      "Train Epoch: 553 [0/54000 (0%)] Loss: -697.976807\n",
      "Train Epoch: 553 [11264/54000 (21%)] Loss: -679.838867\n",
      "Train Epoch: 553 [22528/54000 (42%)] Loss: -702.176575\n",
      "Train Epoch: 553 [33792/54000 (63%)] Loss: -684.259277\n",
      "Train Epoch: 553 [45056/54000 (83%)] Loss: -676.604248\n",
      "    epoch          : 553\n",
      "    loss           : -689.7804657558225\n",
      "    ess            : 1.9591812952509466\n",
      "    log_marginal   : 689.8156064591318\n",
      "    log_joint      : 897.9160081395563\n",
      "    val_loss       : -693.6607716878256\n",
      "    val_ess        : 1.9593808352947235\n",
      "    val_log_marginal: 693.6934254964193\n",
      "    val_log_joint  : 901.8193918863932\n",
      "Train Epoch: 554 [0/54000 (0%)] Loss: -711.764832\n",
      "Train Epoch: 554 [11264/54000 (21%)] Loss: -672.505188\n",
      "Train Epoch: 554 [22528/54000 (42%)] Loss: -690.254089\n",
      "Train Epoch: 554 [33792/54000 (63%)] Loss: -677.387512\n",
      "Train Epoch: 554 [45056/54000 (83%)] Loss: -675.450012\n",
      "    epoch          : 554\n",
      "    loss           : -690.1405173247715\n",
      "    ess            : 1.9598480811658896\n",
      "    log_marginal   : 690.1737503915463\n",
      "    log_joint      : 898.2956825112396\n",
      "    val_loss       : -694.1002451578776\n",
      "    val_ess        : 1.9578334490458171\n",
      "    val_log_marginal: 694.1385650634766\n",
      "    val_log_joint  : 902.4643402099609\n",
      "Train Epoch: 555 [0/54000 (0%)] Loss: -675.827637\n",
      "Train Epoch: 555 [11264/54000 (21%)] Loss: -690.299561\n",
      "Train Epoch: 555 [22528/54000 (42%)] Loss: -701.488281\n",
      "Train Epoch: 555 [33792/54000 (63%)] Loss: -687.779114\n",
      "Train Epoch: 555 [45056/54000 (83%)] Loss: -684.893066\n",
      "    epoch          : 555\n",
      "    loss           : -690.1631089696344\n",
      "    ess            : 1.9603011124538925\n",
      "    log_marginal   : 690.1975074624115\n",
      "    log_joint      : 898.3642485996462\n",
      "    val_loss       : -694.5074157714844\n",
      "    val_ess        : 1.9572193523248036\n",
      "    val_log_marginal: 694.5436655680338\n",
      "    val_log_joint  : 902.6672058105469\n",
      "Train Epoch: 556 [0/54000 (0%)] Loss: -693.704834\n",
      "Train Epoch: 556 [11264/54000 (21%)] Loss: -692.844238\n",
      "Train Epoch: 556 [22528/54000 (42%)] Loss: -686.072388\n",
      "Train Epoch: 556 [33792/54000 (63%)] Loss: -687.816772\n",
      "Train Epoch: 556 [45056/54000 (83%)] Loss: -690.837219\n",
      "    epoch          : 556\n",
      "    loss           : -690.4293690807415\n",
      "    ess            : 1.9602799291880626\n",
      "    log_marginal   : 690.4623603101047\n",
      "    log_joint      : 898.7566868044296\n",
      "    val_loss       : -694.9969736735026\n",
      "    val_ess        : 1.9584464530150096\n",
      "    val_log_marginal: 695.033945719401\n",
      "    val_log_joint  : 903.1672108968099\n",
      "Train Epoch: 557 [0/54000 (0%)] Loss: -673.945190\n",
      "Train Epoch: 557 [11264/54000 (21%)] Loss: -710.172119\n",
      "Train Epoch: 557 [22528/54000 (42%)] Loss: -682.571899\n",
      "Train Epoch: 557 [33792/54000 (63%)] Loss: -696.712769\n",
      "Train Epoch: 557 [45056/54000 (83%)] Loss: -720.145020\n",
      "    epoch          : 557\n",
      "    loss           : -690.9389516002727\n",
      "    ess            : 1.9601806289744828\n",
      "    log_marginal   : 690.9726815853479\n",
      "    log_joint      : 899.0918083910672\n",
      "    val_loss       : -694.9646504720052\n",
      "    val_ess        : 1.9620848695437114\n",
      "    val_log_marginal: 694.99609375\n",
      "    val_log_joint  : 903.0241139729818\n",
      "Train Epoch: 558 [0/54000 (0%)] Loss: -706.298218\n",
      "Train Epoch: 558 [11264/54000 (21%)] Loss: -687.403076\n",
      "Train Epoch: 558 [22528/54000 (42%)] Loss: -698.079102\n",
      "Train Epoch: 558 [33792/54000 (63%)] Loss: -681.073120\n",
      "Train Epoch: 558 [45056/54000 (83%)] Loss: -703.029053\n",
      "    epoch          : 558\n",
      "    loss           : -690.8480593123526\n",
      "    ess            : 1.9610053874411673\n",
      "    log_marginal   : 690.8801021935805\n",
      "    log_joint      : 899.088120370541\n",
      "    val_loss       : -695.4261576334635\n",
      "    val_ess        : 1.9597370028495789\n",
      "    val_log_marginal: 695.4602406819662\n",
      "    val_log_joint  : 903.7220408121744\n",
      "Train Epoch: 559 [0/54000 (0%)] Loss: -692.128235\n",
      "Train Epoch: 559 [11264/54000 (21%)] Loss: -684.120239\n",
      "Train Epoch: 559 [22528/54000 (42%)] Loss: -693.113647\n",
      "Train Epoch: 559 [33792/54000 (63%)] Loss: -711.821655\n",
      "Train Epoch: 559 [45056/54000 (83%)] Loss: -692.389648\n",
      "    epoch          : 559\n",
      "    loss           : -691.240708261166\n",
      "    ess            : 1.9601763498108342\n",
      "    log_marginal   : 691.2741382526901\n",
      "    log_joint      : 899.4878994923718\n",
      "    val_loss       : -695.9608357747396\n",
      "    val_ess        : 1.9624527494112651\n",
      "    val_log_marginal: 695.9925333658854\n",
      "    val_log_joint  : 904.0345967610677\n",
      "Train Epoch: 560 [0/54000 (0%)] Loss: -687.361267\n",
      "Train Epoch: 560 [11264/54000 (21%)] Loss: -715.022705\n",
      "Train Epoch: 560 [22528/54000 (42%)] Loss: -682.468384\n",
      "Train Epoch: 560 [33792/54000 (63%)] Loss: -683.575928\n",
      "Train Epoch: 560 [45056/54000 (83%)] Loss: -686.605225\n",
      "    epoch          : 560\n",
      "    loss           : -691.5045304208431\n",
      "    ess            : 1.960355575354594\n",
      "    log_marginal   : 691.5375193469929\n",
      "    log_joint      : 899.6288014537884\n",
      "    val_loss       : -695.4589284261068\n",
      "    val_ess        : 1.9558484554290771\n",
      "    val_log_marginal: 695.4967905680338\n",
      "    val_log_joint  : 903.5784556070963\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch560.pth ...\n",
      "Train Epoch: 561 [0/54000 (0%)] Loss: -684.806091\n",
      "Train Epoch: 561 [11264/54000 (21%)] Loss: -705.676147\n",
      "Train Epoch: 561 [22528/54000 (42%)] Loss: -704.712769\n",
      "Train Epoch: 561 [33792/54000 (63%)] Loss: -667.892212\n",
      "Train Epoch: 561 [45056/54000 (83%)] Loss: -701.621338\n",
      "    epoch          : 561\n",
      "    loss           : -691.6026271604142\n",
      "    ess            : 1.961247831020715\n",
      "    log_marginal   : 691.6351065005896\n",
      "    log_joint      : 899.814885553324\n",
      "    val_loss       : -695.7465769449869\n",
      "    val_ess        : 1.9597141842047374\n",
      "    val_log_marginal: 695.7794087727865\n",
      "    val_log_joint  : 903.8119506835938\n",
      "Train Epoch: 562 [0/54000 (0%)] Loss: -702.707520\n",
      "Train Epoch: 562 [11264/54000 (21%)] Loss: -682.351746\n",
      "Train Epoch: 562 [22528/54000 (42%)] Loss: -659.059326\n",
      "Train Epoch: 562 [33792/54000 (63%)] Loss: -675.122437\n",
      "Train Epoch: 562 [45056/54000 (83%)] Loss: -708.449524\n",
      "    epoch          : 562\n",
      "    loss           : -692.0378671322229\n",
      "    ess            : 1.959513193031527\n",
      "    log_marginal   : 692.072797091502\n",
      "    log_joint      : 900.1736680516657\n",
      "    val_loss       : -696.4493001302084\n",
      "    val_ess        : 1.9604334433873494\n",
      "    val_log_marginal: 696.4862518310547\n",
      "    val_log_joint  : 904.7209726969401\n",
      "Train Epoch: 563 [0/54000 (0%)] Loss: -686.599915\n",
      "Train Epoch: 563 [11264/54000 (21%)] Loss: -667.064209\n",
      "Train Epoch: 563 [22528/54000 (42%)] Loss: -696.891235\n",
      "Train Epoch: 563 [33792/54000 (63%)] Loss: -668.806519\n",
      "Train Epoch: 563 [45056/54000 (83%)] Loss: -669.135986\n",
      "    epoch          : 563\n",
      "    loss           : -692.4447159677181\n",
      "    ess            : 1.9603032256072421\n",
      "    log_marginal   : 692.4778782106796\n",
      "    log_joint      : 900.6080598651238\n",
      "    val_loss       : -696.9028523763021\n",
      "    val_ess        : 1.9607381323973339\n",
      "    val_log_marginal: 696.9358723958334\n",
      "    val_log_joint  : 904.9962615966797\n",
      "Train Epoch: 564 [0/54000 (0%)] Loss: -667.290405\n",
      "Train Epoch: 564 [11264/54000 (21%)] Loss: -706.728821\n",
      "Train Epoch: 564 [22528/54000 (42%)] Loss: -686.904297\n",
      "Train Epoch: 564 [33792/54000 (63%)] Loss: -685.050781\n",
      "Train Epoch: 564 [45056/54000 (83%)] Loss: -679.431274\n",
      "    epoch          : 564\n",
      "    loss           : -692.4187915730026\n",
      "    ess            : 1.9601328080555178\n",
      "    log_marginal   : 692.4522083210495\n",
      "    log_joint      : 900.5994636967497\n",
      "    val_loss       : -696.3484395345052\n",
      "    val_ess        : 1.9578130543231964\n",
      "    val_log_marginal: 696.3836873372396\n",
      "    val_log_joint  : 904.5640614827474\n",
      "Train Epoch: 565 [0/54000 (0%)] Loss: -686.785217\n",
      "Train Epoch: 565 [11264/54000 (21%)] Loss: -704.258972\n",
      "Train Epoch: 565 [22528/54000 (42%)] Loss: -671.068054\n",
      "Train Epoch: 565 [33792/54000 (63%)] Loss: -699.233887\n",
      "Train Epoch: 565 [45056/54000 (83%)] Loss: -699.446777\n",
      "    epoch          : 565\n",
      "    loss           : -692.717731979658\n",
      "    ess            : 1.9618512571982618\n",
      "    log_marginal   : 692.7491178692512\n",
      "    log_joint      : 900.9575477456146\n",
      "    val_loss       : -697.1638539632162\n",
      "    val_ess        : 1.9594090779622395\n",
      "    val_log_marginal: 697.1960856119791\n",
      "    val_log_joint  : 905.2460479736328\n",
      "Train Epoch: 566 [0/54000 (0%)] Loss: -725.748352\n",
      "Train Epoch: 566 [11264/54000 (21%)] Loss: -690.638306\n",
      "Train Epoch: 566 [22528/54000 (42%)] Loss: -682.163635\n",
      "Train Epoch: 566 [33792/54000 (63%)] Loss: -695.279663\n",
      "Train Epoch: 566 [45056/54000 (83%)] Loss: -697.143433\n",
      "    epoch          : 566\n",
      "    loss           : -693.2222151846256\n",
      "    ess            : 1.959959623948583\n",
      "    log_marginal   : 693.2556244472288\n",
      "    log_joint      : 901.351848098467\n",
      "    val_loss       : -696.8544413248698\n",
      "    val_ess        : 1.9608156581719716\n",
      "    val_log_marginal: 696.8893992106119\n",
      "    val_log_joint  : 904.6351826985677\n",
      "Train Epoch: 567 [0/54000 (0%)] Loss: -691.805908\n",
      "Train Epoch: 567 [11264/54000 (21%)] Loss: -699.109131\n",
      "Train Epoch: 567 [22528/54000 (42%)] Loss: -712.769897\n",
      "Train Epoch: 567 [33792/54000 (63%)] Loss: -703.160767\n",
      "Train Epoch: 567 [45056/54000 (83%)] Loss: -687.830566\n",
      "    epoch          : 567\n",
      "    loss           : -693.3913706653523\n",
      "    ess            : 1.959954617158422\n",
      "    log_marginal   : 693.424211034235\n",
      "    log_joint      : 901.5062163730837\n",
      "    val_loss       : -697.8659413655599\n",
      "    val_ess        : 1.9626223146915436\n",
      "    val_log_marginal: 697.8968353271484\n",
      "    val_log_joint  : 905.9976450602213\n",
      "Train Epoch: 568 [0/54000 (0%)] Loss: -683.637817\n",
      "Train Epoch: 568 [11264/54000 (21%)] Loss: -713.517212\n",
      "Train Epoch: 568 [22528/54000 (42%)] Loss: -682.002075\n",
      "Train Epoch: 568 [33792/54000 (63%)] Loss: -698.367798\n",
      "Train Epoch: 568 [45056/54000 (83%)] Loss: -702.294067\n",
      "    epoch          : 568\n",
      "    loss           : -693.4121951697008\n",
      "    ess            : 1.9603126656334355\n",
      "    log_marginal   : 693.4448224913399\n",
      "    log_joint      : 901.6012527177919\n",
      "    val_loss       : -698.1610056559244\n",
      "    val_ess        : 1.9638844827810924\n",
      "    val_log_marginal: 698.1903432210287\n",
      "    val_log_joint  : 906.3370208740234\n",
      "Train Epoch: 569 [0/54000 (0%)] Loss: -705.681519\n",
      "Train Epoch: 569 [11264/54000 (21%)] Loss: -676.269836\n",
      "Train Epoch: 569 [22528/54000 (42%)] Loss: -698.224976\n",
      "Train Epoch: 569 [33792/54000 (63%)] Loss: -707.641052\n",
      "Train Epoch: 569 [45056/54000 (83%)] Loss: -695.270325\n",
      "    epoch          : 569\n",
      "    loss           : -693.6917787947745\n",
      "    ess            : 1.961190014515283\n",
      "    log_marginal   : 693.723291361107\n",
      "    log_joint      : 901.8807303950472\n",
      "    val_loss       : -698.4673207600912\n",
      "    val_ess        : 1.9585599303245544\n",
      "    val_log_marginal: 698.5038096110026\n",
      "    val_log_joint  : 906.7312978108724\n",
      "Train Epoch: 570 [0/54000 (0%)] Loss: -680.469727\n",
      "Train Epoch: 570 [11264/54000 (21%)] Loss: -671.690125\n",
      "Train Epoch: 570 [22528/54000 (42%)] Loss: -715.175171\n",
      "Train Epoch: 570 [33792/54000 (63%)] Loss: -707.280090\n",
      "Train Epoch: 570 [45056/54000 (83%)] Loss: -705.931458\n",
      "    epoch          : 570\n",
      "    loss           : -693.8522148852078\n",
      "    ess            : 1.9591954058071352\n",
      "    log_marginal   : 693.8866554116303\n",
      "    log_joint      : 902.0462865289652\n",
      "    val_loss       : -697.4884745279948\n",
      "    val_ess        : 1.9596722920735676\n",
      "    val_log_marginal: 697.5250142415365\n",
      "    val_log_joint  : 905.9003041585287\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch570.pth ...\n",
      "Train Epoch: 571 [0/54000 (0%)] Loss: -703.291138\n",
      "Train Epoch: 571 [11264/54000 (21%)] Loss: -693.075317\n",
      "Train Epoch: 571 [22528/54000 (42%)] Loss: -696.120117\n",
      "Train Epoch: 571 [33792/54000 (63%)] Loss: -703.200317\n",
      "Train Epoch: 571 [45056/54000 (83%)] Loss: -696.882324\n",
      "    epoch          : 571\n",
      "    loss           : -694.2852063448923\n",
      "    ess            : 1.9595315546359655\n",
      "    log_marginal   : 694.3201247881044\n",
      "    log_joint      : 902.5486496259581\n",
      "    val_loss       : -698.3111419677734\n",
      "    val_ess        : 1.959882120291392\n",
      "    val_log_marginal: 698.3473866780599\n",
      "    val_log_joint  : 906.5580495198568\n",
      "Train Epoch: 572 [0/54000 (0%)] Loss: -690.569702\n",
      "Train Epoch: 572 [11264/54000 (21%)] Loss: -674.070801\n",
      "Train Epoch: 572 [22528/54000 (42%)] Loss: -703.797852\n",
      "Train Epoch: 572 [33792/54000 (63%)] Loss: -701.942871\n",
      "Train Epoch: 572 [45056/54000 (83%)] Loss: -678.580444\n",
      "    epoch          : 572\n",
      "    loss           : -694.487687596735\n",
      "    ess            : 1.9610776889998958\n",
      "    log_marginal   : 694.5202504283977\n",
      "    log_joint      : 902.7105327102373\n",
      "    val_loss       : -698.3783620198568\n",
      "    val_ess        : 1.9608870943387349\n",
      "    val_log_marginal: 698.4100443522135\n",
      "    val_log_joint  : 906.7599334716797\n",
      "Train Epoch: 573 [0/54000 (0%)] Loss: -701.989563\n",
      "Train Epoch: 573 [11264/54000 (21%)] Loss: -677.702515\n",
      "Train Epoch: 573 [22528/54000 (42%)] Loss: -719.148071\n",
      "Train Epoch: 573 [33792/54000 (63%)] Loss: -680.075989\n",
      "Train Epoch: 573 [45056/54000 (83%)] Loss: -689.848938\n",
      "    epoch          : 573\n",
      "    loss           : -694.5817992012455\n",
      "    ess            : 1.9592558572877128\n",
      "    log_marginal   : 694.6153506872789\n",
      "    log_joint      : 902.8795252386129\n",
      "    val_loss       : -698.8174438476562\n",
      "    val_ess        : 1.9601938525835674\n",
      "    val_log_marginal: 698.8534901936849\n",
      "    val_log_joint  : 907.0266418457031\n",
      "Train Epoch: 574 [0/54000 (0%)] Loss: -718.613892\n",
      "Train Epoch: 574 [11264/54000 (21%)] Loss: -695.277832\n",
      "Train Epoch: 574 [22528/54000 (42%)] Loss: -685.651733\n",
      "Train Epoch: 574 [33792/54000 (63%)] Loss: -704.449524\n",
      "Train Epoch: 574 [45056/54000 (83%)] Loss: -697.626160\n",
      "    epoch          : 574\n",
      "    loss           : -695.0501300163988\n",
      "    ess            : 1.961124394299849\n",
      "    log_marginal   : 695.0815942152491\n",
      "    log_joint      : 903.2161588848762\n",
      "    val_loss       : -699.6062774658203\n",
      "    val_ess        : 1.9583966235319774\n",
      "    val_log_marginal: 699.6456044514974\n",
      "    val_log_joint  : 907.6100718180338\n",
      "Train Epoch: 575 [0/54000 (0%)] Loss: -686.870605\n",
      "Train Epoch: 575 [11264/54000 (21%)] Loss: -711.776794\n",
      "Train Epoch: 575 [22528/54000 (42%)] Loss: -693.048584\n",
      "Train Epoch: 575 [33792/54000 (63%)] Loss: -700.035156\n",
      "Train Epoch: 575 [45056/54000 (83%)] Loss: -703.672852\n",
      "    epoch          : 575\n",
      "    loss           : -695.0436695026901\n",
      "    ess            : 1.9610626213955429\n",
      "    log_marginal   : 695.0772635981722\n",
      "    log_joint      : 903.3713534373157\n",
      "    val_loss       : -699.3808644612631\n",
      "    val_ess        : 1.9613129993279774\n",
      "    val_log_marginal: 699.4115193684896\n",
      "    val_log_joint  : 907.4660288492838\n",
      "Train Epoch: 576 [0/54000 (0%)] Loss: -677.981445\n",
      "Train Epoch: 576 [11264/54000 (21%)] Loss: -701.618713\n",
      "Train Epoch: 576 [22528/54000 (42%)] Loss: -683.784363\n",
      "Train Epoch: 576 [33792/54000 (63%)] Loss: -700.406982\n",
      "Train Epoch: 576 [45056/54000 (83%)] Loss: -700.029602\n",
      "    epoch          : 576\n",
      "    loss           : -695.3580333781692\n",
      "    ess            : 1.96018071556991\n",
      "    log_marginal   : 695.392487148069\n",
      "    log_joint      : 903.5548297234301\n",
      "    val_loss       : -699.7648468017578\n",
      "    val_ess        : 1.9584996004899342\n",
      "    val_log_marginal: 699.8005727132162\n",
      "    val_log_joint  : 908.2390492757162\n",
      "Train Epoch: 577 [0/54000 (0%)] Loss: -718.349609\n",
      "Train Epoch: 577 [11264/54000 (21%)] Loss: -699.612732\n",
      "Train Epoch: 577 [22528/54000 (42%)] Loss: -685.603394\n",
      "Train Epoch: 577 [33792/54000 (63%)] Loss: -681.156982\n",
      "Train Epoch: 577 [45056/54000 (83%)] Loss: -721.594543\n",
      "    epoch          : 577\n",
      "    loss           : -695.947182709316\n",
      "    ess            : 1.9615663773608658\n",
      "    log_marginal   : 695.9780901063164\n",
      "    log_joint      : 904.0691511046211\n",
      "    val_loss       : -700.1824188232422\n",
      "    val_ess        : 1.9597061574459076\n",
      "    val_log_marginal: 700.2152506510416\n",
      "    val_log_joint  : 908.6467590332031\n",
      "Train Epoch: 578 [0/54000 (0%)] Loss: -712.523987\n",
      "Train Epoch: 578 [11264/54000 (21%)] Loss: -699.686890\n",
      "Train Epoch: 578 [22528/54000 (42%)] Loss: -673.280762\n",
      "Train Epoch: 578 [33792/54000 (63%)] Loss: -691.046936\n",
      "Train Epoch: 578 [45056/54000 (83%)] Loss: -679.292969\n",
      "    epoch          : 578\n",
      "    loss           : -696.0697130887014\n",
      "    ess            : 1.95986452305092\n",
      "    log_marginal   : 696.1028177513266\n",
      "    log_joint      : 904.1956153725678\n",
      "    val_loss       : -700.6829884847006\n",
      "    val_ess        : 1.9589882095654805\n",
      "    val_log_marginal: 700.7173716227213\n",
      "    val_log_joint  : 909.0013326009115\n",
      "Train Epoch: 579 [0/54000 (0%)] Loss: -683.568115\n",
      "Train Epoch: 579 [11264/54000 (21%)] Loss: -699.983093\n",
      "Train Epoch: 579 [22528/54000 (42%)] Loss: -682.103088\n",
      "Train Epoch: 579 [33792/54000 (63%)] Loss: -685.800110\n",
      "Train Epoch: 579 [45056/54000 (83%)] Loss: -680.686890\n",
      "    epoch          : 579\n",
      "    loss           : -696.1288561551077\n",
      "    ess            : 1.9598431148619022\n",
      "    log_marginal   : 696.16392373139\n",
      "    log_joint      : 904.3160590405735\n",
      "    val_loss       : -700.4904174804688\n",
      "    val_ess        : 1.9601771732171376\n",
      "    val_log_marginal: 700.5255889892578\n",
      "    val_log_joint  : 908.7138010660807\n",
      "Train Epoch: 580 [0/54000 (0%)] Loss: -679.901550\n",
      "Train Epoch: 580 [11264/54000 (21%)] Loss: -693.541504\n",
      "Train Epoch: 580 [22528/54000 (42%)] Loss: -684.322388\n",
      "Train Epoch: 580 [33792/54000 (63%)] Loss: -698.876831\n",
      "Train Epoch: 580 [45056/54000 (83%)] Loss: -697.308838\n",
      "    epoch          : 580\n",
      "    loss           : -696.4532741330704\n",
      "    ess            : 1.959976555041547\n",
      "    log_marginal   : 696.4872350152933\n",
      "    log_joint      : 904.6628366146448\n",
      "    val_loss       : -700.1299082438151\n",
      "    val_ess        : 1.959324300289154\n",
      "    val_log_marginal: 700.1651509602865\n",
      "    val_log_joint  : 908.4973500569662\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch580.pth ...\n",
      "Train Epoch: 581 [0/54000 (0%)] Loss: -706.933594\n",
      "Train Epoch: 581 [11264/54000 (21%)] Loss: -678.301453\n",
      "Train Epoch: 581 [22528/54000 (42%)] Loss: -696.446533\n",
      "Train Epoch: 581 [33792/54000 (63%)] Loss: -693.921265\n",
      "Train Epoch: 581 [45056/54000 (83%)] Loss: -706.893188\n",
      "    epoch          : 581\n",
      "    loss           : -696.5312839723983\n",
      "    ess            : 1.9593909843912665\n",
      "    log_marginal   : 696.5668075849425\n",
      "    log_joint      : 904.7145069050339\n",
      "    val_loss       : -700.6233876546224\n",
      "    val_ess        : 1.9609252015749614\n",
      "    val_log_marginal: 700.6557210286459\n",
      "    val_log_joint  : 908.8196919759115\n",
      "Train Epoch: 582 [0/54000 (0%)] Loss: -702.625244\n",
      "Train Epoch: 582 [11264/54000 (21%)] Loss: -701.249634\n",
      "Train Epoch: 582 [22528/54000 (42%)] Loss: -688.890259\n",
      "Train Epoch: 582 [33792/54000 (63%)] Loss: -708.273315\n",
      "Train Epoch: 582 [45056/54000 (83%)] Loss: -705.819275\n",
      "    epoch          : 582\n",
      "    loss           : -696.5645659824587\n",
      "    ess            : 1.960851884113168\n",
      "    log_marginal   : 696.597894056788\n",
      "    log_joint      : 904.8346603681456\n",
      "    val_loss       : -700.5250854492188\n",
      "    val_ess        : 1.958934634923935\n",
      "    val_log_marginal: 700.5600331624349\n",
      "    val_log_joint  : 908.8874104817709\n",
      "Train Epoch: 583 [0/54000 (0%)] Loss: -706.978027\n",
      "Train Epoch: 583 [11264/54000 (21%)] Loss: -696.900757\n",
      "Train Epoch: 583 [22528/54000 (42%)] Loss: -703.437744\n",
      "Train Epoch: 583 [33792/54000 (63%)] Loss: -715.538757\n",
      "Train Epoch: 583 [45056/54000 (83%)] Loss: -707.871521\n",
      "    epoch          : 583\n",
      "    loss           : -697.0986944234596\n",
      "    ess            : 1.9605611720175113\n",
      "    log_marginal   : 697.131563006707\n",
      "    log_joint      : 905.3314554466391\n",
      "    val_loss       : -701.0313161214193\n",
      "    val_ess        : 1.9619103372097015\n",
      "    val_log_marginal: 701.0589904785156\n",
      "    val_log_joint  : 909.3529205322266\n",
      "Train Epoch: 584 [0/54000 (0%)] Loss: -677.032471\n",
      "Train Epoch: 584 [11264/54000 (21%)] Loss: -699.151550\n",
      "Train Epoch: 584 [22528/54000 (42%)] Loss: -710.156006\n",
      "Train Epoch: 584 [33792/54000 (63%)] Loss: -692.010132\n",
      "Train Epoch: 584 [45056/54000 (83%)] Loss: -693.262451\n",
      "    epoch          : 584\n",
      "    loss           : -697.0788787265993\n",
      "    ess            : 1.9595878484114162\n",
      "    log_marginal   : 697.1129351921801\n",
      "    log_joint      : 905.297648879717\n",
      "    val_loss       : -702.1183675130209\n",
      "    val_ess        : 1.959449291229248\n",
      "    val_log_marginal: 702.152577718099\n",
      "    val_log_joint  : 910.1008046468099\n",
      "Train Epoch: 585 [0/54000 (0%)] Loss: -691.378052\n",
      "Train Epoch: 585 [11264/54000 (21%)] Loss: -734.478760\n",
      "Train Epoch: 585 [22528/54000 (42%)] Loss: -706.882385\n",
      "Train Epoch: 585 [33792/54000 (63%)] Loss: -701.988403\n",
      "Train Epoch: 585 [45056/54000 (83%)] Loss: -696.136475\n",
      "    epoch          : 585\n",
      "    loss           : -697.3051176251106\n",
      "    ess            : 1.9588878469647102\n",
      "    log_marginal   : 697.3407276081589\n",
      "    log_joint      : 905.519196132444\n",
      "    val_loss       : -701.6974029541016\n",
      "    val_ess        : 1.9602203170458476\n",
      "    val_log_marginal: 701.7338612874349\n",
      "    val_log_joint  : 909.6825358072916\n",
      "Train Epoch: 586 [0/54000 (0%)] Loss: -703.882019\n",
      "Train Epoch: 586 [11264/54000 (21%)] Loss: -676.103821\n",
      "Train Epoch: 586 [22528/54000 (42%)] Loss: -697.963257\n",
      "Train Epoch: 586 [33792/54000 (63%)] Loss: -701.565186\n",
      "Train Epoch: 586 [45056/54000 (83%)] Loss: -691.485779\n",
      "    epoch          : 586\n",
      "    loss           : -697.8332594385687\n",
      "    ess            : 1.960644098947633\n",
      "    log_marginal   : 697.8662927015772\n",
      "    log_joint      : 906.0273351129496\n",
      "    val_loss       : -701.4208221435547\n",
      "    val_ess        : 1.9613440334796906\n",
      "    val_log_marginal: 701.4519856770834\n",
      "    val_log_joint  : 909.9977671305338\n",
      "Train Epoch: 587 [0/54000 (0%)] Loss: -691.381653\n",
      "Train Epoch: 587 [11264/54000 (21%)] Loss: -711.302856\n",
      "Train Epoch: 587 [22528/54000 (42%)] Loss: -700.999634\n",
      "Train Epoch: 587 [33792/54000 (63%)] Loss: -685.002441\n",
      "Train Epoch: 587 [45056/54000 (83%)] Loss: -695.067261\n",
      "    epoch          : 587\n",
      "    loss           : -697.9122135954083\n",
      "    ess            : 1.9604252104489308\n",
      "    log_marginal   : 697.9459694916347\n",
      "    log_joint      : 906.1824381126547\n",
      "    val_loss       : -702.2593129475912\n",
      "    val_ess        : 1.9600804150104523\n",
      "    val_log_marginal: 702.2945251464844\n",
      "    val_log_joint  : 910.5408223470052\n",
      "Train Epoch: 588 [0/54000 (0%)] Loss: -692.020020\n",
      "Train Epoch: 588 [11264/54000 (21%)] Loss: -678.255737\n",
      "Train Epoch: 588 [22528/54000 (42%)] Loss: -689.052185\n",
      "Train Epoch: 588 [33792/54000 (63%)] Loss: -696.976440\n",
      "Train Epoch: 588 [45056/54000 (83%)] Loss: -725.156372\n",
      "    epoch          : 588\n",
      "    loss           : -698.0336159760097\n",
      "    ess            : 1.960930052793251\n",
      "    log_marginal   : 698.0656605846477\n",
      "    log_joint      : 906.2895024137677\n",
      "    val_loss       : -702.471445719401\n",
      "    val_ess        : 1.9576024909814198\n",
      "    val_log_marginal: 702.5113423665365\n",
      "    val_log_joint  : 910.7586669921875\n",
      "Train Epoch: 589 [0/54000 (0%)] Loss: -711.028687\n",
      "Train Epoch: 589 [11264/54000 (21%)] Loss: -703.398865\n",
      "Train Epoch: 589 [22528/54000 (42%)] Loss: -694.022156\n",
      "Train Epoch: 589 [33792/54000 (63%)] Loss: -685.689331\n",
      "Train Epoch: 589 [45056/54000 (83%)] Loss: -693.697754\n",
      "    epoch          : 589\n",
      "    loss           : -698.4195729381634\n",
      "    ess            : 1.9611325905008137\n",
      "    log_marginal   : 698.4526021705484\n",
      "    log_joint      : 906.631955704599\n",
      "    val_loss       : -702.0553588867188\n",
      "    val_ess        : 1.9580638607343037\n",
      "    val_log_marginal: 702.0916849772135\n",
      "    val_log_joint  : 910.1812896728516\n",
      "Train Epoch: 590 [0/54000 (0%)] Loss: -700.872864\n",
      "Train Epoch: 590 [11264/54000 (21%)] Loss: -673.819458\n",
      "Train Epoch: 590 [22528/54000 (42%)] Loss: -681.388062\n",
      "Train Epoch: 590 [33792/54000 (63%)] Loss: -679.077942\n",
      "Train Epoch: 590 [45056/54000 (83%)] Loss: -697.137939\n",
      "    epoch          : 590\n",
      "    loss           : -698.7249853745947\n",
      "    ess            : 1.9608490984394866\n",
      "    log_marginal   : 698.7581821657577\n",
      "    log_joint      : 906.8990242436247\n",
      "    val_loss       : -702.3482716878256\n",
      "    val_ess        : 1.9586084187030792\n",
      "    val_log_marginal: 702.3836059570312\n",
      "    val_log_joint  : 910.6164245605469\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch590.pth ...\n",
      "Train Epoch: 591 [0/54000 (0%)] Loss: -683.347046\n",
      "Train Epoch: 591 [11264/54000 (21%)] Loss: -714.407043\n",
      "Train Epoch: 591 [22528/54000 (42%)] Loss: -717.506348\n",
      "Train Epoch: 591 [33792/54000 (63%)] Loss: -712.463928\n",
      "Train Epoch: 591 [45056/54000 (83%)] Loss: -690.248535\n",
      "    epoch          : 591\n",
      "    loss           : -698.9866309975678\n",
      "    ess            : 1.9603082740081932\n",
      "    log_marginal   : 699.0199538896669\n",
      "    log_joint      : 907.2092659428434\n",
      "    val_loss       : -702.1527557373047\n",
      "    val_ess        : 1.9599182605743408\n",
      "    val_log_marginal: 702.1846822102865\n",
      "    val_log_joint  : 910.2753295898438\n",
      "Train Epoch: 592 [0/54000 (0%)] Loss: -697.319580\n",
      "Train Epoch: 592 [11264/54000 (21%)] Loss: -682.957947\n",
      "Train Epoch: 592 [22528/54000 (42%)] Loss: -690.779053\n",
      "Train Epoch: 592 [33792/54000 (63%)] Loss: -681.114380\n",
      "Train Epoch: 592 [45056/54000 (83%)] Loss: -703.871277\n",
      "    epoch          : 592\n",
      "    loss           : -699.0947041061689\n",
      "    ess            : 1.9607538344725124\n",
      "    log_marginal   : 699.1284168171433\n",
      "    log_joint      : 907.3380685482385\n",
      "    val_loss       : -702.5966389973959\n",
      "    val_ess        : 1.9592254956563313\n",
      "    val_log_marginal: 702.6297709147135\n",
      "    val_log_joint  : 910.7578633626302\n",
      "Train Epoch: 593 [0/54000 (0%)] Loss: -715.375000\n",
      "Train Epoch: 593 [11264/54000 (21%)] Loss: -669.335938\n",
      "Train Epoch: 593 [22528/54000 (42%)] Loss: -711.838074\n",
      "Train Epoch: 593 [33792/54000 (63%)] Loss: -704.807251\n",
      "Train Epoch: 593 [45056/54000 (83%)] Loss: -703.410522\n",
      "    epoch          : 593\n",
      "    loss           : -699.2903321464107\n",
      "    ess            : 1.959673694844516\n",
      "    log_marginal   : 699.3243713378906\n",
      "    log_joint      : 907.5668714991156\n",
      "    val_loss       : -702.6887715657552\n",
      "    val_ess        : 1.9621546665827434\n",
      "    val_log_marginal: 702.7196655273438\n",
      "    val_log_joint  : 911.0745493570963\n",
      "Train Epoch: 594 [0/54000 (0%)] Loss: -697.121216\n",
      "Train Epoch: 594 [11264/54000 (21%)] Loss: -687.082397\n",
      "Train Epoch: 594 [22528/54000 (42%)] Loss: -695.156677\n",
      "Train Epoch: 594 [33792/54000 (63%)] Loss: -708.679993\n",
      "Train Epoch: 594 [45056/54000 (83%)] Loss: -734.232544\n",
      "    epoch          : 594\n",
      "    loss           : -699.7295330695387\n",
      "    ess            : 1.9613987837197646\n",
      "    log_marginal   : 699.7601473826282\n",
      "    log_joint      : 907.9385059284714\n",
      "    val_loss       : -703.6305440266927\n",
      "    val_ess        : 1.9620644847551982\n",
      "    val_log_marginal: 703.6647796630859\n",
      "    val_log_joint  : 911.9833119710287\n",
      "Train Epoch: 595 [0/54000 (0%)] Loss: -710.708618\n",
      "Train Epoch: 595 [11264/54000 (21%)] Loss: -704.146667\n",
      "Train Epoch: 595 [22528/54000 (42%)] Loss: -694.367798\n",
      "Train Epoch: 595 [33792/54000 (63%)] Loss: -688.231873\n",
      "Train Epoch: 595 [45056/54000 (83%)] Loss: -731.010376\n",
      "    epoch          : 595\n",
      "    loss           : -699.7932595306972\n",
      "    ess            : 1.960917334511595\n",
      "    log_marginal   : 699.8273643637604\n",
      "    log_joint      : 908.0725322219561\n",
      "    val_loss       : -703.8843434651693\n",
      "    val_ess        : 1.9665335913499196\n",
      "    val_log_marginal: 703.9117991129557\n",
      "    val_log_joint  : 911.9083099365234\n",
      "Train Epoch: 596 [0/54000 (0%)] Loss: -691.773621\n",
      "Train Epoch: 596 [11264/54000 (21%)] Loss: -683.844055\n",
      "Train Epoch: 596 [22528/54000 (42%)] Loss: -710.440369\n",
      "Train Epoch: 596 [33792/54000 (63%)] Loss: -698.331116\n",
      "Train Epoch: 596 [45056/54000 (83%)] Loss: -699.508057\n",
      "    epoch          : 596\n",
      "    loss           : -699.920027247015\n",
      "    ess            : 1.9609451856253282\n",
      "    log_marginal   : 699.9518985388414\n",
      "    log_joint      : 908.2057437536852\n",
      "    val_loss       : -704.8151143391927\n",
      "    val_ess        : 1.9619209071000416\n",
      "    val_log_marginal: 704.8442993164062\n",
      "    val_log_joint  : 912.8971964518229\n",
      "Train Epoch: 597 [0/54000 (0%)] Loss: -694.888123\n",
      "Train Epoch: 597 [11264/54000 (21%)] Loss: -700.842529\n",
      "Train Epoch: 597 [22528/54000 (42%)] Loss: -720.284668\n",
      "Train Epoch: 597 [33792/54000 (63%)] Loss: -683.132935\n",
      "Train Epoch: 597 [45056/54000 (83%)] Loss: -707.083130\n",
      "    epoch          : 597\n",
      "    loss           : -700.1829885806677\n",
      "    ess            : 1.9603256009659678\n",
      "    log_marginal   : 700.2161479446123\n",
      "    log_joint      : 908.3803181198408\n",
      "    val_loss       : -704.6717376708984\n",
      "    val_ess        : 1.960586170355479\n",
      "    val_log_marginal: 704.7091827392578\n",
      "    val_log_joint  : 913.1018931070963\n",
      "Train Epoch: 598 [0/54000 (0%)] Loss: -714.518616\n",
      "Train Epoch: 598 [11264/54000 (21%)] Loss: -697.170044\n",
      "Train Epoch: 598 [22528/54000 (42%)] Loss: -701.229736\n",
      "Train Epoch: 598 [33792/54000 (63%)] Loss: -706.394287\n",
      "Train Epoch: 598 [45056/54000 (83%)] Loss: -698.118530\n",
      "    epoch          : 598\n",
      "    loss           : -700.2994995117188\n",
      "    ess            : 1.9600388441445693\n",
      "    log_marginal   : 700.3339740105395\n",
      "    log_joint      : 908.5574997236143\n",
      "    val_loss       : -704.187510172526\n",
      "    val_ess        : 1.9601333141326904\n",
      "    val_log_marginal: 704.2213846842448\n",
      "    val_log_joint  : 912.6473134358724\n",
      "Train Epoch: 599 [0/54000 (0%)] Loss: -722.527832\n",
      "Train Epoch: 599 [11264/54000 (21%)] Loss: -700.532715\n",
      "Train Epoch: 599 [22528/54000 (42%)] Loss: -714.954834\n",
      "Train Epoch: 599 [33792/54000 (63%)] Loss: -713.055908\n",
      "Train Epoch: 599 [45056/54000 (83%)] Loss: -721.215210\n",
      "    epoch          : 599\n",
      "    loss           : -700.4709207786703\n",
      "    ess            : 1.9592742132690717\n",
      "    log_marginal   : 700.505217930056\n",
      "    log_joint      : 908.7786853718308\n",
      "    val_loss       : -704.3414001464844\n",
      "    val_ess        : 1.9634645183881123\n",
      "    val_log_marginal: 704.3709360758463\n",
      "    val_log_joint  : 912.6812082926432\n",
      "Train Epoch: 600 [0/54000 (0%)] Loss: -704.558167\n",
      "Train Epoch: 600 [11264/54000 (21%)] Loss: -704.823242\n",
      "Train Epoch: 600 [22528/54000 (42%)] Loss: -689.747070\n",
      "Train Epoch: 600 [33792/54000 (63%)] Loss: -714.976379\n",
      "Train Epoch: 600 [45056/54000 (83%)] Loss: -683.989319\n",
      "    epoch          : 600\n",
      "    loss           : -700.9343808731943\n",
      "    ess            : 1.9617762205735692\n",
      "    log_marginal   : 700.9660097518057\n",
      "    log_joint      : 909.1253650593308\n",
      "    val_loss       : -704.7770792643229\n",
      "    val_ess        : 1.9606995979944866\n",
      "    val_log_marginal: 704.8091125488281\n",
      "    val_log_joint  : 913.3046824137369\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [0/54000 (0%)] Loss: -705.054932\n",
      "Train Epoch: 601 [11264/54000 (21%)] Loss: -705.029785\n",
      "Train Epoch: 601 [22528/54000 (42%)] Loss: -710.257812\n",
      "Train Epoch: 601 [33792/54000 (63%)] Loss: -702.220642\n",
      "Train Epoch: 601 [45056/54000 (83%)] Loss: -687.998352\n",
      "    epoch          : 601\n",
      "    loss           : -701.1670699209537\n",
      "    ess            : 1.960585744875782\n",
      "    log_marginal   : 701.2006231343971\n",
      "    log_joint      : 909.3786039532356\n",
      "    val_loss       : -704.7317301432291\n",
      "    val_ess        : 1.960700015227\n",
      "    val_log_marginal: 704.7637939453125\n",
      "    val_log_joint  : 913.1053059895834\n",
      "Train Epoch: 602 [0/54000 (0%)] Loss: -706.424744\n",
      "Train Epoch: 602 [11264/54000 (21%)] Loss: -691.098145\n",
      "Train Epoch: 602 [22528/54000 (42%)] Loss: -705.333618\n",
      "Train Epoch: 602 [33792/54000 (63%)] Loss: -689.834106\n",
      "Train Epoch: 602 [45056/54000 (83%)] Loss: -725.872864\n",
      "    epoch          : 602\n",
      "    loss           : -701.4167434404482\n",
      "    ess            : 1.9607909692908234\n",
      "    log_marginal   : 701.4507198693617\n",
      "    log_joint      : 909.6848904591686\n",
      "    val_loss       : -706.2809651692709\n",
      "    val_ess        : 1.9597268501917522\n",
      "    val_log_marginal: 706.3182576497396\n",
      "    val_log_joint  : 914.5748291015625\n",
      "Train Epoch: 603 [0/54000 (0%)] Loss: -685.953979\n",
      "Train Epoch: 603 [11264/54000 (21%)] Loss: -699.578369\n",
      "Train Epoch: 603 [22528/54000 (42%)] Loss: -728.105103\n",
      "Train Epoch: 603 [33792/54000 (63%)] Loss: -705.696655\n",
      "Train Epoch: 603 [45056/54000 (83%)] Loss: -688.513367\n",
      "    epoch          : 603\n",
      "    loss           : -701.5327551499853\n",
      "    ess            : 1.9607216513381813\n",
      "    log_marginal   : 701.5657262262308\n",
      "    log_joint      : 909.7719795658903\n",
      "    val_loss       : -705.7612253824869\n",
      "    val_ess        : 1.959479421377182\n",
      "    val_log_marginal: 705.7943420410156\n",
      "    val_log_joint  : 914.1866149902344\n",
      "Train Epoch: 604 [0/54000 (0%)] Loss: -709.468140\n",
      "Train Epoch: 604 [11264/54000 (21%)] Loss: -712.811401\n",
      "Train Epoch: 604 [22528/54000 (42%)] Loss: -703.547119\n",
      "Train Epoch: 604 [33792/54000 (63%)] Loss: -704.154663\n",
      "Train Epoch: 604 [45056/54000 (83%)] Loss: -718.389893\n",
      "    epoch          : 604\n",
      "    loss           : -701.7309823665979\n",
      "    ess            : 1.9614682118847686\n",
      "    log_marginal   : 701.7631761083063\n",
      "    log_joint      : 909.9281673791273\n",
      "    val_loss       : -706.0352121988932\n",
      "    val_ess        : 1.9620574911435444\n",
      "    val_log_marginal: 706.0624186197916\n",
      "    val_log_joint  : 914.0924326578776\n",
      "Train Epoch: 605 [0/54000 (0%)] Loss: -706.734985\n",
      "Train Epoch: 605 [11264/54000 (21%)] Loss: -702.808838\n",
      "Train Epoch: 605 [22528/54000 (42%)] Loss: -703.390198\n",
      "Train Epoch: 605 [33792/54000 (63%)] Loss: -709.175964\n",
      "Train Epoch: 605 [45056/54000 (83%)] Loss: -715.621338\n",
      "    epoch          : 605\n",
      "    loss           : -702.0335722149543\n",
      "    ess            : 1.9616685667127933\n",
      "    log_marginal   : 702.0658632674307\n",
      "    log_joint      : 910.228956114571\n",
      "    val_loss       : -706.0709177652994\n",
      "    val_ess        : 1.9617342948913574\n",
      "    val_log_marginal: 706.1049296061198\n",
      "    val_log_joint  : 914.1473185221354\n",
      "Train Epoch: 606 [0/54000 (0%)] Loss: -716.022095\n",
      "Train Epoch: 606 [11264/54000 (21%)] Loss: -708.765381\n",
      "Train Epoch: 606 [22528/54000 (42%)] Loss: -703.996826\n",
      "Train Epoch: 606 [33792/54000 (63%)] Loss: -705.204224\n",
      "Train Epoch: 606 [45056/54000 (83%)] Loss: -707.915894\n",
      "    epoch          : 606\n",
      "    loss           : -702.12081621278\n",
      "    ess            : 1.9600478095828362\n",
      "    log_marginal   : 702.1552342828714\n",
      "    log_joint      : 910.4429073693617\n",
      "    val_loss       : -706.078135172526\n",
      "    val_ess        : 1.9605020781358082\n",
      "    val_log_marginal: 706.1116943359375\n",
      "    val_log_joint  : 914.4552663167318\n",
      "Train Epoch: 607 [0/54000 (0%)] Loss: -707.181885\n",
      "Train Epoch: 607 [11264/54000 (21%)] Loss: -702.150269\n",
      "Train Epoch: 607 [22528/54000 (42%)] Loss: -707.457275\n",
      "Train Epoch: 607 [33792/54000 (63%)] Loss: -700.197754\n",
      "Train Epoch: 607 [45056/54000 (83%)] Loss: -710.339294\n",
      "    epoch          : 607\n",
      "    loss           : -702.2381666651312\n",
      "    ess            : 1.9610049915763568\n",
      "    log_marginal   : 702.2713559708505\n",
      "    log_joint      : 910.4834571694428\n",
      "    val_loss       : -707.0457407633463\n",
      "    val_ess        : 1.9595763484636943\n",
      "    val_log_marginal: 707.0810241699219\n",
      "    val_log_joint  : 915.5554555257162\n",
      "Train Epoch: 608 [0/54000 (0%)] Loss: -695.955444\n",
      "Train Epoch: 608 [11264/54000 (21%)] Loss: -693.765259\n",
      "Train Epoch: 608 [22528/54000 (42%)] Loss: -709.645020\n",
      "Train Epoch: 608 [33792/54000 (63%)] Loss: -712.188477\n",
      "Train Epoch: 608 [45056/54000 (83%)] Loss: -708.921265\n",
      "    epoch          : 608\n",
      "    loss           : -702.5570367777123\n",
      "    ess            : 1.9606656229720925\n",
      "    log_marginal   : 702.5910379661703\n",
      "    log_joint      : 910.8969513515257\n",
      "    val_loss       : -706.9810994466146\n",
      "    val_ess        : 1.9559191167354584\n",
      "    val_log_marginal: 707.0213267008463\n",
      "    val_log_joint  : 915.3422088623047\n",
      "Train Epoch: 609 [0/54000 (0%)] Loss: -725.823669\n",
      "Train Epoch: 609 [11264/54000 (21%)] Loss: -707.003662\n",
      "Train Epoch: 609 [22528/54000 (42%)] Loss: -700.044067\n",
      "Train Epoch: 609 [33792/54000 (63%)] Loss: -713.406921\n",
      "Train Epoch: 609 [45056/54000 (83%)] Loss: -703.964233\n",
      "    epoch          : 609\n",
      "    loss           : -703.0039229482975\n",
      "    ess            : 1.960119495976646\n",
      "    log_marginal   : 703.0377824891289\n",
      "    log_joint      : 911.1903582878832\n",
      "    val_loss       : -706.5905812581381\n",
      "    val_ess        : 1.962729165951411\n",
      "    val_log_marginal: 706.622792561849\n",
      "    val_log_joint  : 914.9770304361979\n",
      "Train Epoch: 610 [0/54000 (0%)] Loss: -695.479126\n",
      "Train Epoch: 610 [11264/54000 (21%)] Loss: -701.707275\n",
      "Train Epoch: 610 [22528/54000 (42%)] Loss: -714.333618\n",
      "Train Epoch: 610 [33792/54000 (63%)] Loss: -711.302246\n",
      "Train Epoch: 610 [45056/54000 (83%)] Loss: -689.133545\n",
      "    epoch          : 610\n",
      "    loss           : -702.9546860029112\n",
      "    ess            : 1.9601036051534257\n",
      "    log_marginal   : 702.9881891214623\n",
      "    log_joint      : 911.2212253786483\n",
      "    val_loss       : -707.6459350585938\n",
      "    val_ess        : 1.964683989683787\n",
      "    val_log_marginal: 707.6745147705078\n",
      "    val_log_joint  : 915.9289855957031\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch610.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 611 [0/54000 (0%)] Loss: -719.410278\n",
      "Train Epoch: 611 [11264/54000 (21%)] Loss: -696.514465\n",
      "Train Epoch: 611 [22528/54000 (42%)] Loss: -713.680420\n",
      "Train Epoch: 611 [33792/54000 (63%)] Loss: -698.987549\n",
      "Train Epoch: 611 [45056/54000 (83%)] Loss: -699.034302\n",
      "    epoch          : 611\n",
      "    loss           : -703.3463416909271\n",
      "    ess            : 1.9609587113812286\n",
      "    log_marginal   : 703.3792396401459\n",
      "    log_joint      : 911.5594580308447\n",
      "    val_loss       : -707.3969370524088\n",
      "    val_ess        : 1.9582362274328868\n",
      "    val_log_marginal: 707.4364267985026\n",
      "    val_log_joint  : 915.6936289469401\n",
      "Train Epoch: 612 [0/54000 (0%)] Loss: -701.161560\n",
      "Train Epoch: 612 [11264/54000 (21%)] Loss: -703.908875\n",
      "Train Epoch: 612 [22528/54000 (42%)] Loss: -692.584656\n",
      "Train Epoch: 612 [33792/54000 (63%)] Loss: -685.305664\n",
      "Train Epoch: 612 [45056/54000 (83%)] Loss: -704.944519\n",
      "    epoch          : 612\n",
      "    loss           : -703.3268328972582\n",
      "    ess            : 1.9610448344698492\n",
      "    log_marginal   : 703.3596018665241\n",
      "    log_joint      : 911.6013321786556\n",
      "    val_loss       : -707.4316864013672\n",
      "    val_ess        : 1.963805228471756\n",
      "    val_log_marginal: 707.4611002604166\n",
      "    val_log_joint  : 915.6893310546875\n",
      "Train Epoch: 613 [0/54000 (0%)] Loss: -700.989746\n",
      "Train Epoch: 613 [11264/54000 (21%)] Loss: -732.621948\n",
      "Train Epoch: 613 [22528/54000 (42%)] Loss: -686.892822\n",
      "Train Epoch: 613 [33792/54000 (63%)] Loss: -697.123657\n",
      "Train Epoch: 613 [45056/54000 (83%)] Loss: -691.746338\n",
      "    epoch          : 613\n",
      "    loss           : -703.9329534566627\n",
      "    ess            : 1.9612900637230783\n",
      "    log_marginal   : 703.9656389344414\n",
      "    log_joint      : 912.076947482127\n",
      "    val_loss       : -707.9001719156901\n",
      "    val_ess        : 1.9590568840503693\n",
      "    val_log_marginal: 707.9374643961588\n",
      "    val_log_joint  : 916.2500457763672\n",
      "Train Epoch: 614 [0/54000 (0%)] Loss: -699.523926\n",
      "Train Epoch: 614 [11264/54000 (21%)] Loss: -712.339844\n",
      "Train Epoch: 614 [22528/54000 (42%)] Loss: -705.601624\n",
      "Train Epoch: 614 [33792/54000 (63%)] Loss: -687.985474\n",
      "Train Epoch: 614 [45056/54000 (83%)] Loss: -713.075439\n",
      "    epoch          : 614\n",
      "    loss           : -704.0085357090212\n",
      "    ess            : 1.9609329250623595\n",
      "    log_marginal   : 704.0415447882887\n",
      "    log_joint      : 912.1803041853995\n",
      "    val_loss       : -708.1114654541016\n",
      "    val_ess        : 1.9634851217269897\n",
      "    val_log_marginal: 708.1419067382812\n",
      "    val_log_joint  : 916.6124979654948\n",
      "Train Epoch: 615 [0/54000 (0%)] Loss: -700.012024\n",
      "Train Epoch: 615 [11264/54000 (21%)] Loss: -706.294556\n",
      "Train Epoch: 615 [22528/54000 (42%)] Loss: -680.178101\n",
      "Train Epoch: 615 [33792/54000 (63%)] Loss: -673.317017\n",
      "Train Epoch: 615 [45056/54000 (83%)] Loss: -720.671082\n",
      "    epoch          : 615\n",
      "    loss           : -704.1515376252948\n",
      "    ess            : 1.9609949363852448\n",
      "    log_marginal   : 704.1848242417822\n",
      "    log_joint      : 912.4700513155955\n",
      "    val_loss       : -708.8387959798177\n",
      "    val_ess        : 1.9600153764088948\n",
      "    val_log_marginal: 708.8733164469401\n",
      "    val_log_joint  : 917.1864217122396\n",
      "Train Epoch: 616 [0/54000 (0%)] Loss: -697.230835\n",
      "Train Epoch: 616 [11264/54000 (21%)] Loss: -699.267334\n",
      "Train Epoch: 616 [22528/54000 (42%)] Loss: -704.675171\n",
      "Train Epoch: 616 [33792/54000 (63%)] Loss: -699.915039\n",
      "Train Epoch: 616 [45056/54000 (83%)] Loss: -679.204163\n",
      "    epoch          : 616\n",
      "    loss           : -704.182749622273\n",
      "    ess            : 1.961199903263236\n",
      "    log_marginal   : 704.2166414080925\n",
      "    log_joint      : 912.4801284502138\n",
      "    val_loss       : -709.0197957356771\n",
      "    val_ess        : 1.956617186466853\n",
      "    val_log_marginal: 709.0547434488932\n",
      "    val_log_joint  : 917.1517028808594\n",
      "Train Epoch: 617 [0/54000 (0%)] Loss: -717.489380\n",
      "Train Epoch: 617 [11264/54000 (21%)] Loss: -702.574829\n",
      "Train Epoch: 617 [22528/54000 (42%)] Loss: -708.553284\n",
      "Train Epoch: 617 [33792/54000 (63%)] Loss: -705.279907\n",
      "Train Epoch: 617 [45056/54000 (83%)] Loss: -712.913879\n",
      "    epoch          : 617\n",
      "    loss           : -704.5452351120283\n",
      "    ess            : 1.9607425703192658\n",
      "    log_marginal   : 704.5789933114681\n",
      "    log_joint      : 912.7809442484154\n",
      "    val_loss       : -708.877197265625\n",
      "    val_ess        : 1.9607115884621937\n",
      "    val_log_marginal: 708.9108225504557\n",
      "    val_log_joint  : 917.1160736083984\n",
      "Train Epoch: 618 [0/54000 (0%)] Loss: -742.660583\n",
      "Train Epoch: 618 [11264/54000 (21%)] Loss: -713.385437\n",
      "Train Epoch: 618 [22528/54000 (42%)] Loss: -699.305908\n",
      "Train Epoch: 618 [33792/54000 (63%)] Loss: -722.960327\n",
      "Train Epoch: 618 [45056/54000 (83%)] Loss: -710.655518\n",
      "    epoch          : 618\n",
      "    loss           : -704.8977459601637\n",
      "    ess            : 1.9614022958953425\n",
      "    log_marginal   : 704.9302581211306\n",
      "    log_joint      : 913.0583455787515\n",
      "    val_loss       : -709.0709635416666\n",
      "    val_ess        : 1.9619355897108715\n",
      "    val_log_marginal: 709.1053161621094\n",
      "    val_log_joint  : 917.1947682698568\n",
      "Train Epoch: 619 [0/54000 (0%)] Loss: -707.525391\n",
      "Train Epoch: 619 [11264/54000 (21%)] Loss: -694.262695\n",
      "Train Epoch: 619 [22528/54000 (42%)] Loss: -717.871216\n",
      "Train Epoch: 619 [33792/54000 (63%)] Loss: -716.722900\n",
      "Train Epoch: 619 [45056/54000 (83%)] Loss: -714.613159\n",
      "    epoch          : 619\n",
      "    loss           : -705.0353226571713\n",
      "    ess            : 1.9610043055606339\n",
      "    log_marginal   : 705.0674484540831\n",
      "    log_joint      : 913.2681769604953\n",
      "    val_loss       : -709.6266581217448\n",
      "    val_ess        : 1.956976979970932\n",
      "    val_log_marginal: 709.6654357910156\n",
      "    val_log_joint  : 917.7004445393881\n",
      "Train Epoch: 620 [0/54000 (0%)] Loss: -694.443359\n",
      "Train Epoch: 620 [11264/54000 (21%)] Loss: -706.625671\n",
      "Train Epoch: 620 [22528/54000 (42%)] Loss: -706.478394\n",
      "Train Epoch: 620 [33792/54000 (63%)] Loss: -713.132141\n",
      "Train Epoch: 620 [45056/54000 (83%)] Loss: -714.531372\n",
      "    epoch          : 620\n",
      "    loss           : -705.3062404416642\n",
      "    ess            : 1.9603602650030605\n",
      "    log_marginal   : 705.3405001658314\n",
      "    log_joint      : 913.5035388874558\n",
      "    val_loss       : -709.4019165039062\n",
      "    val_ess        : 1.958094169696172\n",
      "    val_log_marginal: 709.4376271565756\n",
      "    val_log_joint  : 917.5938568115234\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch620.pth ...\n",
      "Train Epoch: 621 [0/54000 (0%)] Loss: -674.983154\n",
      "Train Epoch: 621 [11264/54000 (21%)] Loss: -700.026245\n",
      "Train Epoch: 621 [22528/54000 (42%)] Loss: -681.766418\n",
      "Train Epoch: 621 [33792/54000 (63%)] Loss: -707.476074\n",
      "Train Epoch: 621 [45056/54000 (83%)] Loss: -692.158691\n",
      "    epoch          : 621\n",
      "    loss           : -705.5759542213297\n",
      "    ess            : 1.9613944764407176\n",
      "    log_marginal   : 705.6094792204083\n",
      "    log_joint      : 913.9616676186615\n",
      "    val_loss       : -709.3253835042318\n",
      "    val_ess        : 1.9627381563186646\n",
      "    val_log_marginal: 709.3593139648438\n",
      "    val_log_joint  : 917.6538594563802\n",
      "Train Epoch: 622 [0/54000 (0%)] Loss: -699.517639\n",
      "Train Epoch: 622 [11264/54000 (21%)] Loss: -715.251282\n",
      "Train Epoch: 622 [22528/54000 (42%)] Loss: -695.257568\n",
      "Train Epoch: 622 [33792/54000 (63%)] Loss: -698.688538\n",
      "Train Epoch: 622 [45056/54000 (83%)] Loss: -705.657410\n",
      "    epoch          : 622\n",
      "    loss           : -705.9975309551887\n",
      "    ess            : 1.9609750295585056\n",
      "    log_marginal   : 706.0300120227741\n",
      "    log_joint      : 914.1604049970518\n",
      "    val_loss       : -709.8670349121094\n",
      "    val_ess        : 1.9656834999720256\n",
      "    val_log_marginal: 709.8972422281901\n",
      "    val_log_joint  : 918.2372385660807\n",
      "Train Epoch: 623 [0/54000 (0%)] Loss: -700.693909\n",
      "Train Epoch: 623 [11264/54000 (21%)] Loss: -710.405762\n",
      "Train Epoch: 623 [22528/54000 (42%)] Loss: -702.294373\n",
      "Train Epoch: 623 [33792/54000 (63%)] Loss: -695.499512\n",
      "Train Epoch: 623 [45056/54000 (83%)] Loss: -709.205566\n",
      "    epoch          : 623\n",
      "    loss           : -705.9768745854216\n",
      "    ess            : 1.9607828743052933\n",
      "    log_marginal   : 706.010916080115\n",
      "    log_joint      : 914.1397866303066\n",
      "    val_loss       : -710.1286315917969\n",
      "    val_ess        : 1.9622335235277812\n",
      "    val_log_marginal: 710.1600952148438\n",
      "    val_log_joint  : 918.4815012613932\n",
      "Train Epoch: 624 [0/54000 (0%)] Loss: -693.558472\n",
      "Train Epoch: 624 [11264/54000 (21%)] Loss: -714.196777\n",
      "Train Epoch: 624 [22528/54000 (42%)] Loss: -714.869751\n",
      "Train Epoch: 624 [33792/54000 (63%)] Loss: -713.021362\n",
      "Train Epoch: 624 [45056/54000 (83%)] Loss: -694.859375\n",
      "    epoch          : 624\n",
      "    loss           : -706.350592271337\n",
      "    ess            : 1.9592576173116576\n",
      "    log_marginal   : 706.3857663712412\n",
      "    log_joint      : 914.6355452627506\n",
      "    val_loss       : -710.7002410888672\n",
      "    val_ess        : 1.960013488928477\n",
      "    val_log_marginal: 710.7373097737631\n",
      "    val_log_joint  : 919.0036926269531\n",
      "Train Epoch: 625 [0/54000 (0%)] Loss: -690.471497\n",
      "Train Epoch: 625 [11264/54000 (21%)] Loss: -707.081238\n",
      "Train Epoch: 625 [22528/54000 (42%)] Loss: -684.869873\n",
      "Train Epoch: 625 [33792/54000 (63%)] Loss: -719.976135\n",
      "Train Epoch: 625 [45056/54000 (83%)] Loss: -709.627991\n",
      "    epoch          : 625\n",
      "    loss           : -706.3668650501179\n",
      "    ess            : 1.9605513687403697\n",
      "    log_marginal   : 706.4003624106354\n",
      "    log_joint      : 914.668409239571\n",
      "    val_loss       : -709.9819590250651\n",
      "    val_ess        : 1.9594919681549072\n",
      "    val_log_marginal: 710.0200347900391\n",
      "    val_log_joint  : 918.2001698811849\n",
      "Train Epoch: 626 [0/54000 (0%)] Loss: -758.822754\n",
      "Train Epoch: 626 [11264/54000 (21%)] Loss: -704.371338\n",
      "Train Epoch: 626 [22528/54000 (42%)] Loss: -709.179443\n",
      "Train Epoch: 626 [33792/54000 (63%)] Loss: -713.307861\n",
      "Train Epoch: 626 [45056/54000 (83%)] Loss: -689.372314\n",
      "    epoch          : 626\n",
      "    loss           : -706.5855954728037\n",
      "    ess            : 1.9611685444723885\n",
      "    log_marginal   : 706.6188751796507\n",
      "    log_joint      : 914.8947016877948\n",
      "    val_loss       : -710.4142049153646\n",
      "    val_ess        : 1.962720473607381\n",
      "    val_log_marginal: 710.4454498291016\n",
      "    val_log_joint  : 918.7985331217448\n",
      "Train Epoch: 627 [0/54000 (0%)] Loss: -701.636841\n",
      "Train Epoch: 627 [11264/54000 (21%)] Loss: -720.149048\n",
      "Train Epoch: 627 [22528/54000 (42%)] Loss: -711.720276\n",
      "Train Epoch: 627 [33792/54000 (63%)] Loss: -701.275513\n",
      "Train Epoch: 627 [45056/54000 (83%)] Loss: -719.089172\n",
      "    epoch          : 627\n",
      "    loss           : -706.9371907935953\n",
      "    ess            : 1.9619213893728435\n",
      "    log_marginal   : 706.9690177485628\n",
      "    log_joint      : 915.1448784594265\n",
      "    val_loss       : -711.2201029459635\n",
      "    val_ess        : 1.9629310468832653\n",
      "    val_log_marginal: 711.2506052652994\n",
      "    val_log_joint  : 919.302968343099\n",
      "Train Epoch: 628 [0/54000 (0%)] Loss: -701.058350\n",
      "Train Epoch: 628 [11264/54000 (21%)] Loss: -709.510864\n",
      "Train Epoch: 628 [22528/54000 (42%)] Loss: -684.910400\n",
      "Train Epoch: 628 [33792/54000 (63%)] Loss: -700.294678\n",
      "Train Epoch: 628 [45056/54000 (83%)] Loss: -699.048950\n",
      "    epoch          : 628\n",
      "    loss           : -706.993106482164\n",
      "    ess            : 1.9619126927177861\n",
      "    log_marginal   : 707.024045548349\n",
      "    log_joint      : 915.2731467193028\n",
      "    val_loss       : -711.2064921061198\n",
      "    val_ess        : 1.9563151001930237\n",
      "    val_log_marginal: 711.2451731363932\n",
      "    val_log_joint  : 919.4993387858073\n",
      "Train Epoch: 629 [0/54000 (0%)] Loss: -691.690063\n",
      "Train Epoch: 629 [11264/54000 (21%)] Loss: -694.362854\n",
      "Train Epoch: 629 [22528/54000 (42%)] Loss: -721.225586\n",
      "Train Epoch: 629 [33792/54000 (63%)] Loss: -715.302063\n",
      "Train Epoch: 629 [45056/54000 (83%)] Loss: -701.670410\n",
      "    epoch          : 629\n",
      "    loss           : -706.919376013414\n",
      "    ess            : 1.9605796235912252\n",
      "    log_marginal   : 706.9532211591612\n",
      "    log_joint      : 915.2170358333948\n",
      "    val_loss       : -711.3869781494141\n",
      "    val_ess        : 1.9640011688073475\n",
      "    val_log_marginal: 711.4167887369791\n",
      "    val_log_joint  : 919.6045633951823\n",
      "Train Epoch: 630 [0/54000 (0%)] Loss: -694.294678\n",
      "Train Epoch: 630 [11264/54000 (21%)] Loss: -725.188110\n",
      "Train Epoch: 630 [22528/54000 (42%)] Loss: -710.984619\n",
      "Train Epoch: 630 [33792/54000 (63%)] Loss: -697.828979\n",
      "Train Epoch: 630 [45056/54000 (83%)] Loss: -714.129272\n",
      "    epoch          : 630\n",
      "    loss           : -707.4645333919885\n",
      "    ess            : 1.961725579117829\n",
      "    log_marginal   : 707.4964305949661\n",
      "    log_joint      : 915.696399040942\n",
      "    val_loss       : -711.2071533203125\n",
      "    val_ess        : 1.9627383649349213\n",
      "    val_log_marginal: 711.2403717041016\n",
      "    val_log_joint  : 919.5119222005209\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch630.pth ...\n",
      "Train Epoch: 631 [0/54000 (0%)] Loss: -698.606262\n",
      "Train Epoch: 631 [11264/54000 (21%)] Loss: -708.667358\n",
      "Train Epoch: 631 [22528/54000 (42%)] Loss: -733.719971\n",
      "Train Epoch: 631 [33792/54000 (63%)] Loss: -680.173828\n",
      "Train Epoch: 631 [45056/54000 (83%)] Loss: -681.757141\n",
      "    epoch          : 631\n",
      "    loss           : -707.3780425449587\n",
      "    ess            : 1.961004985953277\n",
      "    log_marginal   : 707.4110712015404\n",
      "    log_joint      : 915.7173162496315\n",
      "    val_loss       : -711.1031087239584\n",
      "    val_ess        : 1.961892416079839\n",
      "    val_log_marginal: 711.1357828776041\n",
      "    val_log_joint  : 919.5701192220052\n",
      "Train Epoch: 632 [0/54000 (0%)] Loss: -705.185974\n",
      "Train Epoch: 632 [11264/54000 (21%)] Loss: -697.571533\n",
      "Train Epoch: 632 [22528/54000 (42%)] Loss: -698.932251\n",
      "Train Epoch: 632 [33792/54000 (63%)] Loss: -682.826477\n",
      "Train Epoch: 632 [45056/54000 (83%)] Loss: -694.209534\n",
      "    epoch          : 632\n",
      "    loss           : -707.8881427117113\n",
      "    ess            : 1.9614125906296496\n",
      "    log_marginal   : 707.9209226212412\n",
      "    log_joint      : 916.1802195423054\n",
      "    val_loss       : -711.9311014811198\n",
      "    val_ess        : 1.9621634085973103\n",
      "    val_log_marginal: 711.9639078776041\n",
      "    val_log_joint  : 920.1072642008463\n",
      "Train Epoch: 633 [0/54000 (0%)] Loss: -706.811401\n",
      "Train Epoch: 633 [11264/54000 (21%)] Loss: -700.054443\n",
      "Train Epoch: 633 [22528/54000 (42%)] Loss: -725.082336\n",
      "Train Epoch: 633 [33792/54000 (63%)] Loss: -699.494873\n",
      "Train Epoch: 633 [45056/54000 (83%)] Loss: -708.401489\n",
      "    epoch          : 633\n",
      "    loss           : -708.0769434515036\n",
      "    ess            : 1.9603735512157656\n",
      "    log_marginal   : 708.1107327443249\n",
      "    log_joint      : 916.3798384756412\n",
      "    val_loss       : -711.9328918457031\n",
      "    val_ess        : 1.9594457745552063\n",
      "    val_log_marginal: 711.9701029459635\n",
      "    val_log_joint  : 920.5143686930338\n",
      "Train Epoch: 634 [0/54000 (0%)] Loss: -695.398315\n",
      "Train Epoch: 634 [11264/54000 (21%)] Loss: -695.499268\n",
      "Train Epoch: 634 [22528/54000 (42%)] Loss: -716.805359\n",
      "Train Epoch: 634 [33792/54000 (63%)] Loss: -698.277710\n",
      "Train Epoch: 634 [45056/54000 (83%)] Loss: -712.233276\n",
      "    epoch          : 634\n",
      "    loss           : -708.413593220261\n",
      "    ess            : 1.9607495575580958\n",
      "    log_marginal   : 708.446415163436\n",
      "    log_joint      : 916.656508535709\n",
      "    val_loss       : -711.8643188476562\n",
      "    val_ess        : 1.961042433977127\n",
      "    val_log_marginal: 711.895517985026\n",
      "    val_log_joint  : 920.168690999349\n",
      "Train Epoch: 635 [0/54000 (0%)] Loss: -710.532593\n",
      "Train Epoch: 635 [11264/54000 (21%)] Loss: -730.012329\n",
      "Train Epoch: 635 [22528/54000 (42%)] Loss: -688.245972\n",
      "Train Epoch: 635 [33792/54000 (63%)] Loss: -684.468628\n",
      "Train Epoch: 635 [45056/54000 (83%)] Loss: -719.472595\n",
      "    epoch          : 635\n",
      "    loss           : -708.2372315604732\n",
      "    ess            : 1.9609956550148298\n",
      "    log_marginal   : 708.2707266177771\n",
      "    log_joint      : 916.4249970058225\n",
      "    val_loss       : -712.9254913330078\n",
      "    val_ess        : 1.9619945486386616\n",
      "    val_log_marginal: 712.9550730387369\n",
      "    val_log_joint  : 921.2859598795573\n",
      "Train Epoch: 636 [0/54000 (0%)] Loss: -740.427490\n",
      "Train Epoch: 636 [11264/54000 (21%)] Loss: -714.074768\n",
      "Train Epoch: 636 [22528/54000 (42%)] Loss: -694.967285\n",
      "Train Epoch: 636 [33792/54000 (63%)] Loss: -716.725708\n",
      "Train Epoch: 636 [45056/54000 (83%)] Loss: -696.480347\n",
      "    epoch          : 636\n",
      "    loss           : -708.6909001188458\n",
      "    ess            : 1.9619583858633942\n",
      "    log_marginal   : 708.7231312877727\n",
      "    log_joint      : 916.8940182092055\n",
      "    val_loss       : -712.2586873372396\n",
      "    val_ess        : 1.9625646770000458\n",
      "    val_log_marginal: 712.2911834716797\n",
      "    val_log_joint  : 920.7262573242188\n",
      "Train Epoch: 637 [0/54000 (0%)] Loss: -711.630859\n",
      "Train Epoch: 637 [11264/54000 (21%)] Loss: -708.845398\n",
      "Train Epoch: 637 [22528/54000 (42%)] Loss: -683.373047\n",
      "Train Epoch: 637 [33792/54000 (63%)] Loss: -732.013489\n",
      "Train Epoch: 637 [45056/54000 (83%)] Loss: -704.795654\n",
      "    epoch          : 637\n",
      "    loss           : -708.6996137511055\n",
      "    ess            : 1.9611387725146312\n",
      "    log_marginal   : 708.7327385668484\n",
      "    log_joint      : 917.0610328530365\n",
      "    val_loss       : -712.9531199137369\n",
      "    val_ess        : 1.9623653093973796\n",
      "    val_log_marginal: 712.9833068847656\n",
      "    val_log_joint  : 921.1826680501302\n",
      "Train Epoch: 638 [0/54000 (0%)] Loss: -715.191895\n",
      "Train Epoch: 638 [11264/54000 (21%)] Loss: -690.812256\n",
      "Train Epoch: 638 [22528/54000 (42%)] Loss: -724.562073\n",
      "Train Epoch: 638 [33792/54000 (63%)] Loss: -723.224243\n",
      "Train Epoch: 638 [45056/54000 (83%)] Loss: -703.943726\n",
      "    epoch          : 638\n",
      "    loss           : -708.9394680958874\n",
      "    ess            : 1.9606268023544888\n",
      "    log_marginal   : 708.9734744665758\n",
      "    log_joint      : 917.2595537293632\n",
      "    val_loss       : -713.0814310709635\n",
      "    val_ess        : 1.9646142522494\n",
      "    val_log_marginal: 713.1099548339844\n",
      "    val_log_joint  : 921.1451009114584\n",
      "Train Epoch: 639 [0/54000 (0%)] Loss: -718.222290\n",
      "Train Epoch: 639 [11264/54000 (21%)] Loss: -700.791382\n",
      "Train Epoch: 639 [22528/54000 (42%)] Loss: -723.061646\n",
      "Train Epoch: 639 [33792/54000 (63%)] Loss: -701.713745\n",
      "Train Epoch: 639 [45056/54000 (83%)] Loss: -699.299927\n",
      "    epoch          : 639\n",
      "    loss           : -709.2028192484154\n",
      "    ess            : 1.9614902453602485\n",
      "    log_marginal   : 709.2353653817806\n",
      "    log_joint      : 917.4252745430424\n",
      "    val_loss       : -713.9867553710938\n",
      "    val_ess        : 1.9643722375233967\n",
      "    val_log_marginal: 714.0170847574869\n",
      "    val_log_joint  : 922.1467234293619\n",
      "Train Epoch: 640 [0/54000 (0%)] Loss: -718.057495\n",
      "Train Epoch: 640 [11264/54000 (21%)] Loss: -707.760498\n",
      "Train Epoch: 640 [22528/54000 (42%)] Loss: -713.933716\n",
      "Train Epoch: 640 [33792/54000 (63%)] Loss: -695.816650\n",
      "Train Epoch: 640 [45056/54000 (83%)] Loss: -728.345398\n",
      "    epoch          : 640\n",
      "    loss           : -709.3489702332695\n",
      "    ess            : 1.9607606080343138\n",
      "    log_marginal   : 709.3827123102152\n",
      "    log_joint      : 917.6791468206442\n",
      "    val_loss       : -713.8426361083984\n",
      "    val_ess        : 1.9623335202534993\n",
      "    val_log_marginal: 713.8753865559896\n",
      "    val_log_joint  : 921.914072672526\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch640.pth ...\n",
      "Train Epoch: 641 [0/54000 (0%)] Loss: -709.496948\n",
      "Train Epoch: 641 [11264/54000 (21%)] Loss: -721.856079\n",
      "Train Epoch: 641 [22528/54000 (42%)] Loss: -688.469543\n",
      "Train Epoch: 641 [33792/54000 (63%)] Loss: -700.401184\n",
      "Train Epoch: 641 [45056/54000 (83%)] Loss: -711.032227\n",
      "    epoch          : 641\n",
      "    loss           : -709.5170777518795\n",
      "    ess            : 1.9613431309753995\n",
      "    log_marginal   : 709.5503436394457\n",
      "    log_joint      : 917.8141790426002\n",
      "    val_loss       : -713.5054372151693\n",
      "    val_ess        : 1.9608954191207886\n",
      "    val_log_marginal: 713.5374501546224\n",
      "    val_log_joint  : 921.7936452229818\n",
      "Train Epoch: 642 [0/54000 (0%)] Loss: -733.040833\n",
      "Train Epoch: 642 [11264/54000 (21%)] Loss: -710.122986\n",
      "Train Epoch: 642 [22528/54000 (42%)] Loss: -709.917236\n",
      "Train Epoch: 642 [33792/54000 (63%)] Loss: -721.642639\n",
      "Train Epoch: 642 [45056/54000 (83%)] Loss: -707.619263\n",
      "    epoch          : 642\n",
      "    loss           : -709.7836424629643\n",
      "    ess            : 1.9610901756106682\n",
      "    log_marginal   : 709.8160492519163\n",
      "    log_joint      : 918.1372536713222\n",
      "    val_loss       : -714.3820292154948\n",
      "    val_ess        : 1.9648840725421906\n",
      "    val_log_marginal: 714.4119160970052\n",
      "    val_log_joint  : 922.6589965820312\n",
      "Train Epoch: 643 [0/54000 (0%)] Loss: -723.036133\n",
      "Train Epoch: 643 [11264/54000 (21%)] Loss: -698.502686\n",
      "Train Epoch: 643 [22528/54000 (42%)] Loss: -719.474365\n",
      "Train Epoch: 643 [33792/54000 (63%)] Loss: -721.493469\n",
      "Train Epoch: 643 [45056/54000 (83%)] Loss: -713.569092\n",
      "    epoch          : 643\n",
      "    loss           : -710.1522245587043\n",
      "    ess            : 1.9612794630932358\n",
      "    log_marginal   : 710.184897368809\n",
      "    log_joint      : 918.5610345804466\n",
      "    val_loss       : -714.4362080891927\n",
      "    val_ess        : 1.9606333871682484\n",
      "    val_log_marginal: 714.4674835205078\n",
      "    val_log_joint  : 922.8438262939453\n",
      "Train Epoch: 644 [0/54000 (0%)] Loss: -736.901794\n",
      "Train Epoch: 644 [11264/54000 (21%)] Loss: -714.981140\n",
      "Train Epoch: 644 [22528/54000 (42%)] Loss: -706.340332\n",
      "Train Epoch: 644 [33792/54000 (63%)] Loss: -719.554077\n",
      "Train Epoch: 644 [45056/54000 (83%)] Loss: -714.865723\n",
      "    epoch          : 644\n",
      "    loss           : -710.0853380887014\n",
      "    ess            : 1.960044044368672\n",
      "    log_marginal   : 710.1192886064638\n",
      "    log_joint      : 918.4100739101194\n",
      "    val_loss       : -713.9881744384766\n",
      "    val_ess        : 1.96199432015419\n",
      "    val_log_marginal: 714.0247650146484\n",
      "    val_log_joint  : 922.6227366129557\n",
      "Train Epoch: 645 [0/54000 (0%)] Loss: -717.846436\n",
      "Train Epoch: 645 [11264/54000 (21%)] Loss: -733.012085\n",
      "Train Epoch: 645 [22528/54000 (42%)] Loss: -700.221619\n",
      "Train Epoch: 645 [33792/54000 (63%)] Loss: -706.282654\n",
      "Train Epoch: 645 [45056/54000 (83%)] Loss: -718.763611\n",
      "    epoch          : 645\n",
      "    loss           : -710.5221022120062\n",
      "    ess            : 1.9611948683576763\n",
      "    log_marginal   : 710.5545683087043\n",
      "    log_joint      : 918.9561065098025\n",
      "    val_loss       : -714.2426401774088\n",
      "    val_ess        : 1.96130833029747\n",
      "    val_log_marginal: 714.2757161458334\n",
      "    val_log_joint  : 922.3616739908854\n",
      "Train Epoch: 646 [0/54000 (0%)] Loss: -712.016541\n",
      "Train Epoch: 646 [11264/54000 (21%)] Loss: -704.012939\n",
      "Train Epoch: 646 [22528/54000 (42%)] Loss: -716.950256\n",
      "Train Epoch: 646 [33792/54000 (63%)] Loss: -699.087708\n",
      "Train Epoch: 646 [45056/54000 (83%)] Loss: -710.060364\n",
      "    epoch          : 646\n",
      "    loss           : -710.8554180793043\n",
      "    ess            : 1.9600459134803627\n",
      "    log_marginal   : 710.8899121554392\n",
      "    log_joint      : 919.1686378335053\n",
      "    val_loss       : -714.242909749349\n",
      "    val_ess        : 1.960213194290797\n",
      "    val_log_marginal: 714.2780202229818\n",
      "    val_log_joint  : 922.6340891520182\n",
      "Train Epoch: 647 [0/54000 (0%)] Loss: -696.519653\n",
      "Train Epoch: 647 [11264/54000 (21%)] Loss: -714.540466\n",
      "Train Epoch: 647 [22528/54000 (42%)] Loss: -694.967041\n",
      "Train Epoch: 647 [33792/54000 (63%)] Loss: -711.812866\n",
      "Train Epoch: 647 [45056/54000 (83%)] Loss: -713.773560\n",
      "    epoch          : 647\n",
      "    loss           : -710.7780070754717\n",
      "    ess            : 1.959961840566599\n",
      "    log_marginal   : 710.810776620541\n",
      "    log_joint      : 919.0696416890846\n",
      "    val_loss       : -715.0809071858724\n",
      "    val_ess        : 1.9597796599070232\n",
      "    val_log_marginal: 715.1179860432943\n",
      "    val_log_joint  : 923.4792429606119\n",
      "Train Epoch: 648 [0/54000 (0%)] Loss: -722.625854\n",
      "Train Epoch: 648 [11264/54000 (21%)] Loss: -719.007324\n",
      "Train Epoch: 648 [22528/54000 (42%)] Loss: -699.742554\n",
      "Train Epoch: 648 [33792/54000 (63%)] Loss: -725.114319\n",
      "Train Epoch: 648 [45056/54000 (83%)] Loss: -699.415039\n",
      "    epoch          : 648\n",
      "    loss           : -711.0020164633697\n",
      "    ess            : 1.9610492260950916\n",
      "    log_marginal   : 711.0340627994177\n",
      "    log_joint      : 919.2925461103331\n",
      "    val_loss       : -715.4394327799479\n",
      "    val_ess        : 1.9583666324615479\n",
      "    val_log_marginal: 715.4808349609375\n",
      "    val_log_joint  : 923.7269236246744\n",
      "Train Epoch: 649 [0/54000 (0%)] Loss: -676.690918\n",
      "Train Epoch: 649 [11264/54000 (21%)] Loss: -721.490601\n",
      "Train Epoch: 649 [22528/54000 (42%)] Loss: -712.533142\n",
      "Train Epoch: 649 [33792/54000 (63%)] Loss: -695.583008\n",
      "Train Epoch: 649 [45056/54000 (83%)] Loss: -724.910095\n",
      "    epoch          : 649\n",
      "    loss           : -711.4506196795769\n",
      "    ess            : 1.9603601277999159\n",
      "    log_marginal   : 711.4831888450766\n",
      "    log_joint      : 919.7035349719929\n",
      "    val_loss       : -715.2907257080078\n",
      "    val_ess        : 1.9617460270722706\n",
      "    val_log_marginal: 715.3241526285807\n",
      "    val_log_joint  : 923.4779307047526\n",
      "Train Epoch: 650 [0/54000 (0%)] Loss: -704.677368\n",
      "Train Epoch: 650 [11264/54000 (21%)] Loss: -699.055908\n",
      "Train Epoch: 650 [22528/54000 (42%)] Loss: -716.060913\n",
      "Train Epoch: 650 [33792/54000 (63%)] Loss: -703.312256\n",
      "Train Epoch: 650 [45056/54000 (83%)] Loss: -695.639893\n",
      "    epoch          : 650\n",
      "    loss           : -711.3113236337338\n",
      "    ess            : 1.9604503040043813\n",
      "    log_marginal   : 711.3459178996536\n",
      "    log_joint      : 919.631290075914\n",
      "    val_loss       : -716.4992370605469\n",
      "    val_ess        : 1.9605646630128224\n",
      "    val_log_marginal: 716.5391591389974\n",
      "    val_log_joint  : 924.7112986246744\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch650.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 651 [0/54000 (0%)] Loss: -692.888184\n",
      "Train Epoch: 651 [11264/54000 (21%)] Loss: -716.307739\n",
      "Train Epoch: 651 [22528/54000 (42%)] Loss: -715.227844\n",
      "Train Epoch: 651 [33792/54000 (63%)] Loss: -728.558594\n",
      "Train Epoch: 651 [45056/54000 (83%)] Loss: -716.904053\n",
      "    epoch          : 651\n",
      "    loss           : -711.6955698841023\n",
      "    ess            : 1.961403269812746\n",
      "    log_marginal   : 711.7286860627948\n",
      "    log_joint      : 919.8851231988871\n",
      "    val_loss       : -715.5977427164713\n",
      "    val_ess        : 1.9590176145235698\n",
      "    val_log_marginal: 715.6340586344401\n",
      "    val_log_joint  : 924.2353006998698\n",
      "Train Epoch: 652 [0/54000 (0%)] Loss: -716.702881\n",
      "Train Epoch: 652 [11264/54000 (21%)] Loss: -719.237976\n",
      "Train Epoch: 652 [22528/54000 (42%)] Loss: -700.697632\n",
      "Train Epoch: 652 [33792/54000 (63%)] Loss: -718.174500\n",
      "Train Epoch: 652 [45056/54000 (83%)] Loss: -694.951904\n",
      "    epoch          : 652\n",
      "    loss           : -711.8561499253759\n",
      "    ess            : 1.9615715382234105\n",
      "    log_marginal   : 711.8896881679319\n",
      "    log_joint      : 920.278760802071\n",
      "    val_loss       : -716.283213297526\n",
      "    val_ess        : 1.9622461001078289\n",
      "    val_log_marginal: 716.3153330485026\n",
      "    val_log_joint  : 924.4845377604166\n",
      "Train Epoch: 653 [0/54000 (0%)] Loss: -715.924927\n",
      "Train Epoch: 653 [11264/54000 (21%)] Loss: -713.004150\n",
      "Train Epoch: 653 [22528/54000 (42%)] Loss: -687.107605\n",
      "Train Epoch: 653 [33792/54000 (63%)] Loss: -709.267944\n",
      "Train Epoch: 653 [45056/54000 (83%)] Loss: -706.968933\n",
      "    epoch          : 653\n",
      "    loss           : -711.8757589088297\n",
      "    ess            : 1.960405688240843\n",
      "    log_marginal   : 711.9091722020563\n",
      "    log_joint      : 920.1894082123379\n",
      "    val_loss       : -716.0117797851562\n",
      "    val_ess        : 1.9603729049364726\n",
      "    val_log_marginal: 716.0433146158854\n",
      "    val_log_joint  : 924.3243865966797\n",
      "Train Epoch: 654 [0/54000 (0%)] Loss: -703.497559\n",
      "Train Epoch: 654 [11264/54000 (21%)] Loss: -716.385986\n",
      "Train Epoch: 654 [22528/54000 (42%)] Loss: -673.066772\n",
      "Train Epoch: 654 [33792/54000 (63%)] Loss: -730.018127\n",
      "Train Epoch: 654 [45056/54000 (83%)] Loss: -695.649658\n",
      "    epoch          : 654\n",
      "    loss           : -712.1014513699514\n",
      "    ess            : 1.9605771696792458\n",
      "    log_marginal   : 712.1344166881634\n",
      "    log_joint      : 920.4314776726488\n",
      "    val_loss       : -715.5939127604166\n",
      "    val_ess        : 1.9601617952187855\n",
      "    val_log_marginal: 715.6298522949219\n",
      "    val_log_joint  : 924.0438690185547\n",
      "Train Epoch: 655 [0/54000 (0%)] Loss: -721.447632\n",
      "Train Epoch: 655 [11264/54000 (21%)] Loss: -724.782104\n",
      "Train Epoch: 655 [22528/54000 (42%)] Loss: -709.481079\n",
      "Train Epoch: 655 [33792/54000 (63%)] Loss: -711.309326\n",
      "Train Epoch: 655 [45056/54000 (83%)] Loss: -692.907471\n",
      "    epoch          : 655\n",
      "    loss           : -712.3026503077093\n",
      "    ess            : 1.9607440683076967\n",
      "    log_marginal   : 712.3369307607975\n",
      "    log_joint      : 920.6615226313753\n",
      "    val_loss       : -716.3555145263672\n",
      "    val_ess        : 1.9593171974023182\n",
      "    val_log_marginal: 716.3905537923177\n",
      "    val_log_joint  : 924.7227630615234\n",
      "Train Epoch: 656 [0/54000 (0%)] Loss: -704.180054\n",
      "Train Epoch: 656 [11264/54000 (21%)] Loss: -723.399902\n",
      "Train Epoch: 656 [22528/54000 (42%)] Loss: -695.625977\n",
      "Train Epoch: 656 [33792/54000 (63%)] Loss: -713.229675\n",
      "Train Epoch: 656 [45056/54000 (83%)] Loss: -703.358521\n",
      "    epoch          : 656\n",
      "    loss           : -712.7144406876474\n",
      "    ess            : 1.9601801498880926\n",
      "    log_marginal   : 712.7500391546286\n",
      "    log_joint      : 921.0970931143131\n",
      "    val_loss       : -716.6878102620443\n",
      "    val_ess        : 1.9608086148897808\n",
      "    val_log_marginal: 716.7216593424479\n",
      "    val_log_joint  : 924.8790639241537\n",
      "Train Epoch: 657 [0/54000 (0%)] Loss: -696.461182\n",
      "Train Epoch: 657 [11264/54000 (21%)] Loss: -704.805298\n",
      "Train Epoch: 657 [22528/54000 (42%)] Loss: -724.701050\n",
      "Train Epoch: 657 [33792/54000 (63%)] Loss: -714.269714\n",
      "Train Epoch: 657 [45056/54000 (83%)] Loss: -726.630737\n",
      "    epoch          : 657\n",
      "    loss           : -712.7746944787367\n",
      "    ess            : 1.9612131816036296\n",
      "    log_marginal   : 712.8074709334463\n",
      "    log_joint      : 921.1400532272627\n",
      "    val_loss       : -716.6520029703776\n",
      "    val_ess        : 1.9611063301563263\n",
      "    val_log_marginal: 716.6869964599609\n",
      "    val_log_joint  : 924.8961385091146\n",
      "Train Epoch: 658 [0/54000 (0%)] Loss: -716.399231\n",
      "Train Epoch: 658 [11264/54000 (21%)] Loss: -698.103210\n",
      "Train Epoch: 658 [22528/54000 (42%)] Loss: -714.966309\n",
      "Train Epoch: 658 [33792/54000 (63%)] Loss: -708.562256\n",
      "Train Epoch: 658 [45056/54000 (83%)] Loss: -709.039673\n",
      "    epoch          : 658\n",
      "    loss           : -713.0214175818102\n",
      "    ess            : 1.9606530565135885\n",
      "    log_marginal   : 713.0557913150427\n",
      "    log_joint      : 921.3526455861218\n",
      "    val_loss       : -717.3108825683594\n",
      "    val_ess        : 1.9599954883257549\n",
      "    val_log_marginal: 717.3460337320963\n",
      "    val_log_joint  : 925.5901590983073\n",
      "Train Epoch: 659 [0/54000 (0%)] Loss: -709.668152\n",
      "Train Epoch: 659 [11264/54000 (21%)] Loss: -691.166382\n",
      "Train Epoch: 659 [22528/54000 (42%)] Loss: -727.370056\n",
      "Train Epoch: 659 [33792/54000 (63%)] Loss: -724.275024\n",
      "Train Epoch: 659 [45056/54000 (83%)] Loss: -729.586426\n",
      "    epoch          : 659\n",
      "    loss           : -713.2034002340065\n",
      "    ess            : 1.961445538502819\n",
      "    log_marginal   : 713.2356814978258\n",
      "    log_joint      : 921.462373553582\n",
      "    val_loss       : -717.0235290527344\n",
      "    val_ess        : 1.9610578616460164\n",
      "    val_log_marginal: 717.0545857747396\n",
      "    val_log_joint  : 925.4489339192709\n",
      "Train Epoch: 660 [0/54000 (0%)] Loss: -748.440796\n",
      "Train Epoch: 660 [11264/54000 (21%)] Loss: -728.414551\n",
      "Train Epoch: 660 [22528/54000 (42%)] Loss: -711.509644\n",
      "Train Epoch: 660 [33792/54000 (63%)] Loss: -698.689880\n",
      "Train Epoch: 660 [45056/54000 (83%)] Loss: -686.165955\n",
      "    epoch          : 660\n",
      "    loss           : -713.3189040849794\n",
      "    ess            : 1.9609372480860296\n",
      "    log_marginal   : 713.3519298625442\n",
      "    log_joint      : 921.6308248267984\n",
      "    val_loss       : -717.8856811523438\n",
      "    val_ess        : 1.9618025819460552\n",
      "    val_log_marginal: 717.9198862711588\n",
      "    val_log_joint  : 926.2044626871744\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch660.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 661 [0/54000 (0%)] Loss: -687.359375\n",
      "Train Epoch: 661 [11264/54000 (21%)] Loss: -713.907593\n",
      "Train Epoch: 661 [22528/54000 (42%)] Loss: -699.943970\n",
      "Train Epoch: 661 [33792/54000 (63%)] Loss: -701.966309\n",
      "Train Epoch: 661 [45056/54000 (83%)] Loss: -723.574707\n",
      "    epoch          : 661\n",
      "    loss           : -713.5257090442585\n",
      "    ess            : 1.9600172436462258\n",
      "    log_marginal   : 713.559137884176\n",
      "    log_joint      : 921.8238905420843\n",
      "    val_loss       : -718.2428181966146\n",
      "    val_ess        : 1.9613168239593506\n",
      "    val_log_marginal: 718.273681640625\n",
      "    val_log_joint  : 926.3845977783203\n",
      "Train Epoch: 662 [0/54000 (0%)] Loss: -705.844666\n",
      "Train Epoch: 662 [11264/54000 (21%)] Loss: -715.526184\n",
      "Train Epoch: 662 [22528/54000 (42%)] Loss: -711.584045\n",
      "Train Epoch: 662 [33792/54000 (63%)] Loss: -735.596802\n",
      "Train Epoch: 662 [45056/54000 (83%)] Loss: -734.158569\n",
      "    epoch          : 662\n",
      "    loss           : -713.6965003823334\n",
      "    ess            : 1.9604285134459443\n",
      "    log_marginal   : 713.7299735591097\n",
      "    log_joint      : 921.9731865648953\n",
      "    val_loss       : -717.5872599283854\n",
      "    val_ess        : 1.9621668954690297\n",
      "    val_log_marginal: 717.6204223632812\n",
      "    val_log_joint  : 925.8634287516276\n",
      "Train Epoch: 663 [0/54000 (0%)] Loss: -731.299072\n",
      "Train Epoch: 663 [11264/54000 (21%)] Loss: -725.744202\n",
      "Train Epoch: 663 [22528/54000 (42%)] Loss: -702.310242\n",
      "Train Epoch: 663 [33792/54000 (63%)] Loss: -709.913696\n",
      "Train Epoch: 663 [45056/54000 (83%)] Loss: -738.380981\n",
      "    epoch          : 663\n",
      "    loss           : -713.9294951816775\n",
      "    ess            : 1.960582530723428\n",
      "    log_marginal   : 713.9627276726488\n",
      "    log_joint      : 922.26004316222\n",
      "    val_loss       : -718.4679260253906\n",
      "    val_ess        : 1.96510977546374\n",
      "    val_log_marginal: 718.4995727539062\n",
      "    val_log_joint  : 926.3306020100912\n",
      "Train Epoch: 664 [0/54000 (0%)] Loss: -706.479614\n",
      "Train Epoch: 664 [11264/54000 (21%)] Loss: -704.255859\n",
      "Train Epoch: 664 [22528/54000 (42%)] Loss: -705.540527\n",
      "Train Epoch: 664 [33792/54000 (63%)] Loss: -708.667969\n",
      "Train Epoch: 664 [45056/54000 (83%)] Loss: -711.987061\n",
      "    epoch          : 664\n",
      "    loss           : -714.168694838038\n",
      "    ess            : 1.9610954759255894\n",
      "    log_marginal   : 714.2020643702093\n",
      "    log_joint      : 922.4837548597803\n",
      "    val_loss       : -717.5477803548177\n",
      "    val_ess        : 1.9583625197410583\n",
      "    val_log_marginal: 717.5813954671224\n",
      "    val_log_joint  : 925.8357340494791\n",
      "Train Epoch: 665 [0/54000 (0%)] Loss: -726.165283\n",
      "Train Epoch: 665 [11264/54000 (21%)] Loss: -727.383301\n",
      "Train Epoch: 665 [22528/54000 (42%)] Loss: -699.605103\n",
      "Train Epoch: 665 [33792/54000 (63%)] Loss: -701.920715\n",
      "Train Epoch: 665 [45056/54000 (83%)] Loss: -720.604797\n",
      "    epoch          : 665\n",
      "    loss           : -714.396455584832\n",
      "    ess            : 1.9606221835568267\n",
      "    log_marginal   : 714.4306767301739\n",
      "    log_joint      : 922.5835410064121\n",
      "    val_loss       : -718.5778249104818\n",
      "    val_ess        : 1.9598039090633392\n",
      "    val_log_marginal: 718.6154022216797\n",
      "    val_log_joint  : 926.6453603108724\n",
      "Train Epoch: 666 [0/54000 (0%)] Loss: -713.264343\n",
      "Train Epoch: 666 [11264/54000 (21%)] Loss: -702.618652\n",
      "Train Epoch: 666 [22528/54000 (42%)] Loss: -699.284790\n",
      "Train Epoch: 666 [33792/54000 (63%)] Loss: -716.347290\n",
      "Train Epoch: 666 [45056/54000 (83%)] Loss: -718.101868\n",
      "    epoch          : 666\n",
      "    loss           : -714.49532620412\n",
      "    ess            : 1.9614552967953232\n",
      "    log_marginal   : 714.5293463940891\n",
      "    log_joint      : 922.8306044092718\n",
      "    val_loss       : -718.1897583007812\n",
      "    val_ess        : 1.9603445132573445\n",
      "    val_log_marginal: 718.2258097330729\n",
      "    val_log_joint  : 926.355214436849\n",
      "Train Epoch: 667 [0/54000 (0%)] Loss: -685.919495\n",
      "Train Epoch: 667 [11264/54000 (21%)] Loss: -734.466431\n",
      "Train Epoch: 667 [22528/54000 (42%)] Loss: -747.941895\n",
      "Train Epoch: 667 [33792/54000 (63%)] Loss: -703.723389\n",
      "Train Epoch: 667 [45056/54000 (83%)] Loss: -720.765137\n",
      "    epoch          : 667\n",
      "    loss           : -714.6561826310068\n",
      "    ess            : 1.9599470642377745\n",
      "    log_marginal   : 714.6903248912884\n",
      "    log_joint      : 922.9000796911852\n",
      "    val_loss       : -718.5520273844401\n",
      "    val_ess        : 1.962203601996104\n",
      "    val_log_marginal: 718.5848083496094\n",
      "    val_log_joint  : 926.8314056396484\n",
      "Train Epoch: 668 [0/54000 (0%)] Loss: -702.135559\n",
      "Train Epoch: 668 [11264/54000 (21%)] Loss: -707.708496\n",
      "Train Epoch: 668 [22528/54000 (42%)] Loss: -729.231689\n",
      "Train Epoch: 668 [33792/54000 (63%)] Loss: -698.719543\n",
      "Train Epoch: 668 [45056/54000 (83%)] Loss: -710.183105\n",
      "    epoch          : 668\n",
      "    loss           : -714.8872329424013\n",
      "    ess            : 1.9602211680052415\n",
      "    log_marginal   : 714.9211926730173\n",
      "    log_joint      : 923.216405904518\n",
      "    val_loss       : -718.7574920654297\n",
      "    val_ess        : 1.9615784684816997\n",
      "    val_log_marginal: 718.7919565836588\n",
      "    val_log_joint  : 926.8280080159506\n",
      "Train Epoch: 669 [0/54000 (0%)] Loss: -712.533203\n",
      "Train Epoch: 669 [11264/54000 (21%)] Loss: -717.596802\n",
      "Train Epoch: 669 [22528/54000 (42%)] Loss: -720.173218\n",
      "Train Epoch: 669 [33792/54000 (63%)] Loss: -709.571899\n",
      "Train Epoch: 669 [45056/54000 (83%)] Loss: -701.615967\n",
      "    epoch          : 669\n",
      "    loss           : -714.8849706109964\n",
      "    ess            : 1.962029664021618\n",
      "    log_marginal   : 714.9167745338297\n",
      "    log_joint      : 923.1020024137677\n",
      "    val_loss       : -719.2373046875\n",
      "    val_ess        : 1.9636664986610413\n",
      "    val_log_marginal: 719.2670949300131\n",
      "    val_log_joint  : 927.5353037516276\n",
      "Train Epoch: 670 [0/54000 (0%)] Loss: -734.588501\n",
      "Train Epoch: 670 [11264/54000 (21%)] Loss: -733.680237\n",
      "Train Epoch: 670 [22528/54000 (42%)] Loss: -722.722412\n",
      "Train Epoch: 670 [33792/54000 (63%)] Loss: -714.593994\n",
      "Train Epoch: 670 [45056/54000 (83%)] Loss: -707.350769\n",
      "    epoch          : 670\n",
      "    loss           : -715.087458196676\n",
      "    ess            : 1.9605767895590585\n",
      "    log_marginal   : 715.1204517292526\n",
      "    log_joint      : 923.5119364036703\n",
      "    val_loss       : -719.0260620117188\n",
      "    val_ess        : 1.95985343058904\n",
      "    val_log_marginal: 719.0615946451823\n",
      "    val_log_joint  : 926.9436238606771\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch670.pth ...\n",
      "Train Epoch: 671 [0/54000 (0%)] Loss: -706.084229\n",
      "Train Epoch: 671 [11264/54000 (21%)] Loss: -703.952942\n",
      "Train Epoch: 671 [22528/54000 (42%)] Loss: -725.984558\n",
      "Train Epoch: 671 [33792/54000 (63%)] Loss: -702.736633\n",
      "Train Epoch: 671 [45056/54000 (83%)] Loss: -729.160339\n",
      "    epoch          : 671\n",
      "    loss           : -715.2305032982016\n",
      "    ess            : 1.9601665442844607\n",
      "    log_marginal   : 715.2644169645489\n",
      "    log_joint      : 923.6306250230322\n",
      "    val_loss       : -719.564707438151\n",
      "    val_ess        : 1.961909035841624\n",
      "    val_log_marginal: 719.5933278401693\n",
      "    val_log_joint  : 927.604482014974\n",
      "Train Epoch: 672 [0/54000 (0%)] Loss: -723.114990\n",
      "Train Epoch: 672 [11264/54000 (21%)] Loss: -711.083801\n",
      "Train Epoch: 672 [22528/54000 (42%)] Loss: -710.227844\n",
      "Train Epoch: 672 [33792/54000 (63%)] Loss: -728.751831\n",
      "Train Epoch: 672 [45056/54000 (83%)] Loss: -733.276123\n",
      "    epoch          : 672\n",
      "    loss           : -715.4576974544885\n",
      "    ess            : 1.9617342195420895\n",
      "    log_marginal   : 715.4900783322892\n",
      "    log_joint      : 923.7908618855026\n",
      "    val_loss       : -719.9584350585938\n",
      "    val_ess        : 1.9629773596922557\n",
      "    val_log_marginal: 719.9881846110026\n",
      "    val_log_joint  : 927.8622131347656\n",
      "Train Epoch: 673 [0/54000 (0%)] Loss: -735.761719\n",
      "Train Epoch: 673 [11264/54000 (21%)] Loss: -717.833374\n",
      "Train Epoch: 673 [22528/54000 (42%)] Loss: -717.350220\n",
      "Train Epoch: 673 [33792/54000 (63%)] Loss: -737.156189\n",
      "Train Epoch: 673 [45056/54000 (83%)] Loss: -716.461792\n",
      "    epoch          : 673\n",
      "    loss           : -715.8759471965286\n",
      "    ess            : 1.961974928963859\n",
      "    log_marginal   : 715.907344602189\n",
      "    log_joint      : 924.1333042360702\n",
      "    val_loss       : -719.1123352050781\n",
      "    val_ess        : 1.963788777589798\n",
      "    val_log_marginal: 719.1445058186849\n",
      "    val_log_joint  : 927.2142791748047\n",
      "Train Epoch: 674 [0/54000 (0%)] Loss: -732.408997\n",
      "Train Epoch: 674 [11264/54000 (21%)] Loss: -713.490051\n",
      "Train Epoch: 674 [22528/54000 (42%)] Loss: -707.856567\n",
      "Train Epoch: 674 [33792/54000 (63%)] Loss: -734.013733\n",
      "Train Epoch: 674 [45056/54000 (83%)] Loss: -726.442383\n",
      "    epoch          : 674\n",
      "    loss           : -715.8266924012382\n",
      "    ess            : 1.9607522712563568\n",
      "    log_marginal   : 715.861348853921\n",
      "    log_joint      : 924.1686384093086\n",
      "    val_loss       : -719.4183044433594\n",
      "    val_ess        : 1.9603784283002217\n",
      "    val_log_marginal: 719.4581705729166\n",
      "    val_log_joint  : 927.7992197672526\n",
      "Train Epoch: 675 [0/54000 (0%)] Loss: -717.928101\n",
      "Train Epoch: 675 [11264/54000 (21%)] Loss: -713.638184\n",
      "Train Epoch: 675 [22528/54000 (42%)] Loss: -713.390747\n",
      "Train Epoch: 675 [33792/54000 (63%)] Loss: -719.315674\n",
      "Train Epoch: 675 [45056/54000 (83%)] Loss: -701.294189\n",
      "    epoch          : 675\n",
      "    loss           : -716.105023654002\n",
      "    ess            : 1.9611690662941843\n",
      "    log_marginal   : 716.138754790684\n",
      "    log_joint      : 924.3258183317364\n",
      "    val_loss       : -720.1873830159506\n",
      "    val_ess        : 1.9580520689487457\n",
      "    val_log_marginal: 720.2248687744141\n",
      "    val_log_joint  : 928.4481709798177\n",
      "Train Epoch: 676 [0/54000 (0%)] Loss: -730.383057\n",
      "Train Epoch: 676 [11264/54000 (21%)] Loss: -721.698608\n",
      "Train Epoch: 676 [22528/54000 (42%)] Loss: -741.323853\n",
      "Train Epoch: 676 [33792/54000 (63%)] Loss: -729.387939\n",
      "Train Epoch: 676 [45056/54000 (83%)] Loss: -718.706848\n",
      "    epoch          : 676\n",
      "    loss           : -716.3262139086453\n",
      "    ess            : 1.9610049589624945\n",
      "    log_marginal   : 716.3600406286852\n",
      "    log_joint      : 924.5516104068396\n",
      "    val_loss       : -720.2521464029948\n",
      "    val_ess        : 1.9584110577901204\n",
      "    val_log_marginal: 720.2881978352865\n",
      "    val_log_joint  : 928.5443013509115\n",
      "Train Epoch: 677 [0/54000 (0%)] Loss: -719.102600\n",
      "Train Epoch: 677 [11264/54000 (21%)] Loss: -725.912842\n",
      "Train Epoch: 677 [22528/54000 (42%)] Loss: -725.078857\n",
      "Train Epoch: 677 [33792/54000 (63%)] Loss: -712.961182\n",
      "Train Epoch: 677 [45056/54000 (83%)] Loss: -721.375732\n",
      "    epoch          : 677\n",
      "    loss           : -716.2347999428803\n",
      "    ess            : 1.9605341846088193\n",
      "    log_marginal   : 716.2693055350826\n",
      "    log_joint      : 924.5352656526386\n",
      "    val_loss       : -720.0637461344401\n",
      "    val_ess        : 1.9622546633084614\n",
      "    val_log_marginal: 720.0923563639323\n",
      "    val_log_joint  : 928.3523406982422\n",
      "Train Epoch: 678 [0/54000 (0%)] Loss: -721.126465\n",
      "Train Epoch: 678 [11264/54000 (21%)] Loss: -706.404419\n",
      "Train Epoch: 678 [22528/54000 (42%)] Loss: -732.651611\n",
      "Train Epoch: 678 [33792/54000 (63%)] Loss: -692.760986\n",
      "Train Epoch: 678 [45056/54000 (83%)] Loss: -708.926025\n",
      "    epoch          : 678\n",
      "    loss           : -716.5672382858564\n",
      "    ess            : 1.961965244896007\n",
      "    log_marginal   : 716.6000982320534\n",
      "    log_joint      : 924.7719709288399\n",
      "    val_loss       : -719.6797637939453\n",
      "    val_ess        : 1.9620280861854553\n",
      "    val_log_marginal: 719.7126159667969\n",
      "    val_log_joint  : 928.1510467529297\n",
      "Train Epoch: 679 [0/54000 (0%)] Loss: -718.690735\n",
      "Train Epoch: 679 [11264/54000 (21%)] Loss: -709.937988\n",
      "Train Epoch: 679 [22528/54000 (42%)] Loss: -728.882324\n",
      "Train Epoch: 679 [33792/54000 (63%)] Loss: -718.969604\n",
      "Train Epoch: 679 [45056/54000 (83%)] Loss: -731.010010\n",
      "    epoch          : 679\n",
      "    loss           : -716.76157998139\n",
      "    ess            : 1.9614207137305781\n",
      "    log_marginal   : 716.7942406996241\n",
      "    log_joint      : 925.1369012796654\n",
      "    val_loss       : -720.9101715087891\n",
      "    val_ess        : 1.9606827398141224\n",
      "    val_log_marginal: 720.9414113362631\n",
      "    val_log_joint  : 929.1382802327474\n",
      "Train Epoch: 680 [0/54000 (0%)] Loss: -722.896118\n",
      "Train Epoch: 680 [11264/54000 (21%)] Loss: -719.625000\n",
      "Train Epoch: 680 [22528/54000 (42%)] Loss: -707.092590\n",
      "Train Epoch: 680 [33792/54000 (63%)] Loss: -716.444336\n",
      "Train Epoch: 680 [45056/54000 (83%)] Loss: -735.947998\n",
      "    epoch          : 680\n",
      "    loss           : -716.7805791890846\n",
      "    ess            : 1.9619340784144852\n",
      "    log_marginal   : 716.813457560989\n",
      "    log_joint      : 925.1912916651312\n",
      "    val_loss       : -721.0233103434244\n",
      "    val_ess        : 1.9636044005552928\n",
      "    val_log_marginal: 721.0546061197916\n",
      "    val_log_joint  : 929.7059631347656\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch680.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 681 [0/54000 (0%)] Loss: -738.631470\n",
      "Train Epoch: 681 [11264/54000 (21%)] Loss: -725.619385\n",
      "Train Epoch: 681 [22528/54000 (42%)] Loss: -709.844849\n",
      "Train Epoch: 681 [33792/54000 (63%)] Loss: -721.142639\n",
      "Train Epoch: 681 [45056/54000 (83%)] Loss: -713.389587\n",
      "    epoch          : 681\n",
      "    loss           : -717.2163465967718\n",
      "    ess            : 1.9616936445236206\n",
      "    log_marginal   : 717.2487942677624\n",
      "    log_joint      : 925.5063775980248\n",
      "    val_loss       : -721.3842213948568\n",
      "    val_ess        : 1.9570239384969075\n",
      "    val_log_marginal: 721.4216766357422\n",
      "    val_log_joint  : 929.6508738199869\n",
      "Train Epoch: 682 [0/54000 (0%)] Loss: -711.921997\n",
      "Train Epoch: 682 [11264/54000 (21%)] Loss: -732.731812\n",
      "Train Epoch: 682 [22528/54000 (42%)] Loss: -750.235718\n",
      "Train Epoch: 682 [33792/54000 (63%)] Loss: -708.092346\n",
      "Train Epoch: 682 [45056/54000 (83%)] Loss: -724.150696\n",
      "    epoch          : 682\n",
      "    loss           : -717.3883148769163\n",
      "    ess            : 1.9612410091004282\n",
      "    log_marginal   : 717.421463300597\n",
      "    log_joint      : 925.7267294829746\n",
      "    val_loss       : -721.7866160074869\n",
      "    val_ess        : 1.9643622537453969\n",
      "    val_log_marginal: 721.8163909912109\n",
      "    val_log_joint  : 930.2464447021484\n",
      "Train Epoch: 683 [0/54000 (0%)] Loss: -723.264771\n",
      "Train Epoch: 683 [11264/54000 (21%)] Loss: -722.023254\n",
      "Train Epoch: 683 [22528/54000 (42%)] Loss: -704.816772\n",
      "Train Epoch: 683 [33792/54000 (63%)] Loss: -715.006348\n",
      "Train Epoch: 683 [45056/54000 (83%)] Loss: -715.425171\n",
      "    epoch          : 683\n",
      "    loss           : -717.4968814489977\n",
      "    ess            : 1.9620659340102717\n",
      "    log_marginal   : 717.5284498682562\n",
      "    log_joint      : 925.7856456828567\n",
      "    val_loss       : -721.600331624349\n",
      "    val_ess        : 1.959612896045049\n",
      "    val_log_marginal: 721.6344299316406\n",
      "    val_log_joint  : 929.8978424072266\n",
      "Train Epoch: 684 [0/54000 (0%)] Loss: -725.537170\n",
      "Train Epoch: 684 [11264/54000 (21%)] Loss: -715.559937\n",
      "Train Epoch: 684 [22528/54000 (42%)] Loss: -711.032104\n",
      "Train Epoch: 684 [33792/54000 (63%)] Loss: -745.856567\n",
      "Train Epoch: 684 [45056/54000 (83%)] Loss: -716.870239\n",
      "    epoch          : 684\n",
      "    loss           : -717.7266166255159\n",
      "    ess            : 1.9613181622523181\n",
      "    log_marginal   : 717.7601145618366\n",
      "    log_joint      : 926.00899980653\n",
      "    val_loss       : -722.566162109375\n",
      "    val_ess        : 1.9622035920619965\n",
      "    val_log_marginal: 722.5999196370443\n",
      "    val_log_joint  : 930.9309387207031\n",
      "Train Epoch: 685 [0/54000 (0%)] Loss: -709.227295\n",
      "Train Epoch: 685 [11264/54000 (21%)] Loss: -737.034485\n",
      "Train Epoch: 685 [22528/54000 (42%)] Loss: -711.930786\n",
      "Train Epoch: 685 [33792/54000 (63%)] Loss: -742.513550\n",
      "Train Epoch: 685 [45056/54000 (83%)] Loss: -718.900879\n",
      "    epoch          : 685\n",
      "    loss           : -717.61335149801\n",
      "    ess            : 1.9609064718462386\n",
      "    log_marginal   : 717.6469185307341\n",
      "    log_joint      : 925.9842938117262\n",
      "    val_loss       : -721.4813283284506\n",
      "    val_ess        : 1.9613969922065735\n",
      "    val_log_marginal: 721.5159556070963\n",
      "    val_log_joint  : 930.1124928792318\n",
      "Train Epoch: 686 [0/54000 (0%)] Loss: -733.360474\n",
      "Train Epoch: 686 [11264/54000 (21%)] Loss: -746.344666\n",
      "Train Epoch: 686 [22528/54000 (42%)] Loss: -737.072266\n",
      "Train Epoch: 686 [33792/54000 (63%)] Loss: -736.106079\n",
      "Train Epoch: 686 [45056/54000 (83%)] Loss: -735.196899\n",
      "    epoch          : 686\n",
      "    loss           : -717.8923466520489\n",
      "    ess            : 1.9605665656755555\n",
      "    log_marginal   : 717.9279698785746\n",
      "    log_joint      : 926.3084319492556\n",
      "    val_loss       : -722.2226155598959\n",
      "    val_ess        : 1.961166908343633\n",
      "    val_log_marginal: 722.2595570882162\n",
      "    val_log_joint  : 930.6168263753256\n",
      "Train Epoch: 687 [0/54000 (0%)] Loss: -719.641541\n",
      "Train Epoch: 687 [11264/54000 (21%)] Loss: -725.382568\n",
      "Train Epoch: 687 [22528/54000 (42%)] Loss: -721.231201\n",
      "Train Epoch: 687 [33792/54000 (63%)] Loss: -720.633362\n",
      "Train Epoch: 687 [45056/54000 (83%)] Loss: -708.215332\n",
      "    epoch          : 687\n",
      "    loss           : -717.867493827388\n",
      "    ess            : 1.9612421876979325\n",
      "    log_marginal   : 717.9010614359154\n",
      "    log_joint      : 926.1666674344045\n",
      "    val_loss       : -721.8282979329427\n",
      "    val_ess        : 1.9616802036762238\n",
      "    val_log_marginal: 721.8650665283203\n",
      "    val_log_joint  : 930.0461120605469\n",
      "Train Epoch: 688 [0/54000 (0%)] Loss: -707.816650\n",
      "Train Epoch: 688 [11264/54000 (21%)] Loss: -740.328735\n",
      "Train Epoch: 688 [22528/54000 (42%)] Loss: -711.781494\n",
      "Train Epoch: 688 [33792/54000 (63%)] Loss: -707.101196\n",
      "Train Epoch: 688 [45056/54000 (83%)] Loss: -692.200195\n",
      "    epoch          : 688\n",
      "    loss           : -718.282901404039\n",
      "    ess            : 1.960583135766803\n",
      "    log_marginal   : 718.3163112424454\n",
      "    log_joint      : 926.6734146981869\n",
      "    val_loss       : -721.747802734375\n",
      "    val_ess        : 1.961347182591756\n",
      "    val_log_marginal: 721.7809448242188\n",
      "    val_log_joint  : 930.1112823486328\n",
      "Train Epoch: 689 [0/54000 (0%)] Loss: -723.536255\n",
      "Train Epoch: 689 [11264/54000 (21%)] Loss: -710.775635\n",
      "Train Epoch: 689 [22528/54000 (42%)] Loss: -724.214722\n",
      "Train Epoch: 689 [33792/54000 (63%)] Loss: -699.471191\n",
      "Train Epoch: 689 [45056/54000 (83%)] Loss: -708.324463\n",
      "    epoch          : 689\n",
      "    loss           : -718.4367796699955\n",
      "    ess            : 1.9599375623577047\n",
      "    log_marginal   : 718.4711891030365\n",
      "    log_joint      : 926.7728950932341\n",
      "    val_loss       : -722.6760406494141\n",
      "    val_ess        : 1.9602131247520447\n",
      "    val_log_marginal: 722.7111256917318\n",
      "    val_log_joint  : 931.0488993326823\n",
      "Train Epoch: 690 [0/54000 (0%)] Loss: -724.554932\n",
      "Train Epoch: 690 [11264/54000 (21%)] Loss: -724.185791\n",
      "Train Epoch: 690 [22528/54000 (42%)] Loss: -720.708130\n",
      "Train Epoch: 690 [33792/54000 (63%)] Loss: -727.469971\n",
      "Train Epoch: 690 [45056/54000 (83%)] Loss: -705.275146\n",
      "    epoch          : 690\n",
      "    loss           : -718.7306846762604\n",
      "    ess            : 1.9609599113464355\n",
      "    log_marginal   : 718.7645810685068\n",
      "    log_joint      : 927.0692075333505\n",
      "    val_loss       : -722.3244222005209\n",
      "    val_ess        : 1.9609078764915466\n",
      "    val_log_marginal: 722.3629252115885\n",
      "    val_log_joint  : 930.6120096842448\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch690.pth ...\n",
      "Train Epoch: 691 [0/54000 (0%)] Loss: -710.576599\n",
      "Train Epoch: 691 [11264/54000 (21%)] Loss: -712.519775\n",
      "Train Epoch: 691 [22528/54000 (42%)] Loss: -717.202759\n",
      "Train Epoch: 691 [33792/54000 (63%)] Loss: -731.433838\n",
      "Train Epoch: 691 [45056/54000 (83%)] Loss: -723.178040\n",
      "    epoch          : 691\n",
      "    loss           : -718.5732911307857\n",
      "    ess            : 1.9600897431373596\n",
      "    log_marginal   : 718.6082187868515\n",
      "    log_joint      : 926.9922796285377\n",
      "    val_loss       : -722.6325225830078\n",
      "    val_ess        : 1.959530194600423\n",
      "    val_log_marginal: 722.6666412353516\n",
      "    val_log_joint  : 930.7171427408854\n",
      "Train Epoch: 692 [0/54000 (0%)] Loss: -726.089111\n",
      "Train Epoch: 692 [11264/54000 (21%)] Loss: -715.014832\n",
      "Train Epoch: 692 [22528/54000 (42%)] Loss: -737.840576\n",
      "Train Epoch: 692 [33792/54000 (63%)] Loss: -726.000488\n",
      "Train Epoch: 692 [45056/54000 (83%)] Loss: -725.891479\n",
      "    epoch          : 692\n",
      "    loss           : -718.9300214659493\n",
      "    ess            : 1.9613409087343037\n",
      "    log_marginal   : 718.9631572219561\n",
      "    log_joint      : 927.1660467183815\n",
      "    val_loss       : -723.2855021158854\n",
      "    val_ess        : 1.9620174765586853\n",
      "    val_log_marginal: 723.3214823404948\n",
      "    val_log_joint  : 931.2661590576172\n",
      "Train Epoch: 693 [0/54000 (0%)] Loss: -720.705444\n",
      "Train Epoch: 693 [11264/54000 (21%)] Loss: -736.208374\n",
      "Train Epoch: 693 [22528/54000 (42%)] Loss: -713.585449\n",
      "Train Epoch: 693 [33792/54000 (63%)] Loss: -715.344788\n",
      "Train Epoch: 693 [45056/54000 (83%)] Loss: -697.199951\n",
      "    epoch          : 693\n",
      "    loss           : -719.2334364405218\n",
      "    ess            : 1.9614291359793465\n",
      "    log_marginal   : 719.2676973162957\n",
      "    log_joint      : 927.5457970961085\n",
      "    val_loss       : -722.8488464355469\n",
      "    val_ess        : 1.9631424248218536\n",
      "    val_log_marginal: 722.8779296875\n",
      "    val_log_joint  : 931.0264638264974\n",
      "Train Epoch: 694 [0/54000 (0%)] Loss: -752.026611\n",
      "Train Epoch: 694 [11264/54000 (21%)] Loss: -705.885132\n",
      "Train Epoch: 694 [22528/54000 (42%)] Loss: -727.532104\n",
      "Train Epoch: 694 [33792/54000 (63%)] Loss: -716.640076\n",
      "Train Epoch: 694 [45056/54000 (83%)] Loss: -701.987244\n",
      "    epoch          : 694\n",
      "    loss           : -719.3622557442143\n",
      "    ess            : 1.959489477130602\n",
      "    log_marginal   : 719.3975340645268\n",
      "    log_joint      : 927.718553651054\n",
      "    val_loss       : -723.73291015625\n",
      "    val_ess        : 1.9609294335047405\n",
      "    val_log_marginal: 723.7655944824219\n",
      "    val_log_joint  : 932.006337483724\n",
      "Train Epoch: 695 [0/54000 (0%)] Loss: -715.924072\n",
      "Train Epoch: 695 [11264/54000 (21%)] Loss: -726.072510\n",
      "Train Epoch: 695 [22528/54000 (42%)] Loss: -734.101929\n",
      "Train Epoch: 695 [33792/54000 (63%)] Loss: -728.645020\n",
      "Train Epoch: 695 [45056/54000 (83%)] Loss: -740.878662\n",
      "    epoch          : 695\n",
      "    loss           : -719.5186531498747\n",
      "    ess            : 1.9606725247401111\n",
      "    log_marginal   : 719.5531616210938\n",
      "    log_joint      : 927.9460454976784\n",
      "    val_loss       : -723.6741027832031\n",
      "    val_ess        : 1.9590466817220051\n",
      "    val_log_marginal: 723.7106119791666\n",
      "    val_log_joint  : 931.8141937255859\n",
      "Train Epoch: 696 [0/54000 (0%)] Loss: -734.806946\n",
      "Train Epoch: 696 [11264/54000 (21%)] Loss: -721.226013\n",
      "Train Epoch: 696 [22528/54000 (42%)] Loss: -729.595581\n",
      "Train Epoch: 696 [33792/54000 (63%)] Loss: -716.736694\n",
      "Train Epoch: 696 [45056/54000 (83%)] Loss: -720.200378\n",
      "    epoch          : 696\n",
      "    loss           : -719.649615017873\n",
      "    ess            : 1.9615378582252647\n",
      "    log_marginal   : 719.6815404352152\n",
      "    log_joint      : 927.955456427808\n",
      "    val_loss       : -723.0272064208984\n",
      "    val_ess        : 1.9595960676670074\n",
      "    val_log_marginal: 723.0637715657552\n",
      "    val_log_joint  : 931.4192047119141\n",
      "Train Epoch: 697 [0/54000 (0%)] Loss: -730.352051\n",
      "Train Epoch: 697 [11264/54000 (21%)] Loss: -711.772827\n",
      "Train Epoch: 697 [22528/54000 (42%)] Loss: -704.774109\n",
      "Train Epoch: 697 [33792/54000 (63%)] Loss: -727.031799\n",
      "Train Epoch: 697 [45056/54000 (83%)] Loss: -716.851379\n",
      "    epoch          : 697\n",
      "    loss           : -719.8403015136719\n",
      "    ess            : 1.9617427969878574\n",
      "    log_marginal   : 719.872914440227\n",
      "    log_joint      : 928.2325474001327\n",
      "    val_loss       : -723.4171091715494\n",
      "    val_ess        : 1.9579278230667114\n",
      "    val_log_marginal: 723.4555155436198\n",
      "    val_log_joint  : 932.0388946533203\n",
      "Train Epoch: 698 [0/54000 (0%)] Loss: -722.479309\n",
      "Train Epoch: 698 [11264/54000 (21%)] Loss: -731.769958\n",
      "Train Epoch: 698 [22528/54000 (42%)] Loss: -724.829834\n",
      "Train Epoch: 698 [33792/54000 (63%)] Loss: -704.523560\n",
      "Train Epoch: 698 [45056/54000 (83%)] Loss: -711.083496\n",
      "    epoch          : 698\n",
      "    loss           : -720.0927100991303\n",
      "    ess            : 1.9604274124469396\n",
      "    log_marginal   : 720.126164850199\n",
      "    log_joint      : 928.5024310417895\n",
      "    val_loss       : -724.5663808186849\n",
      "    val_ess        : 1.9631250500679016\n",
      "    val_log_marginal: 724.5975189208984\n",
      "    val_log_joint  : 932.9859161376953\n",
      "Train Epoch: 699 [0/54000 (0%)] Loss: -719.645142\n",
      "Train Epoch: 699 [11264/54000 (21%)] Loss: -695.128906\n",
      "Train Epoch: 699 [22528/54000 (42%)] Loss: -725.811401\n",
      "Train Epoch: 699 [33792/54000 (63%)] Loss: -713.894775\n",
      "Train Epoch: 699 [45056/54000 (83%)] Loss: -719.569702\n",
      "    epoch          : 699\n",
      "    loss           : -720.2351811247052\n",
      "    ess            : 1.9612461890814439\n",
      "    log_marginal   : 720.2686370273806\n",
      "    log_joint      : 928.5976671902639\n",
      "    val_loss       : -724.6707204182943\n",
      "    val_ess        : 1.9642429848512013\n",
      "    val_log_marginal: 724.7003631591797\n",
      "    val_log_joint  : 932.8627726236979\n",
      "Train Epoch: 700 [0/54000 (0%)] Loss: -721.851013\n",
      "Train Epoch: 700 [11264/54000 (21%)] Loss: -718.863403\n",
      "Train Epoch: 700 [22528/54000 (42%)] Loss: -717.263977\n",
      "Train Epoch: 700 [33792/54000 (63%)] Loss: -729.486328\n",
      "Train Epoch: 700 [45056/54000 (83%)] Loss: -722.435425\n",
      "    epoch          : 700\n",
      "    loss           : -720.488171271558\n",
      "    ess            : 1.9596484663351528\n",
      "    log_marginal   : 720.5221776422464\n",
      "    log_joint      : 928.8168507701946\n",
      "    val_loss       : -725.0372060139974\n",
      "    val_ess        : 1.962209979693095\n",
      "    val_log_marginal: 725.0696767171224\n",
      "    val_log_joint  : 933.4006144205729\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch700.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 701 [0/54000 (0%)] Loss: -748.568115\n",
      "Train Epoch: 701 [11264/54000 (21%)] Loss: -734.253235\n",
      "Train Epoch: 701 [22528/54000 (42%)] Loss: -697.340820\n",
      "Train Epoch: 701 [33792/54000 (63%)] Loss: -733.773254\n",
      "Train Epoch: 701 [45056/54000 (83%)] Loss: -732.195557\n",
      "    epoch          : 701\n",
      "    loss           : -720.4617326844414\n",
      "    ess            : 1.961034338429289\n",
      "    log_marginal   : 720.4962601571713\n",
      "    log_joint      : 928.751618007444\n",
      "    val_loss       : -724.2444051106771\n",
      "    val_ess        : 1.9663409690062206\n",
      "    val_log_marginal: 724.2742513020834\n",
      "    val_log_joint  : 932.3351084391276\n",
      "Train Epoch: 702 [0/54000 (0%)] Loss: -741.785828\n",
      "Train Epoch: 702 [11264/54000 (21%)] Loss: -712.712585\n",
      "Train Epoch: 702 [22528/54000 (42%)] Loss: -721.625732\n",
      "Train Epoch: 702 [33792/54000 (63%)] Loss: -738.950378\n",
      "Train Epoch: 702 [45056/54000 (83%)] Loss: -719.685181\n",
      "    epoch          : 702\n",
      "    loss           : -720.6237044424381\n",
      "    ess            : 1.9605526474286925\n",
      "    log_marginal   : 720.6577332694576\n",
      "    log_joint      : 928.9812898455925\n",
      "    val_loss       : -725.2526194254557\n",
      "    val_ess        : 1.9627316097418468\n",
      "    val_log_marginal: 725.2826334635416\n",
      "    val_log_joint  : 933.259521484375\n",
      "Train Epoch: 703 [0/54000 (0%)] Loss: -727.403259\n",
      "Train Epoch: 703 [11264/54000 (21%)] Loss: -723.637329\n",
      "Train Epoch: 703 [22528/54000 (42%)] Loss: -709.454834\n",
      "Train Epoch: 703 [33792/54000 (63%)] Loss: -734.119019\n",
      "Train Epoch: 703 [45056/54000 (83%)] Loss: -738.108948\n",
      "    epoch          : 703\n",
      "    loss           : -721.1099496517542\n",
      "    ess            : 1.959796574880492\n",
      "    log_marginal   : 721.1449118560215\n",
      "    log_joint      : 929.4675246904482\n",
      "    val_loss       : -724.6644694010416\n",
      "    val_ess        : 1.959380219380061\n",
      "    val_log_marginal: 724.6962738037109\n",
      "    val_log_joint  : 933.0819498697916\n",
      "Train Epoch: 704 [0/54000 (0%)] Loss: -744.161499\n",
      "Train Epoch: 704 [11264/54000 (21%)] Loss: -729.742065\n",
      "Train Epoch: 704 [22528/54000 (42%)] Loss: -722.929749\n",
      "Train Epoch: 704 [33792/54000 (63%)] Loss: -709.914307\n",
      "Train Epoch: 704 [45056/54000 (83%)] Loss: -711.346924\n",
      "    epoch          : 704\n",
      "    loss           : -721.0926692170917\n",
      "    ess            : 1.9612616716690783\n",
      "    log_marginal   : 721.1260790554983\n",
      "    log_joint      : 929.4660264501032\n",
      "    val_loss       : -724.4171803792318\n",
      "    val_ess        : 1.9596977432568867\n",
      "    val_log_marginal: 724.453379313151\n",
      "    val_log_joint  : 932.7406616210938\n",
      "Train Epoch: 705 [0/54000 (0%)] Loss: -703.022949\n",
      "Train Epoch: 705 [11264/54000 (21%)] Loss: -715.794189\n",
      "Train Epoch: 705 [22528/54000 (42%)] Loss: -718.548462\n",
      "Train Epoch: 705 [33792/54000 (63%)] Loss: -708.106201\n",
      "Train Epoch: 705 [45056/54000 (83%)] Loss: -750.011292\n",
      "    epoch          : 705\n",
      "    loss           : -721.1462552052624\n",
      "    ess            : 1.9606671119635959\n",
      "    log_marginal   : 721.1804544700766\n",
      "    log_joint      : 929.5760428950472\n",
      "    val_loss       : -724.4695332845052\n",
      "    val_ess        : 1.9644688566525776\n",
      "    val_log_marginal: 724.5026143391927\n",
      "    val_log_joint  : 932.8365173339844\n",
      "Train Epoch: 706 [0/54000 (0%)] Loss: -718.086304\n",
      "Train Epoch: 706 [11264/54000 (21%)] Loss: -725.329834\n",
      "Train Epoch: 706 [22528/54000 (42%)] Loss: -712.517517\n",
      "Train Epoch: 706 [33792/54000 (63%)] Loss: -720.011597\n",
      "Train Epoch: 706 [45056/54000 (83%)] Loss: -696.926453\n",
      "    epoch          : 706\n",
      "    loss           : -721.4606847223246\n",
      "    ess            : 1.9607844780076225\n",
      "    log_marginal   : 721.4957177504053\n",
      "    log_joint      : 929.7850698794958\n",
      "    val_loss       : -725.2677154541016\n",
      "    val_ess        : 1.958536167939504\n",
      "    val_log_marginal: 725.3015747070312\n",
      "    val_log_joint  : 933.6083424886068\n",
      "Train Epoch: 707 [0/54000 (0%)] Loss: -711.884766\n",
      "Train Epoch: 707 [11264/54000 (21%)] Loss: -725.450806\n",
      "Train Epoch: 707 [22528/54000 (42%)] Loss: -739.462769\n",
      "Train Epoch: 707 [33792/54000 (63%)] Loss: -700.766968\n",
      "Train Epoch: 707 [45056/54000 (83%)] Loss: -711.430115\n",
      "    epoch          : 707\n",
      "    loss           : -721.5197299021595\n",
      "    ess            : 1.9611978935745527\n",
      "    log_marginal   : 721.5524810215212\n",
      "    log_joint      : 929.8573890542084\n",
      "    val_loss       : -725.7681477864584\n",
      "    val_ess        : 1.9632761180400848\n",
      "    val_log_marginal: 725.7970835367838\n",
      "    val_log_joint  : 934.0976053873698\n",
      "Train Epoch: 708 [0/54000 (0%)] Loss: -727.548462\n",
      "Train Epoch: 708 [11264/54000 (21%)] Loss: -711.416260\n",
      "Train Epoch: 708 [22528/54000 (42%)] Loss: -714.262756\n",
      "Train Epoch: 708 [33792/54000 (63%)] Loss: -716.811890\n",
      "Train Epoch: 708 [45056/54000 (83%)] Loss: -697.630615\n",
      "    epoch          : 708\n",
      "    loss           : -721.7093310086233\n",
      "    ess            : 1.9605518489513758\n",
      "    log_marginal   : 721.7430264454968\n",
      "    log_joint      : 930.0187590976931\n",
      "    val_loss       : -725.0945434570312\n",
      "    val_ess        : 1.9568578203519185\n",
      "    val_log_marginal: 725.1357879638672\n",
      "    val_log_joint  : 933.5472310384115\n",
      "Train Epoch: 709 [0/54000 (0%)] Loss: -722.558105\n",
      "Train Epoch: 709 [11264/54000 (21%)] Loss: -725.085205\n",
      "Train Epoch: 709 [22528/54000 (42%)] Loss: -719.314575\n",
      "Train Epoch: 709 [33792/54000 (63%)] Loss: -731.298096\n",
      "Train Epoch: 709 [45056/54000 (83%)] Loss: -708.052368\n",
      "    epoch          : 709\n",
      "    loss           : -721.8759518029555\n",
      "    ess            : 1.960323473192611\n",
      "    log_marginal   : 721.9105961637677\n",
      "    log_joint      : 930.1615853939417\n",
      "    val_loss       : -725.7796122233073\n",
      "    val_ess        : 1.9633926649888356\n",
      "    val_log_marginal: 725.8105163574219\n",
      "    val_log_joint  : 934.149403889974\n",
      "Train Epoch: 710 [0/54000 (0%)] Loss: -736.868042\n",
      "Train Epoch: 710 [11264/54000 (21%)] Loss: -727.710693\n",
      "Train Epoch: 710 [22528/54000 (42%)] Loss: -705.194275\n",
      "Train Epoch: 710 [33792/54000 (63%)] Loss: -733.004517\n",
      "Train Epoch: 710 [45056/54000 (83%)] Loss: -700.506531\n",
      "    epoch          : 710\n",
      "    loss           : -721.8859972683889\n",
      "    ess            : 1.959897572139524\n",
      "    log_marginal   : 721.9215600355616\n",
      "    log_joint      : 930.3125927043411\n",
      "    val_loss       : -725.3498077392578\n",
      "    val_ess        : 1.9599449634552002\n",
      "    val_log_marginal: 725.3841603597006\n",
      "    val_log_joint  : 933.6195933024088\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch710.pth ...\n",
      "Train Epoch: 711 [0/54000 (0%)] Loss: -714.599976\n",
      "Train Epoch: 711 [11264/54000 (21%)] Loss: -733.211731\n",
      "Train Epoch: 711 [22528/54000 (42%)] Loss: -699.787537\n",
      "Train Epoch: 711 [33792/54000 (63%)] Loss: -733.536255\n",
      "Train Epoch: 711 [45056/54000 (83%)] Loss: -716.870117\n",
      "    epoch          : 711\n",
      "    loss           : -722.0061812490787\n",
      "    ess            : 1.9607243909026093\n",
      "    log_marginal   : 722.0399118099573\n",
      "    log_joint      : 930.3572088277565\n",
      "    val_loss       : -725.9453430175781\n",
      "    val_ess        : 1.9597266912460327\n",
      "    val_log_marginal: 725.9806315104166\n",
      "    val_log_joint  : 934.2010345458984\n",
      "Train Epoch: 712 [0/54000 (0%)] Loss: -722.080200\n",
      "Train Epoch: 712 [11264/54000 (21%)] Loss: -733.659607\n",
      "Train Epoch: 712 [22528/54000 (42%)] Loss: -727.687805\n",
      "Train Epoch: 712 [33792/54000 (63%)] Loss: -739.771667\n",
      "Train Epoch: 712 [45056/54000 (83%)] Loss: -726.191772\n",
      "    epoch          : 712\n",
      "    loss           : -722.2623440724499\n",
      "    ess            : 1.9608632922172546\n",
      "    log_marginal   : 722.2957936412884\n",
      "    log_joint      : 930.655086877211\n",
      "    val_loss       : -725.7096303304037\n",
      "    val_ess        : 1.9615736305713654\n",
      "    val_log_marginal: 725.743642171224\n",
      "    val_log_joint  : 933.9989624023438\n",
      "Train Epoch: 713 [0/54000 (0%)] Loss: -716.728455\n",
      "Train Epoch: 713 [11264/54000 (21%)] Loss: -723.849243\n",
      "Train Epoch: 713 [22528/54000 (42%)] Loss: -730.886475\n",
      "Train Epoch: 713 [33792/54000 (63%)] Loss: -714.932373\n",
      "Train Epoch: 713 [45056/54000 (83%)] Loss: -723.610840\n",
      "    epoch          : 713\n",
      "    loss           : -722.6029064250442\n",
      "    ess            : 1.9606183182518437\n",
      "    log_marginal   : 722.6364101193985\n",
      "    log_joint      : 930.8596018665241\n",
      "    val_loss       : -726.7233835856119\n",
      "    val_ess        : 1.960123250881831\n",
      "    val_log_marginal: 726.7555287679037\n",
      "    val_log_joint  : 935.1926727294922\n",
      "Train Epoch: 714 [0/54000 (0%)] Loss: -736.677002\n",
      "Train Epoch: 714 [11264/54000 (21%)] Loss: -717.834351\n",
      "Train Epoch: 714 [22528/54000 (42%)] Loss: -746.326172\n",
      "Train Epoch: 714 [33792/54000 (63%)] Loss: -716.418823\n",
      "Train Epoch: 714 [45056/54000 (83%)] Loss: -719.959473\n",
      "    epoch          : 714\n",
      "    loss           : -722.4485634857754\n",
      "    ess            : 1.960947889202046\n",
      "    log_marginal   : 722.4814314932194\n",
      "    log_joint      : 930.8006148428287\n",
      "    val_loss       : -726.6233367919922\n",
      "    val_ess        : 1.9598292509714763\n",
      "    val_log_marginal: 726.6587829589844\n",
      "    val_log_joint  : 934.8222401936849\n",
      "Train Epoch: 715 [0/54000 (0%)] Loss: -705.966370\n",
      "Train Epoch: 715 [11264/54000 (21%)] Loss: -710.330322\n",
      "Train Epoch: 715 [22528/54000 (42%)] Loss: -743.488403\n",
      "Train Epoch: 715 [33792/54000 (63%)] Loss: -736.787292\n",
      "Train Epoch: 715 [45056/54000 (83%)] Loss: -712.036438\n",
      "    epoch          : 715\n",
      "    loss           : -722.6697324356943\n",
      "    ess            : 1.9602246835546673\n",
      "    log_marginal   : 722.7050666089328\n",
      "    log_joint      : 931.0123705594045\n",
      "    val_loss       : -726.6063232421875\n",
      "    val_ess        : 1.9622383217016857\n",
      "    val_log_marginal: 726.6407623291016\n",
      "    val_log_joint  : 934.7419026692709\n",
      "Train Epoch: 716 [0/54000 (0%)] Loss: -717.136780\n",
      "Train Epoch: 716 [11264/54000 (21%)] Loss: -713.104187\n",
      "Train Epoch: 716 [22528/54000 (42%)] Loss: -733.994995\n",
      "Train Epoch: 716 [33792/54000 (63%)] Loss: -701.121216\n",
      "Train Epoch: 716 [45056/54000 (83%)] Loss: -731.499756\n",
      "    epoch          : 716\n",
      "    loss           : -722.9648569934773\n",
      "    ess            : 1.9608397764979668\n",
      "    log_marginal   : 722.9982253740419\n",
      "    log_joint      : 931.2895663279407\n",
      "    val_loss       : -727.3451690673828\n",
      "    val_ess        : 1.9624509116013844\n",
      "    val_log_marginal: 727.3770904541016\n",
      "    val_log_joint  : 935.8779551188151\n",
      "Train Epoch: 717 [0/54000 (0%)] Loss: -728.202759\n",
      "Train Epoch: 717 [11264/54000 (21%)] Loss: -700.662659\n",
      "Train Epoch: 717 [22528/54000 (42%)] Loss: -733.388550\n",
      "Train Epoch: 717 [33792/54000 (63%)] Loss: -736.947449\n",
      "Train Epoch: 717 [45056/54000 (83%)] Loss: -731.921448\n",
      "    epoch          : 717\n",
      "    loss           : -722.9609507434773\n",
      "    ess            : 1.9605892131913383\n",
      "    log_marginal   : 722.9948644098246\n",
      "    log_joint      : 931.3647386083063\n",
      "    val_loss       : -727.3117370605469\n",
      "    val_ess        : 1.9596301019191742\n",
      "    val_log_marginal: 727.3482615152994\n",
      "    val_log_joint  : 935.6298675537109\n",
      "Train Epoch: 718 [0/54000 (0%)] Loss: -691.176575\n",
      "Train Epoch: 718 [11264/54000 (21%)] Loss: -727.012695\n",
      "Train Epoch: 718 [22528/54000 (42%)] Loss: -726.203613\n",
      "Train Epoch: 718 [33792/54000 (63%)] Loss: -744.466675\n",
      "Train Epoch: 718 [45056/54000 (83%)] Loss: -749.398010\n",
      "    epoch          : 718\n",
      "    loss           : -723.0922840046433\n",
      "    ess            : 1.9605929356700968\n",
      "    log_marginal   : 723.1265661851415\n",
      "    log_joint      : 931.3638086858786\n",
      "    val_loss       : -727.2282307942709\n",
      "    val_ess        : 1.9619323213895161\n",
      "    val_log_marginal: 727.2597503662109\n",
      "    val_log_joint  : 935.7290242513021\n",
      "Train Epoch: 719 [0/54000 (0%)] Loss: -712.334229\n",
      "Train Epoch: 719 [11264/54000 (21%)] Loss: -761.799438\n",
      "Train Epoch: 719 [22528/54000 (42%)] Loss: -714.076660\n",
      "Train Epoch: 719 [33792/54000 (63%)] Loss: -699.253418\n",
      "Train Epoch: 719 [45056/54000 (83%)] Loss: -721.655518\n",
      "    epoch          : 719\n",
      "    loss           : -723.3383282355543\n",
      "    ess            : 1.9606554913070966\n",
      "    log_marginal   : 723.373193704857\n",
      "    log_joint      : 931.6346078548792\n",
      "    val_loss       : -726.8198750813802\n",
      "    val_ess        : 1.9608445763587952\n",
      "    val_log_marginal: 726.8534088134766\n",
      "    val_log_joint  : 935.1389719645182\n",
      "Train Epoch: 720 [0/54000 (0%)] Loss: -698.099609\n",
      "Train Epoch: 720 [11264/54000 (21%)] Loss: -711.323486\n",
      "Train Epoch: 720 [22528/54000 (42%)] Loss: -712.487305\n",
      "Train Epoch: 720 [33792/54000 (63%)] Loss: -723.723877\n",
      "Train Epoch: 720 [45056/54000 (83%)] Loss: -730.673401\n",
      "    epoch          : 720\n",
      "    loss           : -723.3721163767689\n",
      "    ess            : 1.9614550628752079\n",
      "    log_marginal   : 723.405895880933\n",
      "    log_joint      : 931.7245552494841\n",
      "    val_loss       : -728.2278340657552\n",
      "    val_ess        : 1.9617941280206044\n",
      "    val_log_marginal: 728.2590993245443\n",
      "    val_log_joint  : 936.395029703776\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch720.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 721 [0/54000 (0%)] Loss: -731.483337\n",
      "Train Epoch: 721 [11264/54000 (21%)] Loss: -708.297485\n",
      "Train Epoch: 721 [22528/54000 (42%)] Loss: -713.452759\n",
      "Train Epoch: 721 [33792/54000 (63%)] Loss: -706.189331\n",
      "Train Epoch: 721 [45056/54000 (83%)] Loss: -714.918457\n",
      "    epoch          : 721\n",
      "    loss           : -723.8980655310289\n",
      "    ess            : 1.960401809440469\n",
      "    log_marginal   : 723.9333294562574\n",
      "    log_joint      : 932.2641687933004\n",
      "    val_loss       : -727.0265757242838\n",
      "    val_ess        : 1.962506393591563\n",
      "    val_log_marginal: 727.0560302734375\n",
      "    val_log_joint  : 935.4827016194662\n",
      "Train Epoch: 722 [0/54000 (0%)] Loss: -709.296875\n",
      "Train Epoch: 722 [11264/54000 (21%)] Loss: -725.302490\n",
      "Train Epoch: 722 [22528/54000 (42%)] Loss: -707.915100\n",
      "Train Epoch: 722 [33792/54000 (63%)] Loss: -722.700867\n",
      "Train Epoch: 722 [45056/54000 (83%)] Loss: -748.666626\n",
      "    epoch          : 722\n",
      "    loss           : -723.8408594671286\n",
      "    ess            : 1.961363357193065\n",
      "    log_marginal   : 723.8744915656324\n",
      "    log_joint      : 932.2693337494472\n",
      "    val_loss       : -728.0203348795573\n",
      "    val_ess        : 1.9582016468048096\n",
      "    val_log_marginal: 728.0595092773438\n",
      "    val_log_joint  : 936.5469563802084\n",
      "Train Epoch: 723 [0/54000 (0%)] Loss: -730.487122\n",
      "Train Epoch: 723 [11264/54000 (21%)] Loss: -725.187805\n",
      "Train Epoch: 723 [22528/54000 (42%)] Loss: -715.757324\n",
      "Train Epoch: 723 [33792/54000 (63%)] Loss: -728.116699\n",
      "Train Epoch: 723 [45056/54000 (83%)] Loss: -692.278320\n",
      "    epoch          : 723\n",
      "    loss           : -724.1995400482754\n",
      "    ess            : 1.9601539294674712\n",
      "    log_marginal   : 724.235337167416\n",
      "    log_joint      : 932.4943507932267\n",
      "    val_loss       : -727.9476267496744\n",
      "    val_ess        : 1.96343790491422\n",
      "    val_log_marginal: 727.9801839192709\n",
      "    val_log_joint  : 936.4040171305338\n",
      "Train Epoch: 724 [0/54000 (0%)] Loss: -753.194702\n",
      "Train Epoch: 724 [11264/54000 (21%)] Loss: -736.080811\n",
      "Train Epoch: 724 [22528/54000 (42%)] Loss: -745.198975\n",
      "Train Epoch: 724 [33792/54000 (63%)] Loss: -730.543335\n",
      "Train Epoch: 724 [45056/54000 (83%)] Loss: -729.249512\n",
      "    epoch          : 724\n",
      "    loss           : -724.3475543328051\n",
      "    ess            : 1.9608881349833507\n",
      "    log_marginal   : 724.3823979215802\n",
      "    log_joint      : 932.6488307736954\n",
      "    val_loss       : -728.2699737548828\n",
      "    val_ess        : 1.9645334879557292\n",
      "    val_log_marginal: 728.3018747965494\n",
      "    val_log_joint  : 936.5669301350912\n",
      "Train Epoch: 725 [0/54000 (0%)] Loss: -715.816284\n",
      "Train Epoch: 725 [11264/54000 (21%)] Loss: -714.455078\n",
      "Train Epoch: 725 [22528/54000 (42%)] Loss: -737.750977\n",
      "Train Epoch: 725 [33792/54000 (63%)] Loss: -727.985107\n",
      "Train Epoch: 725 [45056/54000 (83%)] Loss: -735.727966\n",
      "    epoch          : 725\n",
      "    loss           : -724.2137681493219\n",
      "    ess            : 1.961400033168073\n",
      "    log_marginal   : 724.2479645351194\n",
      "    log_joint      : 932.5144256015993\n",
      "    val_loss       : -728.6027425130209\n",
      "    val_ess        : 1.9597342411677043\n",
      "    val_log_marginal: 728.6368509928385\n",
      "    val_log_joint  : 936.9093983968099\n",
      "Train Epoch: 726 [0/54000 (0%)] Loss: -729.380859\n",
      "Train Epoch: 726 [11264/54000 (21%)] Loss: -723.770325\n",
      "Train Epoch: 726 [22528/54000 (42%)] Loss: -735.598755\n",
      "Train Epoch: 726 [33792/54000 (63%)] Loss: -726.417419\n",
      "Train Epoch: 726 [45056/54000 (83%)] Loss: -715.156067\n",
      "    epoch          : 726\n",
      "    loss           : -724.5359836794296\n",
      "    ess            : 1.9616300171276309\n",
      "    log_marginal   : 724.569662993809\n",
      "    log_joint      : 932.8985676315596\n",
      "    val_loss       : -728.7217966715494\n",
      "    val_ess        : 1.9626607199509938\n",
      "    val_log_marginal: 728.7519582112631\n",
      "    val_log_joint  : 937.2963612874349\n",
      "Train Epoch: 727 [0/54000 (0%)] Loss: -734.531616\n",
      "Train Epoch: 727 [11264/54000 (21%)] Loss: -717.990845\n",
      "Train Epoch: 727 [22528/54000 (42%)] Loss: -732.911743\n",
      "Train Epoch: 727 [33792/54000 (63%)] Loss: -731.099792\n",
      "Train Epoch: 727 [45056/54000 (83%)] Loss: -743.680298\n",
      "    epoch          : 727\n",
      "    loss           : -724.662192290684\n",
      "    ess            : 1.9600127980394184\n",
      "    log_marginal   : 724.6975005527712\n",
      "    log_joint      : 933.0220025980248\n",
      "    val_loss       : -729.3892211914062\n",
      "    val_ess        : 1.96585214138031\n",
      "    val_log_marginal: 729.4203186035156\n",
      "    val_log_joint  : 937.5379689534506\n",
      "Train Epoch: 728 [0/54000 (0%)] Loss: -726.871887\n",
      "Train Epoch: 728 [11264/54000 (21%)] Loss: -713.101318\n",
      "Train Epoch: 728 [22528/54000 (42%)] Loss: -737.385864\n",
      "Train Epoch: 728 [33792/54000 (63%)] Loss: -735.979431\n",
      "Train Epoch: 728 [45056/54000 (83%)] Loss: -729.127808\n",
      "    epoch          : 728\n",
      "    loss           : -724.63330078125\n",
      "    ess            : 1.9615247564495735\n",
      "    log_marginal   : 724.6675063799013\n",
      "    log_joint      : 933.0623232283682\n",
      "    val_loss       : -729.0645599365234\n",
      "    val_ess        : 1.962196797132492\n",
      "    val_log_marginal: 729.0995127360026\n",
      "    val_log_joint  : 937.5730845133463\n",
      "Train Epoch: 729 [0/54000 (0%)] Loss: -731.256958\n",
      "Train Epoch: 729 [11264/54000 (21%)] Loss: -711.835266\n",
      "Train Epoch: 729 [22528/54000 (42%)] Loss: -719.833801\n",
      "Train Epoch: 729 [33792/54000 (63%)] Loss: -727.870972\n",
      "Train Epoch: 729 [45056/54000 (83%)] Loss: -729.921021\n",
      "    epoch          : 729\n",
      "    loss           : -724.8704125746241\n",
      "    ess            : 1.960270714085057\n",
      "    log_marginal   : 724.9053275630159\n",
      "    log_joint      : 933.3099445846846\n",
      "    val_loss       : -728.8888295491537\n",
      "    val_ess        : 1.9625501036643982\n",
      "    val_log_marginal: 728.9217681884766\n",
      "    val_log_joint  : 937.4617869059244\n",
      "Train Epoch: 730 [0/54000 (0%)] Loss: -708.967163\n",
      "Train Epoch: 730 [11264/54000 (21%)] Loss: -720.695435\n",
      "Train Epoch: 730 [22528/54000 (42%)] Loss: -722.921631\n",
      "Train Epoch: 730 [33792/54000 (63%)] Loss: -741.702087\n",
      "Train Epoch: 730 [45056/54000 (83%)] Loss: -709.994995\n",
      "    epoch          : 730\n",
      "    loss           : -725.0089905936763\n",
      "    ess            : 1.9600476408904453\n",
      "    log_marginal   : 725.0436113465507\n",
      "    log_joint      : 933.4166731924381\n",
      "    val_loss       : -728.9828389485677\n",
      "    val_ess        : 1.9635664125283558\n",
      "    val_log_marginal: 729.0182139078776\n",
      "    val_log_joint  : 937.1245676676432\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch730.pth ...\n",
      "Train Epoch: 731 [0/54000 (0%)] Loss: -737.365356\n",
      "Train Epoch: 731 [11264/54000 (21%)] Loss: -744.492676\n",
      "Train Epoch: 731 [22528/54000 (42%)] Loss: -740.898560\n",
      "Train Epoch: 731 [33792/54000 (63%)] Loss: -735.066284\n",
      "Train Epoch: 731 [45056/54000 (83%)] Loss: -724.297913\n",
      "    epoch          : 731\n",
      "    loss           : -725.4671959067291\n",
      "    ess            : 1.9602519374973368\n",
      "    log_marginal   : 725.5018961204672\n",
      "    log_joint      : 933.674297404739\n",
      "    val_loss       : -728.6848754882812\n",
      "    val_ess        : 1.9626010656356812\n",
      "    val_log_marginal: 728.7161865234375\n",
      "    val_log_joint  : 937.2276916503906\n",
      "Train Epoch: 732 [0/54000 (0%)] Loss: -741.687866\n",
      "Train Epoch: 732 [11264/54000 (21%)] Loss: -727.303955\n",
      "Train Epoch: 732 [22528/54000 (42%)] Loss: -712.562378\n",
      "Train Epoch: 732 [33792/54000 (63%)] Loss: -750.450317\n",
      "Train Epoch: 732 [45056/54000 (83%)] Loss: -724.643677\n",
      "    epoch          : 732\n",
      "    loss           : -725.1450880518499\n",
      "    ess            : 1.9617732189736277\n",
      "    log_marginal   : 725.1788687076208\n",
      "    log_joint      : 933.5772607191553\n",
      "    val_loss       : -729.9920603434244\n",
      "    val_ess        : 1.9628535707791646\n",
      "    val_log_marginal: 730.0220845540365\n",
      "    val_log_joint  : 938.1600189208984\n",
      "Train Epoch: 733 [0/54000 (0%)] Loss: -713.149353\n",
      "Train Epoch: 733 [11264/54000 (21%)] Loss: -729.997070\n",
      "Train Epoch: 733 [22528/54000 (42%)] Loss: -734.856689\n",
      "Train Epoch: 733 [33792/54000 (63%)] Loss: -737.245239\n",
      "Train Epoch: 733 [45056/54000 (83%)] Loss: -717.390747\n",
      "    epoch          : 733\n",
      "    loss           : -725.5493630463222\n",
      "    ess            : 1.9603573196339157\n",
      "    log_marginal   : 725.5840575020268\n",
      "    log_joint      : 933.9544833201282\n",
      "    val_loss       : -729.4828491210938\n",
      "    val_ess        : 1.9645523031552632\n",
      "    val_log_marginal: 729.5109659830729\n",
      "    val_log_joint  : 937.7422332763672\n",
      "Train Epoch: 734 [0/54000 (0%)] Loss: -719.451294\n",
      "Train Epoch: 734 [11264/54000 (21%)] Loss: -707.099182\n",
      "Train Epoch: 734 [22528/54000 (42%)] Loss: -721.888367\n",
      "Train Epoch: 734 [33792/54000 (63%)] Loss: -706.608887\n",
      "Train Epoch: 734 [45056/54000 (83%)] Loss: -752.603943\n",
      "    epoch          : 734\n",
      "    loss           : -725.6744620845003\n",
      "    ess            : 1.9605912127584781\n",
      "    log_marginal   : 725.7088922464623\n",
      "    log_joint      : 934.0831316102226\n",
      "    val_loss       : -729.5854644775391\n",
      "    val_ess        : 1.9588852922121684\n",
      "    val_log_marginal: 729.6204477945963\n",
      "    val_log_joint  : 938.0420430501302\n",
      "Train Epoch: 735 [0/54000 (0%)] Loss: -720.906982\n",
      "Train Epoch: 735 [11264/54000 (21%)] Loss: -732.155701\n",
      "Train Epoch: 735 [22528/54000 (42%)] Loss: -705.660217\n",
      "Train Epoch: 735 [33792/54000 (63%)] Loss: -728.538452\n",
      "Train Epoch: 735 [45056/54000 (83%)] Loss: -743.837830\n",
      "    epoch          : 735\n",
      "    loss           : -725.7418708081516\n",
      "    ess            : 1.9600196908105094\n",
      "    log_marginal   : 725.7778458505306\n",
      "    log_joint      : 934.2210514860333\n",
      "    val_loss       : -729.536865234375\n",
      "    val_ess        : 1.9606913328170776\n",
      "    val_log_marginal: 729.5735575358073\n",
      "    val_log_joint  : 938.1072031656901\n",
      "Train Epoch: 736 [0/54000 (0%)] Loss: -720.944946\n",
      "Train Epoch: 736 [11264/54000 (21%)] Loss: -728.522400\n",
      "Train Epoch: 736 [22528/54000 (42%)] Loss: -717.603577\n",
      "Train Epoch: 736 [33792/54000 (63%)] Loss: -722.015503\n",
      "Train Epoch: 736 [45056/54000 (83%)] Loss: -719.364258\n",
      "    epoch          : 736\n",
      "    loss           : -725.873911731648\n",
      "    ess            : 1.9611587963014279\n",
      "    log_marginal   : 725.9075115851637\n",
      "    log_joint      : 934.2484401486954\n",
      "    val_loss       : -730.4312693277994\n",
      "    val_ess        : 1.9589224457740784\n",
      "    val_log_marginal: 730.4716288248698\n",
      "    val_log_joint  : 938.8621877034506\n",
      "Train Epoch: 737 [0/54000 (0%)] Loss: -718.626221\n",
      "Train Epoch: 737 [11264/54000 (21%)] Loss: -716.536377\n",
      "Train Epoch: 737 [22528/54000 (42%)] Loss: -727.052612\n",
      "Train Epoch: 737 [33792/54000 (63%)] Loss: -725.586243\n",
      "Train Epoch: 737 [45056/54000 (83%)] Loss: -728.917908\n",
      "    epoch          : 737\n",
      "    loss           : -726.2234082491892\n",
      "    ess            : 1.9603206346619804\n",
      "    log_marginal   : 726.2574900501179\n",
      "    log_joint      : 934.6522648649395\n",
      "    val_loss       : -730.039296468099\n",
      "    val_ess        : 1.9549868206183116\n",
      "    val_log_marginal: 730.0832824707031\n",
      "    val_log_joint  : 938.7322285970052\n",
      "Train Epoch: 738 [0/54000 (0%)] Loss: -731.001160\n",
      "Train Epoch: 738 [11264/54000 (21%)] Loss: -734.214294\n",
      "Train Epoch: 738 [22528/54000 (42%)] Loss: -724.218567\n",
      "Train Epoch: 738 [33792/54000 (63%)] Loss: -718.416077\n",
      "Train Epoch: 738 [45056/54000 (83%)] Loss: -709.935425\n",
      "    epoch          : 738\n",
      "    loss           : -726.3796484605322\n",
      "    ess            : 1.9604457684282988\n",
      "    log_marginal   : 726.4135316093013\n",
      "    log_joint      : 934.7580957952536\n",
      "    val_loss       : -730.604726155599\n",
      "    val_ess        : 1.95980966091156\n",
      "    val_log_marginal: 730.6380716959635\n",
      "    val_log_joint  : 938.9845682779948\n",
      "Train Epoch: 739 [0/54000 (0%)] Loss: -723.532776\n",
      "Train Epoch: 739 [11264/54000 (21%)] Loss: -706.207825\n",
      "Train Epoch: 739 [22528/54000 (42%)] Loss: -727.547363\n",
      "Train Epoch: 739 [33792/54000 (63%)] Loss: -718.008240\n",
      "Train Epoch: 739 [45056/54000 (83%)] Loss: -725.987610\n",
      "    epoch          : 739\n",
      "    loss           : -726.4173370937132\n",
      "    ess            : 1.9608962861996777\n",
      "    log_marginal   : 726.4521017974278\n",
      "    log_joint      : 934.7831582123379\n",
      "    val_loss       : -730.5042215983073\n",
      "    val_ess        : 1.9574140906333923\n",
      "    val_log_marginal: 730.5463816324869\n",
      "    val_log_joint  : 939.1766001383463\n",
      "Train Epoch: 740 [0/54000 (0%)] Loss: -728.156006\n",
      "Train Epoch: 740 [11264/54000 (21%)] Loss: -728.656616\n",
      "Train Epoch: 740 [22528/54000 (42%)] Loss: -719.922119\n",
      "Train Epoch: 740 [33792/54000 (63%)] Loss: -713.044861\n",
      "Train Epoch: 740 [45056/54000 (83%)] Loss: -747.881287\n",
      "    epoch          : 740\n",
      "    loss           : -726.6706571758918\n",
      "    ess            : 1.960311235121961\n",
      "    log_marginal   : 726.7058191839254\n",
      "    log_joint      : 934.9756181824882\n",
      "    val_loss       : -730.638661702474\n",
      "    val_ess        : 1.959525505701701\n",
      "    val_log_marginal: 730.6747690836588\n",
      "    val_log_joint  : 939.0975443522135\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch740.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 741 [0/54000 (0%)] Loss: -717.234375\n",
      "Train Epoch: 741 [11264/54000 (21%)] Loss: -748.142822\n",
      "Train Epoch: 741 [22528/54000 (42%)] Loss: -730.386414\n",
      "Train Epoch: 741 [33792/54000 (63%)] Loss: -741.517090\n",
      "Train Epoch: 741 [45056/54000 (83%)] Loss: -738.838623\n",
      "    epoch          : 741\n",
      "    loss           : -726.7373121729437\n",
      "    ess            : 1.9611963404799408\n",
      "    log_marginal   : 726.7710651901533\n",
      "    log_joint      : 935.061196381191\n",
      "    val_loss       : -731.0397440592448\n",
      "    val_ess        : 1.9610749085744221\n",
      "    val_log_marginal: 731.0752207438151\n",
      "    val_log_joint  : 939.4844767252604\n",
      "Train Epoch: 742 [0/54000 (0%)] Loss: -720.434937\n",
      "Train Epoch: 742 [11264/54000 (21%)] Loss: -731.308594\n",
      "Train Epoch: 742 [22528/54000 (42%)] Loss: -706.443359\n",
      "Train Epoch: 742 [33792/54000 (63%)] Loss: -700.773315\n",
      "Train Epoch: 742 [45056/54000 (83%)] Loss: -736.837524\n",
      "    epoch          : 742\n",
      "    loss           : -726.9986272847877\n",
      "    ess            : 1.959604061999411\n",
      "    log_marginal   : 727.0338336296801\n",
      "    log_joint      : 935.3649453217129\n",
      "    val_loss       : -731.8656005859375\n",
      "    val_ess        : 1.9582975109418232\n",
      "    val_log_marginal: 731.9053090413412\n",
      "    val_log_joint  : 940.0396118164062\n",
      "Train Epoch: 743 [0/54000 (0%)] Loss: -714.761963\n",
      "Train Epoch: 743 [11264/54000 (21%)] Loss: -741.953674\n",
      "Train Epoch: 743 [22528/54000 (42%)] Loss: -719.320251\n",
      "Train Epoch: 743 [33792/54000 (63%)] Loss: -733.093750\n",
      "Train Epoch: 743 [45056/54000 (83%)] Loss: -719.175537\n",
      "    epoch          : 743\n",
      "    loss           : -726.8791809082031\n",
      "    ess            : 1.9599499533761222\n",
      "    log_marginal   : 726.9147459785893\n",
      "    log_joint      : 935.3138013155955\n",
      "    val_loss       : -731.6138102213541\n",
      "    val_ess        : 1.9614554246266682\n",
      "    val_log_marginal: 731.6483408610026\n",
      "    val_log_joint  : 939.6243998209635\n",
      "Train Epoch: 744 [0/54000 (0%)] Loss: -713.914917\n",
      "Train Epoch: 744 [11264/54000 (21%)] Loss: -724.911682\n",
      "Train Epoch: 744 [22528/54000 (42%)] Loss: -721.587769\n",
      "Train Epoch: 744 [33792/54000 (63%)] Loss: -726.088989\n",
      "Train Epoch: 744 [45056/54000 (83%)] Loss: -703.827515\n",
      "    epoch          : 744\n",
      "    loss           : -727.2224190190153\n",
      "    ess            : 1.9606728587510451\n",
      "    log_marginal   : 727.257059349204\n",
      "    log_joint      : 935.6343372272995\n",
      "    val_loss       : -731.1777140299479\n",
      "    val_ess        : 1.9580965141455333\n",
      "    val_log_marginal: 731.2143961588541\n",
      "    val_log_joint  : 939.8587951660156\n",
      "Train Epoch: 745 [0/54000 (0%)] Loss: -763.509033\n",
      "Train Epoch: 745 [11264/54000 (21%)] Loss: -729.261780\n",
      "Train Epoch: 745 [22528/54000 (42%)] Loss: -724.704529\n",
      "Train Epoch: 745 [33792/54000 (63%)] Loss: -739.433899\n",
      "Train Epoch: 745 [45056/54000 (83%)] Loss: -736.205200\n",
      "    epoch          : 745\n",
      "    loss           : -727.410267955852\n",
      "    ess            : 1.9609979087451719\n",
      "    log_marginal   : 727.4450741174086\n",
      "    log_joint      : 935.692746720224\n",
      "    val_loss       : -731.0329640706381\n",
      "    val_ess        : 1.9589639604091644\n",
      "    val_log_marginal: 731.0687103271484\n",
      "    val_log_joint  : 939.5582936604818\n",
      "Train Epoch: 746 [0/54000 (0%)] Loss: -720.867065\n",
      "Train Epoch: 746 [11264/54000 (21%)] Loss: -724.999268\n",
      "Train Epoch: 746 [22528/54000 (42%)] Loss: -714.238464\n",
      "Train Epoch: 746 [33792/54000 (63%)] Loss: -742.057251\n",
      "Train Epoch: 746 [45056/54000 (83%)] Loss: -737.799988\n",
      "    epoch          : 746\n",
      "    loss           : -727.3718186864313\n",
      "    ess            : 1.9615612671060383\n",
      "    log_marginal   : 727.4056062518425\n",
      "    log_joint      : 935.7606558169958\n",
      "    val_loss       : -731.5181884765625\n",
      "    val_ess        : 1.9574656983216603\n",
      "    val_log_marginal: 731.5550333658854\n",
      "    val_log_joint  : 939.8990885416666\n",
      "Train Epoch: 747 [0/54000 (0%)] Loss: -732.464722\n",
      "Train Epoch: 747 [11264/54000 (21%)] Loss: -724.638367\n",
      "Train Epoch: 747 [22528/54000 (42%)] Loss: -736.079956\n",
      "Train Epoch: 747 [33792/54000 (63%)] Loss: -729.903442\n",
      "Train Epoch: 747 [45056/54000 (83%)] Loss: -733.897827\n",
      "    epoch          : 747\n",
      "    loss           : -727.4784954718824\n",
      "    ess            : 1.9610765272716306\n",
      "    log_marginal   : 727.5117245080336\n",
      "    log_joint      : 935.9712599268499\n",
      "    val_loss       : -731.1742451985677\n",
      "    val_ess        : 1.965036153793335\n",
      "    val_log_marginal: 731.2042338053385\n",
      "    val_log_joint  : 939.5717213948568\n",
      "Train Epoch: 748 [0/54000 (0%)] Loss: -747.866089\n",
      "Train Epoch: 748 [11264/54000 (21%)] Loss: -712.518799\n",
      "Train Epoch: 748 [22528/54000 (42%)] Loss: -743.811401\n",
      "Train Epoch: 748 [33792/54000 (63%)] Loss: -737.949707\n",
      "Train Epoch: 748 [45056/54000 (83%)] Loss: -718.571655\n",
      "    epoch          : 748\n",
      "    loss           : -727.7488587577388\n",
      "    ess            : 1.9611344393694177\n",
      "    log_marginal   : 727.7813565236218\n",
      "    log_joint      : 936.1407395848688\n",
      "    val_loss       : -731.4304250081381\n",
      "    val_ess        : 1.9602358043193817\n",
      "    val_log_marginal: 731.4669698079427\n",
      "    val_log_joint  : 940.0736948649088\n",
      "Train Epoch: 749 [0/54000 (0%)] Loss: -731.234619\n",
      "Train Epoch: 749 [11264/54000 (21%)] Loss: -720.846252\n",
      "Train Epoch: 749 [22528/54000 (42%)] Loss: -718.675781\n",
      "Train Epoch: 749 [33792/54000 (63%)] Loss: -724.027405\n",
      "Train Epoch: 749 [45056/54000 (83%)] Loss: -732.462769\n",
      "    epoch          : 749\n",
      "    loss           : -727.7661887114903\n",
      "    ess            : 1.9601843064686038\n",
      "    log_marginal   : 727.8007916144605\n",
      "    log_joint      : 936.1284363944576\n",
      "    val_loss       : -731.9570515950521\n",
      "    val_ess        : 1.9625955323378246\n",
      "    val_log_marginal: 731.9905548095703\n",
      "    val_log_joint  : 940.4060618082682\n",
      "Train Epoch: 750 [0/54000 (0%)] Loss: -726.388000\n",
      "Train Epoch: 750 [11264/54000 (21%)] Loss: -702.371094\n",
      "Train Epoch: 750 [22528/54000 (42%)] Loss: -731.124756\n",
      "Train Epoch: 750 [33792/54000 (63%)] Loss: -723.099976\n",
      "Train Epoch: 750 [45056/54000 (83%)] Loss: -715.714722\n",
      "    epoch          : 750\n",
      "    loss           : -727.8366607090212\n",
      "    ess            : 1.9612950131578266\n",
      "    log_marginal   : 727.8697791909271\n",
      "    log_joint      : 936.1783274524616\n",
      "    val_loss       : -731.8484547932943\n",
      "    val_ess        : 1.9600041210651398\n",
      "    val_log_marginal: 731.8851979573568\n",
      "    val_log_joint  : 940.4941457112631\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch750.pth ...\n",
      "Train Epoch: 751 [0/54000 (0%)] Loss: -706.491638\n",
      "Train Epoch: 751 [11264/54000 (21%)] Loss: -745.946289\n",
      "Train Epoch: 751 [22528/54000 (42%)] Loss: -721.729980\n",
      "Train Epoch: 751 [33792/54000 (63%)] Loss: -725.831726\n",
      "Train Epoch: 751 [45056/54000 (83%)] Loss: -727.778748\n",
      "    epoch          : 751\n",
      "    loss           : -728.3373476424307\n",
      "    ess            : 1.9616496574203923\n",
      "    log_marginal   : 728.3703832086527\n",
      "    log_joint      : 936.7295900740713\n",
      "    val_loss       : -731.9730529785156\n",
      "    val_ess        : 1.9620663821697235\n",
      "    val_log_marginal: 732.0080210367838\n",
      "    val_log_joint  : 940.6471608479818\n",
      "Train Epoch: 752 [0/54000 (0%)] Loss: -712.388245\n",
      "Train Epoch: 752 [11264/54000 (21%)] Loss: -705.492004\n",
      "Train Epoch: 752 [22528/54000 (42%)] Loss: -732.142761\n",
      "Train Epoch: 752 [33792/54000 (63%)] Loss: -733.308960\n",
      "Train Epoch: 752 [45056/54000 (83%)] Loss: -720.238281\n",
      "    epoch          : 752\n",
      "    loss           : -728.3781767071418\n",
      "    ess            : 1.9626500617783025\n",
      "    log_marginal   : 728.4104746692585\n",
      "    log_joint      : 936.7254581091539\n",
      "    val_loss       : -732.3539886474609\n",
      "    val_ess        : 1.9604395429293315\n",
      "    val_log_marginal: 732.3945973714193\n",
      "    val_log_joint  : 940.9837544759115\n",
      "Train Epoch: 753 [0/54000 (0%)] Loss: -736.562439\n",
      "Train Epoch: 753 [11264/54000 (21%)] Loss: -725.527344\n",
      "Train Epoch: 753 [22528/54000 (42%)] Loss: -742.925720\n",
      "Train Epoch: 753 [33792/54000 (63%)] Loss: -736.431030\n",
      "Train Epoch: 753 [45056/54000 (83%)] Loss: -747.826355\n",
      "    epoch          : 753\n",
      "    loss           : -728.3219886635834\n",
      "    ess            : 1.9605247906918795\n",
      "    log_marginal   : 728.3565806262898\n",
      "    log_joint      : 936.6900007139961\n",
      "    val_loss       : -731.9390869140625\n",
      "    val_ess        : 1.9595039089520772\n",
      "    val_log_marginal: 731.9751586914062\n",
      "    val_log_joint  : 940.6722513834635\n",
      "Train Epoch: 754 [0/54000 (0%)] Loss: -736.370483\n",
      "Train Epoch: 754 [11264/54000 (21%)] Loss: -756.608459\n",
      "Train Epoch: 754 [22528/54000 (42%)] Loss: -726.991882\n",
      "Train Epoch: 754 [33792/54000 (63%)] Loss: -725.795654\n",
      "Train Epoch: 754 [45056/54000 (83%)] Loss: -749.082153\n",
      "    epoch          : 754\n",
      "    loss           : -728.397494334095\n",
      "    ess            : 1.9605900240394305\n",
      "    log_marginal   : 728.4318605818838\n",
      "    log_joint      : 936.8025080842792\n",
      "    val_loss       : -732.0033569335938\n",
      "    val_ess        : 1.9613591929276784\n",
      "    val_log_marginal: 732.0362243652344\n",
      "    val_log_joint  : 940.7261199951172\n",
      "Train Epoch: 755 [0/54000 (0%)] Loss: -739.984985\n",
      "Train Epoch: 755 [11264/54000 (21%)] Loss: -703.243896\n",
      "Train Epoch: 755 [22528/54000 (42%)] Loss: -733.089478\n",
      "Train Epoch: 755 [33792/54000 (63%)] Loss: -744.399414\n",
      "Train Epoch: 755 [45056/54000 (83%)] Loss: -718.714600\n",
      "    epoch          : 755\n",
      "    loss           : -728.5457349093455\n",
      "    ess            : 1.9609512990375735\n",
      "    log_marginal   : 728.5788412993809\n",
      "    log_joint      : 936.9368286132812\n",
      "    val_loss       : -733.5240936279297\n",
      "    val_ess        : 1.9607399304707844\n",
      "    val_log_marginal: 733.5586649576823\n",
      "    val_log_joint  : 941.8527425130209\n",
      "Train Epoch: 756 [0/54000 (0%)] Loss: -712.658936\n",
      "Train Epoch: 756 [11264/54000 (21%)] Loss: -737.754028\n",
      "Train Epoch: 756 [22528/54000 (42%)] Loss: -734.450073\n",
      "Train Epoch: 756 [33792/54000 (63%)] Loss: -735.588196\n",
      "Train Epoch: 756 [45056/54000 (83%)] Loss: -700.582886\n",
      "    epoch          : 756\n",
      "    loss           : -728.7157276081589\n",
      "    ess            : 1.9600221717132713\n",
      "    log_marginal   : 728.7497086434994\n",
      "    log_joint      : 937.0913742353331\n",
      "    val_loss       : -733.6940663655599\n",
      "    val_ess        : 1.9631112118562062\n",
      "    val_log_marginal: 733.7274169921875\n",
      "    val_log_joint  : 942.2182769775391\n",
      "Train Epoch: 757 [0/54000 (0%)] Loss: -731.676025\n",
      "Train Epoch: 757 [11264/54000 (21%)] Loss: -726.759521\n",
      "Train Epoch: 757 [22528/54000 (42%)] Loss: -722.661194\n",
      "Train Epoch: 757 [33792/54000 (63%)] Loss: -733.423218\n",
      "Train Epoch: 757 [45056/54000 (83%)] Loss: -740.541138\n",
      "    epoch          : 757\n",
      "    loss           : -728.9418703475088\n",
      "    ess            : 1.9600551375802957\n",
      "    log_marginal   : 728.9766223835495\n",
      "    log_joint      : 937.2345932294737\n",
      "    val_loss       : -733.1748301188151\n",
      "    val_ess        : 1.9612629910310109\n",
      "    val_log_marginal: 733.2087249755859\n",
      "    val_log_joint  : 941.3644714355469\n",
      "Train Epoch: 758 [0/54000 (0%)] Loss: -729.443604\n",
      "Train Epoch: 758 [11264/54000 (21%)] Loss: -730.770630\n",
      "Train Epoch: 758 [22528/54000 (42%)] Loss: -718.605530\n",
      "Train Epoch: 758 [33792/54000 (63%)] Loss: -741.127441\n",
      "Train Epoch: 758 [45056/54000 (83%)] Loss: -708.513184\n",
      "    epoch          : 758\n",
      "    loss           : -728.9518801131338\n",
      "    ess            : 1.9609798069270152\n",
      "    log_marginal   : 728.985860572671\n",
      "    log_joint      : 937.3272215645268\n",
      "    val_loss       : -733.4757385253906\n",
      "    val_ess        : 1.9617757399876912\n",
      "    val_log_marginal: 733.5101369222006\n",
      "    val_log_joint  : 941.8337707519531\n",
      "Train Epoch: 759 [0/54000 (0%)] Loss: -720.785889\n",
      "Train Epoch: 759 [11264/54000 (21%)] Loss: -720.484375\n",
      "Train Epoch: 759 [22528/54000 (42%)] Loss: -737.680725\n",
      "Train Epoch: 759 [33792/54000 (63%)] Loss: -741.355408\n",
      "Train Epoch: 759 [45056/54000 (83%)] Loss: -735.645813\n",
      "    epoch          : 759\n",
      "    loss           : -729.3275733803803\n",
      "    ess            : 1.960682674398962\n",
      "    log_marginal   : 729.3610517393868\n",
      "    log_joint      : 937.6676347840507\n",
      "    val_loss       : -733.6812032063802\n",
      "    val_ess        : 1.9608988563219707\n",
      "    val_log_marginal: 733.714101155599\n",
      "    val_log_joint  : 941.8515625\n",
      "Train Epoch: 760 [0/54000 (0%)] Loss: -731.565063\n",
      "Train Epoch: 760 [11264/54000 (21%)] Loss: -717.486633\n",
      "Train Epoch: 760 [22528/54000 (42%)] Loss: -751.141968\n",
      "Train Epoch: 760 [33792/54000 (63%)] Loss: -742.887756\n",
      "Train Epoch: 760 [45056/54000 (83%)] Loss: -718.335510\n",
      "    epoch          : 760\n",
      "    loss           : -729.3907551315596\n",
      "    ess            : 1.9611750908617704\n",
      "    log_marginal   : 729.4245150584095\n",
      "    log_joint      : 937.8501287496315\n",
      "    val_loss       : -734.0185496012369\n",
      "    val_ess        : 1.9575869143009186\n",
      "    val_log_marginal: 734.0573883056641\n",
      "    val_log_joint  : 942.2061513264974\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch760.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 761 [0/54000 (0%)] Loss: -742.527588\n",
      "Train Epoch: 761 [11264/54000 (21%)] Loss: -720.434753\n",
      "Train Epoch: 761 [22528/54000 (42%)] Loss: -718.444458\n",
      "Train Epoch: 761 [33792/54000 (63%)] Loss: -732.195801\n",
      "Train Epoch: 761 [45056/54000 (83%)] Loss: -723.953247\n",
      "    epoch          : 761\n",
      "    loss           : -729.3851560196787\n",
      "    ess            : 1.9599347148301467\n",
      "    log_marginal   : 729.4203318469929\n",
      "    log_joint      : 937.8386835062279\n",
      "    val_loss       : -733.4876302083334\n",
      "    val_ess        : 1.9621492822964985\n",
      "    val_log_marginal: 733.5198364257812\n",
      "    val_log_joint  : 941.8541514078776\n",
      "Train Epoch: 762 [0/54000 (0%)] Loss: -728.149902\n",
      "Train Epoch: 762 [11264/54000 (21%)] Loss: -718.619141\n",
      "Train Epoch: 762 [22528/54000 (42%)] Loss: -730.893555\n",
      "Train Epoch: 762 [33792/54000 (63%)] Loss: -719.419067\n",
      "Train Epoch: 762 [45056/54000 (83%)] Loss: -719.345581\n",
      "    epoch          : 762\n",
      "    loss           : -729.5364587172022\n",
      "    ess            : 1.960303542748937\n",
      "    log_marginal   : 729.5712026919958\n",
      "    log_joint      : 937.986321791163\n",
      "    val_loss       : -733.9387715657552\n",
      "    val_ess        : 1.9621077577273052\n",
      "    val_log_marginal: 733.9718475341797\n",
      "    val_log_joint  : 942.4911346435547\n",
      "Train Epoch: 763 [0/54000 (0%)] Loss: -713.464783\n",
      "Train Epoch: 763 [11264/54000 (21%)] Loss: -717.235840\n",
      "Train Epoch: 763 [22528/54000 (42%)] Loss: -709.524719\n",
      "Train Epoch: 763 [33792/54000 (63%)] Loss: -745.310181\n",
      "Train Epoch: 763 [45056/54000 (83%)] Loss: -728.673523\n",
      "    epoch          : 763\n",
      "    loss           : -729.6218670539137\n",
      "    ess            : 1.9608991123595327\n",
      "    log_marginal   : 729.6556667111954\n",
      "    log_joint      : 937.9166847085053\n",
      "    val_loss       : -733.5585021972656\n",
      "    val_ess        : 1.9644472201665242\n",
      "    val_log_marginal: 733.5904541015625\n",
      "    val_log_joint  : 941.8620147705078\n",
      "Train Epoch: 764 [0/54000 (0%)] Loss: -737.064941\n",
      "Train Epoch: 764 [11264/54000 (21%)] Loss: -727.693970\n",
      "Train Epoch: 764 [22528/54000 (42%)] Loss: -727.327881\n",
      "Train Epoch: 764 [33792/54000 (63%)] Loss: -734.539917\n",
      "Train Epoch: 764 [45056/54000 (83%)] Loss: -734.628296\n",
      "    epoch          : 764\n",
      "    loss           : -729.8555591511276\n",
      "    ess            : 1.9607626312183883\n",
      "    log_marginal   : 729.8912071371979\n",
      "    log_joint      : 938.3156916780292\n",
      "    val_loss       : -734.3569132486979\n",
      "    val_ess        : 1.9598532617092133\n",
      "    val_log_marginal: 734.3972880045573\n",
      "    val_log_joint  : 942.4516398111979\n",
      "Train Epoch: 765 [0/54000 (0%)] Loss: -712.701782\n",
      "Train Epoch: 765 [11264/54000 (21%)] Loss: -757.556030\n",
      "Train Epoch: 765 [22528/54000 (42%)] Loss: -759.713745\n",
      "Train Epoch: 765 [33792/54000 (63%)] Loss: -725.335938\n",
      "Train Epoch: 765 [45056/54000 (83%)] Loss: -715.857056\n",
      "    epoch          : 765\n",
      "    loss           : -729.7660683685879\n",
      "    ess            : 1.9596586114955399\n",
      "    log_marginal   : 729.8007357615345\n",
      "    log_joint      : 938.2482581948334\n",
      "    val_loss       : -734.1942698160807\n",
      "    val_ess        : 1.9606959521770477\n",
      "    val_log_marginal: 734.2304484049479\n",
      "    val_log_joint  : 942.464365641276\n",
      "Train Epoch: 766 [0/54000 (0%)] Loss: -753.160217\n",
      "Train Epoch: 766 [11264/54000 (21%)] Loss: -723.433472\n",
      "Train Epoch: 766 [22528/54000 (42%)] Loss: -734.910156\n",
      "Train Epoch: 766 [33792/54000 (63%)] Loss: -733.731628\n",
      "Train Epoch: 766 [45056/54000 (83%)] Loss: -719.830017\n",
      "    epoch          : 766\n",
      "    loss           : -730.3373557036778\n",
      "    ess            : 1.9606095203813516\n",
      "    log_marginal   : 730.3724618587854\n",
      "    log_joint      : 938.7663073269827\n",
      "    val_loss       : -733.6169586181641\n",
      "    val_ess        : 1.962760219971339\n",
      "    val_log_marginal: 733.6491444905599\n",
      "    val_log_joint  : 942.0182444254557\n",
      "Train Epoch: 767 [0/54000 (0%)] Loss: -705.720032\n",
      "Train Epoch: 767 [11264/54000 (21%)] Loss: -718.629944\n",
      "Train Epoch: 767 [22528/54000 (42%)] Loss: -706.968689\n",
      "Train Epoch: 767 [33792/54000 (63%)] Loss: -739.897339\n",
      "Train Epoch: 767 [45056/54000 (83%)] Loss: -743.900757\n",
      "    epoch          : 767\n",
      "    loss           : -730.1713043788694\n",
      "    ess            : 1.9603520170697626\n",
      "    log_marginal   : 730.2062452784124\n",
      "    log_joint      : 938.5623514427328\n",
      "    val_loss       : -735.2671610514323\n",
      "    val_ess        : 1.9616941412289937\n",
      "    val_log_marginal: 735.3004964192709\n",
      "    val_log_joint  : 943.4998524983724\n",
      "Train Epoch: 768 [0/54000 (0%)] Loss: -733.974121\n",
      "Train Epoch: 768 [11264/54000 (21%)] Loss: -745.514526\n",
      "Train Epoch: 768 [22528/54000 (42%)] Loss: -747.412476\n",
      "Train Epoch: 768 [33792/54000 (63%)] Loss: -752.733215\n",
      "Train Epoch: 768 [45056/54000 (83%)] Loss: -709.690308\n",
      "    epoch          : 768\n",
      "    loss           : -730.2185818654186\n",
      "    ess            : 1.9612558439092815\n",
      "    log_marginal   : 730.2528392863724\n",
      "    log_joint      : 938.6555221845518\n",
      "    val_loss       : -734.8292388916016\n",
      "    val_ess        : 1.962522675593694\n",
      "    val_log_marginal: 734.8623708089193\n",
      "    val_log_joint  : 942.7746124267578\n",
      "Train Epoch: 769 [0/54000 (0%)] Loss: -731.692688\n",
      "Train Epoch: 769 [11264/54000 (21%)] Loss: -721.933289\n",
      "Train Epoch: 769 [22528/54000 (42%)] Loss: -748.746155\n",
      "Train Epoch: 769 [33792/54000 (63%)] Loss: -717.067383\n",
      "Train Epoch: 769 [45056/54000 (83%)] Loss: -726.464661\n",
      "    epoch          : 769\n",
      "    loss           : -730.5227004716982\n",
      "    ess            : 1.9621125515901818\n",
      "    log_marginal   : 730.555448712043\n",
      "    log_joint      : 938.8569612323113\n",
      "    val_loss       : -734.2532348632812\n",
      "    val_ess        : 1.960172841946284\n",
      "    val_log_marginal: 734.2872212727865\n",
      "    val_log_joint  : 942.8271993001302\n",
      "Train Epoch: 770 [0/54000 (0%)] Loss: -720.821411\n",
      "Train Epoch: 770 [11264/54000 (21%)] Loss: -743.329834\n",
      "Train Epoch: 770 [22528/54000 (42%)] Loss: -717.170715\n",
      "Train Epoch: 770 [33792/54000 (63%)] Loss: -744.462280\n",
      "Train Epoch: 770 [45056/54000 (83%)] Loss: -747.348450\n",
      "    epoch          : 770\n",
      "    loss           : -730.7144349296138\n",
      "    ess            : 1.9598484702830046\n",
      "    log_marginal   : 730.7491789044075\n",
      "    log_joint      : 939.0843764970888\n",
      "    val_loss       : -734.7633870442709\n",
      "    val_ess        : 1.9628994762897491\n",
      "    val_log_marginal: 734.797861735026\n",
      "    val_log_joint  : 943.1964975992838\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch770.pth ...\n",
      "Train Epoch: 771 [0/54000 (0%)] Loss: -713.544556\n",
      "Train Epoch: 771 [11264/54000 (21%)] Loss: -744.769226\n",
      "Train Epoch: 771 [22528/54000 (42%)] Loss: -729.159546\n",
      "Train Epoch: 771 [33792/54000 (63%)] Loss: -737.218445\n",
      "Train Epoch: 771 [45056/54000 (83%)] Loss: -707.842651\n",
      "    epoch          : 771\n",
      "    loss           : -730.8148262455778\n",
      "    ess            : 1.9609867514304395\n",
      "    log_marginal   : 730.8490243587854\n",
      "    log_joint      : 939.2250181953862\n",
      "    val_loss       : -735.0605265299479\n",
      "    val_ess        : 1.9613609214623768\n",
      "    val_log_marginal: 735.0938008626302\n",
      "    val_log_joint  : 943.2007395426432\n",
      "Train Epoch: 772 [0/54000 (0%)] Loss: -732.501770\n",
      "Train Epoch: 772 [11264/54000 (21%)] Loss: -738.519226\n",
      "Train Epoch: 772 [22528/54000 (42%)] Loss: -713.831726\n",
      "Train Epoch: 772 [33792/54000 (63%)] Loss: -734.986084\n",
      "Train Epoch: 772 [45056/54000 (83%)] Loss: -718.257690\n",
      "    epoch          : 772\n",
      "    loss           : -730.9968578410599\n",
      "    ess            : 1.961831120949871\n",
      "    log_marginal   : 731.0299832326061\n",
      "    log_joint      : 939.3577126556972\n",
      "    val_loss       : -734.9794209798177\n",
      "    val_ess        : 1.9630760451157887\n",
      "    val_log_marginal: 735.0112711588541\n",
      "    val_log_joint  : 943.5732828776041\n",
      "Train Epoch: 773 [0/54000 (0%)] Loss: -711.071838\n",
      "Train Epoch: 773 [11264/54000 (21%)] Loss: -725.133423\n",
      "Train Epoch: 773 [22528/54000 (42%)] Loss: -723.662842\n",
      "Train Epoch: 773 [33792/54000 (63%)] Loss: -748.190796\n",
      "Train Epoch: 773 [45056/54000 (83%)] Loss: -723.959656\n",
      "    epoch          : 773\n",
      "    loss           : -731.0677680249485\n",
      "    ess            : 1.9604454917727776\n",
      "    log_marginal   : 731.1025269706295\n",
      "    log_joint      : 939.4781396254053\n",
      "    val_loss       : -735.3248392740885\n",
      "    val_ess        : 1.9598669807116191\n",
      "    val_log_marginal: 735.3592122395834\n",
      "    val_log_joint  : 943.7731018066406\n",
      "Train Epoch: 774 [0/54000 (0%)] Loss: -730.486755\n",
      "Train Epoch: 774 [11264/54000 (21%)] Loss: -728.588379\n",
      "Train Epoch: 774 [22528/54000 (42%)] Loss: -728.390503\n",
      "Train Epoch: 774 [33792/54000 (63%)] Loss: -745.625854\n",
      "Train Epoch: 774 [45056/54000 (83%)] Loss: -750.149353\n",
      "    epoch          : 774\n",
      "    loss           : -731.2312823601488\n",
      "    ess            : 1.9601208860019468\n",
      "    log_marginal   : 731.2660614589475\n",
      "    log_joint      : 939.7205113824808\n",
      "    val_loss       : -735.4590250651041\n",
      "    val_ess        : 1.9593939185142517\n",
      "    val_log_marginal: 735.4943695068359\n",
      "    val_log_joint  : 943.48974609375\n",
      "Train Epoch: 775 [0/54000 (0%)] Loss: -719.726746\n",
      "Train Epoch: 775 [11264/54000 (21%)] Loss: -750.921387\n",
      "Train Epoch: 775 [22528/54000 (42%)] Loss: -717.275269\n",
      "Train Epoch: 775 [33792/54000 (63%)] Loss: -726.998840\n",
      "Train Epoch: 775 [45056/54000 (83%)] Loss: -751.905090\n",
      "    epoch          : 775\n",
      "    loss           : -731.3864521530439\n",
      "    ess            : 1.960350827226099\n",
      "    log_marginal   : 731.4210141739755\n",
      "    log_joint      : 939.7063788647922\n",
      "    val_loss       : -736.333730061849\n",
      "    val_ess        : 1.960014800230662\n",
      "    val_log_marginal: 736.3685862223307\n",
      "    val_log_joint  : 944.6516571044922\n",
      "Train Epoch: 776 [0/54000 (0%)] Loss: -729.850708\n",
      "Train Epoch: 776 [11264/54000 (21%)] Loss: -720.425415\n",
      "Train Epoch: 776 [22528/54000 (42%)] Loss: -747.367188\n",
      "Train Epoch: 776 [33792/54000 (63%)] Loss: -734.587646\n",
      "Train Epoch: 776 [45056/54000 (83%)] Loss: -758.775879\n",
      "    epoch          : 776\n",
      "    loss           : -731.4435424804688\n",
      "    ess            : 1.960229385573909\n",
      "    log_marginal   : 731.4788668650501\n",
      "    log_joint      : 939.880489133439\n",
      "    val_loss       : -735.9357350667318\n",
      "    val_ess        : 1.956245352824529\n",
      "    val_log_marginal: 735.9741617838541\n",
      "    val_log_joint  : 944.5125172932943\n",
      "Train Epoch: 777 [0/54000 (0%)] Loss: -722.963867\n",
      "Train Epoch: 777 [11264/54000 (21%)] Loss: -726.253601\n",
      "Train Epoch: 777 [22528/54000 (42%)] Loss: -743.958740\n",
      "Train Epoch: 777 [33792/54000 (63%)] Loss: -738.600586\n",
      "Train Epoch: 777 [45056/54000 (83%)] Loss: -740.032471\n",
      "    epoch          : 777\n",
      "    loss           : -731.703042084316\n",
      "    ess            : 1.9600647001896265\n",
      "    log_marginal   : 731.7382173358269\n",
      "    log_joint      : 940.156208542158\n",
      "    val_loss       : -736.0315399169922\n",
      "    val_ess        : 1.9603816668192546\n",
      "    val_log_marginal: 736.0676625569662\n",
      "    val_log_joint  : 944.3296305338541\n",
      "Train Epoch: 778 [0/54000 (0%)] Loss: -733.393188\n",
      "Train Epoch: 778 [11264/54000 (21%)] Loss: -725.326904\n",
      "Train Epoch: 778 [22528/54000 (42%)] Loss: -743.833130\n",
      "Train Epoch: 778 [33792/54000 (63%)] Loss: -728.333923\n",
      "Train Epoch: 778 [45056/54000 (83%)] Loss: -733.134277\n",
      "    epoch          : 778\n",
      "    loss           : -732.1210033488724\n",
      "    ess            : 1.9606759008371606\n",
      "    log_marginal   : 732.1557599913399\n",
      "    log_joint      : 940.3903048533314\n",
      "    val_loss       : -735.9410705566406\n",
      "    val_ess        : 1.9615096151828766\n",
      "    val_log_marginal: 735.9715677897135\n",
      "    val_log_joint  : 944.4598388671875\n",
      "Train Epoch: 779 [0/54000 (0%)] Loss: -740.691162\n",
      "Train Epoch: 779 [11264/54000 (21%)] Loss: -737.507751\n",
      "Train Epoch: 779 [22528/54000 (42%)] Loss: -729.713074\n",
      "Train Epoch: 779 [33792/54000 (63%)] Loss: -695.419800\n",
      "Train Epoch: 779 [45056/54000 (83%)] Loss: -714.748047\n",
      "    epoch          : 779\n",
      "    loss           : -731.841685169148\n",
      "    ess            : 1.9598515551045257\n",
      "    log_marginal   : 731.8776273907356\n",
      "    log_joint      : 940.2623469514667\n",
      "    val_loss       : -736.2650146484375\n",
      "    val_ess        : 1.9622858067353566\n",
      "    val_log_marginal: 736.2990366617838\n",
      "    val_log_joint  : 944.6984659830729\n",
      "Train Epoch: 780 [0/54000 (0%)] Loss: -740.843567\n",
      "Train Epoch: 780 [11264/54000 (21%)] Loss: -732.108154\n",
      "Train Epoch: 780 [22528/54000 (42%)] Loss: -740.952393\n",
      "Train Epoch: 780 [33792/54000 (63%)] Loss: -734.226929\n",
      "Train Epoch: 780 [45056/54000 (83%)] Loss: -728.466309\n",
      "    epoch          : 780\n",
      "    loss           : -732.0641191590507\n",
      "    ess            : 1.9610327617177423\n",
      "    log_marginal   : 732.0980190061173\n",
      "    log_joint      : 940.4631077028671\n",
      "    val_loss       : -736.1139322916666\n",
      "    val_ess        : 1.96029927333196\n",
      "    val_log_marginal: 736.1490529378256\n",
      "    val_log_joint  : 944.5718231201172\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch780.pth ...\n",
      "Train Epoch: 781 [0/54000 (0%)] Loss: -743.651733\n",
      "Train Epoch: 781 [11264/54000 (21%)] Loss: -734.566711\n",
      "Train Epoch: 781 [22528/54000 (42%)] Loss: -733.685059\n",
      "Train Epoch: 781 [33792/54000 (63%)] Loss: -714.476868\n",
      "Train Epoch: 781 [45056/54000 (83%)] Loss: -709.690552\n",
      "    epoch          : 781\n",
      "    loss           : -732.1721531130233\n",
      "    ess            : 1.9602876620472602\n",
      "    log_marginal   : 732.207811463554\n",
      "    log_joint      : 940.593644627985\n",
      "    val_loss       : -736.8263549804688\n",
      "    val_ess        : 1.9596676131089528\n",
      "    val_log_marginal: 736.8608856201172\n",
      "    val_log_joint  : 945.3571624755859\n",
      "Train Epoch: 782 [0/54000 (0%)] Loss: -737.593933\n",
      "Train Epoch: 782 [11264/54000 (21%)] Loss: -720.371582\n",
      "Train Epoch: 782 [22528/54000 (42%)] Loss: -751.553711\n",
      "Train Epoch: 782 [33792/54000 (63%)] Loss: -752.907898\n",
      "Train Epoch: 782 [45056/54000 (83%)] Loss: -741.074219\n",
      "    epoch          : 782\n",
      "    loss           : -732.4134878482458\n",
      "    ess            : 1.9606175445160776\n",
      "    log_marginal   : 732.4476249262972\n",
      "    log_joint      : 940.814759452388\n",
      "    val_loss       : -736.4193674723307\n",
      "    val_ess        : 1.956751714150111\n",
      "    val_log_marginal: 736.4633839925131\n",
      "    val_log_joint  : 944.9219004313151\n",
      "Train Epoch: 783 [0/54000 (0%)] Loss: -744.554504\n",
      "Train Epoch: 783 [11264/54000 (21%)] Loss: -726.110657\n",
      "Train Epoch: 783 [22528/54000 (42%)] Loss: -733.916321\n",
      "Train Epoch: 783 [33792/54000 (63%)] Loss: -742.078125\n",
      "Train Epoch: 783 [45056/54000 (83%)] Loss: -733.333435\n",
      "    epoch          : 783\n",
      "    loss           : -732.6383085430793\n",
      "    ess            : 1.9601469163624745\n",
      "    log_marginal   : 732.6732028025501\n",
      "    log_joint      : 941.0181337752432\n",
      "    val_loss       : -737.1266886393229\n",
      "    val_ess        : 1.9628198047478993\n",
      "    val_log_marginal: 737.158457438151\n",
      "    val_log_joint  : 945.4836832682291\n",
      "Train Epoch: 784 [0/54000 (0%)] Loss: -714.800903\n",
      "Train Epoch: 784 [11264/54000 (21%)] Loss: -728.160645\n",
      "Train Epoch: 784 [22528/54000 (42%)] Loss: -702.028381\n",
      "Train Epoch: 784 [33792/54000 (63%)] Loss: -715.487915\n",
      "Train Epoch: 784 [45056/54000 (83%)] Loss: -743.485962\n",
      "    epoch          : 784\n",
      "    loss           : -732.5737034059921\n",
      "    ess            : 1.960222471435115\n",
      "    log_marginal   : 732.607239921138\n",
      "    log_joint      : 941.0767517089844\n",
      "    val_loss       : -737.6662394205729\n",
      "    val_ess        : 1.959734211365382\n",
      "    val_log_marginal: 737.7028452555338\n",
      "    val_log_joint  : 946.2086130777994\n",
      "Train Epoch: 785 [0/54000 (0%)] Loss: -732.692566\n",
      "Train Epoch: 785 [11264/54000 (21%)] Loss: -760.176880\n",
      "Train Epoch: 785 [22528/54000 (42%)] Loss: -698.645081\n",
      "Train Epoch: 785 [33792/54000 (63%)] Loss: -720.370972\n",
      "Train Epoch: 785 [45056/54000 (83%)] Loss: -760.635010\n",
      "    epoch          : 785\n",
      "    loss           : -732.89034573537\n",
      "    ess            : 1.9606991950071082\n",
      "    log_marginal   : 732.9240860849056\n",
      "    log_joint      : 941.3124320552034\n",
      "    val_loss       : -736.9188639322916\n",
      "    val_ess        : 1.9603393375873566\n",
      "    val_log_marginal: 736.9550730387369\n",
      "    val_log_joint  : 945.5575052897135\n",
      "Train Epoch: 786 [0/54000 (0%)] Loss: -737.439575\n",
      "Train Epoch: 786 [11264/54000 (21%)] Loss: -705.797913\n",
      "Train Epoch: 786 [22528/54000 (42%)] Loss: -740.319824\n",
      "Train Epoch: 786 [33792/54000 (63%)] Loss: -732.703430\n",
      "Train Epoch: 786 [45056/54000 (83%)] Loss: -736.735352\n",
      "    epoch          : 786\n",
      "    loss           : -732.9338142826872\n",
      "    ess            : 1.9611175318933882\n",
      "    log_marginal   : 732.9677285248379\n",
      "    log_joint      : 941.2397472453567\n",
      "    val_loss       : -737.1684265136719\n",
      "    val_ess        : 1.9613385895888011\n",
      "    val_log_marginal: 737.2023874918619\n",
      "    val_log_joint  : 945.5772450764974\n",
      "Train Epoch: 787 [0/54000 (0%)] Loss: -750.477966\n",
      "Train Epoch: 787 [11264/54000 (21%)] Loss: -741.379700\n",
      "Train Epoch: 787 [22528/54000 (42%)] Loss: -733.273376\n",
      "Train Epoch: 787 [33792/54000 (63%)] Loss: -724.279419\n",
      "Train Epoch: 787 [45056/54000 (83%)] Loss: -713.705811\n",
      "    epoch          : 787\n",
      "    loss           : -732.8773492777123\n",
      "    ess            : 1.9612093612832844\n",
      "    log_marginal   : 732.9117276173718\n",
      "    log_joint      : 941.236592994546\n",
      "    val_loss       : -737.4321339925131\n",
      "    val_ess        : 1.9603952467441559\n",
      "    val_log_marginal: 737.4661966959635\n",
      "    val_log_joint  : 945.7508748372396\n",
      "Train Epoch: 788 [0/54000 (0%)] Loss: -744.624512\n",
      "Train Epoch: 788 [11264/54000 (21%)] Loss: -744.194580\n",
      "Train Epoch: 788 [22528/54000 (42%)] Loss: -740.936768\n",
      "Train Epoch: 788 [33792/54000 (63%)] Loss: -736.275757\n",
      "Train Epoch: 788 [45056/54000 (83%)] Loss: -719.837036\n",
      "    epoch          : 788\n",
      "    loss           : -733.1672386313385\n",
      "    ess            : 1.959800270368468\n",
      "    log_marginal   : 733.2031929447966\n",
      "    log_joint      : 941.5700055968086\n",
      "    val_loss       : -736.8880055745443\n",
      "    val_ess        : 1.9569559693336487\n",
      "    val_log_marginal: 736.9310963948568\n",
      "    val_log_joint  : 945.1785074869791\n",
      "Train Epoch: 789 [0/54000 (0%)] Loss: -736.149658\n",
      "Train Epoch: 789 [11264/54000 (21%)] Loss: -748.598572\n",
      "Train Epoch: 789 [22528/54000 (42%)] Loss: -745.062134\n",
      "Train Epoch: 789 [33792/54000 (63%)] Loss: -729.271667\n",
      "Train Epoch: 789 [45056/54000 (83%)] Loss: -744.275391\n",
      "    epoch          : 789\n",
      "    loss           : -733.2509005564564\n",
      "    ess            : 1.9595153984033837\n",
      "    log_marginal   : 733.2863896207989\n",
      "    log_joint      : 941.7374336674528\n",
      "    val_loss       : -736.8621673583984\n",
      "    val_ess        : 1.957212467988332\n",
      "    val_log_marginal: 736.9000905354818\n",
      "    val_log_joint  : 945.2307891845703\n",
      "Train Epoch: 790 [0/54000 (0%)] Loss: -717.414673\n",
      "Train Epoch: 790 [11264/54000 (21%)] Loss: -739.434937\n",
      "Train Epoch: 790 [22528/54000 (42%)] Loss: -726.059570\n",
      "Train Epoch: 790 [33792/54000 (63%)] Loss: -714.695496\n",
      "Train Epoch: 790 [45056/54000 (83%)] Loss: -751.103516\n",
      "    epoch          : 790\n",
      "    loss           : -733.1676491791347\n",
      "    ess            : 1.960526058134043\n",
      "    log_marginal   : 733.202239414431\n",
      "    log_joint      : 941.6133250110554\n",
      "    val_loss       : -737.8003540039062\n",
      "    val_ess        : 1.956781377394994\n",
      "    val_log_marginal: 737.8396301269531\n",
      "    val_log_joint  : 945.8651835123698\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch790.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 791 [0/54000 (0%)] Loss: -722.305176\n",
      "Train Epoch: 791 [11264/54000 (21%)] Loss: -722.445068\n",
      "Train Epoch: 791 [22528/54000 (42%)] Loss: -735.211060\n",
      "Train Epoch: 791 [33792/54000 (63%)] Loss: -735.057434\n",
      "Train Epoch: 791 [45056/54000 (83%)] Loss: -716.577881\n",
      "    epoch          : 791\n",
      "    loss           : -733.4490137640036\n",
      "    ess            : 1.9608437913768697\n",
      "    log_marginal   : 733.4838279868072\n",
      "    log_joint      : 941.8085304116303\n",
      "    val_loss       : -737.161631266276\n",
      "    val_ess        : 1.961034615834554\n",
      "    val_log_marginal: 737.1962636311849\n",
      "    val_log_joint  : 945.6448313395182\n",
      "Train Epoch: 792 [0/54000 (0%)] Loss: -729.815857\n",
      "Train Epoch: 792 [11264/54000 (21%)] Loss: -738.358765\n",
      "Train Epoch: 792 [22528/54000 (42%)] Loss: -751.682373\n",
      "Train Epoch: 792 [33792/54000 (63%)] Loss: -754.837158\n",
      "Train Epoch: 792 [45056/54000 (83%)] Loss: -741.067017\n",
      "    epoch          : 792\n",
      "    loss           : -733.5689841216465\n",
      "    ess            : 1.9604981361695055\n",
      "    log_marginal   : 733.6037609172317\n",
      "    log_joint      : 941.981130923865\n",
      "    val_loss       : -737.4413706461588\n",
      "    val_ess        : 1.9579841494560242\n",
      "    val_log_marginal: 737.4743601481119\n",
      "    val_log_joint  : 945.771006266276\n",
      "Train Epoch: 793 [0/54000 (0%)] Loss: -727.131714\n",
      "Train Epoch: 793 [11264/54000 (21%)] Loss: -739.971313\n",
      "Train Epoch: 793 [22528/54000 (42%)] Loss: -749.857544\n",
      "Train Epoch: 793 [33792/54000 (63%)] Loss: -725.176147\n",
      "Train Epoch: 793 [45056/54000 (83%)] Loss: -738.825928\n",
      "    epoch          : 793\n",
      "    loss           : -733.5559531157871\n",
      "    ess            : 1.9588215418581694\n",
      "    log_marginal   : 733.5944881799086\n",
      "    log_joint      : 941.9843801822302\n",
      "    val_loss       : -737.5718180338541\n",
      "    val_ess        : 1.9603562156359355\n",
      "    val_log_marginal: 737.6111145019531\n",
      "    val_log_joint  : 945.9007873535156\n",
      "Train Epoch: 794 [0/54000 (0%)] Loss: -720.646362\n",
      "Train Epoch: 794 [11264/54000 (21%)] Loss: -735.162598\n",
      "Train Epoch: 794 [22528/54000 (42%)] Loss: -741.887878\n",
      "Train Epoch: 794 [33792/54000 (63%)] Loss: -735.916260\n",
      "Train Epoch: 794 [45056/54000 (83%)] Loss: -722.892517\n",
      "    epoch          : 794\n",
      "    loss           : -733.7510214751621\n",
      "    ess            : 1.9609337910166327\n",
      "    log_marginal   : 733.7854412726637\n",
      "    log_joint      : 942.1523207178656\n",
      "    val_loss       : -738.312510172526\n",
      "    val_ess        : 1.9582616488138835\n",
      "    val_log_marginal: 738.3496449788412\n",
      "    val_log_joint  : 946.5524190266927\n",
      "Train Epoch: 795 [0/54000 (0%)] Loss: -731.486145\n",
      "Train Epoch: 795 [11264/54000 (21%)] Loss: -719.697998\n",
      "Train Epoch: 795 [22528/54000 (42%)] Loss: -751.476990\n",
      "Train Epoch: 795 [33792/54000 (63%)] Loss: -742.527771\n",
      "Train Epoch: 795 [45056/54000 (83%)] Loss: -742.163208\n",
      "    epoch          : 795\n",
      "    loss           : -733.9245616984817\n",
      "    ess            : 1.9617386235381074\n",
      "    log_marginal   : 733.9575632923054\n",
      "    log_joint      : 942.3478416586822\n",
      "    val_loss       : -738.5349934895834\n",
      "    val_ess        : 1.959585835536321\n",
      "    val_log_marginal: 738.5694274902344\n",
      "    val_log_joint  : 946.9349568684896\n",
      "Train Epoch: 796 [0/54000 (0%)] Loss: -726.468567\n",
      "Train Epoch: 796 [11264/54000 (21%)] Loss: -734.250366\n",
      "Train Epoch: 796 [22528/54000 (42%)] Loss: -737.394470\n",
      "Train Epoch: 796 [33792/54000 (63%)] Loss: -741.829956\n",
      "Train Epoch: 796 [45056/54000 (83%)] Loss: -746.078735\n",
      "    epoch          : 796\n",
      "    loss           : -734.0804650648585\n",
      "    ess            : 1.9605950836865407\n",
      "    log_marginal   : 734.115137064232\n",
      "    log_joint      : 942.5428910165463\n",
      "    val_loss       : -738.3169759114584\n",
      "    val_ess        : 1.9603640635808308\n",
      "    val_log_marginal: 738.3506317138672\n",
      "    val_log_joint  : 946.4134267171224\n",
      "Train Epoch: 797 [0/54000 (0%)] Loss: -739.668518\n",
      "Train Epoch: 797 [11264/54000 (21%)] Loss: -715.286926\n",
      "Train Epoch: 797 [22528/54000 (42%)] Loss: -740.754700\n",
      "Train Epoch: 797 [33792/54000 (63%)] Loss: -722.698364\n",
      "Train Epoch: 797 [45056/54000 (83%)] Loss: -718.237549\n",
      "    epoch          : 797\n",
      "    loss           : -734.1578518849499\n",
      "    ess            : 1.9608903797167652\n",
      "    log_marginal   : 734.1926989285452\n",
      "    log_joint      : 942.5975946390404\n",
      "    val_loss       : -738.5726623535156\n",
      "    val_ess        : 1.9570904473463695\n",
      "    val_log_marginal: 738.6106618245443\n",
      "    val_log_joint  : 946.8636881510416\n",
      "Train Epoch: 798 [0/54000 (0%)] Loss: -734.391296\n",
      "Train Epoch: 798 [11264/54000 (21%)] Loss: -727.700928\n",
      "Train Epoch: 798 [22528/54000 (42%)] Loss: -731.430054\n",
      "Train Epoch: 798 [33792/54000 (63%)] Loss: -749.710388\n",
      "Train Epoch: 798 [45056/54000 (83%)] Loss: -722.766113\n",
      "    epoch          : 798\n",
      "    loss           : -734.4717591483638\n",
      "    ess            : 1.9610833311980624\n",
      "    log_marginal   : 734.5059751114755\n",
      "    log_joint      : 942.9057029868072\n",
      "    val_loss       : -737.8319244384766\n",
      "    val_ess        : 1.961199978987376\n",
      "    val_log_marginal: 737.8626403808594\n",
      "    val_log_joint  : 946.0547739664713\n",
      "Train Epoch: 799 [0/54000 (0%)] Loss: -726.653259\n",
      "Train Epoch: 799 [11264/54000 (21%)] Loss: -723.239441\n",
      "Train Epoch: 799 [22528/54000 (42%)] Loss: -759.203125\n",
      "Train Epoch: 799 [33792/54000 (63%)] Loss: -713.143005\n",
      "Train Epoch: 799 [45056/54000 (83%)] Loss: -732.577881\n",
      "    epoch          : 799\n",
      "    loss           : -734.4763730606943\n",
      "    ess            : 1.9600659001548335\n",
      "    log_marginal   : 734.5114216354658\n",
      "    log_joint      : 942.8613125783093\n",
      "    val_loss       : -738.0829010009766\n",
      "    val_ess        : 1.9595655898253124\n",
      "    val_log_marginal: 738.1204935709635\n",
      "    val_log_joint  : 946.6147664388021\n",
      "Train Epoch: 800 [0/54000 (0%)] Loss: -730.493042\n",
      "Train Epoch: 800 [11264/54000 (21%)] Loss: -734.243469\n",
      "Train Epoch: 800 [22528/54000 (42%)] Loss: -738.796143\n",
      "Train Epoch: 800 [33792/54000 (63%)] Loss: -733.232300\n",
      "Train Epoch: 800 [45056/54000 (83%)] Loss: -730.174133\n",
      "    epoch          : 800\n",
      "    loss           : -734.66817949403\n",
      "    ess            : 1.9609462877489485\n",
      "    log_marginal   : 734.702154771337\n",
      "    log_joint      : 943.1180771161925\n",
      "    val_loss       : -738.5773671468099\n",
      "    val_ess        : 1.9615659415721893\n",
      "    val_log_marginal: 738.6124674479166\n",
      "    val_log_joint  : 946.8812001546224\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch800.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 801 [0/54000 (0%)] Loss: -724.164368\n",
      "Train Epoch: 801 [11264/54000 (21%)] Loss: -724.090942\n",
      "Train Epoch: 801 [22528/54000 (42%)] Loss: -725.052856\n",
      "Train Epoch: 801 [33792/54000 (63%)] Loss: -742.922791\n",
      "Train Epoch: 801 [45056/54000 (83%)] Loss: -774.422913\n",
      "    epoch          : 801\n",
      "    loss           : -734.6450293199072\n",
      "    ess            : 1.9591813694755986\n",
      "    log_marginal   : 734.6808955354511\n",
      "    log_joint      : 943.1388906802771\n",
      "    val_loss       : -739.2859547932943\n",
      "    val_ess        : 1.9593901932239532\n",
      "    val_log_marginal: 739.3228658040365\n",
      "    val_log_joint  : 947.4991149902344\n",
      "Train Epoch: 802 [0/54000 (0%)] Loss: -757.068726\n",
      "Train Epoch: 802 [11264/54000 (21%)] Loss: -747.023315\n",
      "Train Epoch: 802 [22528/54000 (42%)] Loss: -723.577637\n",
      "Train Epoch: 802 [33792/54000 (63%)] Loss: -743.811035\n",
      "Train Epoch: 802 [45056/54000 (83%)] Loss: -752.326538\n",
      "    epoch          : 802\n",
      "    loss           : -735.0449195717865\n",
      "    ess            : 1.9611254930496216\n",
      "    log_marginal   : 735.078557428324\n",
      "    log_joint      : 943.4647746535967\n",
      "    val_loss       : -738.3477223714193\n",
      "    val_ess        : 1.9598166346549988\n",
      "    val_log_marginal: 738.3855895996094\n",
      "    val_log_joint  : 946.6632080078125\n",
      "Train Epoch: 803 [0/54000 (0%)] Loss: -732.043091\n",
      "Train Epoch: 803 [11264/54000 (21%)] Loss: -745.530945\n",
      "Train Epoch: 803 [22528/54000 (42%)] Loss: -760.720764\n",
      "Train Epoch: 803 [33792/54000 (63%)] Loss: -746.947388\n",
      "Train Epoch: 803 [45056/54000 (83%)] Loss: -736.218872\n",
      "    epoch          : 803\n",
      "    loss           : -734.9847918816332\n",
      "    ess            : 1.9617504713670262\n",
      "    log_marginal   : 735.0182973033977\n",
      "    log_joint      : 943.4324968445976\n",
      "    val_loss       : -738.7713419596354\n",
      "    val_ess        : 1.962165375550588\n",
      "    val_log_marginal: 738.80322265625\n",
      "    val_log_joint  : 947.2535807291666\n",
      "Train Epoch: 804 [0/54000 (0%)] Loss: -760.943848\n",
      "Train Epoch: 804 [11264/54000 (21%)] Loss: -729.450684\n",
      "Train Epoch: 804 [22528/54000 (42%)] Loss: -728.182678\n",
      "Train Epoch: 804 [33792/54000 (63%)] Loss: -738.033081\n",
      "Train Epoch: 804 [45056/54000 (83%)] Loss: -722.064087\n",
      "    epoch          : 804\n",
      "    loss           : -734.966950038694\n",
      "    ess            : 1.9604386181201574\n",
      "    log_marginal   : 735.001618007444\n",
      "    log_joint      : 943.462514049602\n",
      "    val_loss       : -739.4219919840494\n",
      "    val_ess        : 1.957920511563619\n",
      "    val_log_marginal: 739.4597473144531\n",
      "    val_log_joint  : 947.8957875569662\n",
      "Train Epoch: 805 [0/54000 (0%)] Loss: -719.141479\n",
      "Train Epoch: 805 [11264/54000 (21%)] Loss: -735.617249\n",
      "Train Epoch: 805 [22528/54000 (42%)] Loss: -743.989014\n",
      "Train Epoch: 805 [33792/54000 (63%)] Loss: -744.886353\n",
      "Train Epoch: 805 [45056/54000 (83%)] Loss: -748.629700\n",
      "    epoch          : 805\n",
      "    loss           : -735.3980021926592\n",
      "    ess            : 1.9604798589112624\n",
      "    log_marginal   : 735.4329240906914\n",
      "    log_joint      : 943.86935136903\n",
      "    val_loss       : -739.3564147949219\n",
      "    val_ess        : 1.9597856005032857\n",
      "    val_log_marginal: 739.3900705973307\n",
      "    val_log_joint  : 947.8195953369141\n",
      "Train Epoch: 806 [0/54000 (0%)] Loss: -777.431091\n",
      "Train Epoch: 806 [11264/54000 (21%)] Loss: -728.321106\n",
      "Train Epoch: 806 [22528/54000 (42%)] Loss: -745.717163\n",
      "Train Epoch: 806 [33792/54000 (63%)] Loss: -736.311890\n",
      "Train Epoch: 806 [45056/54000 (83%)] Loss: -735.614502\n",
      "    epoch          : 806\n",
      "    loss           : -735.5416582215507\n",
      "    ess            : 1.9612023088167299\n",
      "    log_marginal   : 735.5765363585274\n",
      "    log_joint      : 943.9388064978258\n",
      "    val_loss       : -739.4935251871744\n",
      "    val_ess        : 1.9610538880030315\n",
      "    val_log_marginal: 739.5277659098307\n",
      "    val_log_joint  : 948.060292561849\n",
      "Train Epoch: 807 [0/54000 (0%)] Loss: -752.192017\n",
      "Train Epoch: 807 [11264/54000 (21%)] Loss: -750.594604\n",
      "Train Epoch: 807 [22528/54000 (42%)] Loss: -742.559692\n",
      "Train Epoch: 807 [33792/54000 (63%)] Loss: -729.503906\n",
      "Train Epoch: 807 [45056/54000 (83%)] Loss: -759.155884\n",
      "    epoch          : 807\n",
      "    loss           : -735.576778195939\n",
      "    ess            : 1.960440826865862\n",
      "    log_marginal   : 735.6111807193396\n",
      "    log_joint      : 944.0732001538547\n",
      "    val_loss       : -739.9925893147787\n",
      "    val_ess        : 1.9595909714698792\n",
      "    val_log_marginal: 740.0271555582682\n",
      "    val_log_joint  : 948.7284749348959\n",
      "Train Epoch: 808 [0/54000 (0%)] Loss: -740.550049\n",
      "Train Epoch: 808 [11264/54000 (21%)] Loss: -740.479614\n",
      "Train Epoch: 808 [22528/54000 (42%)] Loss: -728.383850\n",
      "Train Epoch: 808 [33792/54000 (63%)] Loss: -721.941040\n",
      "Train Epoch: 808 [45056/54000 (83%)] Loss: -744.598633\n",
      "    epoch          : 808\n",
      "    loss           : -735.6988726921801\n",
      "    ess            : 1.9601979165706995\n",
      "    log_marginal   : 735.7341469818691\n",
      "    log_joint      : 944.1430733158903\n",
      "    val_loss       : -740.6374766031901\n",
      "    val_ess        : 1.9629786411921184\n",
      "    val_log_marginal: 740.6709289550781\n",
      "    val_log_joint  : 949.0503692626953\n",
      "Train Epoch: 809 [0/54000 (0%)] Loss: -717.959229\n",
      "Train Epoch: 809 [11264/54000 (21%)] Loss: -704.108337\n",
      "Train Epoch: 809 [22528/54000 (42%)] Loss: -722.601562\n",
      "Train Epoch: 809 [33792/54000 (63%)] Loss: -746.592407\n",
      "Train Epoch: 809 [45056/54000 (83%)] Loss: -746.379517\n",
      "    epoch          : 809\n",
      "    loss           : -735.8087814618956\n",
      "    ess            : 1.959062712372474\n",
      "    log_marginal   : 735.8446804982311\n",
      "    log_joint      : 944.3282683750368\n",
      "    val_loss       : -739.7216593424479\n",
      "    val_ess        : 1.9614664912223816\n",
      "    val_log_marginal: 739.7554931640625\n",
      "    val_log_joint  : 948.1360677083334\n",
      "Train Epoch: 810 [0/54000 (0%)] Loss: -721.872314\n",
      "Train Epoch: 810 [11264/54000 (21%)] Loss: -727.301147\n",
      "Train Epoch: 810 [22528/54000 (42%)] Loss: -725.705994\n",
      "Train Epoch: 810 [33792/54000 (63%)] Loss: -728.774597\n",
      "Train Epoch: 810 [45056/54000 (83%)] Loss: -739.880310\n",
      "    epoch          : 810\n",
      "    loss           : -736.1412514740566\n",
      "    ess            : 1.960270128160153\n",
      "    log_marginal   : 736.1766472582547\n",
      "    log_joint      : 944.6184047483048\n",
      "    val_loss       : -740.496836344401\n",
      "    val_ess        : 1.9627507030963898\n",
      "    val_log_marginal: 740.5316569010416\n",
      "    val_log_joint  : 949.1214447021484\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch810.pth ...\n",
      "Train Epoch: 811 [0/54000 (0%)] Loss: -721.827881\n",
      "Train Epoch: 811 [11264/54000 (21%)] Loss: -746.341431\n",
      "Train Epoch: 811 [22528/54000 (42%)] Loss: -719.424011\n",
      "Train Epoch: 811 [33792/54000 (63%)] Loss: -722.376953\n",
      "Train Epoch: 811 [45056/54000 (83%)] Loss: -741.280334\n",
      "    epoch          : 811\n",
      "    loss           : -736.1243096117703\n",
      "    ess            : 1.9597905266959712\n",
      "    log_marginal   : 736.1600975180572\n",
      "    log_joint      : 944.5497972020563\n",
      "    val_loss       : -739.8904876708984\n",
      "    val_ess        : 1.9642778436342876\n",
      "    val_log_marginal: 739.9227447509766\n",
      "    val_log_joint  : 948.1060791015625\n",
      "Train Epoch: 812 [0/54000 (0%)] Loss: -721.837036\n",
      "Train Epoch: 812 [11264/54000 (21%)] Loss: -761.500977\n",
      "Train Epoch: 812 [22528/54000 (42%)] Loss: -740.784790\n",
      "Train Epoch: 812 [33792/54000 (63%)] Loss: -733.447754\n",
      "Train Epoch: 812 [45056/54000 (83%)] Loss: -755.548279\n",
      "    epoch          : 812\n",
      "    loss           : -736.2805901293484\n",
      "    ess            : 1.9595546587458197\n",
      "    log_marginal   : 736.3171789781103\n",
      "    log_joint      : 944.6928745485702\n",
      "    val_loss       : -740.3114318847656\n",
      "    val_ess        : 1.9633306960264842\n",
      "    val_log_marginal: 740.3422139485677\n",
      "    val_log_joint  : 948.7250111897787\n",
      "Train Epoch: 813 [0/54000 (0%)] Loss: -753.454041\n",
      "Train Epoch: 813 [11264/54000 (21%)] Loss: -749.852478\n",
      "Train Epoch: 813 [22528/54000 (42%)] Loss: -728.582886\n",
      "Train Epoch: 813 [33792/54000 (63%)] Loss: -734.153259\n",
      "Train Epoch: 813 [45056/54000 (83%)] Loss: -739.268127\n",
      "    epoch          : 813\n",
      "    loss           : -736.3500942014298\n",
      "    ess            : 1.9607659252184741\n",
      "    log_marginal   : 736.384856601931\n",
      "    log_joint      : 944.8229082215507\n",
      "    val_loss       : -740.9958038330078\n",
      "    val_ess        : 1.9634177883466084\n",
      "    val_log_marginal: 741.0261077880859\n",
      "    val_log_joint  : 949.1911061604818\n",
      "Train Epoch: 814 [0/54000 (0%)] Loss: -743.345703\n",
      "Train Epoch: 814 [11264/54000 (21%)] Loss: -754.809875\n",
      "Train Epoch: 814 [22528/54000 (42%)] Loss: -719.425415\n",
      "Train Epoch: 814 [33792/54000 (63%)] Loss: -711.593750\n",
      "Train Epoch: 814 [45056/54000 (83%)] Loss: -742.610352\n",
      "    epoch          : 814\n",
      "    loss           : -736.6545582897259\n",
      "    ess            : 1.9607654517551638\n",
      "    log_marginal   : 736.6889210826946\n",
      "    log_joint      : 945.0634846237471\n",
      "    val_loss       : -740.3722330729166\n",
      "    val_ess        : 1.9592325389385223\n",
      "    val_log_marginal: 740.406005859375\n",
      "    val_log_joint  : 949.0288645426432\n",
      "Train Epoch: 815 [0/54000 (0%)] Loss: -745.651245\n",
      "Train Epoch: 815 [11264/54000 (21%)] Loss: -762.091064\n",
      "Train Epoch: 815 [22528/54000 (42%)] Loss: -741.923035\n",
      "Train Epoch: 815 [33792/54000 (63%)] Loss: -747.595825\n",
      "Train Epoch: 815 [45056/54000 (83%)] Loss: -729.625183\n",
      "    epoch          : 815\n",
      "    loss           : -736.5671691894531\n",
      "    ess            : 1.960461674996142\n",
      "    log_marginal   : 736.60191201264\n",
      "    log_joint      : 945.0347819778154\n",
      "    val_loss       : -740.7191162109375\n",
      "    val_ess        : 1.9598335325717926\n",
      "    val_log_marginal: 740.7528025309244\n",
      "    val_log_joint  : 949.0111389160156\n",
      "Train Epoch: 816 [0/54000 (0%)] Loss: -730.355774\n",
      "Train Epoch: 816 [11264/54000 (21%)] Loss: -731.092041\n",
      "Train Epoch: 816 [22528/54000 (42%)] Loss: -750.747925\n",
      "Train Epoch: 816 [33792/54000 (63%)] Loss: -741.911255\n",
      "Train Epoch: 816 [45056/54000 (83%)] Loss: -732.547119\n",
      "    epoch          : 816\n",
      "    loss           : -736.8051377782282\n",
      "    ess            : 1.960464984740851\n",
      "    log_marginal   : 736.8406947873673\n",
      "    log_joint      : 945.2616058925413\n",
      "    val_loss       : -740.9731903076172\n",
      "    val_ess        : 1.9612197081247966\n",
      "    val_log_marginal: 741.0062408447266\n",
      "    val_log_joint  : 949.3329772949219\n",
      "Train Epoch: 817 [0/54000 (0%)] Loss: -724.780762\n",
      "Train Epoch: 817 [11264/54000 (21%)] Loss: -749.096680\n",
      "Train Epoch: 817 [22528/54000 (42%)] Loss: -752.097900\n",
      "Train Epoch: 817 [33792/54000 (63%)] Loss: -749.421631\n",
      "Train Epoch: 817 [45056/54000 (83%)] Loss: -740.801514\n",
      "    epoch          : 817\n",
      "    loss           : -736.8628424878391\n",
      "    ess            : 1.9595920713442676\n",
      "    log_marginal   : 736.8980183151533\n",
      "    log_joint      : 945.2450676684109\n",
      "    val_loss       : -741.1707204182943\n",
      "    val_ess        : 1.9616837998231251\n",
      "    val_log_marginal: 741.2047526041666\n",
      "    val_log_joint  : 949.6983846028646\n",
      "Train Epoch: 818 [0/54000 (0%)] Loss: -742.107117\n",
      "Train Epoch: 818 [11264/54000 (21%)] Loss: -725.871216\n",
      "Train Epoch: 818 [22528/54000 (42%)] Loss: -730.997803\n",
      "Train Epoch: 818 [33792/54000 (63%)] Loss: -723.228455\n",
      "Train Epoch: 818 [45056/54000 (83%)] Loss: -726.213318\n",
      "    epoch          : 818\n",
      "    loss           : -736.9303295207474\n",
      "    ess            : 1.9608032793368932\n",
      "    log_marginal   : 736.964551817696\n",
      "    log_joint      : 945.4409887925634\n",
      "    val_loss       : -741.1569620768229\n",
      "    val_ess        : 1.959642618894577\n",
      "    val_log_marginal: 741.1925048828125\n",
      "    val_log_joint  : 949.8096110026041\n",
      "Train Epoch: 819 [0/54000 (0%)] Loss: -723.645996\n",
      "Train Epoch: 819 [11264/54000 (21%)] Loss: -723.447266\n",
      "Train Epoch: 819 [22528/54000 (42%)] Loss: -739.047852\n",
      "Train Epoch: 819 [33792/54000 (63%)] Loss: -752.172607\n",
      "Train Epoch: 819 [45056/54000 (83%)] Loss: -728.795105\n",
      "    epoch          : 819\n",
      "    loss           : -737.1033279131044\n",
      "    ess            : 1.9599058616836116\n",
      "    log_marginal   : 737.139445754717\n",
      "    log_joint      : 945.543026330336\n",
      "    val_loss       : -740.9812062581381\n",
      "    val_ess        : 1.95888884862264\n",
      "    val_log_marginal: 741.021494547526\n",
      "    val_log_joint  : 949.2401529947916\n",
      "Train Epoch: 820 [0/54000 (0%)] Loss: -735.980591\n",
      "Train Epoch: 820 [11264/54000 (21%)] Loss: -725.008911\n",
      "Train Epoch: 820 [22528/54000 (42%)] Loss: -741.774109\n",
      "Train Epoch: 820 [33792/54000 (63%)] Loss: -730.025024\n",
      "Train Epoch: 820 [45056/54000 (83%)] Loss: -724.904175\n",
      "    epoch          : 820\n",
      "    loss           : -737.1773986816406\n",
      "    ess            : 1.9596010547763896\n",
      "    log_marginal   : 737.2132355312132\n",
      "    log_joint      : 945.7357557764593\n",
      "    val_loss       : -740.2393391927084\n",
      "    val_ess        : 1.9602687060832977\n",
      "    val_log_marginal: 740.2744852701823\n",
      "    val_log_joint  : 948.6571146647135\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch820.pth ...\n",
      "Train Epoch: 821 [0/54000 (0%)] Loss: -734.981567\n",
      "Train Epoch: 821 [11264/54000 (21%)] Loss: -739.045227\n",
      "Train Epoch: 821 [22528/54000 (42%)] Loss: -736.328369\n",
      "Train Epoch: 821 [33792/54000 (63%)] Loss: -727.936401\n",
      "Train Epoch: 821 [45056/54000 (83%)] Loss: -733.953491\n",
      "    epoch          : 821\n",
      "    loss           : -737.3694636506855\n",
      "    ess            : 1.96056696041575\n",
      "    log_marginal   : 737.4047886110702\n",
      "    log_joint      : 945.7692686836674\n",
      "    val_loss       : -741.0285085042318\n",
      "    val_ess        : 1.959465116262436\n",
      "    val_log_marginal: 741.0645243326823\n",
      "    val_log_joint  : 949.3959299723307\n",
      "Train Epoch: 822 [0/54000 (0%)] Loss: -748.458191\n",
      "Train Epoch: 822 [11264/54000 (21%)] Loss: -754.510864\n",
      "Train Epoch: 822 [22528/54000 (42%)] Loss: -730.056152\n",
      "Train Epoch: 822 [33792/54000 (63%)] Loss: -744.318237\n",
      "Train Epoch: 822 [45056/54000 (83%)] Loss: -729.522217\n",
      "    epoch          : 822\n",
      "    loss           : -737.2594650556456\n",
      "    ess            : 1.9598984650845797\n",
      "    log_marginal   : 737.2946944326725\n",
      "    log_joint      : 945.7851493403597\n",
      "    val_loss       : -741.2692006429037\n",
      "    val_ess        : 1.9633145431677501\n",
      "    val_log_marginal: 741.3010508219401\n",
      "    val_log_joint  : 949.83984375\n",
      "Train Epoch: 823 [0/54000 (0%)] Loss: -747.209473\n",
      "Train Epoch: 823 [11264/54000 (21%)] Loss: -747.245911\n",
      "Train Epoch: 823 [22528/54000 (42%)] Loss: -752.423218\n",
      "Train Epoch: 823 [33792/54000 (63%)] Loss: -729.816528\n",
      "Train Epoch: 823 [45056/54000 (83%)] Loss: -729.053040\n",
      "    epoch          : 823\n",
      "    loss           : -737.6538126243735\n",
      "    ess            : 1.960740918258451\n",
      "    log_marginal   : 737.68917558778\n",
      "    log_joint      : 946.0444808096256\n",
      "    val_loss       : -741.9329477945963\n",
      "    val_ess        : 1.962601552406947\n",
      "    val_log_marginal: 741.9657033284506\n",
      "    val_log_joint  : 950.3042958577474\n",
      "Train Epoch: 824 [0/54000 (0%)] Loss: -749.590759\n",
      "Train Epoch: 824 [11264/54000 (21%)] Loss: -752.679688\n",
      "Train Epoch: 824 [22528/54000 (42%)] Loss: -741.053467\n",
      "Train Epoch: 824 [33792/54000 (63%)] Loss: -759.130737\n",
      "Train Epoch: 824 [45056/54000 (83%)] Loss: -740.193726\n",
      "    epoch          : 824\n",
      "    loss           : -737.6117213986954\n",
      "    ess            : 1.959725726325557\n",
      "    log_marginal   : 737.6470728460348\n",
      "    log_joint      : 946.0597062020931\n",
      "    val_loss       : -741.2683715820312\n",
      "    val_ess        : 1.9579259753227234\n",
      "    val_log_marginal: 741.3074442545573\n",
      "    val_log_joint  : 949.8078155517578\n",
      "Train Epoch: 825 [0/54000 (0%)] Loss: -740.564087\n",
      "Train Epoch: 825 [11264/54000 (21%)] Loss: -732.013611\n",
      "Train Epoch: 825 [22528/54000 (42%)] Loss: -739.124939\n",
      "Train Epoch: 825 [33792/54000 (63%)] Loss: -744.419739\n",
      "Train Epoch: 825 [45056/54000 (83%)] Loss: -738.871155\n",
      "    epoch          : 825\n",
      "    loss           : -737.7120965921654\n",
      "    ess            : 1.9589258050018887\n",
      "    log_marginal   : 737.7486698942364\n",
      "    log_joint      : 946.1891427669885\n",
      "    val_loss       : -741.9900512695312\n",
      "    val_ess        : 1.963384707768758\n",
      "    val_log_marginal: 742.0196380615234\n",
      "    val_log_joint  : 950.4825032552084\n",
      "Train Epoch: 826 [0/54000 (0%)] Loss: -743.556152\n",
      "Train Epoch: 826 [11264/54000 (21%)] Loss: -770.971436\n",
      "Train Epoch: 826 [22528/54000 (42%)] Loss: -750.307129\n",
      "Train Epoch: 826 [33792/54000 (63%)] Loss: -722.357910\n",
      "Train Epoch: 826 [45056/54000 (83%)] Loss: -726.442261\n",
      "    epoch          : 826\n",
      "    loss           : -737.6850580179466\n",
      "    ess            : 1.9608034795185305\n",
      "    log_marginal   : 737.7203893121683\n",
      "    log_joint      : 946.177119992814\n",
      "    val_loss       : -741.9828236897787\n",
      "    val_ess        : 1.9605395297209423\n",
      "    val_log_marginal: 742.0182139078776\n",
      "    val_log_joint  : 950.4223175048828\n",
      "Train Epoch: 827 [0/54000 (0%)] Loss: -731.836853\n",
      "Train Epoch: 827 [11264/54000 (21%)] Loss: -727.704529\n",
      "Train Epoch: 827 [22528/54000 (42%)] Loss: -726.514038\n",
      "Train Epoch: 827 [33792/54000 (63%)] Loss: -752.035156\n",
      "Train Epoch: 827 [45056/54000 (83%)] Loss: -734.784119\n",
      "    epoch          : 827\n",
      "    loss           : -738.0580830124189\n",
      "    ess            : 1.96024918106367\n",
      "    log_marginal   : 738.0924106813827\n",
      "    log_joint      : 946.513063826651\n",
      "    val_loss       : -742.3116353352865\n",
      "    val_ess        : 1.9634680251280467\n",
      "    val_log_marginal: 742.3424682617188\n",
      "    val_log_joint  : 950.5979970296224\n",
      "Train Epoch: 828 [0/54000 (0%)] Loss: -743.027466\n",
      "Train Epoch: 828 [11264/54000 (21%)] Loss: -743.062866\n",
      "Train Epoch: 828 [22528/54000 (42%)] Loss: -753.760742\n",
      "Train Epoch: 828 [33792/54000 (63%)] Loss: -732.670166\n",
      "Train Epoch: 828 [45056/54000 (83%)] Loss: -744.588989\n",
      "    epoch          : 828\n",
      "    loss           : -738.1841989193323\n",
      "    ess            : 1.960574080359261\n",
      "    log_marginal   : 738.218756333837\n",
      "    log_joint      : 946.6195494453862\n",
      "    val_loss       : -742.4377136230469\n",
      "    val_ess        : 1.9590261181195576\n",
      "    val_log_marginal: 742.4719390869141\n",
      "    val_log_joint  : 950.6913045247396\n",
      "Train Epoch: 829 [0/54000 (0%)] Loss: -758.494263\n",
      "Train Epoch: 829 [11264/54000 (21%)] Loss: -745.011536\n",
      "Train Epoch: 829 [22528/54000 (42%)] Loss: -740.755859\n",
      "Train Epoch: 829 [33792/54000 (63%)] Loss: -709.556763\n",
      "Train Epoch: 829 [45056/54000 (83%)] Loss: -725.401855\n",
      "    epoch          : 829\n",
      "    loss           : -738.2642874087927\n",
      "    ess            : 1.9607589312319487\n",
      "    log_marginal   : 738.2987711204672\n",
      "    log_joint      : 946.6448502450619\n",
      "    val_loss       : -742.8395182291666\n",
      "    val_ess        : 1.9590843121210735\n",
      "    val_log_marginal: 742.8731384277344\n",
      "    val_log_joint  : 951.3338317871094\n",
      "Train Epoch: 830 [0/54000 (0%)] Loss: -712.529907\n",
      "Train Epoch: 830 [11264/54000 (21%)] Loss: -753.419312\n",
      "Train Epoch: 830 [22528/54000 (42%)] Loss: -745.944885\n",
      "Train Epoch: 830 [33792/54000 (63%)] Loss: -742.440186\n",
      "Train Epoch: 830 [45056/54000 (83%)] Loss: -745.406738\n",
      "    epoch          : 830\n",
      "    loss           : -738.2935307340802\n",
      "    ess            : 1.9595920814658112\n",
      "    log_marginal   : 738.3283605035746\n",
      "    log_joint      : 946.8248279499558\n",
      "    val_loss       : -741.9518229166666\n",
      "    val_ess        : 1.962053696314494\n",
      "    val_log_marginal: 741.9839121500651\n",
      "    val_log_joint  : 950.461924235026\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch830.pth ...\n",
      "Train Epoch: 831 [0/54000 (0%)] Loss: -740.633484\n",
      "Train Epoch: 831 [11264/54000 (21%)] Loss: -749.528625\n",
      "Train Epoch: 831 [22528/54000 (42%)] Loss: -745.804382\n",
      "Train Epoch: 831 [33792/54000 (63%)] Loss: -739.239075\n",
      "Train Epoch: 831 [45056/54000 (83%)] Loss: -732.214417\n",
      "    epoch          : 831\n",
      "    loss           : -738.7465440282282\n",
      "    ess            : 1.9611516190025042\n",
      "    log_marginal   : 738.7809822514372\n",
      "    log_joint      : 947.1437619767099\n",
      "    val_loss       : -743.3951772054037\n",
      "    val_ess        : 1.960551490386327\n",
      "    val_log_marginal: 743.4267120361328\n",
      "    val_log_joint  : 951.8616383870443\n",
      "Train Epoch: 832 [0/54000 (0%)] Loss: -727.747498\n",
      "Train Epoch: 832 [11264/54000 (21%)] Loss: -734.784424\n",
      "Train Epoch: 832 [22528/54000 (42%)] Loss: -761.063477\n",
      "Train Epoch: 832 [33792/54000 (63%)] Loss: -743.321899\n",
      "Train Epoch: 832 [45056/54000 (83%)] Loss: -723.011353\n",
      "    epoch          : 832\n",
      "    loss           : -738.600542752248\n",
      "    ess            : 1.9591419696807861\n",
      "    log_marginal   : 738.6367815125664\n",
      "    log_joint      : 947.0159031130233\n",
      "    val_loss       : -742.3358052571615\n",
      "    val_ess        : 1.9635910391807556\n",
      "    val_log_marginal: 742.364247639974\n",
      "    val_log_joint  : 950.8395233154297\n",
      "Train Epoch: 833 [0/54000 (0%)] Loss: -749.860474\n",
      "Train Epoch: 833 [11264/54000 (21%)] Loss: -733.925415\n",
      "Train Epoch: 833 [22528/54000 (42%)] Loss: -736.156738\n",
      "Train Epoch: 833 [33792/54000 (63%)] Loss: -741.278564\n",
      "Train Epoch: 833 [45056/54000 (83%)] Loss: -735.014648\n",
      "    epoch          : 833\n",
      "    loss           : -738.8034570082178\n",
      "    ess            : 1.9605334940946326\n",
      "    log_marginal   : 738.838733025317\n",
      "    log_joint      : 947.2795421672317\n",
      "    val_loss       : -743.0352427164713\n",
      "    val_ess        : 1.9625774721304576\n",
      "    val_log_marginal: 743.0684814453125\n",
      "    val_log_joint  : 951.3571217854818\n",
      "Train Epoch: 834 [0/54000 (0%)] Loss: -739.795837\n",
      "Train Epoch: 834 [11264/54000 (21%)] Loss: -738.139160\n",
      "Train Epoch: 834 [22528/54000 (42%)] Loss: -743.987915\n",
      "Train Epoch: 834 [33792/54000 (63%)] Loss: -740.299316\n",
      "Train Epoch: 834 [45056/54000 (83%)] Loss: -744.175598\n",
      "    epoch          : 834\n",
      "    loss           : -739.0279949836012\n",
      "    ess            : 1.9594823155763015\n",
      "    log_marginal   : 739.062870241561\n",
      "    log_joint      : 947.356619205115\n",
      "    val_loss       : -742.3825225830078\n",
      "    val_ess        : 1.9617273211479187\n",
      "    val_log_marginal: 742.4154561360677\n",
      "    val_log_joint  : 950.9787241617838\n",
      "Train Epoch: 835 [0/54000 (0%)] Loss: -689.784973\n",
      "Train Epoch: 835 [11264/54000 (21%)] Loss: -751.130859\n",
      "Train Epoch: 835 [22528/54000 (42%)] Loss: -738.735962\n",
      "Train Epoch: 835 [33792/54000 (63%)] Loss: -740.567261\n",
      "Train Epoch: 835 [45056/54000 (83%)] Loss: -751.092773\n",
      "    epoch          : 835\n",
      "    loss           : -738.9746139814268\n",
      "    ess            : 1.9602873910148189\n",
      "    log_marginal   : 739.0094328106575\n",
      "    log_joint      : 947.3714824172686\n",
      "    val_loss       : -742.6674041748047\n",
      "    val_ess        : 1.9563708504041035\n",
      "    val_log_marginal: 742.7052917480469\n",
      "    val_log_joint  : 951.2190653483073\n",
      "Train Epoch: 836 [0/54000 (0%)] Loss: -740.796021\n",
      "Train Epoch: 836 [11264/54000 (21%)] Loss: -732.945618\n",
      "Train Epoch: 836 [22528/54000 (42%)] Loss: -723.982849\n",
      "Train Epoch: 836 [33792/54000 (63%)] Loss: -741.917603\n",
      "Train Epoch: 836 [45056/54000 (83%)] Loss: -762.021484\n",
      "    epoch          : 836\n",
      "    loss           : -738.9649669719192\n",
      "    ess            : 1.9612210629121312\n",
      "    log_marginal   : 738.9991213240713\n",
      "    log_joint      : 947.4958663076725\n",
      "    val_loss       : -743.0408579508463\n",
      "    val_ess        : 1.9601438840230305\n",
      "    val_log_marginal: 743.0756327311198\n",
      "    val_log_joint  : 951.47900390625\n",
      "Train Epoch: 837 [0/54000 (0%)] Loss: -718.138916\n",
      "Train Epoch: 837 [11264/54000 (21%)] Loss: -757.895813\n",
      "Train Epoch: 837 [22528/54000 (42%)] Loss: -748.072998\n",
      "Train Epoch: 837 [33792/54000 (63%)] Loss: -737.898682\n",
      "Train Epoch: 837 [45056/54000 (83%)] Loss: -724.813599\n",
      "    epoch          : 837\n",
      "    loss           : -739.0999358555056\n",
      "    ess            : 1.9590284914340612\n",
      "    log_marginal   : 739.1363968759213\n",
      "    log_joint      : 947.5258178710938\n",
      "    val_loss       : -743.6720377604166\n",
      "    val_ess        : 1.9576350251833599\n",
      "    val_log_marginal: 743.7102355957031\n",
      "    val_log_joint  : 952.0745849609375\n",
      "Train Epoch: 838 [0/54000 (0%)] Loss: -742.929504\n",
      "Train Epoch: 838 [11264/54000 (21%)] Loss: -751.089966\n",
      "Train Epoch: 838 [22528/54000 (42%)] Loss: -725.011108\n",
      "Train Epoch: 838 [33792/54000 (63%)] Loss: -737.951294\n",
      "Train Epoch: 838 [45056/54000 (83%)] Loss: -723.713440\n",
      "    epoch          : 838\n",
      "    loss           : -739.0944927863355\n",
      "    ess            : 1.958604266058724\n",
      "    log_marginal   : 739.1311472766804\n",
      "    log_joint      : 947.5625391546286\n",
      "    val_loss       : -744.0827128092448\n",
      "    val_ess        : 1.9592199424902599\n",
      "    val_log_marginal: 744.1170094807943\n",
      "    val_log_joint  : 952.5049794514974\n",
      "Train Epoch: 839 [0/54000 (0%)] Loss: -744.298157\n",
      "Train Epoch: 839 [11264/54000 (21%)] Loss: -746.553345\n",
      "Train Epoch: 839 [22528/54000 (42%)] Loss: -717.365784\n",
      "Train Epoch: 839 [33792/54000 (63%)] Loss: -754.047974\n",
      "Train Epoch: 839 [45056/54000 (83%)] Loss: -747.384888\n",
      "    epoch          : 839\n",
      "    loss           : -739.2741975604363\n",
      "    ess            : 1.9606021350284792\n",
      "    log_marginal   : 739.3085154407429\n",
      "    log_joint      : 947.7401744914505\n",
      "    val_loss       : -743.3544158935547\n",
      "    val_ess        : 1.9594544370969136\n",
      "    val_log_marginal: 743.3890380859375\n",
      "    val_log_joint  : 951.9131927490234\n",
      "Train Epoch: 840 [0/54000 (0%)] Loss: -734.131470\n",
      "Train Epoch: 840 [11264/54000 (21%)] Loss: -736.862671\n",
      "Train Epoch: 840 [22528/54000 (42%)] Loss: -732.172546\n",
      "Train Epoch: 840 [33792/54000 (63%)] Loss: -742.532166\n",
      "Train Epoch: 840 [45056/54000 (83%)] Loss: -730.706421\n",
      "    epoch          : 840\n",
      "    loss           : -739.2647751142393\n",
      "    ess            : 1.9597131070101037\n",
      "    log_marginal   : 739.3007029407429\n",
      "    log_joint      : 947.6356172381707\n",
      "    val_loss       : -743.4334615071615\n",
      "    val_ess        : 1.9605409502983093\n",
      "    val_log_marginal: 743.4665679931641\n",
      "    val_log_joint  : 951.960703531901\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch840.pth ...\n",
      "Train Epoch: 841 [0/54000 (0%)] Loss: -737.071289\n",
      "Train Epoch: 841 [11264/54000 (21%)] Loss: -742.851196\n",
      "Train Epoch: 841 [22528/54000 (42%)] Loss: -730.270752\n",
      "Train Epoch: 841 [33792/54000 (63%)] Loss: -729.876953\n",
      "Train Epoch: 841 [45056/54000 (83%)] Loss: -744.486694\n",
      "    epoch          : 841\n",
      "    loss           : -739.6515456865419\n",
      "    ess            : 1.959649900220475\n",
      "    log_marginal   : 739.688251423386\n",
      "    log_joint      : 948.1493259645858\n",
      "    val_loss       : -743.6280975341797\n",
      "    val_ess        : 1.9574588040510814\n",
      "    val_log_marginal: 743.6638946533203\n",
      "    val_log_joint  : 952.1485697428385\n",
      "Train Epoch: 842 [0/54000 (0%)] Loss: -718.041504\n",
      "Train Epoch: 842 [11264/54000 (21%)] Loss: -766.518677\n",
      "Train Epoch: 842 [22528/54000 (42%)] Loss: -745.974976\n",
      "Train Epoch: 842 [33792/54000 (63%)] Loss: -734.707031\n",
      "Train Epoch: 842 [45056/54000 (83%)] Loss: -718.111572\n",
      "    epoch          : 842\n",
      "    loss           : -739.6286344708137\n",
      "    ess            : 1.9605837902932797\n",
      "    log_marginal   : 739.6638436947229\n",
      "    log_joint      : 948.0318879901238\n",
      "    val_loss       : -744.2274373372396\n",
      "    val_ess        : 1.9593364199002583\n",
      "    val_log_marginal: 744.2684427897135\n",
      "    val_log_joint  : 952.6362915039062\n",
      "Train Epoch: 843 [0/54000 (0%)] Loss: -755.134888\n",
      "Train Epoch: 843 [11264/54000 (21%)] Loss: -757.326050\n",
      "Train Epoch: 843 [22528/54000 (42%)] Loss: -734.810486\n",
      "Train Epoch: 843 [33792/54000 (63%)] Loss: -766.813049\n",
      "Train Epoch: 843 [45056/54000 (83%)] Loss: -765.533508\n",
      "    epoch          : 843\n",
      "    loss           : -739.8463699052919\n",
      "    ess            : 1.9600676421849232\n",
      "    log_marginal   : 739.8833762114903\n",
      "    log_joint      : 948.2329769494398\n",
      "    val_loss       : -743.9026794433594\n",
      "    val_ess        : 1.9636759559313457\n",
      "    val_log_marginal: 743.9317423502604\n",
      "    val_log_joint  : 952.1451466878256\n",
      "Train Epoch: 844 [0/54000 (0%)] Loss: -734.921753\n",
      "Train Epoch: 844 [11264/54000 (21%)] Loss: -724.964111\n",
      "Train Epoch: 844 [22528/54000 (42%)] Loss: -757.665771\n",
      "Train Epoch: 844 [33792/54000 (63%)] Loss: -735.894226\n",
      "Train Epoch: 844 [45056/54000 (83%)] Loss: -726.078186\n",
      "    epoch          : 844\n",
      "    loss           : -739.8732535884066\n",
      "    ess            : 1.959974801765298\n",
      "    log_marginal   : 739.909931110886\n",
      "    log_joint      : 948.2744054254496\n",
      "    val_loss       : -743.9720611572266\n",
      "    val_ess        : 1.9597854415575664\n",
      "    val_log_marginal: 744.0062459309896\n",
      "    val_log_joint  : 952.5810750325521\n",
      "Train Epoch: 845 [0/54000 (0%)] Loss: -739.895935\n",
      "Train Epoch: 845 [11264/54000 (21%)] Loss: -745.529907\n",
      "Train Epoch: 845 [22528/54000 (42%)] Loss: -722.943481\n",
      "Train Epoch: 845 [33792/54000 (63%)] Loss: -758.554138\n",
      "Train Epoch: 845 [45056/54000 (83%)] Loss: -717.700012\n",
      "    epoch          : 845\n",
      "    loss           : -739.9697484430277\n",
      "    ess            : 1.961210601734665\n",
      "    log_marginal   : 740.0054033387382\n",
      "    log_joint      : 948.3410805756191\n",
      "    val_loss       : -743.7230580647787\n",
      "    val_ess        : 1.9633775452772777\n",
      "    val_log_marginal: 743.7537384033203\n",
      "    val_log_joint  : 952.2980041503906\n",
      "Train Epoch: 846 [0/54000 (0%)] Loss: -753.648315\n",
      "Train Epoch: 846 [11264/54000 (21%)] Loss: -751.099487\n",
      "Train Epoch: 846 [22528/54000 (42%)] Loss: -754.730957\n",
      "Train Epoch: 846 [33792/54000 (63%)] Loss: -736.249817\n",
      "Train Epoch: 846 [45056/54000 (83%)] Loss: -743.273315\n",
      "    epoch          : 846\n",
      "    loss           : -739.9544896539652\n",
      "    ess            : 1.960427294362266\n",
      "    log_marginal   : 739.9899948408018\n",
      "    log_joint      : 948.3758061247052\n",
      "    val_loss       : -743.6717885335287\n",
      "    val_ess        : 1.9603140254815419\n",
      "    val_log_marginal: 743.706797281901\n",
      "    val_log_joint  : 952.3130900065104\n",
      "Train Epoch: 847 [0/54000 (0%)] Loss: -743.140015\n",
      "Train Epoch: 847 [11264/54000 (21%)] Loss: -726.767578\n",
      "Train Epoch: 847 [22528/54000 (42%)] Loss: -742.794861\n",
      "Train Epoch: 847 [33792/54000 (63%)] Loss: -752.465820\n",
      "Train Epoch: 847 [45056/54000 (83%)] Loss: -730.384033\n",
      "    epoch          : 847\n",
      "    loss           : -740.1142566608933\n",
      "    ess            : 1.9596293703565058\n",
      "    log_marginal   : 740.1509813992483\n",
      "    log_joint      : 948.6058263238871\n",
      "    val_loss       : -744.2667643229166\n",
      "    val_ess        : 1.95594522356987\n",
      "    val_log_marginal: 744.3072865804037\n",
      "    val_log_joint  : 952.8135732014974\n",
      "Train Epoch: 848 [0/54000 (0%)] Loss: -717.897766\n",
      "Train Epoch: 848 [11264/54000 (21%)] Loss: -736.688477\n",
      "Train Epoch: 848 [22528/54000 (42%)] Loss: -738.376953\n",
      "Train Epoch: 848 [33792/54000 (63%)] Loss: -735.489014\n",
      "Train Epoch: 848 [45056/54000 (83%)] Loss: -731.558838\n",
      "    epoch          : 848\n",
      "    loss           : -740.0245073426445\n",
      "    ess            : 1.961312786588129\n",
      "    log_marginal   : 740.0573459841171\n",
      "    log_joint      : 948.5411221486218\n",
      "    val_loss       : -744.1586100260416\n",
      "    val_ess        : 1.9596445361773174\n",
      "    val_log_marginal: 744.1923319498698\n",
      "    val_log_joint  : 952.6776529947916\n",
      "Train Epoch: 849 [0/54000 (0%)] Loss: -730.510315\n",
      "Train Epoch: 849 [11264/54000 (21%)] Loss: -748.690552\n",
      "Train Epoch: 849 [22528/54000 (42%)] Loss: -727.492065\n",
      "Train Epoch: 849 [33792/54000 (63%)] Loss: -729.574829\n",
      "Train Epoch: 849 [45056/54000 (83%)] Loss: -731.274170\n",
      "    epoch          : 849\n",
      "    loss           : -740.4785950858638\n",
      "    ess            : 1.9600213709867225\n",
      "    log_marginal   : 740.5138008549528\n",
      "    log_joint      : 949.0119985904333\n",
      "    val_loss       : -744.9996643066406\n",
      "    val_ess        : 1.960059493780136\n",
      "    val_log_marginal: 745.0356190999349\n",
      "    val_log_joint  : 953.3661244710287\n",
      "Train Epoch: 850 [0/54000 (0%)] Loss: -757.676270\n",
      "Train Epoch: 850 [11264/54000 (21%)] Loss: -759.470093\n",
      "Train Epoch: 850 [22528/54000 (42%)] Loss: -745.945251\n",
      "Train Epoch: 850 [33792/54000 (63%)] Loss: -720.552734\n",
      "Train Epoch: 850 [45056/54000 (83%)] Loss: -744.537903\n",
      "    epoch          : 850\n",
      "    loss           : -740.3265720583358\n",
      "    ess            : 1.9604017813250703\n",
      "    log_marginal   : 740.3610678618809\n",
      "    log_joint      : 948.9729867611292\n",
      "    val_loss       : -744.9024912516276\n",
      "    val_ess        : 1.9634596904118855\n",
      "    val_log_marginal: 744.9355824788412\n",
      "    val_log_joint  : 953.3421986897787\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [0/54000 (0%)] Loss: -743.000793\n",
      "Train Epoch: 851 [11264/54000 (21%)] Loss: -761.924805\n",
      "Train Epoch: 851 [22528/54000 (42%)] Loss: -748.794983\n",
      "Train Epoch: 851 [33792/54000 (63%)] Loss: -766.724243\n",
      "Train Epoch: 851 [45056/54000 (83%)] Loss: -722.923645\n",
      "    epoch          : 851\n",
      "    loss           : -740.6732459878021\n",
      "    ess            : 1.9607423319006867\n",
      "    log_marginal   : 740.7076064775575\n",
      "    log_joint      : 949.1487587982754\n",
      "    val_loss       : -745.0423482259115\n",
      "    val_ess        : 1.9587917923927307\n",
      "    val_log_marginal: 745.0769399007162\n",
      "    val_log_joint  : 953.6371307373047\n",
      "Train Epoch: 852 [0/54000 (0%)] Loss: -733.520996\n",
      "Train Epoch: 852 [11264/54000 (21%)] Loss: -736.842773\n",
      "Train Epoch: 852 [22528/54000 (42%)] Loss: -722.837036\n",
      "Train Epoch: 852 [33792/54000 (63%)] Loss: -746.889282\n",
      "Train Epoch: 852 [45056/54000 (83%)] Loss: -725.859802\n",
      "    epoch          : 852\n",
      "    loss           : -740.8834320644163\n",
      "    ess            : 1.9612880720282502\n",
      "    log_marginal   : 740.9177983122052\n",
      "    log_joint      : 949.3650403292673\n",
      "    val_loss       : -745.1146697998047\n",
      "    val_ess        : 1.960313081741333\n",
      "    val_log_marginal: 745.1507517496744\n",
      "    val_log_joint  : 953.593495686849\n",
      "Train Epoch: 853 [0/54000 (0%)] Loss: -776.421021\n",
      "Train Epoch: 853 [11264/54000 (21%)] Loss: -753.051025\n",
      "Train Epoch: 853 [22528/54000 (42%)] Loss: -735.627686\n",
      "Train Epoch: 853 [33792/54000 (63%)] Loss: -752.777222\n",
      "Train Epoch: 853 [45056/54000 (83%)] Loss: -732.191895\n",
      "    epoch          : 853\n",
      "    loss           : -741.1617397092423\n",
      "    ess            : 1.960765909473851\n",
      "    log_marginal   : 741.1963155494547\n",
      "    log_joint      : 949.6172686882738\n",
      "    val_loss       : -745.0219217936198\n",
      "    val_ess        : 1.9617209235827129\n",
      "    val_log_marginal: 745.0528920491537\n",
      "    val_log_joint  : 953.3911641438802\n",
      "Train Epoch: 854 [0/54000 (0%)] Loss: -731.708801\n",
      "Train Epoch: 854 [11264/54000 (21%)] Loss: -747.509583\n",
      "Train Epoch: 854 [22528/54000 (42%)] Loss: -765.982178\n",
      "Train Epoch: 854 [33792/54000 (63%)] Loss: -747.509705\n",
      "Train Epoch: 854 [45056/54000 (83%)] Loss: -706.767578\n",
      "    epoch          : 854\n",
      "    loss           : -741.0469112756117\n",
      "    ess            : 1.9590485174700898\n",
      "    log_marginal   : 741.0835818884508\n",
      "    log_joint      : 949.4911067170917\n",
      "    val_loss       : -745.2207692464193\n",
      "    val_ess        : 1.9569026629130046\n",
      "    val_log_marginal: 745.2578125\n",
      "    val_log_joint  : 953.6263783772787\n",
      "Train Epoch: 855 [0/54000 (0%)] Loss: -729.969849\n",
      "Train Epoch: 855 [11264/54000 (21%)] Loss: -752.477295\n",
      "Train Epoch: 855 [22528/54000 (42%)] Loss: -744.052490\n",
      "Train Epoch: 855 [33792/54000 (63%)] Loss: -748.696899\n",
      "Train Epoch: 855 [45056/54000 (83%)] Loss: -748.527588\n",
      "    epoch          : 855\n",
      "    loss           : -741.1353431557709\n",
      "    ess            : 1.9600118938482032\n",
      "    log_marginal   : 741.171484029518\n",
      "    log_joint      : 949.6281001252948\n",
      "    val_loss       : -745.1942749023438\n",
      "    val_ess        : 1.9599895278612773\n",
      "    val_log_marginal: 745.2278340657552\n",
      "    val_log_joint  : 953.5984039306641\n",
      "Train Epoch: 856 [0/54000 (0%)] Loss: -727.974854\n",
      "Train Epoch: 856 [11264/54000 (21%)] Loss: -731.141785\n",
      "Train Epoch: 856 [22528/54000 (42%)] Loss: -707.007690\n",
      "Train Epoch: 856 [33792/54000 (63%)] Loss: -726.650269\n",
      "Train Epoch: 856 [45056/54000 (83%)] Loss: -748.229614\n",
      "    epoch          : 856\n",
      "    loss           : -741.6577177227668\n",
      "    ess            : 1.9598260600611848\n",
      "    log_marginal   : 741.6932096661262\n",
      "    log_joint      : 949.9962584297612\n",
      "    val_loss       : -745.0661010742188\n",
      "    val_ess        : 1.9618825415770214\n",
      "    val_log_marginal: 745.0986531575521\n",
      "    val_log_joint  : 953.4302215576172\n",
      "Train Epoch: 857 [0/54000 (0%)] Loss: -734.054077\n",
      "Train Epoch: 857 [11264/54000 (21%)] Loss: -722.877869\n",
      "Train Epoch: 857 [22528/54000 (42%)] Loss: -741.702881\n",
      "Train Epoch: 857 [33792/54000 (63%)] Loss: -759.365967\n",
      "Train Epoch: 857 [45056/54000 (83%)] Loss: -751.901550\n",
      "    epoch          : 857\n",
      "    loss           : -741.5255599111881\n",
      "    ess            : 1.9596776906049476\n",
      "    log_marginal   : 741.5610524303509\n",
      "    log_joint      : 949.9716244103773\n",
      "    val_loss       : -745.4609883626302\n",
      "    val_ess        : 1.9635363320509593\n",
      "    val_log_marginal: 745.4934844970703\n",
      "    val_log_joint  : 954.0503590901693\n",
      "Train Epoch: 858 [0/54000 (0%)] Loss: -764.650452\n",
      "Train Epoch: 858 [11264/54000 (21%)] Loss: -730.073181\n",
      "Train Epoch: 858 [22528/54000 (42%)] Loss: -741.892944\n",
      "Train Epoch: 858 [33792/54000 (63%)] Loss: -747.567261\n",
      "Train Epoch: 858 [45056/54000 (83%)] Loss: -764.315125\n",
      "    epoch          : 858\n",
      "    loss           : -741.5300120227741\n",
      "    ess            : 1.9605292947787158\n",
      "    log_marginal   : 741.565094569944\n",
      "    log_joint      : 949.9503876308225\n",
      "    val_loss       : -745.2326100667318\n",
      "    val_ess        : 1.9561744332313538\n",
      "    val_log_marginal: 745.2757364908854\n",
      "    val_log_joint  : 953.7811635335287\n",
      "Train Epoch: 859 [0/54000 (0%)] Loss: -741.211731\n",
      "Train Epoch: 859 [11264/54000 (21%)] Loss: -734.395264\n",
      "Train Epoch: 859 [22528/54000 (42%)] Loss: -727.502930\n",
      "Train Epoch: 859 [33792/54000 (63%)] Loss: -723.246704\n",
      "Train Epoch: 859 [45056/54000 (83%)] Loss: -734.616821\n",
      "    epoch          : 859\n",
      "    loss           : -741.459697795364\n",
      "    ess            : 1.9593965444924697\n",
      "    log_marginal   : 741.496805442954\n",
      "    log_joint      : 949.9655894153523\n",
      "    val_loss       : -746.0734456380209\n",
      "    val_ess        : 1.9575437903404236\n",
      "    val_log_marginal: 746.1106669108073\n",
      "    val_log_joint  : 954.2954152425131\n",
      "Train Epoch: 860 [0/54000 (0%)] Loss: -727.173462\n",
      "Train Epoch: 860 [11264/54000 (21%)] Loss: -738.606689\n",
      "Train Epoch: 860 [22528/54000 (42%)] Loss: -737.362610\n",
      "Train Epoch: 860 [33792/54000 (63%)] Loss: -746.539795\n",
      "Train Epoch: 860 [45056/54000 (83%)] Loss: -740.827148\n",
      "    epoch          : 860\n",
      "    loss           : -741.5412758881191\n",
      "    ess            : 1.9594926777875648\n",
      "    log_marginal   : 741.5783656858048\n",
      "    log_joint      : 950.1235668254349\n",
      "    val_loss       : -745.7136383056641\n",
      "    val_ess        : 1.9605087836583455\n",
      "    val_log_marginal: 745.7490793863932\n",
      "    val_log_joint  : 954.3473256429037\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch860.pth ...\n",
      "Train Epoch: 861 [0/54000 (0%)] Loss: -733.034363\n",
      "Train Epoch: 861 [11264/54000 (21%)] Loss: -740.084351\n",
      "Train Epoch: 861 [22528/54000 (42%)] Loss: -748.855774\n",
      "Train Epoch: 861 [33792/54000 (63%)] Loss: -744.728271\n",
      "Train Epoch: 861 [45056/54000 (83%)] Loss: -736.033569\n",
      "    epoch          : 861\n",
      "    loss           : -741.528417623268\n",
      "    ess            : 1.9598289435764529\n",
      "    log_marginal   : 741.5651815162515\n",
      "    log_joint      : 950.0799295677328\n",
      "    val_loss       : -746.3012440999349\n",
      "    val_ess        : 1.9591439266999562\n",
      "    val_log_marginal: 746.3385721842448\n",
      "    val_log_joint  : 954.7619578043619\n",
      "Train Epoch: 862 [0/54000 (0%)] Loss: -736.031433\n",
      "Train Epoch: 862 [11264/54000 (21%)] Loss: -745.881714\n",
      "Train Epoch: 862 [22528/54000 (42%)] Loss: -732.970825\n",
      "Train Epoch: 862 [33792/54000 (63%)] Loss: -748.899414\n",
      "Train Epoch: 862 [45056/54000 (83%)] Loss: -731.423279\n",
      "    epoch          : 862\n",
      "    loss           : -741.8237529250811\n",
      "    ess            : 1.9594062161895465\n",
      "    log_marginal   : 741.8606964687132\n",
      "    log_joint      : 950.3324268269089\n",
      "    val_loss       : -745.9001668294271\n",
      "    val_ess        : 1.9588106671969097\n",
      "    val_log_marginal: 745.9384765625\n",
      "    val_log_joint  : 954.7491200764974\n",
      "Train Epoch: 863 [0/54000 (0%)] Loss: -734.270081\n",
      "Train Epoch: 863 [11264/54000 (21%)] Loss: -737.737061\n",
      "Train Epoch: 863 [22528/54000 (42%)] Loss: -768.201294\n",
      "Train Epoch: 863 [33792/54000 (63%)] Loss: -722.351074\n",
      "Train Epoch: 863 [45056/54000 (83%)] Loss: -739.610413\n",
      "    epoch          : 863\n",
      "    loss           : -741.8375520526238\n",
      "    ess            : 1.9603732745602447\n",
      "    log_marginal   : 741.8726881495062\n",
      "    log_joint      : 950.3034633420548\n",
      "    val_loss       : -745.7851715087891\n",
      "    val_ess        : 1.9597025215625763\n",
      "    val_log_marginal: 745.8180745442709\n",
      "    val_log_joint  : 954.5005340576172\n",
      "Train Epoch: 864 [0/54000 (0%)] Loss: -732.591064\n",
      "Train Epoch: 864 [11264/54000 (21%)] Loss: -744.868103\n",
      "Train Epoch: 864 [22528/54000 (42%)] Loss: -760.951538\n",
      "Train Epoch: 864 [33792/54000 (63%)] Loss: -719.222656\n",
      "Train Epoch: 864 [45056/54000 (83%)] Loss: -740.300476\n",
      "    epoch          : 864\n",
      "    loss           : -741.9691858831442\n",
      "    ess            : 1.9608069602048621\n",
      "    log_marginal   : 742.0041175698334\n",
      "    log_joint      : 950.4414223724941\n",
      "    val_loss       : -747.0256296793619\n",
      "    val_ess        : 1.9603477815786998\n",
      "    val_log_marginal: 747.0611165364584\n",
      "    val_log_joint  : 955.4802856445312\n",
      "Train Epoch: 865 [0/54000 (0%)] Loss: -749.312805\n",
      "Train Epoch: 865 [11264/54000 (21%)] Loss: -728.995117\n",
      "Train Epoch: 865 [22528/54000 (42%)] Loss: -732.649658\n",
      "Train Epoch: 865 [33792/54000 (63%)] Loss: -744.729492\n",
      "Train Epoch: 865 [45056/54000 (83%)] Loss: -757.992554\n",
      "    epoch          : 865\n",
      "    loss           : -742.2949926988134\n",
      "    ess            : 1.959759218512841\n",
      "    log_marginal   : 742.3305560417895\n",
      "    log_joint      : 950.7871450748083\n",
      "    val_loss       : -745.3201446533203\n",
      "    val_ess        : 1.957119236389796\n",
      "    val_log_marginal: 745.3582305908203\n",
      "    val_log_joint  : 953.9076232910156\n",
      "Train Epoch: 866 [0/54000 (0%)] Loss: -744.942261\n",
      "Train Epoch: 866 [11264/54000 (21%)] Loss: -769.004028\n",
      "Train Epoch: 866 [22528/54000 (42%)] Loss: -737.514648\n",
      "Train Epoch: 866 [33792/54000 (63%)] Loss: -728.920044\n",
      "Train Epoch: 866 [45056/54000 (83%)] Loss: -733.039246\n",
      "    epoch          : 866\n",
      "    loss           : -741.9264606979658\n",
      "    ess            : 1.9603401400008291\n",
      "    log_marginal   : 741.9611977631191\n",
      "    log_joint      : 950.4669621305645\n",
      "    val_loss       : -746.5737762451172\n",
      "    val_ess        : 1.9605693419774373\n",
      "    val_log_marginal: 746.6091257731119\n",
      "    val_log_joint  : 955.10009765625\n",
      "Train Epoch: 867 [0/54000 (0%)] Loss: -752.270447\n",
      "Train Epoch: 867 [11264/54000 (21%)] Loss: -725.913330\n",
      "Train Epoch: 867 [22528/54000 (42%)] Loss: -736.511108\n",
      "Train Epoch: 867 [33792/54000 (63%)] Loss: -759.661926\n",
      "Train Epoch: 867 [45056/54000 (83%)] Loss: -743.630005\n",
      "    epoch          : 867\n",
      "    loss           : -742.5556220288547\n",
      "    ess            : 1.9587785286723443\n",
      "    log_marginal   : 742.5926450333505\n",
      "    log_joint      : 951.074177292158\n",
      "    val_loss       : -746.816884358724\n",
      "    val_ess        : 1.9582760830720265\n",
      "    val_log_marginal: 746.8532918294271\n",
      "    val_log_joint  : 955.0202229817709\n",
      "Train Epoch: 868 [0/54000 (0%)] Loss: -751.478271\n",
      "Train Epoch: 868 [11264/54000 (21%)] Loss: -744.087402\n",
      "Train Epoch: 868 [22528/54000 (42%)] Loss: -751.482544\n",
      "Train Epoch: 868 [33792/54000 (63%)] Loss: -751.387085\n",
      "Train Epoch: 868 [45056/54000 (83%)] Loss: -752.798157\n",
      "    epoch          : 868\n",
      "    loss           : -742.4220748037662\n",
      "    ess            : 1.9607131267493625\n",
      "    log_marginal   : 742.457157350936\n",
      "    log_joint      : 950.8647512759802\n",
      "    val_loss       : -746.0582427978516\n",
      "    val_ess        : 1.960538923740387\n",
      "    val_log_marginal: 746.091807047526\n",
      "    val_log_joint  : 954.5970458984375\n",
      "Train Epoch: 869 [0/54000 (0%)] Loss: -732.299377\n",
      "Train Epoch: 869 [11264/54000 (21%)] Loss: -729.500488\n",
      "Train Epoch: 869 [22528/54000 (42%)] Loss: -740.428589\n",
      "Train Epoch: 869 [33792/54000 (63%)] Loss: -733.509033\n",
      "Train Epoch: 869 [45056/54000 (83%)] Loss: -746.225037\n",
      "    epoch          : 869\n",
      "    loss           : -742.5557797989755\n",
      "    ess            : 1.9593695840745602\n",
      "    log_marginal   : 742.5920156802771\n",
      "    log_joint      : 950.9663684772995\n",
      "    val_loss       : -746.2461242675781\n",
      "    val_ess        : 1.9561521808306377\n",
      "    val_log_marginal: 746.2830810546875\n",
      "    val_log_joint  : 954.6748046875\n",
      "Train Epoch: 870 [0/54000 (0%)] Loss: -744.591797\n",
      "Train Epoch: 870 [11264/54000 (21%)] Loss: -727.059326\n",
      "Train Epoch: 870 [22528/54000 (42%)] Loss: -740.714478\n",
      "Train Epoch: 870 [33792/54000 (63%)] Loss: -742.431152\n",
      "Train Epoch: 870 [45056/54000 (83%)] Loss: -740.101135\n",
      "    epoch          : 870\n",
      "    loss           : -742.7208459242335\n",
      "    ess            : 1.96000611219766\n",
      "    log_marginal   : 742.7572821851047\n",
      "    log_joint      : 951.1441535229953\n",
      "    val_loss       : -746.8360697428385\n",
      "    val_ess        : 1.9600097239017487\n",
      "    val_log_marginal: 746.8706461588541\n",
      "    val_log_joint  : 955.1358235677084\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch870.pth ...\n",
      "Train Epoch: 871 [0/54000 (0%)] Loss: -730.941589\n",
      "Train Epoch: 871 [11264/54000 (21%)] Loss: -732.126953\n",
      "Train Epoch: 871 [22528/54000 (42%)] Loss: -735.469482\n",
      "Train Epoch: 871 [33792/54000 (63%)] Loss: -724.170776\n",
      "Train Epoch: 871 [45056/54000 (83%)] Loss: -735.518188\n",
      "    epoch          : 871\n",
      "    loss           : -742.8398161114387\n",
      "    ess            : 1.9597877747607682\n",
      "    log_marginal   : 742.8744069225384\n",
      "    log_joint      : 951.1847275068175\n",
      "    val_loss       : -747.052500406901\n",
      "    val_ess        : 1.9631229440371196\n",
      "    val_log_marginal: 747.0830586751302\n",
      "    val_log_joint  : 955.2619069417318\n",
      "Train Epoch: 872 [0/54000 (0%)] Loss: -752.780273\n",
      "Train Epoch: 872 [11264/54000 (21%)] Loss: -731.997925\n",
      "Train Epoch: 872 [22528/54000 (42%)] Loss: -747.062988\n",
      "Train Epoch: 872 [33792/54000 (63%)] Loss: -756.666260\n",
      "Train Epoch: 872 [45056/54000 (83%)] Loss: -735.632141\n",
      "    epoch          : 872\n",
      "    loss           : -742.648667245541\n",
      "    ess            : 1.9595447272624609\n",
      "    log_marginal   : 742.6850562905365\n",
      "    log_joint      : 951.103290485886\n",
      "    val_loss       : -747.0268351236979\n",
      "    val_ess        : 1.9583825866381328\n",
      "    val_log_marginal: 747.0620676676432\n",
      "    val_log_joint  : 955.5000966389974\n",
      "Train Epoch: 873 [0/54000 (0%)] Loss: -726.436523\n",
      "Train Epoch: 873 [11264/54000 (21%)] Loss: -732.727417\n",
      "Train Epoch: 873 [22528/54000 (42%)] Loss: -732.872742\n",
      "Train Epoch: 873 [33792/54000 (63%)] Loss: -749.898193\n",
      "Train Epoch: 873 [45056/54000 (83%)] Loss: -745.565552\n",
      "    epoch          : 873\n",
      "    loss           : -742.779623931309\n",
      "    ess            : 1.9602900293638121\n",
      "    log_marginal   : 742.8157342874779\n",
      "    log_joint      : 951.2644238741892\n",
      "    val_loss       : -747.2787068684896\n",
      "    val_ess        : 1.9590387841065724\n",
      "    val_log_marginal: 747.3142496744791\n",
      "    val_log_joint  : 955.8683166503906\n",
      "Train Epoch: 874 [0/54000 (0%)] Loss: -738.527161\n",
      "Train Epoch: 874 [11264/54000 (21%)] Loss: -749.833008\n",
      "Train Epoch: 874 [22528/54000 (42%)] Loss: -740.792847\n",
      "Train Epoch: 874 [33792/54000 (63%)] Loss: -748.044128\n",
      "Train Epoch: 874 [45056/54000 (83%)] Loss: -738.717773\n",
      "    epoch          : 874\n",
      "    loss           : -742.9308281664578\n",
      "    ess            : 1.95947978743967\n",
      "    log_marginal   : 742.9671866938753\n",
      "    log_joint      : 951.3116731463738\n",
      "    val_loss       : -747.1615702311198\n",
      "    val_ess        : 1.9579602777957916\n",
      "    val_log_marginal: 747.1969655354818\n",
      "    val_log_joint  : 955.3471527099609\n",
      "Train Epoch: 875 [0/54000 (0%)] Loss: -754.678955\n",
      "Train Epoch: 875 [11264/54000 (21%)] Loss: -736.061340\n",
      "Train Epoch: 875 [22528/54000 (42%)] Loss: -742.064758\n",
      "Train Epoch: 875 [33792/54000 (63%)] Loss: -728.165100\n",
      "Train Epoch: 875 [45056/54000 (83%)] Loss: -741.933899\n",
      "    epoch          : 875\n",
      "    loss           : -743.214384258918\n",
      "    ess            : 1.9605391374174155\n",
      "    log_marginal   : 743.2485478239239\n",
      "    log_joint      : 951.6262921027418\n",
      "    val_loss       : -746.9984283447266\n",
      "    val_ess        : 1.9594542582829793\n",
      "    val_log_marginal: 747.0376993815104\n",
      "    val_log_joint  : 955.5130310058594\n",
      "Train Epoch: 876 [0/54000 (0%)] Loss: -751.621277\n",
      "Train Epoch: 876 [11264/54000 (21%)] Loss: -749.491943\n",
      "Train Epoch: 876 [22528/54000 (42%)] Loss: -751.381104\n",
      "Train Epoch: 876 [33792/54000 (63%)] Loss: -734.094482\n",
      "Train Epoch: 876 [45056/54000 (83%)] Loss: -749.617615\n",
      "    epoch          : 876\n",
      "    loss           : -743.001584610849\n",
      "    ess            : 1.9597215360065676\n",
      "    log_marginal   : 743.0376275980248\n",
      "    log_joint      : 951.4619244269605\n",
      "    val_loss       : -747.69580078125\n",
      "    val_ess        : 1.9598356386025746\n",
      "    val_log_marginal: 747.7324879964193\n",
      "    val_log_joint  : 955.9837290445963\n",
      "Train Epoch: 877 [0/54000 (0%)] Loss: -757.942017\n",
      "Train Epoch: 877 [11264/54000 (21%)] Loss: -753.447754\n",
      "Train Epoch: 877 [22528/54000 (42%)] Loss: -726.695740\n",
      "Train Epoch: 877 [33792/54000 (63%)] Loss: -744.836914\n",
      "Train Epoch: 877 [45056/54000 (83%)] Loss: -736.214783\n",
      "    epoch          : 877\n",
      "    loss           : -743.3256392568912\n",
      "    ess            : 1.9605159129736558\n",
      "    log_marginal   : 743.360463268352\n",
      "    log_joint      : 951.7266632655882\n",
      "    val_loss       : -746.513905843099\n",
      "    val_ess        : 1.953865001598994\n",
      "    val_log_marginal: 746.5564219156901\n",
      "    val_log_joint  : 955.0947062174479\n",
      "Train Epoch: 878 [0/54000 (0%)] Loss: -763.149963\n",
      "Train Epoch: 878 [11264/54000 (21%)] Loss: -732.372192\n",
      "Train Epoch: 878 [22528/54000 (42%)] Loss: -736.370117\n",
      "Train Epoch: 878 [33792/54000 (63%)] Loss: -747.968811\n",
      "Train Epoch: 878 [45056/54000 (83%)] Loss: -755.056641\n",
      "    epoch          : 878\n",
      "    loss           : -743.513475526054\n",
      "    ess            : 1.9609552014548823\n",
      "    log_marginal   : 743.5473724941038\n",
      "    log_joint      : 952.0295548349056\n",
      "    val_loss       : -746.6457570393881\n",
      "    val_ess        : 1.9624040921529133\n",
      "    val_log_marginal: 746.6794179280599\n",
      "    val_log_joint  : 955.2014617919922\n",
      "Train Epoch: 879 [0/54000 (0%)] Loss: -738.463257\n",
      "Train Epoch: 879 [11264/54000 (21%)] Loss: -738.541016\n",
      "Train Epoch: 879 [22528/54000 (42%)] Loss: -734.649658\n",
      "Train Epoch: 879 [33792/54000 (63%)] Loss: -751.657288\n",
      "Train Epoch: 879 [45056/54000 (83%)] Loss: -733.645020\n",
      "    epoch          : 879\n",
      "    loss           : -743.6224319170107\n",
      "    ess            : 1.9606478461679422\n",
      "    log_marginal   : 743.6562016325177\n",
      "    log_joint      : 952.0236085135982\n",
      "    val_loss       : -747.2701365152994\n",
      "    val_ess        : 1.9577216605345409\n",
      "    val_log_marginal: 747.3120778401693\n",
      "    val_log_joint  : 955.532470703125\n",
      "Train Epoch: 880 [0/54000 (0%)] Loss: -758.368958\n",
      "Train Epoch: 880 [11264/54000 (21%)] Loss: -741.156494\n",
      "Train Epoch: 880 [22528/54000 (42%)] Loss: -739.235107\n",
      "Train Epoch: 880 [33792/54000 (63%)] Loss: -741.043457\n",
      "Train Epoch: 880 [45056/54000 (83%)] Loss: -722.595520\n",
      "    epoch          : 880\n",
      "    loss           : -743.721812122273\n",
      "    ess            : 1.9598985111938332\n",
      "    log_marginal   : 743.7581741045107\n",
      "    log_joint      : 952.1397975705704\n",
      "    val_loss       : -748.4069213867188\n",
      "    val_ess        : 1.9605967700481415\n",
      "    val_log_marginal: 748.4436289469401\n",
      "    val_log_joint  : 956.7550404866537\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch880.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 881 [0/54000 (0%)] Loss: -743.971130\n",
      "Train Epoch: 881 [11264/54000 (21%)] Loss: -711.670654\n",
      "Train Epoch: 881 [22528/54000 (42%)] Loss: -746.314453\n",
      "Train Epoch: 881 [33792/54000 (63%)] Loss: -748.743347\n",
      "Train Epoch: 881 [45056/54000 (83%)] Loss: -746.318726\n",
      "    epoch          : 881\n",
      "    loss           : -743.8480978911778\n",
      "    ess            : 1.9594638280148775\n",
      "    log_marginal   : 743.8831671948703\n",
      "    log_joint      : 952.2690279978626\n",
      "    val_loss       : -748.3724110921224\n",
      "    val_ess        : 1.9607161184151967\n",
      "    val_log_marginal: 748.4067789713541\n",
      "    val_log_joint  : 956.7649637858073\n",
      "Train Epoch: 882 [0/54000 (0%)] Loss: -752.028748\n",
      "Train Epoch: 882 [11264/54000 (21%)] Loss: -748.394775\n",
      "Train Epoch: 882 [22528/54000 (42%)] Loss: -752.454834\n",
      "Train Epoch: 882 [33792/54000 (63%)] Loss: -753.069702\n",
      "Train Epoch: 882 [45056/54000 (83%)] Loss: -750.939453\n",
      "    epoch          : 882\n",
      "    loss           : -743.6736455953346\n",
      "    ess            : 1.958894024480064\n",
      "    log_marginal   : 743.7100640063015\n",
      "    log_joint      : 952.1800727124485\n",
      "    val_loss       : -748.1215209960938\n",
      "    val_ess        : 1.9608383278052013\n",
      "    val_log_marginal: 748.1580708821615\n",
      "    val_log_joint  : 956.3966115315756\n",
      "Train Epoch: 883 [0/54000 (0%)] Loss: -757.502136\n",
      "Train Epoch: 883 [11264/54000 (21%)] Loss: -739.117065\n",
      "Train Epoch: 883 [22528/54000 (42%)] Loss: -727.004028\n",
      "Train Epoch: 883 [33792/54000 (63%)] Loss: -737.511353\n",
      "Train Epoch: 883 [45056/54000 (83%)] Loss: -746.552307\n",
      "    epoch          : 883\n",
      "    loss           : -743.7648770314343\n",
      "    ess            : 1.9599021808156427\n",
      "    log_marginal   : 743.8010887289947\n",
      "    log_joint      : 952.3037990354142\n",
      "    val_loss       : -748.2398427327474\n",
      "    val_ess        : 1.9612481892108917\n",
      "    val_log_marginal: 748.2731374104818\n",
      "    val_log_joint  : 956.6269887288412\n",
      "Train Epoch: 884 [0/54000 (0%)] Loss: -742.838013\n",
      "Train Epoch: 884 [11264/54000 (21%)] Loss: -738.022827\n",
      "Train Epoch: 884 [22528/54000 (42%)] Loss: -743.263977\n",
      "Train Epoch: 884 [33792/54000 (63%)] Loss: -736.675781\n",
      "Train Epoch: 884 [45056/54000 (83%)] Loss: -738.223389\n",
      "    epoch          : 884\n",
      "    loss           : -743.9145991487323\n",
      "    ess            : 1.9598433667758726\n",
      "    log_marginal   : 743.9492268112471\n",
      "    log_joint      : 952.4365384083874\n",
      "    val_loss       : -747.2882385253906\n",
      "    val_ess        : 1.9570230344931285\n",
      "    val_log_marginal: 747.3292287190756\n",
      "    val_log_joint  : 955.9805755615234\n",
      "Train Epoch: 885 [0/54000 (0%)] Loss: -751.824951\n",
      "Train Epoch: 885 [11264/54000 (21%)] Loss: -750.301392\n",
      "Train Epoch: 885 [22528/54000 (42%)] Loss: -731.361267\n",
      "Train Epoch: 885 [33792/54000 (63%)] Loss: -753.695984\n",
      "Train Epoch: 885 [45056/54000 (83%)] Loss: -717.143799\n",
      "    epoch          : 885\n",
      "    loss           : -744.0057597610186\n",
      "    ess            : 1.9601117439989775\n",
      "    log_marginal   : 744.0404473070828\n",
      "    log_joint      : 952.4992980957031\n",
      "    val_loss       : -748.525380452474\n",
      "    val_ess        : 1.959203581015269\n",
      "    val_log_marginal: 748.5639292399088\n",
      "    val_log_joint  : 956.7423146565756\n",
      "Train Epoch: 886 [0/54000 (0%)] Loss: -764.356873\n",
      "Train Epoch: 886 [11264/54000 (21%)] Loss: -742.686157\n",
      "Train Epoch: 886 [22528/54000 (42%)] Loss: -740.143433\n",
      "Train Epoch: 886 [33792/54000 (63%)] Loss: -776.215088\n",
      "Train Epoch: 886 [45056/54000 (83%)] Loss: -740.114136\n",
      "    epoch          : 886\n",
      "    loss           : -744.1736645968455\n",
      "    ess            : 1.9601899779067848\n",
      "    log_marginal   : 744.2099632407135\n",
      "    log_joint      : 952.6224353718308\n",
      "    val_loss       : -748.0801747639974\n",
      "    val_ess        : 1.9593353569507599\n",
      "    val_log_marginal: 748.1171112060547\n",
      "    val_log_joint  : 956.7031606038412\n",
      "Train Epoch: 887 [0/54000 (0%)] Loss: -720.275024\n",
      "Train Epoch: 887 [11264/54000 (21%)] Loss: -761.664795\n",
      "Train Epoch: 887 [22528/54000 (42%)] Loss: -738.863037\n",
      "Train Epoch: 887 [33792/54000 (63%)] Loss: -742.937988\n",
      "Train Epoch: 887 [45056/54000 (83%)] Loss: -743.546509\n",
      "    epoch          : 887\n",
      "    loss           : -744.4824593022184\n",
      "    ess            : 1.9593589260893047\n",
      "    log_marginal   : 744.5195272193765\n",
      "    log_joint      : 952.9086102179762\n",
      "    val_loss       : -749.1719868977865\n",
      "    val_ess        : 1.9611129264036815\n",
      "    val_log_marginal: 749.2059224446615\n",
      "    val_log_joint  : 957.5965983072916\n",
      "Train Epoch: 888 [0/54000 (0%)] Loss: -726.682922\n",
      "Train Epoch: 888 [11264/54000 (21%)] Loss: -730.815918\n",
      "Train Epoch: 888 [22528/54000 (42%)] Loss: -729.550842\n",
      "Train Epoch: 888 [33792/54000 (63%)] Loss: -747.671143\n",
      "Train Epoch: 888 [45056/54000 (83%)] Loss: -744.795898\n",
      "    epoch          : 888\n",
      "    loss           : -744.6884546819723\n",
      "    ess            : 1.9596567558792402\n",
      "    log_marginal   : 744.7244573629127\n",
      "    log_joint      : 953.0701547298792\n",
      "    val_loss       : -748.3394724527994\n",
      "    val_ess        : 1.9591524004936218\n",
      "    val_log_marginal: 748.3763326009115\n",
      "    val_log_joint  : 956.7348683675131\n",
      "Train Epoch: 889 [0/54000 (0%)] Loss: -734.108765\n",
      "Train Epoch: 889 [11264/54000 (21%)] Loss: -751.127319\n",
      "Train Epoch: 889 [22528/54000 (42%)] Loss: -731.687622\n",
      "Train Epoch: 889 [33792/54000 (63%)] Loss: -735.198730\n",
      "Train Epoch: 889 [45056/54000 (83%)] Loss: -746.097412\n",
      "    epoch          : 889\n",
      "    loss           : -744.5206223973688\n",
      "    ess            : 1.9593021093674425\n",
      "    log_marginal   : 744.5570488695828\n",
      "    log_joint      : 953.0196251059479\n",
      "    val_loss       : -748.4778035481771\n",
      "    val_ess        : 1.958654781182607\n",
      "    val_log_marginal: 748.5148773193359\n",
      "    val_log_joint  : 956.7163340250651\n",
      "Train Epoch: 890 [0/54000 (0%)] Loss: -728.438965\n",
      "Train Epoch: 890 [11264/54000 (21%)] Loss: -766.092102\n",
      "Train Epoch: 890 [22528/54000 (42%)] Loss: -747.681030\n",
      "Train Epoch: 890 [33792/54000 (63%)] Loss: -742.663818\n",
      "Train Epoch: 890 [45056/54000 (83%)] Loss: -738.816895\n",
      "    epoch          : 890\n",
      "    loss           : -744.7022048662294\n",
      "    ess            : 1.9595465300218113\n",
      "    log_marginal   : 744.7385823951578\n",
      "    log_joint      : 953.2369574780735\n",
      "    val_loss       : -748.0839436848959\n",
      "    val_ess        : 1.9614045719305675\n",
      "    val_log_marginal: 748.1185455322266\n",
      "    val_log_joint  : 956.3505655924479\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch890.pth ...\n",
      "Train Epoch: 891 [0/54000 (0%)] Loss: -744.630676\n",
      "Train Epoch: 891 [11264/54000 (21%)] Loss: -769.772217\n",
      "Train Epoch: 891 [22528/54000 (42%)] Loss: -730.198608\n",
      "Train Epoch: 891 [33792/54000 (63%)] Loss: -745.442383\n",
      "Train Epoch: 891 [45056/54000 (83%)] Loss: -734.967651\n",
      "    epoch          : 891\n",
      "    loss           : -744.9209352889151\n",
      "    ess            : 1.960633542177812\n",
      "    log_marginal   : 744.9554644890551\n",
      "    log_joint      : 953.3682774957621\n",
      "    val_loss       : -748.668467203776\n",
      "    val_ess        : 1.9597870806852977\n",
      "    val_log_marginal: 748.7040863037109\n",
      "    val_log_joint  : 957.3927561442057\n",
      "Train Epoch: 892 [0/54000 (0%)] Loss: -725.482849\n",
      "Train Epoch: 892 [11264/54000 (21%)] Loss: -756.020569\n",
      "Train Epoch: 892 [22528/54000 (42%)] Loss: -733.882385\n",
      "Train Epoch: 892 [33792/54000 (63%)] Loss: -736.018372\n",
      "Train Epoch: 892 [45056/54000 (83%)] Loss: -730.464355\n",
      "    epoch          : 892\n",
      "    loss           : -744.8646741183298\n",
      "    ess            : 1.9594966026971925\n",
      "    log_marginal   : 744.9007073168484\n",
      "    log_joint      : 953.3901724185583\n",
      "    val_loss       : -749.0862833658854\n",
      "    val_ess        : 1.9603938659032185\n",
      "    val_log_marginal: 749.1225128173828\n",
      "    val_log_joint  : 957.5718231201172\n",
      "Train Epoch: 893 [0/54000 (0%)] Loss: -753.217285\n",
      "Train Epoch: 893 [11264/54000 (21%)] Loss: -742.195557\n",
      "Train Epoch: 893 [22528/54000 (42%)] Loss: -720.943359\n",
      "Train Epoch: 893 [33792/54000 (63%)] Loss: -752.086182\n",
      "Train Epoch: 893 [45056/54000 (83%)] Loss: -752.188232\n",
      "    epoch          : 893\n",
      "    loss           : -744.9577320026901\n",
      "    ess            : 1.9602040929614373\n",
      "    log_marginal   : 744.9933828677771\n",
      "    log_joint      : 953.4478938264667\n",
      "    val_loss       : -748.5755310058594\n",
      "    val_ess        : 1.9591022431850433\n",
      "    val_log_marginal: 748.6122334798177\n",
      "    val_log_joint  : 957.1150156656901\n",
      "Train Epoch: 894 [0/54000 (0%)] Loss: -751.640747\n",
      "Train Epoch: 894 [11264/54000 (21%)] Loss: -760.262207\n",
      "Train Epoch: 894 [22528/54000 (42%)] Loss: -734.622070\n",
      "Train Epoch: 894 [33792/54000 (63%)] Loss: -758.646484\n",
      "Train Epoch: 894 [45056/54000 (83%)] Loss: -759.977600\n",
      "    epoch          : 894\n",
      "    loss           : -745.1024619048496\n",
      "    ess            : 1.9587726368094391\n",
      "    log_marginal   : 745.1395321252211\n",
      "    log_joint      : 953.5965386156765\n",
      "    val_loss       : -750.2197011311849\n",
      "    val_ess        : 1.9579643706480663\n",
      "    val_log_marginal: 750.2572072347006\n",
      "    val_log_joint  : 958.2750447591146\n",
      "Train Epoch: 895 [0/54000 (0%)] Loss: -753.370605\n",
      "Train Epoch: 895 [11264/54000 (21%)] Loss: -776.369263\n",
      "Train Epoch: 895 [22528/54000 (42%)] Loss: -732.232910\n",
      "Train Epoch: 895 [33792/54000 (63%)] Loss: -746.989868\n",
      "Train Epoch: 895 [45056/54000 (83%)] Loss: -736.598511\n",
      "    epoch          : 895\n",
      "    loss           : -745.098382338038\n",
      "    ess            : 1.9600970340224932\n",
      "    log_marginal   : 745.1335840765036\n",
      "    log_joint      : 953.5123365870062\n",
      "    val_loss       : -749.2779642740885\n",
      "    val_ess        : 1.9622115592161815\n",
      "    val_log_marginal: 749.3091328938802\n",
      "    val_log_joint  : 957.9443766276041\n",
      "Train Epoch: 896 [0/54000 (0%)] Loss: -710.482910\n",
      "Train Epoch: 896 [11264/54000 (21%)] Loss: -742.818542\n",
      "Train Epoch: 896 [22528/54000 (42%)] Loss: -769.801880\n",
      "Train Epoch: 896 [33792/54000 (63%)] Loss: -750.672058\n",
      "Train Epoch: 896 [45056/54000 (83%)] Loss: -740.567627\n",
      "    epoch          : 896\n",
      "    loss           : -745.340737396816\n",
      "    ess            : 1.9595525725832525\n",
      "    log_marginal   : 745.3754612184921\n",
      "    log_joint      : 953.7772827148438\n",
      "    val_loss       : -750.3990224202474\n",
      "    val_ess        : 1.9614057342211406\n",
      "    val_log_marginal: 750.4345194498698\n",
      "    val_log_joint  : 958.9124399820963\n",
      "Train Epoch: 897 [0/54000 (0%)] Loss: -748.535278\n",
      "Train Epoch: 897 [11264/54000 (21%)] Loss: -736.341003\n",
      "Train Epoch: 897 [22528/54000 (42%)] Loss: -758.663269\n",
      "Train Epoch: 897 [33792/54000 (63%)] Loss: -756.273560\n",
      "Train Epoch: 897 [45056/54000 (83%)] Loss: -722.987793\n",
      "    epoch          : 897\n",
      "    loss           : -745.2206495752874\n",
      "    ess            : 1.9602228144429765\n",
      "    log_marginal   : 745.2553411519752\n",
      "    log_joint      : 953.7199735821418\n",
      "    val_loss       : -749.4436747233073\n",
      "    val_ess        : 1.9587078789869945\n",
      "    val_log_marginal: 749.4817555745443\n",
      "    val_log_joint  : 958.0338999430338\n",
      "Train Epoch: 898 [0/54000 (0%)] Loss: -741.157227\n",
      "Train Epoch: 898 [11264/54000 (21%)] Loss: -744.679504\n",
      "Train Epoch: 898 [22528/54000 (42%)] Loss: -747.244690\n",
      "Train Epoch: 898 [33792/54000 (63%)] Loss: -722.994751\n",
      "Train Epoch: 898 [45056/54000 (83%)] Loss: -759.506165\n",
      "    epoch          : 898\n",
      "    loss           : -745.4838222287735\n",
      "    ess            : 1.9597040898395035\n",
      "    log_marginal   : 745.5192093759213\n",
      "    log_joint      : 954.0953881605616\n",
      "    val_loss       : -749.8337097167969\n",
      "    val_ess        : 1.9599414467811584\n",
      "    val_log_marginal: 749.8694254557291\n",
      "    val_log_joint  : 958.2440745035807\n",
      "Train Epoch: 899 [0/54000 (0%)] Loss: -751.891602\n",
      "Train Epoch: 899 [11264/54000 (21%)] Loss: -763.239685\n",
      "Train Epoch: 899 [22528/54000 (42%)] Loss: -749.124512\n",
      "Train Epoch: 899 [33792/54000 (63%)] Loss: -748.998413\n",
      "Train Epoch: 899 [45056/54000 (83%)] Loss: -729.115112\n",
      "    epoch          : 899\n",
      "    loss           : -745.782555346219\n",
      "    ess            : 1.9608785993648026\n",
      "    log_marginal   : 745.8166555728552\n",
      "    log_joint      : 954.267884452388\n",
      "    val_loss       : -749.9862009684244\n",
      "    val_ess        : 1.9543455143769581\n",
      "    val_log_marginal: 750.0288848876953\n",
      "    val_log_joint  : 958.6622721354166\n",
      "Train Epoch: 900 [0/54000 (0%)] Loss: -743.861877\n",
      "Train Epoch: 900 [11264/54000 (21%)] Loss: -738.445679\n",
      "Train Epoch: 900 [22528/54000 (42%)] Loss: -748.957764\n",
      "Train Epoch: 900 [33792/54000 (63%)] Loss: -753.033936\n",
      "Train Epoch: 900 [45056/54000 (83%)] Loss: -738.065735\n",
      "    epoch          : 900\n",
      "    loss           : -745.530168065485\n",
      "    ess            : 1.9599926437971726\n",
      "    log_marginal   : 745.5654198988428\n",
      "    log_joint      : 953.9842765376253\n",
      "    val_loss       : -749.8856964111328\n",
      "    val_ess        : 1.9593868851661682\n",
      "    val_log_marginal: 749.9228261311849\n",
      "    val_log_joint  : 958.5664469401041\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [0/54000 (0%)] Loss: -735.999023\n",
      "Train Epoch: 901 [11264/54000 (21%)] Loss: -734.039917\n",
      "Train Epoch: 901 [22528/54000 (42%)] Loss: -753.124756\n",
      "Train Epoch: 901 [33792/54000 (63%)] Loss: -727.035522\n",
      "Train Epoch: 901 [45056/54000 (83%)] Loss: -752.123779\n",
      "    epoch          : 901\n",
      "    loss           : -745.7887515661852\n",
      "    ess            : 1.960869681160405\n",
      "    log_marginal   : 745.8234932377653\n",
      "    log_joint      : 954.2003473245873\n",
      "    val_loss       : -749.9217631022135\n",
      "    val_ess        : 1.9607111811637878\n",
      "    val_log_marginal: 749.9546457926432\n",
      "    val_log_joint  : 958.6130015055338\n",
      "Train Epoch: 902 [0/54000 (0%)] Loss: -758.163330\n",
      "Train Epoch: 902 [11264/54000 (21%)] Loss: -726.359192\n",
      "Train Epoch: 902 [22528/54000 (42%)] Loss: -749.344971\n",
      "Train Epoch: 902 [33792/54000 (63%)] Loss: -741.297974\n",
      "Train Epoch: 902 [45056/54000 (83%)] Loss: -758.014893\n",
      "    epoch          : 902\n",
      "    loss           : -745.9104758208653\n",
      "    ess            : 1.9583438342472292\n",
      "    log_marginal   : 745.9473450858638\n",
      "    log_joint      : 954.4425607357385\n",
      "    val_loss       : -750.1443379720052\n",
      "    val_ess        : 1.9573627213637035\n",
      "    val_log_marginal: 750.1803588867188\n",
      "    val_log_joint  : 958.4673055013021\n",
      "Train Epoch: 903 [0/54000 (0%)] Loss: -742.156921\n",
      "Train Epoch: 903 [11264/54000 (21%)] Loss: -769.139465\n",
      "Train Epoch: 903 [22528/54000 (42%)] Loss: -760.371216\n",
      "Train Epoch: 903 [33792/54000 (63%)] Loss: -734.913269\n",
      "Train Epoch: 903 [45056/54000 (83%)] Loss: -753.440918\n",
      "    epoch          : 903\n",
      "    loss           : -745.8775905393204\n",
      "    ess            : 1.9610071249727934\n",
      "    log_marginal   : 745.911654490345\n",
      "    log_joint      : 954.3667562232828\n",
      "    val_loss       : -750.1088816324869\n",
      "    val_ess        : 1.9605592787265778\n",
      "    val_log_marginal: 750.1421152750651\n",
      "    val_log_joint  : 958.6741689046224\n",
      "Train Epoch: 904 [0/54000 (0%)] Loss: -736.995056\n",
      "Train Epoch: 904 [11264/54000 (21%)] Loss: -739.242920\n",
      "Train Epoch: 904 [22528/54000 (42%)] Loss: -764.042480\n",
      "Train Epoch: 904 [33792/54000 (63%)] Loss: -749.223755\n",
      "Train Epoch: 904 [45056/54000 (83%)] Loss: -761.818054\n",
      "    epoch          : 904\n",
      "    loss           : -746.0228605450325\n",
      "    ess            : 1.9595258022254367\n",
      "    log_marginal   : 746.0588206165241\n",
      "    log_joint      : 954.582672694944\n",
      "    val_loss       : -749.6165466308594\n",
      "    val_ess        : 1.960332949956258\n",
      "    val_log_marginal: 749.6506856282552\n",
      "    val_log_joint  : 958.3276112874349\n",
      "Train Epoch: 905 [0/54000 (0%)] Loss: -752.314087\n",
      "Train Epoch: 905 [11264/54000 (21%)] Loss: -753.348206\n",
      "Train Epoch: 905 [22528/54000 (42%)] Loss: -728.766724\n",
      "Train Epoch: 905 [33792/54000 (63%)] Loss: -756.837463\n",
      "Train Epoch: 905 [45056/54000 (83%)] Loss: -739.673401\n",
      "    epoch          : 905\n",
      "    loss           : -746.1364475466171\n",
      "    ess            : 1.960001289844513\n",
      "    log_marginal   : 746.1723494619694\n",
      "    log_joint      : 954.657756301592\n",
      "    val_loss       : -750.3251597086588\n",
      "    val_ess        : 1.9580450753370922\n",
      "    val_log_marginal: 750.3622436523438\n",
      "    val_log_joint  : 958.5737711588541\n",
      "Train Epoch: 906 [0/54000 (0%)] Loss: -737.108032\n",
      "Train Epoch: 906 [11264/54000 (21%)] Loss: -737.100708\n",
      "Train Epoch: 906 [22528/54000 (42%)] Loss: -751.736572\n",
      "Train Epoch: 906 [33792/54000 (63%)] Loss: -743.884521\n",
      "Train Epoch: 906 [45056/54000 (83%)] Loss: -759.086304\n",
      "    epoch          : 906\n",
      "    loss           : -746.2024265505233\n",
      "    ess            : 1.959538146009985\n",
      "    log_marginal   : 746.2384257766436\n",
      "    log_joint      : 954.7226424307194\n",
      "    val_loss       : -750.0735270182291\n",
      "    val_ess        : 1.9594616989294689\n",
      "    val_log_marginal: 750.1092122395834\n",
      "    val_log_joint  : 958.5095977783203\n",
      "Train Epoch: 907 [0/54000 (0%)] Loss: -743.796265\n",
      "Train Epoch: 907 [11264/54000 (21%)] Loss: -744.761536\n",
      "Train Epoch: 907 [22528/54000 (42%)] Loss: -751.354004\n",
      "Train Epoch: 907 [33792/54000 (63%)] Loss: -764.399780\n",
      "Train Epoch: 907 [45056/54000 (83%)] Loss: -739.215698\n",
      "    epoch          : 907\n",
      "    loss           : -746.4189873461453\n",
      "    ess            : 1.9591470461971354\n",
      "    log_marginal   : 746.4555157355543\n",
      "    log_joint      : 954.9113539209906\n",
      "    val_loss       : -750.2859090169271\n",
      "    val_ess        : 1.9594510893026988\n",
      "    val_log_marginal: 750.3206431070963\n",
      "    val_log_joint  : 958.77587890625\n",
      "Train Epoch: 908 [0/54000 (0%)] Loss: -747.661499\n",
      "Train Epoch: 908 [11264/54000 (21%)] Loss: -769.857544\n",
      "Train Epoch: 908 [22528/54000 (42%)] Loss: -738.272583\n",
      "Train Epoch: 908 [33792/54000 (63%)] Loss: -742.169189\n",
      "Train Epoch: 908 [45056/54000 (83%)] Loss: -738.054810\n",
      "    epoch          : 908\n",
      "    loss           : -746.4949582657724\n",
      "    ess            : 1.9584030441518099\n",
      "    log_marginal   : 746.5333672289578\n",
      "    log_joint      : 954.9065528725678\n",
      "    val_loss       : -751.4861399332682\n",
      "    val_ess        : 1.9617927173773448\n",
      "    val_log_marginal: 751.5182647705078\n",
      "    val_log_joint  : 959.9886067708334\n",
      "Train Epoch: 909 [0/54000 (0%)] Loss: -743.685791\n",
      "Train Epoch: 909 [11264/54000 (21%)] Loss: -753.775635\n",
      "Train Epoch: 909 [22528/54000 (42%)] Loss: -752.419678\n",
      "Train Epoch: 909 [33792/54000 (63%)] Loss: -731.711853\n",
      "Train Epoch: 909 [45056/54000 (83%)] Loss: -733.979736\n",
      "    epoch          : 909\n",
      "    loss           : -746.5677547814711\n",
      "    ess            : 1.9595753449314046\n",
      "    log_marginal   : 746.6033751289799\n",
      "    log_joint      : 955.0491045106132\n",
      "    val_loss       : -751.0704345703125\n",
      "    val_ess        : 1.9619692464669545\n",
      "    val_log_marginal: 751.1022644042969\n",
      "    val_log_joint  : 959.2612864176432\n",
      "Train Epoch: 910 [0/54000 (0%)] Loss: -761.809570\n",
      "Train Epoch: 910 [11264/54000 (21%)] Loss: -754.774902\n",
      "Train Epoch: 910 [22528/54000 (42%)] Loss: -769.683044\n",
      "Train Epoch: 910 [33792/54000 (63%)] Loss: -718.387634\n",
      "Train Epoch: 910 [45056/54000 (83%)] Loss: -768.268005\n",
      "    epoch          : 910\n",
      "    loss           : -746.7394034907503\n",
      "    ess            : 1.9593957313951456\n",
      "    log_marginal   : 746.7759232431088\n",
      "    log_joint      : 955.1690184395268\n",
      "    val_loss       : -750.9978078206381\n",
      "    val_ess        : 1.9585542976856232\n",
      "    val_log_marginal: 751.0328725179037\n",
      "    val_log_joint  : 959.6720072428385\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch910.pth ...\n",
      "Train Epoch: 911 [0/54000 (0%)] Loss: -738.850220\n",
      "Train Epoch: 911 [11264/54000 (21%)] Loss: -762.302795\n",
      "Train Epoch: 911 [22528/54000 (42%)] Loss: -737.195923\n",
      "Train Epoch: 911 [33792/54000 (63%)] Loss: -746.254028\n",
      "Train Epoch: 911 [45056/54000 (83%)] Loss: -757.929810\n",
      "    epoch          : 911\n",
      "    loss           : -746.6136900703862\n",
      "    ess            : 1.9609477564973652\n",
      "    log_marginal   : 746.6486764583948\n",
      "    log_joint      : 955.1521180350826\n",
      "    val_loss       : -751.2157999674479\n",
      "    val_ess        : 1.9617738723754883\n",
      "    val_log_marginal: 751.2478179931641\n",
      "    val_log_joint  : 959.6360575358073\n",
      "Train Epoch: 912 [0/54000 (0%)] Loss: -749.687927\n",
      "Train Epoch: 912 [11264/54000 (21%)] Loss: -752.881592\n",
      "Train Epoch: 912 [22528/54000 (42%)] Loss: -741.344543\n",
      "Train Epoch: 912 [33792/54000 (63%)] Loss: -770.659180\n",
      "Train Epoch: 912 [45056/54000 (83%)] Loss: -755.689331\n",
      "    epoch          : 912\n",
      "    loss           : -746.9121784714033\n",
      "    ess            : 1.9610251413201385\n",
      "    log_marginal   : 746.9473830888857\n",
      "    log_joint      : 955.3660295594414\n",
      "    val_loss       : -751.2049814860026\n",
      "    val_ess        : 1.9614996214707692\n",
      "    val_log_marginal: 751.2366790771484\n",
      "    val_log_joint  : 959.7728983561198\n",
      "Train Epoch: 913 [0/54000 (0%)] Loss: -725.884155\n",
      "Train Epoch: 913 [11264/54000 (21%)] Loss: -737.215576\n",
      "Train Epoch: 913 [22528/54000 (42%)] Loss: -741.345459\n",
      "Train Epoch: 913 [33792/54000 (63%)] Loss: -721.608398\n",
      "Train Epoch: 913 [45056/54000 (83%)] Loss: -729.206543\n",
      "    epoch          : 913\n",
      "    loss           : -746.9116717644457\n",
      "    ess            : 1.9606837000486985\n",
      "    log_marginal   : 746.9465758125737\n",
      "    log_joint      : 955.4406369767099\n",
      "    val_loss       : -751.0948791503906\n",
      "    val_ess        : 1.9578714271386464\n",
      "    val_log_marginal: 751.1343434651693\n",
      "    val_log_joint  : 959.4696400960287\n",
      "Train Epoch: 914 [0/54000 (0%)] Loss: -740.521240\n",
      "Train Epoch: 914 [11264/54000 (21%)] Loss: -741.418091\n",
      "Train Epoch: 914 [22528/54000 (42%)] Loss: -749.212646\n",
      "Train Epoch: 914 [33792/54000 (63%)] Loss: -777.710938\n",
      "Train Epoch: 914 [45056/54000 (83%)] Loss: -752.216064\n",
      "    epoch          : 914\n",
      "    loss           : -747.2861460559773\n",
      "    ess            : 1.9596040732455704\n",
      "    log_marginal   : 747.3224498820755\n",
      "    log_joint      : 955.7520878629864\n",
      "    val_loss       : -751.4402720133463\n",
      "    val_ess        : 1.960305353005727\n",
      "    val_log_marginal: 751.4769134521484\n",
      "    val_log_joint  : 959.9881388346354\n",
      "Train Epoch: 915 [0/54000 (0%)] Loss: -751.500244\n",
      "Train Epoch: 915 [11264/54000 (21%)] Loss: -729.569092\n",
      "Train Epoch: 915 [22528/54000 (42%)] Loss: -768.837524\n",
      "Train Epoch: 915 [33792/54000 (63%)] Loss: -730.359070\n",
      "Train Epoch: 915 [45056/54000 (83%)] Loss: -733.820312\n",
      "    epoch          : 915\n",
      "    loss           : -747.0645043714991\n",
      "    ess            : 1.9600162494857356\n",
      "    log_marginal   : 747.0998552430351\n",
      "    log_joint      : 955.5439412818765\n",
      "    val_loss       : -750.9436340332031\n",
      "    val_ess        : 1.9589623709519703\n",
      "    val_log_marginal: 750.9787292480469\n",
      "    val_log_joint  : 959.718017578125\n",
      "Train Epoch: 916 [0/54000 (0%)] Loss: -729.625488\n",
      "Train Epoch: 916 [11264/54000 (21%)] Loss: -752.479004\n",
      "Train Epoch: 916 [22528/54000 (42%)] Loss: -751.525269\n",
      "Train Epoch: 916 [33792/54000 (63%)] Loss: -762.170898\n",
      "Train Epoch: 916 [45056/54000 (83%)] Loss: -733.646973\n",
      "    epoch          : 916\n",
      "    loss           : -747.1824271723909\n",
      "    ess            : 1.959468253378598\n",
      "    log_marginal   : 747.2194323269827\n",
      "    log_joint      : 955.7116065835053\n",
      "    val_loss       : -751.4982350667318\n",
      "    val_ess        : 1.9574914574623108\n",
      "    val_log_marginal: 751.5369008382162\n",
      "    val_log_joint  : 960.1667226155599\n",
      "Train Epoch: 917 [0/54000 (0%)] Loss: -760.924866\n",
      "Train Epoch: 917 [11264/54000 (21%)] Loss: -758.516846\n",
      "Train Epoch: 917 [22528/54000 (42%)] Loss: -768.663635\n",
      "Train Epoch: 917 [33792/54000 (63%)] Loss: -767.776367\n",
      "Train Epoch: 917 [45056/54000 (83%)] Loss: -754.202881\n",
      "    epoch          : 917\n",
      "    loss           : -747.2117246231943\n",
      "    ess            : 1.960971639966065\n",
      "    log_marginal   : 747.2457546018204\n",
      "    log_joint      : 955.6748553581957\n",
      "    val_loss       : -751.4497578938802\n",
      "    val_ess        : 1.9586330155531566\n",
      "    val_log_marginal: 751.4904429117838\n",
      "    val_log_joint  : 959.8775990804037\n",
      "Train Epoch: 918 [0/54000 (0%)] Loss: -760.681763\n",
      "Train Epoch: 918 [11264/54000 (21%)] Loss: -750.739807\n",
      "Train Epoch: 918 [22528/54000 (42%)] Loss: -752.723511\n",
      "Train Epoch: 918 [33792/54000 (63%)] Loss: -743.934082\n",
      "Train Epoch: 918 [45056/54000 (83%)] Loss: -718.772766\n",
      "    epoch          : 918\n",
      "    loss           : -747.4452831340286\n",
      "    ess            : 1.9608621923428662\n",
      "    log_marginal   : 747.4782271475162\n",
      "    log_joint      : 955.8895499751253\n",
      "    val_loss       : -751.6632792154948\n",
      "    val_ess        : 1.9617978831132252\n",
      "    val_log_marginal: 751.6964619954427\n",
      "    val_log_joint  : 960.1689198811849\n",
      "Train Epoch: 919 [0/54000 (0%)] Loss: -741.377502\n",
      "Train Epoch: 919 [11264/54000 (21%)] Loss: -731.860962\n",
      "Train Epoch: 919 [22528/54000 (42%)] Loss: -747.127319\n",
      "Train Epoch: 919 [33792/54000 (63%)] Loss: -736.440430\n",
      "Train Epoch: 919 [45056/54000 (83%)] Loss: -743.706543\n",
      "    epoch          : 919\n",
      "    loss           : -747.4847250884434\n",
      "    ess            : 1.9601070149889532\n",
      "    log_marginal   : 747.5202003335053\n",
      "    log_joint      : 956.0035014602373\n",
      "    val_loss       : -751.1902109781901\n",
      "    val_ess        : 1.9581622779369354\n",
      "    val_log_marginal: 751.2279561360677\n",
      "    val_log_joint  : 959.7018534342448\n",
      "Train Epoch: 920 [0/54000 (0%)] Loss: -742.568665\n",
      "Train Epoch: 920 [11264/54000 (21%)] Loss: -756.195435\n",
      "Train Epoch: 920 [22528/54000 (42%)] Loss: -734.558105\n",
      "Train Epoch: 920 [33792/54000 (63%)] Loss: -746.621765\n",
      "Train Epoch: 920 [45056/54000 (83%)] Loss: -775.961914\n",
      "    epoch          : 920\n",
      "    loss           : -747.8471921524912\n",
      "    ess            : 1.9602368046652596\n",
      "    log_marginal   : 747.8821002312426\n",
      "    log_joint      : 956.3817679927034\n",
      "    val_loss       : -751.0582377115885\n",
      "    val_ess        : 1.9637789527575176\n",
      "    val_log_marginal: 751.090098063151\n",
      "    val_log_joint  : 959.5472666422526\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch920.pth ...\n",
      "Train Epoch: 921 [0/54000 (0%)] Loss: -750.524048\n",
      "Train Epoch: 921 [11264/54000 (21%)] Loss: -745.220093\n",
      "Train Epoch: 921 [22528/54000 (42%)] Loss: -752.262573\n",
      "Train Epoch: 921 [33792/54000 (63%)] Loss: -737.887573\n",
      "Train Epoch: 921 [45056/54000 (83%)] Loss: -749.275940\n",
      "    epoch          : 921\n",
      "    loss           : -747.7624396558078\n",
      "    ess            : 1.9597001390637092\n",
      "    log_marginal   : 747.7987797575177\n",
      "    log_joint      : 956.1816417766067\n",
      "    val_loss       : -751.9379069010416\n",
      "    val_ess        : 1.9581795831521351\n",
      "    val_log_marginal: 751.975840250651\n",
      "    val_log_joint  : 960.2686157226562\n",
      "Train Epoch: 922 [0/54000 (0%)] Loss: -751.399170\n",
      "Train Epoch: 922 [11264/54000 (21%)] Loss: -736.546082\n",
      "Train Epoch: 922 [22528/54000 (42%)] Loss: -772.496948\n",
      "Train Epoch: 922 [33792/54000 (63%)] Loss: -763.231201\n",
      "Train Epoch: 922 [45056/54000 (83%)] Loss: -766.067993\n",
      "    epoch          : 922\n",
      "    loss           : -747.8546942944797\n",
      "    ess            : 1.9591495046075784\n",
      "    log_marginal   : 747.8918883125737\n",
      "    log_joint      : 956.4233669065079\n",
      "    val_loss       : -751.6528472900391\n",
      "    val_ess        : 1.9616481463114421\n",
      "    val_log_marginal: 751.6845245361328\n",
      "    val_log_joint  : 960.2334950764974\n",
      "Train Epoch: 923 [0/54000 (0%)] Loss: -744.453064\n",
      "Train Epoch: 923 [11264/54000 (21%)] Loss: -741.039246\n",
      "Train Epoch: 923 [22528/54000 (42%)] Loss: -733.338135\n",
      "Train Epoch: 923 [33792/54000 (63%)] Loss: -761.240112\n",
      "Train Epoch: 923 [45056/54000 (83%)] Loss: -755.934326\n",
      "    epoch          : 923\n",
      "    loss           : -747.6711195459906\n",
      "    ess            : 1.960538295080077\n",
      "    log_marginal   : 747.7067468031397\n",
      "    log_joint      : 956.1578040932709\n",
      "    val_loss       : -752.6451263427734\n",
      "    val_ess        : 1.9587974051634471\n",
      "    val_log_marginal: 752.6805572509766\n",
      "    val_log_joint  : 961.1565602620443\n",
      "Train Epoch: 924 [0/54000 (0%)] Loss: -759.259277\n",
      "Train Epoch: 924 [11264/54000 (21%)] Loss: -756.007446\n",
      "Train Epoch: 924 [22528/54000 (42%)] Loss: -756.385071\n",
      "Train Epoch: 924 [33792/54000 (63%)] Loss: -760.585938\n",
      "Train Epoch: 924 [45056/54000 (83%)] Loss: -762.650574\n",
      "    epoch          : 924\n",
      "    loss           : -748.0619276514593\n",
      "    ess            : 1.9588840277689807\n",
      "    log_marginal   : 748.0987295474646\n",
      "    log_joint      : 956.5372999659124\n",
      "    val_loss       : -751.98046875\n",
      "    val_ess        : 1.9578615923722584\n",
      "    val_log_marginal: 752.0186564127604\n",
      "    val_log_joint  : 960.6009979248047\n",
      "Train Epoch: 925 [0/54000 (0%)] Loss: -757.494385\n",
      "Train Epoch: 925 [11264/54000 (21%)] Loss: -737.773804\n",
      "Train Epoch: 925 [22528/54000 (42%)] Loss: -730.119629\n",
      "Train Epoch: 925 [33792/54000 (63%)] Loss: -766.255737\n",
      "Train Epoch: 925 [45056/54000 (83%)] Loss: -749.292603\n",
      "    epoch          : 925\n",
      "    loss           : -747.9772972250885\n",
      "    ess            : 1.9591271742334906\n",
      "    log_marginal   : 748.0129642126695\n",
      "    log_joint      : 956.5744174021595\n",
      "    val_loss       : -753.0799153645834\n",
      "    val_ess        : 1.9594682057698567\n",
      "    val_log_marginal: 753.1184539794922\n",
      "    val_log_joint  : 961.7008514404297\n",
      "Train Epoch: 926 [0/54000 (0%)] Loss: -739.122559\n",
      "Train Epoch: 926 [11264/54000 (21%)] Loss: -744.301025\n",
      "Train Epoch: 926 [22528/54000 (42%)] Loss: -746.990356\n",
      "Train Epoch: 926 [33792/54000 (63%)] Loss: -745.733826\n",
      "Train Epoch: 926 [45056/54000 (83%)] Loss: -763.025635\n",
      "    epoch          : 926\n",
      "    loss           : -748.1238881237102\n",
      "    ess            : 1.9597464338788446\n",
      "    log_marginal   : 748.160100397074\n",
      "    log_joint      : 956.5617082703789\n",
      "    val_loss       : -752.1847890218099\n",
      "    val_ess        : 1.9603233635425568\n",
      "    val_log_marginal: 752.2190907796224\n",
      "    val_log_joint  : 960.7302449544271\n",
      "Train Epoch: 927 [0/54000 (0%)] Loss: -775.631775\n",
      "Train Epoch: 927 [11264/54000 (21%)] Loss: -728.943542\n",
      "Train Epoch: 927 [22528/54000 (42%)] Loss: -734.603394\n",
      "Train Epoch: 927 [33792/54000 (63%)] Loss: -762.120605\n",
      "Train Epoch: 927 [45056/54000 (83%)] Loss: -764.046997\n",
      "    epoch          : 927\n",
      "    loss           : -748.4052889841907\n",
      "    ess            : 1.959794801361156\n",
      "    log_marginal   : 748.4429874060289\n",
      "    log_joint      : 956.8350052743588\n",
      "    val_loss       : -752.6553548177084\n",
      "    val_ess        : 1.9592903355757396\n",
      "    val_log_marginal: 752.6924896240234\n",
      "    val_log_joint  : 961.1917317708334\n",
      "Train Epoch: 928 [0/54000 (0%)] Loss: -737.992676\n",
      "Train Epoch: 928 [11264/54000 (21%)] Loss: -745.546021\n",
      "Train Epoch: 928 [22528/54000 (42%)] Loss: -754.877686\n",
      "Train Epoch: 928 [33792/54000 (63%)] Loss: -759.022949\n",
      "Train Epoch: 928 [45056/54000 (83%)] Loss: -754.962891\n",
      "    epoch          : 928\n",
      "    loss           : -748.17836142486\n",
      "    ess            : 1.9601937903548188\n",
      "    log_marginal   : 748.2129032926739\n",
      "    log_joint      : 956.686633415942\n",
      "    val_loss       : -752.4492696126302\n",
      "    val_ess        : 1.9584354956944783\n",
      "    val_log_marginal: 752.4897867838541\n",
      "    val_log_joint  : 961.0964050292969\n",
      "Train Epoch: 929 [0/54000 (0%)] Loss: -737.609131\n",
      "Train Epoch: 929 [11264/54000 (21%)] Loss: -746.198853\n",
      "Train Epoch: 929 [22528/54000 (42%)] Loss: -782.921692\n",
      "Train Epoch: 929 [33792/54000 (63%)] Loss: -751.194824\n",
      "Train Epoch: 929 [45056/54000 (83%)] Loss: -742.785645\n",
      "    epoch          : 929\n",
      "    loss           : -748.5844064388635\n",
      "    ess            : 1.960918165602774\n",
      "    log_marginal   : 748.6188780586674\n",
      "    log_joint      : 957.1182446749705\n",
      "    val_loss       : -751.7732950846354\n",
      "    val_ess        : 1.9553435544172924\n",
      "    val_log_marginal: 751.8144887288412\n",
      "    val_log_joint  : 960.2581380208334\n",
      "Train Epoch: 930 [0/54000 (0%)] Loss: -744.717896\n",
      "Train Epoch: 930 [11264/54000 (21%)] Loss: -747.882751\n",
      "Train Epoch: 930 [22528/54000 (42%)] Loss: -729.126404\n",
      "Train Epoch: 930 [33792/54000 (63%)] Loss: -735.202271\n",
      "Train Epoch: 930 [45056/54000 (83%)] Loss: -753.742798\n",
      "    epoch          : 930\n",
      "    loss           : -748.4714505177624\n",
      "    ess            : 1.9595647015661564\n",
      "    log_marginal   : 748.5059860517393\n",
      "    log_joint      : 956.8837170870798\n",
      "    val_loss       : -753.3378092447916\n",
      "    val_ess        : 1.9588112433751423\n",
      "    val_log_marginal: 753.3743133544922\n",
      "    val_log_joint  : 961.8468424479166\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch930.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 931 [0/54000 (0%)] Loss: -732.992310\n",
      "Train Epoch: 931 [11264/54000 (21%)] Loss: -741.860229\n",
      "Train Epoch: 931 [22528/54000 (42%)] Loss: -758.625427\n",
      "Train Epoch: 931 [33792/54000 (63%)] Loss: -763.135010\n",
      "Train Epoch: 931 [45056/54000 (83%)] Loss: -736.986511\n",
      "    epoch          : 931\n",
      "    loss           : -748.5501265615787\n",
      "    ess            : 1.960278072447147\n",
      "    log_marginal   : 748.585750939711\n",
      "    log_joint      : 957.1823212245725\n",
      "    val_loss       : -752.2832183837891\n",
      "    val_ess        : 1.958893895149231\n",
      "    val_log_marginal: 752.3208821614584\n",
      "    val_log_joint  : 961.0261433919271\n",
      "Train Epoch: 932 [0/54000 (0%)] Loss: -752.840881\n",
      "Train Epoch: 932 [11264/54000 (21%)] Loss: -747.024780\n",
      "Train Epoch: 932 [22528/54000 (42%)] Loss: -724.882446\n",
      "Train Epoch: 932 [33792/54000 (63%)] Loss: -751.502075\n",
      "Train Epoch: 932 [45056/54000 (83%)] Loss: -758.435059\n",
      "    epoch          : 932\n",
      "    loss           : -748.4732666015625\n",
      "    ess            : 1.9596522439200923\n",
      "    log_marginal   : 748.5091765781618\n",
      "    log_joint      : 956.9125815337559\n",
      "    val_loss       : -752.7077026367188\n",
      "    val_ess        : 1.959950606028239\n",
      "    val_log_marginal: 752.7451578776041\n",
      "    val_log_joint  : 961.0888417561849\n",
      "Train Epoch: 933 [0/54000 (0%)] Loss: -725.368164\n",
      "Train Epoch: 933 [11264/54000 (21%)] Loss: -762.399963\n",
      "Train Epoch: 933 [22528/54000 (42%)] Loss: -744.675659\n",
      "Train Epoch: 933 [33792/54000 (63%)] Loss: -758.977783\n",
      "Train Epoch: 933 [45056/54000 (83%)] Loss: -732.199280\n",
      "    epoch          : 933\n",
      "    loss           : -748.852002989571\n",
      "    ess            : 1.960211120686441\n",
      "    log_marginal   : 748.8861619481501\n",
      "    log_joint      : 957.321135898806\n",
      "    val_loss       : -753.3548177083334\n",
      "    val_ess        : 1.9618887801965077\n",
      "    val_log_marginal: 753.3858489990234\n",
      "    val_log_joint  : 961.9219055175781\n",
      "Train Epoch: 934 [0/54000 (0%)] Loss: -746.721375\n",
      "Train Epoch: 934 [11264/54000 (21%)] Loss: -738.108643\n",
      "Train Epoch: 934 [22528/54000 (42%)] Loss: -763.121826\n",
      "Train Epoch: 934 [33792/54000 (63%)] Loss: -730.899475\n",
      "Train Epoch: 934 [45056/54000 (83%)] Loss: -768.967224\n",
      "    epoch          : 934\n",
      "    loss           : -748.8074214143573\n",
      "    ess            : 1.960061767191257\n",
      "    log_marginal   : 748.8426784299454\n",
      "    log_joint      : 957.3274110038326\n",
      "    val_loss       : -752.9524688720703\n",
      "    val_ess        : 1.9583042860031128\n",
      "    val_log_marginal: 752.9899546305338\n",
      "    val_log_joint  : 961.5356140136719\n",
      "Train Epoch: 935 [0/54000 (0%)] Loss: -747.751953\n",
      "Train Epoch: 935 [11264/54000 (21%)] Loss: -760.384521\n",
      "Train Epoch: 935 [22528/54000 (42%)] Loss: -774.067017\n",
      "Train Epoch: 935 [33792/54000 (63%)] Loss: -732.791992\n",
      "Train Epoch: 935 [45056/54000 (83%)] Loss: -748.263123\n",
      "    epoch          : 935\n",
      "    loss           : -749.0105936302328\n",
      "    ess            : 1.959653895980907\n",
      "    log_marginal   : 749.046295741819\n",
      "    log_joint      : 957.5065013957474\n",
      "    val_loss       : -752.8924662272135\n",
      "    val_ess        : 1.9605364203453064\n",
      "    val_log_marginal: 752.9280700683594\n",
      "    val_log_joint  : 961.5083618164062\n",
      "Train Epoch: 936 [0/54000 (0%)] Loss: -749.630432\n",
      "Train Epoch: 936 [11264/54000 (21%)] Loss: -782.181885\n",
      "Train Epoch: 936 [22528/54000 (42%)] Loss: -737.739929\n",
      "Train Epoch: 936 [33792/54000 (63%)] Loss: -772.086487\n",
      "Train Epoch: 936 [45056/54000 (83%)] Loss: -742.034790\n",
      "    epoch          : 936\n",
      "    loss           : -748.9878943101415\n",
      "    ess            : 1.959493929485105\n",
      "    log_marginal   : 749.0241094625221\n",
      "    log_joint      : 957.4773450167673\n",
      "    val_loss       : -752.7841288248698\n",
      "    val_ess        : 1.9639711280663807\n",
      "    val_log_marginal: 752.8141377766927\n",
      "    val_log_joint  : 961.6591644287109\n",
      "Train Epoch: 937 [0/54000 (0%)] Loss: -758.008667\n",
      "Train Epoch: 937 [11264/54000 (21%)] Loss: -733.591614\n",
      "Train Epoch: 937 [22528/54000 (42%)] Loss: -758.350464\n",
      "Train Epoch: 937 [33792/54000 (63%)] Loss: -743.576233\n",
      "Train Epoch: 937 [45056/54000 (83%)] Loss: -744.149414\n",
      "    epoch          : 937\n",
      "    loss           : -749.3101864220961\n",
      "    ess            : 1.9613840208863311\n",
      "    log_marginal   : 749.3439060427108\n",
      "    log_joint      : 957.7124927448776\n",
      "    val_loss       : -753.8702748616537\n",
      "    val_ess        : 1.9635676046212514\n",
      "    val_log_marginal: 753.9006551106771\n",
      "    val_log_joint  : 962.371571858724\n",
      "Train Epoch: 938 [0/54000 (0%)] Loss: -753.501831\n",
      "Train Epoch: 938 [11264/54000 (21%)] Loss: -733.895569\n",
      "Train Epoch: 938 [22528/54000 (42%)] Loss: -749.083374\n",
      "Train Epoch: 938 [33792/54000 (63%)] Loss: -769.453125\n",
      "Train Epoch: 938 [45056/54000 (83%)] Loss: -736.616333\n",
      "    epoch          : 938\n",
      "    loss           : -749.2940224701504\n",
      "    ess            : 1.9604289610430878\n",
      "    log_marginal   : 749.3280996646521\n",
      "    log_joint      : 957.7638998931309\n",
      "    val_loss       : -752.6544596354166\n",
      "    val_ess        : 1.9612370332082112\n",
      "    val_log_marginal: 752.6843719482422\n",
      "    val_log_joint  : 960.9008483886719\n",
      "Train Epoch: 939 [0/54000 (0%)] Loss: -744.639160\n",
      "Train Epoch: 939 [11264/54000 (21%)] Loss: -748.120422\n",
      "Train Epoch: 939 [22528/54000 (42%)] Loss: -736.550110\n",
      "Train Epoch: 939 [33792/54000 (63%)] Loss: -743.298950\n",
      "Train Epoch: 939 [45056/54000 (83%)] Loss: -741.915833\n",
      "    epoch          : 939\n",
      "    loss           : -749.327684510429\n",
      "    ess            : 1.9589840634813849\n",
      "    log_marginal   : 749.3653846596771\n",
      "    log_joint      : 957.8198023382223\n",
      "    val_loss       : -754.0960083007812\n",
      "    val_ess        : 1.959865132967631\n",
      "    val_log_marginal: 754.1307423909506\n",
      "    val_log_joint  : 962.4929504394531\n",
      "Train Epoch: 940 [0/54000 (0%)] Loss: -750.245483\n",
      "Train Epoch: 940 [11264/54000 (21%)] Loss: -750.358704\n",
      "Train Epoch: 940 [22528/54000 (42%)] Loss: -750.244385\n",
      "Train Epoch: 940 [33792/54000 (63%)] Loss: -753.178101\n",
      "Train Epoch: 940 [45056/54000 (83%)] Loss: -737.980530\n",
      "    epoch          : 940\n",
      "    loss           : -749.3275820174307\n",
      "    ess            : 1.9600873499546412\n",
      "    log_marginal   : 749.3631004477447\n",
      "    log_joint      : 957.8225638911409\n",
      "    val_loss       : -753.6170552571615\n",
      "    val_ess        : 1.96157439549764\n",
      "    val_log_marginal: 753.6471811930338\n",
      "    val_log_joint  : 962.1843770345052\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch940.pth ...\n",
      "Train Epoch: 941 [0/54000 (0%)] Loss: -761.239746\n",
      "Train Epoch: 941 [11264/54000 (21%)] Loss: -744.569458\n",
      "Train Epoch: 941 [22528/54000 (42%)] Loss: -761.656433\n",
      "Train Epoch: 941 [33792/54000 (63%)] Loss: -763.309692\n",
      "Train Epoch: 941 [45056/54000 (83%)] Loss: -750.766541\n",
      "    epoch          : 941\n",
      "    loss           : -749.4693442290684\n",
      "    ess            : 1.9601933540038343\n",
      "    log_marginal   : 749.5046415508918\n",
      "    log_joint      : 957.9565452719635\n",
      "    val_loss       : -753.0584665934244\n",
      "    val_ess        : 1.9603427946567535\n",
      "    val_log_marginal: 753.0959676106771\n",
      "    val_log_joint  : 961.7277577718099\n",
      "Train Epoch: 942 [0/54000 (0%)] Loss: -728.766785\n",
      "Train Epoch: 942 [11264/54000 (21%)] Loss: -746.830444\n",
      "Train Epoch: 942 [22528/54000 (42%)] Loss: -748.273193\n",
      "Train Epoch: 942 [33792/54000 (63%)] Loss: -779.043762\n",
      "Train Epoch: 942 [45056/54000 (83%)] Loss: -759.419189\n",
      "    epoch          : 942\n",
      "    loss           : -749.7178966594192\n",
      "    ess            : 1.959598939373808\n",
      "    log_marginal   : 749.7539292821344\n",
      "    log_joint      : 958.1762862295475\n",
      "    val_loss       : -754.4760437011719\n",
      "    val_ess        : 1.9617082277933757\n",
      "    val_log_marginal: 754.5132598876953\n",
      "    val_log_joint  : 963.0207061767578\n",
      "Train Epoch: 943 [0/54000 (0%)] Loss: -751.521362\n",
      "Train Epoch: 943 [11264/54000 (21%)] Loss: -739.709961\n",
      "Train Epoch: 943 [22528/54000 (42%)] Loss: -761.558350\n",
      "Train Epoch: 943 [33792/54000 (63%)] Loss: -749.684448\n",
      "Train Epoch: 943 [45056/54000 (83%)] Loss: -741.855225\n",
      "    epoch          : 943\n",
      "    loss           : -749.6785658350531\n",
      "    ess            : 1.960488278910799\n",
      "    log_marginal   : 749.7135729519827\n",
      "    log_joint      : 958.1713901735702\n",
      "    val_loss       : -754.1042633056641\n",
      "    val_ess        : 1.9614142179489136\n",
      "    val_log_marginal: 754.1383717854818\n",
      "    val_log_joint  : 962.4405975341797\n",
      "Train Epoch: 944 [0/54000 (0%)] Loss: -738.091370\n",
      "Train Epoch: 944 [11264/54000 (21%)] Loss: -768.526855\n",
      "Train Epoch: 944 [22528/54000 (42%)] Loss: -740.498962\n",
      "Train Epoch: 944 [33792/54000 (63%)] Loss: -742.916382\n",
      "Train Epoch: 944 [45056/54000 (83%)] Loss: -734.001221\n",
      "    epoch          : 944\n",
      "    loss           : -749.7006576825987\n",
      "    ess            : 1.959752879052792\n",
      "    log_marginal   : 749.7363690070387\n",
      "    log_joint      : 958.1302018075619\n",
      "    val_loss       : -753.2783406575521\n",
      "    val_ess        : 1.95560684800148\n",
      "    val_log_marginal: 753.3196665445963\n",
      "    val_log_joint  : 962.1282145182291\n",
      "Train Epoch: 945 [0/54000 (0%)] Loss: -765.582153\n",
      "Train Epoch: 945 [11264/54000 (21%)] Loss: -743.337646\n",
      "Train Epoch: 945 [22528/54000 (42%)] Loss: -736.447021\n",
      "Train Epoch: 945 [33792/54000 (63%)] Loss: -752.994873\n",
      "Train Epoch: 945 [45056/54000 (83%)] Loss: -755.257446\n",
      "    epoch          : 945\n",
      "    loss           : -749.9161785773512\n",
      "    ess            : 1.960291808506228\n",
      "    log_marginal   : 749.9515496020047\n",
      "    log_joint      : 958.4167261663473\n",
      "    val_loss       : -753.5356903076172\n",
      "    val_ess        : 1.9595347046852112\n",
      "    val_log_marginal: 753.5687408447266\n",
      "    val_log_joint  : 962.1034037272135\n",
      "Train Epoch: 946 [0/54000 (0%)] Loss: -761.615601\n",
      "Train Epoch: 946 [11264/54000 (21%)] Loss: -743.153687\n",
      "Train Epoch: 946 [22528/54000 (42%)] Loss: -747.988159\n",
      "Train Epoch: 946 [33792/54000 (63%)] Loss: -753.442871\n",
      "Train Epoch: 946 [45056/54000 (83%)] Loss: -709.874756\n",
      "    epoch          : 946\n",
      "    loss           : -749.8719891242262\n",
      "    ess            : 1.9596109705151252\n",
      "    log_marginal   : 749.9087915960348\n",
      "    log_joint      : 958.4724506882002\n",
      "    val_loss       : -754.1394195556641\n",
      "    val_ess        : 1.9621461629867554\n",
      "    val_log_marginal: 754.1752319335938\n",
      "    val_log_joint  : 962.717030843099\n",
      "Train Epoch: 947 [0/54000 (0%)] Loss: -768.814331\n",
      "Train Epoch: 947 [11264/54000 (21%)] Loss: -768.501953\n",
      "Train Epoch: 947 [22528/54000 (42%)] Loss: -762.186890\n",
      "Train Epoch: 947 [33792/54000 (63%)] Loss: -777.431824\n",
      "Train Epoch: 947 [45056/54000 (83%)] Loss: -754.234436\n",
      "    epoch          : 947\n",
      "    loss           : -749.9238834021227\n",
      "    ess            : 1.959970087375281\n",
      "    log_marginal   : 749.9596004845961\n",
      "    log_joint      : 958.4106571989239\n",
      "    val_loss       : -753.8657938639323\n",
      "    val_ess        : 1.963342656691869\n",
      "    val_log_marginal: 753.8951059977213\n",
      "    val_log_joint  : 962.3492482503256\n",
      "Train Epoch: 948 [0/54000 (0%)] Loss: -740.409546\n",
      "Train Epoch: 948 [11264/54000 (21%)] Loss: -741.954895\n",
      "Train Epoch: 948 [22528/54000 (42%)] Loss: -734.169434\n",
      "Train Epoch: 948 [33792/54000 (63%)] Loss: -748.432373\n",
      "Train Epoch: 948 [45056/54000 (83%)] Loss: -752.262573\n",
      "    epoch          : 948\n",
      "    loss           : -749.995638865345\n",
      "    ess            : 1.960506630393694\n",
      "    log_marginal   : 750.0309477032356\n",
      "    log_joint      : 958.5884508816702\n",
      "    val_loss       : -753.6600596110026\n",
      "    val_ess        : 1.9587778349717457\n",
      "    val_log_marginal: 753.7004089355469\n",
      "    val_log_joint  : 962.2947998046875\n",
      "Train Epoch: 949 [0/54000 (0%)] Loss: -776.249207\n",
      "Train Epoch: 949 [11264/54000 (21%)] Loss: -759.614990\n",
      "Train Epoch: 949 [22528/54000 (42%)] Loss: -736.950623\n",
      "Train Epoch: 949 [33792/54000 (63%)] Loss: -737.981934\n",
      "Train Epoch: 949 [45056/54000 (83%)] Loss: -752.502441\n",
      "    epoch          : 949\n",
      "    loss           : -750.108768679061\n",
      "    ess            : 1.959177220767399\n",
      "    log_marginal   : 750.1462166264372\n",
      "    log_joint      : 958.5781376676739\n",
      "    val_loss       : -754.5933939615885\n",
      "    val_ess        : 1.9603359699249268\n",
      "    val_log_marginal: 754.6272684733073\n",
      "    val_log_joint  : 962.8166453043619\n",
      "Train Epoch: 950 [0/54000 (0%)] Loss: -724.886841\n",
      "Train Epoch: 950 [11264/54000 (21%)] Loss: -752.278564\n",
      "Train Epoch: 950 [22528/54000 (42%)] Loss: -747.711670\n",
      "Train Epoch: 950 [33792/54000 (63%)] Loss: -753.012024\n",
      "Train Epoch: 950 [45056/54000 (83%)] Loss: -744.557373\n",
      "    epoch          : 950\n",
      "    loss           : -750.0116300762825\n",
      "    ess            : 1.9597415136841108\n",
      "    log_marginal   : 750.0477680710127\n",
      "    log_joint      : 958.547419134176\n",
      "    val_loss       : -755.4065806070963\n",
      "    val_ess        : 1.9630759457747142\n",
      "    val_log_marginal: 755.4364674886068\n",
      "    val_log_joint  : 963.7605336507162\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch950.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 951 [0/54000 (0%)] Loss: -748.389038\n",
      "Train Epoch: 951 [11264/54000 (21%)] Loss: -739.889648\n",
      "Train Epoch: 951 [22528/54000 (42%)] Loss: -751.041992\n",
      "Train Epoch: 951 [33792/54000 (63%)] Loss: -724.227661\n",
      "Train Epoch: 951 [45056/54000 (83%)] Loss: -749.119995\n",
      "    epoch          : 951\n",
      "    loss           : -749.9778269641804\n",
      "    ess            : 1.9589562461061298\n",
      "    log_marginal   : 750.0155726018942\n",
      "    log_joint      : 958.5192278016289\n",
      "    val_loss       : -754.5470428466797\n",
      "    val_ess        : 1.9586096902688344\n",
      "    val_log_marginal: 754.5823160807291\n",
      "    val_log_joint  : 962.9721984863281\n",
      "Train Epoch: 952 [0/54000 (0%)] Loss: -758.034241\n",
      "Train Epoch: 952 [11264/54000 (21%)] Loss: -744.895203\n",
      "Train Epoch: 952 [22528/54000 (42%)] Loss: -761.367249\n",
      "Train Epoch: 952 [33792/54000 (63%)] Loss: -765.839111\n",
      "Train Epoch: 952 [45056/54000 (83%)] Loss: -765.803955\n",
      "    epoch          : 952\n",
      "    loss           : -750.2689404757517\n",
      "    ess            : 1.960180161134252\n",
      "    log_marginal   : 750.3047007434773\n",
      "    log_joint      : 958.7977035810362\n",
      "    val_loss       : -754.6047312418619\n",
      "    val_ess        : 1.954407552878062\n",
      "    val_log_marginal: 754.6514333089193\n",
      "    val_log_joint  : 962.9612731933594\n",
      "Train Epoch: 953 [0/54000 (0%)] Loss: -738.896912\n",
      "Train Epoch: 953 [11264/54000 (21%)] Loss: -761.662415\n",
      "Train Epoch: 953 [22528/54000 (42%)] Loss: -748.495667\n",
      "Train Epoch: 953 [33792/54000 (63%)] Loss: -758.475220\n",
      "Train Epoch: 953 [45056/54000 (83%)] Loss: -737.673096\n",
      "    epoch          : 953\n",
      "    loss           : -750.4989618265404\n",
      "    ess            : 1.9587291029264342\n",
      "    log_marginal   : 750.535344537699\n",
      "    log_joint      : 958.9869868440448\n",
      "    val_loss       : -754.780039469401\n",
      "    val_ess        : 1.9633249541123707\n",
      "    val_log_marginal: 754.8121185302734\n",
      "    val_log_joint  : 963.2442474365234\n",
      "Train Epoch: 954 [0/54000 (0%)] Loss: -751.595032\n",
      "Train Epoch: 954 [11264/54000 (21%)] Loss: -728.612915\n",
      "Train Epoch: 954 [22528/54000 (42%)] Loss: -732.747437\n",
      "Train Epoch: 954 [33792/54000 (63%)] Loss: -741.322571\n",
      "Train Epoch: 954 [45056/54000 (83%)] Loss: -720.576904\n",
      "    epoch          : 954\n",
      "    loss           : -750.4769580769089\n",
      "    ess            : 1.9605504735460821\n",
      "    log_marginal   : 750.5124880232901\n",
      "    log_joint      : 958.9769713203862\n",
      "    val_loss       : -754.1971333821615\n",
      "    val_ess        : 1.9575591882069905\n",
      "    val_log_marginal: 754.2391967773438\n",
      "    val_log_joint  : 962.8679453531901\n",
      "Train Epoch: 955 [0/54000 (0%)] Loss: -735.691223\n",
      "Train Epoch: 955 [11264/54000 (21%)] Loss: -774.064941\n",
      "Train Epoch: 955 [22528/54000 (42%)] Loss: -755.560303\n",
      "Train Epoch: 955 [33792/54000 (63%)] Loss: -757.450684\n",
      "Train Epoch: 955 [45056/54000 (83%)] Loss: -727.861755\n",
      "    epoch          : 955\n",
      "    loss           : -750.5293809422907\n",
      "    ess            : 1.959169306845035\n",
      "    log_marginal   : 750.5661592303582\n",
      "    log_joint      : 959.0108786528965\n",
      "    val_loss       : -754.9837799072266\n",
      "    val_ess        : 1.9574705958366394\n",
      "    val_log_marginal: 755.0237833658854\n",
      "    val_log_joint  : 963.3466288248698\n",
      "Train Epoch: 956 [0/54000 (0%)] Loss: -729.224060\n",
      "Train Epoch: 956 [11264/54000 (21%)] Loss: -725.263062\n",
      "Train Epoch: 956 [22528/54000 (42%)] Loss: -736.546021\n",
      "Train Epoch: 956 [33792/54000 (63%)] Loss: -736.123840\n",
      "Train Epoch: 956 [45056/54000 (83%)] Loss: -768.659790\n",
      "    epoch          : 956\n",
      "    loss           : -750.762792623268\n",
      "    ess            : 1.9593194633159998\n",
      "    log_marginal   : 750.7988597941849\n",
      "    log_joint      : 959.2613870872641\n",
      "    val_loss       : -754.8428802490234\n",
      "    val_ess        : 1.9600731333096821\n",
      "    val_log_marginal: 754.8796590169271\n",
      "    val_log_joint  : 963.3066813151041\n",
      "Train Epoch: 957 [0/54000 (0%)] Loss: -754.309692\n",
      "Train Epoch: 957 [11264/54000 (21%)] Loss: -736.670776\n",
      "Train Epoch: 957 [22528/54000 (42%)] Loss: -753.022705\n",
      "Train Epoch: 957 [33792/54000 (63%)] Loss: -732.723877\n",
      "Train Epoch: 957 [45056/54000 (83%)] Loss: -729.605225\n",
      "    epoch          : 957\n",
      "    loss           : -750.7951878961527\n",
      "    ess            : 1.9604981069294911\n",
      "    log_marginal   : 750.8299572062942\n",
      "    log_joint      : 959.2315754440596\n",
      "    val_loss       : -754.6736043294271\n",
      "    val_ess        : 1.9599373439947765\n",
      "    val_log_marginal: 754.7076822916666\n",
      "    val_log_joint  : 963.2926381429037\n",
      "Train Epoch: 958 [0/54000 (0%)] Loss: -747.447754\n",
      "Train Epoch: 958 [11264/54000 (21%)] Loss: -768.481689\n",
      "Train Epoch: 958 [22528/54000 (42%)] Loss: -748.011963\n",
      "Train Epoch: 958 [33792/54000 (63%)] Loss: -723.348755\n",
      "Train Epoch: 958 [45056/54000 (83%)] Loss: -768.265015\n",
      "    epoch          : 958\n",
      "    loss           : -750.5902243560215\n",
      "    ess            : 1.9592600993390352\n",
      "    log_marginal   : 750.6266548588591\n",
      "    log_joint      : 959.0923156738281\n",
      "    val_loss       : -754.9698282877604\n",
      "    val_ess        : 1.9590644339720409\n",
      "    val_log_marginal: 755.0051981608073\n",
      "    val_log_joint  : 963.5753021240234\n",
      "Train Epoch: 959 [0/54000 (0%)] Loss: -771.534058\n",
      "Train Epoch: 959 [11264/54000 (21%)] Loss: -762.056152\n",
      "Train Epoch: 959 [22528/54000 (42%)] Loss: -739.041016\n",
      "Train Epoch: 959 [33792/54000 (63%)] Loss: -736.648438\n",
      "Train Epoch: 959 [45056/54000 (83%)] Loss: -737.963684\n",
      "    epoch          : 959\n",
      "    loss           : -750.8439970196418\n",
      "    ess            : 1.9597008858086928\n",
      "    log_marginal   : 750.8812071602299\n",
      "    log_joint      : 959.4394784603479\n",
      "    val_loss       : -754.8512013753256\n",
      "    val_ess        : 1.9592353006203969\n",
      "    val_log_marginal: 754.8878479003906\n",
      "    val_log_joint  : 963.2354329427084\n",
      "Train Epoch: 960 [0/54000 (0%)] Loss: -748.743042\n",
      "Train Epoch: 960 [11264/54000 (21%)] Loss: -765.996460\n",
      "Train Epoch: 960 [22528/54000 (42%)] Loss: -755.365723\n",
      "Train Epoch: 960 [33792/54000 (63%)] Loss: -732.715027\n",
      "Train Epoch: 960 [45056/54000 (83%)] Loss: -761.322388\n",
      "    epoch          : 960\n",
      "    loss           : -750.9931214530513\n",
      "    ess            : 1.960468760076559\n",
      "    log_marginal   : 751.028655430056\n",
      "    log_joint      : 959.3848376004202\n",
      "    val_loss       : -754.8634541829427\n",
      "    val_ess        : 1.9601198931535084\n",
      "    val_log_marginal: 754.9025624593099\n",
      "    val_log_joint  : 963.2632344563802\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch960.pth ...\n",
      "Train Epoch: 961 [0/54000 (0%)] Loss: -775.884277\n",
      "Train Epoch: 961 [11264/54000 (21%)] Loss: -766.286865\n",
      "Train Epoch: 961 [22528/54000 (42%)] Loss: -745.188110\n",
      "Train Epoch: 961 [33792/54000 (63%)] Loss: -742.315125\n",
      "Train Epoch: 961 [45056/54000 (83%)] Loss: -755.476074\n",
      "    epoch          : 961\n",
      "    loss           : -750.9696160082547\n",
      "    ess            : 1.9605306938009441\n",
      "    log_marginal   : 751.0047037376547\n",
      "    log_joint      : 959.4225625092129\n",
      "    val_loss       : -755.2196299235026\n",
      "    val_ess        : 1.9623224437236786\n",
      "    val_log_marginal: 755.2531483968099\n",
      "    val_log_joint  : 963.8964894612631\n",
      "Train Epoch: 962 [0/54000 (0%)] Loss: -745.620728\n",
      "Train Epoch: 962 [11264/54000 (21%)] Loss: -749.841736\n",
      "Train Epoch: 962 [22528/54000 (42%)] Loss: -745.256836\n",
      "Train Epoch: 962 [33792/54000 (63%)] Loss: -756.321960\n",
      "Train Epoch: 962 [45056/54000 (83%)] Loss: -731.098022\n",
      "    epoch          : 962\n",
      "    loss           : -751.0191915260172\n",
      "    ess            : 1.9594272105198987\n",
      "    log_marginal   : 751.056458671138\n",
      "    log_joint      : 959.5779182865934\n",
      "    val_loss       : -756.0008494059244\n",
      "    val_ess        : 1.9588089386622112\n",
      "    val_log_marginal: 756.0379180908203\n",
      "    val_log_joint  : 964.3655751546224\n",
      "Train Epoch: 963 [0/54000 (0%)] Loss: -742.945618\n",
      "Train Epoch: 963 [11264/54000 (21%)] Loss: -756.067444\n",
      "Train Epoch: 963 [22528/54000 (42%)] Loss: -774.319641\n",
      "Train Epoch: 963 [33792/54000 (63%)] Loss: -771.211182\n",
      "Train Epoch: 963 [45056/54000 (83%)] Loss: -761.832397\n",
      "    epoch          : 963\n",
      "    loss           : -751.0728892200398\n",
      "    ess            : 1.9587227465971462\n",
      "    log_marginal   : 751.1098362184921\n",
      "    log_joint      : 959.543421907245\n",
      "    val_loss       : -755.4437866210938\n",
      "    val_ess        : 1.9573470552762349\n",
      "    val_log_marginal: 755.4844106038412\n",
      "    val_log_joint  : 963.5218048095703\n",
      "Train Epoch: 964 [0/54000 (0%)] Loss: -748.137695\n",
      "Train Epoch: 964 [11264/54000 (21%)] Loss: -725.249634\n",
      "Train Epoch: 964 [22528/54000 (42%)] Loss: -741.724854\n",
      "Train Epoch: 964 [33792/54000 (63%)] Loss: -768.533264\n",
      "Train Epoch: 964 [45056/54000 (83%)] Loss: -740.465820\n",
      "    epoch          : 964\n",
      "    loss           : -751.0139373203493\n",
      "    ess            : 1.9588941301939622\n",
      "    log_marginal   : 751.0516006181825\n",
      "    log_joint      : 959.5370921008991\n",
      "    val_loss       : -755.5564422607422\n",
      "    val_ess        : 1.9580010374387105\n",
      "    val_log_marginal: 755.5909881591797\n",
      "    val_log_joint  : 964.0103912353516\n",
      "Train Epoch: 965 [0/54000 (0%)] Loss: -781.065613\n",
      "Train Epoch: 965 [11264/54000 (21%)] Loss: -734.782959\n",
      "Train Epoch: 965 [22528/54000 (42%)] Loss: -752.372803\n",
      "Train Epoch: 965 [33792/54000 (63%)] Loss: -726.970642\n",
      "Train Epoch: 965 [45056/54000 (83%)] Loss: -740.617676\n",
      "    epoch          : 965\n",
      "    loss           : -751.4499724765993\n",
      "    ess            : 1.9589380273279153\n",
      "    log_marginal   : 751.4863200637529\n",
      "    log_joint      : 959.8977972066627\n",
      "    val_loss       : -755.7204996744791\n",
      "    val_ess        : 1.9621112445990245\n",
      "    val_log_marginal: 755.7542978922526\n",
      "    val_log_joint  : 964.0784657796224\n",
      "Train Epoch: 966 [0/54000 (0%)] Loss: -745.621765\n",
      "Train Epoch: 966 [11264/54000 (21%)] Loss: -763.640747\n",
      "Train Epoch: 966 [22528/54000 (42%)] Loss: -739.128418\n",
      "Train Epoch: 966 [33792/54000 (63%)] Loss: -760.135498\n",
      "Train Epoch: 966 [45056/54000 (83%)] Loss: -745.469177\n",
      "    epoch          : 966\n",
      "    loss           : -751.3406544811321\n",
      "    ess            : 1.9602071766583424\n",
      "    log_marginal   : 751.3756374143204\n",
      "    log_joint      : 959.9088008088886\n",
      "    val_loss       : -755.8985443115234\n",
      "    val_ess        : 1.9572553435961406\n",
      "    val_log_marginal: 755.9391377766927\n",
      "    val_log_joint  : 964.4622192382812\n",
      "Train Epoch: 967 [0/54000 (0%)] Loss: -779.892090\n",
      "Train Epoch: 967 [11264/54000 (21%)] Loss: -733.877075\n",
      "Train Epoch: 967 [22528/54000 (42%)] Loss: -750.383301\n",
      "Train Epoch: 967 [33792/54000 (63%)] Loss: -730.961731\n",
      "Train Epoch: 967 [45056/54000 (83%)] Loss: -741.722656\n",
      "    epoch          : 967\n",
      "    loss           : -751.4782225410893\n",
      "    ess            : 1.9594643610828328\n",
      "    log_marginal   : 751.5146225263487\n",
      "    log_joint      : 959.9489913076725\n",
      "    val_loss       : -755.2354736328125\n",
      "    val_ess        : 1.956689457098643\n",
      "    val_log_marginal: 755.2751312255859\n",
      "    val_log_joint  : 964.0501556396484\n",
      "Train Epoch: 968 [0/54000 (0%)] Loss: -767.795044\n",
      "Train Epoch: 968 [11264/54000 (21%)] Loss: -746.760742\n",
      "Train Epoch: 968 [22528/54000 (42%)] Loss: -721.677002\n",
      "Train Epoch: 968 [33792/54000 (63%)] Loss: -747.971863\n",
      "Train Epoch: 968 [45056/54000 (83%)] Loss: -756.317505\n",
      "    epoch          : 968\n",
      "    loss           : -751.7464985397627\n",
      "    ess            : 1.959822655848737\n",
      "    log_marginal   : 751.7834000497494\n",
      "    log_joint      : 960.1994081893057\n",
      "    val_loss       : -755.1874643961588\n",
      "    val_ess        : 1.960545112689336\n",
      "    val_log_marginal: 755.2229309082031\n",
      "    val_log_joint  : 963.4310404459635\n",
      "Train Epoch: 969 [0/54000 (0%)] Loss: -726.275635\n",
      "Train Epoch: 969 [11264/54000 (21%)] Loss: -771.214233\n",
      "Train Epoch: 969 [22528/54000 (42%)] Loss: -746.296753\n",
      "Train Epoch: 969 [33792/54000 (63%)] Loss: -769.276733\n",
      "Train Epoch: 969 [45056/54000 (83%)] Loss: -737.471191\n",
      "    epoch          : 969\n",
      "    loss           : -751.5063804770416\n",
      "    ess            : 1.9598803958802853\n",
      "    log_marginal   : 751.5425052282945\n",
      "    log_joint      : 960.105727285709\n",
      "    val_loss       : -755.3709513346354\n",
      "    val_ess        : 1.9546039799849193\n",
      "    val_log_marginal: 755.4140472412109\n",
      "    val_log_joint  : 964.005126953125\n",
      "Train Epoch: 970 [0/54000 (0%)] Loss: -732.824707\n",
      "Train Epoch: 970 [11264/54000 (21%)] Loss: -728.639282\n",
      "Train Epoch: 970 [22528/54000 (42%)] Loss: -741.358459\n",
      "Train Epoch: 970 [33792/54000 (63%)] Loss: -733.118286\n",
      "Train Epoch: 970 [45056/54000 (83%)] Loss: -759.314941\n",
      "    epoch          : 970\n",
      "    loss           : -751.802210969745\n",
      "    ess            : 1.959174929924731\n",
      "    log_marginal   : 751.8388499133991\n",
      "    log_joint      : 960.2446450287441\n",
      "    val_loss       : -756.0684509277344\n",
      "    val_ess        : 1.9621437589327495\n",
      "    val_log_marginal: 756.103281656901\n",
      "    val_log_joint  : 964.5590413411459\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch970.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 971 [0/54000 (0%)] Loss: -758.132446\n",
      "Train Epoch: 971 [11264/54000 (21%)] Loss: -757.950745\n",
      "Train Epoch: 971 [22528/54000 (42%)] Loss: -737.776794\n",
      "Train Epoch: 971 [33792/54000 (63%)] Loss: -758.399719\n",
      "Train Epoch: 971 [45056/54000 (83%)] Loss: -777.302002\n",
      "    epoch          : 971\n",
      "    loss           : -751.6315699163473\n",
      "    ess            : 1.9594129447667104\n",
      "    log_marginal   : 751.6670428581957\n",
      "    log_joint      : 960.2823676343235\n",
      "    val_loss       : -756.375742594401\n",
      "    val_ess        : 1.9630605280399323\n",
      "    val_log_marginal: 756.4062245686849\n",
      "    val_log_joint  : 964.776133219401\n",
      "Train Epoch: 972 [0/54000 (0%)] Loss: -759.940125\n",
      "Train Epoch: 972 [11264/54000 (21%)] Loss: -756.171204\n",
      "Train Epoch: 972 [22528/54000 (42%)] Loss: -755.982910\n",
      "Train Epoch: 972 [33792/54000 (63%)] Loss: -764.272583\n",
      "Train Epoch: 972 [45056/54000 (83%)] Loss: -761.163635\n",
      "    epoch          : 972\n",
      "    loss           : -752.0376909363945\n",
      "    ess            : 1.9601367104728267\n",
      "    log_marginal   : 752.0738582970961\n",
      "    log_joint      : 960.4259597490419\n",
      "    val_loss       : -755.4465484619141\n",
      "    val_ess        : 1.9615660707155864\n",
      "    val_log_marginal: 755.4825388590494\n",
      "    val_log_joint  : 964.1122131347656\n",
      "Train Epoch: 973 [0/54000 (0%)] Loss: -761.005615\n",
      "Train Epoch: 973 [11264/54000 (21%)] Loss: -757.140625\n",
      "Train Epoch: 973 [22528/54000 (42%)] Loss: -769.247803\n",
      "Train Epoch: 973 [33792/54000 (63%)] Loss: -767.315308\n",
      "Train Epoch: 973 [45056/54000 (83%)] Loss: -738.120972\n",
      "    epoch          : 973\n",
      "    loss           : -751.9995635410525\n",
      "    ess            : 1.9600370627529216\n",
      "    log_marginal   : 752.0354522129275\n",
      "    log_joint      : 960.5090165048275\n",
      "    val_loss       : -755.710215250651\n",
      "    val_ess        : 1.95996688803037\n",
      "    val_log_marginal: 755.7464853922526\n",
      "    val_log_joint  : 964.2562459309896\n",
      "Train Epoch: 974 [0/54000 (0%)] Loss: -731.770447\n",
      "Train Epoch: 974 [11264/54000 (21%)] Loss: -764.651611\n",
      "Train Epoch: 974 [22528/54000 (42%)] Loss: -740.675659\n",
      "Train Epoch: 974 [33792/54000 (63%)] Loss: -757.879883\n",
      "Train Epoch: 974 [45056/54000 (83%)] Loss: -748.630127\n",
      "    epoch          : 974\n",
      "    loss           : -752.177128054061\n",
      "    ess            : 1.9597426540446732\n",
      "    log_marginal   : 752.2135044313827\n",
      "    log_joint      : 960.7567795087706\n",
      "    val_loss       : -755.6409047444662\n",
      "    val_ess        : 1.9565611282984416\n",
      "    val_log_marginal: 755.6767374674479\n",
      "    val_log_joint  : 964.347422281901\n",
      "Train Epoch: 975 [0/54000 (0%)] Loss: -756.044312\n",
      "Train Epoch: 975 [11264/54000 (21%)] Loss: -732.843750\n",
      "Train Epoch: 975 [22528/54000 (42%)] Loss: -750.332275\n",
      "Train Epoch: 975 [33792/54000 (63%)] Loss: -738.083496\n",
      "Train Epoch: 975 [45056/54000 (83%)] Loss: -750.555908\n",
      "    epoch          : 975\n",
      "    loss           : -752.1178876768868\n",
      "    ess            : 1.9595844993051492\n",
      "    log_marginal   : 752.1548605864903\n",
      "    log_joint      : 960.5629957666937\n",
      "    val_loss       : -755.6111450195312\n",
      "    val_ess        : 1.95908456047376\n",
      "    val_log_marginal: 755.6473286946615\n",
      "    val_log_joint  : 964.2621561686198\n",
      "Train Epoch: 976 [0/54000 (0%)] Loss: -735.399780\n",
      "Train Epoch: 976 [11264/54000 (21%)] Loss: -748.265991\n",
      "Train Epoch: 976 [22528/54000 (42%)] Loss: -744.901672\n",
      "Train Epoch: 976 [33792/54000 (63%)] Loss: -762.075439\n",
      "Train Epoch: 976 [45056/54000 (83%)] Loss: -756.142578\n",
      "    epoch          : 976\n",
      "    loss           : -752.1846728054983\n",
      "    ess            : 1.9588917437589393\n",
      "    log_marginal   : 752.223086950914\n",
      "    log_joint      : 960.8103413132002\n",
      "    val_loss       : -755.7919565836588\n",
      "    val_ess        : 1.9569205045700073\n",
      "    val_log_marginal: 755.8341369628906\n",
      "    val_log_joint  : 964.3811899820963\n",
      "Train Epoch: 977 [0/54000 (0%)] Loss: -770.327393\n",
      "Train Epoch: 977 [11264/54000 (21%)] Loss: -739.730957\n",
      "Train Epoch: 977 [22528/54000 (42%)] Loss: -747.167603\n",
      "Train Epoch: 977 [33792/54000 (63%)] Loss: -766.910034\n",
      "Train Epoch: 977 [45056/54000 (83%)] Loss: -747.607300\n",
      "    epoch          : 977\n",
      "    loss           : -752.3971367602078\n",
      "    ess            : 1.9586438705336373\n",
      "    log_marginal   : 752.4341165794516\n",
      "    log_joint      : 960.8893035312868\n",
      "    val_loss       : -756.6521555582682\n",
      "    val_ess        : 1.960389643907547\n",
      "    val_log_marginal: 756.6859130859375\n",
      "    val_log_joint  : 965.0730692545573\n",
      "Train Epoch: 978 [0/54000 (0%)] Loss: -749.050537\n",
      "Train Epoch: 978 [11264/54000 (21%)] Loss: -765.575684\n",
      "Train Epoch: 978 [22528/54000 (42%)] Loss: -771.414673\n",
      "Train Epoch: 978 [33792/54000 (63%)] Loss: -747.872803\n",
      "Train Epoch: 978 [45056/54000 (83%)] Loss: -756.059326\n",
      "    epoch          : 978\n",
      "    loss           : -752.3788285165463\n",
      "    ess            : 1.960159350116298\n",
      "    log_marginal   : 752.4142692134066\n",
      "    log_joint      : 960.819664721219\n",
      "    val_loss       : -756.7296091715494\n",
      "    val_ess        : 1.9614502986272175\n",
      "    val_log_marginal: 756.7599639892578\n",
      "    val_log_joint  : 965.2684427897135\n",
      "Train Epoch: 979 [0/54000 (0%)] Loss: -756.416138\n",
      "Train Epoch: 979 [11264/54000 (21%)] Loss: -757.079468\n",
      "Train Epoch: 979 [22528/54000 (42%)] Loss: -753.955933\n",
      "Train Epoch: 979 [33792/54000 (63%)] Loss: -743.600098\n",
      "Train Epoch: 979 [45056/54000 (83%)] Loss: -741.916199\n",
      "    epoch          : 979\n",
      "    loss           : -752.41476152528\n",
      "    ess            : 1.9606364706777177\n",
      "    log_marginal   : 752.4482462181235\n",
      "    log_joint      : 960.8518878288988\n",
      "    val_loss       : -756.5265452067057\n",
      "    val_ess        : 1.958040863275528\n",
      "    val_log_marginal: 756.5655059814453\n",
      "    val_log_joint  : 965.0466003417969\n",
      "Train Epoch: 980 [0/54000 (0%)] Loss: -740.682922\n",
      "Train Epoch: 980 [11264/54000 (21%)] Loss: -761.999390\n",
      "Train Epoch: 980 [22528/54000 (42%)] Loss: -757.126221\n",
      "Train Epoch: 980 [33792/54000 (63%)] Loss: -750.784180\n",
      "Train Epoch: 980 [45056/54000 (83%)] Loss: -755.514709\n",
      "    epoch          : 980\n",
      "    loss           : -752.5024932285525\n",
      "    ess            : 1.958909900683277\n",
      "    log_marginal   : 752.5388356334759\n",
      "    log_joint      : 961.0243703014446\n",
      "    val_loss       : -757.0370127360026\n",
      "    val_ess        : 1.959900716940562\n",
      "    val_log_marginal: 757.0719655354818\n",
      "    val_log_joint  : 965.5366821289062\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch980.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 981 [0/54000 (0%)] Loss: -765.805176\n",
      "Train Epoch: 981 [11264/54000 (21%)] Loss: -743.437561\n",
      "Train Epoch: 981 [22528/54000 (42%)] Loss: -734.095703\n",
      "Train Epoch: 981 [33792/54000 (63%)] Loss: -736.833740\n",
      "Train Epoch: 981 [45056/54000 (83%)] Loss: -745.176514\n",
      "    epoch          : 981\n",
      "    loss           : -752.3892902878096\n",
      "    ess            : 1.9604668291109912\n",
      "    log_marginal   : 752.4239761064638\n",
      "    log_joint      : 960.8645422593603\n",
      "    val_loss       : -756.3728078206381\n",
      "    val_ess        : 1.961888611316681\n",
      "    val_log_marginal: 756.4065856933594\n",
      "    val_log_joint  : 964.6308797200521\n",
      "Train Epoch: 982 [0/54000 (0%)] Loss: -750.919189\n",
      "Train Epoch: 982 [11264/54000 (21%)] Loss: -719.332642\n",
      "Train Epoch: 982 [22528/54000 (42%)] Loss: -750.479797\n",
      "Train Epoch: 982 [33792/54000 (63%)] Loss: -755.287720\n",
      "Train Epoch: 982 [45056/54000 (83%)] Loss: -750.920715\n",
      "    epoch          : 982\n",
      "    loss           : -752.3900543788694\n",
      "    ess            : 1.9597179124940116\n",
      "    log_marginal   : 752.4268338185436\n",
      "    log_joint      : 960.962450135429\n",
      "    val_loss       : -757.6658376057943\n",
      "    val_ess        : 1.9622429112593334\n",
      "    val_log_marginal: 757.6977996826172\n",
      "    val_log_joint  : 965.9587707519531\n",
      "Train Epoch: 983 [0/54000 (0%)] Loss: -751.570312\n",
      "Train Epoch: 983 [11264/54000 (21%)] Loss: -753.273438\n",
      "Train Epoch: 983 [22528/54000 (42%)] Loss: -754.006714\n",
      "Train Epoch: 983 [33792/54000 (63%)] Loss: -735.424683\n",
      "Train Epoch: 983 [45056/54000 (83%)] Loss: -758.630920\n",
      "    epoch          : 983\n",
      "    loss           : -752.5240006356869\n",
      "    ess            : 1.9588428623271439\n",
      "    log_marginal   : 752.5617543346477\n",
      "    log_joint      : 961.1269583072302\n",
      "    val_loss       : -757.262461344401\n",
      "    val_ess        : 1.961974690357844\n",
      "    val_log_marginal: 757.2996927897135\n",
      "    val_log_joint  : 965.5673777262369\n",
      "Train Epoch: 984 [0/54000 (0%)] Loss: -764.304260\n",
      "Train Epoch: 984 [11264/54000 (21%)] Loss: -751.897095\n",
      "Train Epoch: 984 [22528/54000 (42%)] Loss: -764.226013\n",
      "Train Epoch: 984 [33792/54000 (63%)] Loss: -732.421692\n",
      "Train Epoch: 984 [45056/54000 (83%)] Loss: -754.594238\n",
      "    epoch          : 984\n",
      "    loss           : -752.7412218777639\n",
      "    ess            : 1.9590053445888016\n",
      "    log_marginal   : 752.7801801573555\n",
      "    log_joint      : 961.2301981224203\n",
      "    val_loss       : -756.2628377278646\n",
      "    val_ess        : 1.9594400425752003\n",
      "    val_log_marginal: 756.2994944254557\n",
      "    val_log_joint  : 964.896962483724\n",
      "Train Epoch: 985 [0/54000 (0%)] Loss: -756.772827\n",
      "Train Epoch: 985 [11264/54000 (21%)] Loss: -772.694092\n",
      "Train Epoch: 985 [22528/54000 (42%)] Loss: -758.928650\n",
      "Train Epoch: 985 [33792/54000 (63%)] Loss: -755.967163\n",
      "Train Epoch: 985 [45056/54000 (83%)] Loss: -765.855225\n",
      "    epoch          : 985\n",
      "    loss           : -752.6726811247052\n",
      "    ess            : 1.959981088368398\n",
      "    log_marginal   : 752.7093776486954\n",
      "    log_joint      : 961.2683036372347\n",
      "    val_loss       : -756.9037221272787\n",
      "    val_ess        : 1.9624404609203339\n",
      "    val_log_marginal: 756.9374033610026\n",
      "    val_log_joint  : 965.4007212320963\n",
      "Train Epoch: 986 [0/54000 (0%)] Loss: -754.129761\n",
      "Train Epoch: 986 [11264/54000 (21%)] Loss: -756.173706\n",
      "Train Epoch: 986 [22528/54000 (42%)] Loss: -742.731201\n",
      "Train Epoch: 986 [33792/54000 (63%)] Loss: -745.092041\n",
      "Train Epoch: 986 [45056/54000 (83%)] Loss: -763.803223\n",
      "    epoch          : 986\n",
      "    loss           : -752.7743616643942\n",
      "    ess            : 1.9603048113157164\n",
      "    log_marginal   : 752.8109464825325\n",
      "    log_joint      : 961.3935938421286\n",
      "    val_loss       : -757.0242207845052\n",
      "    val_ess        : 1.9612220227718353\n",
      "    val_log_marginal: 757.0582580566406\n",
      "    val_log_joint  : 965.2269592285156\n",
      "Train Epoch: 987 [0/54000 (0%)] Loss: -747.905762\n",
      "Train Epoch: 987 [11264/54000 (21%)] Loss: -772.983643\n",
      "Train Epoch: 987 [22528/54000 (42%)] Loss: -749.927368\n",
      "Train Epoch: 987 [33792/54000 (63%)] Loss: -757.001892\n",
      "Train Epoch: 987 [45056/54000 (83%)] Loss: -741.737610\n",
      "    epoch          : 987\n",
      "    loss           : -753.0047831985186\n",
      "    ess            : 1.9591709487843063\n",
      "    log_marginal   : 753.042153412441\n",
      "    log_joint      : 961.5074750792305\n",
      "    val_loss       : -757.1458994547526\n",
      "    val_ess        : 1.9627379775047302\n",
      "    val_log_marginal: 757.1773834228516\n",
      "    val_log_joint  : 965.5773569742838\n",
      "Train Epoch: 988 [0/54000 (0%)] Loss: -773.990479\n",
      "Train Epoch: 988 [11264/54000 (21%)] Loss: -745.947876\n",
      "Train Epoch: 988 [22528/54000 (42%)] Loss: -774.059753\n",
      "Train Epoch: 988 [33792/54000 (63%)] Loss: -769.254028\n",
      "Train Epoch: 988 [45056/54000 (83%)] Loss: -750.031860\n",
      "    epoch          : 988\n",
      "    loss           : -753.2252888229658\n",
      "    ess            : 1.9598945885334376\n",
      "    log_marginal   : 753.2605205032061\n",
      "    log_joint      : 961.6613827111586\n",
      "    val_loss       : -757.3491821289062\n",
      "    val_ess        : 1.9576563835144043\n",
      "    val_log_marginal: 757.3876291910807\n",
      "    val_log_joint  : 966.0224202473959\n",
      "Train Epoch: 989 [0/54000 (0%)] Loss: -765.302368\n",
      "Train Epoch: 989 [11264/54000 (21%)] Loss: -753.658813\n",
      "Train Epoch: 989 [22528/54000 (42%)] Loss: -745.340454\n",
      "Train Epoch: 989 [33792/54000 (63%)] Loss: -753.691223\n",
      "Train Epoch: 989 [45056/54000 (83%)] Loss: -761.699585\n",
      "    epoch          : 989\n",
      "    loss           : -753.2025181032577\n",
      "    ess            : 1.9607108437790062\n",
      "    log_marginal   : 753.2391973531471\n",
      "    log_joint      : 961.7240070846846\n",
      "    val_loss       : -757.2308400472006\n",
      "    val_ess        : 1.9615954955418904\n",
      "    val_log_marginal: 757.2636667887369\n",
      "    val_log_joint  : 965.7709299723307\n",
      "Train Epoch: 990 [0/54000 (0%)] Loss: -750.670959\n",
      "Train Epoch: 990 [11264/54000 (21%)] Loss: -757.164734\n",
      "Train Epoch: 990 [22528/54000 (42%)] Loss: -744.817993\n",
      "Train Epoch: 990 [33792/54000 (63%)] Loss: -755.178467\n",
      "Train Epoch: 990 [45056/54000 (83%)] Loss: -744.883972\n",
      "    epoch          : 990\n",
      "    loss           : -753.3935126538547\n",
      "    ess            : 1.960167280907901\n",
      "    log_marginal   : 753.4290869370947\n",
      "    log_joint      : 961.9138477253464\n",
      "    val_loss       : -757.1532185872396\n",
      "    val_ess        : 1.9614672164122264\n",
      "    val_log_marginal: 757.1858113606771\n",
      "    val_log_joint  : 965.7064921061198\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch990.pth ...\n",
      "Train Epoch: 991 [0/54000 (0%)] Loss: -763.162354\n",
      "Train Epoch: 991 [11264/54000 (21%)] Loss: -744.133545\n",
      "Train Epoch: 991 [22528/54000 (42%)] Loss: -763.385559\n",
      "Train Epoch: 991 [33792/54000 (63%)] Loss: -723.836426\n",
      "Train Epoch: 991 [45056/54000 (83%)] Loss: -754.956421\n",
      "    epoch          : 991\n",
      "    loss           : -753.0883242049307\n",
      "    ess            : 1.959865319279005\n",
      "    log_marginal   : 753.1239410976194\n",
      "    log_joint      : 961.6020864810583\n",
      "    val_loss       : -756.9968770345052\n",
      "    val_ess        : 1.9627156456311543\n",
      "    val_log_marginal: 757.0286356608073\n",
      "    val_log_joint  : 965.6645151774088\n",
      "Train Epoch: 992 [0/54000 (0%)] Loss: -747.259155\n",
      "Train Epoch: 992 [11264/54000 (21%)] Loss: -770.872803\n",
      "Train Epoch: 992 [22528/54000 (42%)] Loss: -741.902222\n",
      "Train Epoch: 992 [33792/54000 (63%)] Loss: -765.894165\n",
      "Train Epoch: 992 [45056/54000 (83%)] Loss: -746.581970\n",
      "    epoch          : 992\n",
      "    loss           : -753.3321763524469\n",
      "    ess            : 1.9608775051134937\n",
      "    log_marginal   : 753.3666485480543\n",
      "    log_joint      : 961.81773232514\n",
      "    val_loss       : -757.8801930745443\n",
      "    val_ess        : 1.9562220176060994\n",
      "    val_log_marginal: 757.9215037027994\n",
      "    val_log_joint  : 966.4773966471354\n",
      "Train Epoch: 993 [0/54000 (0%)] Loss: -759.541382\n",
      "Train Epoch: 993 [11264/54000 (21%)] Loss: -751.208618\n",
      "Train Epoch: 993 [22528/54000 (42%)] Loss: -751.813721\n",
      "Train Epoch: 993 [33792/54000 (63%)] Loss: -735.098267\n",
      "Train Epoch: 993 [45056/54000 (83%)] Loss: -750.670288\n",
      "    epoch          : 993\n",
      "    loss           : -753.2852115271227\n",
      "    ess            : 1.959407758037999\n",
      "    log_marginal   : 753.3221199467497\n",
      "    log_joint      : 961.8009522635982\n",
      "    val_loss       : -757.6090037027994\n",
      "    val_ess        : 1.9602059523264568\n",
      "    val_log_marginal: 757.6447601318359\n",
      "    val_log_joint  : 966.2868041992188\n",
      "Train Epoch: 994 [0/54000 (0%)] Loss: -774.438721\n",
      "Train Epoch: 994 [11264/54000 (21%)] Loss: -778.031494\n",
      "Train Epoch: 994 [22528/54000 (42%)] Loss: -737.482788\n",
      "Train Epoch: 994 [33792/54000 (63%)] Loss: -762.314575\n",
      "Train Epoch: 994 [45056/54000 (83%)] Loss: -740.678833\n",
      "    epoch          : 994\n",
      "    loss           : -753.5378118551002\n",
      "    ess            : 1.9592356726808369\n",
      "    log_marginal   : 753.5750248747052\n",
      "    log_joint      : 961.9948189213591\n",
      "    val_loss       : -757.9833424886068\n",
      "    val_ess        : 1.9603621164957683\n",
      "    val_log_marginal: 758.0202433268229\n",
      "    val_log_joint  : 966.7551116943359\n",
      "Train Epoch: 995 [0/54000 (0%)] Loss: -765.532959\n",
      "Train Epoch: 995 [11264/54000 (21%)] Loss: -744.951111\n",
      "Train Epoch: 995 [22528/54000 (42%)] Loss: -766.575256\n",
      "Train Epoch: 995 [33792/54000 (63%)] Loss: -790.569885\n",
      "Train Epoch: 995 [45056/54000 (83%)] Loss: -763.510193\n",
      "    epoch          : 995\n",
      "    loss           : -753.3599243164062\n",
      "    ess            : 1.959094208366466\n",
      "    log_marginal   : 753.3981461434994\n",
      "    log_joint      : 961.8669007499263\n",
      "    val_loss       : -757.7640635172526\n",
      "    val_ess        : 1.955707848072052\n",
      "    val_log_marginal: 757.8041788736979\n",
      "    val_log_joint  : 966.4267069498698\n",
      "Train Epoch: 996 [0/54000 (0%)] Loss: -737.899353\n",
      "Train Epoch: 996 [11264/54000 (21%)] Loss: -742.386475\n",
      "Train Epoch: 996 [22528/54000 (42%)] Loss: -740.388184\n",
      "Train Epoch: 996 [33792/54000 (63%)] Loss: -760.539429\n",
      "Train Epoch: 996 [45056/54000 (83%)] Loss: -742.100098\n",
      "    epoch          : 996\n",
      "    loss           : -753.4423315660009\n",
      "    ess            : 1.960458239294448\n",
      "    log_marginal   : 753.4782870310657\n",
      "    log_joint      : 962.0552362406029\n",
      "    val_loss       : -757.3044738769531\n",
      "    val_ess        : 1.9607824782530467\n",
      "    val_log_marginal: 757.3402506510416\n",
      "    val_log_joint  : 965.855224609375\n",
      "Train Epoch: 997 [0/54000 (0%)] Loss: -744.223633\n",
      "Train Epoch: 997 [11264/54000 (21%)] Loss: -751.294922\n",
      "Train Epoch: 997 [22528/54000 (42%)] Loss: -760.500061\n",
      "Train Epoch: 997 [33792/54000 (63%)] Loss: -749.482422\n",
      "Train Epoch: 997 [45056/54000 (83%)] Loss: -776.653687\n",
      "    epoch          : 997\n",
      "    loss           : -753.7869475742556\n",
      "    ess            : 1.9603643473589196\n",
      "    log_marginal   : 753.8232272166126\n",
      "    log_joint      : 962.2542787947745\n",
      "    val_loss       : -757.6118113199869\n",
      "    val_ess        : 1.9597901205221813\n",
      "    val_log_marginal: 757.6468709309896\n",
      "    val_log_joint  : 966.3792114257812\n",
      "Train Epoch: 998 [0/54000 (0%)] Loss: -770.613403\n",
      "Train Epoch: 998 [11264/54000 (21%)] Loss: -762.304199\n",
      "Train Epoch: 998 [22528/54000 (42%)] Loss: -762.360840\n",
      "Train Epoch: 998 [33792/54000 (63%)] Loss: -727.973511\n",
      "Train Epoch: 998 [45056/54000 (83%)] Loss: -753.290894\n",
      "    epoch          : 998\n",
      "    loss           : -753.8853022737323\n",
      "    ess            : 1.9602540146629766\n",
      "    log_marginal   : 753.9197410727447\n",
      "    log_joint      : 962.423395696676\n",
      "    val_loss       : -757.8512929280599\n",
      "    val_ess        : 1.963432490825653\n",
      "    val_log_marginal: 757.8849182128906\n",
      "    val_log_joint  : 966.339609781901\n",
      "Train Epoch: 999 [0/54000 (0%)] Loss: -733.828918\n",
      "Train Epoch: 999 [11264/54000 (21%)] Loss: -770.914734\n",
      "Train Epoch: 999 [22528/54000 (42%)] Loss: -769.806885\n",
      "Train Epoch: 999 [33792/54000 (63%)] Loss: -779.594482\n",
      "Train Epoch: 999 [45056/54000 (83%)] Loss: -760.513367\n",
      "    epoch          : 999\n",
      "    loss           : -753.7413364626327\n",
      "    ess            : 1.959514392996734\n",
      "    log_marginal   : 753.778368104179\n",
      "    log_joint      : 962.3313362553434\n",
      "    val_loss       : -758.1116638183594\n",
      "    val_ess        : 1.9646086196104686\n",
      "    val_log_marginal: 758.1387583414713\n",
      "    val_log_joint  : 966.4889424641927\n",
      "Train Epoch: 1000 [0/54000 (0%)] Loss: -731.871826\n",
      "Train Epoch: 1000 [11264/54000 (21%)] Loss: -746.156311\n",
      "Train Epoch: 1000 [22528/54000 (42%)] Loss: -743.086670\n",
      "Train Epoch: 1000 [33792/54000 (63%)] Loss: -746.747559\n",
      "Train Epoch: 1000 [45056/54000 (83%)] Loss: -758.214844\n",
      "    epoch          : 1000\n",
      "    loss           : -753.8755867436247\n",
      "    ess            : 1.9592098706173446\n",
      "    log_marginal   : 753.9121162846403\n",
      "    log_joint      : 962.5778779803582\n",
      "    val_loss       : -758.30419921875\n",
      "    val_ess        : 1.9584315518538158\n",
      "    val_log_marginal: 758.3408762613932\n",
      "    val_log_joint  : 966.5955861409506\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1000.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1001 [0/54000 (0%)] Loss: -750.581177\n",
      "Train Epoch: 1001 [11264/54000 (21%)] Loss: -754.639648\n",
      "Train Epoch: 1001 [22528/54000 (42%)] Loss: -791.902954\n",
      "Train Epoch: 1001 [33792/54000 (63%)] Loss: -730.543701\n",
      "Train Epoch: 1001 [45056/54000 (83%)] Loss: -767.029358\n",
      "    epoch          : 1001\n",
      "    loss           : -754.0590941231205\n",
      "    ess            : 1.9601093924270485\n",
      "    log_marginal   : 754.0943298339844\n",
      "    log_joint      : 962.6023444409641\n",
      "    val_loss       : -757.9028523763021\n",
      "    val_ess        : 1.9635304709275563\n",
      "    val_log_marginal: 757.9386545817057\n",
      "    val_log_joint  : 966.4020029703776\n",
      "Train Epoch: 1002 [0/54000 (0%)] Loss: -740.940918\n",
      "Train Epoch: 1002 [11264/54000 (21%)] Loss: -766.175293\n",
      "Train Epoch: 1002 [22528/54000 (42%)] Loss: -765.368164\n",
      "Train Epoch: 1002 [33792/54000 (63%)] Loss: -758.976318\n",
      "Train Epoch: 1002 [45056/54000 (83%)] Loss: -747.054749\n",
      "    epoch          : 1002\n",
      "    loss           : -754.0390521355395\n",
      "    ess            : 1.9605756334538729\n",
      "    log_marginal   : 754.0752373461453\n",
      "    log_joint      : 962.5481440706073\n",
      "    val_loss       : -757.2714792887369\n",
      "    val_ess        : 1.9614324072996776\n",
      "    val_log_marginal: 757.3052520751953\n",
      "    val_log_joint  : 965.5987955729166\n",
      "Train Epoch: 1003 [0/54000 (0%)] Loss: -745.742554\n",
      "Train Epoch: 1003 [11264/54000 (21%)] Loss: -750.380981\n",
      "Train Epoch: 1003 [22528/54000 (42%)] Loss: -775.477234\n",
      "Train Epoch: 1003 [33792/54000 (63%)] Loss: -757.129456\n",
      "Train Epoch: 1003 [45056/54000 (83%)] Loss: -748.557495\n",
      "    epoch          : 1003\n",
      "    loss           : -754.3750529739092\n",
      "    ess            : 1.9594744713801258\n",
      "    log_marginal   : 754.4125723209021\n",
      "    log_joint      : 962.9164445985039\n",
      "    val_loss       : -757.6501515706381\n",
      "    val_ess        : 1.9570511678854625\n",
      "    val_log_marginal: 757.6875254313151\n",
      "    val_log_joint  : 966.4765625\n",
      "Train Epoch: 1004 [0/54000 (0%)] Loss: -719.867004\n",
      "Train Epoch: 1004 [11264/54000 (21%)] Loss: -724.902466\n",
      "Train Epoch: 1004 [22528/54000 (42%)] Loss: -756.511475\n",
      "Train Epoch: 1004 [33792/54000 (63%)] Loss: -760.350952\n",
      "Train Epoch: 1004 [45056/54000 (83%)] Loss: -749.042969\n",
      "    epoch          : 1004\n",
      "    loss           : -754.442012570939\n",
      "    ess            : 1.9596258098224424\n",
      "    log_marginal   : 754.4780002809921\n",
      "    log_joint      : 962.8717760769827\n",
      "    val_loss       : -758.2637125651041\n",
      "    val_ess        : 1.962855448325475\n",
      "    val_log_marginal: 758.2970479329427\n",
      "    val_log_joint  : 966.7778065999349\n",
      "Train Epoch: 1005 [0/54000 (0%)] Loss: -745.373352\n",
      "Train Epoch: 1005 [11264/54000 (21%)] Loss: -752.631592\n",
      "Train Epoch: 1005 [22528/54000 (42%)] Loss: -759.506226\n",
      "Train Epoch: 1005 [33792/54000 (63%)] Loss: -752.393005\n",
      "Train Epoch: 1005 [45056/54000 (83%)] Loss: -774.630127\n",
      "    epoch          : 1005\n",
      "    loss           : -754.2519537008034\n",
      "    ess            : 1.9581773303589731\n",
      "    log_marginal   : 754.2902025906545\n",
      "    log_joint      : 962.8630088950104\n",
      "    val_loss       : -758.5860087076823\n",
      "    val_ess        : 1.9645572304725647\n",
      "    val_log_marginal: 758.6167907714844\n",
      "    val_log_joint  : 966.9366760253906\n",
      "Train Epoch: 1006 [0/54000 (0%)] Loss: -748.429932\n",
      "Train Epoch: 1006 [11264/54000 (21%)] Loss: -761.192871\n",
      "Train Epoch: 1006 [22528/54000 (42%)] Loss: -776.457031\n",
      "Train Epoch: 1006 [33792/54000 (63%)] Loss: -768.001160\n",
      "Train Epoch: 1006 [45056/54000 (83%)] Loss: -757.949951\n",
      "    epoch          : 1006\n",
      "    loss           : -754.4851465765036\n",
      "    ess            : 1.9592851670283191\n",
      "    log_marginal   : 754.5222340709759\n",
      "    log_joint      : 962.972803079857\n",
      "    val_loss       : -758.8140920003256\n",
      "    val_ess        : 1.961287945508957\n",
      "    val_log_marginal: 758.8508961995443\n",
      "    val_log_joint  : 967.5107930501302\n",
      "Train Epoch: 1007 [0/54000 (0%)] Loss: -754.343384\n",
      "Train Epoch: 1007 [11264/54000 (21%)] Loss: -777.652954\n",
      "Train Epoch: 1007 [22528/54000 (42%)] Loss: -752.102295\n",
      "Train Epoch: 1007 [33792/54000 (63%)] Loss: -738.399658\n",
      "Train Epoch: 1007 [45056/54000 (83%)] Loss: -764.559998\n",
      "    epoch          : 1007\n",
      "    loss           : -754.4259447781545\n",
      "    ess            : 1.9603367020499032\n",
      "    log_marginal   : 754.463567193949\n",
      "    log_joint      : 963.0603539808741\n",
      "    val_loss       : -758.3630218505859\n",
      "    val_ess        : 1.9589435656865437\n",
      "    val_log_marginal: 758.4050343831381\n",
      "    val_log_joint  : 966.9218546549479\n",
      "Train Epoch: 1008 [0/54000 (0%)] Loss: -762.297974\n",
      "Train Epoch: 1008 [11264/54000 (21%)] Loss: -749.054443\n",
      "Train Epoch: 1008 [22528/54000 (42%)] Loss: -759.567261\n",
      "Train Epoch: 1008 [33792/54000 (63%)] Loss: -747.626892\n",
      "Train Epoch: 1008 [45056/54000 (83%)] Loss: -756.244507\n",
      "    epoch          : 1008\n",
      "    loss           : -754.6386649653597\n",
      "    ess            : 1.959509956386854\n",
      "    log_marginal   : 754.6754754984154\n",
      "    log_joint      : 963.1468154619325\n",
      "    val_loss       : -758.9716644287109\n",
      "    val_ess        : 1.9610640307267506\n",
      "    val_log_marginal: 759.006337483724\n",
      "    val_log_joint  : 967.6438903808594\n",
      "Train Epoch: 1009 [0/54000 (0%)] Loss: -734.473022\n",
      "Train Epoch: 1009 [11264/54000 (21%)] Loss: -735.317505\n",
      "Train Epoch: 1009 [22528/54000 (42%)] Loss: -776.951782\n",
      "Train Epoch: 1009 [33792/54000 (63%)] Loss: -765.887390\n",
      "Train Epoch: 1009 [45056/54000 (83%)] Loss: -747.630615\n",
      "    epoch          : 1009\n",
      "    loss           : -754.6631452452461\n",
      "    ess            : 1.9594927711306878\n",
      "    log_marginal   : 754.6987385299971\n",
      "    log_joint      : 963.2468659023069\n",
      "    val_loss       : -759.0626424153646\n",
      "    val_ess        : 1.9611307978630066\n",
      "    val_log_marginal: 759.0982309977213\n",
      "    val_log_joint  : 967.6424763997396\n",
      "Train Epoch: 1010 [0/54000 (0%)] Loss: -750.873108\n",
      "Train Epoch: 1010 [11264/54000 (21%)] Loss: -755.128052\n",
      "Train Epoch: 1010 [22528/54000 (42%)] Loss: -751.731934\n",
      "Train Epoch: 1010 [33792/54000 (63%)] Loss: -748.951904\n",
      "Train Epoch: 1010 [45056/54000 (83%)] Loss: -760.177124\n",
      "    epoch          : 1010\n",
      "    loss           : -754.9627771917379\n",
      "    ess            : 1.9596224460961684\n",
      "    log_marginal   : 754.9989007913841\n",
      "    log_joint      : 963.3909416918484\n",
      "    val_loss       : -759.0503845214844\n",
      "    val_ess        : 1.9606234431266785\n",
      "    val_log_marginal: 759.0875295003256\n",
      "    val_log_joint  : 967.3997904459635\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1010.pth ...\n",
      "Train Epoch: 1011 [0/54000 (0%)] Loss: -749.213623\n",
      "Train Epoch: 1011 [11264/54000 (21%)] Loss: -762.592285\n",
      "Train Epoch: 1011 [22528/54000 (42%)] Loss: -761.794922\n",
      "Train Epoch: 1011 [33792/54000 (63%)] Loss: -749.545166\n",
      "Train Epoch: 1011 [45056/54000 (83%)] Loss: -771.869751\n",
      "    epoch          : 1011\n",
      "    loss           : -754.6949768066406\n",
      "    ess            : 1.9600816346564383\n",
      "    log_marginal   : 754.7312057783018\n",
      "    log_joint      : 963.2782339419958\n",
      "    val_loss       : -758.4977518717448\n",
      "    val_ess        : 1.9570350746313732\n",
      "    val_log_marginal: 758.5350036621094\n",
      "    val_log_joint  : 967.2157389322916\n",
      "Train Epoch: 1012 [0/54000 (0%)] Loss: -759.978699\n",
      "Train Epoch: 1012 [11264/54000 (21%)] Loss: -723.203918\n",
      "Train Epoch: 1012 [22528/54000 (42%)] Loss: -748.940918\n",
      "Train Epoch: 1012 [33792/54000 (63%)] Loss: -749.976746\n",
      "Train Epoch: 1012 [45056/54000 (83%)] Loss: -750.392700\n",
      "    epoch          : 1012\n",
      "    loss           : -754.7725720675486\n",
      "    ess            : 1.9604772138145734\n",
      "    log_marginal   : 754.8082200536188\n",
      "    log_joint      : 963.3629225245062\n",
      "    val_loss       : -758.7667694091797\n",
      "    val_ess        : 1.9648386140664418\n",
      "    val_log_marginal: 758.7979024251302\n",
      "    val_log_joint  : 967.3528188069662\n",
      "Train Epoch: 1013 [0/54000 (0%)] Loss: -765.359192\n",
      "Train Epoch: 1013 [11264/54000 (21%)] Loss: -759.411011\n",
      "Train Epoch: 1013 [22528/54000 (42%)] Loss: -733.958008\n",
      "Train Epoch: 1013 [33792/54000 (63%)] Loss: -769.510254\n",
      "Train Epoch: 1013 [45056/54000 (83%)] Loss: -751.707520\n",
      "    epoch          : 1013\n",
      "    loss           : -754.9248259922243\n",
      "    ess            : 1.9605596582844573\n",
      "    log_marginal   : 754.9601837734007\n",
      "    log_joint      : 963.4889532125221\n",
      "    val_loss       : -758.7252248128256\n",
      "    val_ess        : 1.9593946039676666\n",
      "    val_log_marginal: 758.7606099446615\n",
      "    val_log_joint  : 967.4722340901693\n",
      "Train Epoch: 1014 [0/54000 (0%)] Loss: -755.749146\n",
      "Train Epoch: 1014 [11264/54000 (21%)] Loss: -748.784485\n",
      "Train Epoch: 1014 [22528/54000 (42%)] Loss: -756.824463\n",
      "Train Epoch: 1014 [33792/54000 (63%)] Loss: -746.976013\n",
      "Train Epoch: 1014 [45056/54000 (83%)] Loss: -743.534424\n",
      "    epoch          : 1014\n",
      "    loss           : -754.9002029131044\n",
      "    ess            : 1.9606192854215514\n",
      "    log_marginal   : 754.9361485895121\n",
      "    log_joint      : 963.4789088986954\n",
      "    val_loss       : -759.1342264811198\n",
      "    val_ess        : 1.9588126639525096\n",
      "    val_log_marginal: 759.1721852620443\n",
      "    val_log_joint  : 967.410654703776\n",
      "Train Epoch: 1015 [0/54000 (0%)] Loss: -751.062317\n",
      "Train Epoch: 1015 [11264/54000 (21%)] Loss: -764.401489\n",
      "Train Epoch: 1015 [22528/54000 (42%)] Loss: -737.933960\n",
      "Train Epoch: 1015 [33792/54000 (63%)] Loss: -742.634766\n",
      "Train Epoch: 1015 [45056/54000 (83%)] Loss: -762.887817\n",
      "    epoch          : 1015\n",
      "    loss           : -755.1396328908093\n",
      "    ess            : 1.9593243846353494\n",
      "    log_marginal   : 755.1763294147995\n",
      "    log_joint      : 963.750572924344\n",
      "    val_loss       : -759.2962900797526\n",
      "    val_ess        : 1.9579868912696838\n",
      "    val_log_marginal: 759.3354797363281\n",
      "    val_log_joint  : 967.6388193766276\n",
      "Train Epoch: 1016 [0/54000 (0%)] Loss: -767.827759\n",
      "Train Epoch: 1016 [11264/54000 (21%)] Loss: -753.487427\n",
      "Train Epoch: 1016 [22528/54000 (42%)] Loss: -764.643066\n",
      "Train Epoch: 1016 [33792/54000 (63%)] Loss: -779.940063\n",
      "Train Epoch: 1016 [45056/54000 (83%)] Loss: -736.962952\n",
      "    epoch          : 1016\n",
      "    loss           : -755.1918663168854\n",
      "    ess            : 1.9598383734811027\n",
      "    log_marginal   : 755.2281367463886\n",
      "    log_joint      : 963.7020758862766\n",
      "    val_loss       : -759.2375946044922\n",
      "    val_ess        : 1.9623901943365734\n",
      "    val_log_marginal: 759.2712097167969\n",
      "    val_log_joint  : 967.7044169108073\n",
      "Train Epoch: 1017 [0/54000 (0%)] Loss: -743.271851\n",
      "Train Epoch: 1017 [11264/54000 (21%)] Loss: -775.411560\n",
      "Train Epoch: 1017 [22528/54000 (42%)] Loss: -738.844849\n",
      "Train Epoch: 1017 [33792/54000 (63%)] Loss: -760.069824\n",
      "Train Epoch: 1017 [45056/54000 (83%)] Loss: -749.788208\n",
      "    epoch          : 1017\n",
      "    loss           : -755.0551544765257\n",
      "    ess            : 1.9605739915146019\n",
      "    log_marginal   : 755.0902433575325\n",
      "    log_joint      : 963.5568600060805\n",
      "    val_loss       : -759.1972605387369\n",
      "    val_ess        : 1.9583260118961334\n",
      "    val_log_marginal: 759.236094156901\n",
      "    val_log_joint  : 967.5992024739584\n",
      "Train Epoch: 1018 [0/54000 (0%)] Loss: -745.279236\n",
      "Train Epoch: 1018 [11264/54000 (21%)] Loss: -758.414429\n",
      "Train Epoch: 1018 [22528/54000 (42%)] Loss: -761.242676\n",
      "Train Epoch: 1018 [33792/54000 (63%)] Loss: -760.213135\n",
      "Train Epoch: 1018 [45056/54000 (83%)] Loss: -769.079834\n",
      "    epoch          : 1018\n",
      "    loss           : -755.1393737792969\n",
      "    ess            : 1.9591423891625315\n",
      "    log_marginal   : 755.1762960182047\n",
      "    log_joint      : 963.6668447818396\n",
      "    val_loss       : -758.9895477294922\n",
      "    val_ess        : 1.96106418967247\n",
      "    val_log_marginal: 759.0249277750651\n",
      "    val_log_joint  : 967.5706532796224\n",
      "Train Epoch: 1019 [0/54000 (0%)] Loss: -741.533813\n",
      "Train Epoch: 1019 [11264/54000 (21%)] Loss: -737.650208\n",
      "Train Epoch: 1019 [22528/54000 (42%)] Loss: -749.137939\n",
      "Train Epoch: 1019 [33792/54000 (63%)] Loss: -775.063293\n",
      "Train Epoch: 1019 [45056/54000 (83%)] Loss: -777.008972\n",
      "    epoch          : 1019\n",
      "    loss           : -755.1293691959021\n",
      "    ess            : 1.959718938143748\n",
      "    log_marginal   : 755.1656171690743\n",
      "    log_joint      : 963.6493150243219\n",
      "    val_loss       : -759.2371419270834\n",
      "    val_ess        : 1.9601731896400452\n",
      "    val_log_marginal: 759.2743428548177\n",
      "    val_log_joint  : 967.6713460286459\n",
      "Train Epoch: 1020 [0/54000 (0%)] Loss: -735.531494\n",
      "Train Epoch: 1020 [11264/54000 (21%)] Loss: -766.171265\n",
      "Train Epoch: 1020 [22528/54000 (42%)] Loss: -762.744568\n",
      "Train Epoch: 1020 [33792/54000 (63%)] Loss: -746.925171\n",
      "Train Epoch: 1020 [45056/54000 (83%)] Loss: -750.979492\n",
      "    epoch          : 1020\n",
      "    loss           : -755.0819103312942\n",
      "    ess            : 1.958852599251945\n",
      "    log_marginal   : 755.1193133660082\n",
      "    log_joint      : 963.7266402334537\n",
      "    val_loss       : -759.1018778483073\n",
      "    val_ess        : 1.9576359391212463\n",
      "    val_log_marginal: 759.1454874674479\n",
      "    val_log_joint  : 967.8945922851562\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1020.pth ...\n",
      "Train Epoch: 1021 [0/54000 (0%)] Loss: -763.057556\n",
      "Train Epoch: 1021 [11264/54000 (21%)] Loss: -742.459595\n",
      "Train Epoch: 1021 [22528/54000 (42%)] Loss: -757.774536\n",
      "Train Epoch: 1021 [33792/54000 (63%)] Loss: -730.304504\n",
      "Train Epoch: 1021 [45056/54000 (83%)] Loss: -756.140442\n",
      "    epoch          : 1021\n",
      "    loss           : -755.4009169092718\n",
      "    ess            : 1.959564116765868\n",
      "    log_marginal   : 755.4377510502653\n",
      "    log_joint      : 963.869496471477\n",
      "    val_loss       : -759.8998972574869\n",
      "    val_ess        : 1.9628138740857441\n",
      "    val_log_marginal: 759.9363861083984\n",
      "    val_log_joint  : 968.4578552246094\n",
      "Train Epoch: 1022 [0/54000 (0%)] Loss: -741.326843\n",
      "Train Epoch: 1022 [11264/54000 (21%)] Loss: -739.823242\n",
      "Train Epoch: 1022 [22528/54000 (42%)] Loss: -774.387085\n",
      "Train Epoch: 1022 [33792/54000 (63%)] Loss: -748.354126\n",
      "Train Epoch: 1022 [45056/54000 (83%)] Loss: -772.223755\n",
      "    epoch          : 1022\n",
      "    loss           : -755.396722181788\n",
      "    ess            : 1.9601904243793127\n",
      "    log_marginal   : 755.433225235849\n",
      "    log_joint      : 963.8869087651091\n",
      "    val_loss       : -759.0200246175131\n",
      "    val_ess        : 1.9583767652511597\n",
      "    val_log_marginal: 759.0568796793619\n",
      "    val_log_joint  : 967.4236958821615\n",
      "Train Epoch: 1023 [0/54000 (0%)] Loss: -761.362183\n",
      "Train Epoch: 1023 [11264/54000 (21%)] Loss: -760.518860\n",
      "Train Epoch: 1023 [22528/54000 (42%)] Loss: -778.652222\n",
      "Train Epoch: 1023 [33792/54000 (63%)] Loss: -758.144897\n",
      "Train Epoch: 1023 [45056/54000 (83%)] Loss: -761.720032\n",
      "    epoch          : 1023\n",
      "    loss           : -755.2857850272701\n",
      "    ess            : 1.9587871218627353\n",
      "    log_marginal   : 755.3245504127359\n",
      "    log_joint      : 963.889104303324\n",
      "    val_loss       : -759.6063130696615\n",
      "    val_ess        : 1.9621306657791138\n",
      "    val_log_marginal: 759.6373850504557\n",
      "    val_log_joint  : 968.18701171875\n",
      "Train Epoch: 1024 [0/54000 (0%)] Loss: -742.826050\n",
      "Train Epoch: 1024 [11264/54000 (21%)] Loss: -783.020996\n",
      "Train Epoch: 1024 [22528/54000 (42%)] Loss: -757.117615\n",
      "Train Epoch: 1024 [33792/54000 (63%)] Loss: -757.996460\n",
      "Train Epoch: 1024 [45056/54000 (83%)] Loss: -786.383789\n",
      "    epoch          : 1024\n",
      "    loss           : -755.3531995089548\n",
      "    ess            : 1.9609529252322215\n",
      "    log_marginal   : 755.3897238677403\n",
      "    log_joint      : 963.8700601829672\n",
      "    val_loss       : -759.9857330322266\n",
      "    val_ess        : 1.9602771004041035\n",
      "    val_log_marginal: 760.0248413085938\n",
      "    val_log_joint  : 968.4780120849609\n",
      "Train Epoch: 1025 [0/54000 (0%)] Loss: -719.110718\n",
      "Train Epoch: 1025 [11264/54000 (21%)] Loss: -767.363403\n",
      "Train Epoch: 1025 [22528/54000 (42%)] Loss: -743.719055\n",
      "Train Epoch: 1025 [33792/54000 (63%)] Loss: -763.078735\n",
      "Train Epoch: 1025 [45056/54000 (83%)] Loss: -773.935425\n",
      "    epoch          : 1025\n",
      "    loss           : -755.673153283461\n",
      "    ess            : 1.9611614717627472\n",
      "    log_marginal   : 755.7080947588075\n",
      "    log_joint      : 964.0253393785009\n",
      "    val_loss       : -759.9947001139323\n",
      "    val_ess        : 1.961783806482951\n",
      "    val_log_marginal: 760.0302683512369\n",
      "    val_log_joint  : 968.5933939615885\n",
      "Train Epoch: 1026 [0/54000 (0%)] Loss: -756.562744\n",
      "Train Epoch: 1026 [11264/54000 (21%)] Loss: -759.218323\n",
      "Train Epoch: 1026 [22528/54000 (42%)] Loss: -760.703003\n",
      "Train Epoch: 1026 [33792/54000 (63%)] Loss: -751.059692\n",
      "Train Epoch: 1026 [45056/54000 (83%)] Loss: -789.391052\n",
      "    epoch          : 1026\n",
      "    loss           : -755.5772054420328\n",
      "    ess            : 1.9595628144606105\n",
      "    log_marginal   : 755.6150247825766\n",
      "    log_joint      : 964.1321347794443\n",
      "    val_loss       : -760.2015533447266\n",
      "    val_ess        : 1.9634055197238922\n",
      "    val_log_marginal: 760.2349955240885\n",
      "    val_log_joint  : 968.6702219645182\n",
      "Train Epoch: 1027 [0/54000 (0%)] Loss: -770.383545\n",
      "Train Epoch: 1027 [11264/54000 (21%)] Loss: -752.235718\n",
      "Train Epoch: 1027 [22528/54000 (42%)] Loss: -750.266235\n",
      "Train Epoch: 1027 [33792/54000 (63%)] Loss: -760.380005\n",
      "Train Epoch: 1027 [45056/54000 (83%)] Loss: -735.967651\n",
      "    epoch          : 1027\n",
      "    loss           : -755.7765888717939\n",
      "    ess            : 1.959156575067988\n",
      "    log_marginal   : 755.8139395084021\n",
      "    log_joint      : 964.2767403080778\n",
      "    val_loss       : -759.8798065185547\n",
      "    val_ess        : 1.9616148173809052\n",
      "    val_log_marginal: 759.9147389729818\n",
      "    val_log_joint  : 968.2970631917318\n",
      "Train Epoch: 1028 [0/54000 (0%)] Loss: -768.846375\n",
      "Train Epoch: 1028 [11264/54000 (21%)] Loss: -772.781494\n",
      "Train Epoch: 1028 [22528/54000 (42%)] Loss: -750.149597\n",
      "Train Epoch: 1028 [33792/54000 (63%)] Loss: -754.312805\n",
      "Train Epoch: 1028 [45056/54000 (83%)] Loss: -750.853149\n",
      "    epoch          : 1028\n",
      "    loss           : -755.9658588913252\n",
      "    ess            : 1.9601991379036094\n",
      "    log_marginal   : 756.0018471771816\n",
      "    log_joint      : 964.4372230385834\n",
      "    val_loss       : -759.8656056722006\n",
      "    val_ess        : 1.9605888426303864\n",
      "    val_log_marginal: 759.8958638509115\n",
      "    val_log_joint  : 968.3783111572266\n",
      "Train Epoch: 1029 [0/54000 (0%)] Loss: -755.430115\n",
      "Train Epoch: 1029 [11264/54000 (21%)] Loss: -768.104614\n",
      "Train Epoch: 1029 [22528/54000 (42%)] Loss: -732.463379\n",
      "Train Epoch: 1029 [33792/54000 (63%)] Loss: -748.059082\n",
      "Train Epoch: 1029 [45056/54000 (83%)] Loss: -762.676880\n",
      "    epoch          : 1029\n",
      "    loss           : -755.795975019347\n",
      "    ess            : 1.9597884686488025\n",
      "    log_marginal   : 755.8310518084832\n",
      "    log_joint      : 964.2523993726047\n",
      "    val_loss       : -760.7894541422526\n",
      "    val_ess        : 1.959250807762146\n",
      "    val_log_marginal: 760.8272196451823\n",
      "    val_log_joint  : 969.3775278727213\n",
      "Train Epoch: 1030 [0/54000 (0%)] Loss: -750.355957\n",
      "Train Epoch: 1030 [11264/54000 (21%)] Loss: -741.329773\n",
      "Train Epoch: 1030 [22528/54000 (42%)] Loss: -750.795715\n",
      "Train Epoch: 1030 [33792/54000 (63%)] Loss: -779.743896\n",
      "Train Epoch: 1030 [45056/54000 (83%)] Loss: -752.510132\n",
      "    epoch          : 1030\n",
      "    loss           : -756.0376915121979\n",
      "    ess            : 1.9590857501299876\n",
      "    log_marginal   : 756.0747438826651\n",
      "    log_joint      : 964.5652010935657\n",
      "    val_loss       : -759.4874776204427\n",
      "    val_ess        : 1.9604025185108185\n",
      "    val_log_marginal: 759.5254567464193\n",
      "    val_log_joint  : 968.1289520263672\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1030.pth ...\n",
      "Train Epoch: 1031 [0/54000 (0%)] Loss: -771.373657\n",
      "Train Epoch: 1031 [11264/54000 (21%)] Loss: -765.128174\n",
      "Train Epoch: 1031 [22528/54000 (42%)] Loss: -768.535400\n",
      "Train Epoch: 1031 [33792/54000 (63%)] Loss: -741.543152\n",
      "Train Epoch: 1031 [45056/54000 (83%)] Loss: -739.019531\n",
      "    epoch          : 1031\n",
      "    loss           : -756.0328426720961\n",
      "    ess            : 1.9595043895379551\n",
      "    log_marginal   : 756.0704247816553\n",
      "    log_joint      : 964.5944582381338\n",
      "    val_loss       : -760.2306976318359\n",
      "    val_ess        : 1.959050844113032\n",
      "    val_log_marginal: 760.2682240804037\n",
      "    val_log_joint  : 968.6047007242838\n",
      "Train Epoch: 1032 [0/54000 (0%)] Loss: -750.630737\n",
      "Train Epoch: 1032 [11264/54000 (21%)] Loss: -745.662109\n",
      "Train Epoch: 1032 [22528/54000 (42%)] Loss: -743.209473\n",
      "Train Epoch: 1032 [33792/54000 (63%)] Loss: -723.786621\n",
      "Train Epoch: 1032 [45056/54000 (83%)] Loss: -759.175781\n",
      "    epoch          : 1032\n",
      "    loss           : -755.8752418374115\n",
      "    ess            : 1.9598446454641953\n",
      "    log_marginal   : 755.9116734918558\n",
      "    log_joint      : 964.410191374005\n",
      "    val_loss       : -760.40234375\n",
      "    val_ess        : 1.9613693157831829\n",
      "    val_log_marginal: 760.4345499674479\n",
      "    val_log_joint  : 968.9803873697916\n",
      "Train Epoch: 1033 [0/54000 (0%)] Loss: -746.583862\n",
      "Train Epoch: 1033 [11264/54000 (21%)] Loss: -778.751465\n",
      "Train Epoch: 1033 [22528/54000 (42%)] Loss: -757.388550\n",
      "Train Epoch: 1033 [33792/54000 (63%)] Loss: -749.525635\n",
      "Train Epoch: 1033 [45056/54000 (83%)] Loss: -737.470703\n",
      "    epoch          : 1033\n",
      "    loss           : -755.9566293392542\n",
      "    ess            : 1.959734709757679\n",
      "    log_marginal   : 755.9940012805866\n",
      "    log_joint      : 964.5114521530439\n",
      "    val_loss       : -759.8203582763672\n",
      "    val_ess        : 1.961359182993571\n",
      "    val_log_marginal: 759.8535207112631\n",
      "    val_log_joint  : 968.6420542399088\n",
      "Train Epoch: 1034 [0/54000 (0%)] Loss: -758.903442\n",
      "Train Epoch: 1034 [11264/54000 (21%)] Loss: -754.616821\n",
      "Train Epoch: 1034 [22528/54000 (42%)] Loss: -766.804749\n",
      "Train Epoch: 1034 [33792/54000 (63%)] Loss: -754.823730\n",
      "Train Epoch: 1034 [45056/54000 (83%)] Loss: -738.475403\n",
      "    epoch          : 1034\n",
      "    loss           : -756.2103340580778\n",
      "    ess            : 1.9611625772602153\n",
      "    log_marginal   : 756.2453653587485\n",
      "    log_joint      : 964.7729313688458\n",
      "    val_loss       : -760.1616770426432\n",
      "    val_ess        : 1.9607936541239421\n",
      "    val_log_marginal: 760.1942952473959\n",
      "    val_log_joint  : 968.5144653320312\n",
      "Train Epoch: 1035 [0/54000 (0%)] Loss: -748.327881\n",
      "Train Epoch: 1035 [11264/54000 (21%)] Loss: -760.351379\n",
      "Train Epoch: 1035 [22528/54000 (42%)] Loss: -759.283813\n",
      "Train Epoch: 1035 [33792/54000 (63%)] Loss: -763.754517\n",
      "Train Epoch: 1035 [45056/54000 (83%)] Loss: -765.197754\n",
      "    epoch          : 1035\n",
      "    loss           : -756.2495330234743\n",
      "    ess            : 1.9602050646296088\n",
      "    log_marginal   : 756.2851735241009\n",
      "    log_joint      : 964.7372350152933\n",
      "    val_loss       : -760.4862670898438\n",
      "    val_ess        : 1.962110976378123\n",
      "    val_log_marginal: 760.5222117106119\n",
      "    val_log_joint  : 968.6841888427734\n",
      "Train Epoch: 1036 [0/54000 (0%)] Loss: -774.614258\n",
      "Train Epoch: 1036 [11264/54000 (21%)] Loss: -751.468079\n",
      "Train Epoch: 1036 [22528/54000 (42%)] Loss: -745.838745\n",
      "Train Epoch: 1036 [33792/54000 (63%)] Loss: -755.417725\n",
      "Train Epoch: 1036 [45056/54000 (83%)] Loss: -778.526123\n",
      "    epoch          : 1036\n",
      "    loss           : -756.2127259452388\n",
      "    ess            : 1.9612543504193145\n",
      "    log_marginal   : 756.2474042784493\n",
      "    log_joint      : 964.7017897120062\n",
      "    val_loss       : -760.6487375895182\n",
      "    val_ess        : 1.961709052324295\n",
      "    val_log_marginal: 760.6893717447916\n",
      "    val_log_joint  : 969.3079986572266\n",
      "Train Epoch: 1037 [0/54000 (0%)] Loss: -750.643555\n",
      "Train Epoch: 1037 [11264/54000 (21%)] Loss: -765.085327\n",
      "Train Epoch: 1037 [22528/54000 (42%)] Loss: -738.335083\n",
      "Train Epoch: 1037 [33792/54000 (63%)] Loss: -743.996338\n",
      "Train Epoch: 1037 [45056/54000 (83%)] Loss: -761.652588\n",
      "    epoch          : 1037\n",
      "    loss           : -756.2657793153007\n",
      "    ess            : 1.9597781311790898\n",
      "    log_marginal   : 756.3019150068175\n",
      "    log_joint      : 964.7700725051592\n",
      "    val_loss       : -760.6650034586588\n",
      "    val_ess        : 1.9603039820988972\n",
      "    val_log_marginal: 760.6983032226562\n",
      "    val_log_joint  : 969.2552235921224\n",
      "Train Epoch: 1038 [0/54000 (0%)] Loss: -777.648438\n",
      "Train Epoch: 1038 [11264/54000 (21%)] Loss: -761.921631\n",
      "Train Epoch: 1038 [22528/54000 (42%)] Loss: -741.853943\n",
      "Train Epoch: 1038 [33792/54000 (63%)] Loss: -759.203308\n",
      "Train Epoch: 1038 [45056/54000 (83%)] Loss: -737.033386\n",
      "    epoch          : 1038\n",
      "    loss           : -756.3381485849056\n",
      "    ess            : 1.9610353157205402\n",
      "    log_marginal   : 756.3737568405439\n",
      "    log_joint      : 964.8760462347067\n",
      "    val_loss       : -761.0405222574869\n",
      "    val_ess        : 1.9618718723456066\n",
      "    val_log_marginal: 761.074717203776\n",
      "    val_log_joint  : 969.6133931477865\n",
      "Train Epoch: 1039 [0/54000 (0%)] Loss: -758.381470\n",
      "Train Epoch: 1039 [11264/54000 (21%)] Loss: -769.880066\n",
      "Train Epoch: 1039 [22528/54000 (42%)] Loss: -749.305054\n",
      "Train Epoch: 1039 [33792/54000 (63%)] Loss: -757.954285\n",
      "Train Epoch: 1039 [45056/54000 (83%)] Loss: -759.269653\n",
      "    epoch          : 1039\n",
      "    loss           : -756.483775012898\n",
      "    ess            : 1.958889420302409\n",
      "    log_marginal   : 756.5215310150722\n",
      "    log_joint      : 964.9432027564859\n",
      "    val_loss       : -760.3083445231119\n",
      "    val_ess        : 1.9609669347604115\n",
      "    val_log_marginal: 760.3450876871744\n",
      "    val_log_joint  : 968.9185892740885\n",
      "Train Epoch: 1040 [0/54000 (0%)] Loss: -774.813965\n",
      "Train Epoch: 1040 [11264/54000 (21%)] Loss: -770.912231\n",
      "Train Epoch: 1040 [22528/54000 (42%)] Loss: -749.150085\n",
      "Train Epoch: 1040 [33792/54000 (63%)] Loss: -772.075317\n",
      "Train Epoch: 1040 [45056/54000 (83%)] Loss: -749.808472\n",
      "    epoch          : 1040\n",
      "    loss           : -756.4289308943838\n",
      "    ess            : 1.960083026930971\n",
      "    log_marginal   : 756.4644821454893\n",
      "    log_joint      : 964.9133767181972\n",
      "    val_loss       : -759.7098795572916\n",
      "    val_ess        : 1.9603631397088368\n",
      "    val_log_marginal: 759.7486521402994\n",
      "    val_log_joint  : 968.3182983398438\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1040.pth ...\n",
      "Train Epoch: 1041 [0/54000 (0%)] Loss: -761.219238\n",
      "Train Epoch: 1041 [11264/54000 (21%)] Loss: -764.043213\n",
      "Train Epoch: 1041 [22528/54000 (42%)] Loss: -746.727539\n",
      "Train Epoch: 1041 [33792/54000 (63%)] Loss: -748.551758\n",
      "Train Epoch: 1041 [45056/54000 (83%)] Loss: -755.053650\n",
      "    epoch          : 1041\n",
      "    loss           : -756.5762392439932\n",
      "    ess            : 1.9599392076708235\n",
      "    log_marginal   : 756.6122672602816\n",
      "    log_joint      : 965.0097063172539\n",
      "    val_loss       : -761.0033721923828\n",
      "    val_ess        : 1.9601174394289653\n",
      "    val_log_marginal: 761.0397440592448\n",
      "    val_log_joint  : 969.5630900065104\n",
      "Train Epoch: 1042 [0/54000 (0%)] Loss: -723.275940\n",
      "Train Epoch: 1042 [11264/54000 (21%)] Loss: -738.589417\n",
      "Train Epoch: 1042 [22528/54000 (42%)] Loss: -753.302979\n",
      "Train Epoch: 1042 [33792/54000 (63%)] Loss: -755.806274\n",
      "Train Epoch: 1042 [45056/54000 (83%)] Loss: -737.837036\n",
      "    epoch          : 1042\n",
      "    loss           : -756.5295485010687\n",
      "    ess            : 1.959546831418883\n",
      "    log_marginal   : 756.5668807119694\n",
      "    log_joint      : 965.0083865759508\n",
      "    val_loss       : -761.0342254638672\n",
      "    val_ess        : 1.957661787668864\n",
      "    val_log_marginal: 761.0721791585287\n",
      "    val_log_joint  : 969.374013264974\n",
      "Train Epoch: 1043 [0/54000 (0%)] Loss: -767.782349\n",
      "Train Epoch: 1043 [11264/54000 (21%)] Loss: -784.825378\n",
      "Train Epoch: 1043 [22528/54000 (42%)] Loss: -753.613586\n",
      "Train Epoch: 1043 [33792/54000 (63%)] Loss: -759.304749\n",
      "Train Epoch: 1043 [45056/54000 (83%)] Loss: -743.136719\n",
      "    epoch          : 1043\n",
      "    loss           : -756.5758626685953\n",
      "    ess            : 1.9594178188521907\n",
      "    log_marginal   : 756.6142883300781\n",
      "    log_joint      : 965.1473711121757\n",
      "    val_loss       : -760.6045074462891\n",
      "    val_ess        : 1.9640614887078602\n",
      "    val_log_marginal: 760.6421915690104\n",
      "    val_log_joint  : 969.2223765055338\n",
      "Train Epoch: 1044 [0/54000 (0%)] Loss: -760.743591\n",
      "Train Epoch: 1044 [11264/54000 (21%)] Loss: -753.227539\n",
      "Train Epoch: 1044 [22528/54000 (42%)] Loss: -768.827271\n",
      "Train Epoch: 1044 [33792/54000 (63%)] Loss: -726.741943\n",
      "Train Epoch: 1044 [45056/54000 (83%)] Loss: -760.136414\n",
      "    epoch          : 1044\n",
      "    loss           : -756.5862121582031\n",
      "    ess            : 1.9590197734113008\n",
      "    log_marginal   : 756.6244587448408\n",
      "    log_joint      : 965.0461258798275\n",
      "    val_loss       : -761.2537943522135\n",
      "    val_ess        : 1.9588947494824727\n",
      "    val_log_marginal: 761.2920532226562\n",
      "    val_log_joint  : 969.7562255859375\n",
      "Train Epoch: 1045 [0/54000 (0%)] Loss: -760.220947\n",
      "Train Epoch: 1045 [11264/54000 (21%)] Loss: -759.883301\n",
      "Train Epoch: 1045 [22528/54000 (42%)] Loss: -759.674683\n",
      "Train Epoch: 1045 [33792/54000 (63%)] Loss: -746.841675\n",
      "Train Epoch: 1045 [45056/54000 (83%)] Loss: -760.597900\n",
      "    epoch          : 1045\n",
      "    loss           : -756.7881153034714\n",
      "    ess            : 1.9594486918089524\n",
      "    log_marginal   : 756.8250191166716\n",
      "    log_joint      : 965.3899000635687\n",
      "    val_loss       : -761.1800384521484\n",
      "    val_ess        : 1.9603336950143178\n",
      "    val_log_marginal: 761.2117919921875\n",
      "    val_log_joint  : 969.5684204101562\n",
      "Train Epoch: 1046 [0/54000 (0%)] Loss: -770.726257\n",
      "Train Epoch: 1046 [11264/54000 (21%)] Loss: -757.811951\n",
      "Train Epoch: 1046 [22528/54000 (42%)] Loss: -755.454346\n",
      "Train Epoch: 1046 [33792/54000 (63%)] Loss: -761.885498\n",
      "Train Epoch: 1046 [45056/54000 (83%)] Loss: -776.035461\n",
      "    epoch          : 1046\n",
      "    loss           : -756.8190370955557\n",
      "    ess            : 1.9603399083299458\n",
      "    log_marginal   : 756.855427292158\n",
      "    log_joint      : 965.2253844063237\n",
      "    val_loss       : -760.5746205647787\n",
      "    val_ess        : 1.958365519841512\n",
      "    val_log_marginal: 760.6130574544271\n",
      "    val_log_joint  : 968.9595286051432\n",
      "Train Epoch: 1047 [0/54000 (0%)] Loss: -757.888184\n",
      "Train Epoch: 1047 [11264/54000 (21%)] Loss: -756.374756\n",
      "Train Epoch: 1047 [22528/54000 (42%)] Loss: -753.927124\n",
      "Train Epoch: 1047 [33792/54000 (63%)] Loss: -764.835938\n",
      "Train Epoch: 1047 [45056/54000 (83%)] Loss: -760.004395\n",
      "    epoch          : 1047\n",
      "    loss           : -756.8113034806162\n",
      "    ess            : 1.959893912639258\n",
      "    log_marginal   : 756.8475336038841\n",
      "    log_joint      : 965.2171055056015\n",
      "    val_loss       : -760.7645009358724\n",
      "    val_ess        : 1.960094004869461\n",
      "    val_log_marginal: 760.7999674479166\n",
      "    val_log_joint  : 969.3973032633463\n",
      "Train Epoch: 1048 [0/54000 (0%)] Loss: -759.430786\n",
      "Train Epoch: 1048 [11264/54000 (21%)] Loss: -753.259155\n",
      "Train Epoch: 1048 [22528/54000 (42%)] Loss: -768.136047\n",
      "Train Epoch: 1048 [33792/54000 (63%)] Loss: -756.352295\n",
      "Train Epoch: 1048 [45056/54000 (83%)] Loss: -766.241516\n",
      "    epoch          : 1048\n",
      "    loss           : -756.9520401864681\n",
      "    ess            : 1.9598264559259955\n",
      "    log_marginal   : 756.988678554319\n",
      "    log_joint      : 965.4480164725826\n",
      "    val_loss       : -761.4530232747396\n",
      "    val_ess        : 1.9600015183289845\n",
      "    val_log_marginal: 761.4872029622396\n",
      "    val_log_joint  : 969.8834075927734\n",
      "Train Epoch: 1049 [0/54000 (0%)] Loss: -777.323486\n",
      "Train Epoch: 1049 [11264/54000 (21%)] Loss: -751.824158\n",
      "Train Epoch: 1049 [22528/54000 (42%)] Loss: -732.051147\n",
      "Train Epoch: 1049 [33792/54000 (63%)] Loss: -770.721802\n",
      "Train Epoch: 1049 [45056/54000 (83%)] Loss: -770.974731\n",
      "    epoch          : 1049\n",
      "    loss           : -756.7964120540979\n",
      "    ess            : 1.9603947974600882\n",
      "    log_marginal   : 756.8326899690448\n",
      "    log_joint      : 965.3229249198482\n",
      "    val_loss       : -761.1576639811198\n",
      "    val_ess        : 1.9585393865903218\n",
      "    val_log_marginal: 761.1942138671875\n",
      "    val_log_joint  : 969.7578786214193\n",
      "Train Epoch: 1050 [0/54000 (0%)] Loss: -761.624756\n",
      "Train Epoch: 1050 [11264/54000 (21%)] Loss: -767.391907\n",
      "Train Epoch: 1050 [22528/54000 (42%)] Loss: -740.169556\n",
      "Train Epoch: 1050 [33792/54000 (63%)] Loss: -755.200867\n",
      "Train Epoch: 1050 [45056/54000 (83%)] Loss: -751.893738\n",
      "    epoch          : 1050\n",
      "    loss           : -757.0058714668705\n",
      "    ess            : 1.959666349977817\n",
      "    log_marginal   : 757.0418229013119\n",
      "    log_joint      : 965.4783359743515\n",
      "    val_loss       : -761.0752309163412\n",
      "    val_ess        : 1.9569146533807118\n",
      "    val_log_marginal: 761.1161193847656\n",
      "    val_log_joint  : 969.4244791666666\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1050.pth ...\n",
      "Train Epoch: 1051 [0/54000 (0%)] Loss: -758.810608\n",
      "Train Epoch: 1051 [11264/54000 (21%)] Loss: -754.817017\n",
      "Train Epoch: 1051 [22528/54000 (42%)] Loss: -759.263794\n",
      "Train Epoch: 1051 [33792/54000 (63%)] Loss: -773.333069\n",
      "Train Epoch: 1051 [45056/54000 (83%)] Loss: -753.573486\n",
      "    epoch          : 1051\n",
      "    loss           : -757.0390774708874\n",
      "    ess            : 1.9600606886845715\n",
      "    log_marginal   : 757.076269185768\n",
      "    log_joint      : 965.5920053158167\n",
      "    val_loss       : -762.2881011962891\n",
      "    val_ess        : 1.955389718214671\n",
      "    val_log_marginal: 762.3268025716146\n",
      "    val_log_joint  : 970.9419759114584\n",
      "Train Epoch: 1052 [0/54000 (0%)] Loss: -752.691162\n",
      "Train Epoch: 1052 [11264/54000 (21%)] Loss: -767.714111\n",
      "Train Epoch: 1052 [22528/54000 (42%)] Loss: -759.818359\n",
      "Train Epoch: 1052 [33792/54000 (63%)] Loss: -744.320801\n",
      "Train Epoch: 1052 [45056/54000 (83%)] Loss: -748.856323\n",
      "    epoch          : 1052\n",
      "    loss           : -757.0735260585569\n",
      "    ess            : 1.9602426054342739\n",
      "    log_marginal   : 757.1098690392836\n",
      "    log_joint      : 965.553729939011\n",
      "    val_loss       : -762.0007578531901\n",
      "    val_ess        : 1.9632079501946766\n",
      "    val_log_marginal: 762.0307668050131\n",
      "    val_log_joint  : 970.4404042561849\n",
      "Train Epoch: 1053 [0/54000 (0%)] Loss: -754.458679\n",
      "Train Epoch: 1053 [11264/54000 (21%)] Loss: -754.102539\n",
      "Train Epoch: 1053 [22528/54000 (42%)] Loss: -784.759277\n",
      "Train Epoch: 1053 [33792/54000 (63%)] Loss: -753.198486\n",
      "Train Epoch: 1053 [45056/54000 (83%)] Loss: -763.630615\n",
      "    epoch          : 1053\n",
      "    loss           : -757.1542352640404\n",
      "    ess            : 1.9606739226377234\n",
      "    log_marginal   : 757.1897007204452\n",
      "    log_joint      : 965.7893659483711\n",
      "    val_loss       : -761.6943817138672\n",
      "    val_ess        : 1.9599393705526988\n",
      "    val_log_marginal: 761.7335154215494\n",
      "    val_log_joint  : 970.113037109375\n",
      "Train Epoch: 1054 [0/54000 (0%)] Loss: -744.703735\n",
      "Train Epoch: 1054 [11264/54000 (21%)] Loss: -761.756226\n",
      "Train Epoch: 1054 [22528/54000 (42%)] Loss: -735.646851\n",
      "Train Epoch: 1054 [33792/54000 (63%)] Loss: -765.895508\n",
      "Train Epoch: 1054 [45056/54000 (83%)] Loss: -731.314209\n",
      "    epoch          : 1054\n",
      "    loss           : -757.156152689232\n",
      "    ess            : 1.9604932935732715\n",
      "    log_marginal   : 757.1914747705999\n",
      "    log_joint      : 965.7264605828051\n",
      "    val_loss       : -761.7775370279948\n",
      "    val_ess        : 1.9621032079060872\n",
      "    val_log_marginal: 761.8122711181641\n",
      "    val_log_joint  : 970.1299641927084\n",
      "Train Epoch: 1055 [0/54000 (0%)] Loss: -765.084229\n",
      "Train Epoch: 1055 [11264/54000 (21%)] Loss: -762.468323\n",
      "Train Epoch: 1055 [22528/54000 (42%)] Loss: -749.902466\n",
      "Train Epoch: 1055 [33792/54000 (63%)] Loss: -761.154175\n",
      "Train Epoch: 1055 [45056/54000 (83%)] Loss: -743.635864\n",
      "    epoch          : 1055\n",
      "    loss           : -757.2863878933889\n",
      "    ess            : 1.96035790555882\n",
      "    log_marginal   : 757.3230838415758\n",
      "    log_joint      : 965.791830962559\n",
      "    val_loss       : -761.8866373697916\n",
      "    val_ess        : 1.9579772154490154\n",
      "    val_log_marginal: 761.9260609944662\n",
      "    val_log_joint  : 970.4599660237631\n",
      "Train Epoch: 1056 [0/54000 (0%)] Loss: -762.612000\n",
      "Train Epoch: 1056 [11264/54000 (21%)] Loss: -756.209290\n",
      "Train Epoch: 1056 [22528/54000 (42%)] Loss: -769.011475\n",
      "Train Epoch: 1056 [33792/54000 (63%)] Loss: -750.550232\n",
      "Train Epoch: 1056 [45056/54000 (83%)] Loss: -768.549561\n",
      "    epoch          : 1056\n",
      "    loss           : -757.3586753989166\n",
      "    ess            : 1.959144871189909\n",
      "    log_marginal   : 757.3972404048128\n",
      "    log_joint      : 965.8805732007297\n",
      "    val_loss       : -761.5579376220703\n",
      "    val_ess        : 1.9602725505828857\n",
      "    val_log_marginal: 761.5955454508463\n",
      "    val_log_joint  : 970.2200113932291\n",
      "Train Epoch: 1057 [0/54000 (0%)] Loss: -764.509155\n",
      "Train Epoch: 1057 [11264/54000 (21%)] Loss: -781.497803\n",
      "Train Epoch: 1057 [22528/54000 (42%)] Loss: -769.389832\n",
      "Train Epoch: 1057 [33792/54000 (63%)] Loss: -766.494385\n",
      "Train Epoch: 1057 [45056/54000 (83%)] Loss: -756.454773\n",
      "    epoch          : 1057\n",
      "    loss           : -757.3102463056456\n",
      "    ess            : 1.9593888948548515\n",
      "    log_marginal   : 757.346086034235\n",
      "    log_joint      : 965.8335047308004\n",
      "    val_loss       : -762.6350758870443\n",
      "    val_ess        : 1.959452619155248\n",
      "    val_log_marginal: 762.6730041503906\n",
      "    val_log_joint  : 971.0247395833334\n",
      "Train Epoch: 1058 [0/54000 (0%)] Loss: -746.409119\n",
      "Train Epoch: 1058 [11264/54000 (21%)] Loss: -784.768127\n",
      "Train Epoch: 1058 [22528/54000 (42%)] Loss: -756.671814\n",
      "Train Epoch: 1058 [33792/54000 (63%)] Loss: -774.391052\n",
      "Train Epoch: 1058 [45056/54000 (83%)] Loss: -786.958984\n",
      "    epoch          : 1058\n",
      "    loss           : -757.4882841290168\n",
      "    ess            : 1.9601183589899316\n",
      "    log_marginal   : 757.5252190355984\n",
      "    log_joint      : 966.0730372015036\n",
      "    val_loss       : -761.8941497802734\n",
      "    val_ess        : 1.9548575977484386\n",
      "    val_log_marginal: 761.9375406901041\n",
      "    val_log_joint  : 970.5095367431641\n",
      "Train Epoch: 1059 [0/54000 (0%)] Loss: -749.288757\n",
      "Train Epoch: 1059 [11264/54000 (21%)] Loss: -784.493530\n",
      "Train Epoch: 1059 [22528/54000 (42%)] Loss: -749.503662\n",
      "Train Epoch: 1059 [33792/54000 (63%)] Loss: -771.908325\n",
      "Train Epoch: 1059 [45056/54000 (83%)] Loss: -754.923279\n",
      "    epoch          : 1059\n",
      "    loss           : -757.629619670364\n",
      "    ess            : 1.9600765851308715\n",
      "    log_marginal   : 757.6673595500442\n",
      "    log_joint      : 966.1814039698187\n",
      "    val_loss       : -761.8003285725912\n",
      "    val_ess        : 1.9580152034759521\n",
      "    val_log_marginal: 761.8432261149088\n",
      "    val_log_joint  : 970.5019378662109\n",
      "Train Epoch: 1060 [0/54000 (0%)] Loss: -751.692017\n",
      "Train Epoch: 1060 [11264/54000 (21%)] Loss: -760.233398\n",
      "Train Epoch: 1060 [22528/54000 (42%)] Loss: -744.117310\n",
      "Train Epoch: 1060 [33792/54000 (63%)] Loss: -742.433228\n",
      "Train Epoch: 1060 [45056/54000 (83%)] Loss: -740.428589\n",
      "    epoch          : 1060\n",
      "    loss           : -757.5481239174896\n",
      "    ess            : 1.960185686372361\n",
      "    log_marginal   : 757.5848647783388\n",
      "    log_joint      : 966.1901118440448\n",
      "    val_loss       : -761.9652913411459\n",
      "    val_ess        : 1.959541787703832\n",
      "    val_log_marginal: 762.0061696370443\n",
      "    val_log_joint  : 970.6747639973959\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1060.pth ...\n",
      "Train Epoch: 1061 [0/54000 (0%)] Loss: -752.083618\n",
      "Train Epoch: 1061 [11264/54000 (21%)] Loss: -762.132019\n",
      "Train Epoch: 1061 [22528/54000 (42%)] Loss: -782.509399\n",
      "Train Epoch: 1061 [33792/54000 (63%)] Loss: -782.000000\n",
      "Train Epoch: 1061 [45056/54000 (83%)] Loss: -756.322021\n",
      "    epoch          : 1061\n",
      "    loss           : -757.8515999272184\n",
      "    ess            : 1.9603650918546713\n",
      "    log_marginal   : 757.8876440660009\n",
      "    log_joint      : 966.402233771558\n",
      "    val_loss       : -762.7612864176432\n",
      "    val_ess        : 1.9561251600583394\n",
      "    val_log_marginal: 762.8016764322916\n",
      "    val_log_joint  : 971.191162109375\n",
      "Train Epoch: 1062 [0/54000 (0%)] Loss: -749.016968\n",
      "Train Epoch: 1062 [11264/54000 (21%)] Loss: -746.137329\n",
      "Train Epoch: 1062 [22528/54000 (42%)] Loss: -739.755859\n",
      "Train Epoch: 1062 [33792/54000 (63%)] Loss: -739.256592\n",
      "Train Epoch: 1062 [45056/54000 (83%)] Loss: -767.636658\n",
      "    epoch          : 1062\n",
      "    loss           : -757.8901597508844\n",
      "    ess            : 1.961048108226848\n",
      "    log_marginal   : 757.9265775860481\n",
      "    log_joint      : 966.381459362102\n",
      "    val_loss       : -762.1840311686198\n",
      "    val_ess        : 1.9626177450021107\n",
      "    val_log_marginal: 762.2158762613932\n",
      "    val_log_joint  : 970.9204254150391\n",
      "Train Epoch: 1063 [0/54000 (0%)] Loss: -763.488525\n",
      "Train Epoch: 1063 [11264/54000 (21%)] Loss: -761.822632\n",
      "Train Epoch: 1063 [22528/54000 (42%)] Loss: -746.472168\n",
      "Train Epoch: 1063 [33792/54000 (63%)] Loss: -782.758118\n",
      "Train Epoch: 1063 [45056/54000 (83%)] Loss: -753.661011\n",
      "    epoch          : 1063\n",
      "    loss           : -757.8701736162294\n",
      "    ess            : 1.9599743080589007\n",
      "    log_marginal   : 757.9069403882297\n",
      "    log_joint      : 966.3146368062721\n",
      "    val_loss       : -762.2138621012369\n",
      "    val_ess        : 1.9584309856096904\n",
      "    val_log_marginal: 762.2507934570312\n",
      "    val_log_joint  : 970.9930674235026\n",
      "Train Epoch: 1064 [0/54000 (0%)] Loss: -769.286072\n",
      "Train Epoch: 1064 [11264/54000 (21%)] Loss: -765.879272\n",
      "Train Epoch: 1064 [22528/54000 (42%)] Loss: -789.798035\n",
      "Train Epoch: 1064 [33792/54000 (63%)] Loss: -742.203491\n",
      "Train Epoch: 1064 [45056/54000 (83%)] Loss: -758.610962\n",
      "    epoch          : 1064\n",
      "    loss           : -757.702512345224\n",
      "    ess            : 1.9605562923089512\n",
      "    log_marginal   : 757.7376962337854\n",
      "    log_joint      : 966.251094602189\n",
      "    val_loss       : -762.6379903157552\n",
      "    val_ess        : 1.9583252767721813\n",
      "    val_log_marginal: 762.6763153076172\n",
      "    val_log_joint  : 971.1564636230469\n",
      "Train Epoch: 1065 [0/54000 (0%)] Loss: -762.688599\n",
      "Train Epoch: 1065 [11264/54000 (21%)] Loss: -771.189697\n",
      "Train Epoch: 1065 [22528/54000 (42%)] Loss: -771.190186\n",
      "Train Epoch: 1065 [33792/54000 (63%)] Loss: -748.019958\n",
      "Train Epoch: 1065 [45056/54000 (83%)] Loss: -754.412231\n",
      "    epoch          : 1065\n",
      "    loss           : -757.7568082989387\n",
      "    ess            : 1.9589012951221105\n",
      "    log_marginal   : 757.7935025197155\n",
      "    log_joint      : 966.2683963415758\n",
      "    val_loss       : -762.8950042724609\n",
      "    val_ess        : 1.9600299100081127\n",
      "    val_log_marginal: 762.9294586181641\n",
      "    val_log_joint  : 971.5459493001302\n",
      "Train Epoch: 1066 [0/54000 (0%)] Loss: -733.620789\n",
      "Train Epoch: 1066 [11264/54000 (21%)] Loss: -769.111816\n",
      "Train Epoch: 1066 [22528/54000 (42%)] Loss: -752.147278\n",
      "Train Epoch: 1066 [33792/54000 (63%)] Loss: -755.182129\n",
      "Train Epoch: 1066 [45056/54000 (83%)] Loss: -755.225830\n",
      "    epoch          : 1066\n",
      "    loss           : -757.7897465543927\n",
      "    ess            : 1.9608116104917706\n",
      "    log_marginal   : 757.8252459831957\n",
      "    log_joint      : 966.3036366588665\n",
      "    val_loss       : -761.9275105794271\n",
      "    val_ess        : 1.959008385737737\n",
      "    val_log_marginal: 761.9658966064453\n",
      "    val_log_joint  : 970.2755839029948\n",
      "Train Epoch: 1067 [0/54000 (0%)] Loss: -745.359314\n",
      "Train Epoch: 1067 [11264/54000 (21%)] Loss: -764.829956\n",
      "Train Epoch: 1067 [22528/54000 (42%)] Loss: -766.554077\n",
      "Train Epoch: 1067 [33792/54000 (63%)] Loss: -756.626892\n",
      "Train Epoch: 1067 [45056/54000 (83%)] Loss: -755.617126\n",
      "    epoch          : 1067\n",
      "    loss           : -757.8886194768942\n",
      "    ess            : 1.9586416527910053\n",
      "    log_marginal   : 757.9261710688753\n",
      "    log_joint      : 966.4637934846698\n",
      "    val_loss       : -762.3252461751302\n",
      "    val_ess        : 1.9605783720811207\n",
      "    val_log_marginal: 762.3620656331381\n",
      "    val_log_joint  : 970.7436574300131\n",
      "Train Epoch: 1068 [0/54000 (0%)] Loss: -759.621033\n",
      "Train Epoch: 1068 [11264/54000 (21%)] Loss: -778.890686\n",
      "Train Epoch: 1068 [22528/54000 (42%)] Loss: -756.778198\n",
      "Train Epoch: 1068 [33792/54000 (63%)] Loss: -743.313599\n",
      "Train Epoch: 1068 [45056/54000 (83%)] Loss: -776.434937\n",
      "    epoch          : 1068\n",
      "    loss           : -758.0005113133844\n",
      "    ess            : 1.960015004535891\n",
      "    log_marginal   : 758.0368963277565\n",
      "    log_joint      : 966.429366777528\n",
      "    val_loss       : -762.9498443603516\n",
      "    val_ess        : 1.9603329996267955\n",
      "    val_log_marginal: 762.9920450846354\n",
      "    val_log_joint  : 971.3916727701823\n",
      "Train Epoch: 1069 [0/54000 (0%)] Loss: -760.265259\n",
      "Train Epoch: 1069 [11264/54000 (21%)] Loss: -751.307556\n",
      "Train Epoch: 1069 [22528/54000 (42%)] Loss: -752.568848\n",
      "Train Epoch: 1069 [33792/54000 (63%)] Loss: -769.991943\n",
      "Train Epoch: 1069 [45056/54000 (83%)] Loss: -751.778320\n",
      "    epoch          : 1069\n",
      "    loss           : -757.9700081303434\n",
      "    ess            : 1.9594256922883808\n",
      "    log_marginal   : 758.0076495476488\n",
      "    log_joint      : 966.5029722969487\n",
      "    val_loss       : -763.1365966796875\n",
      "    val_ess        : 1.960124433040619\n",
      "    val_log_marginal: 763.1745808919271\n",
      "    val_log_joint  : 971.4345448811849\n",
      "Train Epoch: 1070 [0/54000 (0%)] Loss: -771.882202\n",
      "Train Epoch: 1070 [11264/54000 (21%)] Loss: -784.398560\n",
      "Train Epoch: 1070 [22528/54000 (42%)] Loss: -756.899658\n",
      "Train Epoch: 1070 [33792/54000 (63%)] Loss: -771.308350\n",
      "Train Epoch: 1070 [45056/54000 (83%)] Loss: -775.937744\n",
      "    epoch          : 1070\n",
      "    loss           : -758.083042936505\n",
      "    ess            : 1.9601120768852953\n",
      "    log_marginal   : 758.1180264454968\n",
      "    log_joint      : 966.6002473651238\n",
      "    val_loss       : -763.0726216634115\n",
      "    val_ess        : 1.9623580475648243\n",
      "    val_log_marginal: 763.1050618489584\n",
      "    val_log_joint  : 971.3426411946615\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1070.pth ...\n",
      "Train Epoch: 1071 [0/54000 (0%)] Loss: -741.401917\n",
      "Train Epoch: 1071 [11264/54000 (21%)] Loss: -741.740540\n",
      "Train Epoch: 1071 [22528/54000 (42%)] Loss: -762.535706\n",
      "Train Epoch: 1071 [33792/54000 (63%)] Loss: -745.903625\n",
      "Train Epoch: 1071 [45056/54000 (83%)] Loss: -748.648560\n",
      "    epoch          : 1071\n",
      "    loss           : -758.2866608241819\n",
      "    ess            : 1.9596378432129913\n",
      "    log_marginal   : 758.3230924786262\n",
      "    log_joint      : 966.9099673864977\n",
      "    val_loss       : -762.4478047688802\n",
      "    val_ess        : 1.9621595939000447\n",
      "    val_log_marginal: 762.4831492106119\n",
      "    val_log_joint  : 971.2149505615234\n",
      "Train Epoch: 1072 [0/54000 (0%)] Loss: -768.370483\n",
      "Train Epoch: 1072 [11264/54000 (21%)] Loss: -741.651489\n",
      "Train Epoch: 1072 [22528/54000 (42%)] Loss: -749.710083\n",
      "Train Epoch: 1072 [33792/54000 (63%)] Loss: -756.759277\n",
      "Train Epoch: 1072 [45056/54000 (83%)] Loss: -746.989990\n",
      "    epoch          : 1072\n",
      "    loss           : -758.30315240824\n",
      "    ess            : 1.9595027925833217\n",
      "    log_marginal   : 758.3394406876474\n",
      "    log_joint      : 966.9094439812426\n",
      "    val_loss       : -763.0206705729166\n",
      "    val_ess        : 1.9587685465812683\n",
      "    val_log_marginal: 763.0603993733724\n",
      "    val_log_joint  : 971.6124420166016\n",
      "Train Epoch: 1073 [0/54000 (0%)] Loss: -756.830933\n",
      "Train Epoch: 1073 [11264/54000 (21%)] Loss: -760.516235\n",
      "Train Epoch: 1073 [22528/54000 (42%)] Loss: -768.067749\n",
      "Train Epoch: 1073 [33792/54000 (63%)] Loss: -750.571899\n",
      "Train Epoch: 1073 [45056/54000 (83%)] Loss: -755.198364\n",
      "    epoch          : 1073\n",
      "    loss           : -758.4350695340139\n",
      "    ess            : 1.959065946767915\n",
      "    log_marginal   : 758.4736892412294\n",
      "    log_joint      : 967.0374894052181\n",
      "    val_loss       : -762.6591288248698\n",
      "    val_ess        : 1.9568588733673096\n",
      "    val_log_marginal: 762.7023417154948\n",
      "    val_log_joint  : 971.2211608886719\n",
      "Train Epoch: 1074 [0/54000 (0%)] Loss: -768.537659\n",
      "Train Epoch: 1074 [11264/54000 (21%)] Loss: -764.075134\n",
      "Train Epoch: 1074 [22528/54000 (42%)] Loss: -767.846802\n",
      "Train Epoch: 1074 [33792/54000 (63%)] Loss: -770.202515\n",
      "Train Epoch: 1074 [45056/54000 (83%)] Loss: -753.210876\n",
      "    epoch          : 1074\n",
      "    loss           : -758.4914930811468\n",
      "    ess            : 1.9589857447822139\n",
      "    log_marginal   : 758.528891509434\n",
      "    log_joint      : 967.0785856426887\n",
      "    val_loss       : -762.8817392985026\n",
      "    val_ess        : 1.96181653936704\n",
      "    val_log_marginal: 762.9147084554037\n",
      "    val_log_joint  : 971.4420572916666\n",
      "Train Epoch: 1075 [0/54000 (0%)] Loss: -744.994141\n",
      "Train Epoch: 1075 [11264/54000 (21%)] Loss: -772.301880\n",
      "Train Epoch: 1075 [22528/54000 (42%)] Loss: -766.385498\n",
      "Train Epoch: 1075 [33792/54000 (63%)] Loss: -733.252808\n",
      "Train Epoch: 1075 [45056/54000 (83%)] Loss: -742.698181\n",
      "    epoch          : 1075\n",
      "    loss           : -758.5525368744472\n",
      "    ess            : 1.959720049264296\n",
      "    log_marginal   : 758.5885096136129\n",
      "    log_joint      : 967.1075692806604\n",
      "    val_loss       : -762.8715057373047\n",
      "    val_ess        : 1.9576207200686138\n",
      "    val_log_marginal: 762.9125061035156\n",
      "    val_log_joint  : 971.0976969401041\n",
      "Train Epoch: 1076 [0/54000 (0%)] Loss: -744.619507\n",
      "Train Epoch: 1076 [11264/54000 (21%)] Loss: -766.167969\n",
      "Train Epoch: 1076 [22528/54000 (42%)] Loss: -777.001465\n",
      "Train Epoch: 1076 [33792/54000 (63%)] Loss: -747.063660\n",
      "Train Epoch: 1076 [45056/54000 (83%)] Loss: -763.285645\n",
      "    epoch          : 1076\n",
      "    loss           : -758.5937396355395\n",
      "    ess            : 1.9591301915780552\n",
      "    log_marginal   : 758.6303757001768\n",
      "    log_joint      : 967.090855436505\n",
      "    val_loss       : -763.1658426920573\n",
      "    val_ess        : 1.956642468770345\n",
      "    val_log_marginal: 763.2062479654948\n",
      "    val_log_joint  : 971.5448201497396\n",
      "Train Epoch: 1077 [0/54000 (0%)] Loss: -742.511353\n",
      "Train Epoch: 1077 [11264/54000 (21%)] Loss: -750.498474\n",
      "Train Epoch: 1077 [22528/54000 (42%)] Loss: -765.668274\n",
      "Train Epoch: 1077 [33792/54000 (63%)] Loss: -774.863647\n",
      "Train Epoch: 1077 [45056/54000 (83%)] Loss: -761.687866\n",
      "    epoch          : 1077\n",
      "    loss           : -758.964543756449\n",
      "    ess            : 1.9587577862559624\n",
      "    log_marginal   : 759.0015592755012\n",
      "    log_joint      : 967.4042565687647\n",
      "    val_loss       : -763.5780181884766\n",
      "    val_ess        : 1.9613905151685078\n",
      "    val_log_marginal: 763.6086120605469\n",
      "    val_log_joint  : 971.8625691731771\n",
      "Train Epoch: 1078 [0/54000 (0%)] Loss: -774.814880\n",
      "Train Epoch: 1078 [11264/54000 (21%)] Loss: -746.838989\n",
      "Train Epoch: 1078 [22528/54000 (42%)] Loss: -769.425903\n",
      "Train Epoch: 1078 [33792/54000 (63%)] Loss: -757.875061\n",
      "Train Epoch: 1078 [45056/54000 (83%)] Loss: -757.253418\n",
      "    epoch          : 1078\n",
      "    loss           : -758.7584055774616\n",
      "    ess            : 1.959199587129197\n",
      "    log_marginal   : 758.7958350991303\n",
      "    log_joint      : 967.4220108895931\n",
      "    val_loss       : -762.8364766438802\n",
      "    val_ess        : 1.9586573938528697\n",
      "    val_log_marginal: 762.8712209065756\n",
      "    val_log_joint  : 971.3345184326172\n",
      "Train Epoch: 1079 [0/54000 (0%)] Loss: -751.775024\n",
      "Train Epoch: 1079 [11264/54000 (21%)] Loss: -751.168091\n",
      "Train Epoch: 1079 [22528/54000 (42%)] Loss: -770.405823\n",
      "Train Epoch: 1079 [33792/54000 (63%)] Loss: -755.160767\n",
      "Train Epoch: 1079 [45056/54000 (83%)] Loss: -765.652344\n",
      "    epoch          : 1079\n",
      "    loss           : -758.7467547722582\n",
      "    ess            : 1.9601362651249148\n",
      "    log_marginal   : 758.7820261829304\n",
      "    log_joint      : 967.2719628675928\n",
      "    val_loss       : -762.2525431315104\n",
      "    val_ess        : 1.9600388805071514\n",
      "    val_log_marginal: 762.2911631266276\n",
      "    val_log_joint  : 970.835215250651\n",
      "Train Epoch: 1080 [0/54000 (0%)] Loss: -774.833679\n",
      "Train Epoch: 1080 [11264/54000 (21%)] Loss: -770.292297\n",
      "Train Epoch: 1080 [22528/54000 (42%)] Loss: -761.856323\n",
      "Train Epoch: 1080 [33792/54000 (63%)] Loss: -770.046631\n",
      "Train Epoch: 1080 [45056/54000 (83%)] Loss: -749.578735\n",
      "    epoch          : 1080\n",
      "    loss           : -758.6918432847509\n",
      "    ess            : 1.9586370677318212\n",
      "    log_marginal   : 758.7294374861807\n",
      "    log_joint      : 967.1909312122273\n",
      "    val_loss       : -763.3916625976562\n",
      "    val_ess        : 1.9587978919347127\n",
      "    val_log_marginal: 763.4306640625\n",
      "    val_log_joint  : 971.8263854980469\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1080.pth ...\n",
      "Train Epoch: 1081 [0/54000 (0%)] Loss: -761.404785\n",
      "Train Epoch: 1081 [11264/54000 (21%)] Loss: -763.199951\n",
      "Train Epoch: 1081 [22528/54000 (42%)] Loss: -756.240234\n",
      "Train Epoch: 1081 [33792/54000 (63%)] Loss: -737.538086\n",
      "Train Epoch: 1081 [45056/54000 (83%)] Loss: -776.411987\n",
      "    epoch          : 1081\n",
      "    loss           : -758.7648436348393\n",
      "    ess            : 1.9599450061906059\n",
      "    log_marginal   : 758.8000471007149\n",
      "    log_joint      : 967.4295769457547\n",
      "    val_loss       : -762.8811798095703\n",
      "    val_ess        : 1.9622187316417694\n",
      "    val_log_marginal: 762.9144846598307\n",
      "    val_log_joint  : 971.5633850097656\n",
      "Train Epoch: 1082 [0/54000 (0%)] Loss: -789.992798\n",
      "Train Epoch: 1082 [11264/54000 (21%)] Loss: -749.673035\n",
      "Train Epoch: 1082 [22528/54000 (42%)] Loss: -749.555847\n",
      "Train Epoch: 1082 [33792/54000 (63%)] Loss: -768.010376\n",
      "Train Epoch: 1082 [45056/54000 (83%)] Loss: -747.573242\n",
      "    epoch          : 1082\n",
      "    loss           : -758.964551817696\n",
      "    ess            : 1.9592887691731722\n",
      "    log_marginal   : 759.0019352750958\n",
      "    log_joint      : 967.5190567880306\n",
      "    val_loss       : -763.2309722900391\n",
      "    val_ess        : 1.9634750882784526\n",
      "    val_log_marginal: 763.2646942138672\n",
      "    val_log_joint  : 971.8501180013021\n",
      "Train Epoch: 1083 [0/54000 (0%)] Loss: -759.564087\n",
      "Train Epoch: 1083 [11264/54000 (21%)] Loss: -747.133545\n",
      "Train Epoch: 1083 [22528/54000 (42%)] Loss: -748.493347\n",
      "Train Epoch: 1083 [33792/54000 (63%)] Loss: -748.931030\n",
      "Train Epoch: 1083 [45056/54000 (83%)] Loss: -763.681580\n",
      "    epoch          : 1083\n",
      "    loss           : -758.994175749005\n",
      "    ess            : 1.960172436147366\n",
      "    log_marginal   : 759.0296279619325\n",
      "    log_joint      : 967.548772272074\n",
      "    val_loss       : -763.073964436849\n",
      "    val_ess        : 1.9580608010292053\n",
      "    val_log_marginal: 763.1124471028646\n",
      "    val_log_joint  : 971.458017985026\n",
      "Train Epoch: 1084 [0/54000 (0%)] Loss: -762.362183\n",
      "Train Epoch: 1084 [11264/54000 (21%)] Loss: -759.222107\n",
      "Train Epoch: 1084 [22528/54000 (42%)] Loss: -754.671631\n",
      "Train Epoch: 1084 [33792/54000 (63%)] Loss: -767.001465\n",
      "Train Epoch: 1084 [45056/54000 (83%)] Loss: -768.317261\n",
      "    epoch          : 1084\n",
      "    loss           : -759.2372925956295\n",
      "    ess            : 1.9585939387105546\n",
      "    log_marginal   : 759.2752052163178\n",
      "    log_joint      : 967.7906096836306\n",
      "    val_loss       : -763.0729064941406\n",
      "    val_ess        : 1.964206486940384\n",
      "    val_log_marginal: 763.1036478678385\n",
      "    val_log_joint  : 971.3889007568359\n",
      "Train Epoch: 1085 [0/54000 (0%)] Loss: -759.799805\n",
      "Train Epoch: 1085 [11264/54000 (21%)] Loss: -757.535278\n",
      "Train Epoch: 1085 [22528/54000 (42%)] Loss: -756.351929\n",
      "Train Epoch: 1085 [33792/54000 (63%)] Loss: -747.804688\n",
      "Train Epoch: 1085 [45056/54000 (83%)] Loss: -762.157959\n",
      "    epoch          : 1085\n",
      "    loss           : -759.0505538076725\n",
      "    ess            : 1.958701360900447\n",
      "    log_marginal   : 759.0875756605616\n",
      "    log_joint      : 967.5283157060732\n",
      "    val_loss       : -763.0372060139974\n",
      "    val_ess        : 1.9601611296335857\n",
      "    val_log_marginal: 763.0747426350912\n",
      "    val_log_joint  : 971.5645955403646\n",
      "Train Epoch: 1086 [0/54000 (0%)] Loss: -724.274719\n",
      "Train Epoch: 1086 [11264/54000 (21%)] Loss: -754.277588\n",
      "Train Epoch: 1086 [22528/54000 (42%)] Loss: -770.341492\n",
      "Train Epoch: 1086 [33792/54000 (63%)] Loss: -768.480347\n",
      "Train Epoch: 1086 [45056/54000 (83%)] Loss: -771.234741\n",
      "    epoch          : 1086\n",
      "    loss           : -759.1276843952683\n",
      "    ess            : 1.959463508623951\n",
      "    log_marginal   : 759.1637256550339\n",
      "    log_joint      : 967.6552417683151\n",
      "    val_loss       : -763.2742869059244\n",
      "    val_ess        : 1.9530342717965443\n",
      "    val_log_marginal: 763.3197937011719\n",
      "    val_log_joint  : 971.4397888183594\n",
      "Train Epoch: 1087 [0/54000 (0%)] Loss: -760.521606\n",
      "Train Epoch: 1087 [11264/54000 (21%)] Loss: -754.955200\n",
      "Train Epoch: 1087 [22528/54000 (42%)] Loss: -743.237793\n",
      "Train Epoch: 1087 [33792/54000 (63%)] Loss: -781.467896\n",
      "Train Epoch: 1087 [45056/54000 (83%)] Loss: -758.823120\n",
      "    epoch          : 1087\n",
      "    loss           : -759.2389152095003\n",
      "    ess            : 1.9599051070663165\n",
      "    log_marginal   : 759.2744273059773\n",
      "    log_joint      : 967.8118752533535\n",
      "    val_loss       : -762.8212839762369\n",
      "    val_ess        : 1.9626051485538483\n",
      "    val_log_marginal: 762.8558349609375\n",
      "    val_log_joint  : 971.2634836832682\n",
      "Train Epoch: 1088 [0/54000 (0%)] Loss: -765.747681\n",
      "Train Epoch: 1088 [11264/54000 (21%)] Loss: -761.160217\n",
      "Train Epoch: 1088 [22528/54000 (42%)] Loss: -776.624268\n",
      "Train Epoch: 1088 [33792/54000 (63%)] Loss: -761.510742\n",
      "Train Epoch: 1088 [45056/54000 (83%)] Loss: -756.589966\n",
      "    epoch          : 1088\n",
      "    loss           : -759.3812739534198\n",
      "    ess            : 1.960310363544608\n",
      "    log_marginal   : 759.4159764703714\n",
      "    log_joint      : 967.8661481749336\n",
      "    val_loss       : -763.8044586181641\n",
      "    val_ess        : 1.956174075603485\n",
      "    val_log_marginal: 763.8471374511719\n",
      "    val_log_joint  : 972.3954366048177\n",
      "Train Epoch: 1089 [0/54000 (0%)] Loss: -757.529541\n",
      "Train Epoch: 1089 [11264/54000 (21%)] Loss: -764.683105\n",
      "Train Epoch: 1089 [22528/54000 (42%)] Loss: -761.031982\n",
      "Train Epoch: 1089 [33792/54000 (63%)] Loss: -740.419434\n",
      "Train Epoch: 1089 [45056/54000 (83%)] Loss: -759.424194\n",
      "    epoch          : 1089\n",
      "    loss           : -759.4883025547243\n",
      "    ess            : 1.9600193702949669\n",
      "    log_marginal   : 759.525140150538\n",
      "    log_joint      : 968.1054664467865\n",
      "    val_loss       : -764.2310892740885\n",
      "    val_ess        : 1.9619962771733601\n",
      "    val_log_marginal: 764.2610829671224\n",
      "    val_log_joint  : 972.746083577474\n",
      "Train Epoch: 1090 [0/54000 (0%)] Loss: -766.403809\n",
      "Train Epoch: 1090 [11264/54000 (21%)] Loss: -772.937134\n",
      "Train Epoch: 1090 [22528/54000 (42%)] Loss: -749.460571\n",
      "Train Epoch: 1090 [33792/54000 (63%)] Loss: -773.128601\n",
      "Train Epoch: 1090 [45056/54000 (83%)] Loss: -780.332275\n",
      "    epoch          : 1090\n",
      "    loss           : -759.5673920253538\n",
      "    ess            : 1.9602233924955692\n",
      "    log_marginal   : 759.6047950600678\n",
      "    log_joint      : 968.1350109172317\n",
      "    val_loss       : -763.7996063232422\n",
      "    val_ess        : 1.9591668546199799\n",
      "    val_log_marginal: 763.8357747395834\n",
      "    val_log_joint  : 972.1815388997396\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1090.pth ...\n",
      "Train Epoch: 1091 [0/54000 (0%)] Loss: -758.265747\n",
      "Train Epoch: 1091 [11264/54000 (21%)] Loss: -775.529724\n",
      "Train Epoch: 1091 [22528/54000 (42%)] Loss: -765.243042\n",
      "Train Epoch: 1091 [33792/54000 (63%)] Loss: -736.493896\n",
      "Train Epoch: 1091 [45056/54000 (83%)] Loss: -753.344055\n",
      "    epoch          : 1091\n",
      "    loss           : -759.6093536952757\n",
      "    ess            : 1.9595147776153852\n",
      "    log_marginal   : 759.6464849508034\n",
      "    log_joint      : 968.1420017458358\n",
      "    val_loss       : -763.3529357910156\n",
      "    val_ess        : 1.959889163573583\n",
      "    val_log_marginal: 763.3898264567057\n",
      "    val_log_joint  : 971.6190897623698\n",
      "Train Epoch: 1092 [0/54000 (0%)] Loss: -770.378540\n",
      "Train Epoch: 1092 [11264/54000 (21%)] Loss: -743.399658\n",
      "Train Epoch: 1092 [22528/54000 (42%)] Loss: -745.018250\n",
      "Train Epoch: 1092 [33792/54000 (63%)] Loss: -736.331543\n",
      "Train Epoch: 1092 [45056/54000 (83%)] Loss: -734.080811\n",
      "    epoch          : 1092\n",
      "    loss           : -759.6982128215286\n",
      "    ess            : 1.9592732719655306\n",
      "    log_marginal   : 759.734548892615\n",
      "    log_joint      : 968.179974825877\n",
      "    val_loss       : -763.5836791992188\n",
      "    val_ess        : 1.9584096372127533\n",
      "    val_log_marginal: 763.6182403564453\n",
      "    val_log_joint  : 971.781728108724\n",
      "Train Epoch: 1093 [0/54000 (0%)] Loss: -751.997681\n",
      "Train Epoch: 1093 [11264/54000 (21%)] Loss: -742.667725\n",
      "Train Epoch: 1093 [22528/54000 (42%)] Loss: -773.039185\n",
      "Train Epoch: 1093 [33792/54000 (63%)] Loss: -769.633850\n",
      "Train Epoch: 1093 [45056/54000 (83%)] Loss: -763.686401\n",
      "    epoch          : 1093\n",
      "    loss           : -759.5199751943912\n",
      "    ess            : 1.9594676888213967\n",
      "    log_marginal   : 759.5573333164431\n",
      "    log_joint      : 967.9412438734522\n",
      "    val_loss       : -763.1307525634766\n",
      "    val_ess        : 1.9629405339558919\n",
      "    val_log_marginal: 763.1659189860026\n",
      "    val_log_joint  : 971.6184132893881\n",
      "Train Epoch: 1094 [0/54000 (0%)] Loss: -766.116028\n",
      "Train Epoch: 1094 [11264/54000 (21%)] Loss: -732.208374\n",
      "Train Epoch: 1094 [22528/54000 (42%)] Loss: -751.583130\n",
      "Train Epoch: 1094 [33792/54000 (63%)] Loss: -748.739136\n",
      "Train Epoch: 1094 [45056/54000 (83%)] Loss: -760.651306\n",
      "    epoch          : 1094\n",
      "    loss           : -759.5944317511793\n",
      "    ess            : 1.9598749988483932\n",
      "    log_marginal   : 759.6305213784271\n",
      "    log_joint      : 968.1824680544296\n",
      "    val_loss       : -763.5174916585287\n",
      "    val_ess        : 1.9607471525669098\n",
      "    val_log_marginal: 763.5538380940756\n",
      "    val_log_joint  : 971.9918924967448\n",
      "Train Epoch: 1095 [0/54000 (0%)] Loss: -755.905396\n",
      "Train Epoch: 1095 [11264/54000 (21%)] Loss: -775.882446\n",
      "Train Epoch: 1095 [22528/54000 (42%)] Loss: -767.400757\n",
      "Train Epoch: 1095 [33792/54000 (63%)] Loss: -755.044312\n",
      "Train Epoch: 1095 [45056/54000 (83%)] Loss: -740.194824\n",
      "    epoch          : 1095\n",
      "    loss           : -759.7845856288694\n",
      "    ess            : 1.9596765075089797\n",
      "    log_marginal   : 759.8200844818691\n",
      "    log_joint      : 968.2745033120209\n",
      "    val_loss       : -763.3316446940104\n",
      "    val_ess        : 1.957210103670756\n",
      "    val_log_marginal: 763.3713734944662\n",
      "    val_log_joint  : 971.9637451171875\n",
      "Train Epoch: 1096 [0/54000 (0%)] Loss: -763.637817\n",
      "Train Epoch: 1096 [11264/54000 (21%)] Loss: -789.102173\n",
      "Train Epoch: 1096 [22528/54000 (42%)] Loss: -755.162964\n",
      "Train Epoch: 1096 [33792/54000 (63%)] Loss: -766.336426\n",
      "Train Epoch: 1096 [45056/54000 (83%)] Loss: -771.125488\n",
      "    epoch          : 1096\n",
      "    loss           : -759.6096715387308\n",
      "    ess            : 1.959344468026791\n",
      "    log_marginal   : 759.6478899110039\n",
      "    log_joint      : 968.1199519319355\n",
      "    val_loss       : -763.0112508138021\n",
      "    val_ess        : 1.9587426980336506\n",
      "    val_log_marginal: 763.0492248535156\n",
      "    val_log_joint  : 971.6705525716146\n",
      "Train Epoch: 1097 [0/54000 (0%)] Loss: -774.711182\n",
      "Train Epoch: 1097 [11264/54000 (21%)] Loss: -769.745728\n",
      "Train Epoch: 1097 [22528/54000 (42%)] Loss: -755.025818\n",
      "Train Epoch: 1097 [33792/54000 (63%)] Loss: -765.179993\n",
      "Train Epoch: 1097 [45056/54000 (83%)] Loss: -758.494507\n",
      "    epoch          : 1097\n",
      "    loss           : -759.7268861014888\n",
      "    ess            : 1.9601076009138576\n",
      "    log_marginal   : 759.7631375294811\n",
      "    log_joint      : 968.2313756402933\n",
      "    val_loss       : -763.3029937744141\n",
      "    val_ess        : 1.9639258484045665\n",
      "    val_log_marginal: 763.3331909179688\n",
      "    val_log_joint  : 971.9756266276041\n",
      "Train Epoch: 1098 [0/54000 (0%)] Loss: -754.971436\n",
      "Train Epoch: 1098 [11264/54000 (21%)] Loss: -749.497192\n",
      "Train Epoch: 1098 [22528/54000 (42%)] Loss: -771.470764\n",
      "Train Epoch: 1098 [33792/54000 (63%)] Loss: -738.989746\n",
      "Train Epoch: 1098 [45056/54000 (83%)] Loss: -758.410034\n",
      "    epoch          : 1098\n",
      "    loss           : -759.6838989257812\n",
      "    ess            : 1.9617676375047215\n",
      "    log_marginal   : 759.7181713176224\n",
      "    log_joint      : 968.3510068497568\n",
      "    val_loss       : -763.7176208496094\n",
      "    val_ess        : 1.9618976215521495\n",
      "    val_log_marginal: 763.7570546468099\n",
      "    val_log_joint  : 972.2145640055338\n",
      "Train Epoch: 1099 [0/54000 (0%)] Loss: -733.259644\n",
      "Train Epoch: 1099 [11264/54000 (21%)] Loss: -771.691772\n",
      "Train Epoch: 1099 [22528/54000 (42%)] Loss: -779.163635\n",
      "Train Epoch: 1099 [33792/54000 (63%)] Loss: -754.248962\n",
      "Train Epoch: 1099 [45056/54000 (83%)] Loss: -763.990112\n",
      "    epoch          : 1099\n",
      "    loss           : -759.793010207842\n",
      "    ess            : 1.9592460877490494\n",
      "    log_marginal   : 759.8306003786483\n",
      "    log_joint      : 968.4634169092718\n",
      "    val_loss       : -763.7296142578125\n",
      "    val_ess        : 1.9617439607779186\n",
      "    val_log_marginal: 763.7625427246094\n",
      "    val_log_joint  : 972.2028452555338\n",
      "Train Epoch: 1100 [0/54000 (0%)] Loss: -757.777710\n",
      "Train Epoch: 1100 [11264/54000 (21%)] Loss: -781.865662\n",
      "Train Epoch: 1100 [22528/54000 (42%)] Loss: -751.446167\n",
      "Train Epoch: 1100 [33792/54000 (63%)] Loss: -739.297180\n",
      "Train Epoch: 1100 [45056/54000 (83%)] Loss: -775.775024\n",
      "    epoch          : 1100\n",
      "    loss           : -759.9658588913252\n",
      "    ess            : 1.9592595640218482\n",
      "    log_marginal   : 760.0033580852005\n",
      "    log_joint      : 968.5631057451357\n",
      "    val_loss       : -763.8055369059244\n",
      "    val_ess        : 1.9597167472044628\n",
      "    val_log_marginal: 763.8404795328776\n",
      "    val_log_joint  : 972.3635609944662\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1100.pth ...\n",
      "Train Epoch: 1101 [0/54000 (0%)] Loss: -764.897705\n",
      "Train Epoch: 1101 [11264/54000 (21%)] Loss: -770.349915\n",
      "Train Epoch: 1101 [22528/54000 (42%)] Loss: -772.749207\n",
      "Train Epoch: 1101 [33792/54000 (63%)] Loss: -775.094971\n",
      "Train Epoch: 1101 [45056/54000 (83%)] Loss: -765.457275\n",
      "    epoch          : 1101\n",
      "    loss           : -759.9241068138266\n",
      "    ess            : 1.960607186803278\n",
      "    log_marginal   : 759.9595452074734\n",
      "    log_joint      : 968.5475325674381\n",
      "    val_loss       : -764.1956481933594\n",
      "    val_ess        : 1.960866371790568\n",
      "    val_log_marginal: 764.232920328776\n",
      "    val_log_joint  : 972.6909383138021\n",
      "Train Epoch: 1102 [0/54000 (0%)] Loss: -773.976929\n",
      "Train Epoch: 1102 [11264/54000 (21%)] Loss: -770.019165\n",
      "Train Epoch: 1102 [22528/54000 (42%)] Loss: -764.612976\n",
      "Train Epoch: 1102 [33792/54000 (63%)] Loss: -757.796570\n",
      "Train Epoch: 1102 [45056/54000 (83%)] Loss: -784.379333\n",
      "    epoch          : 1102\n",
      "    loss           : -760.0683040978773\n",
      "    ess            : 1.959964043689224\n",
      "    log_marginal   : 760.1041766472582\n",
      "    log_joint      : 968.6369744066922\n",
      "    val_loss       : -764.4686940511068\n",
      "    val_ess        : 1.9600924452145894\n",
      "    val_log_marginal: 764.5038146972656\n",
      "    val_log_joint  : 973.1234639485677\n",
      "Train Epoch: 1103 [0/54000 (0%)] Loss: -773.563477\n",
      "Train Epoch: 1103 [11264/54000 (21%)] Loss: -747.104370\n",
      "Train Epoch: 1103 [22528/54000 (42%)] Loss: -758.451965\n",
      "Train Epoch: 1103 [33792/54000 (63%)] Loss: -774.175293\n",
      "Train Epoch: 1103 [45056/54000 (83%)] Loss: -757.643677\n",
      "    epoch          : 1103\n",
      "    loss           : -760.3896864405218\n",
      "    ess            : 1.959301990158153\n",
      "    log_marginal   : 760.4268263330999\n",
      "    log_joint      : 968.9238517329378\n",
      "    val_loss       : -764.603505452474\n",
      "    val_ess        : 1.9596412777900696\n",
      "    val_log_marginal: 764.6378784179688\n",
      "    val_log_joint  : 973.1159261067709\n",
      "Train Epoch: 1104 [0/54000 (0%)] Loss: -755.022400\n",
      "Train Epoch: 1104 [11264/54000 (21%)] Loss: -788.000732\n",
      "Train Epoch: 1104 [22528/54000 (42%)] Loss: -754.832153\n",
      "Train Epoch: 1104 [33792/54000 (63%)] Loss: -736.754028\n",
      "Train Epoch: 1104 [45056/54000 (83%)] Loss: -758.319702\n",
      "    epoch          : 1104\n",
      "    loss           : -760.32966009176\n",
      "    ess            : 1.9608117004610457\n",
      "    log_marginal   : 760.364391974683\n",
      "    log_joint      : 968.9261797059257\n",
      "    val_loss       : -764.7875111897787\n",
      "    val_ess        : 1.960439403851827\n",
      "    val_log_marginal: 764.8210906982422\n",
      "    val_log_joint  : 973.3290761311849\n",
      "Train Epoch: 1105 [0/54000 (0%)] Loss: -753.486450\n",
      "Train Epoch: 1105 [11264/54000 (21%)] Loss: -769.111267\n",
      "Train Epoch: 1105 [22528/54000 (42%)] Loss: -757.829468\n",
      "Train Epoch: 1105 [33792/54000 (63%)] Loss: -763.429810\n",
      "Train Epoch: 1105 [45056/54000 (83%)] Loss: -769.013062\n",
      "    epoch          : 1105\n",
      "    loss           : -760.25223238963\n",
      "    ess            : 1.9593370680539113\n",
      "    log_marginal   : 760.2891517495209\n",
      "    log_joint      : 968.7623912883255\n",
      "    val_loss       : -764.8032379150391\n",
      "    val_ess        : 1.958415041367213\n",
      "    val_log_marginal: 764.8417409261068\n",
      "    val_log_joint  : 973.4416453043619\n",
      "Train Epoch: 1106 [0/54000 (0%)] Loss: -779.423767\n",
      "Train Epoch: 1106 [11264/54000 (21%)] Loss: -764.639893\n",
      "Train Epoch: 1106 [22528/54000 (42%)] Loss: -761.171143\n",
      "Train Epoch: 1106 [33792/54000 (63%)] Loss: -767.594482\n",
      "Train Epoch: 1106 [45056/54000 (83%)] Loss: -752.437744\n",
      "    epoch          : 1106\n",
      "    loss           : -760.4808240206736\n",
      "    ess            : 1.9597275853157043\n",
      "    log_marginal   : 760.5180543143795\n",
      "    log_joint      : 969.001843146558\n",
      "    val_loss       : -765.1365000406901\n",
      "    val_ess        : 1.959468940893809\n",
      "    val_log_marginal: 765.1735229492188\n",
      "    val_log_joint  : 973.7217966715494\n",
      "Train Epoch: 1107 [0/54000 (0%)] Loss: -752.544739\n",
      "Train Epoch: 1107 [11264/54000 (21%)] Loss: -751.582397\n",
      "Train Epoch: 1107 [22528/54000 (42%)] Loss: -769.252380\n",
      "Train Epoch: 1107 [33792/54000 (63%)] Loss: -765.076782\n",
      "Train Epoch: 1107 [45056/54000 (83%)] Loss: -779.056396\n",
      "    epoch          : 1107\n",
      "    loss           : -760.5649788334684\n",
      "    ess            : 1.9600337777497634\n",
      "    log_marginal   : 760.6009216308594\n",
      "    log_joint      : 969.1276043586012\n",
      "    val_loss       : -764.0126342773438\n",
      "    val_ess        : 1.959918389717738\n",
      "    val_log_marginal: 764.0472056070963\n",
      "    val_log_joint  : 972.5464579264323\n",
      "Train Epoch: 1108 [0/54000 (0%)] Loss: -756.834595\n",
      "Train Epoch: 1108 [11264/54000 (21%)] Loss: -760.991333\n",
      "Train Epoch: 1108 [22528/54000 (42%)] Loss: -734.087891\n",
      "Train Epoch: 1108 [33792/54000 (63%)] Loss: -767.957886\n",
      "Train Epoch: 1108 [45056/54000 (83%)] Loss: -760.208252\n",
      "    epoch          : 1108\n",
      "    loss           : -760.3656345583358\n",
      "    ess            : 1.9594759884870276\n",
      "    log_marginal   : 760.4029880739608\n",
      "    log_joint      : 968.9620954405586\n",
      "    val_loss       : -764.7448018391927\n",
      "    val_ess        : 1.9550353984038036\n",
      "    val_log_marginal: 764.7915293375651\n",
      "    val_log_joint  : 973.1162872314453\n",
      "Train Epoch: 1109 [0/54000 (0%)] Loss: -762.982056\n",
      "Train Epoch: 1109 [11264/54000 (21%)] Loss: -764.259888\n",
      "Train Epoch: 1109 [22528/54000 (42%)] Loss: -737.567871\n",
      "Train Epoch: 1109 [33792/54000 (63%)] Loss: -742.924072\n",
      "Train Epoch: 1109 [45056/54000 (83%)] Loss: -756.982300\n",
      "    epoch          : 1109\n",
      "    loss           : -760.3072181557709\n",
      "    ess            : 1.9614244452062644\n",
      "    log_marginal   : 760.3425960900648\n",
      "    log_joint      : 968.8519085578199\n",
      "    val_loss       : -764.9075876871744\n",
      "    val_ess        : 1.9603346288204193\n",
      "    val_log_marginal: 764.9410705566406\n",
      "    val_log_joint  : 973.5804646809896\n",
      "Train Epoch: 1110 [0/54000 (0%)] Loss: -768.153137\n",
      "Train Epoch: 1110 [11264/54000 (21%)] Loss: -754.780273\n",
      "Train Epoch: 1110 [22528/54000 (42%)] Loss: -742.059998\n",
      "Train Epoch: 1110 [33792/54000 (63%)] Loss: -734.303406\n",
      "Train Epoch: 1110 [45056/54000 (83%)] Loss: -749.093201\n",
      "    epoch          : 1110\n",
      "    loss           : -760.3729708689564\n",
      "    ess            : 1.959105965101494\n",
      "    log_marginal   : 760.4106191959021\n",
      "    log_joint      : 968.8833370568617\n",
      "    val_loss       : -765.2490844726562\n",
      "    val_ess        : 1.960214098294576\n",
      "    val_log_marginal: 765.2810719807943\n",
      "    val_log_joint  : 974.1089782714844\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1110.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1111 [0/54000 (0%)] Loss: -771.543945\n",
      "Train Epoch: 1111 [11264/54000 (21%)] Loss: -762.011536\n",
      "Train Epoch: 1111 [22528/54000 (42%)] Loss: -755.819153\n",
      "Train Epoch: 1111 [33792/54000 (63%)] Loss: -771.707947\n",
      "Train Epoch: 1111 [45056/54000 (83%)] Loss: -763.698975\n",
      "    epoch          : 1111\n",
      "    loss           : -760.5552022682047\n",
      "    ess            : 1.9599758442842736\n",
      "    log_marginal   : 760.5926910976194\n",
      "    log_joint      : 969.0035175827314\n",
      "    val_loss       : -765.8290659586588\n",
      "    val_ess        : 1.9628615379333496\n",
      "    val_log_marginal: 765.8613332112631\n",
      "    val_log_joint  : 974.2065073649088\n",
      "Train Epoch: 1112 [0/54000 (0%)] Loss: -764.570557\n",
      "Train Epoch: 1112 [11264/54000 (21%)] Loss: -768.557068\n",
      "Train Epoch: 1112 [22528/54000 (42%)] Loss: -737.562988\n",
      "Train Epoch: 1112 [33792/54000 (63%)] Loss: -765.912109\n",
      "Train Epoch: 1112 [45056/54000 (83%)] Loss: -726.815796\n",
      "    epoch          : 1112\n",
      "    loss           : -760.642033990824\n",
      "    ess            : 1.9602678553113397\n",
      "    log_marginal   : 760.6782422335642\n",
      "    log_joint      : 969.1863455142615\n",
      "    val_loss       : -765.0338439941406\n",
      "    val_ess        : 1.9614208439985912\n",
      "    val_log_marginal: 765.0675099690756\n",
      "    val_log_joint  : 973.3817545572916\n",
      "Train Epoch: 1113 [0/54000 (0%)] Loss: -760.077148\n",
      "Train Epoch: 1113 [11264/54000 (21%)] Loss: -760.766724\n",
      "Train Epoch: 1113 [22528/54000 (42%)] Loss: -733.861816\n",
      "Train Epoch: 1113 [33792/54000 (63%)] Loss: -752.122864\n",
      "Train Epoch: 1113 [45056/54000 (83%)] Loss: -754.516052\n",
      "    epoch          : 1113\n",
      "    loss           : -760.6627865197523\n",
      "    ess            : 1.9588374113136868\n",
      "    log_marginal   : 760.7007590239903\n",
      "    log_joint      : 969.24539645213\n",
      "    val_loss       : -765.2376403808594\n",
      "    val_ess        : 1.9574590822060902\n",
      "    val_log_marginal: 765.2768096923828\n",
      "    val_log_joint  : 973.9484710693359\n",
      "Train Epoch: 1114 [0/54000 (0%)] Loss: -778.495422\n",
      "Train Epoch: 1114 [11264/54000 (21%)] Loss: -778.770020\n",
      "Train Epoch: 1114 [22528/54000 (42%)] Loss: -736.101807\n",
      "Train Epoch: 1114 [33792/54000 (63%)] Loss: -766.676758\n",
      "Train Epoch: 1114 [45056/54000 (83%)] Loss: -759.277100\n",
      "    epoch          : 1114\n",
      "    loss           : -760.601682267099\n",
      "    ess            : 1.9604466748687457\n",
      "    log_marginal   : 760.638063826651\n",
      "    log_joint      : 969.2488201789137\n",
      "    val_loss       : -765.9431915283203\n",
      "    val_ess        : 1.95997820297877\n",
      "    val_log_marginal: 765.9752502441406\n",
      "    val_log_joint  : 974.1211242675781\n",
      "Train Epoch: 1115 [0/54000 (0%)] Loss: -778.964111\n",
      "Train Epoch: 1115 [11264/54000 (21%)] Loss: -753.544678\n",
      "Train Epoch: 1115 [22528/54000 (42%)] Loss: -766.373535\n",
      "Train Epoch: 1115 [33792/54000 (63%)] Loss: -787.153503\n",
      "Train Epoch: 1115 [45056/54000 (83%)] Loss: -759.828491\n",
      "    epoch          : 1115\n",
      "    loss           : -760.9253021816038\n",
      "    ess            : 1.9601245522499084\n",
      "    log_marginal   : 760.9611188780586\n",
      "    log_joint      : 969.3818589696344\n",
      "    val_loss       : -765.4158121744791\n",
      "    val_ess        : 1.9620011746883392\n",
      "    val_log_marginal: 765.4527537027994\n",
      "    val_log_joint  : 973.8787282307943\n",
      "Train Epoch: 1116 [0/54000 (0%)] Loss: -768.041016\n",
      "Train Epoch: 1116 [11264/54000 (21%)] Loss: -785.183472\n",
      "Train Epoch: 1116 [22528/54000 (42%)] Loss: -770.576294\n",
      "Train Epoch: 1116 [33792/54000 (63%)] Loss: -731.075012\n",
      "Train Epoch: 1116 [45056/54000 (83%)] Loss: -761.251099\n",
      "    epoch          : 1116\n",
      "    loss           : -760.9551708293411\n",
      "    ess            : 1.9608164845772509\n",
      "    log_marginal   : 760.9913664044075\n",
      "    log_joint      : 969.5556473642025\n",
      "    val_loss       : -764.8330027262369\n",
      "    val_ess        : 1.9600618680318196\n",
      "    val_log_marginal: 764.8702290852865\n",
      "    val_log_joint  : 973.4362284342448\n",
      "Train Epoch: 1117 [0/54000 (0%)] Loss: -782.473267\n",
      "Train Epoch: 1117 [11264/54000 (21%)] Loss: -754.790161\n",
      "Train Epoch: 1117 [22528/54000 (42%)] Loss: -756.857605\n",
      "Train Epoch: 1117 [33792/54000 (63%)] Loss: -764.176270\n",
      "Train Epoch: 1117 [45056/54000 (83%)] Loss: -746.169006\n",
      "    epoch          : 1117\n",
      "    loss           : -761.0189802061836\n",
      "    ess            : 1.9602913912737145\n",
      "    log_marginal   : 761.0552569695238\n",
      "    log_joint      : 969.5377352732532\n",
      "    val_loss       : -765.5555979410807\n",
      "    val_ess        : 1.9623816311359406\n",
      "    val_log_marginal: 765.587656656901\n",
      "    val_log_joint  : 973.9400482177734\n",
      "Train Epoch: 1118 [0/54000 (0%)] Loss: -761.357178\n",
      "Train Epoch: 1118 [11264/54000 (21%)] Loss: -738.112671\n",
      "Train Epoch: 1118 [22528/54000 (42%)] Loss: -758.245056\n",
      "Train Epoch: 1118 [33792/54000 (63%)] Loss: -746.756958\n",
      "Train Epoch: 1118 [45056/54000 (83%)] Loss: -761.216675\n",
      "    epoch          : 1118\n",
      "    loss           : -761.0396728515625\n",
      "    ess            : 1.96036925180903\n",
      "    log_marginal   : 761.075460182046\n",
      "    log_joint      : 969.5807702406397\n",
      "    val_loss       : -764.9959462483724\n",
      "    val_ess        : 1.9636990229288738\n",
      "    val_log_marginal: 765.0298258463541\n",
      "    val_log_joint  : 973.3600463867188\n",
      "Train Epoch: 1119 [0/54000 (0%)] Loss: -756.959229\n",
      "Train Epoch: 1119 [11264/54000 (21%)] Loss: -767.063416\n",
      "Train Epoch: 1119 [22528/54000 (42%)] Loss: -768.121582\n",
      "Train Epoch: 1119 [33792/54000 (63%)] Loss: -757.437256\n",
      "Train Epoch: 1119 [45056/54000 (83%)] Loss: -772.452026\n",
      "    epoch          : 1119\n",
      "    loss           : -761.0430441802403\n",
      "    ess            : 1.9605870314364164\n",
      "    log_marginal   : 761.0799865722656\n",
      "    log_joint      : 969.5911508236292\n",
      "    val_loss       : -764.8310750325521\n",
      "    val_ess        : 1.9621408780415852\n",
      "    val_log_marginal: 764.8636830647787\n",
      "    val_log_joint  : 973.4906005859375\n",
      "Train Epoch: 1120 [0/54000 (0%)] Loss: -769.448425\n",
      "Train Epoch: 1120 [11264/54000 (21%)] Loss: -760.446655\n",
      "Train Epoch: 1120 [22528/54000 (42%)] Loss: -766.671265\n",
      "Train Epoch: 1120 [33792/54000 (63%)] Loss: -766.389709\n",
      "Train Epoch: 1120 [45056/54000 (83%)] Loss: -753.337769\n",
      "    epoch          : 1120\n",
      "    loss           : -761.0621268794222\n",
      "    ess            : 1.9594018481812387\n",
      "    log_marginal   : 761.0993162910893\n",
      "    log_joint      : 969.6286448352741\n",
      "    val_loss       : -765.1922403971354\n",
      "    val_ess        : 1.9615939160188038\n",
      "    val_log_marginal: 765.2293141682943\n",
      "    val_log_joint  : 973.9208272298177\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1120.pth ...\n",
      "Train Epoch: 1121 [0/54000 (0%)] Loss: -743.028320\n",
      "Train Epoch: 1121 [11264/54000 (21%)] Loss: -762.442261\n",
      "Train Epoch: 1121 [22528/54000 (42%)] Loss: -745.694580\n",
      "Train Epoch: 1121 [33792/54000 (63%)] Loss: -773.590942\n",
      "Train Epoch: 1121 [45056/54000 (83%)] Loss: -754.792908\n",
      "    epoch          : 1121\n",
      "    loss           : -761.0452230201578\n",
      "    ess            : 1.9588332716024146\n",
      "    log_marginal   : 761.0823122420401\n",
      "    log_joint      : 969.6751127422981\n",
      "    val_loss       : -765.6831563313802\n",
      "    val_ess        : 1.9633542398611705\n",
      "    val_log_marginal: 765.7149200439453\n",
      "    val_log_joint  : 974.2737630208334\n",
      "Train Epoch: 1122 [0/54000 (0%)] Loss: -762.926025\n",
      "Train Epoch: 1122 [11264/54000 (21%)] Loss: -782.531799\n",
      "Train Epoch: 1122 [22528/54000 (42%)] Loss: -761.815918\n",
      "Train Epoch: 1122 [33792/54000 (63%)] Loss: -775.922363\n",
      "Train Epoch: 1122 [45056/54000 (83%)] Loss: -788.795410\n",
      "    epoch          : 1122\n",
      "    loss           : -761.1155896456736\n",
      "    ess            : 1.9592946250483674\n",
      "    log_marginal   : 761.1539957298422\n",
      "    log_joint      : 969.8271484375\n",
      "    val_loss       : -765.5584208170573\n",
      "    val_ess        : 1.9605092604955037\n",
      "    val_log_marginal: 765.5960845947266\n",
      "    val_log_joint  : 974.3995005289713\n",
      "Train Epoch: 1123 [0/54000 (0%)] Loss: -755.574280\n",
      "Train Epoch: 1123 [11264/54000 (21%)] Loss: -780.783569\n",
      "Train Epoch: 1123 [22528/54000 (42%)] Loss: -781.628235\n",
      "Train Epoch: 1123 [33792/54000 (63%)] Loss: -772.248718\n",
      "Train Epoch: 1123 [45056/54000 (83%)] Loss: -770.697327\n",
      "    epoch          : 1123\n",
      "    loss           : -761.2999446077167\n",
      "    ess            : 1.9605790995201975\n",
      "    log_marginal   : 761.3369560961453\n",
      "    log_joint      : 969.8201190300707\n",
      "    val_loss       : -765.3762461344401\n",
      "    val_ess        : 1.9619865814844768\n",
      "    val_log_marginal: 765.4093882242838\n",
      "    val_log_joint  : 973.8847961425781\n",
      "Train Epoch: 1124 [0/54000 (0%)] Loss: -746.603516\n",
      "Train Epoch: 1124 [11264/54000 (21%)] Loss: -752.290771\n",
      "Train Epoch: 1124 [22528/54000 (42%)] Loss: -765.456421\n",
      "Train Epoch: 1124 [33792/54000 (63%)] Loss: -732.593262\n",
      "Train Epoch: 1124 [45056/54000 (83%)] Loss: -765.495361\n",
      "    epoch          : 1124\n",
      "    loss           : -761.4085560924602\n",
      "    ess            : 1.960082012527394\n",
      "    log_marginal   : 761.4459568239608\n",
      "    log_joint      : 969.8849671561763\n",
      "    val_loss       : -765.3958638509115\n",
      "    val_ess        : 1.9609405795733135\n",
      "    val_log_marginal: 765.4312337239584\n",
      "    val_log_joint  : 973.8989868164062\n",
      "Train Epoch: 1125 [0/54000 (0%)] Loss: -764.165955\n",
      "Train Epoch: 1125 [11264/54000 (21%)] Loss: -766.347656\n",
      "Train Epoch: 1125 [22528/54000 (42%)] Loss: -759.306152\n",
      "Train Epoch: 1125 [33792/54000 (63%)] Loss: -747.942383\n",
      "Train Epoch: 1125 [45056/54000 (83%)] Loss: -764.169739\n",
      "    epoch          : 1125\n",
      "    loss           : -761.1783383927255\n",
      "    ess            : 1.9584243106392194\n",
      "    log_marginal   : 761.2179139335201\n",
      "    log_joint      : 969.7304773870504\n",
      "    val_loss       : -764.5044301350912\n",
      "    val_ess        : 1.9593859910964966\n",
      "    val_log_marginal: 764.5439860026041\n",
      "    val_log_joint  : 973.1602223714193\n",
      "Train Epoch: 1126 [0/54000 (0%)] Loss: -763.849121\n",
      "Train Epoch: 1126 [11264/54000 (21%)] Loss: -763.291443\n",
      "Train Epoch: 1126 [22528/54000 (42%)] Loss: -771.032532\n",
      "Train Epoch: 1126 [33792/54000 (63%)] Loss: -755.123108\n",
      "Train Epoch: 1126 [45056/54000 (83%)] Loss: -761.381897\n",
      "    epoch          : 1126\n",
      "    loss           : -761.4344574550413\n",
      "    ess            : 1.9590986382286504\n",
      "    log_marginal   : 761.4734819520195\n",
      "    log_joint      : 970.1166393352005\n",
      "    val_loss       : -765.07958984375\n",
      "    val_ess        : 1.9602498014767964\n",
      "    val_log_marginal: 765.1153361002604\n",
      "    val_log_joint  : 973.4937032063802\n",
      "Train Epoch: 1127 [0/54000 (0%)] Loss: -748.217712\n",
      "Train Epoch: 1127 [11264/54000 (21%)] Loss: -756.808411\n",
      "Train Epoch: 1127 [22528/54000 (42%)] Loss: -738.623779\n",
      "Train Epoch: 1127 [33792/54000 (63%)] Loss: -737.870544\n",
      "Train Epoch: 1127 [45056/54000 (83%)] Loss: -782.310547\n",
      "    epoch          : 1127\n",
      "    loss           : -761.4334762861143\n",
      "    ess            : 1.9601129979457494\n",
      "    log_marginal   : 761.4707134894605\n",
      "    log_joint      : 970.1526241662367\n",
      "    val_loss       : -766.0466003417969\n",
      "    val_ess        : 1.961305300394694\n",
      "    val_log_marginal: 766.0840657552084\n",
      "    val_log_joint  : 974.5535329182943\n",
      "Train Epoch: 1128 [0/54000 (0%)] Loss: -760.268555\n",
      "Train Epoch: 1128 [11264/54000 (21%)] Loss: -749.941650\n",
      "Train Epoch: 1128 [22528/54000 (42%)] Loss: -732.530090\n",
      "Train Epoch: 1128 [33792/54000 (63%)] Loss: -754.066650\n",
      "Train Epoch: 1128 [45056/54000 (83%)] Loss: -763.985596\n",
      "    epoch          : 1128\n",
      "    loss           : -761.5022761506855\n",
      "    ess            : 1.9591707058672636\n",
      "    log_marginal   : 761.5399457823555\n",
      "    log_joint      : 970.1304989220961\n",
      "    val_loss       : -764.4004364013672\n",
      "    val_ess        : 1.9624103804429371\n",
      "    val_log_marginal: 764.4341684977213\n",
      "    val_log_joint  : 973.2725372314453\n",
      "Train Epoch: 1129 [0/54000 (0%)] Loss: -766.990662\n",
      "Train Epoch: 1129 [11264/54000 (21%)] Loss: -751.762451\n",
      "Train Epoch: 1129 [22528/54000 (42%)] Loss: -752.214050\n",
      "Train Epoch: 1129 [33792/54000 (63%)] Loss: -767.257202\n",
      "Train Epoch: 1129 [45056/54000 (83%)] Loss: -782.302673\n",
      "    epoch          : 1129\n",
      "    loss           : -761.6175260723762\n",
      "    ess            : 1.9605786485492058\n",
      "    log_marginal   : 761.6551104851488\n",
      "    log_joint      : 970.2131428268721\n",
      "    val_loss       : -766.0288747151693\n",
      "    val_ess        : 1.9609203934669495\n",
      "    val_log_marginal: 766.0636596679688\n",
      "    val_log_joint  : 974.4017995198568\n",
      "Train Epoch: 1130 [0/54000 (0%)] Loss: -747.864990\n",
      "Train Epoch: 1130 [11264/54000 (21%)] Loss: -776.290527\n",
      "Train Epoch: 1130 [22528/54000 (42%)] Loss: -753.885315\n",
      "Train Epoch: 1130 [33792/54000 (63%)] Loss: -759.079468\n",
      "Train Epoch: 1130 [45056/54000 (83%)] Loss: -768.123901\n",
      "    epoch          : 1130\n",
      "    loss           : -761.6896719302771\n",
      "    ess            : 1.9601969100394339\n",
      "    log_marginal   : 761.7261266168558\n",
      "    log_joint      : 970.2450348476194\n",
      "    val_loss       : -765.5168304443359\n",
      "    val_ess        : 1.957934965689977\n",
      "    val_log_marginal: 765.5538736979166\n",
      "    val_log_joint  : 974.0294850667318\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1130.pth ...\n",
      "Train Epoch: 1131 [0/54000 (0%)] Loss: -767.699951\n",
      "Train Epoch: 1131 [11264/54000 (21%)] Loss: -754.270142\n",
      "Train Epoch: 1131 [22528/54000 (42%)] Loss: -768.967529\n",
      "Train Epoch: 1131 [33792/54000 (63%)] Loss: -741.362122\n",
      "Train Epoch: 1131 [45056/54000 (83%)] Loss: -783.827393\n",
      "    epoch          : 1131\n",
      "    loss           : -761.536767923607\n",
      "    ess            : 1.9596977053948168\n",
      "    log_marginal   : 761.5736498562795\n",
      "    log_joint      : 970.0997107163915\n",
      "    val_loss       : -766.1349283854166\n",
      "    val_ess        : 1.9569622377554576\n",
      "    val_log_marginal: 766.1753997802734\n",
      "    val_log_joint  : 974.5655161539713\n",
      "Train Epoch: 1132 [0/54000 (0%)] Loss: -769.044556\n",
      "Train Epoch: 1132 [11264/54000 (21%)] Loss: -788.410583\n",
      "Train Epoch: 1132 [22528/54000 (42%)] Loss: -735.283447\n",
      "Train Epoch: 1132 [33792/54000 (63%)] Loss: -760.766968\n",
      "Train Epoch: 1132 [45056/54000 (83%)] Loss: -771.647095\n",
      "    epoch          : 1132\n",
      "    loss           : -761.7105776228995\n",
      "    ess            : 1.9604662150706884\n",
      "    log_marginal   : 761.7475447744694\n",
      "    log_joint      : 970.2084419682341\n",
      "    val_loss       : -765.8554077148438\n",
      "    val_ess        : 1.9601275324821472\n",
      "    val_log_marginal: 765.8890940348307\n",
      "    val_log_joint  : 974.2971649169922\n",
      "Train Epoch: 1133 [0/54000 (0%)] Loss: -746.830017\n",
      "Train Epoch: 1133 [11264/54000 (21%)] Loss: -763.919189\n",
      "Train Epoch: 1133 [22528/54000 (42%)] Loss: -775.717407\n",
      "Train Epoch: 1133 [33792/54000 (63%)] Loss: -771.286682\n",
      "Train Epoch: 1133 [45056/54000 (83%)] Loss: -763.620117\n",
      "    epoch          : 1133\n",
      "    loss           : -761.6974660045696\n",
      "    ess            : 1.9609407231492817\n",
      "    log_marginal   : 761.7325410662957\n",
      "    log_joint      : 970.1784178535893\n",
      "    val_loss       : -765.3241526285807\n",
      "    val_ess        : 1.9572163621584575\n",
      "    val_log_marginal: 765.3638356526693\n",
      "    val_log_joint  : 973.9593353271484\n",
      "Train Epoch: 1134 [0/54000 (0%)] Loss: -754.504089\n",
      "Train Epoch: 1134 [11264/54000 (21%)] Loss: -732.696655\n",
      "Train Epoch: 1134 [22528/54000 (42%)] Loss: -764.582520\n",
      "Train Epoch: 1134 [33792/54000 (63%)] Loss: -768.325806\n",
      "Train Epoch: 1134 [45056/54000 (83%)] Loss: -769.493408\n",
      "    epoch          : 1134\n",
      "    loss           : -761.8966058695091\n",
      "    ess            : 1.9590007932680957\n",
      "    log_marginal   : 761.9341361567659\n",
      "    log_joint      : 970.3583742537588\n",
      "    val_loss       : -765.9796651204427\n",
      "    val_ess        : 1.956710586945216\n",
      "    val_log_marginal: 766.0205739339193\n",
      "    val_log_joint  : 974.4903157552084\n",
      "Train Epoch: 1135 [0/54000 (0%)] Loss: -772.153870\n",
      "Train Epoch: 1135 [11264/54000 (21%)] Loss: -777.922607\n",
      "Train Epoch: 1135 [22528/54000 (42%)] Loss: -793.025391\n",
      "Train Epoch: 1135 [33792/54000 (63%)] Loss: -764.093628\n",
      "Train Epoch: 1135 [45056/54000 (83%)] Loss: -741.017090\n",
      "    epoch          : 1135\n",
      "    loss           : -761.8626248341686\n",
      "    ess            : 1.9588662003571133\n",
      "    log_marginal   : 761.901290605653\n",
      "    log_joint      : 970.3711449964991\n",
      "    val_loss       : -765.9986216227213\n",
      "    val_ess        : 1.9609888692696889\n",
      "    val_log_marginal: 766.0338389078776\n",
      "    val_log_joint  : 974.7808736165365\n",
      "Train Epoch: 1136 [0/54000 (0%)] Loss: -760.805115\n",
      "Train Epoch: 1136 [11264/54000 (21%)] Loss: -751.907471\n",
      "Train Epoch: 1136 [22528/54000 (42%)] Loss: -763.222412\n",
      "Train Epoch: 1136 [33792/54000 (63%)] Loss: -765.275024\n",
      "Train Epoch: 1136 [45056/54000 (83%)] Loss: -771.549072\n",
      "    epoch          : 1136\n",
      "    loss           : -761.8955383300781\n",
      "    ess            : 1.959155894675345\n",
      "    log_marginal   : 761.9347868145637\n",
      "    log_joint      : 970.4096409059921\n",
      "    val_loss       : -766.4789072672526\n",
      "    val_ess        : 1.9559345245361328\n",
      "    val_log_marginal: 766.5235036214193\n",
      "    val_log_joint  : 974.9122009277344\n",
      "Train Epoch: 1137 [0/54000 (0%)] Loss: -767.971558\n",
      "Train Epoch: 1137 [11264/54000 (21%)] Loss: -749.161255\n",
      "Train Epoch: 1137 [22528/54000 (42%)] Loss: -750.023804\n",
      "Train Epoch: 1137 [33792/54000 (63%)] Loss: -766.440491\n",
      "Train Epoch: 1137 [45056/54000 (83%)] Loss: -782.411011\n",
      "    epoch          : 1137\n",
      "    loss           : -761.8245014694502\n",
      "    ess            : 1.9600874781608582\n",
      "    log_marginal   : 761.8621808897774\n",
      "    log_joint      : 970.3899766454157\n",
      "    val_loss       : -766.3156127929688\n",
      "    val_ess        : 1.9578770697116852\n",
      "    val_log_marginal: 766.3535512288412\n",
      "    val_log_joint  : 974.8253224690756\n",
      "Train Epoch: 1138 [0/54000 (0%)] Loss: -761.036804\n",
      "Train Epoch: 1138 [11264/54000 (21%)] Loss: -780.689209\n",
      "Train Epoch: 1138 [22528/54000 (42%)] Loss: -768.597107\n",
      "Train Epoch: 1138 [33792/54000 (63%)] Loss: -738.559998\n",
      "Train Epoch: 1138 [45056/54000 (83%)] Loss: -765.073364\n",
      "    epoch          : 1138\n",
      "    loss           : -761.8045153347952\n",
      "    ess            : 1.9597398211371224\n",
      "    log_marginal   : 761.8408583155218\n",
      "    log_joint      : 970.3740084666126\n",
      "    val_loss       : -766.1316121419271\n",
      "    val_ess        : 1.962912340958913\n",
      "    val_log_marginal: 766.1600952148438\n",
      "    val_log_joint  : 974.7378184000651\n",
      "Train Epoch: 1139 [0/54000 (0%)] Loss: -749.542969\n",
      "Train Epoch: 1139 [11264/54000 (21%)] Loss: -761.734863\n",
      "Train Epoch: 1139 [22528/54000 (42%)] Loss: -775.955078\n",
      "Train Epoch: 1139 [33792/54000 (63%)] Loss: -748.141541\n",
      "Train Epoch: 1139 [45056/54000 (83%)] Loss: -752.581177\n",
      "    epoch          : 1139\n",
      "    loss           : -761.8254279370578\n",
      "    ess            : 1.9598566406178024\n",
      "    log_marginal   : 761.8602864967203\n",
      "    log_joint      : 970.3391648778376\n",
      "    val_loss       : -766.2489369710287\n",
      "    val_ess        : 1.9604388078053792\n",
      "    val_log_marginal: 766.2833862304688\n",
      "    val_log_joint  : 974.8733113606771\n",
      "Train Epoch: 1140 [0/54000 (0%)] Loss: -757.412231\n",
      "Train Epoch: 1140 [11264/54000 (21%)] Loss: -759.990479\n",
      "Train Epoch: 1140 [22528/54000 (42%)] Loss: -774.719604\n",
      "Train Epoch: 1140 [33792/54000 (63%)] Loss: -750.121582\n",
      "Train Epoch: 1140 [45056/54000 (83%)] Loss: -759.868652\n",
      "    epoch          : 1140\n",
      "    loss           : -762.1613873175855\n",
      "    ess            : 1.9604356030248247\n",
      "    log_marginal   : 762.1979347085053\n",
      "    log_joint      : 970.6275053204231\n",
      "    val_loss       : -765.6324615478516\n",
      "    val_ess        : 1.960668553908666\n",
      "    val_log_marginal: 765.6652475992838\n",
      "    val_log_joint  : 974.3927663167318\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1140.pth ...\n",
      "Train Epoch: 1141 [0/54000 (0%)] Loss: -785.316650\n",
      "Train Epoch: 1141 [11264/54000 (21%)] Loss: -761.113647\n",
      "Train Epoch: 1141 [22528/54000 (42%)] Loss: -751.575073\n",
      "Train Epoch: 1141 [33792/54000 (63%)] Loss: -743.384033\n",
      "Train Epoch: 1141 [45056/54000 (83%)] Loss: -753.912292\n",
      "    epoch          : 1141\n",
      "    loss           : -762.048536192696\n",
      "    ess            : 1.9591595125648211\n",
      "    log_marginal   : 762.0861758825914\n",
      "    log_joint      : 970.5619328336895\n",
      "    val_loss       : -766.2062835693359\n",
      "    val_ess        : 1.9613876541455586\n",
      "    val_log_marginal: 766.242909749349\n",
      "    val_log_joint  : 974.8606516520182\n",
      "Train Epoch: 1142 [0/54000 (0%)] Loss: -762.118774\n",
      "Train Epoch: 1142 [11264/54000 (21%)] Loss: -756.708252\n",
      "Train Epoch: 1142 [22528/54000 (42%)] Loss: -778.542969\n",
      "Train Epoch: 1142 [33792/54000 (63%)] Loss: -741.283508\n",
      "Train Epoch: 1142 [45056/54000 (83%)] Loss: -738.381226\n",
      "    epoch          : 1142\n",
      "    loss           : -762.0073391896374\n",
      "    ess            : 1.960389178878856\n",
      "    log_marginal   : 762.0441710274174\n",
      "    log_joint      : 970.5676240741082\n",
      "    val_loss       : -766.5427500406901\n",
      "    val_ess        : 1.9605986575285594\n",
      "    val_log_marginal: 766.5807240804037\n",
      "    val_log_joint  : 975.1760864257812\n",
      "Train Epoch: 1143 [0/54000 (0%)] Loss: -747.737854\n",
      "Train Epoch: 1143 [11264/54000 (21%)] Loss: -761.600342\n",
      "Train Epoch: 1143 [22528/54000 (42%)] Loss: -758.529541\n",
      "Train Epoch: 1143 [33792/54000 (63%)] Loss: -771.088074\n",
      "Train Epoch: 1143 [45056/54000 (83%)] Loss: -743.437317\n",
      "    epoch          : 1143\n",
      "    loss           : -762.2437916881634\n",
      "    ess            : 1.9595669676672738\n",
      "    log_marginal   : 762.2809206404776\n",
      "    log_joint      : 970.8493496876843\n",
      "    val_loss       : -765.7975260416666\n",
      "    val_ess        : 1.9619909524917603\n",
      "    val_log_marginal: 765.8317921956381\n",
      "    val_log_joint  : 974.3706359863281\n",
      "Train Epoch: 1144 [0/54000 (0%)] Loss: -768.809631\n",
      "Train Epoch: 1144 [11264/54000 (21%)] Loss: -775.193542\n",
      "Train Epoch: 1144 [22528/54000 (42%)] Loss: -749.124878\n",
      "Train Epoch: 1144 [33792/54000 (63%)] Loss: -774.115723\n",
      "Train Epoch: 1144 [45056/54000 (83%)] Loss: -756.389648\n",
      "    epoch          : 1144\n",
      "    loss           : -762.3103620421211\n",
      "    ess            : 1.9602217291885953\n",
      "    log_marginal   : 762.3459973605173\n",
      "    log_joint      : 970.8108457169443\n",
      "    val_loss       : -766.6474660237631\n",
      "    val_ess        : 1.9592658181985219\n",
      "    val_log_marginal: 766.6845550537109\n",
      "    val_log_joint  : 975.1684926350912\n",
      "Train Epoch: 1145 [0/54000 (0%)] Loss: -750.741638\n",
      "Train Epoch: 1145 [11264/54000 (21%)] Loss: -765.123047\n",
      "Train Epoch: 1145 [22528/54000 (42%)] Loss: -751.257812\n",
      "Train Epoch: 1145 [33792/54000 (63%)] Loss: -769.313354\n",
      "Train Epoch: 1145 [45056/54000 (83%)] Loss: -766.446106\n",
      "    epoch          : 1145\n",
      "    loss           : -762.1412687481575\n",
      "    ess            : 1.9598526448573705\n",
      "    log_marginal   : 762.1779600899174\n",
      "    log_joint      : 970.770321252211\n",
      "    val_loss       : -767.0969085693359\n",
      "    val_ess        : 1.9607750872770946\n",
      "    val_log_marginal: 767.1336720784506\n",
      "    val_log_joint  : 975.2963053385416\n",
      "Train Epoch: 1146 [0/54000 (0%)] Loss: -763.053589\n",
      "Train Epoch: 1146 [11264/54000 (21%)] Loss: -753.738525\n",
      "Train Epoch: 1146 [22528/54000 (42%)] Loss: -739.761658\n",
      "Train Epoch: 1146 [33792/54000 (63%)] Loss: -788.077637\n",
      "Train Epoch: 1146 [45056/54000 (83%)] Loss: -755.219543\n",
      "    epoch          : 1146\n",
      "    loss           : -762.280254435989\n",
      "    ess            : 1.9605916727263972\n",
      "    log_marginal   : 762.3164425256117\n",
      "    log_joint      : 970.8588107127064\n",
      "    val_loss       : -766.4973500569662\n",
      "    val_ess        : 1.9603988826274872\n",
      "    val_log_marginal: 766.5343322753906\n",
      "    val_log_joint  : 974.9654591878256\n",
      "Train Epoch: 1147 [0/54000 (0%)] Loss: -783.736755\n",
      "Train Epoch: 1147 [11264/54000 (21%)] Loss: -754.417297\n",
      "Train Epoch: 1147 [22528/54000 (42%)] Loss: -735.285034\n",
      "Train Epoch: 1147 [33792/54000 (63%)] Loss: -756.278564\n",
      "Train Epoch: 1147 [45056/54000 (83%)] Loss: -761.282349\n",
      "    epoch          : 1147\n",
      "    loss           : -762.4724155641952\n",
      "    ess            : 1.9599116174679883\n",
      "    log_marginal   : 762.5098508438974\n",
      "    log_joint      : 971.0372400823629\n",
      "    val_loss       : -766.7941538492838\n",
      "    val_ess        : 1.9568725327650707\n",
      "    val_log_marginal: 766.8375905354818\n",
      "    val_log_joint  : 975.4796600341797\n",
      "Train Epoch: 1148 [0/54000 (0%)] Loss: -802.023682\n",
      "Train Epoch: 1148 [11264/54000 (21%)] Loss: -720.499878\n",
      "Train Epoch: 1148 [22528/54000 (42%)] Loss: -761.390503\n",
      "Train Epoch: 1148 [33792/54000 (63%)] Loss: -781.398987\n",
      "Train Epoch: 1148 [45056/54000 (83%)] Loss: -746.383423\n",
      "    epoch          : 1148\n",
      "    loss           : -762.5084274579893\n",
      "    ess            : 1.960534465762804\n",
      "    log_marginal   : 762.545429157761\n",
      "    log_joint      : 971.0771254053656\n",
      "    val_loss       : -767.2547810872396\n",
      "    val_ess        : 1.959355225165685\n",
      "    val_log_marginal: 767.2938232421875\n",
      "    val_log_joint  : 975.8353271484375\n",
      "Train Epoch: 1149 [0/54000 (0%)] Loss: -753.576538\n",
      "Train Epoch: 1149 [11264/54000 (21%)] Loss: -764.853638\n",
      "Train Epoch: 1149 [22528/54000 (42%)] Loss: -767.208008\n",
      "Train Epoch: 1149 [33792/54000 (63%)] Loss: -758.158386\n",
      "Train Epoch: 1149 [45056/54000 (83%)] Loss: -776.458313\n",
      "    epoch          : 1149\n",
      "    loss           : -762.5109943893721\n",
      "    ess            : 1.9607325050066102\n",
      "    log_marginal   : 762.5468836370504\n",
      "    log_joint      : 971.0071986936173\n",
      "    val_loss       : -766.2203572591146\n",
      "    val_ess        : 1.96285018324852\n",
      "    val_log_marginal: 766.2552541097006\n",
      "    val_log_joint  : 974.9227396647135\n",
      "Train Epoch: 1150 [0/54000 (0%)] Loss: -769.068359\n",
      "Train Epoch: 1150 [11264/54000 (21%)] Loss: -753.862000\n",
      "Train Epoch: 1150 [22528/54000 (42%)] Loss: -734.981934\n",
      "Train Epoch: 1150 [33792/54000 (63%)] Loss: -777.697083\n",
      "Train Epoch: 1150 [45056/54000 (83%)] Loss: -748.338440\n",
      "    epoch          : 1150\n",
      "    loss           : -762.5839976184773\n",
      "    ess            : 1.9590802665026683\n",
      "    log_marginal   : 762.6221445911335\n",
      "    log_joint      : 971.046024538436\n",
      "    val_loss       : -766.7403615315756\n",
      "    val_ess        : 1.9580006897449493\n",
      "    val_log_marginal: 766.7763264973959\n",
      "    val_log_joint  : 975.0534973144531\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1150.pth ...\n",
      "Train Epoch: 1151 [0/54000 (0%)] Loss: -755.944824\n",
      "Train Epoch: 1151 [11264/54000 (21%)] Loss: -735.970093\n",
      "Train Epoch: 1151 [22528/54000 (42%)] Loss: -763.381165\n",
      "Train Epoch: 1151 [33792/54000 (63%)] Loss: -749.134644\n",
      "Train Epoch: 1151 [45056/54000 (83%)] Loss: -787.583008\n",
      "    epoch          : 1151\n",
      "    loss           : -762.4801330566406\n",
      "    ess            : 1.9583396180620734\n",
      "    log_marginal   : 762.5183013340212\n",
      "    log_joint      : 970.9784194658388\n",
      "    val_loss       : -766.3114725748698\n",
      "    val_ess        : 1.958892434835434\n",
      "    val_log_marginal: 766.3478749593099\n",
      "    val_log_joint  : 974.8624979654948\n",
      "Train Epoch: 1152 [0/54000 (0%)] Loss: -768.708618\n",
      "Train Epoch: 1152 [11264/54000 (21%)] Loss: -768.450562\n",
      "Train Epoch: 1152 [22528/54000 (42%)] Loss: -785.329102\n",
      "Train Epoch: 1152 [33792/54000 (63%)] Loss: -772.353760\n",
      "Train Epoch: 1152 [45056/54000 (83%)] Loss: -742.774048\n",
      "    epoch          : 1152\n",
      "    loss           : -762.6178053370062\n",
      "    ess            : 1.9596794146411824\n",
      "    log_marginal   : 762.6544747982385\n",
      "    log_joint      : 971.1725728736734\n",
      "    val_loss       : -766.5570271809896\n",
      "    val_ess        : 1.958630919456482\n",
      "    val_log_marginal: 766.5916849772135\n",
      "    val_log_joint  : 974.9683736165365\n",
      "Train Epoch: 1153 [0/54000 (0%)] Loss: -782.314148\n",
      "Train Epoch: 1153 [11264/54000 (21%)] Loss: -743.831787\n",
      "Train Epoch: 1153 [22528/54000 (42%)] Loss: -803.977905\n",
      "Train Epoch: 1153 [33792/54000 (63%)] Loss: -773.665161\n",
      "Train Epoch: 1153 [45056/54000 (83%)] Loss: -766.244202\n",
      "    epoch          : 1153\n",
      "    loss           : -762.445436873526\n",
      "    ess            : 1.9594022001860276\n",
      "    log_marginal   : 762.4822825305866\n",
      "    log_joint      : 970.966050058041\n",
      "    val_loss       : -766.5659891764323\n",
      "    val_ess        : 1.9630187650521596\n",
      "    val_log_marginal: 766.6000518798828\n",
      "    val_log_joint  : 975.1734924316406\n",
      "Train Epoch: 1154 [0/54000 (0%)] Loss: -764.061707\n",
      "Train Epoch: 1154 [11264/54000 (21%)] Loss: -767.611450\n",
      "Train Epoch: 1154 [22528/54000 (42%)] Loss: -776.673706\n",
      "Train Epoch: 1154 [33792/54000 (63%)] Loss: -750.529663\n",
      "Train Epoch: 1154 [45056/54000 (83%)] Loss: -775.456787\n",
      "    epoch          : 1154\n",
      "    loss           : -762.7278707252359\n",
      "    ess            : 1.9598425739216354\n",
      "    log_marginal   : 762.7641163951946\n",
      "    log_joint      : 971.2678976958653\n",
      "    val_loss       : -766.5674133300781\n",
      "    val_ess        : 1.9583376348018646\n",
      "    val_log_marginal: 766.6043701171875\n",
      "    val_log_joint  : 975.0379740397135\n",
      "Train Epoch: 1155 [0/54000 (0%)] Loss: -753.770264\n",
      "Train Epoch: 1155 [11264/54000 (21%)] Loss: -757.457886\n",
      "Train Epoch: 1155 [22528/54000 (42%)] Loss: -790.694458\n",
      "Train Epoch: 1155 [33792/54000 (63%)] Loss: -764.329712\n",
      "Train Epoch: 1155 [45056/54000 (83%)] Loss: -772.122375\n",
      "    epoch          : 1155\n",
      "    loss           : -762.8257273548054\n",
      "    ess            : 1.9596886016287893\n",
      "    log_marginal   : 762.8633566802403\n",
      "    log_joint      : 971.3545987111218\n",
      "    val_loss       : -766.6241912841797\n",
      "    val_ess        : 1.9617125292619069\n",
      "    val_log_marginal: 766.6594492594401\n",
      "    val_log_joint  : 975.3551991780599\n",
      "Train Epoch: 1156 [0/54000 (0%)] Loss: -749.174805\n",
      "Train Epoch: 1156 [11264/54000 (21%)] Loss: -770.109680\n",
      "Train Epoch: 1156 [22528/54000 (42%)] Loss: -773.281128\n",
      "Train Epoch: 1156 [33792/54000 (63%)] Loss: -745.699280\n",
      "Train Epoch: 1156 [45056/54000 (83%)] Loss: -778.047974\n",
      "    epoch          : 1156\n",
      "    loss           : -762.7292808676666\n",
      "    ess            : 1.9599340715498295\n",
      "    log_marginal   : 762.7660683685879\n",
      "    log_joint      : 971.2369494168264\n",
      "    val_loss       : -766.9498036702474\n",
      "    val_ess        : 1.9618148406346638\n",
      "    val_log_marginal: 766.9853820800781\n",
      "    val_log_joint  : 975.5842437744141\n",
      "Train Epoch: 1157 [0/54000 (0%)] Loss: -764.643433\n",
      "Train Epoch: 1157 [11264/54000 (21%)] Loss: -775.553101\n",
      "Train Epoch: 1157 [22528/54000 (42%)] Loss: -751.146179\n",
      "Train Epoch: 1157 [33792/54000 (63%)] Loss: -758.049011\n",
      "Train Epoch: 1157 [45056/54000 (83%)] Loss: -761.134094\n",
      "    epoch          : 1157\n",
      "    loss           : -762.9396034096771\n",
      "    ess            : 1.9608204792130668\n",
      "    log_marginal   : 762.9752698214548\n",
      "    log_joint      : 971.465534714033\n",
      "    val_loss       : -767.4045104980469\n",
      "    val_ess        : 1.9607987801233928\n",
      "    val_log_marginal: 767.4427490234375\n",
      "    val_log_joint  : 975.9182383219401\n",
      "Train Epoch: 1158 [0/54000 (0%)] Loss: -758.255737\n",
      "Train Epoch: 1158 [11264/54000 (21%)] Loss: -769.127441\n",
      "Train Epoch: 1158 [22528/54000 (42%)] Loss: -764.605408\n",
      "Train Epoch: 1158 [33792/54000 (63%)] Loss: -771.039673\n",
      "Train Epoch: 1158 [45056/54000 (83%)] Loss: -760.367188\n",
      "    epoch          : 1158\n",
      "    loss           : -762.9639633466612\n",
      "    ess            : 1.9596404601942818\n",
      "    log_marginal   : 763.0027586739018\n",
      "    log_joint      : 971.5321557386866\n",
      "    val_loss       : -766.9063161214193\n",
      "    val_ess        : 1.96128116051356\n",
      "    val_log_marginal: 766.9418690999349\n",
      "    val_log_joint  : 975.3201700846354\n",
      "Train Epoch: 1159 [0/54000 (0%)] Loss: -761.689697\n",
      "Train Epoch: 1159 [11264/54000 (21%)] Loss: -768.832520\n",
      "Train Epoch: 1159 [22528/54000 (42%)] Loss: -757.961670\n",
      "Train Epoch: 1159 [33792/54000 (63%)] Loss: -747.979248\n",
      "Train Epoch: 1159 [45056/54000 (83%)] Loss: -766.803162\n",
      "    epoch          : 1159\n",
      "    loss           : -762.9860834085716\n",
      "    ess            : 1.960240178513077\n",
      "    log_marginal   : 763.0232682138119\n",
      "    log_joint      : 971.585714088296\n",
      "    val_loss       : -766.6277262369791\n",
      "    val_ess        : 1.9621927241484325\n",
      "    val_log_marginal: 766.6594187418619\n",
      "    val_log_joint  : 975.0034586588541\n",
      "Train Epoch: 1160 [0/54000 (0%)] Loss: -753.100037\n",
      "Train Epoch: 1160 [11264/54000 (21%)] Loss: -750.170776\n",
      "Train Epoch: 1160 [22528/54000 (42%)] Loss: -768.357117\n",
      "Train Epoch: 1160 [33792/54000 (63%)] Loss: -760.631104\n",
      "Train Epoch: 1160 [45056/54000 (83%)] Loss: -753.428833\n",
      "    epoch          : 1160\n",
      "    loss           : -763.0935421349867\n",
      "    ess            : 1.9600387699199173\n",
      "    log_marginal   : 763.1311127284788\n",
      "    log_joint      : 971.553265841502\n",
      "    val_loss       : -766.7278188069662\n",
      "    val_ess        : 1.9608805775642395\n",
      "    val_log_marginal: 766.7618459065756\n",
      "    val_log_joint  : 975.3466237386068\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1160.pth ...\n",
      "Train Epoch: 1161 [0/54000 (0%)] Loss: -777.736572\n",
      "Train Epoch: 1161 [11264/54000 (21%)] Loss: -771.099060\n",
      "Train Epoch: 1161 [22528/54000 (42%)] Loss: -757.970581\n",
      "Train Epoch: 1161 [33792/54000 (63%)] Loss: -781.803223\n",
      "Train Epoch: 1161 [45056/54000 (83%)] Loss: -763.228271\n",
      "    epoch          : 1161\n",
      "    loss           : -762.70961142486\n",
      "    ess            : 1.9595889021765511\n",
      "    log_marginal   : 762.7470875866009\n",
      "    log_joint      : 971.3381364930351\n",
      "    val_loss       : -767.2531382242838\n",
      "    val_ess        : 1.9586990773677826\n",
      "    val_log_marginal: 767.2904154459635\n",
      "    val_log_joint  : 975.7797241210938\n",
      "Train Epoch: 1162 [0/54000 (0%)] Loss: -754.895325\n",
      "Train Epoch: 1162 [11264/54000 (21%)] Loss: -742.953064\n",
      "Train Epoch: 1162 [22528/54000 (42%)] Loss: -763.953064\n",
      "Train Epoch: 1162 [33792/54000 (63%)] Loss: -731.719299\n",
      "Train Epoch: 1162 [45056/54000 (83%)] Loss: -767.227112\n",
      "    epoch          : 1162\n",
      "    loss           : -763.0489858951208\n",
      "    ess            : 1.9580687644346706\n",
      "    log_marginal   : 763.088594256707\n",
      "    log_joint      : 971.615703654739\n",
      "    val_loss       : -766.8148040771484\n",
      "    val_ess        : 1.9570065140724182\n",
      "    val_log_marginal: 766.8554077148438\n",
      "    val_log_joint  : 975.6707458496094\n",
      "Train Epoch: 1163 [0/54000 (0%)] Loss: -773.259033\n",
      "Train Epoch: 1163 [11264/54000 (21%)] Loss: -773.686646\n",
      "Train Epoch: 1163 [22528/54000 (42%)] Loss: -758.024902\n",
      "Train Epoch: 1163 [33792/54000 (63%)] Loss: -766.332153\n",
      "Train Epoch: 1163 [45056/54000 (83%)] Loss: -764.121155\n",
      "    epoch          : 1163\n",
      "    loss           : -762.9818639215433\n",
      "    ess            : 1.9591446800051995\n",
      "    log_marginal   : 763.0194333634287\n",
      "    log_joint      : 971.4758145314343\n",
      "    val_loss       : -766.8832397460938\n",
      "    val_ess        : 1.9615851044654846\n",
      "    val_log_marginal: 766.9212443033854\n",
      "    val_log_joint  : 975.4287516276041\n",
      "Train Epoch: 1164 [0/54000 (0%)] Loss: -772.308960\n",
      "Train Epoch: 1164 [11264/54000 (21%)] Loss: -763.094910\n",
      "Train Epoch: 1164 [22528/54000 (42%)] Loss: -753.108215\n",
      "Train Epoch: 1164 [33792/54000 (63%)] Loss: -748.181335\n",
      "Train Epoch: 1164 [45056/54000 (83%)] Loss: -764.620117\n",
      "    epoch          : 1164\n",
      "    loss           : -762.9555140081442\n",
      "    ess            : 1.960957518163717\n",
      "    log_marginal   : 762.9902217073261\n",
      "    log_joint      : 971.4938918779482\n",
      "    val_loss       : -767.3138326009115\n",
      "    val_ess        : 1.9602815012137096\n",
      "    val_log_marginal: 767.3512369791666\n",
      "    val_log_joint  : 976.1679128011068\n",
      "Train Epoch: 1165 [0/54000 (0%)] Loss: -746.463745\n",
      "Train Epoch: 1165 [11264/54000 (21%)] Loss: -770.998962\n",
      "Train Epoch: 1165 [22528/54000 (42%)] Loss: -769.181641\n",
      "Train Epoch: 1165 [33792/54000 (63%)] Loss: -777.127869\n",
      "Train Epoch: 1165 [45056/54000 (83%)] Loss: -778.704163\n",
      "    epoch          : 1165\n",
      "    loss           : -763.155713927071\n",
      "    ess            : 1.9594675954782739\n",
      "    log_marginal   : 763.1927121720224\n",
      "    log_joint      : 971.7518656028891\n",
      "    val_loss       : -766.5727793375651\n",
      "    val_ess        : 1.9573740164438884\n",
      "    val_log_marginal: 766.6161804199219\n",
      "    val_log_joint  : 975.3276672363281\n",
      "Train Epoch: 1166 [0/54000 (0%)] Loss: -789.046265\n",
      "Train Epoch: 1166 [11264/54000 (21%)] Loss: -751.256226\n",
      "Train Epoch: 1166 [22528/54000 (42%)] Loss: -777.349121\n",
      "Train Epoch: 1166 [33792/54000 (63%)] Loss: -773.093140\n",
      "Train Epoch: 1166 [45056/54000 (83%)] Loss: -778.605957\n",
      "    epoch          : 1166\n",
      "    loss           : -763.2637478810436\n",
      "    ess            : 1.959989125998515\n",
      "    log_marginal   : 763.2996906784346\n",
      "    log_joint      : 971.9397145397259\n",
      "    val_loss       : -767.6323598225912\n",
      "    val_ess        : 1.9605983793735504\n",
      "    val_log_marginal: 767.6662648518881\n",
      "    val_log_joint  : 976.1102040608724\n",
      "Train Epoch: 1167 [0/54000 (0%)] Loss: -764.874878\n",
      "Train Epoch: 1167 [11264/54000 (21%)] Loss: -797.168091\n",
      "Train Epoch: 1167 [22528/54000 (42%)] Loss: -767.257019\n",
      "Train Epoch: 1167 [33792/54000 (63%)] Loss: -733.985352\n",
      "Train Epoch: 1167 [45056/54000 (83%)] Loss: -740.284607\n",
      "    epoch          : 1167\n",
      "    loss           : -763.2049606611143\n",
      "    ess            : 1.960100642915042\n",
      "    log_marginal   : 763.2419053563532\n",
      "    log_joint      : 971.7325882821713\n",
      "    val_loss       : -768.2290751139323\n",
      "    val_ess        : 1.9619315663973491\n",
      "    val_log_marginal: 768.2644805908203\n",
      "    val_log_joint  : 976.8298034667969\n",
      "Train Epoch: 1168 [0/54000 (0%)] Loss: -775.680725\n",
      "Train Epoch: 1168 [11264/54000 (21%)] Loss: -755.588440\n",
      "Train Epoch: 1168 [22528/54000 (42%)] Loss: -745.090942\n",
      "Train Epoch: 1168 [33792/54000 (63%)] Loss: -732.458008\n",
      "Train Epoch: 1168 [45056/54000 (83%)] Loss: -768.294922\n",
      "    epoch          : 1168\n",
      "    loss           : -763.1372490648953\n",
      "    ess            : 1.959176077032989\n",
      "    log_marginal   : 763.1752065982458\n",
      "    log_joint      : 971.6918346477005\n",
      "    val_loss       : -766.9634908040365\n",
      "    val_ess        : 1.9589777290821075\n",
      "    val_log_marginal: 767.0013224283854\n",
      "    val_log_joint  : 975.8235168457031\n",
      "Train Epoch: 1169 [0/54000 (0%)] Loss: -753.949402\n",
      "Train Epoch: 1169 [11264/54000 (21%)] Loss: -773.867249\n",
      "Train Epoch: 1169 [22528/54000 (42%)] Loss: -760.912842\n",
      "Train Epoch: 1169 [33792/54000 (63%)] Loss: -753.580688\n",
      "Train Epoch: 1169 [45056/54000 (83%)] Loss: -767.418579\n",
      "    epoch          : 1169\n",
      "    loss           : -763.2678608444502\n",
      "    ess            : 1.959098256983847\n",
      "    log_marginal   : 763.3077922317217\n",
      "    log_joint      : 971.8297314913767\n",
      "    val_loss       : -767.5942993164062\n",
      "    val_ess        : 1.957616776227951\n",
      "    val_log_marginal: 767.6353556315104\n",
      "    val_log_joint  : 976.1715749104818\n",
      "Train Epoch: 1170 [0/54000 (0%)] Loss: -762.418457\n",
      "Train Epoch: 1170 [11264/54000 (21%)] Loss: -768.390259\n",
      "Train Epoch: 1170 [22528/54000 (42%)] Loss: -773.328369\n",
      "Train Epoch: 1170 [33792/54000 (63%)] Loss: -750.754883\n",
      "Train Epoch: 1170 [45056/54000 (83%)] Loss: -755.383301\n",
      "    epoch          : 1170\n",
      "    loss           : -763.2244331791716\n",
      "    ess            : 1.9600474542041995\n",
      "    log_marginal   : 763.2618252736218\n",
      "    log_joint      : 971.8357826088959\n",
      "    val_loss       : -766.8132578531901\n",
      "    val_ess        : 1.9606180687745411\n",
      "    val_log_marginal: 766.851318359375\n",
      "    val_log_joint  : 975.3217010498047\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1170.pth ...\n",
      "Train Epoch: 1171 [0/54000 (0%)] Loss: -779.555786\n",
      "Train Epoch: 1171 [11264/54000 (21%)] Loss: -744.818604\n",
      "Train Epoch: 1171 [22528/54000 (42%)] Loss: -782.969116\n",
      "Train Epoch: 1171 [33792/54000 (63%)] Loss: -760.272217\n",
      "Train Epoch: 1171 [45056/54000 (83%)] Loss: -771.487793\n",
      "    epoch          : 1171\n",
      "    loss           : -763.4479542858196\n",
      "    ess            : 1.9591774029551812\n",
      "    log_marginal   : 763.4868198610702\n",
      "    log_joint      : 972.0113807534271\n",
      "    val_loss       : -767.5619506835938\n",
      "    val_ess        : 1.9616674681504567\n",
      "    val_log_marginal: 767.5979512532552\n",
      "    val_log_joint  : 975.9538828531901\n",
      "Train Epoch: 1172 [0/54000 (0%)] Loss: -754.512878\n",
      "Train Epoch: 1172 [11264/54000 (21%)] Loss: -754.308838\n",
      "Train Epoch: 1172 [22528/54000 (42%)] Loss: -768.701111\n",
      "Train Epoch: 1172 [33792/54000 (63%)] Loss: -772.760742\n",
      "Train Epoch: 1172 [45056/54000 (83%)] Loss: -769.234497\n",
      "    epoch          : 1172\n",
      "    loss           : -763.406843653265\n",
      "    ess            : 1.959523952232217\n",
      "    log_marginal   : 763.4446468713148\n",
      "    log_joint      : 971.966929309773\n",
      "    val_loss       : -768.0842030843099\n",
      "    val_ess        : 1.958667238553365\n",
      "    val_log_marginal: 768.1208241780599\n",
      "    val_log_joint  : 976.4953155517578\n",
      "Train Epoch: 1173 [0/54000 (0%)] Loss: -767.052612\n",
      "Train Epoch: 1173 [11264/54000 (21%)] Loss: -770.739624\n",
      "Train Epoch: 1173 [22528/54000 (42%)] Loss: -774.806335\n",
      "Train Epoch: 1173 [33792/54000 (63%)] Loss: -758.055359\n",
      "Train Epoch: 1173 [45056/54000 (83%)] Loss: -752.053955\n",
      "    epoch          : 1173\n",
      "    loss           : -763.4477406627727\n",
      "    ess            : 1.9597832538046926\n",
      "    log_marginal   : 763.4832349093455\n",
      "    log_joint      : 972.0300966658682\n",
      "    val_loss       : -767.2512410481771\n",
      "    val_ess        : 1.9592376848061879\n",
      "    val_log_marginal: 767.2881724039713\n",
      "    val_log_joint  : 975.9171142578125\n",
      "Train Epoch: 1174 [0/54000 (0%)] Loss: -785.605652\n",
      "Train Epoch: 1174 [11264/54000 (21%)] Loss: -747.336914\n",
      "Train Epoch: 1174 [22528/54000 (42%)] Loss: -763.497803\n",
      "Train Epoch: 1174 [33792/54000 (63%)] Loss: -743.422729\n",
      "Train Epoch: 1174 [45056/54000 (83%)] Loss: -740.997742\n",
      "    epoch          : 1174\n",
      "    loss           : -763.5677662975384\n",
      "    ess            : 1.9592238597150118\n",
      "    log_marginal   : 763.6073234126253\n",
      "    log_joint      : 972.0565980155513\n",
      "    val_loss       : -768.0487314860026\n",
      "    val_ess        : 1.961708664894104\n",
      "    val_log_marginal: 768.0786946614584\n",
      "    val_log_joint  : 976.6516825358073\n",
      "Train Epoch: 1175 [0/54000 (0%)] Loss: -769.657593\n",
      "Train Epoch: 1175 [11264/54000 (21%)] Loss: -760.116028\n",
      "Train Epoch: 1175 [22528/54000 (42%)] Loss: -753.303284\n",
      "Train Epoch: 1175 [33792/54000 (63%)] Loss: -763.954224\n",
      "Train Epoch: 1175 [45056/54000 (83%)] Loss: -763.727905\n",
      "    epoch          : 1175\n",
      "    loss           : -763.2141343602594\n",
      "    ess            : 1.9590404292322554\n",
      "    log_marginal   : 763.2522698168484\n",
      "    log_joint      : 971.7819329027859\n",
      "    val_loss       : -767.5813649495443\n",
      "    val_ess        : 1.9611172378063202\n",
      "    val_log_marginal: 767.6198883056641\n",
      "    val_log_joint  : 976.2226003011068\n",
      "Train Epoch: 1176 [0/54000 (0%)] Loss: -742.308838\n",
      "Train Epoch: 1176 [11264/54000 (21%)] Loss: -772.714478\n",
      "Train Epoch: 1176 [22528/54000 (42%)] Loss: -753.575684\n",
      "Train Epoch: 1176 [33792/54000 (63%)] Loss: -757.375854\n",
      "Train Epoch: 1176 [45056/54000 (83%)] Loss: -765.185913\n",
      "    epoch          : 1176\n",
      "    loss           : -763.3004023713886\n",
      "    ess            : 1.960099072951191\n",
      "    log_marginal   : 763.3379643278302\n",
      "    log_joint      : 971.8348561412884\n",
      "    val_loss       : -767.9915211995443\n",
      "    val_ess        : 1.9567733605702717\n",
      "    val_log_marginal: 768.0323028564453\n",
      "    val_log_joint  : 976.490956624349\n",
      "Train Epoch: 1177 [0/54000 (0%)] Loss: -753.883545\n",
      "Train Epoch: 1177 [11264/54000 (21%)] Loss: -765.639404\n",
      "Train Epoch: 1177 [22528/54000 (42%)] Loss: -750.029297\n",
      "Train Epoch: 1177 [33792/54000 (63%)] Loss: -757.931213\n",
      "Train Epoch: 1177 [45056/54000 (83%)] Loss: -746.693237\n",
      "    epoch          : 1177\n",
      "    loss           : -763.5312586370504\n",
      "    ess            : 1.9597970989515197\n",
      "    log_marginal   : 763.5682039080925\n",
      "    log_joint      : 972.2173853460348\n",
      "    val_loss       : -768.2275950113932\n",
      "    val_ess        : 1.9627265632152557\n",
      "    val_log_marginal: 768.2643534342448\n",
      "    val_log_joint  : 976.7703145345052\n",
      "Train Epoch: 1178 [0/54000 (0%)] Loss: -779.495850\n",
      "Train Epoch: 1178 [11264/54000 (21%)] Loss: -767.325195\n",
      "Train Epoch: 1178 [22528/54000 (42%)] Loss: -761.263184\n",
      "Train Epoch: 1178 [33792/54000 (63%)] Loss: -775.857483\n",
      "Train Epoch: 1178 [45056/54000 (83%)] Loss: -770.397949\n",
      "    epoch          : 1178\n",
      "    loss           : -763.7838837245725\n",
      "    ess            : 1.9599444438826363\n",
      "    log_marginal   : 763.8207518379643\n",
      "    log_joint      : 972.2817037330484\n",
      "    val_loss       : -768.4212239583334\n",
      "    val_ess        : 1.9598776996135712\n",
      "    val_log_marginal: 768.4603068033854\n",
      "    val_log_joint  : 977.169677734375\n",
      "Train Epoch: 1179 [0/54000 (0%)] Loss: -753.623047\n",
      "Train Epoch: 1179 [11264/54000 (21%)] Loss: -751.808716\n",
      "Train Epoch: 1179 [22528/54000 (42%)] Loss: -767.897583\n",
      "Train Epoch: 1179 [33792/54000 (63%)] Loss: -748.780334\n",
      "Train Epoch: 1179 [45056/54000 (83%)] Loss: -767.151184\n",
      "    epoch          : 1179\n",
      "    loss           : -763.7116146447523\n",
      "    ess            : 1.959758516752495\n",
      "    log_marginal   : 763.7475770194576\n",
      "    log_joint      : 972.2583336020416\n",
      "    val_loss       : -768.1113128662109\n",
      "    val_ess        : 1.9567822913328807\n",
      "    val_log_marginal: 768.1524912516276\n",
      "    val_log_joint  : 976.5515594482422\n",
      "Train Epoch: 1180 [0/54000 (0%)] Loss: -744.513733\n",
      "Train Epoch: 1180 [11264/54000 (21%)] Loss: -749.079468\n",
      "Train Epoch: 1180 [22528/54000 (42%)] Loss: -734.987122\n",
      "Train Epoch: 1180 [33792/54000 (63%)] Loss: -742.223633\n",
      "Train Epoch: 1180 [45056/54000 (83%)] Loss: -771.255005\n",
      "    epoch          : 1180\n",
      "    loss           : -763.80559381449\n",
      "    ess            : 1.9603794250848159\n",
      "    log_marginal   : 763.8418596375664\n",
      "    log_joint      : 972.3002572689417\n",
      "    val_loss       : -767.9210001627604\n",
      "    val_ess        : 1.960620512564977\n",
      "    val_log_marginal: 767.9557393391927\n",
      "    val_log_joint  : 976.4689280192057\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1180.pth ...\n",
      "Train Epoch: 1181 [0/54000 (0%)] Loss: -764.987183\n",
      "Train Epoch: 1181 [11264/54000 (21%)] Loss: -757.765259\n",
      "Train Epoch: 1181 [22528/54000 (42%)] Loss: -758.931335\n",
      "Train Epoch: 1181 [33792/54000 (63%)] Loss: -784.132996\n",
      "Train Epoch: 1181 [45056/54000 (83%)] Loss: -762.701782\n",
      "    epoch          : 1181\n",
      "    loss           : -763.5998696381191\n",
      "    ess            : 1.9607149801164303\n",
      "    log_marginal   : 763.6348019006117\n",
      "    log_joint      : 972.1964577728847\n",
      "    val_loss       : -768.1794738769531\n",
      "    val_ess        : 1.9600866436958313\n",
      "    val_log_marginal: 768.2172139485677\n",
      "    val_log_joint  : 976.5833587646484\n",
      "Train Epoch: 1182 [0/54000 (0%)] Loss: -760.579956\n",
      "Train Epoch: 1182 [11264/54000 (21%)] Loss: -769.992371\n",
      "Train Epoch: 1182 [22528/54000 (42%)] Loss: -775.999756\n",
      "Train Epoch: 1182 [33792/54000 (63%)] Loss: -758.693481\n",
      "Train Epoch: 1182 [45056/54000 (83%)] Loss: -751.685547\n",
      "    epoch          : 1182\n",
      "    loss           : -763.9461606583505\n",
      "    ess            : 1.9606698144156978\n",
      "    log_marginal   : 763.9822940466539\n",
      "    log_joint      : 972.4589302494841\n",
      "    val_loss       : -768.5521799723307\n",
      "    val_ess        : 1.9593152006467183\n",
      "    val_log_marginal: 768.5898640950521\n",
      "    val_log_joint  : 977.2624053955078\n",
      "Train Epoch: 1183 [0/54000 (0%)] Loss: -775.949951\n",
      "Train Epoch: 1183 [11264/54000 (21%)] Loss: -751.084167\n",
      "Train Epoch: 1183 [22528/54000 (42%)] Loss: -761.733521\n",
      "Train Epoch: 1183 [33792/54000 (63%)] Loss: -775.666748\n",
      "Train Epoch: 1183 [45056/54000 (83%)] Loss: -766.880859\n",
      "    epoch          : 1183\n",
      "    loss           : -763.8333026238207\n",
      "    ess            : 1.9599520125479069\n",
      "    log_marginal   : 763.8697060639004\n",
      "    log_joint      : 972.4106232265257\n",
      "    val_loss       : -767.8147277832031\n",
      "    val_ess        : 1.9578335583209991\n",
      "    val_log_marginal: 767.8545633951823\n",
      "    val_log_joint  : 976.5027160644531\n",
      "Train Epoch: 1184 [0/54000 (0%)] Loss: -744.697205\n",
      "Train Epoch: 1184 [11264/54000 (21%)] Loss: -749.961914\n",
      "Train Epoch: 1184 [22528/54000 (42%)] Loss: -777.364380\n",
      "Train Epoch: 1184 [33792/54000 (63%)] Loss: -767.302124\n",
      "Train Epoch: 1184 [45056/54000 (83%)] Loss: -784.239014\n",
      "    epoch          : 1184\n",
      "    loss           : -763.9064020120873\n",
      "    ess            : 1.9612195964129466\n",
      "    log_marginal   : 763.9422590147774\n",
      "    log_joint      : 972.5373414237545\n",
      "    val_loss       : -767.7360432942709\n",
      "    val_ess        : 1.9601113597551982\n",
      "    val_log_marginal: 767.7742563883463\n",
      "    val_log_joint  : 976.5517222086588\n",
      "Train Epoch: 1185 [0/54000 (0%)] Loss: -792.162354\n",
      "Train Epoch: 1185 [11264/54000 (21%)] Loss: -752.196045\n",
      "Train Epoch: 1185 [22528/54000 (42%)] Loss: -757.907654\n",
      "Train Epoch: 1185 [33792/54000 (63%)] Loss: -757.215332\n",
      "Train Epoch: 1185 [45056/54000 (83%)] Loss: -757.809204\n",
      "    epoch          : 1185\n",
      "    loss           : -763.9503663260982\n",
      "    ess            : 1.961738425605702\n",
      "    log_marginal   : 763.9849565613945\n",
      "    log_joint      : 972.4222607882517\n",
      "    val_loss       : -768.3149668375651\n",
      "    val_ess        : 1.9591153065363567\n",
      "    val_log_marginal: 768.3558603922526\n",
      "    val_log_joint  : 976.575927734375\n",
      "Train Epoch: 1186 [0/54000 (0%)] Loss: -784.882446\n",
      "Train Epoch: 1186 [11264/54000 (21%)] Loss: -761.893433\n",
      "Train Epoch: 1186 [22528/54000 (42%)] Loss: -775.740906\n",
      "Train Epoch: 1186 [33792/54000 (63%)] Loss: -767.737671\n",
      "Train Epoch: 1186 [45056/54000 (83%)] Loss: -757.274963\n",
      "    epoch          : 1186\n",
      "    loss           : -763.9017829175266\n",
      "    ess            : 1.9594056010246277\n",
      "    log_marginal   : 763.9401866984817\n",
      "    log_joint      : 972.4520517025354\n",
      "    val_loss       : -768.2972513834635\n",
      "    val_ess        : 1.96067480246226\n",
      "    val_log_marginal: 768.3323008219401\n",
      "    val_log_joint  : 976.6360473632812\n",
      "Train Epoch: 1187 [0/54000 (0%)] Loss: -746.131348\n",
      "Train Epoch: 1187 [11264/54000 (21%)] Loss: -762.201416\n",
      "Train Epoch: 1187 [22528/54000 (42%)] Loss: -776.621948\n",
      "Train Epoch: 1187 [33792/54000 (63%)] Loss: -761.643127\n",
      "Train Epoch: 1187 [45056/54000 (83%)] Loss: -770.880981\n",
      "    epoch          : 1187\n",
      "    loss           : -764.0161213424971\n",
      "    ess            : 1.959481807249897\n",
      "    log_marginal   : 764.0529554834906\n",
      "    log_joint      : 972.5805030678803\n",
      "    val_loss       : -768.250244140625\n",
      "    val_ess        : 1.9607159694035847\n",
      "    val_log_marginal: 768.2909444173177\n",
      "    val_log_joint  : 976.7831522623698\n",
      "Train Epoch: 1188 [0/54000 (0%)] Loss: -748.776672\n",
      "Train Epoch: 1188 [11264/54000 (21%)] Loss: -757.945312\n",
      "Train Epoch: 1188 [22528/54000 (42%)] Loss: -744.936523\n",
      "Train Epoch: 1188 [33792/54000 (63%)] Loss: -755.947693\n",
      "Train Epoch: 1188 [45056/54000 (83%)] Loss: -781.561646\n",
      "    epoch          : 1188\n",
      "    loss           : -763.8387002045254\n",
      "    ess            : 1.9606467103058438\n",
      "    log_marginal   : 763.8748474121094\n",
      "    log_joint      : 972.449839466023\n",
      "    val_loss       : -769.2344258626302\n",
      "    val_ess        : 1.9587924281756084\n",
      "    val_log_marginal: 769.2745564778646\n",
      "    val_log_joint  : 977.6567637125651\n",
      "Train Epoch: 1189 [0/54000 (0%)] Loss: -770.083984\n",
      "Train Epoch: 1189 [11264/54000 (21%)] Loss: -768.714722\n",
      "Train Epoch: 1189 [22528/54000 (42%)] Loss: -765.117981\n",
      "Train Epoch: 1189 [33792/54000 (63%)] Loss: -766.914734\n",
      "Train Epoch: 1189 [45056/54000 (83%)] Loss: -770.811279\n",
      "    epoch          : 1189\n",
      "    loss           : -764.0865040905071\n",
      "    ess            : 1.9593641611765016\n",
      "    log_marginal   : 764.124832441222\n",
      "    log_joint      : 972.6314916070902\n",
      "    val_loss       : -768.3841857910156\n",
      "    val_ess        : 1.9615104893843334\n",
      "    val_log_marginal: 768.4195098876953\n",
      "    val_log_joint  : 977.1258748372396\n",
      "Train Epoch: 1190 [0/54000 (0%)] Loss: -761.584473\n",
      "Train Epoch: 1190 [11264/54000 (21%)] Loss: -749.269958\n",
      "Train Epoch: 1190 [22528/54000 (42%)] Loss: -756.162964\n",
      "Train Epoch: 1190 [33792/54000 (63%)] Loss: -775.093689\n",
      "Train Epoch: 1190 [45056/54000 (83%)] Loss: -778.344360\n",
      "    epoch          : 1190\n",
      "    loss           : -764.0336816175928\n",
      "    ess            : 1.9600252880240387\n",
      "    log_marginal   : 764.0690370955557\n",
      "    log_joint      : 972.6097757591391\n",
      "    val_loss       : -768.8721160888672\n",
      "    val_ess        : 1.960365245739619\n",
      "    val_log_marginal: 768.907958984375\n",
      "    val_log_joint  : 977.5109608968099\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1190.pth ...\n",
      "Train Epoch: 1191 [0/54000 (0%)] Loss: -755.999878\n",
      "Train Epoch: 1191 [11264/54000 (21%)] Loss: -758.802185\n",
      "Train Epoch: 1191 [22528/54000 (42%)] Loss: -765.698792\n",
      "Train Epoch: 1191 [33792/54000 (63%)] Loss: -772.377686\n",
      "Train Epoch: 1191 [45056/54000 (83%)] Loss: -759.998535\n",
      "    epoch          : 1191\n",
      "    loss           : -763.9963597711527\n",
      "    ess            : 1.9601473684580821\n",
      "    log_marginal   : 764.0339879449808\n",
      "    log_joint      : 972.5697424546728\n",
      "    val_loss       : -769.1669311523438\n",
      "    val_ess        : 1.9607705374558766\n",
      "    val_log_marginal: 769.2064107259115\n",
      "    val_log_joint  : 977.8037465413412\n",
      "Train Epoch: 1192 [0/54000 (0%)] Loss: -766.005127\n",
      "Train Epoch: 1192 [11264/54000 (21%)] Loss: -784.922607\n",
      "Train Epoch: 1192 [22528/54000 (42%)] Loss: -755.783752\n",
      "Train Epoch: 1192 [33792/54000 (63%)] Loss: -730.094788\n",
      "Train Epoch: 1192 [45056/54000 (83%)] Loss: -743.111206\n",
      "    epoch          : 1192\n",
      "    loss           : -764.0662755426371\n",
      "    ess            : 1.9595223305360325\n",
      "    log_marginal   : 764.1034897138487\n",
      "    log_joint      : 972.5950069787367\n",
      "    val_loss       : -768.7766977945963\n",
      "    val_ess        : 1.9595316648483276\n",
      "    val_log_marginal: 768.8151906331381\n",
      "    val_log_joint  : 977.0576883951823\n",
      "Train Epoch: 1193 [0/54000 (0%)] Loss: -763.243225\n",
      "Train Epoch: 1193 [11264/54000 (21%)] Loss: -759.875854\n",
      "Train Epoch: 1193 [22528/54000 (42%)] Loss: -780.627808\n",
      "Train Epoch: 1193 [33792/54000 (63%)] Loss: -784.959473\n",
      "Train Epoch: 1193 [45056/54000 (83%)] Loss: -767.457153\n",
      "    epoch          : 1193\n",
      "    loss           : -763.9721409059921\n",
      "    ess            : 1.9598883064288013\n",
      "    log_marginal   : 764.0096936495798\n",
      "    log_joint      : 972.604101217018\n",
      "    val_loss       : -768.4203236897787\n",
      "    val_ess        : 1.9561973611513774\n",
      "    val_log_marginal: 768.4623158772787\n",
      "    val_log_joint  : 977.0080769856771\n",
      "Train Epoch: 1194 [0/54000 (0%)] Loss: -752.323853\n",
      "Train Epoch: 1194 [11264/54000 (21%)] Loss: -763.215576\n",
      "Train Epoch: 1194 [22528/54000 (42%)] Loss: -759.823486\n",
      "Train Epoch: 1194 [33792/54000 (63%)] Loss: -756.714050\n",
      "Train Epoch: 1194 [45056/54000 (83%)] Loss: -778.147583\n",
      "    epoch          : 1194\n",
      "    loss           : -764.1555187297317\n",
      "    ess            : 1.9608733642776057\n",
      "    log_marginal   : 764.1904158682194\n",
      "    log_joint      : 972.6911321676002\n",
      "    val_loss       : -768.7123565673828\n",
      "    val_ess        : 1.9594465295473735\n",
      "    val_log_marginal: 768.7516784667969\n",
      "    val_log_joint  : 977.3765360514323\n",
      "Train Epoch: 1195 [0/54000 (0%)] Loss: -794.422241\n",
      "Train Epoch: 1195 [11264/54000 (21%)] Loss: -782.162720\n",
      "Train Epoch: 1195 [22528/54000 (42%)] Loss: -750.896973\n",
      "Train Epoch: 1195 [33792/54000 (63%)] Loss: -786.357178\n",
      "Train Epoch: 1195 [45056/54000 (83%)] Loss: -760.668579\n",
      "    epoch          : 1195\n",
      "    loss           : -764.2805636423939\n",
      "    ess            : 1.9589741241257146\n",
      "    log_marginal   : 764.3186910377359\n",
      "    log_joint      : 972.7972492721846\n",
      "    val_loss       : -768.3230031331381\n",
      "    val_ess        : 1.9621106386184692\n",
      "    val_log_marginal: 768.3532663981119\n",
      "    val_log_joint  : 977.1551106770834\n",
      "Train Epoch: 1196 [0/54000 (0%)] Loss: -749.187134\n",
      "Train Epoch: 1196 [11264/54000 (21%)] Loss: -755.183167\n",
      "Train Epoch: 1196 [22528/54000 (42%)] Loss: -753.318176\n",
      "Train Epoch: 1196 [33792/54000 (63%)] Loss: -767.653076\n",
      "Train Epoch: 1196 [45056/54000 (83%)] Loss: -769.464417\n",
      "    epoch          : 1196\n",
      "    loss           : -764.2769648713886\n",
      "    ess            : 1.9587419449158434\n",
      "    log_marginal   : 764.3158816931383\n",
      "    log_joint      : 972.8828004081295\n",
      "    val_loss       : -768.4037068684896\n",
      "    val_ess        : 1.9568288922309875\n",
      "    val_log_marginal: 768.4472961425781\n",
      "    val_log_joint  : 976.9240468343099\n",
      "Train Epoch: 1197 [0/54000 (0%)] Loss: -773.057922\n",
      "Train Epoch: 1197 [11264/54000 (21%)] Loss: -759.979736\n",
      "Train Epoch: 1197 [22528/54000 (42%)] Loss: -741.202271\n",
      "Train Epoch: 1197 [33792/54000 (63%)] Loss: -745.137329\n",
      "Train Epoch: 1197 [45056/54000 (83%)] Loss: -765.314148\n",
      "    epoch          : 1197\n",
      "    loss           : -764.3461574338517\n",
      "    ess            : 1.9602079537679564\n",
      "    log_marginal   : 764.3831493449661\n",
      "    log_joint      : 972.9306122401975\n",
      "    val_loss       : -768.100351969401\n",
      "    val_ess        : 1.958982954422633\n",
      "    val_log_marginal: 768.1414540608724\n",
      "    val_log_joint  : 976.6571909586588\n",
      "Train Epoch: 1198 [0/54000 (0%)] Loss: -753.906311\n",
      "Train Epoch: 1198 [11264/54000 (21%)] Loss: -768.602600\n",
      "Train Epoch: 1198 [22528/54000 (42%)] Loss: -757.162109\n",
      "Train Epoch: 1198 [33792/54000 (63%)] Loss: -757.561279\n",
      "Train Epoch: 1198 [45056/54000 (83%)] Loss: -771.304260\n",
      "    epoch          : 1198\n",
      "    loss           : -764.1124653366377\n",
      "    ess            : 1.960079456275364\n",
      "    log_marginal   : 764.1486971873157\n",
      "    log_joint      : 972.674581275796\n",
      "    val_loss       : -768.3273976643881\n",
      "    val_ess        : 1.9594551920890808\n",
      "    val_log_marginal: 768.3590698242188\n",
      "    val_log_joint  : 976.7836252848307\n",
      "Train Epoch: 1199 [0/54000 (0%)] Loss: -757.452881\n",
      "Train Epoch: 1199 [11264/54000 (21%)] Loss: -788.096008\n",
      "Train Epoch: 1199 [22528/54000 (42%)] Loss: -794.030273\n",
      "Train Epoch: 1199 [33792/54000 (63%)] Loss: -756.914673\n",
      "Train Epoch: 1199 [45056/54000 (83%)] Loss: -762.517944\n",
      "    epoch          : 1199\n",
      "    loss           : -764.4500513616598\n",
      "    ess            : 1.9594410050590083\n",
      "    log_marginal   : 764.4877601479584\n",
      "    log_joint      : 972.9936817097214\n",
      "    val_loss       : -768.6257781982422\n",
      "    val_ess        : 1.958877056837082\n",
      "    val_log_marginal: 768.6620890299479\n",
      "    val_log_joint  : 977.2517242431641\n",
      "Train Epoch: 1200 [0/54000 (0%)] Loss: -771.031738\n",
      "Train Epoch: 1200 [11264/54000 (21%)] Loss: -749.813843\n",
      "Train Epoch: 1200 [22528/54000 (42%)] Loss: -765.699829\n",
      "Train Epoch: 1200 [33792/54000 (63%)] Loss: -776.785889\n",
      "Train Epoch: 1200 [45056/54000 (83%)] Loss: -771.023438\n",
      "    epoch          : 1200\n",
      "    loss           : -764.3638766306751\n",
      "    ess            : 1.959772878098038\n",
      "    log_marginal   : 764.401478893352\n",
      "    log_joint      : 972.9791708892246\n",
      "    val_loss       : -768.8240966796875\n",
      "    val_ess        : 1.9629571040471394\n",
      "    val_log_marginal: 768.8537648518881\n",
      "    val_log_joint  : 977.0271555582682\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1200.pth ...\n",
      "Train Epoch: 1201 [0/54000 (0%)] Loss: -760.603271\n",
      "Train Epoch: 1201 [11264/54000 (21%)] Loss: -764.030273\n",
      "Train Epoch: 1201 [22528/54000 (42%)] Loss: -768.837646\n",
      "Train Epoch: 1201 [33792/54000 (63%)] Loss: -760.955566\n",
      "Train Epoch: 1201 [45056/54000 (83%)] Loss: -757.395996\n",
      "    epoch          : 1201\n",
      "    loss           : -764.5381964917453\n",
      "    ess            : 1.9597466475558731\n",
      "    log_marginal   : 764.5748607707474\n",
      "    log_joint      : 973.1119108380012\n",
      "    val_loss       : -768.7214660644531\n",
      "    val_ess        : 1.9626294076442719\n",
      "    val_log_marginal: 768.7537892659506\n",
      "    val_log_joint  : 977.4077301025391\n",
      "Train Epoch: 1202 [0/54000 (0%)] Loss: -761.461548\n",
      "Train Epoch: 1202 [11264/54000 (21%)] Loss: -774.176880\n",
      "Train Epoch: 1202 [22528/54000 (42%)] Loss: -763.514954\n",
      "Train Epoch: 1202 [33792/54000 (63%)] Loss: -750.813354\n",
      "Train Epoch: 1202 [45056/54000 (83%)] Loss: -757.659180\n",
      "    epoch          : 1202\n",
      "    loss           : -764.6418848577536\n",
      "    ess            : 1.960917036488371\n",
      "    log_marginal   : 764.6779059644016\n",
      "    log_joint      : 973.2089020351194\n",
      "    val_loss       : -768.4973958333334\n",
      "    val_ess        : 1.9613801737626393\n",
      "    val_log_marginal: 768.5345865885416\n",
      "    val_log_joint  : 977.1734975179037\n",
      "Train Epoch: 1203 [0/54000 (0%)] Loss: -762.442749\n",
      "Train Epoch: 1203 [11264/54000 (21%)] Loss: -763.271118\n",
      "Train Epoch: 1203 [22528/54000 (42%)] Loss: -756.431763\n",
      "Train Epoch: 1203 [33792/54000 (63%)] Loss: -781.346924\n",
      "Train Epoch: 1203 [45056/54000 (83%)] Loss: -763.531616\n",
      "    epoch          : 1203\n",
      "    loss           : -764.6819394669443\n",
      "    ess            : 1.959979236125946\n",
      "    log_marginal   : 764.718458067696\n",
      "    log_joint      : 973.2204181023363\n",
      "    val_loss       : -769.0359903971354\n",
      "    val_ess        : 1.9598814845085144\n",
      "    val_log_marginal: 769.0709482828776\n",
      "    val_log_joint  : 977.5506540934244\n",
      "Train Epoch: 1204 [0/54000 (0%)] Loss: -746.246338\n",
      "Train Epoch: 1204 [11264/54000 (21%)] Loss: -762.003357\n",
      "Train Epoch: 1204 [22528/54000 (42%)] Loss: -743.967285\n",
      "Train Epoch: 1204 [33792/54000 (63%)] Loss: -749.361389\n",
      "Train Epoch: 1204 [45056/54000 (83%)] Loss: -759.699463\n",
      "    epoch          : 1204\n",
      "    loss           : -764.703062813237\n",
      "    ess            : 1.9598815767270215\n",
      "    log_marginal   : 764.7401606721698\n",
      "    log_joint      : 973.3464620338297\n",
      "    val_loss       : -769.3929138183594\n",
      "    val_ess        : 1.9618764221668243\n",
      "    val_log_marginal: 769.4297993977865\n",
      "    val_log_joint  : 978.0484517415365\n",
      "Train Epoch: 1205 [0/54000 (0%)] Loss: -798.249817\n",
      "Train Epoch: 1205 [11264/54000 (21%)] Loss: -756.735474\n",
      "Train Epoch: 1205 [22528/54000 (42%)] Loss: -771.966919\n",
      "Train Epoch: 1205 [33792/54000 (63%)] Loss: -771.470032\n",
      "Train Epoch: 1205 [45056/54000 (83%)] Loss: -780.425110\n",
      "    epoch          : 1205\n",
      "    loss           : -764.590981537441\n",
      "    ess            : 1.9602823932215852\n",
      "    log_marginal   : 764.6278156784346\n",
      "    log_joint      : 973.1881235950398\n",
      "    val_loss       : -768.9636383056641\n",
      "    val_ess        : 1.959813227256139\n",
      "    val_log_marginal: 769.0010579427084\n",
      "    val_log_joint  : 977.4111989339193\n",
      "Train Epoch: 1206 [0/54000 (0%)] Loss: -752.223267\n",
      "Train Epoch: 1206 [11264/54000 (21%)] Loss: -761.912231\n",
      "Train Epoch: 1206 [22528/54000 (42%)] Loss: -745.647888\n",
      "Train Epoch: 1206 [33792/54000 (63%)] Loss: -774.476013\n",
      "Train Epoch: 1206 [45056/54000 (83%)] Loss: -727.403198\n",
      "    epoch          : 1206\n",
      "    loss           : -764.6948604943617\n",
      "    ess            : 1.960669478155532\n",
      "    log_marginal   : 764.7295267357016\n",
      "    log_joint      : 973.3012637732164\n",
      "    val_loss       : -769.4314117431641\n",
      "    val_ess        : 1.9621397256851196\n",
      "    val_log_marginal: 769.4637807210287\n",
      "    val_log_joint  : 978.1122843424479\n",
      "Train Epoch: 1207 [0/54000 (0%)] Loss: -772.944214\n",
      "Train Epoch: 1207 [11264/54000 (21%)] Loss: -763.532959\n",
      "Train Epoch: 1207 [22528/54000 (42%)] Loss: -747.121582\n",
      "Train Epoch: 1207 [33792/54000 (63%)] Loss: -761.720825\n",
      "Train Epoch: 1207 [45056/54000 (83%)] Loss: -773.190613\n",
      "    epoch          : 1207\n",
      "    loss           : -764.746700070939\n",
      "    ess            : 1.9602173094479542\n",
      "    log_marginal   : 764.7826492021669\n",
      "    log_joint      : 973.3196128989166\n",
      "    val_loss       : -769.0862884521484\n",
      "    val_ess        : 1.959740936756134\n",
      "    val_log_marginal: 769.1231994628906\n",
      "    val_log_joint  : 977.4743347167969\n",
      "Train Epoch: 1208 [0/54000 (0%)] Loss: -760.227783\n",
      "Train Epoch: 1208 [11264/54000 (21%)] Loss: -783.499023\n",
      "Train Epoch: 1208 [22528/54000 (42%)] Loss: -760.282349\n",
      "Train Epoch: 1208 [33792/54000 (63%)] Loss: -761.957886\n",
      "Train Epoch: 1208 [45056/54000 (83%)] Loss: -738.510864\n",
      "    epoch          : 1208\n",
      "    loss           : -764.938629726194\n",
      "    ess            : 1.960371415570097\n",
      "    log_marginal   : 764.9758099250074\n",
      "    log_joint      : 973.436657599683\n",
      "    val_loss       : -769.0021565755209\n",
      "    val_ess        : 1.9615668952465057\n",
      "    val_log_marginal: 769.0372823079427\n",
      "    val_log_joint  : 977.5801595052084\n",
      "Train Epoch: 1209 [0/54000 (0%)] Loss: -752.176758\n",
      "Train Epoch: 1209 [11264/54000 (21%)] Loss: -760.877380\n",
      "Train Epoch: 1209 [22528/54000 (42%)] Loss: -768.771118\n",
      "Train Epoch: 1209 [33792/54000 (63%)] Loss: -776.138855\n",
      "Train Epoch: 1209 [45056/54000 (83%)] Loss: -757.748047\n",
      "    epoch          : 1209\n",
      "    loss           : -764.6521900105026\n",
      "    ess            : 1.9597097252899747\n",
      "    log_marginal   : 764.6885496895268\n",
      "    log_joint      : 973.303605565485\n",
      "    val_loss       : -769.5158335367838\n",
      "    val_ess        : 1.9597829480965931\n",
      "    val_log_marginal: 769.5519968668619\n",
      "    val_log_joint  : 977.9766845703125\n",
      "Train Epoch: 1210 [0/54000 (0%)] Loss: -759.455200\n",
      "Train Epoch: 1210 [11264/54000 (21%)] Loss: -778.994873\n",
      "Train Epoch: 1210 [22528/54000 (42%)] Loss: -771.065430\n",
      "Train Epoch: 1210 [33792/54000 (63%)] Loss: -772.344727\n",
      "Train Epoch: 1210 [45056/54000 (83%)] Loss: -768.525940\n",
      "    epoch          : 1210\n",
      "    loss           : -764.7729895249853\n",
      "    ess            : 1.9603264376802265\n",
      "    log_marginal   : 764.8097908451872\n",
      "    log_joint      : 973.3454152233196\n",
      "    val_loss       : -768.2787679036459\n",
      "    val_ess        : 1.957354078690211\n",
      "    val_log_marginal: 768.3193664550781\n",
      "    val_log_joint  : 977.2628275553385\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1210.pth ...\n",
      "Train Epoch: 1211 [0/54000 (0%)] Loss: -771.182251\n",
      "Train Epoch: 1211 [11264/54000 (21%)] Loss: -773.300903\n",
      "Train Epoch: 1211 [22528/54000 (42%)] Loss: -756.087769\n",
      "Train Epoch: 1211 [33792/54000 (63%)] Loss: -759.248047\n",
      "Train Epoch: 1211 [45056/54000 (83%)] Loss: -757.222351\n",
      "    epoch          : 1211\n",
      "    loss           : -764.5668997134802\n",
      "    ess            : 1.9600837927944255\n",
      "    log_marginal   : 764.60288857514\n",
      "    log_joint      : 973.1642243007444\n",
      "    val_loss       : -769.9897918701172\n",
      "    val_ess        : 1.9640200436115265\n",
      "    val_log_marginal: 770.0230662027994\n",
      "    val_log_joint  : 978.6337941487631\n",
      "Train Epoch: 1212 [0/54000 (0%)] Loss: -765.633057\n",
      "Train Epoch: 1212 [11264/54000 (21%)] Loss: -757.979248\n",
      "Train Epoch: 1212 [22528/54000 (42%)] Loss: -762.743042\n",
      "Train Epoch: 1212 [33792/54000 (63%)] Loss: -745.408081\n",
      "Train Epoch: 1212 [45056/54000 (83%)] Loss: -785.989014\n",
      "    epoch          : 1212\n",
      "    loss           : -764.9953970279333\n",
      "    ess            : 1.9604146255637116\n",
      "    log_marginal   : 765.0319783912515\n",
      "    log_joint      : 973.3794382923054\n",
      "    val_loss       : -769.3995971679688\n",
      "    val_ess        : 1.9599013527234395\n",
      "    val_log_marginal: 769.4344584147135\n",
      "    val_log_joint  : 978.0229187011719\n",
      "Train Epoch: 1213 [0/54000 (0%)] Loss: -792.125488\n",
      "Train Epoch: 1213 [11264/54000 (21%)] Loss: -754.982788\n",
      "Train Epoch: 1213 [22528/54000 (42%)] Loss: -770.781738\n",
      "Train Epoch: 1213 [33792/54000 (63%)] Loss: -766.233276\n",
      "Train Epoch: 1213 [45056/54000 (83%)] Loss: -749.670715\n",
      "    epoch          : 1213\n",
      "    loss           : -765.0760636239681\n",
      "    ess            : 1.959345282248731\n",
      "    log_marginal   : 765.1144622226931\n",
      "    log_joint      : 973.6365955280808\n",
      "    val_loss       : -769.3892008463541\n",
      "    val_ess        : 1.9587820768356323\n",
      "    val_log_marginal: 769.4264984130859\n",
      "    val_log_joint  : 977.8781483968099\n",
      "Train Epoch: 1214 [0/54000 (0%)] Loss: -767.684692\n",
      "Train Epoch: 1214 [11264/54000 (21%)] Loss: -777.785034\n",
      "Train Epoch: 1214 [22528/54000 (42%)] Loss: -781.895081\n",
      "Train Epoch: 1214 [33792/54000 (63%)] Loss: -780.240479\n",
      "Train Epoch: 1214 [45056/54000 (83%)] Loss: -746.967773\n",
      "    epoch          : 1214\n",
      "    loss           : -765.1770405319502\n",
      "    ess            : 1.9596309830557626\n",
      "    log_marginal   : 765.2125175044222\n",
      "    log_joint      : 973.5340771945017\n",
      "    val_loss       : -769.2870229085287\n",
      "    val_ess        : 1.9624482492605846\n",
      "    val_log_marginal: 769.3195648193359\n",
      "    val_log_joint  : 978.3459828694662\n",
      "Train Epoch: 1215 [0/54000 (0%)] Loss: -756.494873\n",
      "Train Epoch: 1215 [11264/54000 (21%)] Loss: -751.278320\n",
      "Train Epoch: 1215 [22528/54000 (42%)] Loss: -733.022705\n",
      "Train Epoch: 1215 [33792/54000 (63%)] Loss: -774.917969\n",
      "Train Epoch: 1215 [45056/54000 (83%)] Loss: -777.434814\n",
      "    epoch          : 1215\n",
      "    loss           : -764.904414914689\n",
      "    ess            : 1.960134135102326\n",
      "    log_marginal   : 764.9419728405071\n",
      "    log_joint      : 973.4270100143721\n",
      "    val_loss       : -769.4453074137369\n",
      "    val_ess        : 1.959535390138626\n",
      "    val_log_marginal: 769.4815063476562\n",
      "    val_log_joint  : 978.2626953125\n",
      "Train Epoch: 1216 [0/54000 (0%)] Loss: -749.202637\n",
      "Train Epoch: 1216 [11264/54000 (21%)] Loss: -781.374146\n",
      "Train Epoch: 1216 [22528/54000 (42%)] Loss: -743.827759\n",
      "Train Epoch: 1216 [33792/54000 (63%)] Loss: -755.144958\n",
      "Train Epoch: 1216 [45056/54000 (83%)] Loss: -767.964600\n",
      "    epoch          : 1216\n",
      "    loss           : -764.9809679715139\n",
      "    ess            : 1.9600847768333722\n",
      "    log_marginal   : 765.0187423993956\n",
      "    log_joint      : 973.5482016509434\n",
      "    val_loss       : -770.3460337320963\n",
      "    val_ess        : 1.9609634478886921\n",
      "    val_log_marginal: 770.3818613688151\n",
      "    val_log_joint  : 978.5200551350912\n",
      "Train Epoch: 1217 [0/54000 (0%)] Loss: -763.775452\n",
      "Train Epoch: 1217 [11264/54000 (21%)] Loss: -762.873901\n",
      "Train Epoch: 1217 [22528/54000 (42%)] Loss: -751.160339\n",
      "Train Epoch: 1217 [33792/54000 (63%)] Loss: -777.309814\n",
      "Train Epoch: 1217 [45056/54000 (83%)] Loss: -731.442139\n",
      "    epoch          : 1217\n",
      "    loss           : -765.0889253436394\n",
      "    ess            : 1.9598481014089764\n",
      "    log_marginal   : 765.1262529481132\n",
      "    log_joint      : 973.5352973218235\n",
      "    val_loss       : -770.4473724365234\n",
      "    val_ess        : 1.9580018222332\n",
      "    val_log_marginal: 770.4852549235026\n",
      "    val_log_joint  : 978.7267557779948\n",
      "Train Epoch: 1218 [0/54000 (0%)] Loss: -754.349915\n",
      "Train Epoch: 1218 [11264/54000 (21%)] Loss: -771.197571\n",
      "Train Epoch: 1218 [22528/54000 (42%)] Loss: -768.982727\n",
      "Train Epoch: 1218 [33792/54000 (63%)] Loss: -787.612427\n",
      "Train Epoch: 1218 [45056/54000 (83%)] Loss: -745.570190\n",
      "    epoch          : 1218\n",
      "    loss           : -764.7798364027491\n",
      "    ess            : 1.9602326863216903\n",
      "    log_marginal   : 764.8169976000515\n",
      "    log_joint      : 973.299310072413\n",
      "    val_loss       : -769.6735534667969\n",
      "    val_ess        : 1.957010527451833\n",
      "    val_log_marginal: 769.7158355712891\n",
      "    val_log_joint  : 977.8569539388021\n",
      "Train Epoch: 1219 [0/54000 (0%)] Loss: -776.384399\n",
      "Train Epoch: 1219 [11264/54000 (21%)] Loss: -772.960022\n",
      "Train Epoch: 1219 [22528/54000 (42%)] Loss: -751.341431\n",
      "Train Epoch: 1219 [33792/54000 (63%)] Loss: -768.284302\n",
      "Train Epoch: 1219 [45056/54000 (83%)] Loss: -775.032776\n",
      "    epoch          : 1219\n",
      "    loss           : -765.0339084841171\n",
      "    ess            : 1.9601842423654952\n",
      "    log_marginal   : 765.0709487627138\n",
      "    log_joint      : 973.561767578125\n",
      "    val_loss       : -769.8216451009115\n",
      "    val_ess        : 1.95804363489151\n",
      "    val_log_marginal: 769.8643442789713\n",
      "    val_log_joint  : 978.2792816162109\n",
      "Train Epoch: 1220 [0/54000 (0%)] Loss: -780.245422\n",
      "Train Epoch: 1220 [11264/54000 (21%)] Loss: -759.853699\n",
      "Train Epoch: 1220 [22528/54000 (42%)] Loss: -771.280212\n",
      "Train Epoch: 1220 [33792/54000 (63%)] Loss: -793.910522\n",
      "Train Epoch: 1220 [45056/54000 (83%)] Loss: -776.888306\n",
      "    epoch          : 1220\n",
      "    loss           : -764.9877843316996\n",
      "    ess            : 1.9596140890751246\n",
      "    log_marginal   : 765.0244117592865\n",
      "    log_joint      : 973.6241092322008\n",
      "    val_loss       : -770.1995137532552\n",
      "    val_ess        : 1.9628309607505798\n",
      "    val_log_marginal: 770.235361735026\n",
      "    val_log_joint  : 978.9330596923828\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1220.pth ...\n",
      "Train Epoch: 1221 [0/54000 (0%)] Loss: -769.583618\n",
      "Train Epoch: 1221 [11264/54000 (21%)] Loss: -785.441467\n",
      "Train Epoch: 1221 [22528/54000 (42%)] Loss: -773.424805\n",
      "Train Epoch: 1221 [33792/54000 (63%)] Loss: -759.903809\n",
      "Train Epoch: 1221 [45056/54000 (83%)] Loss: -752.902222\n",
      "    epoch          : 1221\n",
      "    loss           : -765.2301946676002\n",
      "    ess            : 1.9598328471183777\n",
      "    log_marginal   : 765.2677836867998\n",
      "    log_joint      : 973.8311709997789\n",
      "    val_loss       : -770.3494415283203\n",
      "    val_ess        : 1.9620944758256276\n",
      "    val_log_marginal: 770.381846110026\n",
      "    val_log_joint  : 978.6880544026693\n",
      "Train Epoch: 1222 [0/54000 (0%)] Loss: -759.737000\n",
      "Train Epoch: 1222 [11264/54000 (21%)] Loss: -779.320801\n",
      "Train Epoch: 1222 [22528/54000 (42%)] Loss: -794.788696\n",
      "Train Epoch: 1222 [33792/54000 (63%)] Loss: -741.010986\n",
      "Train Epoch: 1222 [45056/54000 (83%)] Loss: -746.593872\n",
      "    epoch          : 1222\n",
      "    loss           : -765.1765303701725\n",
      "    ess            : 1.958672730427868\n",
      "    log_marginal   : 765.2162590746609\n",
      "    log_joint      : 973.7540766877948\n",
      "    val_loss       : -770.418955485026\n",
      "    val_ess        : 1.9619067311286926\n",
      "    val_log_marginal: 770.4534098307291\n",
      "    val_log_joint  : 978.7014363606771\n",
      "Train Epoch: 1223 [0/54000 (0%)] Loss: -776.342957\n",
      "Train Epoch: 1223 [11264/54000 (21%)] Loss: -787.453857\n",
      "Train Epoch: 1223 [22528/54000 (42%)] Loss: -750.773804\n",
      "Train Epoch: 1223 [33792/54000 (63%)] Loss: -762.403198\n",
      "Train Epoch: 1223 [45056/54000 (83%)] Loss: -763.029175\n",
      "    epoch          : 1223\n",
      "    loss           : -765.2394299777048\n",
      "    ess            : 1.960303025425605\n",
      "    log_marginal   : 765.2764316774765\n",
      "    log_joint      : 973.791127330852\n",
      "    val_loss       : -769.7786966959635\n",
      "    val_ess        : 1.9606235524018605\n",
      "    val_log_marginal: 769.8138783772787\n",
      "    val_log_joint  : 978.4045664469401\n",
      "Train Epoch: 1224 [0/54000 (0%)] Loss: -766.981567\n",
      "Train Epoch: 1224 [11264/54000 (21%)] Loss: -767.481079\n",
      "Train Epoch: 1224 [22528/54000 (42%)] Loss: -771.756836\n",
      "Train Epoch: 1224 [33792/54000 (63%)] Loss: -755.850342\n",
      "Train Epoch: 1224 [45056/54000 (83%)] Loss: -741.290283\n",
      "    epoch          : 1224\n",
      "    loss           : -765.1214864478922\n",
      "    ess            : 1.9602418350723554\n",
      "    log_marginal   : 765.1594675891804\n",
      "    log_joint      : 973.69259355653\n",
      "    val_loss       : -768.6305084228516\n",
      "    val_ess        : 1.9611926476160686\n",
      "    val_log_marginal: 768.6621144612631\n",
      "    val_log_joint  : 977.3527221679688\n",
      "Train Epoch: 1225 [0/54000 (0%)] Loss: -757.235962\n",
      "Train Epoch: 1225 [11264/54000 (21%)] Loss: -769.586487\n",
      "Train Epoch: 1225 [22528/54000 (42%)] Loss: -765.538940\n",
      "Train Epoch: 1225 [33792/54000 (63%)] Loss: -757.772156\n",
      "Train Epoch: 1225 [45056/54000 (83%)] Loss: -747.560669\n",
      "    epoch          : 1225\n",
      "    loss           : -765.3751808022553\n",
      "    ess            : 1.9604502522720482\n",
      "    log_marginal   : 765.4106209233122\n",
      "    log_joint      : 973.9467497051887\n",
      "    val_loss       : -769.8943328857422\n",
      "    val_ess        : 1.9579082528750102\n",
      "    val_log_marginal: 769.9332580566406\n",
      "    val_log_joint  : 978.4289194742838\n",
      "Train Epoch: 1226 [0/54000 (0%)] Loss: -782.635559\n",
      "Train Epoch: 1226 [11264/54000 (21%)] Loss: -749.968201\n",
      "Train Epoch: 1226 [22528/54000 (42%)] Loss: -754.641602\n",
      "Train Epoch: 1226 [33792/54000 (63%)] Loss: -765.107056\n",
      "Train Epoch: 1226 [45056/54000 (83%)] Loss: -747.245422\n",
      "    epoch          : 1226\n",
      "    loss           : -765.3618958671138\n",
      "    ess            : 1.9592900411137995\n",
      "    log_marginal   : 765.3988192576282\n",
      "    log_joint      : 973.9302097536483\n",
      "    val_loss       : -770.1488087972006\n",
      "    val_ess        : 1.9617530604203541\n",
      "    val_log_marginal: 770.1822357177734\n",
      "    val_log_joint  : 978.7362416585287\n",
      "Train Epoch: 1227 [0/54000 (0%)] Loss: -774.920898\n",
      "Train Epoch: 1227 [11264/54000 (21%)] Loss: -762.096924\n",
      "Train Epoch: 1227 [22528/54000 (42%)] Loss: -758.204834\n",
      "Train Epoch: 1227 [33792/54000 (63%)] Loss: -760.860291\n",
      "Train Epoch: 1227 [45056/54000 (83%)] Loss: -758.477600\n",
      "    epoch          : 1227\n",
      "    loss           : -765.5172061560289\n",
      "    ess            : 1.959157962844057\n",
      "    log_marginal   : 765.5549155181309\n",
      "    log_joint      : 974.0248574310879\n",
      "    val_loss       : -769.6970520019531\n",
      "    val_ess        : 1.961492508649826\n",
      "    val_log_marginal: 769.7309621175131\n",
      "    val_log_joint  : 978.2921244303385\n",
      "Train Epoch: 1228 [0/54000 (0%)] Loss: -764.011902\n",
      "Train Epoch: 1228 [11264/54000 (21%)] Loss: -764.858154\n",
      "Train Epoch: 1228 [22528/54000 (42%)] Loss: -773.053101\n",
      "Train Epoch: 1228 [33792/54000 (63%)] Loss: -756.243042\n",
      "Train Epoch: 1228 [45056/54000 (83%)] Loss: -766.272339\n",
      "    epoch          : 1228\n",
      "    loss           : -765.3675462254938\n",
      "    ess            : 1.9592648350967552\n",
      "    log_marginal   : 765.4048531010466\n",
      "    log_joint      : 973.8770515873747\n",
      "    val_loss       : -769.6543884277344\n",
      "    val_ess        : 1.9599002301692963\n",
      "    val_log_marginal: 769.6919301350912\n",
      "    val_log_joint  : 978.332529703776\n",
      "Train Epoch: 1229 [0/54000 (0%)] Loss: -764.594849\n",
      "Train Epoch: 1229 [11264/54000 (21%)] Loss: -767.086426\n",
      "Train Epoch: 1229 [22528/54000 (42%)] Loss: -785.440308\n",
      "Train Epoch: 1229 [33792/54000 (63%)] Loss: -756.168579\n",
      "Train Epoch: 1229 [45056/54000 (83%)] Loss: -766.145447\n",
      "    epoch          : 1229\n",
      "    loss           : -765.2853623876032\n",
      "    ess            : 1.9596847070837922\n",
      "    log_marginal   : 765.3222984457916\n",
      "    log_joint      : 973.8586287588444\n",
      "    val_loss       : -769.4693247477213\n",
      "    val_ess        : 1.9551789065202076\n",
      "    val_log_marginal: 769.5116119384766\n",
      "    val_log_joint  : 978.1582590738932\n",
      "Train Epoch: 1230 [0/54000 (0%)] Loss: -769.689392\n",
      "Train Epoch: 1230 [11264/54000 (21%)] Loss: -766.994568\n",
      "Train Epoch: 1230 [22528/54000 (42%)] Loss: -775.478760\n",
      "Train Epoch: 1230 [33792/54000 (63%)] Loss: -778.093140\n",
      "Train Epoch: 1230 [45056/54000 (83%)] Loss: -760.076965\n",
      "    epoch          : 1230\n",
      "    loss           : -765.1260249299823\n",
      "    ess            : 1.9599828112800166\n",
      "    log_marginal   : 765.1641321722067\n",
      "    log_joint      : 973.7582967506265\n",
      "    val_loss       : -769.9684244791666\n",
      "    val_ess        : 1.959634264310201\n",
      "    val_log_marginal: 770.0048777262369\n",
      "    val_log_joint  : 978.6982472737631\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1230.pth ...\n",
      "Train Epoch: 1231 [0/54000 (0%)] Loss: -772.126892\n",
      "Train Epoch: 1231 [11264/54000 (21%)] Loss: -772.244995\n",
      "Train Epoch: 1231 [22528/54000 (42%)] Loss: -759.804810\n",
      "Train Epoch: 1231 [33792/54000 (63%)] Loss: -767.408447\n",
      "Train Epoch: 1231 [45056/54000 (83%)] Loss: -744.029175\n",
      "    epoch          : 1231\n",
      "    loss           : -765.3405145609154\n",
      "    ess            : 1.959668718418985\n",
      "    log_marginal   : 765.378188223209\n",
      "    log_joint      : 973.9133381393721\n",
      "    val_loss       : -769.4122924804688\n",
      "    val_ess        : 1.959288477897644\n",
      "    val_log_marginal: 769.4499867757162\n",
      "    val_log_joint  : 977.9553629557291\n",
      "Train Epoch: 1232 [0/54000 (0%)] Loss: -769.093262\n",
      "Train Epoch: 1232 [11264/54000 (21%)] Loss: -761.669556\n",
      "Train Epoch: 1232 [22528/54000 (42%)] Loss: -765.500061\n",
      "Train Epoch: 1232 [33792/54000 (63%)] Loss: -755.289185\n",
      "Train Epoch: 1232 [45056/54000 (83%)] Loss: -783.510864\n",
      "    epoch          : 1232\n",
      "    loss           : -765.314082883439\n",
      "    ess            : 1.9609455837393708\n",
      "    log_marginal   : 765.3500285598467\n",
      "    log_joint      : 973.8859834491082\n",
      "    val_loss       : -769.9002939860026\n",
      "    val_ess        : 1.9574056367079418\n",
      "    val_log_marginal: 769.9446258544922\n",
      "    val_log_joint  : 978.4538421630859\n",
      "Train Epoch: 1233 [0/54000 (0%)] Loss: -749.154724\n",
      "Train Epoch: 1233 [11264/54000 (21%)] Loss: -768.332520\n",
      "Train Epoch: 1233 [22528/54000 (42%)] Loss: -781.791504\n",
      "Train Epoch: 1233 [33792/54000 (63%)] Loss: -780.367798\n",
      "Train Epoch: 1233 [45056/54000 (83%)] Loss: -773.381348\n",
      "    epoch          : 1233\n",
      "    loss           : -765.4078213673718\n",
      "    ess            : 1.9601313752948113\n",
      "    log_marginal   : 765.4453856270268\n",
      "    log_joint      : 973.9882150326135\n",
      "    val_loss       : -769.697031656901\n",
      "    val_ess        : 1.9583139419555664\n",
      "    val_log_marginal: 769.7347666422526\n",
      "    val_log_joint  : 978.1560821533203\n",
      "Train Epoch: 1234 [0/54000 (0%)] Loss: -759.078003\n",
      "Train Epoch: 1234 [11264/54000 (21%)] Loss: -756.272644\n",
      "Train Epoch: 1234 [22528/54000 (42%)] Loss: -744.092834\n",
      "Train Epoch: 1234 [33792/54000 (63%)] Loss: -743.960083\n",
      "Train Epoch: 1234 [45056/54000 (83%)] Loss: -751.171265\n",
      "    epoch          : 1234\n",
      "    loss           : -765.3508197136645\n",
      "    ess            : 1.9594617587215495\n",
      "    log_marginal   : 765.388587231906\n",
      "    log_joint      : 973.9120368237766\n",
      "    val_loss       : -769.4440968831381\n",
      "    val_ess        : 1.9611857732137044\n",
      "    val_log_marginal: 769.4766947428385\n",
      "    val_log_joint  : 977.9977671305338\n",
      "Train Epoch: 1235 [0/54000 (0%)] Loss: -749.622925\n",
      "Train Epoch: 1235 [11264/54000 (21%)] Loss: -762.123474\n",
      "Train Epoch: 1235 [22528/54000 (42%)] Loss: -777.766602\n",
      "Train Epoch: 1235 [33792/54000 (63%)] Loss: -769.487671\n",
      "Train Epoch: 1235 [45056/54000 (83%)] Loss: -754.592041\n",
      "    epoch          : 1235\n",
      "    loss           : -765.6193317917158\n",
      "    ess            : 1.9602229808861356\n",
      "    log_marginal   : 765.6561624778891\n",
      "    log_joint      : 974.1637118357532\n",
      "    val_loss       : -769.8062591552734\n",
      "    val_ess        : 1.9593318402767181\n",
      "    val_log_marginal: 769.8444569905599\n",
      "    val_log_joint  : 978.2942555745443\n",
      "Train Epoch: 1236 [0/54000 (0%)] Loss: -772.464417\n",
      "Train Epoch: 1236 [11264/54000 (21%)] Loss: -764.189209\n",
      "Train Epoch: 1236 [22528/54000 (42%)] Loss: -754.612122\n",
      "Train Epoch: 1236 [33792/54000 (63%)] Loss: -767.061401\n",
      "Train Epoch: 1236 [45056/54000 (83%)] Loss: -758.557739\n",
      "    epoch          : 1236\n",
      "    loss           : -765.5849574826798\n",
      "    ess            : 1.9599542505336258\n",
      "    log_marginal   : 765.6217374981575\n",
      "    log_joint      : 974.061055885171\n",
      "    val_loss       : -770.0385894775391\n",
      "    val_ess        : 1.9608165423075359\n",
      "    val_log_marginal: 770.0766042073568\n",
      "    val_log_joint  : 978.6055450439453\n",
      "Train Epoch: 1237 [0/54000 (0%)] Loss: -764.199341\n",
      "Train Epoch: 1237 [11264/54000 (21%)] Loss: -760.425232\n",
      "Train Epoch: 1237 [22528/54000 (42%)] Loss: -778.233521\n",
      "Train Epoch: 1237 [33792/54000 (63%)] Loss: -777.287109\n",
      "Train Epoch: 1237 [45056/54000 (83%)] Loss: -769.897827\n",
      "    epoch          : 1237\n",
      "    loss           : -765.6044461232311\n",
      "    ess            : 1.9590759558497735\n",
      "    log_marginal   : 765.6434228285303\n",
      "    log_joint      : 974.2009634341833\n",
      "    val_loss       : -770.2679290771484\n",
      "    val_ess        : 1.9605284134546916\n",
      "    val_log_marginal: 770.3063354492188\n",
      "    val_log_joint  : 978.8690541585287\n",
      "Train Epoch: 1238 [0/54000 (0%)] Loss: -771.429688\n",
      "Train Epoch: 1238 [11264/54000 (21%)] Loss: -749.751953\n",
      "Train Epoch: 1238 [22528/54000 (42%)] Loss: -763.769592\n",
      "Train Epoch: 1238 [33792/54000 (63%)] Loss: -771.185730\n",
      "Train Epoch: 1238 [45056/54000 (83%)] Loss: -787.220581\n",
      "    epoch          : 1238\n",
      "    loss           : -765.6713965074072\n",
      "    ess            : 1.9591820251266912\n",
      "    log_marginal   : 765.7091738143057\n",
      "    log_joint      : 974.1709433501621\n",
      "    val_loss       : -769.0040334065756\n",
      "    val_ess        : 1.9571196933587391\n",
      "    val_log_marginal: 769.0460357666016\n",
      "    val_log_joint  : 977.3903147379557\n",
      "Train Epoch: 1239 [0/54000 (0%)] Loss: -747.424805\n",
      "Train Epoch: 1239 [11264/54000 (21%)] Loss: -772.678345\n",
      "Train Epoch: 1239 [22528/54000 (42%)] Loss: -773.043457\n",
      "Train Epoch: 1239 [33792/54000 (63%)] Loss: -762.589844\n",
      "Train Epoch: 1239 [45056/54000 (83%)] Loss: -755.758423\n",
      "    epoch          : 1239\n",
      "    loss           : -765.5152242408609\n",
      "    ess            : 1.9598027186573677\n",
      "    log_marginal   : 765.5516207713001\n",
      "    log_joint      : 974.1021503952314\n",
      "    val_loss       : -770.2685089111328\n",
      "    val_ess        : 1.9634860754013062\n",
      "    val_log_marginal: 770.3031056722006\n",
      "    val_log_joint  : 978.5604248046875\n",
      "Train Epoch: 1240 [0/54000 (0%)] Loss: -755.616699\n",
      "Train Epoch: 1240 [11264/54000 (21%)] Loss: -756.438232\n",
      "Train Epoch: 1240 [22528/54000 (42%)] Loss: -754.402161\n",
      "Train Epoch: 1240 [33792/54000 (63%)] Loss: -778.558716\n",
      "Train Epoch: 1240 [45056/54000 (83%)] Loss: -743.465637\n",
      "    epoch          : 1240\n",
      "    loss           : -765.7312432055203\n",
      "    ess            : 1.9607954610068843\n",
      "    log_marginal   : 765.7676011571344\n",
      "    log_joint      : 974.275063568691\n",
      "    val_loss       : -769.2056274414062\n",
      "    val_ess        : 1.9591965476671855\n",
      "    val_log_marginal: 769.2426096598307\n",
      "    val_log_joint  : 977.8676503499349\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1240.pth ...\n",
      "Train Epoch: 1241 [0/54000 (0%)] Loss: -770.272522\n",
      "Train Epoch: 1241 [11264/54000 (21%)] Loss: -761.196533\n",
      "Train Epoch: 1241 [22528/54000 (42%)] Loss: -781.080627\n",
      "Train Epoch: 1241 [33792/54000 (63%)] Loss: -748.508179\n",
      "Train Epoch: 1241 [45056/54000 (83%)] Loss: -765.108643\n",
      "    epoch          : 1241\n",
      "    loss           : -765.6883406729069\n",
      "    ess            : 1.9607339478888601\n",
      "    log_marginal   : 765.7252767310953\n",
      "    log_joint      : 974.2939458883034\n",
      "    val_loss       : -769.9489390055338\n",
      "    val_ess        : 1.9559766749540966\n",
      "    val_log_marginal: 769.9919281005859\n",
      "    val_log_joint  : 978.7423553466797\n",
      "Train Epoch: 1242 [0/54000 (0%)] Loss: -742.575317\n",
      "Train Epoch: 1242 [11264/54000 (21%)] Loss: -770.666504\n",
      "Train Epoch: 1242 [22528/54000 (42%)] Loss: -754.619507\n",
      "Train Epoch: 1242 [33792/54000 (63%)] Loss: -753.966187\n",
      "Train Epoch: 1242 [45056/54000 (83%)] Loss: -733.563965\n",
      "    epoch          : 1242\n",
      "    loss           : -765.7922357523216\n",
      "    ess            : 1.9599743350496832\n",
      "    log_marginal   : 765.8294562573703\n",
      "    log_joint      : 974.3644409179688\n",
      "    val_loss       : -769.6542510986328\n",
      "    val_ess        : 1.959615429242452\n",
      "    val_log_marginal: 769.6935679117838\n",
      "    val_log_joint  : 978.3209126790365\n",
      "Train Epoch: 1243 [0/54000 (0%)] Loss: -772.063354\n",
      "Train Epoch: 1243 [11264/54000 (21%)] Loss: -777.833191\n",
      "Train Epoch: 1243 [22528/54000 (42%)] Loss: -756.122559\n",
      "Train Epoch: 1243 [33792/54000 (63%)] Loss: -739.494751\n",
      "Train Epoch: 1243 [45056/54000 (83%)] Loss: -766.020752\n",
      "    epoch          : 1243\n",
      "    loss           : -765.7605913270195\n",
      "    ess            : 1.9590617789412446\n",
      "    log_marginal   : 765.7982120154039\n",
      "    log_joint      : 974.2927591575766\n",
      "    val_loss       : -770.1666717529297\n",
      "    val_ess        : 1.9588966071605682\n",
      "    val_log_marginal: 770.2056935628256\n",
      "    val_log_joint  : 978.8879241943359\n",
      "Train Epoch: 1244 [0/54000 (0%)] Loss: -773.558228\n",
      "Train Epoch: 1244 [11264/54000 (21%)] Loss: -746.159546\n",
      "Train Epoch: 1244 [22528/54000 (42%)] Loss: -770.214600\n",
      "Train Epoch: 1244 [33792/54000 (63%)] Loss: -771.080444\n",
      "Train Epoch: 1244 [45056/54000 (83%)] Loss: -749.216675\n",
      "    epoch          : 1244\n",
      "    loss           : -765.7880893923202\n",
      "    ess            : 1.9608505739355988\n",
      "    log_marginal   : 765.8242717239092\n",
      "    log_joint      : 974.377832376732\n",
      "    val_loss       : -769.8479054768881\n",
      "    val_ess        : 1.9594011108080547\n",
      "    val_log_marginal: 769.8878835042318\n",
      "    val_log_joint  : 978.2394104003906\n",
      "Train Epoch: 1245 [0/54000 (0%)] Loss: -781.237732\n",
      "Train Epoch: 1245 [11264/54000 (21%)] Loss: -765.787231\n",
      "Train Epoch: 1245 [22528/54000 (42%)] Loss: -770.173218\n",
      "Train Epoch: 1245 [33792/54000 (63%)] Loss: -767.973511\n",
      "Train Epoch: 1245 [45056/54000 (83%)] Loss: -755.614990\n",
      "    epoch          : 1245\n",
      "    loss           : -765.7556348116892\n",
      "    ess            : 1.9601498741023946\n",
      "    log_marginal   : 765.7935744951357\n",
      "    log_joint      : 974.335978957842\n",
      "    val_loss       : -769.8683420817057\n",
      "    val_ess        : 1.9607609510421753\n",
      "    val_log_marginal: 769.904286702474\n",
      "    val_log_joint  : 978.4531809488932\n",
      "Train Epoch: 1246 [0/54000 (0%)] Loss: -772.649170\n",
      "Train Epoch: 1246 [11264/54000 (21%)] Loss: -774.156128\n",
      "Train Epoch: 1246 [22528/54000 (42%)] Loss: -760.834106\n",
      "Train Epoch: 1246 [33792/54000 (63%)] Loss: -744.513428\n",
      "Train Epoch: 1246 [45056/54000 (83%)] Loss: -769.840210\n",
      "    epoch          : 1246\n",
      "    loss           : -765.7362786059109\n",
      "    ess            : 1.9607017996176235\n",
      "    log_marginal   : 765.7733206119177\n",
      "    log_joint      : 974.4110579580631\n",
      "    val_loss       : -770.1023406982422\n",
      "    val_ess        : 1.9594621360301971\n",
      "    val_log_marginal: 770.1419677734375\n",
      "    val_log_joint  : 978.7797495524088\n",
      "Train Epoch: 1247 [0/54000 (0%)] Loss: -733.826782\n",
      "Train Epoch: 1247 [11264/54000 (21%)] Loss: -770.831360\n",
      "Train Epoch: 1247 [22528/54000 (42%)] Loss: -764.637024\n",
      "Train Epoch: 1247 [33792/54000 (63%)] Loss: -767.486450\n",
      "Train Epoch: 1247 [45056/54000 (83%)] Loss: -776.878418\n",
      "    epoch          : 1247\n",
      "    loss           : -765.7952886617409\n",
      "    ess            : 1.960452474513144\n",
      "    log_marginal   : 765.8323151210569\n",
      "    log_joint      : 974.4108558510834\n",
      "    val_loss       : -771.0328877766927\n",
      "    val_ess        : 1.9602424999078114\n",
      "    val_log_marginal: 771.0723114013672\n",
      "    val_log_joint  : 979.2103576660156\n",
      "Train Epoch: 1248 [0/54000 (0%)] Loss: -756.439575\n",
      "Train Epoch: 1248 [11264/54000 (21%)] Loss: -778.754395\n",
      "Train Epoch: 1248 [22528/54000 (42%)] Loss: -745.750244\n",
      "Train Epoch: 1248 [33792/54000 (63%)] Loss: -735.996582\n",
      "Train Epoch: 1248 [45056/54000 (83%)] Loss: -784.927856\n",
      "    epoch          : 1248\n",
      "    loss           : -765.9372501013414\n",
      "    ess            : 1.960988551940558\n",
      "    log_marginal   : 765.9729090276754\n",
      "    log_joint      : 974.5590186928803\n",
      "    val_loss       : -770.1042073567709\n",
      "    val_ess        : 1.9587878088156383\n",
      "    val_log_marginal: 770.143564860026\n",
      "    val_log_joint  : 978.4535675048828\n",
      "Train Epoch: 1249 [0/54000 (0%)] Loss: -773.454895\n",
      "Train Epoch: 1249 [11264/54000 (21%)] Loss: -770.720825\n",
      "Train Epoch: 1249 [22528/54000 (42%)] Loss: -752.889648\n",
      "Train Epoch: 1249 [33792/54000 (63%)] Loss: -776.218018\n",
      "Train Epoch: 1249 [45056/54000 (83%)] Loss: -765.601196\n",
      "    epoch          : 1249\n",
      "    loss           : -766.1113143057194\n",
      "    ess            : 1.9596500374236197\n",
      "    log_marginal   : 766.1488630186836\n",
      "    log_joint      : 974.5480260309183\n",
      "    val_loss       : -770.3732452392578\n",
      "    val_ess        : 1.9554474552472432\n",
      "    val_log_marginal: 770.4177805582682\n",
      "    val_log_joint  : 978.7851969401041\n",
      "Train Epoch: 1250 [0/54000 (0%)] Loss: -771.943726\n",
      "Train Epoch: 1250 [11264/54000 (21%)] Loss: -770.040466\n",
      "Train Epoch: 1250 [22528/54000 (42%)] Loss: -761.558472\n",
      "Train Epoch: 1250 [33792/54000 (63%)] Loss: -755.603149\n",
      "Train Epoch: 1250 [45056/54000 (83%)] Loss: -743.387207\n",
      "    epoch          : 1250\n",
      "    loss           : -766.0009316498379\n",
      "    ess            : 1.9599106019397952\n",
      "    log_marginal   : 766.0366844321197\n",
      "    log_joint      : 974.5342073260613\n",
      "    val_loss       : -770.5297648111979\n",
      "    val_ess        : 1.9594286779562633\n",
      "    val_log_marginal: 770.5680236816406\n",
      "    val_log_joint  : 979.1814524332682\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1250.pth ...\n",
      "Train Epoch: 1251 [0/54000 (0%)] Loss: -769.530762\n",
      "Train Epoch: 1251 [11264/54000 (21%)] Loss: -781.474243\n",
      "Train Epoch: 1251 [22528/54000 (42%)] Loss: -770.191650\n",
      "Train Epoch: 1251 [33792/54000 (63%)] Loss: -736.549744\n",
      "Train Epoch: 1251 [45056/54000 (83%)] Loss: -753.479736\n",
      "    epoch          : 1251\n",
      "    loss           : -765.9940698011866\n",
      "    ess            : 1.959070454228599\n",
      "    log_marginal   : 766.0335215442585\n",
      "    log_joint      : 974.5695530153671\n",
      "    val_loss       : -770.0058797200521\n",
      "    val_ess        : 1.9570728143056233\n",
      "    val_log_marginal: 770.0435892740885\n",
      "    val_log_joint  : 978.6902669270834\n",
      "Train Epoch: 1252 [0/54000 (0%)] Loss: -769.849731\n",
      "Train Epoch: 1252 [11264/54000 (21%)] Loss: -782.455811\n",
      "Train Epoch: 1252 [22528/54000 (42%)] Loss: -797.298157\n",
      "Train Epoch: 1252 [33792/54000 (63%)] Loss: -773.391602\n",
      "Train Epoch: 1252 [45056/54000 (83%)] Loss: -765.624329\n",
      "    epoch          : 1252\n",
      "    loss           : -766.1455705750664\n",
      "    ess            : 1.9615491999770112\n",
      "    log_marginal   : 766.180587480653\n",
      "    log_joint      : 974.6381674712559\n",
      "    val_loss       : -771.1941426595052\n",
      "    val_ess        : 1.9641862014929454\n",
      "    val_log_marginal: 771.2242635091146\n",
      "    val_log_joint  : 979.8785451253256\n",
      "Train Epoch: 1253 [0/54000 (0%)] Loss: -755.638672\n",
      "Train Epoch: 1253 [11264/54000 (21%)] Loss: -758.916992\n",
      "Train Epoch: 1253 [22528/54000 (42%)] Loss: -770.812012\n",
      "Train Epoch: 1253 [33792/54000 (63%)] Loss: -792.086792\n",
      "Train Epoch: 1253 [45056/54000 (83%)] Loss: -770.866699\n",
      "    epoch          : 1253\n",
      "    loss           : -766.2729584316038\n",
      "    ess            : 1.95879188123739\n",
      "    log_marginal   : 766.3109176923643\n",
      "    log_joint      : 974.7543329202904\n",
      "    val_loss       : -771.0037180582682\n",
      "    val_ess        : 1.960453748703003\n",
      "    val_log_marginal: 771.0385182698568\n",
      "    val_log_joint  : 979.4475708007812\n",
      "Train Epoch: 1254 [0/54000 (0%)] Loss: -760.652283\n",
      "Train Epoch: 1254 [11264/54000 (21%)] Loss: -761.221436\n",
      "Train Epoch: 1254 [22528/54000 (42%)] Loss: -771.807251\n",
      "Train Epoch: 1254 [33792/54000 (63%)] Loss: -753.830383\n",
      "Train Epoch: 1254 [45056/54000 (83%)] Loss: -781.595642\n",
      "    epoch          : 1254\n",
      "    loss           : -765.995870338296\n",
      "    ess            : 1.9602114648189184\n",
      "    log_marginal   : 766.0328518849499\n",
      "    log_joint      : 974.629862083579\n",
      "    val_loss       : -770.9867197672526\n",
      "    val_ess        : 1.9584335386753082\n",
      "    val_log_marginal: 771.0289713541666\n",
      "    val_log_joint  : 979.8723704020182\n",
      "Train Epoch: 1255 [0/54000 (0%)] Loss: -769.676636\n",
      "Train Epoch: 1255 [11264/54000 (21%)] Loss: -760.272095\n",
      "Train Epoch: 1255 [22528/54000 (42%)] Loss: -760.028931\n",
      "Train Epoch: 1255 [33792/54000 (63%)] Loss: -767.713501\n",
      "Train Epoch: 1255 [45056/54000 (83%)] Loss: -776.596558\n",
      "    epoch          : 1255\n",
      "    loss           : -765.9411805350826\n",
      "    ess            : 1.9600524216328028\n",
      "    log_marginal   : 765.9798054245283\n",
      "    log_joint      : 974.5458114911925\n",
      "    val_loss       : -770.4986979166666\n",
      "    val_ess        : 1.9587547878424327\n",
      "    val_log_marginal: 770.5366414388021\n",
      "    val_log_joint  : 979.2560729980469\n",
      "Train Epoch: 1256 [0/54000 (0%)] Loss: -742.256531\n",
      "Train Epoch: 1256 [11264/54000 (21%)] Loss: -772.659302\n",
      "Train Epoch: 1256 [22528/54000 (42%)] Loss: -775.470459\n",
      "Train Epoch: 1256 [33792/54000 (63%)] Loss: -770.881714\n",
      "Train Epoch: 1256 [45056/54000 (83%)] Loss: -763.280273\n",
      "    epoch          : 1256\n",
      "    loss           : -766.1462811164137\n",
      "    ess            : 1.9593720368619234\n",
      "    log_marginal   : 766.183893743551\n",
      "    log_joint      : 974.6507119232754\n",
      "    val_loss       : -770.3076629638672\n",
      "    val_ess        : 1.9617819090684254\n",
      "    val_log_marginal: 770.3397827148438\n",
      "    val_log_joint  : 978.67822265625\n",
      "Train Epoch: 1257 [0/54000 (0%)] Loss: -759.796265\n",
      "Train Epoch: 1257 [11264/54000 (21%)] Loss: -791.787964\n",
      "Train Epoch: 1257 [22528/54000 (42%)] Loss: -753.137756\n",
      "Train Epoch: 1257 [33792/54000 (63%)] Loss: -762.016357\n",
      "Train Epoch: 1257 [45056/54000 (83%)] Loss: -768.636902\n",
      "    epoch          : 1257\n",
      "    loss           : -766.1697324356943\n",
      "    ess            : 1.9595291861947977\n",
      "    log_marginal   : 766.2091081727226\n",
      "    log_joint      : 974.730148027528\n",
      "    val_loss       : -770.3700714111328\n",
      "    val_ess        : 1.9590012729167938\n",
      "    val_log_marginal: 770.4091746012369\n",
      "    val_log_joint  : 979.2451731363932\n",
      "Train Epoch: 1258 [0/54000 (0%)] Loss: -782.391357\n",
      "Train Epoch: 1258 [11264/54000 (21%)] Loss: -776.500854\n",
      "Train Epoch: 1258 [22528/54000 (42%)] Loss: -776.842529\n",
      "Train Epoch: 1258 [33792/54000 (63%)] Loss: -776.024658\n",
      "Train Epoch: 1258 [45056/54000 (83%)] Loss: -772.897095\n",
      "    epoch          : 1258\n",
      "    loss           : -766.016266444944\n",
      "    ess            : 1.9596836049601716\n",
      "    log_marginal   : 766.0528501114755\n",
      "    log_joint      : 974.6225269245651\n",
      "    val_loss       : -771.2340850830078\n",
      "    val_ess        : 1.958632489045461\n",
      "    val_log_marginal: 771.2694040934244\n",
      "    val_log_joint  : 979.8791097005209\n",
      "Train Epoch: 1259 [0/54000 (0%)] Loss: -782.808472\n",
      "Train Epoch: 1259 [11264/54000 (21%)] Loss: -761.365112\n",
      "Train Epoch: 1259 [22528/54000 (42%)] Loss: -761.145142\n",
      "Train Epoch: 1259 [33792/54000 (63%)] Loss: -759.325623\n",
      "Train Epoch: 1259 [45056/54000 (83%)] Loss: -773.871826\n",
      "    epoch          : 1259\n",
      "    loss           : -766.1518859863281\n",
      "    ess            : 1.9593638597794298\n",
      "    log_marginal   : 766.1891583136793\n",
      "    log_joint      : 974.8121481841465\n",
      "    val_loss       : -769.8039194742838\n",
      "    val_ess        : 1.9601266086101532\n",
      "    val_log_marginal: 769.8401997884115\n",
      "    val_log_joint  : 978.741455078125\n",
      "Train Epoch: 1260 [0/54000 (0%)] Loss: -748.328552\n",
      "Train Epoch: 1260 [11264/54000 (21%)] Loss: -784.579102\n",
      "Train Epoch: 1260 [22528/54000 (42%)] Loss: -773.235962\n",
      "Train Epoch: 1260 [33792/54000 (63%)] Loss: -769.783508\n",
      "Train Epoch: 1260 [45056/54000 (83%)] Loss: -772.987427\n",
      "    epoch          : 1260\n",
      "    loss           : -766.45689248139\n",
      "    ess            : 1.9601796741755504\n",
      "    log_marginal   : 766.4938763312574\n",
      "    log_joint      : 975.0301715203051\n",
      "    val_loss       : -770.9429321289062\n",
      "    val_ess        : 1.9612374901771545\n",
      "    val_log_marginal: 770.9820149739584\n",
      "    val_log_joint  : 979.7608083089193\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1260.pth ...\n",
      "Train Epoch: 1261 [0/54000 (0%)] Loss: -783.083740\n",
      "Train Epoch: 1261 [11264/54000 (21%)] Loss: -761.204590\n",
      "Train Epoch: 1261 [22528/54000 (42%)] Loss: -753.653931\n",
      "Train Epoch: 1261 [33792/54000 (63%)] Loss: -754.130798\n",
      "Train Epoch: 1261 [45056/54000 (83%)] Loss: -771.395935\n",
      "    epoch          : 1261\n",
      "    loss           : -766.3586149395637\n",
      "    ess            : 1.9606854949357375\n",
      "    log_marginal   : 766.3949970749189\n",
      "    log_joint      : 974.8499341280955\n",
      "    val_loss       : -771.4702707926432\n",
      "    val_ess        : 1.9599004685878754\n",
      "    val_log_marginal: 771.5070444742838\n",
      "    val_log_joint  : 979.9792124430338\n",
      "Train Epoch: 1262 [0/54000 (0%)] Loss: -798.874268\n",
      "Train Epoch: 1262 [11264/54000 (21%)] Loss: -758.679871\n",
      "Train Epoch: 1262 [22528/54000 (42%)] Loss: -782.967285\n",
      "Train Epoch: 1262 [33792/54000 (63%)] Loss: -761.220947\n",
      "Train Epoch: 1262 [45056/54000 (83%)] Loss: -767.314087\n",
      "    epoch          : 1262\n",
      "    loss           : -766.2770742740271\n",
      "    ess            : 1.9592773385767668\n",
      "    log_marginal   : 766.3134592883991\n",
      "    log_joint      : 974.8898891233048\n",
      "    val_loss       : -770.5314381917318\n",
      "    val_ess        : 1.9607279400030773\n",
      "    val_log_marginal: 770.5656890869141\n",
      "    val_log_joint  : 979.1411437988281\n",
      "Train Epoch: 1263 [0/54000 (0%)] Loss: -768.689026\n",
      "Train Epoch: 1263 [11264/54000 (21%)] Loss: -773.225220\n",
      "Train Epoch: 1263 [22528/54000 (42%)] Loss: -761.901062\n",
      "Train Epoch: 1263 [33792/54000 (63%)] Loss: -777.540283\n",
      "Train Epoch: 1263 [45056/54000 (83%)] Loss: -757.456299\n",
      "    epoch          : 1263\n",
      "    loss           : -766.4936120375147\n",
      "    ess            : 1.9608664535126596\n",
      "    log_marginal   : 766.5294408258402\n",
      "    log_joint      : 975.0105798109522\n",
      "    val_loss       : -772.2630259195963\n",
      "    val_ess        : 1.9601645171642303\n",
      "    val_log_marginal: 772.3011525472006\n",
      "    val_log_joint  : 980.7776184082031\n",
      "Train Epoch: 1264 [0/54000 (0%)] Loss: -755.562439\n",
      "Train Epoch: 1264 [11264/54000 (21%)] Loss: -765.160889\n",
      "Train Epoch: 1264 [22528/54000 (42%)] Loss: -794.839966\n",
      "Train Epoch: 1264 [33792/54000 (63%)] Loss: -789.051575\n",
      "Train Epoch: 1264 [45056/54000 (83%)] Loss: -775.705627\n",
      "    epoch          : 1264\n",
      "    loss           : -766.4501066387825\n",
      "    ess            : 1.960668941713729\n",
      "    log_marginal   : 766.4872367427034\n",
      "    log_joint      : 975.0181930829893\n",
      "    val_loss       : -770.8087717692057\n",
      "    val_ess        : 1.9576137562592824\n",
      "    val_log_marginal: 770.8467864990234\n",
      "    val_log_joint  : 979.2649078369141\n",
      "Train Epoch: 1265 [0/54000 (0%)] Loss: -802.038574\n",
      "Train Epoch: 1265 [11264/54000 (21%)] Loss: -743.771484\n",
      "Train Epoch: 1265 [22528/54000 (42%)] Loss: -756.907837\n",
      "Train Epoch: 1265 [33792/54000 (63%)] Loss: -756.377441\n",
      "Train Epoch: 1265 [45056/54000 (83%)] Loss: -761.907715\n",
      "    epoch          : 1265\n",
      "    loss           : -766.5009857753538\n",
      "    ess            : 1.9595183359002166\n",
      "    log_marginal   : 766.5390095260908\n",
      "    log_joint      : 975.0442193948998\n",
      "    val_loss       : -770.9123586018881\n",
      "    val_ess        : 1.9631642997264862\n",
      "    val_log_marginal: 770.9447224934896\n",
      "    val_log_joint  : 979.6086680094401\n",
      "Train Epoch: 1266 [0/54000 (0%)] Loss: -784.775024\n",
      "Train Epoch: 1266 [11264/54000 (21%)] Loss: -765.076050\n",
      "Train Epoch: 1266 [22528/54000 (42%)] Loss: -772.236938\n",
      "Train Epoch: 1266 [33792/54000 (63%)] Loss: -765.265320\n",
      "Train Epoch: 1266 [45056/54000 (83%)] Loss: -770.827515\n",
      "    epoch          : 1266\n",
      "    loss           : -766.5271105496389\n",
      "    ess            : 1.9600174112140007\n",
      "    log_marginal   : 766.562609978442\n",
      "    log_joint      : 975.1148336158609\n",
      "    val_loss       : -770.8677622477213\n",
      "    val_ess        : 1.961064080397288\n",
      "    val_log_marginal: 770.9052530924479\n",
      "    val_log_joint  : 979.5509541829427\n",
      "Train Epoch: 1267 [0/54000 (0%)] Loss: -771.286133\n",
      "Train Epoch: 1267 [11264/54000 (21%)] Loss: -767.363281\n",
      "Train Epoch: 1267 [22528/54000 (42%)] Loss: -772.860779\n",
      "Train Epoch: 1267 [33792/54000 (63%)] Loss: -757.835693\n",
      "Train Epoch: 1267 [45056/54000 (83%)] Loss: -750.147400\n",
      "    epoch          : 1267\n",
      "    loss           : -766.4408563577904\n",
      "    ess            : 1.960078795001192\n",
      "    log_marginal   : 766.478501229916\n",
      "    log_joint      : 975.020067322929\n",
      "    val_loss       : -771.0585988362631\n",
      "    val_ess        : 1.9637995262940724\n",
      "    val_log_marginal: 771.0932210286459\n",
      "    val_log_joint  : 979.7363840738932\n",
      "Train Epoch: 1268 [0/54000 (0%)] Loss: -755.016846\n",
      "Train Epoch: 1268 [11264/54000 (21%)] Loss: -765.193359\n",
      "Train Epoch: 1268 [22528/54000 (42%)] Loss: -768.192871\n",
      "Train Epoch: 1268 [33792/54000 (63%)] Loss: -788.242310\n",
      "Train Epoch: 1268 [45056/54000 (83%)] Loss: -791.482727\n",
      "    epoch          : 1268\n",
      "    loss           : -766.5613604851488\n",
      "    ess            : 1.961478348048228\n",
      "    log_marginal   : 766.5972439747936\n",
      "    log_joint      : 975.0141883706146\n",
      "    val_loss       : -771.3540089925131\n",
      "    val_ess        : 1.9608482420444489\n",
      "    val_log_marginal: 771.3901316324869\n",
      "    val_log_joint  : 979.8927917480469\n",
      "Train Epoch: 1269 [0/54000 (0%)] Loss: -750.279358\n",
      "Train Epoch: 1269 [11264/54000 (21%)] Loss: -763.200684\n",
      "Train Epoch: 1269 [22528/54000 (42%)] Loss: -751.779785\n",
      "Train Epoch: 1269 [33792/54000 (63%)] Loss: -754.552795\n",
      "Train Epoch: 1269 [45056/54000 (83%)] Loss: -792.730042\n",
      "    epoch          : 1269\n",
      "    loss           : -766.6657415426002\n",
      "    ess            : 1.9596460664047386\n",
      "    log_marginal   : 766.7036812260466\n",
      "    log_joint      : 975.2061485434479\n",
      "    val_loss       : -770.5279490152994\n",
      "    val_ess        : 1.9587979714075725\n",
      "    val_log_marginal: 770.568125406901\n",
      "    val_log_joint  : 979.2189483642578\n",
      "Train Epoch: 1270 [0/54000 (0%)] Loss: -755.497559\n",
      "Train Epoch: 1270 [11264/54000 (21%)] Loss: -749.808838\n",
      "Train Epoch: 1270 [22528/54000 (42%)] Loss: -770.626770\n",
      "Train Epoch: 1270 [33792/54000 (63%)] Loss: -779.029663\n",
      "Train Epoch: 1270 [45056/54000 (83%)] Loss: -759.482178\n",
      "    epoch          : 1270\n",
      "    loss           : -766.4679381172612\n",
      "    ess            : 1.9598272487802326\n",
      "    log_marginal   : 766.5055766555498\n",
      "    log_joint      : 975.074280936763\n",
      "    val_loss       : -771.5485788981119\n",
      "    val_ess        : 1.9588993887106578\n",
      "    val_log_marginal: 771.5857137044271\n",
      "    val_log_joint  : 979.9997049967448\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1270.pth ...\n",
      "Train Epoch: 1271 [0/54000 (0%)] Loss: -757.023682\n",
      "Train Epoch: 1271 [11264/54000 (21%)] Loss: -765.811462\n",
      "Train Epoch: 1271 [22528/54000 (42%)] Loss: -780.497192\n",
      "Train Epoch: 1271 [33792/54000 (63%)] Loss: -756.250549\n",
      "Train Epoch: 1271 [45056/54000 (83%)] Loss: -767.263855\n",
      "    epoch          : 1271\n",
      "    loss           : -766.7805601875737\n",
      "    ess            : 1.9603910165013008\n",
      "    log_marginal   : 766.8172325278229\n",
      "    log_joint      : 975.2786364285452\n",
      "    val_loss       : -770.815185546875\n",
      "    val_ess        : 1.9594126840432484\n",
      "    val_log_marginal: 770.8545837402344\n",
      "    val_log_joint  : 979.1187642415365\n",
      "Train Epoch: 1272 [0/54000 (0%)] Loss: -779.937866\n",
      "Train Epoch: 1272 [11264/54000 (21%)] Loss: -773.941223\n",
      "Train Epoch: 1272 [22528/54000 (42%)] Loss: -764.828857\n",
      "Train Epoch: 1272 [33792/54000 (63%)] Loss: -765.657715\n",
      "Train Epoch: 1272 [45056/54000 (83%)] Loss: -754.432861\n",
      "    epoch          : 1272\n",
      "    loss           : -766.6094268223025\n",
      "    ess            : 1.960564838265473\n",
      "    log_marginal   : 766.6442197403818\n",
      "    log_joint      : 975.202142103663\n",
      "    val_loss       : -771.5337422688802\n",
      "    val_ess        : 1.9600072701772053\n",
      "    val_log_marginal: 771.5698852539062\n",
      "    val_log_joint  : 980.3190409342448\n",
      "Train Epoch: 1273 [0/54000 (0%)] Loss: -762.808960\n",
      "Train Epoch: 1273 [11264/54000 (21%)] Loss: -770.720886\n",
      "Train Epoch: 1273 [22528/54000 (42%)] Loss: -743.562988\n",
      "Train Epoch: 1273 [33792/54000 (63%)] Loss: -791.951172\n",
      "Train Epoch: 1273 [45056/54000 (83%)] Loss: -759.756958\n",
      "    epoch          : 1273\n",
      "    loss           : -766.5728063043558\n",
      "    ess            : 1.960239295689565\n",
      "    log_marginal   : 766.609242565227\n",
      "    log_joint      : 975.1512312979069\n",
      "    val_loss       : -770.7602132161459\n",
      "    val_ess        : 1.9614926278591156\n",
      "    val_log_marginal: 770.7980499267578\n",
      "    val_log_joint  : 979.1310729980469\n",
      "Train Epoch: 1274 [0/54000 (0%)] Loss: -754.131714\n",
      "Train Epoch: 1274 [11264/54000 (21%)] Loss: -756.127747\n",
      "Train Epoch: 1274 [22528/54000 (42%)] Loss: -764.672974\n",
      "Train Epoch: 1274 [33792/54000 (63%)] Loss: -748.486023\n",
      "Train Epoch: 1274 [45056/54000 (83%)] Loss: -784.810120\n",
      "    epoch          : 1274\n",
      "    loss           : -766.6541817143278\n",
      "    ess            : 1.9600380850288104\n",
      "    log_marginal   : 766.6916532696418\n",
      "    log_joint      : 975.2689059275501\n",
      "    val_loss       : -771.0822397867838\n",
      "    val_ess        : 1.9620045522848766\n",
      "    val_log_marginal: 771.1163177490234\n",
      "    val_log_joint  : 979.6579844156901\n",
      "Train Epoch: 1275 [0/54000 (0%)] Loss: -769.479736\n",
      "Train Epoch: 1275 [11264/54000 (21%)] Loss: -776.164734\n",
      "Train Epoch: 1275 [22528/54000 (42%)] Loss: -766.033691\n",
      "Train Epoch: 1275 [33792/54000 (63%)] Loss: -759.621399\n",
      "Train Epoch: 1275 [45056/54000 (83%)] Loss: -767.093750\n",
      "    epoch          : 1275\n",
      "    loss           : -766.6475098807857\n",
      "    ess            : 1.9605114246314426\n",
      "    log_marginal   : 766.6835511405513\n",
      "    log_joint      : 975.1508777546433\n",
      "    val_loss       : -771.4472147623698\n",
      "    val_ess        : 1.96288858850797\n",
      "    val_log_marginal: 771.479736328125\n",
      "    val_log_joint  : 979.8367207845052\n",
      "Train Epoch: 1276 [0/54000 (0%)] Loss: -753.161011\n",
      "Train Epoch: 1276 [11264/54000 (21%)] Loss: -786.318604\n",
      "Train Epoch: 1276 [22528/54000 (42%)] Loss: -749.802979\n",
      "Train Epoch: 1276 [33792/54000 (63%)] Loss: -751.124512\n",
      "Train Epoch: 1276 [45056/54000 (83%)] Loss: -777.872681\n",
      "    epoch          : 1276\n",
      "    loss           : -766.5102003565374\n",
      "    ess            : 1.959207812570176\n",
      "    log_marginal   : 766.5482033783535\n",
      "    log_joint      : 975.0996134056235\n",
      "    val_loss       : -770.6663462320963\n",
      "    val_ess        : 1.9531669517358143\n",
      "    val_log_marginal: 770.7090861002604\n",
      "    val_log_joint  : 979.170908610026\n",
      "Train Epoch: 1277 [0/54000 (0%)] Loss: -768.939453\n",
      "Train Epoch: 1277 [11264/54000 (21%)] Loss: -772.461914\n",
      "Train Epoch: 1277 [22528/54000 (42%)] Loss: -760.632324\n",
      "Train Epoch: 1277 [33792/54000 (63%)] Loss: -741.538696\n",
      "Train Epoch: 1277 [45056/54000 (83%)] Loss: -766.915100\n",
      "    epoch          : 1277\n",
      "    loss           : -766.6868994370947\n",
      "    ess            : 1.9593229046407736\n",
      "    log_marginal   : 766.7235844450177\n",
      "    log_joint      : 975.2520060989092\n",
      "    val_loss       : -770.6928965250651\n",
      "    val_ess        : 1.9584734439849854\n",
      "    val_log_marginal: 770.7327880859375\n",
      "    val_log_joint  : 979.4144337972006\n",
      "Train Epoch: 1278 [0/54000 (0%)] Loss: -777.296631\n",
      "Train Epoch: 1278 [11264/54000 (21%)] Loss: -783.145874\n",
      "Train Epoch: 1278 [22528/54000 (42%)] Loss: -770.799988\n",
      "Train Epoch: 1278 [33792/54000 (63%)] Loss: -757.471069\n",
      "Train Epoch: 1278 [45056/54000 (83%)] Loss: -777.290344\n",
      "    epoch          : 1278\n",
      "    loss           : -766.8965160441849\n",
      "    ess            : 1.959953933391931\n",
      "    log_marginal   : 766.9343382637455\n",
      "    log_joint      : 975.4524795244325\n",
      "    val_loss       : -770.2447001139323\n",
      "    val_ess        : 1.9552658398946126\n",
      "    val_log_marginal: 770.2865753173828\n",
      "    val_log_joint  : 978.9274037679037\n",
      "Train Epoch: 1279 [0/54000 (0%)] Loss: -750.561401\n",
      "Train Epoch: 1279 [11264/54000 (21%)] Loss: -770.071350\n",
      "Train Epoch: 1279 [22528/54000 (42%)] Loss: -791.467651\n",
      "Train Epoch: 1279 [33792/54000 (63%)] Loss: -762.550171\n",
      "Train Epoch: 1279 [45056/54000 (83%)] Loss: -760.292969\n",
      "    epoch          : 1279\n",
      "    loss           : -766.8111975327978\n",
      "    ess            : 1.9601311863593336\n",
      "    log_marginal   : 766.8473481952019\n",
      "    log_joint      : 975.3255114285452\n",
      "    val_loss       : -771.2183125813802\n",
      "    val_ess        : 1.9613663057486217\n",
      "    val_log_marginal: 771.2524668375651\n",
      "    val_log_joint  : 980.0471038818359\n",
      "Train Epoch: 1280 [0/54000 (0%)] Loss: -803.134460\n",
      "Train Epoch: 1280 [11264/54000 (21%)] Loss: -735.741943\n",
      "Train Epoch: 1280 [22528/54000 (42%)] Loss: -762.041321\n",
      "Train Epoch: 1280 [33792/54000 (63%)] Loss: -774.227173\n",
      "Train Epoch: 1280 [45056/54000 (83%)] Loss: -768.344238\n",
      "    epoch          : 1280\n",
      "    loss           : -766.6418819787367\n",
      "    ess            : 1.9589197613158316\n",
      "    log_marginal   : 766.6801527491156\n",
      "    log_joint      : 975.2118628160009\n",
      "    val_loss       : -770.9566650390625\n",
      "    val_ess        : 1.961597889661789\n",
      "    val_log_marginal: 770.9892374674479\n",
      "    val_log_joint  : 979.3231811523438\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1280.pth ...\n",
      "Train Epoch: 1281 [0/54000 (0%)] Loss: -775.403687\n",
      "Train Epoch: 1281 [11264/54000 (21%)] Loss: -772.186890\n",
      "Train Epoch: 1281 [22528/54000 (42%)] Loss: -766.051880\n",
      "Train Epoch: 1281 [33792/54000 (63%)] Loss: -761.521301\n",
      "Train Epoch: 1281 [45056/54000 (83%)] Loss: -765.963928\n",
      "    epoch          : 1281\n",
      "    loss           : -767.0122876437205\n",
      "    ess            : 1.9601416531598792\n",
      "    log_marginal   : 767.0491661215729\n",
      "    log_joint      : 975.5885228570902\n",
      "    val_loss       : -770.5497639973959\n",
      "    val_ess        : 1.9593040148417156\n",
      "    val_log_marginal: 770.5920664469401\n",
      "    val_log_joint  : 978.9295959472656\n",
      "Train Epoch: 1282 [0/54000 (0%)] Loss: -757.021240\n",
      "Train Epoch: 1282 [11264/54000 (21%)] Loss: -758.696289\n",
      "Train Epoch: 1282 [22528/54000 (42%)] Loss: -775.224121\n",
      "Train Epoch: 1282 [33792/54000 (63%)] Loss: -788.265381\n",
      "Train Epoch: 1282 [45056/54000 (83%)] Loss: -749.035828\n",
      "    epoch          : 1282\n",
      "    loss           : -766.8811144558889\n",
      "    ess            : 1.9588869697642777\n",
      "    log_marginal   : 766.9193650731501\n",
      "    log_joint      : 975.4118289587633\n",
      "    val_loss       : -771.4327189127604\n",
      "    val_ess        : 1.9635350108146667\n",
      "    val_log_marginal: 771.4651692708334\n",
      "    val_log_joint  : 979.8385925292969\n",
      "Train Epoch: 1283 [0/54000 (0%)] Loss: -763.532410\n",
      "Train Epoch: 1283 [11264/54000 (21%)] Loss: -789.075684\n",
      "Train Epoch: 1283 [22528/54000 (42%)] Loss: -779.541992\n",
      "Train Epoch: 1283 [33792/54000 (63%)] Loss: -771.414551\n",
      "Train Epoch: 1283 [45056/54000 (83%)] Loss: -753.850464\n",
      "    epoch          : 1283\n",
      "    loss           : -766.905498576614\n",
      "    ess            : 1.9594044921533116\n",
      "    log_marginal   : 766.9444493707621\n",
      "    log_joint      : 975.4786163905882\n",
      "    val_loss       : -771.2791392008463\n",
      "    val_ess        : 1.957603931427002\n",
      "    val_log_marginal: 771.3177591959635\n",
      "    val_log_joint  : 979.7775421142578\n",
      "Train Epoch: 1284 [0/54000 (0%)] Loss: -763.954468\n",
      "Train Epoch: 1284 [11264/54000 (21%)] Loss: -767.444458\n",
      "Train Epoch: 1284 [22528/54000 (42%)] Loss: -787.721680\n",
      "Train Epoch: 1284 [33792/54000 (63%)] Loss: -773.067627\n",
      "Train Epoch: 1284 [45056/54000 (83%)] Loss: -771.114258\n",
      "    epoch          : 1284\n",
      "    loss           : -766.973235508181\n",
      "    ess            : 1.9603974954137262\n",
      "    log_marginal   : 767.009639524064\n",
      "    log_joint      : 975.498988313495\n",
      "    val_loss       : -771.4064737955729\n",
      "    val_ess        : 1.961560696363449\n",
      "    val_log_marginal: 771.4379730224609\n",
      "    val_log_joint  : 979.7896372477213\n",
      "Train Epoch: 1285 [0/54000 (0%)] Loss: -763.419189\n",
      "Train Epoch: 1285 [11264/54000 (21%)] Loss: -761.329773\n",
      "Train Epoch: 1285 [22528/54000 (42%)] Loss: -764.130005\n",
      "Train Epoch: 1285 [33792/54000 (63%)] Loss: -762.214905\n",
      "Train Epoch: 1285 [45056/54000 (83%)] Loss: -770.515625\n",
      "    epoch          : 1285\n",
      "    loss           : -766.8326300854953\n",
      "    ess            : 1.9600576139845938\n",
      "    log_marginal   : 766.8699168079304\n",
      "    log_joint      : 975.4410141279112\n",
      "    val_loss       : -771.3378651936849\n",
      "    val_ess        : 1.9643465876579285\n",
      "    val_log_marginal: 771.3668721516927\n",
      "    val_log_joint  : 979.9092559814453\n",
      "Train Epoch: 1286 [0/54000 (0%)] Loss: -770.887512\n",
      "Train Epoch: 1286 [11264/54000 (21%)] Loss: -764.929810\n",
      "Train Epoch: 1286 [22528/54000 (42%)] Loss: -765.314087\n",
      "Train Epoch: 1286 [33792/54000 (63%)] Loss: -764.973389\n",
      "Train Epoch: 1286 [45056/54000 (83%)] Loss: -763.034851\n",
      "    epoch          : 1286\n",
      "    loss           : -767.0998074513561\n",
      "    ess            : 1.9602487773265478\n",
      "    log_marginal   : 767.1373031904112\n",
      "    log_joint      : 975.6604884885392\n",
      "    val_loss       : -771.4694264729818\n",
      "    val_ess        : 1.9597830673058827\n",
      "    val_log_marginal: 771.5074717203776\n",
      "    val_log_joint  : 980.2088317871094\n",
      "Train Epoch: 1287 [0/54000 (0%)] Loss: -799.590210\n",
      "Train Epoch: 1287 [11264/54000 (21%)] Loss: -757.573730\n",
      "Train Epoch: 1287 [22528/54000 (42%)] Loss: -747.134766\n",
      "Train Epoch: 1287 [33792/54000 (63%)] Loss: -773.652405\n",
      "Train Epoch: 1287 [45056/54000 (83%)] Loss: -774.153320\n",
      "    epoch          : 1287\n",
      "    loss           : -767.0507150326135\n",
      "    ess            : 1.95981542681748\n",
      "    log_marginal   : 767.0879395682857\n",
      "    log_joint      : 975.70542763764\n",
      "    val_loss       : -771.0318094889323\n",
      "    val_ess        : 1.9591377874215443\n",
      "    val_log_marginal: 771.0697479248047\n",
      "    val_log_joint  : 979.9434102376302\n",
      "Train Epoch: 1288 [0/54000 (0%)] Loss: -777.128418\n",
      "Train Epoch: 1288 [11264/54000 (21%)] Loss: -766.476379\n",
      "Train Epoch: 1288 [22528/54000 (42%)] Loss: -801.389160\n",
      "Train Epoch: 1288 [33792/54000 (63%)] Loss: -767.395020\n",
      "Train Epoch: 1288 [45056/54000 (83%)] Loss: -741.426636\n",
      "    epoch          : 1288\n",
      "    loss           : -767.1975017043779\n",
      "    ess            : 1.960520661102151\n",
      "    log_marginal   : 767.23312090028\n",
      "    log_joint      : 975.7221564526828\n",
      "    val_loss       : -771.4819691975912\n",
      "    val_ess        : 1.9619746208190918\n",
      "    val_log_marginal: 771.5154368082682\n",
      "    val_log_joint  : 980.0638275146484\n",
      "Train Epoch: 1289 [0/54000 (0%)] Loss: -778.126282\n",
      "Train Epoch: 1289 [11264/54000 (21%)] Loss: -769.726990\n",
      "Train Epoch: 1289 [22528/54000 (42%)] Loss: -775.143799\n",
      "Train Epoch: 1289 [33792/54000 (63%)] Loss: -780.754761\n",
      "Train Epoch: 1289 [45056/54000 (83%)] Loss: -754.259949\n",
      "    epoch          : 1289\n",
      "    loss           : -767.0431190346771\n",
      "    ess            : 1.960524395951685\n",
      "    log_marginal   : 767.079288122789\n",
      "    log_joint      : 975.6337671819723\n",
      "    val_loss       : -771.7586263020834\n",
      "    val_ess        : 1.9622128506501515\n",
      "    val_log_marginal: 771.7933858235677\n",
      "    val_log_joint  : 980.3775533040365\n",
      "Train Epoch: 1290 [0/54000 (0%)] Loss: -759.076477\n",
      "Train Epoch: 1290 [11264/54000 (21%)] Loss: -770.775635\n",
      "Train Epoch: 1290 [22528/54000 (42%)] Loss: -758.244324\n",
      "Train Epoch: 1290 [33792/54000 (63%)] Loss: -764.783569\n",
      "Train Epoch: 1290 [45056/54000 (83%)] Loss: -790.449341\n",
      "    epoch          : 1290\n",
      "    loss           : -767.0595916172243\n",
      "    ess            : 1.9595347676637038\n",
      "    log_marginal   : 767.0962852621979\n",
      "    log_joint      : 975.6516717874779\n",
      "    val_loss       : -771.2709910074869\n",
      "    val_ess        : 1.960444062948227\n",
      "    val_log_marginal: 771.3060506184896\n",
      "    val_log_joint  : 979.9634145100912\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1290.pth ...\n",
      "Tra
n Epoch: 1291 [0/54000 (0%)] Loss: -787.306641\n",
      "Train Epoch: 1291 [11264/54000 (21%)] Loss: -764.543701\n",
      "Train Epoch: 1291 [22528/54000 (42%)] Loss: -771.644775\n",
      "Train Epoch: 1291 [33792/54000 (63%)] Loss: -770.324341\n",
      "Train Epoch: 1291 [45056/54000 (83%)] Loss: -759.501953\n",
      "    epoch          : 1291\n",
      "    loss           : -767.1283315982458\n",
      "    ess            : 1.959697424240832\n",
      "    log_marginal   : 767.165905646558\n",
      "    log_joint      : 975.7131727686468\n",
      "    val_loss       : -771.0332387288412\n",
      "    val_ess        : 1.9620295365651448\n",
      "    val_log_marginal: 771.0674031575521\n",
      "    val_log_joint  : 979.7155100504557\n",
      "Train Epoch: 1292 [0/54000 (0%)] Loss: -762.462769\n",
      "Train Epoch: 1292 [11264/54000 (21%)] Loss: -768.511108\n",
      "Train Epoch: 1292 [22528/54000 (42%)] Loss: -782.938721\n",
      "Train Epoch: 1292 [33792/54000 (63%)] Loss: -767.781677\n",
      "Train Epoch: 1292 [45056/54000 (83%)] Loss: -777.372437\n",
      "    epoch          : 1292\n",
      "    loss           : -767.0982746628096\n",
      "    ess            : 1.9610710661366302\n",
      "    log_marginal   : 767.1347235913547\n",
      "    log_joint      : 975.6327814066185\n",
      "    val_loss       : -771.9017028808594\n",
      "    val_ess        : 1.956360936164856\n",
      "    val_log_marginal: 771.9437459309896\n",
      "    val_log_joint  : 980.5895690917969\n",
      "Train Epoch: 1293 [0/54000 (0%)] Loss: -767.383179\n",
      "Train Epoch: 1293 [11264/54000 (21%)] Loss: -764.853882\n",
      "Train Epoch: 1293 [22528/54000 (42%)] Loss: -762.880859\n",
      "Train Epoch: 1293 [33792/54000 (63%)] Loss: -755.259949\n",
      "Train Epoch: 1293 [45056/54000 (83%)] Loss: -766.205078\n",
      "    epoch          : 1293\n",
      "    loss           : -767.1658578548792\n",
      "    ess            : 1.9610107124976393\n",
      "    log_marginal   : 767.2023459380528\n",
      "    log_joint      : 975.692494518352\n",
      "    val_loss       : -771.2319030761719\n",
      "    val_ess        : 1.9589242140452068\n",
      "    val_log_marginal: 771.2686513264974\n",
      "    val_log_joint  : 979.8101857503256\n",
      "Train Epoch: 1294 [0/54000 (0%)] Loss: -775.593689\n",
      "Train Epoch: 1294 [11264/54000 (21%)] Loss: -762.541687\n",
      "Train Epoch: 1294 [22528/54000 (42%)] Loss: -764.005127\n",
      "Train Epoch: 1294 [33792/54000 (63%)] Loss: -792.440674\n",
      "Train Epoch: 1294 [45056/54000 (83%)] Loss: -776.524658\n",
      "    epoch          : 1294\n",
      "    loss           : -767.2427759710348\n",
      "    ess            : 1.95938585164412\n",
      "    log_marginal   : 767.2813334914873\n",
      "    log_joint      : 975.7487718114313\n",
      "    val_loss       : -771.2140858968099\n",
      "    val_ess        : 1.9567511975765228\n",
      "    val_log_marginal: 771.2566680908203\n",
      "    val_log_joint  : 979.7256215413412\n",
      "Train Epoch: 1295 [0/54000 (0%)] Loss: -765.317932\n",
      "Train Epoch: 1295 [11264/54000 (21%)] Loss: -755.606567\n",
      "Train Epoch: 1295 [22528/54000 (42%)] Loss: -770.131104\n",
      "Train Epoch: 1295 [33792/54000 (63%)] Loss: -764.067932\n",
      "Train Epoch: 1295 [45056/54000 (83%)] Loss: -781.901672\n",
      "    epoch          : 1295\n",
      "    loss           : -767.2111119684183\n",
      "    ess            : 1.9590136656221353\n",
      "    log_marginal   : 767.2495094155365\n",
      "    log_joint      : 975.8234972683889\n",
      "    val_loss       : -772.0751241048177\n",
      "    val_ess        : 1.9604321519533794\n",
      "    val_log_marginal: 772.1122385660807\n",
      "    val_log_joint  : 980.5633850097656\n",
      "Train Epoch: 1296 [0/54000 (0%)] Loss: -781.909302\n",
      "Train Epoch: 1296 [11264/54000 (21%)] Loss: -769.329590\n",
      "Train Epoch: 1296 [22528/54000 (42%)] Loss: -772.625305\n",
      "Train Epoch: 1296 [33792/54000 (63%)] Loss: -790.891479\n",
      "Train Epoch: 1296 [45056/54000 (83%)] Loss: -774.089844\n",
      "    epoch          : 1296\n",
      "    loss           : -767.1693299491451\n",
      "    ess            : 1.9607492516625602\n",
      "    log_marginal   : 767.2047309155735\n",
      "    log_joint      : 975.7544935694281\n",
      "    val_loss       : -770.80615234375\n",
      "    val_ess        : 1.9617969393730164\n",
      "    val_log_marginal: 770.8378499348959\n",
      "    val_log_joint  : 979.3676452636719\n",
      "Train Epoch: 1297 [0/54000 (0%)] Loss: -775.185303\n",
      "Train Epoch: 1297 [11264/54000 (21%)] Loss: -775.625854\n",
      "Train Epoch: 1297 [22528/54000 (42%)] Loss: -781.547241\n",
      "Train Epoch: 1297 [33792/54000 (63%)] Loss: -769.304321\n",
      "Train Epoch: 1297 [45056/54000 (83%)] Loss: -771.495605\n",
      "    epoch          : 1297\n",
      "    loss           : -767.0379920815521\n",
      "    ess            : 1.96067306230653\n",
      "    log_marginal   : 767.0744346762604\n",
      "    log_joint      : 975.6883550679909\n",
      "    val_loss       : -771.0784505208334\n",
      "    val_ess        : 1.9604324102401733\n",
      "    val_log_marginal: 771.1164855957031\n",
      "    val_log_joint  : 979.6540069580078\n",
      "Train Epoch: 1298 [0/54000 (0%)] Loss: -774.760986\n",
      "Train Epoch: 1298 [11264/54000 (21%)] Loss: -755.155884\n",
      "Train Epoch: 1298 [22528/54000 (42%)] Loss: -782.582336\n",
      "Train Epoch: 1298 [33792/54000 (63%)] Loss: -770.907593\n",
      "Train Epoch: 1298 [45056/54000 (83%)] Loss: -768.894409\n",
      "    epoch          : 1298\n",
      "    loss           : -767.3303314784788\n",
      "    ess            : 1.961273137128578\n",
      "    log_marginal   : 767.365960463038\n",
      "    log_joint      : 975.8231258752211\n",
      "    val_loss       : -771.2367960611979\n",
      "    val_ess        : 1.9597706000010173\n",
      "    val_log_marginal: 771.2741495768229\n",
      "    val_log_joint  : 979.6768900553385\n",
      "Train Epoch: 1299 [0/54000 (0%)] Loss: -780.529785\n",
      "Train Epoch: 1299 [11264/54000 (21%)] Loss: -792.084106\n",
      "Train Epoch: 1299 [22528/54000 (42%)] Loss: -784.005615\n",
      "Train Epoch: 1299 [33792/54000 (63%)] Loss: -769.224365\n",
      "Train Epoch: 1299 [45056/54000 (83%)] Loss: -761.204468\n",
      "    epoch          : 1299\n",
      "    loss           : -767.2477106058373\n",
      "    ess            : 1.96105143933926\n",
      "    log_marginal   : 767.283672404739\n",
      "    log_joint      : 975.6895072505159\n",
      "    val_loss       : -771.34765625\n",
      "    val_ess        : 1.960424264272054\n",
      "    val_log_marginal: 771.3806101481119\n",
      "    val_log_joint  : 979.9851989746094\n",
      "Train Epoch: 1300 [0/54000 (0%)] Loss: -760.390259\n",
      "Train Epoch: 1300 [11264/54000 (21%)] Loss: -765.263916\n",
      "Train Epoch: 1300 [22528/54000 (42%)] Loss: -759.235229\n",
      "Train Epoch: 1300 [33792/54000 (63%)] Loss: -769.822510\n",
      "Train Epoch: 1300 [45056/54000 (83%)] Loss: -764.439209\n",
      "    epoch          : 1300\n",
      "    loss           : -767.351527375995\n",
      "    ess            : 1.9618458579171378\n",
      "    log_marginal   : 767.3858412256781\n",
      "    log_joint      : 975.8005388367851\n",
      "    val_loss       : -771.5577341715494\n",
      "    val_ess        : 1.9613732695579529\n",
      "    val_log_marginal: 771.5945536295573\n",
      "    val_log_joint  : 979.9283905029297\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1300.pth ...\n",
      "Train Epoch: 1301 [0/54000 (0%)] Loss: -777.462769\n",
      "Train Epoch: 1301 [11264/54000 (21%)] Loss: -765.288513\n",
      "Train Epoch: 1301 [22528/54000 (42%)] Loss: -778.468750\n",
      "Train Epoch: 1301 [33792/54000 (63%)] Loss: -781.365662\n",
      "Train Epoch: 1301 [45056/54000 (83%)] Loss: -755.379761\n",
      "    epoch          : 1301\n",
      "    loss           : -767.0435796773659\n",
      "    ess            : 1.9576315801098663\n",
      "    log_marginal   : 767.0851952894678\n",
      "    log_joint      : 975.6410113640551\n",
      "    val_loss       : -771.3431752522787\n",
      "    val_ess        : 1.9597593148549397\n",
      "    val_log_marginal: 771.3857218424479\n",
      "    val_log_joint  : 979.9671427408854\n",
      "Train Epoch: 1302 [0/54000 (0%)] Loss: -769.512573\n",
      "Train Epoch: 1302 [11264/54000 (21%)] Loss: -783.572205\n",
      "Train Epoch: 1302 [22528/54000 (42%)] Loss: -788.920776\n",
      "Train Epoch: 1302 [33792/54000 (63%)] Loss: -744.634399\n",
      "Train Epoch: 1302 [45056/54000 (83%)] Loss: -748.362305\n",
      "    epoch          : 1302\n",
      "    loss           : -767.3572589226488\n",
      "    ess            : 1.9595932375709966\n",
      "    log_marginal   : 767.3940976700693\n",
      "    log_joint      : 975.8870555949661\n",
      "    val_loss       : -771.0770161946615\n",
      "    val_ess        : 1.9540989995002747\n",
      "    val_log_marginal: 771.1212870279948\n",
      "    val_log_joint  : 979.9573720296224\n",
      "Train Epoch: 1303 [0/54000 (0%)] Loss: -784.880859\n",
      "Train Epoch: 1303 [11264/54000 (21%)] Loss: -770.474915\n",
      "Train Epoch: 1303 [22528/54000 (42%)] Loss: -778.918945\n",
      "Train Epoch: 1303 [33792/54000 (63%)] Loss: -778.930969\n",
      "Train Epoch: 1303 [45056/54000 (83%)] Loss: -762.981079\n",
      "    epoch          : 1303\n",
      "    loss           : -767.3432415656324\n",
      "    ess            : 1.95965232489244\n",
      "    log_marginal   : 767.3805927780439\n",
      "    log_joint      : 975.883588107127\n",
      "    val_loss       : -772.3668924967448\n",
      "    val_ess        : 1.9582700232664745\n",
      "    val_log_marginal: 772.4067230224609\n",
      "    val_log_joint  : 980.7159220377604\n",
      "Train Epoch: 1304 [0/54000 (0%)] Loss: -758.294800\n",
      "Train Epoch: 1304 [11264/54000 (21%)] Loss: -764.111145\n",
      "Train Epoch: 1304 [22528/54000 (42%)] Loss: -769.217285\n",
      "Train Epoch: 1304 [33792/54000 (63%)] Loss: -767.414673\n",
      "Train Epoch: 1304 [45056/54000 (83%)] Loss: -774.353638\n",
      "    epoch          : 1304\n",
      "    loss           : -767.285309413694\n",
      "    ess            : 1.9597332724985086\n",
      "    log_marginal   : 767.3241692309109\n",
      "    log_joint      : 975.8795931834095\n",
      "    val_loss       : -771.5799560546875\n",
      "    val_ess        : 1.9584429363409679\n",
      "    val_log_marginal: 771.6200663248698\n",
      "    val_log_joint  : 980.4445292154948\n",
      "Train Epoch: 1305 [0/54000 (0%)] Loss: -781.402161\n",
      "Train Epoch: 1305 [11264/54000 (21%)] Loss: -758.610352\n",
      "Train Epoch: 1305 [22528/54000 (42%)] Loss: -765.361328\n",
      "Train Epoch: 1305 [33792/54000 (63%)] Loss: -761.192139\n",
      "Train Epoch: 1305 [45056/54000 (83%)] Loss: -761.615723\n",
      "    epoch          : 1305\n",
      "    loss           : -767.2445367777123\n",
      "    ess            : 1.9602395453543033\n",
      "    log_marginal   : 767.2816720638635\n",
      "    log_joint      : 975.7491904204746\n",
      "    val_loss       : -771.536610921224\n",
      "    val_ess        : 1.9598205586274464\n",
      "    val_log_marginal: 771.5744934082031\n",
      "    val_log_joint  : 980.1270141601562\n",
      "Train Epoch: 1306 [0/54000 (0%)] Loss: -761.062744\n",
      "Train Epoch: 1306 [11264/54000 (21%)] Loss: -791.824402\n",
      "Train Epoch: 1306 [22528/54000 (42%)] Loss: -788.677307\n",
      "Train Epoch: 1306 [33792/54000 (63%)] Loss: -771.197632\n",
      "Train Epoch: 1306 [45056/54000 (83%)] Loss: -758.615356\n",
      "    epoch          : 1306\n",
      "    loss           : -767.3994607025722\n",
      "    ess            : 1.95916518737685\n",
      "    log_marginal   : 767.4379923118735\n",
      "    log_joint      : 975.9251622613871\n",
      "    val_loss       : -771.050791422526\n",
      "    val_ess        : 1.9607111712296803\n",
      "    val_log_marginal: 771.0883076985677\n",
      "    val_log_joint  : 979.6882680257162\n",
      "Train Epoch: 1307 [0/54000 (0%)] Loss: -766.642456\n",
      "Train Epoch: 1307 [11264/54000 (21%)] Loss: -751.340576\n",
      "Train Epoch: 1307 [22528/54000 (42%)] Loss: -746.735474\n",
      "Train Epoch: 1307 [33792/54000 (63%)] Loss: -755.628662\n",
      "Train Epoch: 1307 [45056/54000 (83%)] Loss: -760.311157\n",
      "    epoch          : 1307\n",
      "    loss           : -767.4516100613577\n",
      "    ess            : 1.9603685241825175\n",
      "    log_marginal   : 767.4884430507444\n",
      "    log_joint      : 976.0871357467939\n",
      "    val_loss       : -771.6204071044922\n",
      "    val_ess        : 1.9588053226470947\n",
      "    val_log_marginal: 771.6603088378906\n",
      "    val_log_joint  : 980.0932210286459\n",
      "Train Epoch: 1308 [0/54000 (0%)] Loss: -761.999756\n",
      "Train Epoch: 1308 [11264/54000 (21%)] Loss: -767.105225\n",
      "Train Epoch: 1308 [22528/54000 (42%)] Loss: -757.591248\n",
      "Train Epoch: 1308 [33792/54000 (63%)] Loss: -754.156738\n",
      "Train Epoch: 1308 [45056/54000 (83%)] Loss: -760.931580\n",
      "    epoch          : 1308\n",
      "    loss           : -767.4576162662146\n",
      "    ess            : 1.958226573917101\n",
      "    log_marginal   : 767.4963695598099\n",
      "    log_joint      : 976.0569031913326\n",
      "    val_loss       : -771.0757904052734\n",
      "    val_ess        : 1.956421544154485\n",
      "    val_log_marginal: 771.1165720621744\n",
      "    val_log_joint  : 979.7298329671224\n",
      "Train Epoch: 1309 [0/54000 (0%)] Loss: -741.836182\n",
      "Train Epoch: 1309 [11264/54000 (21%)] Loss: -766.661255\n",
      "Train Epoch: 1309 [22528/54000 (42%)] Loss: -777.306702\n",
      "Train Epoch: 1309 [33792/54000 (63%)] Loss: -782.880005\n",
      "Train Epoch: 1309 [45056/54000 (83%)] Loss: -763.633057\n",
      "    epoch          : 1309\n",
      "    loss           : -767.4286827231354\n",
      "    ess            : 1.9602222082749852\n",
      "    log_marginal   : 767.4655168641289\n",
      "    log_joint      : 976.0423981288694\n",
      "    val_loss       : -771.9554748535156\n",
      "    val_ess        : 1.959823876619339\n",
      "    val_log_marginal: 771.9944000244141\n",
      "    val_log_joint  : 980.3953908284506\n",
      "Train Epoch: 1310 [0/54000 (0%)] Loss: -782.389648\n",
      "Train Epoch: 1310 [11264/54000 (21%)] Loss: -773.848633\n",
      "Train Epoch: 1310 [22528/54000 (42%)] Loss: -761.834167\n",
      "Train Epoch: 1310 [33792/54000 (63%)] Loss: -752.001953\n",
      "Train Epoch: 1310 [45056/54000 (83%)] Loss: -783.175781\n",
      "    epoch          : 1310\n",
      "    loss           : -767.5776419009802\n",
      "    ess            : 1.959760697382801\n",
      "    log_marginal   : 767.615484849462\n",
      "    log_joint      : 976.1149464733196\n",
      "    val_loss       : -772.097666422526\n",
      "    val_ess        : 1.962001274029414\n",
      "    val_log_marginal: 772.1346842447916\n",
      "    val_log_joint  : 980.3781534830729\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1310.pth ...\n",
      "Train Epoch: 1311 [0/54000 (0%)] Loss: -788.394165\n",
      "Train Epoch: 1311 [11264/54000 (21%)] Loss: -774.777588\n",
      "Train Epoch: 1311 [22528/54000 (42%)] Loss: -753.385376\n",
      "Train Epoch: 1311 [33792/54000 (63%)] Loss: -722.162292\n",
      "Train Epoch: 1311 [45056/54000 (83%)] Loss: -778.098267\n",
      "    epoch          : 1311\n",
      "    loss           : -767.4173290324661\n",
      "    ess            : 1.95896341328351\n",
      "    log_marginal   : 767.4556245623894\n",
      "    log_joint      : 976.0070507121536\n",
      "    val_loss       : -772.2205454508463\n",
      "    val_ess        : 1.961202363173167\n",
      "    val_log_marginal: 772.2557881673177\n",
      "    val_log_joint  : 980.6671702067057\n",
      "Train Epoch: 1312 [0/54000 (0%)] Loss: -762.742981\n",
      "Train Epoch: 1312 [11264/54000 (21%)] Loss: -749.688904\n",
      "Train Epoch: 1312 [22528/54000 (42%)] Loss: -780.763794\n",
      "Train Epoch: 1312 [33792/54000 (63%)] Loss: -746.573669\n",
      "Train Epoch: 1312 [45056/54000 (83%)] Loss: -765.264221\n",
      "    epoch          : 1312\n",
      "    loss           : -767.6599178674086\n",
      "    ess            : 1.9600991696681616\n",
      "    log_marginal   : 767.6977274192953\n",
      "    log_joint      : 976.2976483039137\n",
      "    val_loss       : -772.0790964762369\n",
      "    val_ess        : 1.9560600022474925\n",
      "    val_log_marginal: 772.1202392578125\n",
      "    val_log_joint  : 980.6585693359375\n",
      "Train Epoch: 1313 [0/54000 (0%)] Loss: -759.571289\n",
      "Train Epoch: 1313 [11264/54000 (21%)] Loss: -772.520203\n",
      "Train Epoch: 1313 [22528/54000 (42%)] Loss: -764.188721\n",
      "Train Epoch: 1313 [33792/54000 (63%)] Loss: -766.577454\n",
      "Train Epoch: 1313 [45056/54000 (83%)] Loss: -793.689636\n",
      "    epoch          : 1313\n",
      "    loss           : -767.5836958975162\n",
      "    ess            : 1.9603477806415197\n",
      "    log_marginal   : 767.6197504007591\n",
      "    log_joint      : 976.2354068396227\n",
      "    val_loss       : -771.5464579264323\n",
      "    val_ess        : 1.9647647142410278\n",
      "    val_log_marginal: 771.5770874023438\n",
      "    val_log_joint  : 980.0728505452474\n",
      "Train Epoch: 1314 [0/54000 (0%)] Loss: -777.589783\n",
      "Train Epoch: 1314 [11264/54000 (21%)] Loss: -766.183594\n",
      "Train Epoch: 1314 [22528/54000 (42%)] Loss: -792.020996\n",
      "Train Epoch: 1314 [33792/54000 (63%)] Loss: -759.109131\n",
      "Train Epoch: 1314 [45056/54000 (83%)] Loss: -790.138062\n",
      "    epoch          : 1314\n",
      "    loss           : -767.7622582777491\n",
      "    ess            : 1.960231360399498\n",
      "    log_marginal   : 767.7995806999926\n",
      "    log_joint      : 976.3499496747862\n",
      "    val_loss       : -771.271230061849\n",
      "    val_ess        : 1.959061602751414\n",
      "    val_log_marginal: 771.3040924072266\n",
      "    val_log_joint  : 980.0389404296875\n",
      "Train Epoch: 1315 [0/54000 (0%)] Loss: -751.526245\n",
      "Train Epoch: 1315 [11264/54000 (21%)] Loss: -739.844116\n",
      "Train Epoch: 1315 [22528/54000 (42%)] Loss: -753.762329\n",
      "Train Epoch: 1315 [33792/54000 (63%)] Loss: -764.434570\n",
      "Train Epoch: 1315 [45056/54000 (83%)] Loss: -764.367981\n",
      "    epoch          : 1315\n",
      "    loss           : -767.9011725659641\n",
      "    ess            : 1.959489793147681\n",
      "    log_marginal   : 767.9394801877579\n",
      "    log_joint      : 976.354520977668\n",
      "    val_loss       : -772.4505615234375\n",
      "    val_ess        : 1.9629513919353485\n",
      "    val_log_marginal: 772.4835408528646\n",
      "    val_log_joint  : 980.9971720377604\n",
      "Train Epoch: 1316 [0/54000 (0%)] Loss: -773.227234\n",
      "Train Epoch: 1316 [11264/54000 (21%)] Loss: -747.458496\n",
      "Train Epoch: 1316 [22528/54000 (42%)] Loss: -779.231262\n",
      "Train Epoch: 1316 [33792/54000 (63%)] Loss: -770.448730\n",
      "Train Epoch: 1316 [45056/54000 (83%)] Loss: -763.966431\n",
      "    epoch          : 1316\n",
      "    loss           : -767.610846177587\n",
      "    ess            : 1.9592842043570753\n",
      "    log_marginal   : 767.648327521558\n",
      "    log_joint      : 976.171281346735\n",
      "    val_loss       : -772.4398091634115\n",
      "    val_ess        : 1.9595202406247456\n",
      "    val_log_marginal: 772.4802907307943\n",
      "    val_log_joint  : 980.9937947591146\n",
      "Train Epoch: 1317 [0/54000 (0%)] Loss: -768.414185\n",
      "Train Epoch: 1317 [11264/54000 (21%)] Loss: -783.916443\n",
      "Train Epoch: 1317 [22528/54000 (42%)] Loss: -759.334412\n",
      "Train Epoch: 1317 [33792/54000 (63%)] Loss: -755.604614\n",
      "Train Epoch: 1317 [45056/54000 (83%)] Loss: -764.822754\n",
      "    epoch          : 1317\n",
      "    loss           : -767.8445906729069\n",
      "    ess            : 1.960332380150849\n",
      "    log_marginal   : 767.8827128860186\n",
      "    log_joint      : 976.4094209491082\n",
      "    val_loss       : -771.7968292236328\n",
      "    val_ess        : 1.9607434074083965\n",
      "    val_log_marginal: 771.8321889241537\n",
      "    val_log_joint  : 980.3579559326172\n",
      "Train Epoch: 1318 [0/54000 (0%)] Loss: -759.251587\n",
      "Train Epoch: 1318 [11264/54000 (21%)] Loss: -739.726135\n",
      "Train Epoch: 1318 [22528/54000 (42%)] Loss: -770.245239\n",
      "Train Epoch: 1318 [33792/54000 (63%)] Loss: -764.970093\n",
      "Train Epoch: 1318 [45056/54000 (83%)] Loss: -781.033020\n",
      "    epoch          : 1318\n",
      "    loss           : -767.7097070082178\n",
      "    ess            : 1.9600124392869338\n",
      "    log_marginal   : 767.7486295880012\n",
      "    log_joint      : 976.333328534972\n",
      "    val_loss       : -772.2162221272787\n",
      "    val_ess        : 1.9619226654370625\n",
      "    val_log_marginal: 772.2503662109375\n",
      "    val_log_joint  : 980.5654805501302\n",
      "Train Epoch: 1319 [0/54000 (0%)] Loss: -755.579651\n",
      "Train Epoch: 1319 [11264/54000 (21%)] Loss: -778.487488\n",
      "Train Epoch: 1319 [22528/54000 (42%)] Loss: -770.054443\n",
      "Train Epoch: 1319 [33792/54000 (63%)] Loss: -789.441345\n",
      "Train Epoch: 1319 [45056/54000 (83%)] Loss: -766.738770\n",
      "    epoch          : 1319\n",
      "    loss           : -767.797377676334\n",
      "    ess            : 1.9589791500343468\n",
      "    log_marginal   : 767.8362720417526\n",
      "    log_joint      : 976.3811697330115\n",
      "    val_loss       : -771.6902872721354\n",
      "    val_ess        : 1.9579938153425853\n",
      "    val_log_marginal: 771.7310434977213\n",
      "    val_log_joint  : 980.5507049560547\n",
      "Train Epoch: 1320 [0/54000 (0%)] Loss: -745.311523\n",
      "Train Epoch: 1320 [11264/54000 (21%)] Loss: -760.329285\n",
      "Train Epoch: 1320 [22528/54000 (42%)] Loss: -752.738770\n",
      "Train Epoch: 1320 [33792/54000 (63%)] Loss: -755.297241\n",
      "Train Epoch: 1320 [45056/54000 (83%)] Loss: -778.052856\n",
      "    epoch          : 1320\n",
      "    loss           : -767.8380506983343\n",
      "    ess            : 1.9600494515221074\n",
      "    log_marginal   : 767.8746867629717\n",
      "    log_joint      : 976.3630002579599\n",
      "    val_loss       : -772.4018198649088\n",
      "    val_ess        : 1.959414541721344\n",
      "    val_log_marginal: 772.4437154134115\n",
      "    val_log_joint  : 981.0204315185547\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1320.pth ...\n",
      "Train Epoch: 1321 [0/54000 (0%)] Loss: -773.853333\n",
      "Train Epoch: 1321 [11264/54000 (21%)] Loss: -767.116882\n",
      "Train Epoch: 1321 [22528/54000 (42%)] Loss: -755.891479\n",
      "Train Epoch: 1321 [33792/54000 (63%)] Loss: -766.611755\n",
      "Train Epoch: 1321 [45056/54000 (83%)] Loss: -768.833984\n",
      "    epoch          : 1321\n",
      "    loss           : -767.979039030255\n",
      "    ess            : 1.961287017138499\n",
      "    log_marginal   : 768.0155363262825\n",
      "    log_joint      : 976.5620929070238\n",
      "    val_loss       : -772.2639973958334\n",
      "    val_ess        : 1.9601563612620037\n",
      "    val_log_marginal: 772.2996063232422\n",
      "    val_log_joint  : 980.9473368326823\n",
      "Train Epoch: 1322 [0/54000 (0%)] Loss: -763.210510\n",
      "Train Epoch: 1322 [11264/54000 (21%)] Loss: -787.074951\n",
      "Train Epoch: 1322 [22528/54000 (42%)] Loss: -773.367737\n",
      "Train Epoch: 1322 [33792/54000 (63%)] Loss: -774.793152\n",
      "Train Epoch: 1322 [45056/54000 (83%)] Loss: -774.089600\n",
      "    epoch          : 1322\n",
      "    loss           : -767.9870997015036\n",
      "    ess            : 1.9608956249255054\n",
      "    log_marginal   : 768.0241157963591\n",
      "    log_joint      : 976.5787940835053\n",
      "    val_loss       : -773.1431325276693\n",
      "    val_ess        : 1.9605637689431508\n",
      "    val_log_marginal: 773.1785736083984\n",
      "    val_log_joint  : 981.2726643880209\n",
      "Train Epoch: 1323 [0/54000 (0%)] Loss: -771.214783\n",
      "Train Epoch: 1323 [11264/54000 (21%)] Loss: -759.833618\n",
      "Train Epoch: 1323 [22528/54000 (42%)] Loss: -772.181152\n",
      "Train Epoch: 1323 [33792/54000 (63%)] Loss: -773.018127\n",
      "Train Epoch: 1323 [45056/54000 (83%)] Loss: -752.878906\n",
      "    epoch          : 1323\n",
      "    loss           : -768.0389225797833\n",
      "    ess            : 1.9603742552253436\n",
      "    log_marginal   : 768.0761471154555\n",
      "    log_joint      : 976.5853588176224\n",
      "    val_loss       : -771.5841471354166\n",
      "    val_ess        : 1.959988792737325\n",
      "    val_log_marginal: 771.6239369710287\n",
      "    val_log_joint  : 980.2115325927734\n",
      "Train Epoch: 1324 [0/54000 (0%)] Loss: -764.877075\n",
      "Train Epoch: 1324 [11264/54000 (21%)] Loss: -771.943542\n",
      "Train Epoch: 1324 [22528/54000 (42%)] Loss: -750.191406\n",
      "Train Epoch: 1324 [33792/54000 (63%)] Loss: -760.106934\n",
      "Train Epoch: 1324 [45056/54000 (83%)] Loss: -769.038940\n",
      "    epoch          : 1324\n",
      "    loss           : -768.008487341539\n",
      "    ess            : 1.9599026295374025\n",
      "    log_marginal   : 768.0455575619104\n",
      "    log_joint      : 976.5716259074661\n",
      "    val_loss       : -772.0034739176432\n",
      "    val_ess        : 1.9587521453698475\n",
      "    val_log_marginal: 772.0414428710938\n",
      "    val_log_joint  : 980.7826182047526\n",
      "Train Epoch: 1325 [0/54000 (0%)] Loss: -781.812012\n",
      "Train Epoch: 1325 [11264/54000 (21%)] Loss: -764.122437\n",
      "Train Epoch: 1325 [22528/54000 (42%)] Loss: -792.417236\n",
      "Train Epoch: 1325 [33792/54000 (63%)] Loss: -758.995239\n",
      "Train Epoch: 1325 [45056/54000 (83%)] Loss: -758.948547\n",
      "    epoch          : 1325\n",
      "    loss           : -768.0761868458874\n",
      "    ess            : 1.9595561050019175\n",
      "    log_marginal   : 768.1140401588297\n",
      "    log_joint      : 976.6224273105837\n",
      "    val_loss       : -772.7385406494141\n",
      "    val_ess        : 1.9638184408346813\n",
      "    val_log_marginal: 772.7705841064453\n",
      "    val_log_joint  : 981.2531077067057\n",
      "Train Epoch: 1326 [0/54000 (0%)] Loss: -751.243591\n",
      "Train Epoch: 1326 [11264/54000 (21%)] Loss: -745.985229\n",
      "Train Epoch: 1326 [22528/54000 (42%)] Loss: -756.700806\n",
      "Train Epoch: 1326 [33792/54000 (63%)] Loss: -787.545288\n",
      "Train Epoch: 1326 [45056/54000 (83%)] Loss: -774.646362\n",
      "    epoch          : 1326\n",
      "    loss           : -767.9674578972582\n",
      "    ess            : 1.9602722176965677\n",
      "    log_marginal   : 768.0035256439785\n",
      "    log_joint      : 976.4196472167969\n",
      "    val_loss       : -772.5430246988932\n",
      "    val_ess        : 1.9594215253988903\n",
      "    val_log_marginal: 772.5796966552734\n",
      "    val_log_joint  : 980.9692942301432\n",
      "Train Epoch: 1327 [0/54000 (0%)] Loss: -776.211975\n",
      "Train Epoch: 1327 [11264/54000 (21%)] Loss: -767.077698\n",
      "Train Epoch: 1327 [22528/54000 (42%)] Loss: -774.106201\n",
      "Train Epoch: 1327 [33792/54000 (63%)] Loss: -788.020508\n",
      "Train Epoch: 1327 [45056/54000 (83%)] Loss: -749.297119\n",
      "    epoch          : 1327\n",
      "    loss           : -767.9077465129349\n",
      "    ess            : 1.9605955504021555\n",
      "    log_marginal   : 767.9439115704231\n",
      "    log_joint      : 976.423255200656\n",
      "    val_loss       : -771.8581797281901\n",
      "    val_ess        : 1.959967315196991\n",
      "    val_log_marginal: 771.8950347900391\n",
      "    val_log_joint  : 980.5942535400391\n",
      "Train Epoch: 1328 [0/54000 (0%)] Loss: -743.789307\n",
      "Train Epoch: 1328 [11264/54000 (21%)] Loss: -753.911072\n",
      "Train Epoch: 1328 [22528/54000 (42%)] Loss: -779.560425\n",
      "Train Epoch: 1328 [33792/54000 (63%)] Loss: -785.442017\n",
      "Train Epoch: 1328 [45056/54000 (83%)] Loss: -755.163147\n",
      "    epoch          : 1328\n",
      "    loss           : -768.1434855910967\n",
      "    ess            : 1.9598732995537091\n",
      "    log_marginal   : 768.1814437002506\n",
      "    log_joint      : 976.6439709933298\n",
      "    val_loss       : -773.0341186523438\n",
      "    val_ess        : 1.9609732727209728\n",
      "    val_log_marginal: 773.0721130371094\n",
      "    val_log_joint  : 981.5344085693359\n",
      "Train Epoch: 1329 [0/54000 (0%)] Loss: -782.065430\n",
      "Train Epoch: 1329 [11264/54000 (21%)] Loss: -746.840698\n",
      "Train Epoch: 1329 [22528/54000 (42%)] Loss: -752.831421\n",
      "Train Epoch: 1329 [33792/54000 (63%)] Loss: -771.241943\n",
      "Train Epoch: 1329 [45056/54000 (83%)] Loss: -739.344604\n",
      "    epoch          : 1329\n",
      "    loss           : -767.9412404186321\n",
      "    ess            : 1.9594528315202244\n",
      "    log_marginal   : 767.9786877902048\n",
      "    log_joint      : 976.4594749594635\n",
      "    val_loss       : -771.7443186442057\n",
      "    val_ess        : 1.9583073655764263\n",
      "    val_log_marginal: 771.7857106526693\n",
      "    val_log_joint  : 980.4302317301432\n",
      "Train Epoch: 1330 [0/54000 (0%)] Loss: -736.456482\n",
      "Train Epoch: 1330 [11264/54000 (21%)] Loss: -762.563232\n",
      "Train Epoch: 1330 [22528/54000 (42%)] Loss: -755.277832\n",
      "Train Epoch: 1330 [33792/54000 (63%)] Loss: -750.005859\n",
      "Train Epoch: 1330 [45056/54000 (83%)] Loss: -745.740601\n",
      "    epoch          : 1330\n",
      "    loss           : -768.0182017200398\n",
      "    ess            : 1.9601819638936024\n",
      "    log_marginal   : 768.0542602539062\n",
      "    log_joint      : 976.5704673911041\n",
      "    val_loss       : -772.5522918701172\n",
      "    val_ess        : 1.9594875971476238\n",
      "    val_log_marginal: 772.588134765625\n",
      "    val_log_joint  : 981.2932535807291\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1330.pth ...\n",
      "Train Epoch: 1331 [0/54000 (0%)] Loss: -764.887756\n",
      "Train Epoch: 1331 [11264/54000 (21%)] Loss: -740.666504\n",
      "Train Epoch: 1331 [22528/54000 (42%)] Loss: -783.647583\n",
      "Train Epoch: 1331 [33792/54000 (63%)] Loss: -756.670227\n",
      "Train Epoch: 1331 [45056/54000 (83%)] Loss: -765.623108\n",
      "    epoch          : 1331\n",
      "    loss           : -768.2767754320828\n",
      "    ess            : 1.9602760076522827\n",
      "    log_marginal   : 768.3142032263414\n",
      "    log_joint      : 976.8684582980173\n",
      "    val_loss       : -772.5019887288412\n",
      "    val_ess        : 1.9585514068603516\n",
      "    val_log_marginal: 772.5389048258463\n",
      "    val_log_joint  : 980.7435557047526\n",
      "Train Epoch: 1332 [0/54000 (0%)] Loss: -774.949463\n",
      "Train Epoch: 1332 [11264/54000 (21%)] Loss: -780.143921\n",
      "Train Epoch: 1332 [22528/54000 (42%)] Loss: -775.827332\n",
      "Train Epoch: 1332 [33792/54000 (63%)] Loss: -759.414001\n",
      "Train Epoch: 1332 [45056/54000 (83%)] Loss: -754.414062\n",
      "    epoch          : 1332\n",
      "    loss           : -767.9870651533018\n",
      "    ess            : 1.9603763312663671\n",
      "    log_marginal   : 768.0247497558594\n",
      "    log_joint      : 976.5119646180351\n",
      "    val_loss       : -772.6217956542969\n",
      "    val_ess        : 1.9592477679252625\n",
      "    val_log_marginal: 772.6583048502604\n",
      "    val_log_joint  : 981.1558990478516\n",
      "Train Epoch: 1333 [0/54000 (0%)] Loss: -746.036865\n",
      "Train Epoch: 1333 [11264/54000 (21%)] Loss: -783.633667\n",
      "Train Epoch: 1333 [22528/54000 (42%)] Loss: -757.439941\n",
      "Train Epoch: 1333 [33792/54000 (63%)] Loss: -772.752563\n",
      "Train Epoch: 1333 [45056/54000 (83%)] Loss: -765.247681\n",
      "    epoch          : 1333\n",
      "    loss           : -768.0113318101415\n",
      "    ess            : 1.9596151844510492\n",
      "    log_marginal   : 768.0492997079525\n",
      "    log_joint      : 976.5854469155365\n",
      "    val_loss       : -773.1305796305338\n",
      "    val_ess        : 1.9582495888074238\n",
      "    val_log_marginal: 773.1700897216797\n",
      "    val_log_joint  : 981.5927581787109\n",
      "Train Epoch: 1334 [0/54000 (0%)] Loss: -745.822876\n",
      "Train Epoch: 1334 [11264/54000 (21%)] Loss: -770.203918\n",
      "Train Epoch: 1334 [22528/54000 (42%)] Loss: -747.078247\n",
      "Train Epoch: 1334 [33792/54000 (63%)] Loss: -754.781128\n",
      "Train Epoch: 1334 [45056/54000 (83%)] Loss: -785.917725\n",
      "    epoch          : 1334\n",
      "    loss           : -768.3461430387677\n",
      "    ess            : 1.959662284491197\n",
      "    log_marginal   : 768.3837596965286\n",
      "    log_joint      : 976.8972432838297\n",
      "    val_loss       : -772.3596598307291\n",
      "    val_ess        : 1.959043711423874\n",
      "    val_log_marginal: 772.4012756347656\n",
      "    val_log_joint  : 980.9132334391276\n",
      "Train Epoch: 1335 [0/54000 (0%)] Loss: -769.053223\n",
      "Train Epoch: 1335 [11264/54000 (21%)] Loss: -774.824219\n",
      "Train Epoch: 1335 [22528/54000 (42%)] Loss: -780.653259\n",
      "Train Epoch: 1335 [33792/54000 (63%)] Loss: -775.884949\n",
      "Train Epoch: 1335 [45056/54000 (83%)] Loss: -791.854736\n",
      "    epoch          : 1335\n",
      "    loss           : -768.1423984743515\n",
      "    ess            : 1.9603100520259928\n",
      "    log_marginal   : 768.1804907456884\n",
      "    log_joint      : 976.6721179890183\n",
      "    val_loss       : -772.5733947753906\n",
      "    val_ess        : 1.960333655277888\n",
      "    val_log_marginal: 772.6098480224609\n",
      "    val_log_joint  : 981.374277750651\n",
      "Train Epoch: 1336 [0/54000 (0%)] Loss: -792.712036\n",
      "Train Epoch: 1336 [11264/54000 (21%)] Loss: -783.071777\n",
      "Train Epoch: 1336 [22528/54000 (42%)] Loss: -772.278320\n",
      "Train Epoch: 1336 [33792/54000 (63%)] Loss: -760.671082\n",
      "Train Epoch: 1336 [45056/54000 (83%)] Loss: -776.894043\n",
      "    epoch          : 1336\n",
      "    loss           : -768.2349289228331\n",
      "    ess            : 1.9603688368257486\n",
      "    log_marginal   : 768.2715097103479\n",
      "    log_joint      : 976.7679748535156\n",
      "    val_loss       : -772.4894154866537\n",
      "    val_ess        : 1.9607814252376556\n",
      "    val_log_marginal: 772.5265502929688\n",
      "    val_log_joint  : 980.9585571289062\n",
      "Train Epoch: 1337 [0/54000 (0%)] Loss: -784.353394\n",
      "Train Epoch: 1337 [11264/54000 (21%)] Loss: -774.418213\n",
      "Train Epoch: 1337 [22528/54000 (42%)] Loss: -785.042603\n",
      "Train Epoch: 1337 [33792/54000 (63%)] Loss: -765.736938\n",
      "Train Epoch: 1337 [45056/54000 (83%)] Loss: -785.863220\n",
      "    epoch          : 1337\n",
      "    loss           : -768.1941562868515\n",
      "    ess            : 1.9596960139724444\n",
      "    log_marginal   : 768.2334617758697\n",
      "    log_joint      : 976.718625626474\n",
      "    val_loss       : -772.318369547526\n",
      "    val_ess        : 1.9659117857615154\n",
      "    val_log_marginal: 772.3459116617838\n",
      "    val_log_joint  : 980.8058420817057\n",
      "Train Epoch: 1338 [0/54000 (0%)] Loss: -766.756348\n",
      "Train Epoch: 1338 [11264/54000 (21%)] Loss: -767.498535\n",
      "Train Epoch: 1338 [22528/54000 (42%)] Loss: -772.386658\n",
      "Train Epoch: 1338 [33792/54000 (63%)] Loss: -757.859741\n",
      "Train Epoch: 1338 [45056/54000 (83%)] Loss: -777.541992\n",
      "    epoch          : 1338\n",
      "    loss           : -768.1898550357458\n",
      "    ess            : 1.9609230599313412\n",
      "    log_marginal   : 768.2269753510097\n",
      "    log_joint      : 976.7892686376032\n",
      "    val_loss       : -773.4478963216146\n",
      "    val_ess        : 1.9618219137191772\n",
      "    val_log_marginal: 773.4834798177084\n",
      "    val_log_joint  : 981.9339701334635\n",
      "Train Epoch: 1339 [0/54000 (0%)] Loss: -773.212036\n",
      "Train Epoch: 1339 [11264/54000 (21%)] Loss: -773.681152\n",
      "Train Epoch: 1339 [22528/54000 (42%)] Loss: -760.997437\n",
      "Train Epoch: 1339 [33792/54000 (63%)] Loss: -788.934204\n",
      "Train Epoch: 1339 [45056/54000 (83%)] Loss: -751.671143\n",
      "    epoch          : 1339\n",
      "    loss           : -768.1499138598172\n",
      "    ess            : 1.9609917323544341\n",
      "    log_marginal   : 768.1850965967718\n",
      "    log_joint      : 976.6624398861292\n",
      "    val_loss       : -772.7986551920573\n",
      "    val_ess        : 1.9581747651100159\n",
      "    val_log_marginal: 772.8361867268881\n",
      "    val_log_joint  : 981.2186330159506\n",
      "Train Epoch: 1340 [0/54000 (0%)] Loss: -771.324463\n",
      "Train Epoch: 1340 [11264/54000 (21%)] Loss: -766.042480\n",
      "Train Epoch: 1340 [22528/54000 (42%)] Loss: -763.677124\n",
      "Train Epoch: 1340 [33792/54000 (63%)] Loss: -770.005188\n",
      "Train Epoch: 1340 [45056/54000 (83%)] Loss: -779.595215\n",
      "    epoch          : 1340\n",
      "    loss           : -768.3968661326282\n",
      "    ess            : 1.9611905374616947\n",
      "    log_marginal   : 768.4331889602373\n",
      "    log_joint      : 976.9083315291495\n",
      "    val_loss       : -773.0135904947916\n",
      "    val_ess        : 1.956803301970164\n",
      "    val_log_marginal: 773.0594991048177\n",
      "    val_log_joint  : 981.3942311604818\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1340.pth ...\n",
      "Train Epoch: 1341 [0/54000 (0%)] Loss: -776.510010\n",
      "Train Epoch: 1341 [11264/54000 (21%)] Loss: -751.481567\n",
      "Train Epoch: 1341 [22528/54000 (42%)] Loss: -747.326965\n",
      "Train Epoch: 1341 [33792/54000 (63%)] Loss: -753.666138\n",
      "Train Epoch: 1341 [45056/54000 (83%)] Loss: -743.204407\n",
      "    epoch          : 1341\n",
      "    loss           : -768.0024857431088\n",
      "    ess            : 1.959838922293681\n",
      "    log_marginal   : 768.0394684413694\n",
      "    log_joint      : 976.6403837383918\n",
      "    val_loss       : -773.3254954020182\n",
      "    val_ess        : 1.9596097469329834\n",
      "    val_log_marginal: 773.3665364583334\n",
      "    val_log_joint  : 981.8885345458984\n",
      "Train Epoch: 1342 [0/54000 (0%)] Loss: -770.714783\n",
      "Train Epoch: 1342 [11264/54000 (21%)] Loss: -770.460205\n",
      "Train Epoch: 1342 [22528/54000 (42%)] Loss: -754.883850\n",
      "Train Epoch: 1342 [33792/54000 (63%)] Loss: -775.078918\n",
      "Train Epoch: 1342 [45056/54000 (83%)] Loss: -767.811890\n",
      "    epoch          : 1342\n",
      "    loss           : -768.3420571381191\n",
      "    ess            : 1.9599414962642598\n",
      "    log_marginal   : 768.3784836103331\n",
      "    log_joint      : 976.8449534290241\n",
      "    val_loss       : -772.8401184082031\n",
      "    val_ess        : 1.9609171748161316\n",
      "    val_log_marginal: 772.8759511311849\n",
      "    val_log_joint  : 981.8988749186198\n",
      "Train Epoch: 1343 [0/54000 (0%)] Loss: -761.908752\n",
      "Train Epoch: 1343 [11264/54000 (21%)] Loss: -758.299927\n",
      "Train Epoch: 1343 [22528/54000 (42%)] Loss: -786.282471\n",
      "Train Epoch: 1343 [33792/54000 (63%)] Loss: -761.549072\n",
      "Train Epoch: 1343 [45056/54000 (83%)] Loss: -794.057190\n",
      "    epoch          : 1343\n",
      "    loss           : -768.1860869785525\n",
      "    ess            : 1.9590372825568576\n",
      "    log_marginal   : 768.224950826393\n",
      "    log_joint      : 976.6477712955115\n",
      "    val_loss       : -772.5021107991537\n",
      "    val_ess        : 1.961949348449707\n",
      "    val_log_marginal: 772.5369771321615\n",
      "    val_log_joint  : 980.8901570638021\n",
      "Train Epoch: 1344 [0/54000 (0%)] Loss: -772.030029\n",
      "Train Epoch: 1344 [11264/54000 (21%)] Loss: -766.247803\n",
      "Train Epoch: 1344 [22528/54000 (42%)] Loss: -744.179077\n",
      "Train Epoch: 1344 [33792/54000 (63%)] Loss: -769.541992\n",
      "Train Epoch: 1344 [45056/54000 (83%)] Loss: -777.943115\n",
      "    epoch          : 1344\n",
      "    loss           : -768.1507274699661\n",
      "    ess            : 1.9599728269397088\n",
      "    log_marginal   : 768.188519747752\n",
      "    log_joint      : 976.737031756707\n",
      "    val_loss       : -772.3314361572266\n",
      "    val_ess        : 1.9600338240464528\n",
      "    val_log_marginal: 772.3675333658854\n",
      "    val_log_joint  : 980.8611145019531\n",
      "Train Epoch: 1345 [0/54000 (0%)] Loss: -777.145874\n",
      "Train Epoch: 1345 [11264/54000 (21%)] Loss: -750.044678\n",
      "Train Epoch: 1345 [22528/54000 (42%)] Loss: -759.539551\n",
      "Train Epoch: 1345 [33792/54000 (63%)] Loss: -772.960510\n",
      "Train Epoch: 1345 [45056/54000 (83%)] Loss: -777.656433\n",
      "    epoch          : 1345\n",
      "    loss           : -768.4519877883623\n",
      "    ess            : 1.96146796222003\n",
      "    log_marginal   : 768.4874123627285\n",
      "    log_joint      : 976.998102727926\n",
      "    val_loss       : -772.0906677246094\n",
      "    val_ess        : 1.9586760103702545\n",
      "    val_log_marginal: 772.1268971761068\n",
      "    val_log_joint  : 981.0003509521484\n",
      "Train Epoch: 1346 [0/54000 (0%)] Loss: -750.943176\n",
      "Train Epoch: 1346 [11264/54000 (21%)] Loss: -769.558289\n",
      "Train Epoch: 1346 [22528/54000 (42%)] Loss: -771.562744\n",
      "Train Epoch: 1346 [33792/54000 (63%)] Loss: -763.333252\n",
      "Train Epoch: 1346 [45056/54000 (83%)] Loss: -774.196899\n",
      "    epoch          : 1346\n",
      "    loss           : -768.3230930544296\n",
      "    ess            : 1.9592652669492758\n",
      "    log_marginal   : 768.3626691710274\n",
      "    log_joint      : 976.94398642486\n",
      "    val_loss       : -772.8814341227213\n",
      "    val_ess        : 1.960696280002594\n",
      "    val_log_marginal: 772.9171244303385\n",
      "    val_log_joint  : 981.2451527913412\n",
      "Train Epoch: 1347 [0/54000 (0%)] Loss: -766.519531\n",
      "Train Epoch: 1347 [11264/54000 (21%)] Loss: -760.066284\n",
      "Train Epoch: 1347 [22528/54000 (42%)] Loss: -763.530762\n",
      "Train Epoch: 1347 [33792/54000 (63%)] Loss: -764.457581\n",
      "Train Epoch: 1347 [45056/54000 (83%)] Loss: -802.832275\n",
      "    epoch          : 1347\n",
      "    loss           : -768.3229727115271\n",
      "    ess            : 1.959349032842888\n",
      "    log_marginal   : 768.3607373507517\n",
      "    log_joint      : 976.8994658848025\n",
      "    val_loss       : -772.9392649332682\n",
      "    val_ess        : 1.9630330105622609\n",
      "    val_log_marginal: 772.9751281738281\n",
      "    val_log_joint  : 981.4581095377604\n",
      "Train Epoch: 1348 [0/54000 (0%)] Loss: -775.008606\n",
      "Train Epoch: 1348 [11264/54000 (21%)] Loss: -782.334778\n",
      "Train Epoch: 1348 [22528/54000 (42%)] Loss: -771.241455\n",
      "Train Epoch: 1348 [33792/54000 (63%)] Loss: -764.960266\n",
      "Train Epoch: 1348 [45056/54000 (83%)] Loss: -762.249023\n",
      "    epoch          : 1348\n",
      "    loss           : -768.3210051914431\n",
      "    ess            : 1.9602599278935846\n",
      "    log_marginal   : 768.3580448942364\n",
      "    log_joint      : 976.988084901054\n",
      "    val_loss       : -772.7217661539713\n",
      "    val_ess        : 1.959574540456136\n",
      "    val_log_marginal: 772.7580210367838\n",
      "    val_log_joint  : 981.3783416748047\n",
      "Train Epoch: 1349 [0/54000 (0%)] Loss: -763.614380\n",
      "Train Epoch: 1349 [11264/54000 (21%)] Loss: -747.485229\n",
      "Train Epoch: 1349 [22528/54000 (42%)] Loss: -772.213318\n",
      "Train Epoch: 1349 [33792/54000 (63%)] Loss: -784.256592\n",
      "Train Epoch: 1349 [45056/54000 (83%)] Loss: -794.811279\n",
      "    epoch          : 1349\n",
      "    loss           : -768.3796974038178\n",
      "    ess            : 1.9606627608245273\n",
      "    log_marginal   : 768.4164659032282\n",
      "    log_joint      : 976.8841489396005\n",
      "    val_loss       : -772.2385457356771\n",
      "    val_ess        : 1.9584448834260304\n",
      "    val_log_marginal: 772.2777811686198\n",
      "    val_log_joint  : 980.7626597086588\n",
      "Train Epoch: 1350 [0/54000 (0%)] Loss: -782.635376\n",
      "Train Epoch: 1350 [11264/54000 (21%)] Loss: -759.132141\n",
      "Train Epoch: 1350 [22528/54000 (42%)] Loss: -768.093262\n",
      "Train Epoch: 1350 [33792/54000 (63%)] Loss: -772.705261\n",
      "Train Epoch: 1350 [45056/54000 (83%)] Loss: -762.196899\n",
      "    epoch          : 1350\n",
      "    loss           : -768.450857486365\n",
      "    ess            : 1.9603990215175557\n",
      "    log_marginal   : 768.4865411722435\n",
      "    log_joint      : 977.0132135355248\n",
      "    val_loss       : -772.1314137776693\n",
      "    val_ess        : 1.9593424797058105\n",
      "    val_log_marginal: 772.1686096191406\n",
      "    val_log_joint  : 981.1375427246094\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1350.pth ...\n",
      "Train Epoch: 1351 [0/54000 (0%)] Loss: -771.153992\n",
      "Train Epoch: 1351 [11264/54000 (21%)] Loss: -768.622559\n",
      "Train Epoch: 1351 [22528/54000 (42%)] Loss: -790.130859\n",
      "Train Epoch: 1351 [33792/54000 (63%)] Loss: -773.932373\n",
      "Train Epoch: 1351 [45056/54000 (83%)] Loss: -776.773804\n",
      "    epoch          : 1351\n",
      "    loss           : -768.5731880619841\n",
      "    ess            : 1.9591650850367996\n",
      "    log_marginal   : 768.6098552200029\n",
      "    log_joint      : 977.1581144512825\n",
      "    val_loss       : -771.6505279541016\n",
      "    val_ess        : 1.959870417912801\n",
      "    val_log_marginal: 771.6913248697916\n",
      "    val_log_joint  : 980.4523111979166\n",
      "Train Epoch: 1352 [0/54000 (0%)] Loss: -748.913330\n",
      "Train Epoch: 1352 [11264/54000 (21%)] Loss: -761.310791\n",
      "Train Epoch: 1352 [22528/54000 (42%)] Loss: -758.445923\n",
      "Train Epoch: 1352 [33792/54000 (63%)] Loss: -770.496338\n",
      "Train Epoch: 1352 [45056/54000 (83%)] Loss: -776.275452\n",
      "    epoch          : 1352\n",
      "    loss           : -768.6689579801739\n",
      "    ess            : 1.9598735492184478\n",
      "    log_marginal   : 768.7057489359154\n",
      "    log_joint      : 977.195906153265\n",
      "    val_loss       : -772.6461537679037\n",
      "    val_ess        : 1.9574209153652191\n",
      "    val_log_marginal: 772.6847279866537\n",
      "    val_log_joint  : 981.5210673014323\n",
      "Train Epoch: 1353 [0/54000 (0%)] Loss: -754.275696\n",
      "Train Epoch: 1353 [11264/54000 (21%)] Loss: -754.328979\n",
      "Train Epoch: 1353 [22528/54000 (42%)] Loss: -785.524902\n",
      "Train Epoch: 1353 [33792/54000 (63%)] Loss: -777.194702\n",
      "Train Epoch: 1353 [45056/54000 (83%)] Loss: -765.624146\n",
      "    epoch          : 1353\n",
      "    loss           : -768.565535059515\n",
      "    ess            : 1.959894820204321\n",
      "    log_marginal   : 768.6036912450251\n",
      "    log_joint      : 977.1228073408018\n",
      "    val_loss       : -772.668711344401\n",
      "    val_ess        : 1.9565076132615407\n",
      "    val_log_marginal: 772.7074228922526\n",
      "    val_log_joint  : 981.1390736897787\n",
      "Train Epoch: 1354 [0/54000 (0%)] Loss: -764.439819\n",
      "Train Epoch: 1354 [11264/54000 (21%)] Loss: -747.081909\n",
      "Train Epoch: 1354 [22528/54000 (42%)] Loss: -780.391663\n",
      "Train Epoch: 1354 [33792/54000 (63%)] Loss: -749.810913\n",
      "Train Epoch: 1354 [45056/54000 (83%)] Loss: -743.839844\n",
      "    epoch          : 1354\n",
      "    loss           : -768.7375390394678\n",
      "    ess            : 1.9591758880975112\n",
      "    log_marginal   : 768.7749818046138\n",
      "    log_joint      : 977.3246765136719\n",
      "    val_loss       : -773.3046925862631\n",
      "    val_ess        : 1.958664874235789\n",
      "    val_log_marginal: 773.3434702555338\n",
      "    val_log_joint  : 981.9275614420573\n",
      "Train Epoch: 1355 [0/54000 (0%)] Loss: -767.059082\n",
      "Train Epoch: 1355 [11264/54000 (21%)] Loss: -760.199585\n",
      "Train Epoch: 1355 [22528/54000 (42%)] Loss: -769.104736\n",
      "Train Epoch: 1355 [33792/54000 (63%)] Loss: -771.821960\n",
      "Train Epoch: 1355 [45056/54000 (83%)] Loss: -798.422119\n",
      "    epoch          : 1355\n",
      "    loss           : -768.6246948242188\n",
      "    ess            : 1.9599959063080121\n",
      "    log_marginal   : 768.6622475678066\n",
      "    log_joint      : 977.1988110812205\n",
      "    val_loss       : -773.3489481608073\n",
      "    val_ess        : 1.9610675076643627\n",
      "    val_log_marginal: 773.3831176757812\n",
      "    val_log_joint  : 981.9259643554688\n",
      "Train Epoch: 1356 [0/54000 (0%)] Loss: -766.810547\n",
      "Train Epoch: 1356 [11264/54000 (21%)] Loss: -759.916138\n",
      "Train Epoch: 1356 [22528/54000 (42%)] Loss: -758.620300\n",
      "Train Epoch: 1356 [33792/54000 (63%)] Loss: -789.389282\n",
      "Train Epoch: 1356 [45056/54000 (83%)] Loss: -761.318115\n",
      "    epoch          : 1356\n",
      "    loss           : -768.523528476931\n",
      "    ess            : 1.9595399510185674\n",
      "    log_marginal   : 768.5616023225605\n",
      "    log_joint      : 977.0776833588222\n",
      "    val_loss       : -772.4378611246744\n",
      "    val_ess        : 1.9607557952404022\n",
      "    val_log_marginal: 772.4747009277344\n",
      "    val_log_joint  : 981.1874186197916\n",
      "Train Epoch: 1357 [0/54000 (0%)] Loss: -767.349854\n",
      "Train Epoch: 1357 [11264/54000 (21%)] Loss: -734.421326\n",
      "Train Epoch: 1357 [22528/54000 (42%)] Loss: -769.821899\n",
      "Train Epoch: 1357 [33792/54000 (63%)] Loss: -759.517090\n",
      "Train Epoch: 1357 [45056/54000 (83%)] Loss: -749.366760\n",
      "    epoch          : 1357\n",
      "    loss           : -768.6041749198482\n",
      "    ess            : 1.9593331498919793\n",
      "    log_marginal   : 768.6424957851194\n",
      "    log_joint      : 977.1298102612766\n",
      "    val_loss       : -772.948476155599\n",
      "    val_ess        : 1.9593785802523296\n",
      "    val_log_marginal: 772.983388264974\n",
      "    val_log_joint  : 981.5890452067057\n",
      "Train Epoch: 1358 [0/54000 (0%)] Loss: -784.060669\n",
      "Train Epoch: 1358 [11264/54000 (21%)] Loss: -767.833008\n",
      "Train Epoch: 1358 [22528/54000 (42%)] Loss: -786.219788\n",
      "Train Epoch: 1358 [33792/54000 (63%)] Loss: -750.204712\n",
      "Train Epoch: 1358 [45056/54000 (83%)] Loss: -777.620361\n",
      "    epoch          : 1358\n",
      "    loss           : -768.6943123295622\n",
      "    ess            : 1.9595384294132017\n",
      "    log_marginal   : 768.7323090175413\n",
      "    log_joint      : 977.2272022175339\n",
      "    val_loss       : -772.9058074951172\n",
      "    val_ess        : 1.960961639881134\n",
      "    val_log_marginal: 772.9394327799479\n",
      "    val_log_joint  : 981.5676981608073\n",
      "Train Epoch: 1359 [0/54000 (0%)] Loss: -764.651855\n",
      "Train Epoch: 1359 [11264/54000 (21%)] Loss: -776.974365\n",
      "Train Epoch: 1359 [22528/54000 (42%)] Loss: -776.959045\n",
      "Train Epoch: 1359 [33792/54000 (63%)] Loss: -762.125732\n",
      "Train Epoch: 1359 [45056/54000 (83%)] Loss: -765.974976\n",
      "    epoch          : 1359\n",
      "    loss           : -768.796266951651\n",
      "    ess            : 1.9593884899931133\n",
      "    log_marginal   : 768.8341479031545\n",
      "    log_joint      : 977.3471696961601\n",
      "    val_loss       : -772.8940734863281\n",
      "    val_ess        : 1.9582865635553997\n",
      "    val_log_marginal: 772.9299265543619\n",
      "    val_log_joint  : 981.5573323567709\n",
      "Train Epoch: 1360 [0/54000 (0%)] Loss: -782.526062\n",
      "Train Epoch: 1360 [11264/54000 (21%)] Loss: -751.012390\n",
      "Train Epoch: 1360 [22528/54000 (42%)] Loss: -791.296265\n",
      "Train Epoch: 1360 [33792/54000 (63%)] Loss: -766.949707\n",
      "Train Epoch: 1360 [45056/54000 (83%)] Loss: -752.261902\n",
      "    epoch          : 1360\n",
      "    loss           : -768.5839515542084\n",
      "    ess            : 1.960438827298722\n",
      "    log_marginal   : 768.6212722490419\n",
      "    log_joint      : 977.1080420152197\n",
      "    val_loss       : -773.5712738037109\n",
      "    val_ess        : 1.9581754902998607\n",
      "    val_log_marginal: 773.6077321370443\n",
      "    val_log_joint  : 982.0892588297526\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1360.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1361 [0/54000 (0%)] Loss: -783.161438\n",
      "Train Epoch: 1361 [11264/54000 (21%)] Loss: -770.098877\n",
      "Train Epoch: 1361 [22528/54000 (42%)] Loss: -770.195679\n",
      "Train Epoch: 1361 [33792/54000 (63%)] Loss: -760.331177\n",
      "Train Epoch: 1361 [45056/54000 (83%)] Loss: -779.092896\n",
      "    epoch          : 1361\n",
      "    loss           : -768.5548625442217\n",
      "    ess            : 1.9603781936303624\n",
      "    log_marginal   : 768.5908974701504\n",
      "    log_joint      : 977.1546481150501\n",
      "    val_loss       : -772.8529103597006\n",
      "    val_ess        : 1.9631868600845337\n",
      "    val_log_marginal: 772.8860015869141\n",
      "    val_log_joint  : 981.4179992675781\n",
      "Train Epoch: 1362 [0/54000 (0%)] Loss: -761.392578\n",
      "Train Epoch: 1362 [11264/54000 (21%)] Loss: -780.234802\n",
      "Train Epoch: 1362 [22528/54000 (42%)] Loss: -748.647705\n",
      "Train Epoch: 1362 [33792/54000 (63%)] Loss: -791.567749\n",
      "Train Epoch: 1362 [45056/54000 (83%)] Loss: -773.376343\n",
      "    epoch          : 1362\n",
      "    loss           : -768.9654771336969\n",
      "    ess            : 1.960428720375277\n",
      "    log_marginal   : 769.0014469938458\n",
      "    log_joint      : 977.4992313025133\n",
      "    val_loss       : -772.8924102783203\n",
      "    val_ess        : 1.9625781178474426\n",
      "    val_log_marginal: 772.9251861572266\n",
      "    val_log_joint  : 981.4585266113281\n",
      "Train Epoch: 1363 [0/54000 (0%)] Loss: -771.677490\n",
      "Train Epoch: 1363 [11264/54000 (21%)] Loss: -785.005432\n",
      "Train Epoch: 1363 [22528/54000 (42%)] Loss: -765.421265\n",
      "Train Epoch: 1363 [33792/54000 (63%)] Loss: -751.564758\n",
      "Train Epoch: 1363 [45056/54000 (83%)] Loss: -758.423889\n",
      "    epoch          : 1363\n",
      "    loss           : -768.8115119214328\n",
      "    ess            : 1.959588790839573\n",
      "    log_marginal   : 768.8497205050486\n",
      "    log_joint      : 977.3473366791347\n",
      "    val_loss       : -772.8852284749349\n",
      "    val_ess        : 1.9601882100105286\n",
      "    val_log_marginal: 772.9185892740885\n",
      "    val_log_joint  : 981.7294718424479\n",
      "Train Epoch: 1364 [0/54000 (0%)] Loss: -745.873230\n",
      "Train Epoch: 1364 [11264/54000 (21%)] Loss: -768.192505\n",
      "Train Epoch: 1364 [22528/54000 (42%)] Loss: -742.796753\n",
      "Train Epoch: 1364 [33792/54000 (63%)] Loss: -792.851807\n",
      "Train Epoch: 1364 [45056/54000 (83%)] Loss: -777.425903\n",
      "    epoch          : 1364\n",
      "    loss           : -768.7590504772259\n",
      "    ess            : 1.9599072640796877\n",
      "    log_marginal   : 768.7963654140257\n",
      "    log_joint      : 977.3680926628832\n",
      "    val_loss       : -772.7203623453776\n",
      "    val_ess        : 1.9633058110872905\n",
      "    val_log_marginal: 772.7535095214844\n",
      "    val_log_joint  : 981.2332763671875\n",
      "Train Epoch: 1365 [0/54000 (0%)] Loss: -770.575684\n",
      "Train Epoch: 1365 [11264/54000 (21%)] Loss: -780.931641\n",
      "Train Epoch: 1365 [22528/54000 (42%)] Loss: -764.630371\n",
      "Train Epoch: 1365 [33792/54000 (63%)] Loss: -755.213501\n",
      "Train Epoch: 1365 [45056/54000 (83%)] Loss: -785.006714\n",
      "    epoch          : 1365\n",
      "    loss           : -768.8584485323923\n",
      "    ess            : 1.9614944188099988\n",
      "    log_marginal   : 768.8940268462559\n",
      "    log_joint      : 977.3934130398733\n",
      "    val_loss       : -772.459706624349\n",
      "    val_ess        : 1.9619557460149128\n",
      "    val_log_marginal: 772.4954833984375\n",
      "    val_log_joint  : 981.2222035725912\n",
      "Train Epoch: 1366 [0/54000 (0%)] Loss: -782.696289\n",
      "Train Epoch: 1366 [11264/54000 (21%)] Loss: -776.905884\n",
      "Train Epoch: 1366 [22528/54000 (42%)] Loss: -752.903992\n",
      "Train Epoch: 1366 [33792/54000 (63%)] Loss: -771.813477\n",
      "Train Epoch: 1366 [45056/54000 (83%)] Loss: -770.610046\n",
      "    epoch          : 1366\n",
      "    loss           : -769.0844260161778\n",
      "    ess            : 1.960320770740509\n",
      "    log_marginal   : 769.120402785967\n",
      "    log_joint      : 977.6415647110849\n",
      "    val_loss       : -772.6982676188151\n",
      "    val_ess        : 1.9598349630832672\n",
      "    val_log_marginal: 772.7354532877604\n",
      "    val_log_joint  : 981.4872741699219\n",
      "Train Epoch: 1367 [0/54000 (0%)] Loss: -754.332581\n",
      "Train Epoch: 1367 [11264/54000 (21%)] Loss: -761.264893\n",
      "Train Epoch: 1367 [22528/54000 (42%)] Loss: -783.374878\n",
      "Train Epoch: 1367 [33792/54000 (63%)] Loss: -768.387146\n",
      "Train Epoch: 1367 [45056/54000 (83%)] Loss: -769.543335\n",
      "    epoch          : 1367\n",
      "    loss           : -769.0097022866303\n",
      "    ess            : 1.9612768134980831\n",
      "    log_marginal   : 769.0454965267542\n",
      "    log_joint      : 977.477377837559\n",
      "    val_loss       : -772.9969228108724\n",
      "    val_ess        : 1.9596205651760101\n",
      "    val_log_marginal: 773.0344645182291\n",
      "    val_log_joint  : 981.6150563557943\n",
      "Train Epoch: 1368 [0/54000 (0%)] Loss: -772.924561\n",
      "Train Epoch: 1368 [11264/54000 (21%)] Loss: -776.483154\n",
      "Train Epoch: 1368 [22528/54000 (42%)] Loss: -777.345581\n",
      "Train Epoch: 1368 [33792/54000 (63%)] Loss: -795.755737\n",
      "Train Epoch: 1368 [45056/54000 (83%)] Loss: -774.137146\n",
      "    epoch          : 1368\n",
      "    loss           : -769.125057580336\n",
      "    ess            : 1.9610995042998836\n",
      "    log_marginal   : 769.1613285856427\n",
      "    log_joint      : 977.5206627036041\n",
      "    val_loss       : -773.8470153808594\n",
      "    val_ess        : 1.9586722950140636\n",
      "    val_log_marginal: 773.8861694335938\n",
      "    val_log_joint  : 982.3849385579427\n",
      "Train Epoch: 1369 [0/54000 (0%)] Loss: -768.027222\n",
      "Train Epoch: 1369 [11264/54000 (21%)] Loss: -776.546997\n",
      "Train Epoch: 1369 [22528/54000 (42%)] Loss: -765.583374\n",
      "Train Epoch: 1369 [33792/54000 (63%)] Loss: -737.830688\n",
      "Train Epoch: 1369 [45056/54000 (83%)] Loss: -799.150574\n",
      "    epoch          : 1369\n",
      "    loss           : -769.0069349756781\n",
      "    ess            : 1.9586933750026632\n",
      "    log_marginal   : 769.0454078530365\n",
      "    log_joint      : 977.6393323214548\n",
      "    val_loss       : -773.2180531819662\n",
      "    val_ess        : 1.9582596520582836\n",
      "    val_log_marginal: 773.2586568196615\n",
      "    val_log_joint  : 981.8842315673828\n",
      "Train Epoch: 1370 [0/54000 (0%)] Loss: -779.270630\n",
      "Train Epoch: 1370 [11264/54000 (21%)] Loss: -779.312195\n",
      "Train Epoch: 1370 [22528/54000 (42%)] Loss: -771.051392\n",
      "Train Epoch: 1370 [33792/54000 (63%)] Loss: -776.932312\n",
      "Train Epoch: 1370 [45056/54000 (83%)] Loss: -782.322754\n",
      "    epoch          : 1370\n",
      "    loss           : -769.2355928241082\n",
      "    ess            : 1.9604208503129348\n",
      "    log_marginal   : 769.2723146834463\n",
      "    log_joint      : 977.7441809312353\n",
      "    val_loss       : -773.4721272786459\n",
      "    val_ess        : 1.9601899286111195\n",
      "    val_log_marginal: 773.5113830566406\n",
      "    val_log_joint  : 982.1092936197916\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1370.pth ...\n",
      "Train Epoch: 1371 [0/54000 (0%)] Loss: -771.893005\n",
      "Train Epoch: 1371 [11264/54000 (21%)] Loss: -767.066772\n",
      "Train Epoch: 1371 [22528/54000 (42%)] Loss: -794.724243\n",
      "Train Epoch: 1371 [33792/54000 (63%)] Loss: -756.781921\n",
      "Train Epoch: 1371 [45056/54000 (83%)] Loss: -754.482422\n",
      "    epoch          : 1371\n",
      "    loss           : -768.9381045935289\n",
      "    ess            : 1.9601791748460733\n",
      "    log_marginal   : 768.9747631144974\n",
      "    log_joint      : 977.4604912523953\n",
      "    val_loss       : -773.3790181477865\n",
      "    val_ess        : 1.959162751833598\n",
      "    val_log_marginal: 773.4147694905599\n",
      "    val_log_joint  : 982.2568766276041\n",
      "Train Epoch: 1372 [0/54000 (0%)] Loss: -768.366455\n",
      "Train Epoch: 1372 [11264/54000 (21%)] Loss: -783.478821\n",
      "Train Epoch: 1372 [22528/54000 (42%)] Loss: -761.056274\n",
      "Train Epoch: 1372 [33792/54000 (63%)] Loss: -798.723755\n",
      "Train Epoch: 1372 [45056/54000 (83%)] Loss: -763.068420\n",
      "    epoch          : 1372\n",
      "    loss           : -768.975389588554\n",
      "    ess            : 1.9592425339626816\n",
      "    log_marginal   : 769.0148833652712\n",
      "    log_joint      : 977.6498482182341\n",
      "    val_loss       : -773.8234608968099\n",
      "    val_ess        : 1.9606805841128032\n",
      "    val_log_marginal: 773.8586680094401\n",
      "    val_log_joint  : 982.4183756510416\n",
      "Train Epoch: 1373 [0/54000 (0%)] Loss: -762.651733\n",
      "Train Epoch: 1373 [11264/54000 (21%)] Loss: -758.261963\n",
      "Train Epoch: 1373 [22528/54000 (42%)] Loss: -760.298462\n",
      "Train Epoch: 1373 [33792/54000 (63%)] Loss: -782.803101\n",
      "Train Epoch: 1373 [45056/54000 (83%)] Loss: -763.594971\n",
      "    epoch          : 1373\n",
      "    loss           : -769.0703741109596\n",
      "    ess            : 1.9605149008193106\n",
      "    log_marginal   : 769.1069572016878\n",
      "    log_joint      : 977.6089022654407\n",
      "    val_loss       : -773.6290588378906\n",
      "    val_ess        : 1.9605904519557953\n",
      "    val_log_marginal: 773.6645558675131\n",
      "    val_log_joint  : 982.0221913655599\n",
      "Train Epoch: 1374 [0/54000 (0%)] Loss: -750.605591\n",
      "Train Epoch: 1374 [11264/54000 (21%)] Loss: -753.718384\n",
      "Train Epoch: 1374 [22528/54000 (42%)] Loss: -786.753906\n",
      "Train Epoch: 1374 [33792/54000 (63%)] Loss: -780.118896\n",
      "Train Epoch: 1374 [45056/54000 (83%)] Loss: -759.255859\n",
      "    epoch          : 1374\n",
      "    loss           : -768.9564473853922\n",
      "    ess            : 1.9602751248287704\n",
      "    log_marginal   : 768.9936782549013\n",
      "    log_joint      : 977.5785459122568\n",
      "    val_loss       : -773.6395975748698\n",
      "    val_ess        : 1.9601364235083263\n",
      "    val_log_marginal: 773.6765645345052\n",
      "    val_log_joint  : 982.0446726481119\n",
      "Train Epoch: 1375 [0/54000 (0%)] Loss: -763.735352\n",
      "Train Epoch: 1375 [11264/54000 (21%)] Loss: -771.105347\n",
      "Train Epoch: 1375 [22528/54000 (42%)] Loss: -773.332947\n",
      "Train Epoch: 1375 [33792/54000 (63%)] Loss: -768.577148\n",
      "Train Epoch: 1375 [45056/54000 (83%)] Loss: -755.598145\n",
      "    epoch          : 1375\n",
      "    loss           : -769.0205037818765\n",
      "    ess            : 1.9600504580533729\n",
      "    log_marginal   : 769.0579546082695\n",
      "    log_joint      : 977.6014928277933\n",
      "    val_loss       : -773.4767862955729\n",
      "    val_ess        : 1.9589114685853322\n",
      "    val_log_marginal: 773.5170949300131\n",
      "    val_log_joint  : 981.8501586914062\n",
      "Train Epoch: 1376 [0/54000 (0%)] Loss: -748.784485\n",
      "Train Epoch: 1376 [11264/54000 (21%)] Loss: -782.584106\n",
      "Train Epoch: 1376 [22528/54000 (42%)] Loss: -765.878052\n",
      "Train Epoch: 1376 [33792/54000 (63%)] Loss: -760.029785\n",
      "Train Epoch: 1376 [45056/54000 (83%)] Loss: -761.377563\n",
      "    epoch          : 1376\n",
      "    loss           : -769.099441816222\n",
      "    ess            : 1.9594507982146065\n",
      "    log_marginal   : 769.1361700093971\n",
      "    log_joint      : 977.6241218998747\n",
      "    val_loss       : -773.0755310058594\n",
      "    val_ess        : 1.9594568610191345\n",
      "    val_log_marginal: 773.1134236653646\n",
      "    val_log_joint  : 981.5958048502604\n",
      "Train Epoch: 1377 [0/54000 (0%)] Loss: -771.829346\n",
      "Train Epoch: 1377 [11264/54000 (21%)] Loss: -769.912476\n",
      "Train Epoch: 1377 [22528/54000 (42%)] Loss: -767.477417\n",
      "Train Epoch: 1377 [33792/54000 (63%)] Loss: -788.312256\n",
      "Train Epoch: 1377 [45056/54000 (83%)] Loss: -773.428162\n",
      "    epoch          : 1377\n",
      "    loss           : -769.0860831782503\n",
      "    ess            : 1.9600338339805603\n",
      "    log_marginal   : 769.1236457104953\n",
      "    log_joint      : 977.5955194437279\n",
      "    val_loss       : -773.1669769287109\n",
      "    val_ess        : 1.9596518178780873\n",
      "    val_log_marginal: 773.2046966552734\n",
      "    val_log_joint  : 982.0421600341797\n",
      "Train Epoch: 1378 [0/54000 (0%)] Loss: -766.017639\n",
      "Train Epoch: 1378 [11264/54000 (21%)] Loss: -744.431091\n",
      "Train Epoch: 1378 [22528/54000 (42%)] Loss: -771.257568\n",
      "Train Epoch: 1378 [33792/54000 (63%)] Loss: -749.358093\n",
      "Train Epoch: 1378 [45056/54000 (83%)] Loss: -790.885864\n",
      "    epoch          : 1378\n",
      "    loss           : -769.1694929014961\n",
      "    ess            : 1.960516741815603\n",
      "    log_marginal   : 769.2064318387014\n",
      "    log_joint      : 977.7768416494694\n",
      "    val_loss       : -773.1724751790365\n",
      "    val_ess        : 1.961157073577245\n",
      "    val_log_marginal: 773.2082112630209\n",
      "    val_log_joint  : 981.640146891276\n",
      "Train Epoch: 1379 [0/54000 (0%)] Loss: -784.901306\n",
      "Train Epoch: 1379 [11264/54000 (21%)] Loss: -783.989990\n",
      "Train Epoch: 1379 [22528/54000 (42%)] Loss: -787.869141\n",
      "Train Epoch: 1379 [33792/54000 (63%)] Loss: -756.682007\n",
      "Train Epoch: 1379 [45056/54000 (83%)] Loss: -794.693115\n",
      "    epoch          : 1379\n",
      "    loss           : -768.9548598955263\n",
      "    ess            : 1.9605899644347857\n",
      "    log_marginal   : 768.9920930682488\n",
      "    log_joint      : 977.5025266251474\n",
      "    val_loss       : -773.4373118082682\n",
      "    val_ess        : 1.9629024267196655\n",
      "    val_log_marginal: 773.4708150227865\n",
      "    val_log_joint  : 982.0623168945312\n",
      "Train Epoch: 1380 [0/54000 (0%)] Loss: -743.511475\n",
      "Train Epoch: 1380 [11264/54000 (21%)] Loss: -767.554443\n",
      "Train Epoch: 1380 [22528/54000 (42%)] Loss: -763.457336\n",
      "Train Epoch: 1380 [33792/54000 (63%)] Loss: -750.805481\n",
      "Train Epoch: 1380 [45056/54000 (83%)] Loss: -769.868774\n",
      "    epoch          : 1380\n",
      "    loss           : -769.3359657143646\n",
      "    ess            : 1.9616681371095046\n",
      "    log_marginal   : 769.3715849102668\n",
      "    log_joint      : 977.8271432552698\n",
      "    val_loss       : -772.8685557047526\n",
      "    val_ess        : 1.959233025709788\n",
      "    val_log_marginal: 772.9075215657552\n",
      "    val_log_joint  : 981.4415435791016\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1380.pth ...\n",
      "Train Epoch: 1381 [0/54000 (0%)] Loss: -756.989868\n",
      "Train Epoch: 1381 [11264/54000 (21%)] Loss: -747.209717\n",
      "Train Epoch: 1381 [22528/54000 (42%)] Loss: -736.920532\n",
      "Train Epoch: 1381 [33792/54000 (63%)] Loss: -761.895020\n",
      "Train Epoch: 1381 [45056/54000 (83%)] Loss: -764.471130\n",
      "    epoch          : 1381\n",
      "    loss           : -769.2373173551739\n",
      "    ess            : 1.9605615780038654\n",
      "    log_marginal   : 769.2734208017025\n",
      "    log_joint      : 977.708831211306\n",
      "    val_loss       : -773.8403065999349\n",
      "    val_ess        : 1.9602692127227783\n",
      "    val_log_marginal: 773.8773040771484\n",
      "    val_log_joint  : 982.4060414632162\n",
      "Train Epoch: 1382 [0/54000 (0%)] Loss: -756.762329\n",
      "Train Epoch: 1382 [11264/54000 (21%)] Loss: -773.061157\n",
      "Train Epoch: 1382 [22528/54000 (42%)] Loss: -776.298767\n",
      "Train Epoch: 1382 [33792/54000 (63%)] Loss: -737.902832\n",
      "Train Epoch: 1382 [45056/54000 (83%)] Loss: -778.127502\n",
      "    epoch          : 1382\n",
      "    loss           : -769.2206685767984\n",
      "    ess            : 1.9607393055591944\n",
      "    log_marginal   : 769.2578142274101\n",
      "    log_joint      : 977.8346661261793\n",
      "    val_loss       : -772.9891153971354\n",
      "    val_ess        : 1.9623813231786091\n",
      "    val_log_marginal: 773.0262298583984\n",
      "    val_log_joint  : 981.7369944254557\n",
      "Train Epoch: 1383 [0/54000 (0%)] Loss: -779.961853\n",
      "Train Epoch: 1383 [11264/54000 (21%)] Loss: -792.010132\n",
      "Train Epoch: 1383 [22528/54000 (42%)] Loss: -751.204773\n",
      "Train Epoch: 1383 [33792/54000 (63%)] Loss: -752.516357\n",
      "Train Epoch: 1383 [45056/54000 (83%)] Loss: -750.489746\n",
      "    epoch          : 1383\n",
      "    loss           : -769.2815281130233\n",
      "    ess            : 1.959812823331581\n",
      "    log_marginal   : 769.3188482320534\n",
      "    log_joint      : 977.7913380748821\n",
      "    val_loss       : -773.9170786539713\n",
      "    val_ess        : 1.9626554648081462\n",
      "    val_log_marginal: 773.9532470703125\n",
      "    val_log_joint  : 982.6244405110677\n",
      "Train Epoch: 1384 [0/54000 (0%)] Loss: -765.256592\n",
      "Train Epoch: 1384 [11264/54000 (21%)] Loss: -758.574829\n",
      "Train Epoch: 1384 [22528/54000 (42%)] Loss: -772.981628\n",
      "Train Epoch: 1384 [33792/54000 (63%)] Loss: -756.193848\n",
      "Train Epoch: 1384 [45056/54000 (83%)] Loss: -768.877563\n",
      "    epoch          : 1384\n",
      "    loss           : -769.2128837153597\n",
      "    ess            : 1.9595548600520727\n",
      "    log_marginal   : 769.2519312444723\n",
      "    log_joint      : 977.796262345224\n",
      "    val_loss       : -773.3229522705078\n",
      "    val_ess        : 1.9579663077990215\n",
      "    val_log_marginal: 773.3639322916666\n",
      "    val_log_joint  : 982.0857289632162\n",
      "Train Epoch: 1385 [0/54000 (0%)] Loss: -749.760132\n",
      "Train Epoch: 1385 [11264/54000 (21%)] Loss: -776.756836\n",
      "Train Epoch: 1385 [22528/54000 (42%)] Loss: -778.534912\n",
      "Train Epoch: 1385 [33792/54000 (63%)] Loss: -782.320557\n",
      "Train Epoch: 1385 [45056/54000 (83%)] Loss: -771.666992\n",
      "    epoch          : 1385\n",
      "    loss           : -769.3635132987545\n",
      "    ess            : 1.9607687513783294\n",
      "    log_marginal   : 769.399741118809\n",
      "    log_joint      : 977.9317569372789\n",
      "    val_loss       : -773.739491780599\n",
      "    val_ess        : 1.9579882522424061\n",
      "    val_log_marginal: 773.7786305745443\n",
      "    val_log_joint  : 982.1405639648438\n",
      "Train Epoch: 1386 [0/54000 (0%)] Loss: -750.114624\n",
      "Train Epoch: 1386 [11264/54000 (21%)] Loss: -748.675232\n",
      "Train Epoch: 1386 [22528/54000 (42%)] Loss: -772.084717\n",
      "Train Epoch: 1386 [33792/54000 (63%)] Loss: -765.515137\n",
      "Train Epoch: 1386 [45056/54000 (83%)] Loss: -761.858643\n",
      "    epoch          : 1386\n",
      "    loss           : -769.3841414541569\n",
      "    ess            : 1.9603940158520106\n",
      "    log_marginal   : 769.4202656296064\n",
      "    log_joint      : 977.990610950398\n",
      "    val_loss       : -773.9034983317057\n",
      "    val_ess        : 1.9600498378276825\n",
      "    val_log_marginal: 773.9421437581381\n",
      "    val_log_joint  : 982.6174163818359\n",
      "Train Epoch: 1387 [0/54000 (0%)] Loss: -775.858765\n",
      "Train Epoch: 1387 [11264/54000 (21%)] Loss: -750.861389\n",
      "Train Epoch: 1387 [22528/54000 (42%)] Loss: -775.217896\n",
      "Train Epoch: 1387 [33792/54000 (63%)] Loss: -775.079529\n",
      "Train Epoch: 1387 [45056/54000 (83%)] Loss: -760.885681\n",
      "    epoch          : 1387\n",
      "    loss           : -769.4904007821713\n",
      "    ess            : 1.9590918185575954\n",
      "    log_marginal   : 769.5293573343529\n",
      "    log_joint      : 978.0779977474573\n",
      "    val_loss       : -773.5247446695963\n",
      "    val_ess        : 1.9629766543706257\n",
      "    val_log_marginal: 773.5599212646484\n",
      "    val_log_joint  : 982.1702016194662\n",
      "Train Epoch: 1388 [0/54000 (0%)] Loss: -744.952881\n",
      "Train Epoch: 1388 [11264/54000 (21%)] Loss: -787.901733\n",
      "Train Epoch: 1388 [22528/54000 (42%)] Loss: -790.536133\n",
      "Train Epoch: 1388 [33792/54000 (63%)] Loss: -792.611816\n",
      "Train Epoch: 1388 [45056/54000 (83%)] Loss: -767.655640\n",
      "    epoch          : 1388\n",
      "    loss           : -769.5294396742335\n",
      "    ess            : 1.9598198690504398\n",
      "    log_marginal   : 769.5673661142025\n",
      "    log_joint      : 978.0813926840729\n",
      "    val_loss       : -773.2315572102865\n",
      "    val_ess        : 1.9601157307624817\n",
      "    val_log_marginal: 773.2701924641927\n",
      "    val_log_joint  : 981.6344451904297\n",
      "Train Epoch: 1389 [0/54000 (0%)] Loss: -775.551392\n",
      "Train Epoch: 1389 [11264/54000 (21%)] Loss: -772.617676\n",
      "Train Epoch: 1389 [22528/54000 (42%)] Loss: -776.061035\n",
      "Train Epoch: 1389 [33792/54000 (63%)] Loss: -763.101379\n",
      "Train Epoch: 1389 [45056/54000 (83%)] Loss: -783.241699\n",
      "    epoch          : 1389\n",
      "    loss           : -769.5684872033461\n",
      "    ess            : 1.961502321486203\n",
      "    log_marginal   : 769.6041248249558\n",
      "    log_joint      : 978.1811137649248\n",
      "    val_loss       : -773.6321360270182\n",
      "    val_ess        : 1.9599709808826447\n",
      "    val_log_marginal: 773.670155843099\n",
      "    val_log_joint  : 982.2487080891927\n",
      "Train Epoch: 1390 [0/54000 (0%)] Loss: -772.732666\n",
      "Train Epoch: 1390 [11264/54000 (21%)] Loss: -791.833313\n",
      "Train Epoch: 1390 [22528/54000 (42%)] Loss: -782.154663\n",
      "Train Epoch: 1390 [33792/54000 (63%)] Loss: -780.747375\n",
      "Train Epoch: 1390 [45056/54000 (83%)] Loss: -778.152466\n",
      "    epoch          : 1390\n",
      "    loss           : -769.5861217570755\n",
      "    ess            : 1.960738478966479\n",
      "    log_marginal   : 769.623501759655\n",
      "    log_joint      : 978.0459986272848\n",
      "    val_loss       : -774.0234629313151\n",
      "    val_ess        : 1.9603939453760784\n",
      "    val_log_marginal: 774.0587666829427\n",
      "    val_log_joint  : 982.4165903727213\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1390.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1391 [0/54000 (0%)] Loss: -753.593689\n",
      "Train Epoch: 1391 [11264/54000 (21%)] Loss: -758.692932\n",
      "Train Epoch: 1391 [22528/54000 (42%)] Loss: -761.587769\n",
      "Train Epoch: 1391 [33792/54000 (63%)] Loss: -765.270020\n",
      "Train Epoch: 1391 [45056/54000 (83%)] Loss: -745.192139\n",
      "    epoch          : 1391\n",
      "    loss           : -769.5241100383255\n",
      "    ess            : 1.959462674158924\n",
      "    log_marginal   : 769.563650455115\n",
      "    log_joint      : 978.1102962853773\n",
      "    val_loss       : -773.5498962402344\n",
      "    val_ess        : 1.9595711926619213\n",
      "    val_log_marginal: 773.5890655517578\n",
      "    val_log_joint  : 982.198252360026\n",
      "Train Epoch: 1392 [0/54000 (0%)] Loss: -786.838867\n",
      "Train Epoch: 1392 [11264/54000 (21%)] Loss: -764.042175\n",
      "Train Epoch: 1392 [22528/54000 (42%)] Loss: -768.111206\n",
      "Train Epoch: 1392 [33792/54000 (63%)] Loss: -768.779846\n",
      "Train Epoch: 1392 [45056/54000 (83%)] Loss: -767.522949\n",
      "    epoch          : 1392\n",
      "    loss           : -769.4252209933298\n",
      "    ess            : 1.960288792286279\n",
      "    log_marginal   : 769.4619687638193\n",
      "    log_joint      : 977.9614269328567\n",
      "    val_loss       : -773.2866923014323\n",
      "    val_ess        : 1.9561800857384999\n",
      "    val_log_marginal: 773.3280639648438\n",
      "    val_log_joint  : 981.761728922526\n",
      "Train Epoch: 1393 [0/54000 (0%)] Loss: -748.172424\n",
      "Train Epoch: 1393 [11264/54000 (21%)] Loss: -762.923828\n",
      "Train Epoch: 1393 [22528/54000 (42%)] Loss: -781.370544\n",
      "Train Epoch: 1393 [33792/54000 (63%)] Loss: -783.905029\n",
      "Train Epoch: 1393 [45056/54000 (83%)] Loss: -767.400452\n",
      "    epoch          : 1393\n",
      "    loss           : -769.5392196943175\n",
      "    ess            : 1.9597471603807413\n",
      "    log_marginal   : 769.5753956920696\n",
      "    log_joint      : 978.0736521594929\n",
      "    val_loss       : -774.2293446858724\n",
      "    val_ess        : 1.958844353755315\n",
      "    val_log_marginal: 774.271728515625\n",
      "    val_log_joint  : 982.6995239257812\n",
      "Train Epoch: 1394 [0/54000 (0%)] Loss: -768.363159\n",
      "Train Epoch: 1394 [11264/54000 (21%)] Loss: -776.196716\n",
      "Train Epoch: 1394 [22528/54000 (42%)] Loss: -768.456665\n",
      "Train Epoch: 1394 [33792/54000 (63%)] Loss: -773.602783\n",
      "Train Epoch: 1394 [45056/54000 (83%)] Loss: -778.749146\n",
      "    epoch          : 1394\n",
      "    loss           : -769.5412822219561\n",
      "    ess            : 1.9593571345761138\n",
      "    log_marginal   : 769.5799019291716\n",
      "    log_joint      : 978.1576417167232\n",
      "    val_loss       : -773.8196716308594\n",
      "    val_ess        : 1.9599111278851826\n",
      "    val_log_marginal: 773.8616638183594\n",
      "    val_log_joint  : 982.3499908447266\n",
      "Train Epoch: 1395 [0/54000 (0%)] Loss: -791.616272\n",
      "Train Epoch: 1395 [11264/54000 (21%)] Loss: -783.440674\n",
      "Train Epoch: 1395 [22528/54000 (42%)] Loss: -755.079163\n",
      "Train Epoch: 1395 [33792/54000 (63%)] Loss: -772.975586\n",
      "Train Epoch: 1395 [45056/54000 (83%)] Loss: -756.403259\n",
      "    epoch          : 1395\n",
      "    loss           : -769.5138089161999\n",
      "    ess            : 1.9598688550715178\n",
      "    log_marginal   : 769.5509315346771\n",
      "    log_joint      : 978.0161080990198\n",
      "    val_loss       : -773.2123057047526\n",
      "    val_ess        : 1.9620573818683624\n",
      "    val_log_marginal: 773.2454020182291\n",
      "    val_log_joint  : 981.7772369384766\n",
      "Train Epoch: 1396 [0/54000 (0%)] Loss: -776.826904\n",
      "Train Epoch: 1396 [11264/54000 (21%)] Loss: -756.392944\n",
      "Train Epoch: 1396 [22528/54000 (42%)] Loss: -776.779541\n",
      "Train Epoch: 1396 [33792/54000 (63%)] Loss: -759.493652\n",
      "Train Epoch: 1396 [45056/54000 (83%)] Loss: -770.559265\n",
      "    epoch          : 1396\n",
      "    loss           : -769.3840959656914\n",
      "    ess            : 1.9617330431938171\n",
      "    log_marginal   : 769.4176509065448\n",
      "    log_joint      : 977.969244615087\n",
      "    val_loss       : -774.0326792399088\n",
      "    val_ess        : 1.9595661958058674\n",
      "    val_log_marginal: 774.0705922444662\n",
      "    val_log_joint  : 982.4892985026041\n",
      "Train Epoch: 1397 [0/54000 (0%)] Loss: -773.973694\n",
      "Train Epoch: 1397 [11264/54000 (21%)] Loss: -790.799988\n",
      "Train Epoch: 1397 [22528/54000 (42%)] Loss: -765.512573\n",
      "Train Epoch: 1397 [33792/54000 (63%)] Loss: -778.192017\n",
      "Train Epoch: 1397 [45056/54000 (83%)] Loss: -770.913574\n",
      "    epoch          : 1397\n",
      "    loss           : -769.5909861438679\n",
      "    ess            : 1.960704764105239\n",
      "    log_marginal   : 769.6266940134876\n",
      "    log_joint      : 978.10086347472\n",
      "    val_loss       : -774.5576883951823\n",
      "    val_ess        : 1.9622110227743785\n",
      "    val_log_marginal: 774.5939636230469\n",
      "    val_log_joint  : 983.0297444661459\n",
      "Train Epoch: 1398 [0/54000 (0%)] Loss: -765.931824\n",
      "Train Epoch: 1398 [11264/54000 (21%)] Loss: -765.672485\n",
      "Train Epoch: 1398 [22528/54000 (42%)] Loss: -771.865234\n",
      "Train Epoch: 1398 [33792/54000 (63%)] Loss: -761.127319\n",
      "Train Epoch: 1398 [45056/54000 (83%)] Loss: -775.856689\n",
      "    epoch          : 1398\n",
      "    loss           : -769.7669504993366\n",
      "    ess            : 1.9602430552806493\n",
      "    log_marginal   : 769.8042959537146\n",
      "    log_joint      : 978.2590625690964\n",
      "    val_loss       : -774.2922770182291\n",
      "    val_ess        : 1.9605046312014263\n",
      "    val_log_marginal: 774.3279571533203\n",
      "    val_log_joint  : 982.8691151936849\n",
      "Train Epoch: 1399 [0/54000 (0%)] Loss: -795.875488\n",
      "Train Epoch: 1399 [11264/54000 (21%)] Loss: -765.836182\n",
      "Train Epoch: 1399 [22528/54000 (42%)] Loss: -776.967651\n",
      "Train Epoch: 1399 [33792/54000 (63%)] Loss: -754.577820\n",
      "Train Epoch: 1399 [45056/54000 (83%)] Loss: -757.642700\n",
      "    epoch          : 1399\n",
      "    loss           : -769.5157701024469\n",
      "    ess            : 1.9607992880749252\n",
      "    log_marginal   : 769.5516282567438\n",
      "    log_joint      : 978.1142042627874\n",
      "    val_loss       : -773.6421813964844\n",
      "    val_ess        : 1.9597037533919017\n",
      "    val_log_marginal: 773.6791636149088\n",
      "    val_log_joint  : 982.2917429606119\n",
      "Train Epoch: 1400 [0/54000 (0%)] Loss: -779.732422\n",
      "Train Epoch: 1400 [11264/54000 (21%)] Loss: -781.439819\n",
      "Train Epoch: 1400 [22528/54000 (42%)] Loss: -780.914429\n",
      "Train Epoch: 1400 [33792/54000 (63%)] Loss: -772.879822\n",
      "Train Epoch: 1400 [45056/54000 (83%)] Loss: -773.097046\n",
      "    epoch          : 1400\n",
      "    loss           : -769.6013788187279\n",
      "    ess            : 1.959918425892884\n",
      "    log_marginal   : 769.6393328972582\n",
      "    log_joint      : 978.2247285662957\n",
      "    val_loss       : -774.1593627929688\n",
      "    val_ess        : 1.9563229084014893\n",
      "    val_log_marginal: 774.2044372558594\n",
      "    val_log_joint  : 982.5121714274088\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1400.pth ...\n",
      "Train Epoch: 1401 [0/54000 (0%)] Loss: -748.863892\n",
      "Train Epoch: 1401 [11264/54000 (21%)] Loss: -771.380371\n",
      "Train Epoch: 1401 [22528/54000 (42%)] Loss: -769.751709\n",
      "Train Epoch: 1401 [33792/54000 (63%)] Loss: -769.649780\n",
      "Train Epoch: 1401 [45056/54000 (83%)] Loss: -774.554688\n",
      "    epoch          : 1401\n",
      "    loss           : -769.652085214291\n",
      "    ess            : 1.960343579076371\n",
      "    log_marginal   : 769.6887172483048\n",
      "    log_joint      : 978.2579673911041\n",
      "    val_loss       : -773.9282786051432\n",
      "    val_ess        : 1.9611128270626068\n",
      "    val_log_marginal: 773.9651184082031\n",
      "    val_log_joint  : 982.4597829182943\n",
      "Train Epoch: 1402 [0/54000 (0%)] Loss: -775.535278\n",
      "Train Epoch: 1402 [11264/54000 (21%)] Loss: -755.664856\n",
      "Train Epoch: 1402 [22528/54000 (42%)] Loss: -760.058105\n",
      "Train Epoch: 1402 [33792/54000 (63%)] Loss: -764.989258\n",
      "Train Epoch: 1402 [45056/54000 (83%)] Loss: -777.955017\n",
      "    epoch          : 1402\n",
      "    loss           : -769.7723158350531\n",
      "    ess            : 1.9593961744938257\n",
      "    log_marginal   : 769.8098916107754\n",
      "    log_joint      : 978.352826388377\n",
      "    val_loss       : -774.0701649983724\n",
      "    val_ess        : 1.9615612924098969\n",
      "    val_log_marginal: 774.1073303222656\n",
      "    val_log_joint  : 982.8564910888672\n",
      "Train Epoch: 1403 [0/54000 (0%)] Loss: -776.850769\n",
      "Train Epoch: 1403 [11264/54000 (21%)] Loss: -781.320190\n",
      "Train Epoch: 1403 [22528/54000 (42%)] Loss: -768.760620\n",
      "Train Epoch: 1403 [33792/54000 (63%)] Loss: -764.020264\n",
      "Train Epoch: 1403 [45056/54000 (83%)] Loss: -783.199097\n",
      "    epoch          : 1403\n",
      "    loss           : -769.7734611079378\n",
      "    ess            : 1.9596559427819162\n",
      "    log_marginal   : 769.8109079037073\n",
      "    log_joint      : 978.239367790942\n",
      "    val_loss       : -773.8523763020834\n",
      "    val_ess        : 1.958496888478597\n",
      "    val_log_marginal: 773.8942260742188\n",
      "    val_log_joint  : 982.4476216634115\n",
      "Train Epoch: 1404 [0/54000 (0%)] Loss: -747.166809\n",
      "Train Epoch: 1404 [11264/54000 (21%)] Loss: -773.625732\n",
      "Train Epoch: 1404 [22528/54000 (42%)] Loss: -776.720581\n",
      "Train Epoch: 1404 [33792/54000 (63%)] Loss: -764.611816\n",
      "Train Epoch: 1404 [45056/54000 (83%)] Loss: -771.491516\n",
      "    epoch          : 1404\n",
      "    loss           : -769.6879157300266\n",
      "    ess            : 1.9602727395183634\n",
      "    log_marginal   : 769.7252473651238\n",
      "    log_joint      : 978.264871849204\n",
      "    val_loss       : -773.5291849772135\n",
      "    val_ess        : 1.9587715367476146\n",
      "    val_log_marginal: 773.5684458414713\n",
      "    val_log_joint  : 982.6003265380859\n",
      "Train Epoch: 1405 [0/54000 (0%)] Loss: -769.766052\n",
      "Train Epoch: 1405 [11264/54000 (21%)] Loss: -766.115295\n",
      "Train Epoch: 1405 [22528/54000 (42%)] Loss: -785.017944\n",
      "Train Epoch: 1405 [33792/54000 (63%)] Loss: -767.634705\n",
      "Train Epoch: 1405 [45056/54000 (83%)] Loss: -785.926025\n",
      "    epoch          : 1405\n",
      "    loss           : -769.8424780503759\n",
      "    ess            : 1.9578299657353815\n",
      "    log_marginal   : 769.882754919664\n",
      "    log_joint      : 978.3265847260097\n",
      "    val_loss       : -774.5444132486979\n",
      "    val_ess        : 1.9643368422985077\n",
      "    val_log_marginal: 774.5791524251302\n",
      "    val_log_joint  : 983.1734568277994\n",
      "Train Epoch: 1406 [0/54000 (0%)] Loss: -761.567627\n",
      "Train Epoch: 1406 [11264/54000 (21%)] Loss: -794.422119\n",
      "Train Epoch: 1406 [22528/54000 (42%)] Loss: -775.995361\n",
      "Train Epoch: 1406 [33792/54000 (63%)] Loss: -761.980652\n",
      "Train Epoch: 1406 [45056/54000 (83%)] Loss: -768.902832\n",
      "    epoch          : 1406\n",
      "    loss           : -769.5864597536483\n",
      "    ess            : 1.9587116972455438\n",
      "    log_marginal   : 769.6248566249632\n",
      "    log_joint      : 978.1594267071418\n",
      "    val_loss       : -773.9316355387369\n",
      "    val_ess        : 1.9572034378846486\n",
      "    val_log_marginal: 773.9750213623047\n",
      "    val_log_joint  : 982.5784200032552\n",
      "Train Epoch: 1407 [0/54000 (0%)] Loss: -773.104980\n",
      "Train Epoch: 1407 [11264/54000 (21%)] Loss: -759.892090\n",
      "Train Epoch: 1407 [22528/54000 (42%)] Loss: -766.819458\n",
      "Train Epoch: 1407 [33792/54000 (63%)] Loss: -786.920776\n",
      "Train Epoch: 1407 [45056/54000 (83%)] Loss: -795.796570\n",
      "    epoch          : 1407\n",
      "    loss           : -769.7710542498894\n",
      "    ess            : 1.9594683366001777\n",
      "    log_marginal   : 769.8090722425928\n",
      "    log_joint      : 978.3413178066038\n",
      "    val_loss       : -774.0484263102213\n",
      "    val_ess        : 1.9602736433347066\n",
      "    val_log_marginal: 774.0832366943359\n",
      "    val_log_joint  : 982.3862457275391\n",
      "Train Epoch: 1408 [0/54000 (0%)] Loss: -780.971741\n",
      "Train Epoch: 1408 [11264/54000 (21%)] Loss: -755.593262\n",
      "Train Epoch: 1408 [22528/54000 (42%)] Loss: -746.710083\n",
      "Train Epoch: 1408 [33792/54000 (63%)] Loss: -770.965576\n",
      "Train Epoch: 1408 [45056/54000 (83%)] Loss: -782.773926\n",
      "    epoch          : 1408\n",
      "    loss           : -769.9537382305793\n",
      "    ess            : 1.9600589151652354\n",
      "    log_marginal   : 769.9915656323703\n",
      "    log_joint      : 978.5538140063015\n",
      "    val_loss       : -774.0150705973307\n",
      "    val_ess        : 1.95811727643013\n",
      "    val_log_marginal: 774.0560048421224\n",
      "    val_log_joint  : 982.579600016276\n",
      "Train Epoch: 1409 [0/54000 (0%)] Loss: -768.457397\n",
      "Train Epoch: 1409 [11264/54000 (21%)] Loss: -747.797180\n",
      "Train Epoch: 1409 [22528/54000 (42%)] Loss: -769.986816\n",
      "Train Epoch: 1409 [33792/54000 (63%)] Loss: -779.863281\n",
      "Train Epoch: 1409 [45056/54000 (83%)] Loss: -769.261536\n",
      "    epoch          : 1409\n",
      "    loss           : -769.845415799123\n",
      "    ess            : 1.9590379303356387\n",
      "    log_marginal   : 769.8825626013414\n",
      "    log_joint      : 978.4614177200029\n",
      "    val_loss       : -773.4680480957031\n",
      "    val_ess        : 1.9584891597429912\n",
      "    val_log_marginal: 773.5021311442057\n",
      "    val_log_joint  : 982.0484670003256\n",
      "Train Epoch: 1410 [0/54000 (0%)] Loss: -781.324341\n",
      "Train Epoch: 1410 [11264/54000 (21%)] Loss: -788.560669\n",
      "Train Epoch: 1410 [22528/54000 (42%)] Loss: -763.737183\n",
      "Train Epoch: 1410 [33792/54000 (63%)] Loss: -776.587524\n",
      "Train Epoch: 1410 [45056/54000 (83%)] Loss: -752.487549\n",
      "    epoch          : 1410\n",
      "    loss           : -769.9059488548422\n",
      "    ess            : 1.9588019825377554\n",
      "    log_marginal   : 769.9449601083431\n",
      "    log_joint      : 978.5567448454083\n",
      "    val_loss       : -775.0537160237631\n",
      "    val_ess        : 1.9569401741027832\n",
      "    val_log_marginal: 775.0940551757812\n",
      "    val_log_joint  : 983.545176188151\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1410.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1411 [0/54000 (0%)] Loss: -757.135132\n",
      "Train Epoch: 1411 [11264/54000 (21%)] Loss: -766.896851\n",
      "Train Epoch: 1411 [22528/54000 (42%)] Loss: -778.333618\n",
      "Train Epoch: 1411 [33792/54000 (63%)] Loss: -757.096375\n",
      "Train Epoch: 1411 [45056/54000 (83%)] Loss: -747.080811\n",
      "    epoch          : 1411\n",
      "    loss           : -769.7760234328936\n",
      "    ess            : 1.9604414780184907\n",
      "    log_marginal   : 769.8130418309626\n",
      "    log_joint      : 978.278841990345\n",
      "    val_loss       : -774.2634124755859\n",
      "    val_ess        : 1.960355003674825\n",
      "    val_log_marginal: 774.2994181315104\n",
      "    val_log_joint  : 982.9500986735026\n",
      "Train Epoch: 1412 [0/54000 (0%)] Loss: -755.714050\n",
      "Train Epoch: 1412 [11264/54000 (21%)] Loss: -769.684631\n",
      "Train Epoch: 1412 [22528/54000 (42%)] Loss: -767.522400\n",
      "Train Epoch: 1412 [33792/54000 (63%)] Loss: -775.793457\n",
      "Train Epoch: 1412 [45056/54000 (83%)] Loss: -767.832825\n",
      "    epoch          : 1412\n",
      "    loss           : -769.9739713848762\n",
      "    ess            : 1.9598043977089648\n",
      "    log_marginal   : 770.011766541679\n",
      "    log_joint      : 978.4720746886055\n",
      "    val_loss       : -773.8883565266927\n",
      "    val_ess        : 1.963476836681366\n",
      "    val_log_marginal: 773.9188181559244\n",
      "    val_log_joint  : 982.4265747070312\n",
      "Train Epoch: 1413 [0/54000 (0%)] Loss: -773.986328\n",
      "Train Epoch: 1413 [11264/54000 (21%)] Loss: -772.446472\n",
      "Train Epoch: 1413 [22528/54000 (42%)] Loss: -760.183838\n",
      "Train Epoch: 1413 [33792/54000 (63%)] Loss: -765.609009\n",
      "Train Epoch: 1413 [45056/54000 (83%)] Loss: -780.472717\n",
      "    epoch          : 1413\n",
      "    loss           : -770.0623059542673\n",
      "    ess            : 1.96149421075605\n",
      "    log_marginal   : 770.0985366533388\n",
      "    log_joint      : 978.6290513524469\n",
      "    val_loss       : -773.9288330078125\n",
      "    val_ess        : 1.96093546350797\n",
      "    val_log_marginal: 773.9642995198568\n",
      "    val_log_joint  : 982.8262023925781\n",
      "Train Epoch: 1414 [0/54000 (0%)] Loss: -780.406982\n",
      "Train Epoch: 1414 [11264/54000 (21%)] Loss: -750.282349\n",
      "Train Epoch: 1414 [22528/54000 (42%)] Loss: -771.116699\n",
      "Train Epoch: 1414 [33792/54000 (63%)] Loss: -781.362671\n",
      "Train Epoch: 1414 [45056/54000 (83%)] Loss: -781.007996\n",
      "    epoch          : 1414\n",
      "    loss           : -770.1104321749705\n",
      "    ess            : 1.9609981955222364\n",
      "    log_marginal   : 770.1458872669148\n",
      "    log_joint      : 978.6069278357164\n",
      "    val_loss       : -774.6639607747396\n",
      "    val_ess        : 1.9618005752563477\n",
      "    val_log_marginal: 774.6959330240885\n",
      "    val_log_joint  : 983.2734375\n",
      "Train Epoch: 1415 [0/54000 (0%)] Loss: -769.405884\n",
      "Train Epoch: 1415 [11264/54000 (21%)] Loss: -768.049683\n",
      "Train Epoch: 1415 [22528/54000 (42%)] Loss: -755.847534\n",
      "Train Epoch: 1415 [33792/54000 (63%)] Loss: -783.434204\n",
      "Train Epoch: 1415 [45056/54000 (83%)] Loss: -779.028076\n",
      "    epoch          : 1415\n",
      "    loss           : -769.7934547280365\n",
      "    ess            : 1.960319068071977\n",
      "    log_marginal   : 769.8312055479805\n",
      "    log_joint      : 978.3500371968971\n",
      "    val_loss       : -774.1592864990234\n",
      "    val_ess        : 1.9562207063039143\n",
      "    val_log_marginal: 774.1986796061198\n",
      "    val_log_joint  : 983.0579477945963\n",
      "Train Epoch: 1416 [0/54000 (0%)] Loss: -770.706177\n",
      "Train Epoch: 1416 [11264/54000 (21%)] Loss: -774.710205\n",
      "Train Epoch: 1416 [22528/54000 (42%)] Loss: -764.476074\n",
      "Train Epoch: 1416 [33792/54000 (63%)] Loss: -769.180115\n",
      "Train Epoch: 1416 [45056/54000 (83%)] Loss: -775.972961\n",
      "    epoch          : 1416\n",
      "    loss           : -770.0738842082474\n",
      "    ess            : 1.959573508433576\n",
      "    log_marginal   : 770.1118077691996\n",
      "    log_joint      : 978.677895599941\n",
      "    val_loss       : -774.3930358886719\n",
      "    val_ess        : 1.9590875307718914\n",
      "    val_log_marginal: 774.4313100179037\n",
      "    val_log_joint  : 982.8020833333334\n",
      "Train Epoch: 1417 [0/54000 (0%)] Loss: -782.874634\n",
      "Train Epoch: 1417 [11264/54000 (21%)] Loss: -762.718323\n",
      "Train Epoch: 1417 [22528/54000 (42%)] Loss: -768.455933\n",
      "Train Epoch: 1417 [33792/54000 (63%)] Loss: -759.733643\n",
      "Train Epoch: 1417 [45056/54000 (83%)] Loss: -755.303467\n",
      "    epoch          : 1417\n",
      "    loss           : -769.9761646198776\n",
      "    ess            : 1.960204059222959\n",
      "    log_marginal   : 770.0136972103479\n",
      "    log_joint      : 978.4695803084463\n",
      "    val_loss       : -774.2467600504557\n",
      "    val_ess        : 1.9605521460374196\n",
      "    val_log_marginal: 774.2839508056641\n",
      "    val_log_joint  : 982.6970926920573\n",
      "Train Epoch: 1418 [0/54000 (0%)] Loss: -742.732666\n",
      "Train Epoch: 1418 [11264/54000 (21%)] Loss: -758.076965\n",
      "Train Epoch: 1418 [22528/54000 (42%)] Loss: -770.546509\n",
      "Train Epoch: 1418 [33792/54000 (63%)] Loss: -769.739014\n",
      "Train Epoch: 1418 [45056/54000 (83%)] Loss: -761.275269\n",
      "    epoch          : 1418\n",
      "    loss           : -769.9048836186247\n",
      "    ess            : 1.9606972651661567\n",
      "    log_marginal   : 769.9419860839844\n",
      "    log_joint      : 978.5387861143868\n",
      "    val_loss       : -774.4630686442057\n",
      "    val_ess        : 1.9636383056640625\n",
      "    val_log_marginal: 774.4976806640625\n",
      "    val_log_joint  : 982.6697692871094\n",
      "Train Epoch: 1419 [0/54000 (0%)] Loss: -803.239014\n",
      "Train Epoch: 1419 [11264/54000 (21%)] Loss: -768.559814\n",
      "Train Epoch: 1419 [22528/54000 (42%)] Loss: -771.569824\n",
      "Train Epoch: 1419 [33792/54000 (63%)] Loss: -772.369446\n",
      "Train Epoch: 1419 [45056/54000 (83%)] Loss: -782.204834\n",
      "    epoch          : 1419\n",
      "    loss           : -769.9417315788988\n",
      "    ess            : 1.9619367808665868\n",
      "    log_marginal   : 769.9764208523733\n",
      "    log_joint      : 978.449127773069\n",
      "    val_loss       : -774.1170806884766\n",
      "    val_ess        : 1.9614704549312592\n",
      "    val_log_marginal: 774.15087890625\n",
      "    val_log_joint  : 982.5665232340494\n",
      "Train Epoch: 1420 [0/54000 (0%)] Loss: -781.813599\n",
      "Train Epoch: 1420 [11264/54000 (21%)] Loss: -773.463501\n",
      "Train Epoch: 1420 [22528/54000 (42%)] Loss: -767.683289\n",
      "Train Epoch: 1420 [33792/54000 (63%)] Loss: -779.377441\n",
      "Train Epoch: 1420 [45056/54000 (83%)] Loss: -778.620728\n",
      "    epoch          : 1420\n",
      "    loss           : -770.2247740547612\n",
      "    ess            : 1.9610565732110221\n",
      "    log_marginal   : 770.2612465912441\n",
      "    log_joint      : 978.7991212089107\n",
      "    val_loss       : -774.2291615804037\n",
      "    val_ess        : 1.9598018825054169\n",
      "    val_log_marginal: 774.2686869303385\n",
      "    val_log_joint  : 983.0041707356771\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1420.pth ...\n",
      "Train Epoch: 1421 [0/54000 (0%)] Loss: -767.427124\n",
      "Train Epoch: 1421 [11264/54000 (21%)] Loss: -759.520386\n",
      "Train Epoch: 1421 [22528/54000 (42%)] Loss: -765.219055\n",
      "Train Epoch: 1421 [33792/54000 (63%)] Loss: -796.464233\n",
      "Train Epoch: 1421 [45056/54000 (83%)] Loss: -759.027466\n",
      "    epoch          : 1421\n",
      "    loss           : -770.330920525317\n",
      "    ess            : 1.9605158095089894\n",
      "    log_marginal   : 770.3687479271078\n",
      "    log_joint      : 978.9142945487545\n",
      "    val_loss       : -774.6512196858724\n",
      "    val_ess        : 1.9583004514376323\n",
      "    val_log_marginal: 774.6932983398438\n",
      "    val_log_joint  : 983.1803283691406\n",
      "Train Epoch: 1422 [0/54000 (0%)] Loss: -759.621094\n",
      "Train Epoch: 1422 [11264/54000 (21%)] Loss: -794.560852\n",
      "Train Epoch: 1422 [22528/54000 (42%)] Loss: -773.151611\n",
      "Train Epoch: 1422 [33792/54000 (63%)] Loss: -786.518066\n",
      "Train Epoch: 1422 [45056/54000 (83%)] Loss: -777.942566\n",
      "    epoch          : 1422\n",
      "    loss           : -770.1176141702904\n",
      "    ess            : 1.960807351571209\n",
      "    log_marginal   : 770.1552170087706\n",
      "    log_joint      : 978.7163252920475\n",
      "    val_loss       : -774.8091430664062\n",
      "    val_ess        : 1.958479990561803\n",
      "    val_log_marginal: 774.8503468831381\n",
      "    val_log_joint  : 983.1946970621744\n",
      "Train Epoch: 1423 [0/54000 (0%)] Loss: -773.621948\n",
      "Train Epoch: 1423 [11264/54000 (21%)] Loss: -760.759766\n",
      "Train Epoch: 1423 [22528/54000 (42%)] Loss: -781.379944\n",
      "Train Epoch: 1423 [33792/54000 (63%)] Loss: -763.778198\n",
      "Train Epoch: 1423 [45056/54000 (83%)] Loss: -748.619934\n",
      "    epoch          : 1423\n",
      "    loss           : -770.0988257066259\n",
      "    ess            : 1.9599676672017798\n",
      "    log_marginal   : 770.1356535137825\n",
      "    log_joint      : 978.645383438974\n",
      "    val_loss       : -774.6314036051432\n",
      "    val_ess        : 1.9595669507980347\n",
      "    val_log_marginal: 774.6706695556641\n",
      "    val_log_joint  : 983.062266031901\n",
      "Train Epoch: 1424 [0/54000 (0%)] Loss: -782.995178\n",
      "Train Epoch: 1424 [11264/54000 (21%)] Loss: -748.349548\n",
      "Train Epoch: 1424 [22528/54000 (42%)] Loss: -771.577637\n",
      "Train Epoch: 1424 [33792/54000 (63%)] Loss: -745.514526\n",
      "Train Epoch: 1424 [45056/54000 (83%)] Loss: -788.002808\n",
      "    epoch          : 1424\n",
      "    loss           : -770.2456941424675\n",
      "    ess            : 1.9591727729113597\n",
      "    log_marginal   : 770.2833453484301\n",
      "    log_joint      : 978.8932201457474\n",
      "    val_loss       : -774.8115234375\n",
      "    val_ess        : 1.9598485231399536\n",
      "    val_log_marginal: 774.8486328125\n",
      "    val_log_joint  : 983.3228352864584\n",
      "Train Epoch: 1425 [0/54000 (0%)] Loss: -759.738281\n",
      "Train Epoch: 1425 [11264/54000 (21%)] Loss: -764.817505\n",
      "Train Epoch: 1425 [22528/54000 (42%)] Loss: -773.228210\n",
      "Train Epoch: 1425 [33792/54000 (63%)] Loss: -793.974792\n",
      "Train Epoch: 1425 [45056/54000 (83%)] Loss: -790.829285\n",
      "    epoch          : 1425\n",
      "    loss           : -770.3326450563827\n",
      "    ess            : 1.9595563782835907\n",
      "    log_marginal   : 770.3716021843676\n",
      "    log_joint      : 979.091203221735\n",
      "    val_loss       : -775.5545399983724\n",
      "    val_ess        : 1.9644590318202972\n",
      "    val_log_marginal: 775.5870208740234\n",
      "    val_log_joint  : 984.2530975341797\n",
      "Train Epoch: 1426 [0/54000 (0%)] Loss: -783.128113\n",
      "Train Epoch: 1426 [11264/54000 (21%)] Loss: -774.140137\n",
      "Train Epoch: 1426 [22528/54000 (42%)] Loss: -798.007568\n",
      "Train Epoch: 1426 [33792/54000 (63%)] Loss: -775.545105\n",
      "Train Epoch: 1426 [45056/54000 (83%)] Loss: -791.432007\n",
      "    epoch          : 1426\n",
      "    loss           : -770.3839992307267\n",
      "    ess            : 1.9604990830961264\n",
      "    log_marginal   : 770.4206986337338\n",
      "    log_joint      : 979.0460976654629\n",
      "    val_loss       : -774.623036702474\n",
      "    val_ess        : 1.958503524462382\n",
      "    val_log_marginal: 774.6646270751953\n",
      "    val_log_joint  : 983.1487223307291\n",
      "Train Epoch: 1427 [0/54000 (0%)] Loss: -784.145386\n",
      "Train Epoch: 1427 [11264/54000 (21%)] Loss: -775.518677\n",
      "Train Epoch: 1427 [22528/54000 (42%)] Loss: -771.847473\n",
      "Train Epoch: 1427 [33792/54000 (63%)] Loss: -766.205994\n",
      "Train Epoch: 1427 [45056/54000 (83%)] Loss: -765.567261\n",
      "    epoch          : 1427\n",
      "    loss           : -770.4032322145858\n",
      "    ess            : 1.959600566693072\n",
      "    log_marginal   : 770.4404227778597\n",
      "    log_joint      : 978.9484535073334\n",
      "    val_loss       : -774.5540720621744\n",
      "    val_ess        : 1.9603536029656727\n",
      "    val_log_marginal: 774.594716389974\n",
      "    val_log_joint  : 983.2675628662109\n",
      "Train Epoch: 1428 [0/54000 (0%)] Loss: -781.467773\n",
      "Train Epoch: 1428 [11264/54000 (21%)] Loss: -755.436218\n",
      "Train Epoch: 1428 [22528/54000 (42%)] Loss: -779.247070\n",
      "Train Epoch: 1428 [33792/54000 (63%)] Loss: -778.082275\n",
      "Train Epoch: 1428 [45056/54000 (83%)] Loss: -794.988281\n",
      "    epoch          : 1428\n",
      "    loss           : -770.2415045972141\n",
      "    ess            : 1.9593785843759213\n",
      "    log_marginal   : 770.2792807525059\n",
      "    log_joint      : 978.8090336637677\n",
      "    val_loss       : -774.4768931070963\n",
      "    val_ess        : 1.9600441257158916\n",
      "    val_log_marginal: 774.509267171224\n",
      "    val_log_joint  : 983.2754465738932\n",
      "Train Epoch: 1429 [0/54000 (0%)] Loss: -774.997559\n",
      "Train Epoch: 1429 [11264/54000 (21%)] Loss: -769.308228\n",
      "Train Epoch: 1429 [22528/54000 (42%)] Loss: -759.731079\n",
      "Train Epoch: 1429 [33792/54000 (63%)] Loss: -757.974792\n",
      "Train Epoch: 1429 [45056/54000 (83%)] Loss: -779.295471\n",
      "    epoch          : 1429\n",
      "    loss           : -770.5133977926002\n",
      "    ess            : 1.9606952138666838\n",
      "    log_marginal   : 770.5493780172096\n",
      "    log_joint      : 978.9864720758402\n",
      "    val_loss       : -775.0483093261719\n",
      "    val_ess        : 1.9578169286251068\n",
      "    val_log_marginal: 775.0953521728516\n",
      "    val_log_joint  : 983.4914703369141\n",
      "Train Epoch: 1430 [0/54000 (0%)] Loss: -777.439209\n",
      "Train Epoch: 1430 [11264/54000 (21%)] Loss: -752.029663\n",
      "Train Epoch: 1430 [22528/54000 (42%)] Loss: -769.606506\n",
      "Train Epoch: 1430 [33792/54000 (63%)] Loss: -797.745361\n",
      "Train Epoch: 1430 [45056/54000 (83%)] Loss: -768.699585\n",
      "    epoch          : 1430\n",
      "    loss           : -770.3921071178509\n",
      "    ess            : 1.9609824419021606\n",
      "    log_marginal   : 770.428466796875\n",
      "    log_joint      : 978.9494047344856\n",
      "    val_loss       : -774.5492299397787\n",
      "    val_ess        : 1.960668573776881\n",
      "    val_log_marginal: 774.5839894612631\n",
      "    val_log_joint  : 983.1470133463541\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1430.pth ...\n",
      "Train Epoch: 1431 [0/54000 (0%)] Loss: -760.195496\n",
      "Train Epoch: 1431 [11264/54000 (21%)] Loss: -781.381714\n",
      "Train Epoch: 1431 [22528/54000 (42%)] Loss: -752.008850\n",
      "Train Epoch: 1431 [33792/54000 (63%)] Loss: -772.565918\n",
      "Train Epoch: 1431 [45056/54000 (83%)] Loss: -774.532959\n",
      "    epoch          : 1431\n",
      "    loss           : -770.4553297510687\n",
      "    ess            : 1.960300694096763\n",
      "    log_marginal   : 770.4920228202388\n",
      "    log_joint      : 979.1437901910746\n",
      "    val_loss       : -775.1543986002604\n",
      "    val_ess        : 1.9592450658480327\n",
      "    val_log_marginal: 775.1948293050131\n",
      "    val_log_joint  : 983.656494140625\n",
      "Train Epoch: 1432 [0/54000 (0%)] Loss: -777.048828\n",
      "Train Epoch: 1432 [11264/54000 (21%)] Loss: -793.470154\n",
      "Train Epoch: 1432 [22528/54000 (42%)] Loss: -795.924866\n",
      "Train Epoch: 1432 [33792/54000 (63%)] Loss: -779.936646\n",
      "Train Epoch: 1432 [45056/54000 (83%)] Loss: -794.192505\n",
      "    epoch          : 1432\n",
      "    loss           : -770.5629640975088\n",
      "    ess            : 1.958961693745739\n",
      "    log_marginal   : 770.6021590322819\n",
      "    log_joint      : 979.1616182147332\n",
      "    val_loss       : -774.2630208333334\n",
      "    val_ess        : 1.9603788455327351\n",
      "    val_log_marginal: 774.2962900797526\n",
      "    val_log_joint  : 982.9262644449869\n",
      "Train Epoch: 1433 [0/54000 (0%)] Loss: -787.028809\n",
      "Train Epoch: 1433 [11264/54000 (21%)] Loss: -783.770874\n",
      "Train Epoch: 1433 [22528/54000 (42%)] Loss: -784.483765\n",
      "Train Epoch: 1433 [33792/54000 (63%)] Loss: -776.053772\n",
      "Train Epoch: 1433 [45056/54000 (83%)] Loss: -761.378540\n",
      "    epoch          : 1433\n",
      "    loss           : -770.5615361051739\n",
      "    ess            : 1.9593074029346682\n",
      "    log_marginal   : 770.5996767439932\n",
      "    log_joint      : 979.1193104869915\n",
      "    val_loss       : -774.9308929443359\n",
      "    val_ess        : 1.9651625752449036\n",
      "    val_log_marginal: 774.9633941650391\n",
      "    val_log_joint  : 983.3987375895182\n",
      "Train Epoch: 1434 [0/54000 (0%)] Loss: -759.885986\n",
      "Train Epoch: 1434 [11264/54000 (21%)] Loss: -776.005737\n",
      "Train Epoch: 1434 [22528/54000 (42%)] Loss: -753.239624\n",
      "Train Epoch: 1434 [33792/54000 (63%)] Loss: -745.488037\n",
      "Train Epoch: 1434 [45056/54000 (83%)] Loss: -770.823914\n",
      "    epoch          : 1434\n",
      "    loss           : -770.8286720131928\n",
      "    ess            : 1.9608754594371003\n",
      "    log_marginal   : 770.8653288067512\n",
      "    log_joint      : 979.4459199725457\n",
      "    val_loss       : -774.7392781575521\n",
      "    val_ess        : 1.958636651436488\n",
      "    val_log_marginal: 774.7775828043619\n",
      "    val_log_joint  : 983.6128489176432\n",
      "Train Epoch: 1435 [0/54000 (0%)] Loss: -757.770752\n",
      "Train Epoch: 1435 [11264/54000 (21%)] Loss: -788.519897\n",
      "Train Epoch: 1435 [22528/54000 (42%)] Loss: -764.363647\n",
      "Train Epoch: 1435 [33792/54000 (63%)] Loss: -775.770020\n",
      "Train Epoch: 1435 [45056/54000 (83%)] Loss: -758.625732\n",
      "    epoch          : 1435\n",
      "    loss           : -770.4916911575029\n",
      "    ess            : 1.9609101853280697\n",
      "    log_marginal   : 770.5280640800045\n",
      "    log_joint      : 979.0860135060436\n",
      "    val_loss       : -775.1139068603516\n",
      "    val_ess        : 1.9585386315981548\n",
      "    val_log_marginal: 775.1531372070312\n",
      "    val_log_joint  : 983.7836710611979\n",
      "Train Epoch: 1436 [0/54000 (0%)] Loss: -779.420349\n",
      "Train Epoch: 1436 [11264/54000 (21%)] Loss: -809.772278\n",
      "Train Epoch: 1436 [22528/54000 (42%)] Loss: -774.153931\n",
      "Train Epoch: 1436 [33792/54000 (63%)] Loss: -747.333130\n",
      "Train Epoch: 1436 [45056/54000 (83%)] Loss: -766.020874\n",
      "    epoch          : 1436\n",
      "    loss           : -770.6685762225457\n",
      "    ess            : 1.9605106902572345\n",
      "    log_marginal   : 770.706758319207\n",
      "    log_joint      : 979.2616634728773\n",
      "    val_loss       : -775.4217580159506\n",
      "    val_ess        : 1.9599159459273021\n",
      "    val_log_marginal: 775.4615020751953\n",
      "    val_log_joint  : 983.9769744873047\n",
      "Train Epoch: 1437 [0/54000 (0%)] Loss: -782.488525\n",
      "Train Epoch: 1437 [11264/54000 (21%)] Loss: -771.997192\n",
      "Train Epoch: 1437 [22528/54000 (42%)] Loss: -770.606018\n",
      "Train Epoch: 1437 [33792/54000 (63%)] Loss: -759.673584\n",
      "Train Epoch: 1437 [45056/54000 (83%)] Loss: -757.210571\n",
      "    epoch          : 1437\n",
      "    loss           : -770.7593591078272\n",
      "    ess            : 1.959672045032933\n",
      "    log_marginal   : 770.7970534990419\n",
      "    log_joint      : 979.3165288961159\n",
      "    val_loss       : -775.2819875081381\n",
      "    val_ess        : 1.9609383443991344\n",
      "    val_log_marginal: 775.3178405761719\n",
      "    val_log_joint  : 983.9285583496094\n",
      "Train Epoch: 1438 [0/54000 (0%)] Loss: -773.399170\n",
      "Train Epoch: 1438 [11264/54000 (21%)] Loss: -760.736328\n",
      "Train Epoch: 1438 [22528/54000 (42%)] Loss: -766.079834\n",
      "Train Epoch: 1438 [33792/54000 (63%)] Loss: -768.463989\n",
      "Train Epoch: 1438 [45056/54000 (83%)] Loss: -760.115967\n",
      "    epoch          : 1438\n",
      "    loss           : -770.6986423708358\n",
      "    ess            : 1.9603861626589074\n",
      "    log_marginal   : 770.7358237212559\n",
      "    log_joint      : 979.3137443110628\n",
      "    val_loss       : -774.7303415934244\n",
      "    val_ess        : 1.9570566713809967\n",
      "    val_log_marginal: 774.7708028157552\n",
      "    val_log_joint  : 983.2369333902994\n",
      "Train Epoch: 1439 [0/54000 (0%)] Loss: -776.146729\n",
      "Train Epoch: 1439 [11264/54000 (21%)] Loss: -786.905762\n",
      "Train Epoch: 1439 [22528/54000 (42%)] Loss: -760.996887\n",
      "Train Epoch: 1439 [33792/54000 (63%)] Loss: -767.272888\n",
      "Train Epoch: 1439 [45056/54000 (83%)] Loss: -760.914795\n",
      "    epoch          : 1439\n",
      "    loss           : -770.7553129376106\n",
      "    ess            : 1.959803525006996\n",
      "    log_marginal   : 770.7927954331884\n",
      "    log_joint      : 979.3240252800707\n",
      "    val_loss       : -775.3622233072916\n",
      "    val_ess        : 1.9568958481152852\n",
      "    val_log_marginal: 775.4054768880209\n",
      "    val_log_joint  : 983.8601125081381\n",
      "Train Epoch: 1440 [0/54000 (0%)] Loss: -769.163635\n",
      "Train Epoch: 1440 [11264/54000 (21%)] Loss: -760.768555\n",
      "Train Epoch: 1440 [22528/54000 (42%)] Loss: -773.378662\n",
      "Train Epoch: 1440 [33792/54000 (63%)] Loss: -796.056641\n",
      "Train Epoch: 1440 [45056/54000 (83%)] Loss: -777.084961\n",
      "    epoch          : 1440\n",
      "    loss           : -770.8258839733196\n",
      "    ess            : 1.9609375607292607\n",
      "    log_marginal   : 770.8621797381707\n",
      "    log_joint      : 979.2879667462043\n",
      "    val_loss       : -775.0503336588541\n",
      "    val_ess        : 1.960226943095525\n",
      "    val_log_marginal: 775.0892944335938\n",
      "    val_log_joint  : 983.4849853515625\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1440.pth ...\n",
      "Train Epoch: 1441 [0/54000 (0%)] Loss: -768.481750\n",
      "Train Epoch: 1441 [11264/54000 (21%)] Loss: -775.576416\n",
      "Train Epoch: 1441 [22528/54000 (42%)] Loss: -780.177368\n",
      "Train Epoch: 1441 [33792/54000 (63%)] Loss: -752.952393\n",
      "Train Epoch: 1441 [45056/54000 (83%)] Loss: -816.002808\n",
      "    epoch          : 1441\n",
      "    loss           : -770.7062648557267\n",
      "    ess            : 1.9599278243082874\n",
      "    log_marginal   : 770.7446208450029\n",
      "    log_joint      : 979.3175532502948\n",
      "    val_loss       : -775.3317260742188\n",
      "    val_ess        : 1.9583712021509807\n",
      "    val_log_marginal: 775.3763529459635\n",
      "    val_log_joint  : 983.8475952148438\n",
      "Train Epoch: 1442 [0/54000 (0%)] Loss: -749.122864\n",
      "Train Epoch: 1442 [11264/54000 (21%)] Loss: -774.432129\n",
      "Train Epoch: 1442 [22528/54000 (42%)] Loss: -805.985474\n",
      "Train Epoch: 1442 [33792/54000 (63%)] Loss: -774.703491\n",
      "Train Epoch: 1442 [45056/54000 (83%)] Loss: -780.208374\n",
      "    epoch          : 1442\n",
      "    loss           : -770.7814261958284\n",
      "    ess            : 1.9603883545353729\n",
      "    log_marginal   : 770.8186651265846\n",
      "    log_joint      : 979.3902772147701\n",
      "    val_loss       : -775.1941680908203\n",
      "    val_ess        : 1.960283358891805\n",
      "    val_log_marginal: 775.2339782714844\n",
      "    val_log_joint  : 983.8359222412109\n",
      "Train Epoch: 1443 [0/54000 (0%)] Loss: -765.254150\n",
      "Train Epoch: 1443 [11264/54000 (21%)] Loss: -764.062256\n",
      "Train Epoch: 1443 [22528/54000 (42%)] Loss: -773.546265\n",
      "Train Epoch: 1443 [33792/54000 (63%)] Loss: -780.595459\n",
      "Train Epoch: 1443 [45056/54000 (83%)] Loss: -785.492920\n",
      "    epoch          : 1443\n",
      "    loss           : -770.816079193691\n",
      "    ess            : 1.9604155758641801\n",
      "    log_marginal   : 770.8546488060141\n",
      "    log_joint      : 979.3944748212706\n",
      "    val_loss       : -775.7269897460938\n",
      "    val_ess        : 1.9581758081912994\n",
      "    val_log_marginal: 775.7655537923177\n",
      "    val_log_joint  : 984.3200276692709\n",
      "Train Epoch: 1444 [0/54000 (0%)] Loss: -807.420410\n",
      "Train Epoch: 1444 [11264/54000 (21%)] Loss: -758.183472\n",
      "Train Epoch: 1444 [22528/54000 (42%)] Loss: -761.912231\n",
      "Train Epoch: 1444 [33792/54000 (63%)] Loss: -771.853394\n",
      "Train Epoch: 1444 [45056/54000 (83%)] Loss: -796.751587\n",
      "    epoch          : 1444\n",
      "    loss           : -770.6844534244177\n",
      "    ess            : 1.96075269411195\n",
      "    log_marginal   : 770.7207514924823\n",
      "    log_joint      : 979.3201432138119\n",
      "    val_loss       : -774.7779897054037\n",
      "    val_ess        : 1.9606805543104808\n",
      "    val_log_marginal: 774.815175374349\n",
      "    val_log_joint  : 983.4032745361328\n",
      "Train Epoch: 1445 [0/54000 (0%)] Loss: -746.480652\n",
      "Train Epoch: 1445 [11264/54000 (21%)] Loss: -758.582153\n",
      "Train Epoch: 1445 [22528/54000 (42%)] Loss: -776.563232\n",
      "Train Epoch: 1445 [33792/54000 (63%)] Loss: -769.311646\n",
      "Train Epoch: 1445 [45056/54000 (83%)] Loss: -774.952087\n",
      "    epoch          : 1445\n",
      "    loss           : -770.8018401523806\n",
      "    ess            : 1.9583834533421498\n",
      "    log_marginal   : 770.841112244804\n",
      "    log_joint      : 979.3229537100162\n",
      "    val_loss       : -775.7481486002604\n",
      "    val_ess        : 1.9620506366093953\n",
      "    val_log_marginal: 775.7791290283203\n",
      "    val_log_joint  : 984.1821492513021\n",
      "Train Epoch: 1446 [0/54000 (0%)] Loss: -770.360718\n",
      "Train Epoch: 1446 [11264/54000 (21%)] Loss: -793.150696\n",
      "Train Epoch: 1446 [22528/54000 (42%)] Loss: -767.562866\n",
      "Train Epoch: 1446 [33792/54000 (63%)] Loss: -783.507996\n",
      "Train Epoch: 1446 [45056/54000 (83%)] Loss: -780.273804\n",
      "    epoch          : 1446\n",
      "    loss           : -770.8528799380896\n",
      "    ess            : 1.9605626430151597\n",
      "    log_marginal   : 770.8902956404776\n",
      "    log_joint      : 979.3840792673939\n",
      "    val_loss       : -775.8710378011068\n",
      "    val_ess        : 1.9586958686510723\n",
      "    val_log_marginal: 775.9132741292318\n",
      "    val_log_joint  : 984.1877136230469\n",
      "Train Epoch: 1447 [0/54000 (0%)] Loss: -757.401062\n",
      "Train Epoch: 1447 [11264/54000 (21%)] Loss: -789.029480\n",
      "Train Epoch: 1447 [22528/54000 (42%)] Loss: -761.163147\n",
      "Train Epoch: 1447 [33792/54000 (63%)] Loss: -760.634277\n",
      "Train Epoch: 1447 [45056/54000 (83%)] Loss: -787.702942\n",
      "    epoch          : 1447\n",
      "    loss           : -771.0407709085716\n",
      "    ess            : 1.9596204330336373\n",
      "    log_marginal   : 771.0787768094045\n",
      "    log_joint      : 979.4968445975826\n",
      "    val_loss       : -775.2999318440756\n",
      "    val_ess        : 1.9618060688177745\n",
      "    val_log_marginal: 775.3329010009766\n",
      "    val_log_joint  : 983.8362630208334\n",
      "Train Epoch: 1448 [0/54000 (0%)] Loss: -764.720398\n",
      "Train Epoch: 1448 [11264/54000 (21%)] Loss: -769.959717\n",
      "Train Epoch: 1448 [22528/54000 (42%)] Loss: -770.580017\n",
      "Train Epoch: 1448 [33792/54000 (63%)] Loss: -773.082458\n",
      "Train Epoch: 1448 [45056/54000 (83%)] Loss: -796.772827\n",
      "    epoch          : 1448\n",
      "    loss           : -770.7359676720961\n",
      "    ess            : 1.9613062087095008\n",
      "    log_marginal   : 770.771867284235\n",
      "    log_joint      : 979.2410381964918\n",
      "    val_loss       : -775.1561940511068\n",
      "    val_ess        : 1.9636429846286774\n",
      "    val_log_marginal: 775.1916351318359\n",
      "    val_log_joint  : 983.54443359375\n",
      "Train Epoch: 1449 [0/54000 (0%)] Loss: -770.732910\n",
      "Train Epoch: 1449 [11264/54000 (21%)] Loss: -772.087646\n",
      "Train Epoch: 1449 [22528/54000 (42%)] Loss: -772.355957\n",
      "Train Epoch: 1449 [33792/54000 (63%)] Loss: -791.662842\n",
      "Train Epoch: 1449 [45056/54000 (83%)] Loss: -748.858459\n",
      "    epoch          : 1449\n",
      "    loss           : -770.674065931788\n",
      "    ess            : 1.9600827187862035\n",
      "    log_marginal   : 770.7116037044885\n",
      "    log_joint      : 979.1942921764446\n",
      "    val_loss       : -774.9550730387369\n",
      "    val_ess        : 1.9615552127361298\n",
      "    val_log_marginal: 774.9917602539062\n",
      "    val_log_joint  : 983.6346232096354\n",
      "Train Epoch: 1450 [0/54000 (0%)] Loss: -778.769409\n",
      "Train Epoch: 1450 [11264/54000 (21%)] Loss: -773.701904\n",
      "Train Epoch: 1450 [22528/54000 (42%)] Loss: -792.093506\n",
      "Train Epoch: 1450 [33792/54000 (63%)] Loss: -764.588562\n",
      "Train Epoch: 1450 [45056/54000 (83%)] Loss: -773.184204\n",
      "    epoch          : 1450\n",
      "    loss           : -770.7993014353626\n",
      "    ess            : 1.9601090089330133\n",
      "    log_marginal   : 770.8367234715876\n",
      "    log_joint      : 979.3740280439268\n",
      "    val_loss       : -775.5726064046224\n",
      "    val_ess        : 1.9590474267800648\n",
      "    val_log_marginal: 775.6105753580729\n",
      "    val_log_joint  : 984.1739959716797\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1450.pth ...\n",
      "Train Epoch: 1451 [0/54000 (0%)] Loss: -769.186768\n",
      "Train Epoch: 1451 [11264/54000 (21%)] Loss: -769.643982\n",
      "Train Epoch: 1451 [22528/54000 (42%)] Loss: -763.723267\n",
      "Train Epoch: 1451 [33792/54000 (63%)] Loss: -758.164307\n",
      "Train Epoch: 1451 [45056/54000 (83%)] Loss: -783.011597\n",
      "    epoch          : 1451\n",
      "    loss           : -770.7574578051297\n",
      "    ess            : 1.9601245522499084\n",
      "    log_marginal   : 770.7949950020268\n",
      "    log_joint      : 979.3770533147848\n",
      "    val_loss       : -775.2197570800781\n",
      "    val_ess        : 1.9652200837930043\n",
      "    val_log_marginal: 775.2505187988281\n",
      "    val_log_joint  : 983.4635569254557\n",
      "Train Epoch: 1452 [0/54000 (0%)] Loss: -770.654236\n",
      "Train Epoch: 1452 [11264/54000 (21%)] Loss: -765.082153\n",
      "Train Epoch: 1452 [22528/54000 (42%)] Loss: -775.897949\n",
      "Train Epoch: 1452 [33792/54000 (63%)] Loss: -776.114136\n",
      "Train Epoch: 1452 [45056/54000 (83%)] Loss: -757.898438\n",
      "    epoch          : 1452\n",
      "    loss           : -770.9753308566111\n",
      "    ess            : 1.9606872099750448\n",
      "    log_marginal   : 771.012637732164\n",
      "    log_joint      : 979.5198554272922\n",
      "    val_loss       : -775.7674153645834\n",
      "    val_ess        : 1.961520145336787\n",
      "    val_log_marginal: 775.8044840494791\n",
      "    val_log_joint  : 984.4234263102213\n",
      "Train Epoch: 1453 [0/54000 (0%)] Loss: -759.078613\n",
      "Train Epoch: 1453 [11264/54000 (21%)] Loss: -756.752686\n",
      "Train Epoch: 1453 [22528/54000 (42%)] Loss: -740.240845\n",
      "Train Epoch: 1453 [33792/54000 (63%)] Loss: -788.976990\n",
      "Train Epoch: 1453 [45056/54000 (83%)] Loss: -776.134949\n",
      "    epoch          : 1453\n",
      "    loss           : -771.0339246066111\n",
      "    ess            : 1.9599817383964107\n",
      "    log_marginal   : 771.0708255407945\n",
      "    log_joint      : 979.6459126022627\n",
      "    val_loss       : -775.2019602457682\n",
      "    val_ess        : 1.960398683945338\n",
      "    val_log_marginal: 775.2380777994791\n",
      "    val_log_joint  : 983.7193400065104\n",
      "Train Epoch: 1454 [0/54000 (0%)] Loss: -770.357788\n",
      "Train Epoch: 1454 [11264/54000 (21%)] Loss: -763.368286\n",
      "Train Epoch: 1454 [22528/54000 (42%)] Loss: -774.646973\n",
      "Train Epoch: 1454 [33792/54000 (63%)] Loss: -774.106567\n",
      "Train Epoch: 1454 [45056/54000 (83%)] Loss: -784.799194\n",
      "    epoch          : 1454\n",
      "    loss           : -771.0000103644605\n",
      "    ess            : 1.960284613213449\n",
      "    log_marginal   : 771.0373546672317\n",
      "    log_joint      : 979.4972827839401\n",
      "    val_loss       : -775.4227091471354\n",
      "    val_ess        : 1.959648181994756\n",
      "    val_log_marginal: 775.4597524007162\n",
      "    val_log_joint  : 983.7807159423828\n",
      "Train Epoch: 1455 [0/54000 (0%)] Loss: -778.975830\n",
      "Train Epoch: 1455 [11264/54000 (21%)] Loss: -771.940430\n",
      "Train Epoch: 1455 [22528/54000 (42%)] Loss: -791.995728\n",
      "Train Epoch: 1455 [33792/54000 (63%)] Loss: -790.444946\n",
      "Train Epoch: 1455 [45056/54000 (83%)] Loss: -763.909424\n",
      "    epoch          : 1455\n",
      "    loss           : -770.8353720610996\n",
      "    ess            : 1.9589330205377542\n",
      "    log_marginal   : 770.8736048284567\n",
      "    log_joint      : 979.4459527933373\n",
      "    val_loss       : -774.8832448323568\n",
      "    val_ess        : 1.959938406944275\n",
      "    val_log_marginal: 774.9194691975912\n",
      "    val_log_joint  : 983.1445109049479\n",
      "Train Epoch: 1456 [0/54000 (0%)] Loss: -757.631104\n",
      "Train Epoch: 1456 [11264/54000 (21%)] Loss: -766.560120\n",
      "Train Epoch: 1456 [22528/54000 (42%)] Loss: -767.851929\n",
      "Train Epoch: 1456 [33792/54000 (63%)] Loss: -766.738708\n",
      "Train Epoch: 1456 [45056/54000 (83%)] Loss: -793.683777\n",
      "    epoch          : 1456\n",
      "    loss           : -770.979883157982\n",
      "    ess            : 1.9603424420896567\n",
      "    log_marginal   : 771.0177998092939\n",
      "    log_joint      : 979.5300206598246\n",
      "    val_loss       : -775.0996144612631\n",
      "    val_ess        : 1.958585927883784\n",
      "    val_log_marginal: 775.1360473632812\n",
      "    val_log_joint  : 983.7195485432943\n",
      "Train Epoch: 1457 [0/54000 (0%)] Loss: -763.070374\n",
      "Train Epoch: 1457 [11264/54000 (21%)] Loss: -759.551025\n",
      "Train Epoch: 1457 [22528/54000 (42%)] Loss: -762.112061\n",
      "Train Epoch: 1457 [33792/54000 (63%)] Loss: -761.726257\n",
      "Train Epoch: 1457 [45056/54000 (83%)] Loss: -777.068115\n",
      "    epoch          : 1457\n",
      "    loss           : -771.0018771189564\n",
      "    ess            : 1.9593479442146589\n",
      "    log_marginal   : 771.0406269577314\n",
      "    log_joint      : 979.6191924473025\n",
      "    val_loss       : -775.1801147460938\n",
      "    val_ess        : 1.9607688585917156\n",
      "    val_log_marginal: 775.2157440185547\n",
      "    val_log_joint  : 983.6862945556641\n",
      "Train Epoch: 1458 [0/54000 (0%)] Loss: -765.087891\n",
      "Train Epoch: 1458 [11264/54000 (21%)] Loss: -755.863098\n",
      "Train Epoch: 1458 [22528/54000 (42%)] Loss: -772.707397\n",
      "Train Epoch: 1458 [33792/54000 (63%)] Loss: -765.931458\n",
      "Train Epoch: 1458 [45056/54000 (83%)] Loss: -783.106201\n",
      "    epoch          : 1458\n",
      "    loss           : -771.0279725272701\n",
      "    ess            : 1.9603806745331243\n",
      "    log_marginal   : 771.06529091889\n",
      "    log_joint      : 979.6398614847435\n",
      "    val_loss       : -775.791249593099\n",
      "    val_ess        : 1.9574492474397023\n",
      "    val_log_marginal: 775.8303934733073\n",
      "    val_log_joint  : 984.5796203613281\n",
      "Train Epoch: 1459 [0/54000 (0%)] Loss: -766.470520\n",
      "Train Epoch: 1459 [11264/54000 (21%)] Loss: -779.161255\n",
      "Train Epoch: 1459 [22528/54000 (42%)] Loss: -781.614990\n",
      "Train Epoch: 1459 [33792/54000 (63%)] Loss: -754.526001\n",
      "Train Epoch: 1459 [45056/54000 (83%)] Loss: -775.352173\n",
      "    epoch          : 1459\n",
      "    loss           : -770.8252281332916\n",
      "    ess            : 1.9603348486828354\n",
      "    log_marginal   : 770.8627589963517\n",
      "    log_joint      : 979.4738878933889\n",
      "    val_loss       : -775.8559163411459\n",
      "    val_ess        : 1.960941344499588\n",
      "    val_log_marginal: 775.8923695882162\n",
      "    val_log_joint  : 984.3732096354166\n",
      "Train Epoch: 1460 [0/54000 (0%)] Loss: -763.807251\n",
      "Train Epoch: 1460 [11264/54000 (21%)] Loss: -766.390564\n",
      "Train Epoch: 1460 [22528/54000 (42%)] Loss: -764.783997\n",
      "Train Epoch: 1460 [33792/54000 (63%)] Loss: -777.005798\n",
      "Train Epoch: 1460 [45056/54000 (83%)] Loss: -766.815796\n",
      "    epoch          : 1460\n",
      "    loss           : -770.9893988843235\n",
      "    ess            : 1.9594547197503864\n",
      "    log_marginal   : 771.026861802587\n",
      "    log_joint      : 979.5522155761719\n",
      "    val_loss       : -774.8195546468099\n",
      "    val_ess        : 1.961194117863973\n",
      "    val_log_marginal: 774.8553263346354\n",
      "    val_log_joint  : 983.3511962890625\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1460.pth ...\n",
      "Train Epoch: 1461 [0/54000 (0%)] Loss: -751.404175\n",
      "Train Epoch: 1461 [11264/54000 (21%)] Loss: -742.896179\n",
      "Train Epoch: 1461 [22528/54000 (42%)] Loss: -785.389038\n",
      "Train Epoch: 1461 [33792/54000 (63%)] Loss: -786.703003\n",
      "Train Epoch: 1461 [45056/54000 (83%)] Loss: -749.078857\n",
      "    epoch          : 1461\n",
      "    loss           : -771.1107851424307\n",
      "    ess            : 1.960096944053218\n",
      "    log_marginal   : 771.1478628482458\n",
      "    log_joint      : 979.5649627109743\n",
      "    val_loss       : -775.3332977294922\n",
      "    val_ess        : 1.9605657756328583\n",
      "    val_log_marginal: 775.3735961914062\n",
      "    val_log_joint  : 984.0572916666666\n",
      "Train Epoch: 1462 [0/54000 (0%)] Loss: -793.667847\n",
      "Train Epoch: 1462 [11264/54000 (21%)] Loss: -755.723816\n",
      "Train Epoch: 1462 [22528/54000 (42%)] Loss: -777.193298\n",
      "Train Epoch: 1462 [33792/54000 (63%)] Loss: -780.917847\n",
      "Train Epoch: 1462 [45056/54000 (83%)] Loss: -789.347351\n",
      "    epoch          : 1462\n",
      "    loss           : -770.9715812251253\n",
      "    ess            : 1.9596619516048792\n",
      "    log_marginal   : 771.0114838222288\n",
      "    log_joint      : 979.5484158497936\n",
      "    val_loss       : -775.1588541666666\n",
      "    val_ess        : 1.9599503378073375\n",
      "    val_log_marginal: 775.1973571777344\n",
      "    val_log_joint  : 983.7420196533203\n",
      "Train Epoch: 1463 [0/54000 (0%)] Loss: -778.523926\n",
      "Train Epoch: 1463 [11264/54000 (21%)] Loss: -742.318054\n",
      "Train Epoch: 1463 [22528/54000 (42%)] Loss: -774.888855\n",
      "Train Epoch: 1463 [33792/54000 (63%)] Loss: -763.672241\n",
      "Train Epoch: 1463 [45056/54000 (83%)] Loss: -778.404419\n",
      "    epoch          : 1463\n",
      "    loss           : -771.0720433649027\n",
      "    ess            : 1.9612447304545708\n",
      "    log_marginal   : 771.1076706220518\n",
      "    log_joint      : 979.6720753795696\n",
      "    val_loss       : -775.0713907877604\n",
      "    val_ess        : 1.9593927760918934\n",
      "    val_log_marginal: 775.1099294026693\n",
      "    val_log_joint  : 983.5464070638021\n",
      "Train Epoch: 1464 [0/54000 (0%)] Loss: -776.461182\n",
      "Train Epoch: 1464 [11264/54000 (21%)] Loss: -766.403870\n",
      "Train Epoch: 1464 [22528/54000 (42%)] Loss: -779.300659\n",
      "Train Epoch: 1464 [33792/54000 (63%)] Loss: -770.715454\n",
      "Train Epoch: 1464 [45056/54000 (83%)] Loss: -747.854248\n",
      "    epoch          : 1464\n",
      "    loss           : -771.1386165978773\n",
      "    ess            : 1.9602730667816017\n",
      "    log_marginal   : 771.1755935381044\n",
      "    log_joint      : 979.7149686993293\n",
      "    val_loss       : -775.5819956461588\n",
      "    val_ess        : 1.9647250771522522\n",
      "    val_log_marginal: 775.6125539143881\n",
      "    val_log_joint  : 984.0301462809244\n",
      "Train Epoch: 1465 [0/54000 (0%)] Loss: -773.152771\n",
      "Train Epoch: 1465 [11264/54000 (21%)] Loss: -784.709412\n",
      "Train Epoch: 1465 [22528/54000 (42%)] Loss: -785.816162\n",
      "Train Epoch: 1465 [33792/54000 (63%)] Loss: -776.800903\n",
      "Train Epoch: 1465 [45056/54000 (83%)] Loss: -784.829468\n",
      "    epoch          : 1465\n",
      "    loss           : -771.1073861751917\n",
      "    ess            : 1.960501862022112\n",
      "    log_marginal   : 771.1462765099867\n",
      "    log_joint      : 979.6983533175486\n",
      "    val_loss       : -775.2356262207031\n",
      "    val_ess        : 1.9594654043515523\n",
      "    val_log_marginal: 775.2733357747396\n",
      "    val_log_joint  : 984.0256601969401\n",
      "Train Epoch: 1466 [0/54000 (0%)] Loss: -796.230713\n",
      "Train Epoch: 1466 [11264/54000 (21%)] Loss: -766.995300\n",
      "Train Epoch: 1466 [22528/54000 (42%)] Loss: -779.357483\n",
      "Train Epoch: 1466 [33792/54000 (63%)] Loss: -757.127380\n",
      "Train Epoch: 1466 [45056/54000 (83%)] Loss: -765.954102\n",
      "    epoch          : 1466\n",
      "    loss           : -771.0202366091171\n",
      "    ess            : 1.9587162575631771\n",
      "    log_marginal   : 771.060163965765\n",
      "    log_joint      : 979.6285538583431\n",
      "    val_loss       : -776.0843607584635\n",
      "    val_ess        : 1.9597890675067902\n",
      "    val_log_marginal: 776.1204477945963\n",
      "    val_log_joint  : 984.8474578857422\n",
      "Train Epoch: 1467 [0/54000 (0%)] Loss: -779.940491\n",
      "Train Epoch: 1467 [11264/54000 (21%)] Loss: -764.369690\n",
      "Train Epoch: 1467 [22528/54000 (42%)] Loss: -760.708313\n",
      "Train Epoch: 1467 [33792/54000 (63%)] Loss: -754.944336\n",
      "Train Epoch: 1467 [45056/54000 (83%)] Loss: -771.818481\n",
      "    epoch          : 1467\n",
      "    loss           : -771.277434726931\n",
      "    ess            : 1.960843894841536\n",
      "    log_marginal   : 771.3136256955704\n",
      "    log_joint      : 979.8664176509066\n",
      "    val_loss       : -774.1696217854818\n",
      "    val_ess        : 1.9639447232087452\n",
      "    val_log_marginal: 774.2038167317709\n",
      "    val_log_joint  : 982.8331451416016\n",
      "Train Epoch: 1468 [0/54000 (0%)] Loss: -738.899170\n",
      "Train Epoch: 1468 [11264/54000 (21%)] Loss: -780.805176\n",
      "Train Epoch: 1468 [22528/54000 (42%)] Loss: -766.968811\n",
      "Train Epoch: 1468 [33792/54000 (63%)] Loss: -777.116699\n",
      "Train Epoch: 1468 [45056/54000 (83%)] Loss: -780.620239\n",
      "    epoch          : 1468\n",
      "    loss           : -771.3592540812942\n",
      "    ess            : 1.960671194319455\n",
      "    log_marginal   : 771.3964383107311\n",
      "    log_joint      : 979.938902656987\n",
      "    val_loss       : -775.3495381673177\n",
      "    val_ess        : 1.9594296117623646\n",
      "    val_log_marginal: 775.3875020345052\n",
      "    val_log_joint  : 983.6073760986328\n",
      "Train Epoch: 1469 [0/54000 (0%)] Loss: -776.709961\n",
      "Train Epoch: 1469 [11264/54000 (21%)] Loss: -776.688843\n",
      "Train Epoch: 1469 [22528/54000 (42%)] Loss: -756.437927\n",
      "Train Epoch: 1469 [33792/54000 (63%)] Loss: -765.915894\n",
      "Train Epoch: 1469 [45056/54000 (83%)] Loss: -793.293152\n",
      "    epoch          : 1469\n",
      "    loss           : -771.1144294019016\n",
      "    ess            : 1.9605441813199025\n",
      "    log_marginal   : 771.1513314876917\n",
      "    log_joint      : 979.6700088213075\n",
      "    val_loss       : -775.0428721110026\n",
      "    val_ess        : 1.959087351957957\n",
      "    val_log_marginal: 775.0826568603516\n",
      "    val_log_joint  : 983.5845998128256\n",
      "Train Epoch: 1470 [0/54000 (0%)] Loss: -776.574219\n",
      "Train Epoch: 1470 [11264/54000 (21%)] Loss: -762.510315\n",
      "Train Epoch: 1470 [22528/54000 (42%)] Loss: -786.683472\n",
      "Train Epoch: 1470 [33792/54000 (63%)] Loss: -763.971069\n",
      "Train Epoch: 1470 [45056/54000 (83%)] Loss: -760.197876\n",
      "    epoch          : 1470\n",
      "    loss           : -771.3160722840507\n",
      "    ess            : 1.9599130401071512\n",
      "    log_marginal   : 771.3541875875221\n",
      "    log_joint      : 979.8682239460495\n",
      "    val_loss       : -775.012196858724\n",
      "    val_ess        : 1.9613553881645203\n",
      "    val_log_marginal: 775.0470937093099\n",
      "    val_log_joint  : 983.5560404459635\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1470.pth ...\n",
      "Train Epoch: 1471 [0/54000 (0%)] Loss: -758.404663\n",
      "Train Epoch: 1471 [11264/54000 (21%)] Loss: -770.273743\n",
      "Train Epoch: 1471 [22528/54000 (42%)] Loss: -771.021301\n",
      "Train Epoch: 1471 [33792/54000 (63%)] Loss: -765.425049\n",
      "Train Epoch: 1471 [45056/54000 (83%)] Loss: -794.553467\n",
      "    epoch          : 1471\n",
      "    loss           : -771.2009438568691\n",
      "    ess            : 1.9608736645500615\n",
      "    log_marginal   : 771.2381620587043\n",
      "    log_joint      : 979.7034606933594\n",
      "    val_loss       : -775.2874399820963\n",
      "    val_ess        : 1.9579489827156067\n",
      "    val_log_marginal: 775.3277893066406\n",
      "    val_log_joint  : 984.0484008789062\n",
      "Train Epoch: 1472 [0/54000 (0%)] Loss: -762.643799\n",
      "Train Epoch: 1472 [11264/54000 (21%)] Loss: -790.262817\n",
      "Train Epoch: 1472 [22528/54000 (42%)] Loss: -768.745300\n",
      "Train Epoch: 1472 [33792/54000 (63%)] Loss: -783.766479\n",
      "Train Epoch: 1472 [45056/54000 (83%)] Loss: -765.908386\n",
      "    epoch          : 1472\n",
      "    loss           : -771.2149001787294\n",
      "    ess            : 1.9596681313694648\n",
      "    log_marginal   : 771.2523130021005\n",
      "    log_joint      : 979.8483754283977\n",
      "    val_loss       : -775.0429636637369\n",
      "    val_ess        : 1.9596758584181468\n",
      "    val_log_marginal: 775.0788218180338\n",
      "    val_log_joint  : 983.7704366048177\n",
      "Train Epoch: 1473 [0/54000 (0%)] Loss: -772.146667\n",
      "Train Epoch: 1473 [11264/54000 (21%)] Loss: -744.100952\n",
      "Train Epoch: 1473 [22528/54000 (42%)] Loss: -761.181946\n",
      "Train Epoch: 1473 [33792/54000 (63%)] Loss: -787.065063\n",
      "Train Epoch: 1473 [45056/54000 (83%)] Loss: -784.139282\n",
      "    epoch          : 1473\n",
      "    loss           : -771.3299122936321\n",
      "    ess            : 1.9609705637086112\n",
      "    log_marginal   : 771.3658562426297\n",
      "    log_joint      : 979.9242375211895\n",
      "    val_loss       : -775.3343454996744\n",
      "    val_ess        : 1.9632239937782288\n",
      "    val_log_marginal: 775.365966796875\n",
      "    val_log_joint  : 983.7943776448568\n",
      "Train Epoch: 1474 [0/54000 (0%)] Loss: -778.090637\n",
      "Train Epoch: 1474 [11264/54000 (21%)] Loss: -757.562500\n",
      "Train Epoch: 1474 [22528/54000 (42%)] Loss: -791.614624\n",
      "Train Epoch: 1474 [33792/54000 (63%)] Loss: -759.489136\n",
      "Train Epoch: 1474 [45056/54000 (83%)] Loss: -753.280762\n",
      "    epoch          : 1474\n",
      "    loss           : -771.2620855367409\n",
      "    ess            : 1.9587859533867746\n",
      "    log_marginal   : 771.3010351792822\n",
      "    log_joint      : 979.9385715700546\n",
      "    val_loss       : -775.3183898925781\n",
      "    val_ess        : 1.963391105333964\n",
      "    val_log_marginal: 775.3516082763672\n",
      "    val_log_joint  : 983.6036631266276\n",
      "Train Epoch: 1475 [0/54000 (0%)] Loss: -769.061035\n",
      "Train Epoch: 1475 [11264/54000 (21%)] Loss: -765.544739\n",
      "Train Epoch: 1475 [22528/54000 (42%)] Loss: -786.314819\n",
      "Train Epoch: 1475 [33792/54000 (63%)] Loss: -769.689331\n",
      "Train Epoch: 1475 [45056/54000 (83%)] Loss: -739.834595\n",
      "    epoch          : 1475\n",
      "    loss           : -771.2963487157282\n",
      "    ess            : 1.9597794132412605\n",
      "    log_marginal   : 771.3339279462706\n",
      "    log_joint      : 979.9465314757149\n",
      "    val_loss       : -775.3115793863932\n",
      "    val_ess        : 1.9606515268484752\n",
      "    val_log_marginal: 775.3462880452474\n",
      "    val_log_joint  : 983.8163350423177\n",
      "Train Epoch: 1476 [0/54000 (0%)] Loss: -764.569031\n",
      "Train Epoch: 1476 [11264/54000 (21%)] Loss: -782.055908\n",
      "Train Epoch: 1476 [22528/54000 (42%)] Loss: -773.927673\n",
      "Train Epoch: 1476 [33792/54000 (63%)] Loss: -751.555847\n",
      "Train Epoch: 1476 [45056/54000 (83%)] Loss: -783.385620\n",
      "    epoch          : 1476\n",
      "    loss           : -771.5621597002138\n",
      "    ess            : 1.9603214308900654\n",
      "    log_marginal   : 771.59981839162\n",
      "    log_joint      : 980.0439620107975\n",
      "    val_loss       : -775.5389302571615\n",
      "    val_ess        : 1.9594665865103404\n",
      "    val_log_marginal: 775.5779062906901\n",
      "    val_log_joint  : 984.2888895670573\n",
      "Train Epoch: 1477 [0/54000 (0%)] Loss: -794.415894\n",
      "Train Epoch: 1477 [11264/54000 (21%)] Loss: -775.473816\n",
      "Train Epoch: 1477 [22528/54000 (42%)] Loss: -770.410645\n",
      "Train Epoch: 1477 [33792/54000 (63%)] Loss: -743.499207\n",
      "Train Epoch: 1477 [45056/54000 (83%)] Loss: -799.175476\n",
      "    epoch          : 1477\n",
      "    loss           : -771.2338285626106\n",
      "    ess            : 1.9599142490692858\n",
      "    log_marginal   : 771.2711118302255\n",
      "    log_joint      : 979.8148688550266\n",
      "    val_loss       : -775.2890574137369\n",
      "    val_ess        : 1.9591427048047383\n",
      "    val_log_marginal: 775.3279622395834\n",
      "    val_log_joint  : 983.8108469645182\n",
      "Train Epoch: 1478 [0/54000 (0%)] Loss: -768.985901\n",
      "Train Epoch: 1478 [11264/54000 (21%)] Loss: -787.743408\n",
      "Train Epoch: 1478 [22528/54000 (42%)] Loss: -764.861267\n",
      "Train Epoch: 1478 [33792/54000 (63%)] Loss: -766.656921\n",
      "Train Epoch: 1478 [45056/54000 (83%)] Loss: -765.188721\n",
      "    epoch          : 1478\n",
      "    loss           : -771.1487184920401\n",
      "    ess            : 1.9605925454283661\n",
      "    log_marginal   : 771.1866426287957\n",
      "    log_joint      : 979.7992663113577\n",
      "    val_loss       : -775.1197408040365\n",
      "    val_ess        : 1.957455684741338\n",
      "    val_log_marginal: 775.1629791259766\n",
      "    val_log_joint  : 983.5784403483073\n",
      "Train Epoch: 1479 [0/54000 (0%)] Loss: -774.788208\n",
      "Train Epoch: 1479 [11264/54000 (21%)] Loss: -791.997803\n",
      "Train Epoch: 1479 [22528/54000 (42%)] Loss: -774.000488\n",
      "Train Epoch: 1479 [33792/54000 (63%)] Loss: -760.592529\n",
      "Train Epoch: 1479 [45056/54000 (83%)] Loss: -775.653931\n",
      "    epoch          : 1479\n",
      "    loss           : -771.4025424021595\n",
      "    ess            : 1.9593901375554643\n",
      "    log_marginal   : 771.4404020489387\n",
      "    log_joint      : 979.9470468197229\n",
      "    val_loss       : -775.3237355550131\n",
      "    val_ess        : 1.9589055975278218\n",
      "    val_log_marginal: 775.3624877929688\n",
      "    val_log_joint  : 984.05810546875\n",
      "Train Epoch: 1480 [0/54000 (0%)] Loss: -739.083496\n",
      "Train Epoch: 1480 [11264/54000 (21%)] Loss: -761.717224\n",
      "Train Epoch: 1480 [22528/54000 (42%)] Loss: -786.076050\n",
      "Train Epoch: 1480 [33792/54000 (63%)] Loss: -761.049561\n",
      "Train Epoch: 1480 [45056/54000 (83%)] Loss: -780.093018\n",
      "    epoch          : 1480\n",
      "    loss           : -771.2478303729363\n",
      "    ess            : 1.9605629106737532\n",
      "    log_marginal   : 771.2846719993735\n",
      "    log_joint      : 979.8206729529039\n",
      "    val_loss       : -775.5700632731119\n",
      "    val_ess        : 1.9593756993611653\n",
      "    val_log_marginal: 775.6103973388672\n",
      "    val_log_joint  : 983.8147684733073\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1480.pth ...\n",
      "Train Epoch: 1481 [0/54000 (0%)] Loss: -780.291443\n",
      "Train Epoch: 1481 [11264/54000 (21%)] Loss: -749.393982\n",
      "Train Epoch: 1481 [22528/54000 (42%)] Loss: -784.264587\n",
      "Train Epoch: 1481 [33792/54000 (63%)] Loss: -765.488892\n",
      "Train Epoch: 1481 [45056/54000 (83%)] Loss: -785.578247\n",
      "    epoch          : 1481\n",
      "    loss           : -771.4304521668632\n",
      "    ess            : 1.9604049178789247\n",
      "    log_marginal   : 771.4669678885982\n",
      "    log_joint      : 980.0030212402344\n",
      "    val_loss       : -774.8821004231771\n",
      "    val_ess        : 1.9611510932445526\n",
      "    val_log_marginal: 774.9188181559244\n",
      "    val_log_joint  : 983.381113688151\n",
      "Train Epoch: 1482 [0/54000 (0%)] Loss: -775.445740\n",
      "Train Epoch: 1482 [11264/54000 (21%)] Loss: -765.978027\n",
      "Train Epoch: 1482 [22528/54000 (42%)] Loss: -788.314026\n",
      "Train Epoch: 1482 [33792/54000 (63%)] Loss: -811.741394\n",
      "Train Epoch: 1482 [45056/54000 (83%)] Loss: -766.708496\n",
      "    epoch          : 1482\n",
      "    loss           : -771.3260970205631\n",
      "    ess            : 1.959782231528804\n",
      "    log_marginal   : 771.3633324964991\n",
      "    log_joint      : 979.9494387068838\n",
      "    val_loss       : -776.00341796875\n",
      "    val_ess        : 1.9587474564711254\n",
      "    val_log_marginal: 776.0432993570963\n",
      "    val_log_joint  : 984.4510498046875\n",
      "Train Epoch: 1483 [0/54000 (0%)] Loss: -781.345520\n",
      "Train Epoch: 1483 [11264/54000 (21%)] Loss: -782.156616\n",
      "Train Epoch: 1483 [22528/54000 (42%)] Loss: -788.306824\n",
      "Train Epoch: 1483 [33792/54000 (63%)] Loss: -776.280151\n",
      "Train Epoch: 1483 [45056/54000 (83%)] Loss: -776.975952\n",
      "    epoch          : 1483\n",
      "    loss           : -771.4573991883476\n",
      "    ess            : 1.9603579404219142\n",
      "    log_marginal   : 771.4947751603037\n",
      "    log_joint      : 980.034138229658\n",
      "    val_loss       : -775.928212483724\n",
      "    val_ess        : 1.960096001625061\n",
      "    val_log_marginal: 775.96728515625\n",
      "    val_log_joint  : 984.3799285888672\n",
      "Train Epoch: 1484 [0/54000 (0%)] Loss: -779.124023\n",
      "Train Epoch: 1484 [11264/54000 (21%)] Loss: -779.694031\n",
      "Train Epoch: 1484 [22528/54000 (42%)] Loss: -771.571533\n",
      "Train Epoch: 1484 [33792/54000 (63%)] Loss: -770.698792\n",
      "Train Epoch: 1484 [45056/54000 (83%)] Loss: -771.415039\n",
      "    epoch          : 1484\n",
      "    loss           : -771.342088807304\n",
      "    ess            : 1.961463083636086\n",
      "    log_marginal   : 771.3781220058225\n",
      "    log_joint      : 979.9378120854216\n",
      "    val_loss       : -775.3494059244791\n",
      "    val_ess        : 1.9574937224388123\n",
      "    val_log_marginal: 775.392100016276\n",
      "    val_log_joint  : 983.5784505208334\n",
      "Train Epoch: 1485 [0/54000 (0%)] Loss: -800.536011\n",
      "Train Epoch: 1485 [11264/54000 (21%)] Loss: -784.229126\n",
      "Train Epoch: 1485 [22528/54000 (42%)] Loss: -780.196045\n",
      "Train Epoch: 1485 [33792/54000 (63%)] Loss: -793.352783\n",
      "Train Epoch: 1485 [45056/54000 (83%)] Loss: -773.004028\n",
      "    epoch          : 1485\n",
      "    loss           : -771.4679271769974\n",
      "    ess            : 1.960444007279738\n",
      "    log_marginal   : 771.5050112166495\n",
      "    log_joint      : 980.0503689747936\n",
      "    val_loss       : -775.1872355143229\n",
      "    val_ess        : 1.9590593576431274\n",
      "    val_log_marginal: 775.2227579752604\n",
      "    val_log_joint  : 983.5584055582682\n",
      "Train Epoch: 1486 [0/54000 (0%)] Loss: -774.454041\n",
      "Train Epoch: 1486 [11264/54000 (21%)] Loss: -771.344116\n",
      "Train Epoch: 1486 [22528/54000 (42%)] Loss: -787.074707\n",
      "Train Epoch: 1486 [33792/54000 (63%)] Loss: -768.641479\n",
      "Train Epoch: 1486 [45056/54000 (83%)] Loss: -793.094238\n",
      "    epoch          : 1486\n",
      "    loss           : -771.3544323039505\n",
      "    ess            : 1.9596355489964754\n",
      "    log_marginal   : 771.3905702986807\n",
      "    log_joint      : 979.8926477972067\n",
      "    val_loss       : -775.6257578531901\n",
      "    val_ess        : 1.9606828888257344\n",
      "    val_log_marginal: 775.662607828776\n",
      "    val_log_joint  : 984.1575368245443\n",
      "Train Epoch: 1487 [0/54000 (0%)] Loss: -753.493469\n",
      "Train Epoch: 1487 [11264/54000 (21%)] Loss: -775.042480\n",
      "Train Epoch: 1487 [22528/54000 (42%)] Loss: -776.012939\n",
      "Train Epoch: 1487 [33792/54000 (63%)] Loss: -785.550293\n",
      "Train Epoch: 1487 [45056/54000 (83%)] Loss: -771.387085\n",
      "    epoch          : 1487\n",
      "    loss           : -771.3194643416495\n",
      "    ess            : 1.960528167913545\n",
      "    log_marginal   : 771.3556829488502\n",
      "    log_joint      : 979.996867629717\n",
      "    val_loss       : -775.3042958577474\n",
      "    val_ess        : 1.9612021644910176\n",
      "    val_log_marginal: 775.3382924397787\n",
      "    val_log_joint  : 983.7994639078776\n",
      "Train Epoch: 1488 [0/54000 (0%)] Loss: -748.702637\n",
      "Train Epoch: 1488 [11264/54000 (21%)] Loss: -768.471313\n",
      "Train Epoch: 1488 [22528/54000 (42%)] Loss: -749.159607\n",
      "Train Epoch: 1488 [33792/54000 (63%)] Loss: -757.685303\n",
      "Train Epoch: 1488 [45056/54000 (83%)] Loss: -766.759888\n",
      "    epoch          : 1488\n",
      "    loss           : -771.6149078944944\n",
      "    ess            : 1.9597752296699669\n",
      "    log_marginal   : 771.653564453125\n",
      "    log_joint      : 979.9871808897774\n",
      "    val_loss       : -775.1260732014974\n",
      "    val_ess        : 1.9575815399487813\n",
      "    val_log_marginal: 775.1652221679688\n",
      "    val_log_joint  : 983.6683705647787\n",
      "Train Epoch: 1489 [0/54000 (0%)] Loss: -797.572632\n",
      "Train Epoch: 1489 [11264/54000 (21%)] Loss: -792.974854\n",
      "Train Epoch: 1489 [22528/54000 (42%)] Loss: -758.490295\n",
      "Train Epoch: 1489 [33792/54000 (63%)] Loss: -760.862549\n",
      "Train Epoch: 1489 [45056/54000 (83%)] Loss: -781.047058\n",
      "    epoch          : 1489\n",
      "    loss           : -771.5377323942364\n",
      "    ess            : 1.9597324369088658\n",
      "    log_marginal   : 771.5763256144974\n",
      "    log_joint      : 980.0637241579452\n",
      "    val_loss       : -775.0917714436849\n",
      "    val_ess        : 1.9619793196519215\n",
      "    val_log_marginal: 775.1249440511068\n",
      "    val_log_joint  : 983.5042317708334\n",
      "Train Epoch: 1490 [0/54000 (0%)] Loss: -787.270813\n",
      "Train Epoch: 1490 [11264/54000 (21%)] Loss: -762.933350\n",
      "Train Epoch: 1490 [22528/54000 (42%)] Loss: -783.359619\n",
      "Train Epoch: 1490 [33792/54000 (63%)] Loss: -777.969849\n",
      "Train Epoch: 1490 [45056/54000 (83%)] Loss: -798.066956\n",
      "    epoch          : 1490\n",
      "    loss           : -771.3252264058815\n",
      "    ess            : 1.9603865146636963\n",
      "    log_marginal   : 771.3621129449808\n",
      "    log_joint      : 979.9620954405586\n",
      "    val_loss       : -774.9837697347006\n",
      "    val_ess        : 1.9636720418930054\n",
      "    val_log_marginal: 775.0196177164713\n",
      "    val_log_joint  : 983.7680206298828\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1490.pth ...\n",
      "Train Epoch: 1491 [0/54000 (0%)] Loss: -797.056274\n",
      "Train Epoch: 1491 [11264/54000 (21%)] Loss: -748.871948\n",
      "Train Epoch: 1491 [22528/54000 (42%)] Loss: -754.772217\n",
      "Train Epoch: 1491 [33792/54000 (63%)] Loss: -764.229553\n",
      "Train Epoch: 1491 [45056/54000 (83%)] Loss: -739.598267\n",
      "    epoch          : 1491\n",
      "    loss           : -771.4694018094045\n",
      "    ess            : 1.9619801044464111\n",
      "    log_marginal   : 771.5039644061394\n",
      "    log_joint      : 980.1378749631485\n",
      "    val_loss       : -775.4047292073568\n",
      "    val_ess        : 1.9603683650493622\n",
      "    val_log_marginal: 775.4430796305338\n",
      "    val_log_joint  : 983.9015452067057\n",
      "Train Epoch: 1492 [0/54000 (0%)] Loss: -768.283875\n",
      "Train Epoch: 1492 [11264/54000 (21%)] Loss: -763.731934\n",
      "Train Epoch: 1492 [22528/54000 (42%)] Loss: -775.615234\n",
      "Train Epoch: 1492 [33792/54000 (63%)] Loss: -769.672058\n",
      "Train Epoch: 1492 [45056/54000 (83%)] Loss: -762.909546\n",
      "    epoch          : 1492\n",
      "    loss           : -771.3419224001327\n",
      "    ess            : 1.960534376918145\n",
      "    log_marginal   : 771.3781231574293\n",
      "    log_joint      : 979.8903992850826\n",
      "    val_loss       : -775.2009124755859\n",
      "    val_ess        : 1.957428773244222\n",
      "    val_log_marginal: 775.2433522542318\n",
      "    val_log_joint  : 983.9370727539062\n",
      "Train Epoch: 1493 [0/54000 (0%)] Loss: -781.168457\n",
      "Train Epoch: 1493 [11264/54000 (21%)] Loss: -759.372314\n",
      "Train Epoch: 1493 [22528/54000 (42%)] Loss: -766.872070\n",
      "Train Epoch: 1493 [33792/54000 (63%)] Loss: -765.320068\n",
      "Train Epoch: 1493 [45056/54000 (83%)] Loss: -756.828735\n",
      "    epoch          : 1493\n",
      "    loss           : -771.5120740206736\n",
      "    ess            : 1.959686040878296\n",
      "    log_marginal   : 771.5503643683668\n",
      "    log_joint      : 980.0408647645195\n",
      "    val_loss       : -775.6342417399088\n",
      "    val_ess        : 1.9645821154117584\n",
      "    val_log_marginal: 775.6665598551432\n",
      "    val_log_joint  : 984.1964874267578\n",
      "Train Epoch: 1494 [0/54000 (0%)] Loss: -783.857971\n",
      "Train Epoch: 1494 [11264/54000 (21%)] Loss: -768.116516\n",
      "Train Epoch: 1494 [22528/54000 (42%)] Loss: -766.913330\n",
      "Train Epoch: 1494 [33792/54000 (63%)] Loss: -765.332092\n",
      "Train Epoch: 1494 [45056/54000 (83%)] Loss: -780.341431\n",
      "    epoch          : 1494\n",
      "    loss           : -771.3452419065079\n",
      "    ess            : 1.9604531773981058\n",
      "    log_marginal   : 771.3833669986365\n",
      "    log_joint      : 979.8583005509287\n",
      "    val_loss       : -775.2926381429037\n",
      "    val_ess        : 1.957997550566991\n",
      "    val_log_marginal: 775.3360544840494\n",
      "    val_log_joint  : 983.7733917236328\n",
      "Train Epoch: 1495 [0/54000 (0%)] Loss: -776.600342\n",
      "Train Epoch: 1495 [11264/54000 (21%)] Loss: -756.163086\n",
      "Train Epoch: 1495 [22528/54000 (42%)] Loss: -751.177795\n",
      "Train Epoch: 1495 [33792/54000 (63%)] Loss: -765.238403\n",
      "Train Epoch: 1495 [45056/54000 (83%)] Loss: -744.824951\n",
      "    epoch          : 1495\n",
      "    loss           : -771.604436334574\n",
      "    ess            : 1.9603553987898916\n",
      "    log_marginal   : 771.6409676029997\n",
      "    log_joint      : 980.0667200628317\n",
      "    val_loss       : -775.7671813964844\n",
      "    val_ess        : 1.9638059238592784\n",
      "    val_log_marginal: 775.8014882405599\n",
      "    val_log_joint  : 984.2259267171224\n",
      "Train Epoch: 1496 [0/54000 (0%)] Loss: -774.209106\n",
      "Train Epoch: 1496 [11264/54000 (21%)] Loss: -764.805359\n",
      "Train Epoch: 1496 [22528/54000 (42%)] Loss: -789.365173\n",
      "Train Epoch: 1496 [33792/54000 (63%)] Loss: -743.624146\n",
      "Train Epoch: 1496 [45056/54000 (83%)] Loss: -809.407471\n",
      "    epoch          : 1496\n",
      "    loss           : -771.5215091345445\n",
      "    ess            : 1.960812785715427\n",
      "    log_marginal   : 771.5583651560657\n",
      "    log_joint      : 980.0952010244694\n",
      "    val_loss       : -775.1101582845052\n",
      "    val_ess        : 1.961072673400243\n",
      "    val_log_marginal: 775.1460266113281\n",
      "    val_log_joint  : 984.0304107666016\n",
      "Train Epoch: 1497 [0/54000 (0%)] Loss: -789.949097\n",
      "Train Epoch: 1497 [11264/54000 (21%)] Loss: -767.651550\n",
      "Train Epoch: 1497 [22528/54000 (42%)] Loss: -774.068604\n",
      "Train Epoch: 1497 [33792/54000 (63%)] Loss: -764.337524\n",
      "Train Epoch: 1497 [45056/54000 (83%)] Loss: -787.183167\n",
      "    epoch          : 1497\n",
      "    loss           : -771.2754499327461\n",
      "    ess            : 1.9594698739501666\n",
      "    log_marginal   : 771.3139268407282\n",
      "    log_joint      : 979.8162565411262\n",
      "    val_loss       : -775.5254872639974\n",
      "    val_ess        : 1.9599885642528534\n",
      "    val_log_marginal: 775.5608723958334\n",
      "    val_log_joint  : 984.1773732503256\n",
      "Train Epoch: 1498 [0/54000 (0%)] Loss: -760.734558\n",
      "Train Epoch: 1498 [11264/54000 (21%)] Loss: -782.375671\n",
      "Train Epoch: 1498 [22528/54000 (42%)] Loss: -793.817749\n",
      "Train Epoch: 1498 [33792/54000 (63%)] Loss: -794.073975\n",
      "Train Epoch: 1498 [45056/54000 (83%)] Loss: -763.528564\n",
      "    epoch          : 1498\n",
      "    loss           : -771.4213412302845\n",
      "    ess            : 1.9599412983318545\n",
      "    log_marginal   : 771.4578788325472\n",
      "    log_joint      : 980.011209739829\n",
      "    val_loss       : -775.6383310953776\n",
      "    val_ess        : 1.959642469882965\n",
      "    val_log_marginal: 775.6747843424479\n",
      "    val_log_joint  : 984.0968373616537\n",
      "Train Epoch: 1499 [0/54000 (0%)] Loss: -786.341675\n",
      "Train Epoch: 1499 [11264/54000 (21%)] Loss: -742.542053\n",
      "Train Epoch: 1499 [22528/54000 (42%)] Loss: -776.640747\n",
      "Train Epoch: 1499 [33792/54000 (63%)] Loss: -780.218506\n",
      "Train Epoch: 1499 [45056/54000 (83%)] Loss: -774.661377\n",
      "    epoch          : 1499\n",
      "    loss           : -771.3442993164062\n",
      "    ess            : 1.961625116051368\n",
      "    log_marginal   : 771.380273782982\n",
      "    log_joint      : 979.8475992454672\n",
      "    val_loss       : -775.7561848958334\n",
      "    val_ess        : 1.9585615992546082\n",
      "    val_log_marginal: 775.7973225911459\n",
      "    val_log_joint  : 984.5624389648438\n",
      "Train Epoch: 1500 [0/54000 (0%)] Loss: -771.575073\n",
      "Train Epoch: 1500 [11264/54000 (21%)] Loss: -771.611572\n",
      "Train Epoch: 1500 [22528/54000 (42%)] Loss: -759.606445\n",
      "Train Epoch: 1500 [33792/54000 (63%)] Loss: -769.269226\n",
      "Train Epoch: 1500 [45056/54000 (83%)] Loss: -778.372375\n",
      "    epoch          : 1500\n",
      "    loss           : -771.3958072302477\n",
      "    ess            : 1.9599171933138146\n",
      "    log_marginal   : 771.4324029886498\n",
      "    log_joint      : 979.9188134535303\n",
      "    val_loss       : -775.6695404052734\n",
      "    val_ess        : 1.958334892988205\n",
      "    val_log_marginal: 775.7098337809244\n",
      "    val_log_joint  : 984.1471303304037\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1500.pth ...\n",
      "Train Epoch: 1501 [0/54000 (0%)] Loss: -764.408325\n",
      "Train Epoch: 1501 [11264/54000 (21%)] Loss: -800.685669\n",
      "Train Epoch: 1501 [22528/54000 (42%)] Loss: -779.464233\n",
      "Train Epoch: 1501 [33792/54000 (63%)] Loss: -759.246521\n",
      "Train Epoch: 1501 [45056/54000 (83%)] Loss: -778.971558\n",
      "    epoch          : 1501\n",
      "    loss           : -771.514706017836\n",
      "    ess            : 1.9615281944004994\n",
      "    log_marginal   : 771.550493924123\n",
      "    log_joint      : 980.0234645627579\n",
      "    val_loss       : -775.6753234863281\n",
      "    val_ess        : 1.9589691360791524\n",
      "    val_log_marginal: 775.7129669189453\n",
      "    val_log_joint  : 984.1122843424479\n",
      "Train Epoch: 1502 [0/54000 (0%)] Loss: -769.960388\n",
      "Train Epoch: 1502 [11264/54000 (21%)] Loss: -793.553223\n",
      "Train Epoch: 1502 [22528/54000 (42%)] Loss: -765.675293\n",
      "Train Epoch: 1502 [33792/54000 (63%)] Loss: -758.919922\n",
      "Train Epoch: 1502 [45056/54000 (83%)] Loss: -783.320190\n",
      "    epoch          : 1502\n",
      "    loss           : -771.5086053812279\n",
      "    ess            : 1.9609459717318696\n",
      "    log_marginal   : 771.5453485452904\n",
      "    log_joint      : 980.0704650878906\n",
      "    val_loss       : -775.3900400797526\n",
      "    val_ess        : 1.9577970306078594\n",
      "    val_log_marginal: 775.4287668863932\n",
      "    val_log_joint  : 983.9834340413412\n",
      "Train Epoch: 1503 [0/54000 (0%)] Loss: -750.696045\n",
      "Train Epoch: 1503 [11264/54000 (21%)] Loss: -773.814758\n",
      "Train Epoch: 1503 [22528/54000 (42%)] Loss: -772.814453\n",
      "Train Epoch: 1503 [33792/54000 (63%)] Loss: -775.123413\n",
      "Train Epoch: 1503 [45056/54000 (83%)] Loss: -767.914673\n",
      "    epoch          : 1503\n",
      "    loss           : -771.6141017697892\n",
      "    ess            : 1.9604499879873023\n",
      "    log_marginal   : 771.6512025077388\n",
      "    log_joint      : 980.1796379809109\n",
      "    val_loss       : -775.4179636637369\n",
      "    val_ess        : 1.960945725440979\n",
      "    val_log_marginal: 775.4495798746744\n",
      "    val_log_joint  : 984.1222127278646\n",
      "Train Epoch: 1504 [0/54000 (0%)] Loss: -766.414429\n",
      "Train Epoch: 1504 [11264/54000 (21%)] Loss: -758.580322\n",
      "Train Epoch: 1504 [22528/54000 (42%)] Loss: -761.896606\n",
      "Train Epoch: 1504 [33792/54000 (63%)] Loss: -767.047607\n",
      "Train Epoch: 1504 [45056/54000 (83%)] Loss: -781.154175\n",
      "    epoch          : 1504\n",
      "    loss           : -771.7719047114534\n",
      "    ess            : 1.960726356731271\n",
      "    log_marginal   : 771.8099653136055\n",
      "    log_joint      : 980.3274657051518\n",
      "    val_loss       : -775.6389312744141\n",
      "    val_ess        : 1.9630191624164581\n",
      "    val_log_marginal: 775.6741078694662\n",
      "    val_log_joint  : 984.3257293701172\n",
      "Train Epoch: 1505 [0/54000 (0%)] Loss: -758.992065\n",
      "Train Epoch: 1505 [11264/54000 (21%)] Loss: -793.743103\n",
      "Train Epoch: 1505 [22528/54000 (42%)] Loss: -777.080200\n",
      "Train Epoch: 1505 [33792/54000 (63%)] Loss: -780.647827\n",
      "Train Epoch: 1505 [45056/54000 (83%)] Loss: -759.010742\n",
      "    epoch          : 1505\n",
      "    loss           : -771.4303473706516\n",
      "    ess            : 1.9597614441277846\n",
      "    log_marginal   : 771.4690545999779\n",
      "    log_joint      : 980.0516472582547\n",
      "    val_loss       : -776.0989227294922\n",
      "    val_ess        : 1.9602119624614716\n",
      "    val_log_marginal: 776.1351420084635\n",
      "    val_log_joint  : 984.8182474772135\n",
      "Train Epoch: 1506 [0/54000 (0%)] Loss: -760.472900\n",
      "Train Epoch: 1506 [11264/54000 (21%)] Loss: -800.362793\n",
      "Train Epoch: 1506 [22528/54000 (42%)] Loss: -771.143921\n",
      "Train Epoch: 1506 [33792/54000 (63%)] Loss: -772.416260\n",
      "Train Epoch: 1506 [45056/54000 (83%)] Loss: -773.797729\n",
      "    epoch          : 1506\n",
      "    loss           : -771.6566018158535\n",
      "    ess            : 1.9594818713530056\n",
      "    log_marginal   : 771.6948725862323\n",
      "    log_joint      : 980.2704542627874\n",
      "    val_loss       : -776.0130513509115\n",
      "    val_ess        : 1.9605605105559032\n",
      "    val_log_marginal: 776.0489400227865\n",
      "    val_log_joint  : 984.6122538248698\n",
      "Train Epoch: 1507 [0/54000 (0%)] Loss: -770.333130\n",
      "Train Epoch: 1507 [11264/54000 (21%)] Loss: -797.513000\n",
      "Train Epoch: 1507 [22528/54000 (42%)] Loss: -773.443787\n",
      "Train Epoch: 1507 [33792/54000 (63%)] Loss: -777.136902\n",
      "Train Epoch: 1507 [45056/54000 (83%)] Loss: -768.395996\n",
      "    epoch          : 1507\n",
      "    loss           : -771.7816783977005\n",
      "    ess            : 1.960406873586043\n",
      "    log_marginal   : 771.8193399681235\n",
      "    log_joint      : 980.3836261101488\n",
      "    val_loss       : -775.8724517822266\n",
      "    val_ess        : 1.963234305381775\n",
      "    val_log_marginal: 775.9083353678385\n",
      "    val_log_joint  : 984.3157806396484\n",
      "Train Epoch: 1508 [0/54000 (0%)] Loss: -731.855408\n",
      "Train Epoch: 1508 [11264/54000 (21%)] Loss: -754.830322\n",
      "Train Epoch: 1508 [22528/54000 (42%)] Loss: -775.864807\n",
      "Train Epoch: 1508 [33792/54000 (63%)] Loss: -786.042725\n",
      "Train Epoch: 1508 [45056/54000 (83%)] Loss: -770.822021\n",
      "    epoch          : 1508\n",
      "    loss           : -771.9209450775722\n",
      "    ess            : 1.959048328534612\n",
      "    log_marginal   : 771.9596200619104\n",
      "    log_joint      : 980.4599091151975\n",
      "    val_loss       : -776.0276997884115\n",
      "    val_ess        : 1.955949326356252\n",
      "    val_log_marginal: 776.0706227620443\n",
      "    val_log_joint  : 984.5923614501953\n",
      "Train Epoch: 1509 [0/54000 (0%)] Loss: -784.788574\n",
      "Train Epoch: 1509 [11264/54000 (21%)] Loss: -802.972595\n",
      "Train Epoch: 1509 [22528/54000 (42%)] Loss: -802.910767\n",
      "Train Epoch: 1509 [33792/54000 (63%)] Loss: -776.961182\n",
      "Train Epoch: 1509 [45056/54000 (83%)] Loss: -786.756165\n",
      "    epoch          : 1509\n",
      "    loss           : -771.7579806345814\n",
      "    ess            : 1.9598637898013276\n",
      "    log_marginal   : 771.7962134019384\n",
      "    log_joint      : 980.354267048386\n",
      "    val_loss       : -775.6894836425781\n",
      "    val_ess        : 1.960261841615041\n",
      "    val_log_marginal: 775.7234039306641\n",
      "    val_log_joint  : 984.3779958089193\n",
      "Train Epoch: 1510 [0/54000 (0%)] Loss: -772.236816\n",
      "Train Epoch: 1510 [11264/54000 (21%)] Loss: -778.362671\n",
      "Train Epoch: 1510 [22528/54000 (42%)] Loss: -769.428040\n",
      "Train Epoch: 1510 [33792/54000 (63%)] Loss: -777.563538\n",
      "Train Epoch: 1510 [45056/54000 (83%)] Loss: -767.721313\n",
      "    epoch          : 1510\n",
      "    loss           : -771.806209924086\n",
      "    ess            : 1.9592514420455356\n",
      "    log_marginal   : 771.845349005933\n",
      "    log_joint      : 980.3277766389667\n",
      "    val_loss       : -775.9815877278646\n",
      "    val_ess        : 1.9565672874450684\n",
      "    val_log_marginal: 776.0221761067709\n",
      "    val_log_joint  : 984.6965382893881\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1510.pth ...\n",
      "Train Epoch: 1511 [0/54000 (0%)] Loss: -767.863159\n",
      "Train Epoch: 1511 [11264/54000 (21%)] Loss: -756.819336\n",
      "Train Epoch: 1511 [22528/54000 (42%)] Loss: -763.352356\n",
      "Train Epoch: 1511 [33792/54000 (63%)] Loss: -769.763306\n",
      "Train Epoch: 1511 [45056/54000 (83%)] Loss: -780.921265\n",
      "    epoch          : 1511\n",
      "    loss           : -771.8407794304613\n",
      "    ess            : 1.960925799495769\n",
      "    log_marginal   : 771.8781317944797\n",
      "    log_joint      : 980.4226431216833\n",
      "    val_loss       : -775.8177134195963\n",
      "    val_ess        : 1.9616956015427907\n",
      "    val_log_marginal: 775.8544158935547\n",
      "    val_log_joint  : 984.437733968099\n",
      "Train Epoch: 1512 [0/54000 (0%)] Loss: -768.884644\n",
      "Train Epoch: 1512 [11264/54000 (21%)] Loss: -767.817078\n",
      "Train Epoch: 1512 [22528/54000 (42%)] Loss: -766.265198\n",
      "Train Epoch: 1512 [33792/54000 (63%)] Loss: -781.611206\n",
      "Train Epoch: 1512 [45056/54000 (83%)] Loss: -758.711182\n",
      "    epoch          : 1512\n",
      "    loss           : -771.7318501022627\n",
      "    ess            : 1.960429828121977\n",
      "    log_marginal   : 771.7670927227668\n",
      "    log_joint      : 980.337588904039\n",
      "    val_loss       : -776.2534891764323\n",
      "    val_ess        : 1.958254834016164\n",
      "    val_log_marginal: 776.2955983479818\n",
      "    val_log_joint  : 985.0510864257812\n",
      "Train Epoch: 1513 [0/54000 (0%)] Loss: -768.703857\n",
      "Train Epoch: 1513 [11264/54000 (21%)] Loss: -767.035461\n",
      "Train Epoch: 1513 [22528/54000 (42%)] Loss: -769.166077\n",
      "Train Epoch: 1513 [33792/54000 (63%)] Loss: -779.279419\n",
      "Train Epoch: 1513 [45056/54000 (83%)] Loss: -784.468445\n",
      "    epoch          : 1513\n",
      "    loss           : -771.820395415684\n",
      "    ess            : 1.9599167131028086\n",
      "    log_marginal   : 771.8568518296728\n",
      "    log_joint      : 980.4248927854142\n",
      "    val_loss       : -776.1512451171875\n",
      "    val_ess        : 1.9589821497599285\n",
      "    val_log_marginal: 776.190673828125\n",
      "    val_log_joint  : 984.6590627034506\n",
      "Train Epoch: 1514 [0/54000 (0%)] Loss: -770.714722\n",
      "Train Epoch: 1514 [11264/54000 (21%)] Loss: -782.795776\n",
      "Train Epoch: 1514 [22528/54000 (42%)] Loss: -796.130737\n",
      "Train Epoch: 1514 [33792/54000 (63%)] Loss: -771.297119\n",
      "Train Epoch: 1514 [45056/54000 (83%)] Loss: -799.680115\n",
      "    epoch          : 1514\n",
      "    loss           : -771.8460543650501\n",
      "    ess            : 1.9597502474514943\n",
      "    log_marginal   : 771.8827860130453\n",
      "    log_joint      : 980.404842736586\n",
      "    val_loss       : -776.7011057535807\n",
      "    val_ess        : 1.9630503753821056\n",
      "    val_log_marginal: 776.7334442138672\n",
      "    val_log_joint  : 985.2225646972656\n",
      "Train Epoch: 1515 [0/54000 (0%)] Loss: -738.935852\n",
      "Train Epoch: 1515 [11264/54000 (21%)] Loss: -778.570435\n",
      "Train Epoch: 1515 [22528/54000 (42%)] Loss: -758.591003\n",
      "Train Epoch: 1515 [33792/54000 (63%)] Loss: -764.020325\n",
      "Train Epoch: 1515 [45056/54000 (83%)] Loss: -744.351562\n",
      "    epoch          : 1515\n",
      "    loss           : -771.8940683040979\n",
      "    ess            : 1.9601180103589904\n",
      "    log_marginal   : 771.9328319621536\n",
      "    log_joint      : 980.3937193672612\n",
      "    val_loss       : -776.470703125\n",
      "    val_ess        : 1.9579683542251587\n",
      "    val_log_marginal: 776.5075632731119\n",
      "    val_log_joint  : 984.9355061848959\n",
      "Train Epoch: 1516 [0/54000 (0%)] Loss: -771.437439\n",
      "Train Epoch: 1516 [11264/54000 (21%)] Loss: -766.064331\n",
      "Train Epoch: 1516 [22528/54000 (42%)] Loss: -761.768188\n",
      "Train Epoch: 1516 [33792/54000 (63%)] Loss: -757.030151\n",
      "Train Epoch: 1516 [45056/54000 (83%)] Loss: -769.597473\n",
      "    epoch          : 1516\n",
      "    loss           : -771.8789989543411\n",
      "    ess            : 1.9607386105465439\n",
      "    log_marginal   : 771.9159171626253\n",
      "    log_joint      : 980.4754385318396\n",
      "    val_loss       : -776.3751271565756\n",
      "    val_ess        : 1.959339400132497\n",
      "    val_log_marginal: 776.4196726481119\n",
      "    val_log_joint  : 984.7883809407552\n",
      "Train Epoch: 1517 [0/54000 (0%)] Loss: -766.503235\n",
      "Train Epoch: 1517 [11264/54000 (21%)] Loss: -778.375488\n",
      "Train Epoch: 1517 [22528/54000 (42%)] Loss: -782.078796\n",
      "Train Epoch: 1517 [33792/54000 (63%)] Loss: -780.723145\n",
      "Train Epoch: 1517 [45056/54000 (83%)] Loss: -745.195923\n",
      "    epoch          : 1517\n",
      "    loss           : -772.0055069833431\n",
      "    ess            : 1.9614880231191527\n",
      "    log_marginal   : 772.0410455667748\n",
      "    log_joint      : 980.5005239810583\n",
      "    val_loss       : -775.8047027587891\n",
      "    val_ess        : 1.9594272275765736\n",
      "    val_log_marginal: 775.8399607340494\n",
      "    val_log_joint  : 984.5362497965494\n",
      "Train Epoch: 1518 [0/54000 (0%)] Loss: -775.902466\n",
      "Train Epoch: 1518 [11264/54000 (21%)] Loss: -784.280701\n",
      "Train Epoch: 1518 [22528/54000 (42%)] Loss: -779.963623\n",
      "Train Epoch: 1518 [33792/54000 (63%)] Loss: -769.634766\n",
      "Train Epoch: 1518 [45056/54000 (83%)] Loss: -791.003662\n",
      "    epoch          : 1518\n",
      "    loss           : -771.9122717515478\n",
      "    ess            : 1.9613065348481231\n",
      "    log_marginal   : 771.9489861254422\n",
      "    log_joint      : 980.487979529039\n",
      "    val_loss       : -776.2563781738281\n",
      "    val_ess        : 1.9599511921405792\n",
      "    val_log_marginal: 776.2950490315756\n",
      "    val_log_joint  : 984.6391296386719\n",
      "Train Epoch: 1519 [0/54000 (0%)] Loss: -783.730835\n",
      "Train Epoch: 1519 [11264/54000 (21%)] Loss: -751.464722\n",
      "Train Epoch: 1519 [22528/54000 (42%)] Loss: -792.901001\n",
      "Train Epoch: 1519 [33792/54000 (63%)] Loss: -772.155640\n",
      "Train Epoch: 1519 [45056/54000 (83%)] Loss: -784.399780\n",
      "    epoch          : 1519\n",
      "    loss           : -771.8183064010908\n",
      "    ess            : 1.9607163487740282\n",
      "    log_marginal   : 771.8544605183151\n",
      "    log_joint      : 980.4435516933225\n",
      "    val_loss       : -775.9469960530599\n",
      "    val_ess        : 1.9581728875637054\n",
      "    val_log_marginal: 775.9870554606119\n",
      "    val_log_joint  : 984.5123647054037\n",
      "Train Epoch: 1520 [0/54000 (0%)] Loss: -814.806396\n",
      "Train Epoch: 1520 [11264/54000 (21%)] Loss: -765.306885\n",
      "Train Epoch: 1520 [22528/54000 (42%)] Loss: -778.265747\n",
      "Train Epoch: 1520 [33792/54000 (63%)] Loss: -760.690674\n",
      "Train Epoch: 1520 [45056/54000 (83%)] Loss: -786.169434\n",
      "    epoch          : 1520\n",
      "    loss           : -772.0107704018646\n",
      "    ess            : 1.9602925485035159\n",
      "    log_marginal   : 772.0487400270858\n",
      "    log_joint      : 980.5225812804024\n",
      "    val_loss       : -776.0424550374349\n",
      "    val_ess        : 1.9633089900016785\n",
      "    val_log_marginal: 776.0763753255209\n",
      "    val_log_joint  : 984.6732533772787\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1520.pth ...\n",
      "Train Epoch: 1521 [0/54000 (0%)] Loss: -791.162964\n",
      "Train Epoch: 1521 [11264/54000 (21%)] Loss: -766.293213\n",
      "Train Epoch: 1521 [22528/54000 (42%)] Loss: -751.128296\n",
      "Train Epoch: 1521 [33792/54000 (63%)] Loss: -788.417725\n",
      "Train Epoch: 1521 [45056/54000 (83%)] Loss: -787.960571\n",
      "    epoch          : 1521\n",
      "    loss           : -771.8568927117113\n",
      "    ess            : 1.959633839580248\n",
      "    log_marginal   : 771.8952976442733\n",
      "    log_joint      : 980.4380746517542\n",
      "    val_loss       : -776.6035919189453\n",
      "    val_ess        : 1.9614762862523396\n",
      "    val_log_marginal: 776.6392262776693\n",
      "    val_log_joint  : 985.1514892578125\n",
      "Train Epoch: 1522 [0/54000 (0%)] Loss: -781.462891\n",
      "Train Epoch: 1522 [11264/54000 (21%)] Loss: -772.017822\n",
      "Train Epoch: 1522 [22528/54000 (42%)] Loss: -777.601013\n",
      "Train Epoch: 1522 [33792/54000 (63%)] Loss: -764.955505\n",
      "Train Epoch: 1522 [45056/54000 (83%)] Loss: -766.347595\n",
      "    epoch          : 1522\n",
      "    loss           : -772.0709752496683\n",
      "    ess            : 1.958892489379307\n",
      "    log_marginal   : 772.1107039541569\n",
      "    log_joint      : 980.5658552061836\n",
      "    val_loss       : -776.420908610026\n",
      "    val_ess        : 1.961539735396703\n",
      "    val_log_marginal: 776.4558919270834\n",
      "    val_log_joint  : 985.1910756429037\n",
      "Train Epoch: 1523 [0/54000 (0%)] Loss: -788.663147\n",
      "Train Epoch: 1523 [11264/54000 (21%)] Loss: -765.210571\n",
      "Train Epoch: 1523 [22528/54000 (42%)] Loss: -788.987610\n",
      "Train Epoch: 1523 [33792/54000 (63%)] Loss: -780.707214\n",
      "Train Epoch: 1523 [45056/54000 (83%)] Loss: -760.505371\n",
      "    epoch          : 1523\n",
      "    loss           : -772.1171166761866\n",
      "    ess            : 1.9611446879944712\n",
      "    log_marginal   : 772.1542030190521\n",
      "    log_joint      : 980.669412864829\n",
      "    val_loss       : -776.1675974527994\n",
      "    val_ess        : 1.9635698397954304\n",
      "    val_log_marginal: 776.1986083984375\n",
      "    val_log_joint  : 984.5602874755859\n",
      "Train Epoch: 1524 [0/54000 (0%)] Loss: -781.445923\n",
      "Train Epoch: 1524 [11264/54000 (21%)] Loss: -776.566711\n",
      "Train Epoch: 1524 [22528/54000 (42%)] Loss: -799.982422\n",
      "Train Epoch: 1524 [33792/54000 (63%)] Loss: -774.469360\n",
      "Train Epoch: 1524 [45056/54000 (83%)] Loss: -763.008057\n",
      "    epoch          : 1524\n",
      "    loss           : -772.0688200176887\n",
      "    ess            : 1.9597624619052094\n",
      "    log_marginal   : 772.1056800698334\n",
      "    log_joint      : 980.6820413841391\n",
      "    val_loss       : -776.9021962483724\n",
      "    val_ess        : 1.9618599116802216\n",
      "    val_log_marginal: 776.9344431559244\n",
      "    val_log_joint  : 985.1536712646484\n",
      "Train Epoch: 1525 [0/54000 (0%)] Loss: -799.602295\n",
      "Train Epoch: 1525 [11264/54000 (21%)] Loss: -751.263184\n",
      "Train Epoch: 1525 [22528/54000 (42%)] Loss: -765.378296\n",
      "Train Epoch: 1525 [33792/54000 (63%)] Loss: -751.389160\n",
      "Train Epoch: 1525 [45056/54000 (83%)] Loss: -786.340515\n",
      "    epoch          : 1525\n",
      "    loss           : -771.9321196933962\n",
      "    ess            : 1.9598198611781281\n",
      "    log_marginal   : 771.9697150464328\n",
      "    log_joint      : 980.533389685289\n",
      "    val_loss       : -777.2761586507162\n",
      "    val_ess        : 1.962389051914215\n",
      "    val_log_marginal: 777.3100535074869\n",
      "    val_log_joint  : 985.945322672526\n",
      "Train Epoch: 1526 [0/54000 (0%)] Loss: -779.873901\n",
      "Train Epoch: 1526 [11264/54000 (21%)] Loss: -784.144165\n",
      "Train Epoch: 1526 [22528/54000 (42%)] Loss: -757.265320\n",
      "Train Epoch: 1526 [33792/54000 (63%)] Loss: -773.451050\n",
      "Train Epoch: 1526 [45056/54000 (83%)] Loss: -766.303101\n",
      "    epoch          : 1526\n",
      "    loss           : -772.0891188135687\n",
      "    ess            : 1.9607144639177143\n",
      "    log_marginal   : 772.126172911446\n",
      "    log_joint      : 980.667279513377\n",
      "    val_loss       : -775.8226979573568\n",
      "    val_ess        : 1.9579390784104664\n",
      "    val_log_marginal: 775.864013671875\n",
      "    val_log_joint  : 984.6379140218099\n",
      "Train Epoch: 1527 [0/54000 (0%)] Loss: -775.005249\n",
      "Train Epoch: 1527 [11264/54000 (21%)] Loss: -755.461060\n",
      "Train Epoch: 1527 [22528/54000 (42%)] Loss: -789.066162\n",
      "Train Epoch: 1527 [33792/54000 (63%)] Loss: -804.333923\n",
      "Train Epoch: 1527 [45056/54000 (83%)] Loss: -777.574707\n",
      "    epoch          : 1527\n",
      "    loss           : -772.3767061053582\n",
      "    ess            : 1.9605767873098265\n",
      "    log_marginal   : 772.413944460311\n",
      "    log_joint      : 980.8145331616672\n",
      "    val_loss       : -776.9526112874349\n",
      "    val_ess        : 1.958357334136963\n",
      "    val_log_marginal: 776.9926300048828\n",
      "    val_log_joint  : 985.8465881347656\n",
      "Train Epoch: 1528 [0/54000 (0%)] Loss: -770.197266\n",
      "Train Epoch: 1528 [11264/54000 (21%)] Loss: -789.090698\n",
      "Train Epoch: 1528 [22528/54000 (42%)] Loss: -777.264404\n",
      "Train Epoch: 1528 [33792/54000 (63%)] Loss: -783.752686\n",
      "Train Epoch: 1528 [45056/54000 (83%)] Loss: -780.644897\n",
      "    epoch          : 1528\n",
      "    loss           : -771.9805545447008\n",
      "    ess            : 1.9597399752095062\n",
      "    log_marginal   : 772.0183928867556\n",
      "    log_joint      : 980.6279446583874\n",
      "    val_loss       : -777.8378346761068\n",
      "    val_ess        : 1.9597211281458538\n",
      "    val_log_marginal: 777.8764495849609\n",
      "    val_log_joint  : 986.3052775065104\n",
      "Train Epoch: 1529 [0/54000 (0%)] Loss: -777.145508\n",
      "Train Epoch: 1529 [11264/54000 (21%)] Loss: -787.831421\n",
      "Train Epoch: 1529 [22528/54000 (42%)] Loss: -777.316589\n",
      "Train Epoch: 1529 [33792/54000 (63%)] Loss: -775.332275\n",
      "Train Epoch: 1529 [45056/54000 (83%)] Loss: -780.264038\n",
      "    epoch          : 1529\n",
      "    loss           : -772.1646999143204\n",
      "    ess            : 1.958539218272803\n",
      "    log_marginal   : 772.2050833072302\n",
      "    log_joint      : 980.713552798865\n",
      "    val_loss       : -777.0509847005209\n",
      "    val_ess        : 1.9619849522908528\n",
      "    val_log_marginal: 777.0865681966146\n",
      "    val_log_joint  : 985.4169769287109\n",
      "Train Epoch: 1530 [0/54000 (0%)] Loss: -775.587524\n",
      "Train Epoch: 1530 [11264/54000 (21%)] Loss: -779.480530\n",
      "Train Epoch: 1530 [22528/54000 (42%)] Loss: -765.509705\n",
      "Train Epoch: 1530 [33792/54000 (63%)] Loss: -790.892395\n",
      "Train Epoch: 1530 [45056/54000 (83%)] Loss: -771.227661\n",
      "    epoch          : 1530\n",
      "    loss           : -772.3062467755012\n",
      "    ess            : 1.960500918469339\n",
      "    log_marginal   : 772.3441363640551\n",
      "    log_joint      : 980.8388585504496\n",
      "    val_loss       : -776.8287862141927\n",
      "    val_ess        : 1.9622969230016072\n",
      "    val_log_marginal: 776.8623555501302\n",
      "    val_log_joint  : 985.3074951171875\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1530.pth ...\n",
      "Train Epoch: 1531 [0/54000 (0%)] Loss: -787.757202\n",
      "Train Epoch: 1531 [11264/54000 (21%)] Loss: -754.351440\n",
      "Train Epoch: 1531 [22528/54000 (42%)] Loss: -793.443176\n",
      "Train Epoch: 1531 [33792/54000 (63%)] Loss: -766.814697\n",
      "Train Epoch: 1531 [45056/54000 (83%)] Loss: -796.013306\n",
      "    epoch          : 1531\n",
      "    loss           : -772.1989648207178\n",
      "    ess            : 1.9613703376841995\n",
      "    log_marginal   : 772.236907383181\n",
      "    log_joint      : 980.7471699264814\n",
      "    val_loss       : -776.9689788818359\n",
      "    val_ess        : 1.9590358038743336\n",
      "    val_log_marginal: 777.0107218424479\n",
      "    val_log_joint  : 985.4765167236328\n",
      "Train Epoch: 1532 [0/54000 (0%)] Loss: -776.492798\n",
      "Train Epoch: 1532 [11264/54000 (21%)] Loss: -772.968933\n",
      "Train Epoch: 1532 [22528/54000 (42%)] Loss: -761.829834\n",
      "Train Epoch: 1532 [33792/54000 (63%)] Loss: -754.498901\n",
      "Train Epoch: 1532 [45056/54000 (83%)] Loss: -782.036316\n",
      "    epoch          : 1532\n",
      "    loss           : -772.1755526560657\n",
      "    ess            : 1.9605667748541202\n",
      "    log_marginal   : 772.2132902325325\n",
      "    log_joint      : 980.7333828908093\n",
      "    val_loss       : -777.0447540283203\n",
      "    val_ess        : 1.9602165718873341\n",
      "    val_log_marginal: 777.0826365152994\n",
      "    val_log_joint  : 985.6958669026693\n",
      "Train Epoch: 1533 [0/54000 (0%)] Loss: -766.097290\n",
      "Train Epoch: 1533 [11264/54000 (21%)] Loss: -757.609863\n",
      "Train Epoch: 1533 [22528/54000 (42%)] Loss: -772.494507\n",
      "Train Epoch: 1533 [33792/54000 (63%)] Loss: -757.936279\n",
      "Train Epoch: 1533 [45056/54000 (83%)] Loss: -769.743042\n",
      "    epoch          : 1533\n",
      "    loss           : -772.1405766325177\n",
      "    ess            : 1.9607872906720862\n",
      "    log_marginal   : 772.1770157724056\n",
      "    log_joint      : 980.7257546478847\n",
      "    val_loss       : -776.2746073404948\n",
      "    val_ess        : 1.956004838148753\n",
      "    val_log_marginal: 776.320566813151\n",
      "    val_log_joint  : 984.8220469156901\n",
      "Train Epoch: 1534 [0/54000 (0%)] Loss: -786.461304\n",
      "Train Epoch: 1534 [11264/54000 (21%)] Loss: -772.850037\n",
      "Train Epoch: 1534 [22528/54000 (42%)] Loss: -772.729858\n",
      "Train Epoch: 1534 [33792/54000 (63%)] Loss: -775.651062\n",
      "Train Epoch: 1534 [45056/54000 (83%)] Loss: -802.727051\n",
      "    epoch          : 1534\n",
      "    loss           : -772.2199948868662\n",
      "    ess            : 1.960108479238906\n",
      "    log_marginal   : 772.2558921957916\n",
      "    log_joint      : 980.8012286492113\n",
      "    val_loss       : -775.7606455485026\n",
      "    val_ess        : 1.9578771591186523\n",
      "    val_log_marginal: 775.8069356282552\n",
      "    val_log_joint  : 984.2530314127604\n",
      "Train Epoch: 1535 [0/54000 (0%)] Loss: -750.993591\n",
      "Train Epoch: 1535 [11264/54000 (21%)] Loss: -767.196777\n",
      "Train Epoch: 1535 [22528/54000 (42%)] Loss: -760.290039\n",
      "Train Epoch: 1535 [33792/54000 (63%)] Loss: -784.157349\n",
      "Train Epoch: 1535 [45056/54000 (83%)] Loss: -771.286255\n",
      "    epoch          : 1535\n",
      "    loss           : -772.1108697855248\n",
      "    ess            : 1.9617151989127106\n",
      "    log_marginal   : 772.1458216253317\n",
      "    log_joint      : 980.6595648999485\n",
      "    val_loss       : -776.7664337158203\n",
      "    val_ess        : 1.9593836963176727\n",
      "    val_log_marginal: 776.8076222737631\n",
      "    val_log_joint  : 985.3348185221354\n",
      "Train Epoch: 1536 [0/54000 (0%)] Loss: -771.464600\n",
      "Train Epoch: 1536 [11264/54000 (21%)] Loss: -764.608337\n",
      "Train Epoch: 1536 [22528/54000 (42%)] Loss: -745.170410\n",
      "Train Epoch: 1536 [33792/54000 (63%)] Loss: -773.430969\n",
      "Train Epoch: 1536 [45056/54000 (83%)] Loss: -774.710449\n",
      "    epoch          : 1536\n",
      "    loss           : -772.2867063126474\n",
      "    ess            : 1.959617961127803\n",
      "    log_marginal   : 772.3247669147995\n",
      "    log_joint      : 980.7616525326135\n",
      "    val_loss       : -776.183095296224\n",
      "    val_ess        : 1.9612678786118825\n",
      "    val_log_marginal: 776.217519124349\n",
      "    val_log_joint  : 984.6385904947916\n",
      "Train Epoch: 1537 [0/54000 (0%)] Loss: -783.296082\n",
      "Train Epoch: 1537 [11264/54000 (21%)] Loss: -759.812744\n",
      "Train Epoch: 1537 [22528/54000 (42%)] Loss: -755.287292\n",
      "Train Epoch: 1537 [33792/54000 (63%)] Loss: -750.461487\n",
      "Train Epoch: 1537 [45056/54000 (83%)] Loss: -782.513367\n",
      "    epoch          : 1537\n",
      "    loss           : -772.2182991459684\n",
      "    ess            : 1.9605045183649603\n",
      "    log_marginal   : 772.2548407788547\n",
      "    log_joint      : 980.7799832326061\n",
      "    val_loss       : -776.5031077067057\n",
      "    val_ess        : 1.9602999190489452\n",
      "    val_log_marginal: 776.5434214274088\n",
      "    val_log_joint  : 985.0472361246744\n",
      "Train Epoch: 1538 [0/54000 (0%)] Loss: -779.968872\n",
      "Train Epoch: 1538 [11264/54000 (21%)] Loss: -750.508362\n",
      "Train Epoch: 1538 [22528/54000 (42%)] Loss: -770.843689\n",
      "Train Epoch: 1538 [33792/54000 (63%)] Loss: -779.472534\n",
      "Train Epoch: 1538 [45056/54000 (83%)] Loss: -754.941895\n",
      "    epoch          : 1538\n",
      "    loss           : -772.2400057810657\n",
      "    ess            : 1.960625556280028\n",
      "    log_marginal   : 772.2782730966244\n",
      "    log_joint      : 980.7560833625074\n",
      "    val_loss       : -776.2216796875\n",
      "    val_ess        : 1.9591212073961894\n",
      "    val_log_marginal: 776.2579447428385\n",
      "    val_log_joint  : 985.0217234293619\n",
      "Train Epoch: 1539 [0/54000 (0%)] Loss: -769.665527\n",
      "Train Epoch: 1539 [11264/54000 (21%)] Loss: -781.311035\n",
      "Train Epoch: 1539 [22528/54000 (42%)] Loss: -775.748169\n",
      "Train Epoch: 1539 [33792/54000 (63%)] Loss: -752.640442\n",
      "Train Epoch: 1539 [45056/54000 (83%)] Loss: -781.735901\n",
      "    epoch          : 1539\n",
      "    loss           : -772.2185668945312\n",
      "    ess            : 1.9606486930037446\n",
      "    log_marginal   : 772.2550520986881\n",
      "    log_joint      : 980.7937172943691\n",
      "    val_loss       : -776.5514424641927\n",
      "    val_ess        : 1.9606780608495076\n",
      "    val_log_marginal: 776.5888366699219\n",
      "    val_log_joint  : 985.0187683105469\n",
      "Train Epoch: 1540 [0/54000 (0%)] Loss: -792.478821\n",
      "Train Epoch: 1540 [11264/54000 (21%)] Loss: -793.124756\n",
      "Train Epoch: 1540 [22528/54000 (42%)] Loss: -774.604431\n",
      "Train Epoch: 1540 [33792/54000 (63%)] Loss: -771.834106\n",
      "Train Epoch: 1540 [45056/54000 (83%)] Loss: -764.586670\n",
      "    epoch          : 1540\n",
      "    loss           : -772.2789496655735\n",
      "    ess            : 1.9604903751949094\n",
      "    log_marginal   : 772.3163843694723\n",
      "    log_joint      : 980.7793648197966\n",
      "    val_loss       : -776.2000071207682\n",
      "    val_ess        : 1.9587417145570118\n",
      "    val_log_marginal: 776.2367248535156\n",
      "    val_log_joint  : 984.8430023193359\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1540.pth ...\n",
      "Train Epoch: 1541 [0/54000 (0%)] Loss: -774.010376\n",
      "Train Epoch: 1541 [11264/54000 (21%)] Loss: -773.154663\n",
      "Train Epoch: 1541 [22528/54000 (42%)] Loss: -762.645386\n",
      "Train Epoch: 1541 [33792/54000 (63%)] Loss: -793.862427\n",
      "Train Epoch: 1541 [45056/54000 (83%)] Loss: -771.919189\n",
      "    epoch          : 1541\n",
      "    loss           : -772.0450001842571\n",
      "    ess            : 1.960171716393165\n",
      "    log_marginal   : 772.0820571611513\n",
      "    log_joint      : 980.6447155070755\n",
      "    val_loss       : -776.7857157389323\n",
      "    val_ess        : 1.9620175957679749\n",
      "    val_log_marginal: 776.8154551188151\n",
      "    val_log_joint  : 985.4749450683594\n",
      "Train Epoch: 1542 [0/54000 (0%)] Loss: -795.198059\n",
      "Train Epoch: 1542 [11264/54000 (21%)] Loss: -770.295227\n",
      "Train Epoch: 1542 [22528/54000 (42%)] Loss: -767.681091\n",
      "Train Epoch: 1542 [33792/54000 (63%)] Loss: -758.388672\n",
      "Train Epoch: 1542 [45056/54000 (83%)] Loss: -758.398132\n",
      "    epoch          : 1542\n",
      "    loss           : -772.0026291181456\n",
      "    ess            : 1.960082306052154\n",
      "    log_marginal   : 772.0397943460716\n",
      "    log_joint      : 980.5921976341391\n",
      "    val_loss       : -776.7376556396484\n",
      "    val_ess        : 1.9625552793343861\n",
      "    val_log_marginal: 776.7747650146484\n",
      "    val_log_joint  : 985.4013366699219\n",
      "Train Epoch: 1543 [0/54000 (0%)] Loss: -786.670654\n",
      "Train Epoch: 1543 [11264/54000 (21%)] Loss: -788.259888\n",
      "Train Epoch: 1543 [22528/54000 (42%)] Loss: -774.443604\n",
      "Train Epoch: 1543 [33792/54000 (63%)] Loss: -761.879150\n",
      "Train Epoch: 1543 [45056/54000 (83%)] Loss: -785.915466\n",
      "    epoch          : 1543\n",
      "    loss           : -772.2407209288399\n",
      "    ess            : 1.960543322113325\n",
      "    log_marginal   : 772.278870780513\n",
      "    log_joint      : 980.793227285709\n",
      "    val_loss       : -776.7404429117838\n",
      "    val_ess        : 1.9632947146892548\n",
      "    val_log_marginal: 776.7741394042969\n",
      "    val_log_joint  : 985.3544362386068\n",
      "Train Epoch: 1544 [0/54000 (0%)] Loss: -777.111450\n",
      "Train Epoch: 1544 [11264/54000 (21%)] Loss: -759.676819\n",
      "Train Epoch: 1544 [22528/54000 (42%)] Loss: -773.351440\n",
      "Train Epoch: 1544 [33792/54000 (63%)] Loss: -762.536377\n",
      "Train Epoch: 1544 [45056/54000 (83%)] Loss: -766.814453\n",
      "    epoch          : 1544\n",
      "    loss           : -772.2444296782871\n",
      "    ess            : 1.9616492795494367\n",
      "    log_marginal   : 772.2795254689343\n",
      "    log_joint      : 980.7728380887014\n",
      "    val_loss       : -777.0905710856119\n",
      "    val_ess        : 1.9601596891880035\n",
      "    val_log_marginal: 777.1279856363932\n",
      "    val_log_joint  : 985.7388509114584\n",
      "Train Epoch: 1545 [0/54000 (0%)] Loss: -772.814331\n",
      "Train Epoch: 1545 [11264/54000 (21%)] Loss: -776.432861\n",
      "Train Epoch: 1545 [22528/54000 (42%)] Loss: -790.295776\n",
      "Train Epoch: 1545 [33792/54000 (63%)] Loss: -741.166138\n",
      "Train Epoch: 1545 [45056/54000 (83%)] Loss: -755.805908\n",
      "    epoch          : 1545\n",
      "    loss           : -772.1155977069207\n",
      "    ess            : 1.9609036996679485\n",
      "    log_marginal   : 772.1525539182267\n",
      "    log_joint      : 980.6924812748747\n",
      "    val_loss       : -776.7703450520834\n",
      "    val_ess        : 1.9614347616831462\n",
      "    val_log_marginal: 776.8035939534506\n",
      "    val_log_joint  : 985.3171641031901\n",
      "Train Epoch: 1546 [0/54000 (0%)] Loss: -762.330139\n",
      "Train Epoch: 1546 [11264/54000 (21%)] Loss: -777.932739\n",
      "Train Epoch: 1546 [22528/54000 (42%)] Loss: -779.213074\n",
      "Train Epoch: 1546 [33792/54000 (63%)] Loss: -782.959473\n",
      "Train Epoch: 1546 [45056/54000 (83%)] Loss: -789.916992\n",
      "    epoch          : 1546\n",
      "    loss           : -772.0378918917673\n",
      "    ess            : 1.9603780822933845\n",
      "    log_marginal   : 772.0751371563606\n",
      "    log_joint      : 980.5744479197376\n",
      "    val_loss       : -776.7186737060547\n",
      "    val_ess        : 1.9625134865442913\n",
      "    val_log_marginal: 776.7521006266276\n",
      "    val_log_joint  : 985.1244099934896\n",
      "Train Epoch: 1547 [0/54000 (0%)] Loss: -745.786804\n",
      "Train Epoch: 1547 [11264/54000 (21%)] Loss: -788.517578\n",
      "Train Epoch: 1547 [22528/54000 (42%)] Loss: -777.633728\n",
      "Train Epoch: 1547 [33792/54000 (63%)] Loss: -771.444885\n",
      "Train Epoch: 1547 [45056/54000 (83%)] Loss: -788.179749\n",
      "    epoch          : 1547\n",
      "    loss           : -772.0903930664062\n",
      "    ess            : 1.9599047213230494\n",
      "    log_marginal   : 772.1284778522995\n",
      "    log_joint      : 980.621735194944\n",
      "    val_loss       : -775.9190419514974\n",
      "    val_ess        : 1.9597219228744507\n",
      "    val_log_marginal: 775.9634552001953\n",
      "    val_log_joint  : 984.5212453206381\n",
      "Train Epoch: 1548 [0/54000 (0%)] Loss: -775.123901\n",
      "Train Epoch: 1548 [11264/54000 (21%)] Loss: -765.343079\n",
      "Train Epoch: 1548 [22528/54000 (42%)] Loss: -752.743774\n",
      "Train Epoch: 1548 [33792/54000 (63%)] Loss: -764.798889\n",
      "Train Epoch: 1548 [45056/54000 (83%)] Loss: -787.202637\n",
      "    epoch          : 1548\n",
      "    loss           : -772.0299250764667\n",
      "    ess            : 1.9599654708268508\n",
      "    log_marginal   : 772.067159400796\n",
      "    log_joint      : 980.5852499907871\n",
      "    val_loss       : -776.6268971761068\n",
      "    val_ess        : 1.95808145403862\n",
      "    val_log_marginal: 776.6661376953125\n",
      "    val_log_joint  : 985.2271525065104\n",
      "Train Epoch: 1549 [0/54000 (0%)] Loss: -772.352905\n",
      "Train Epoch: 1549 [11264/54000 (21%)] Loss: -786.243652\n",
      "Train Epoch: 1549 [22528/54000 (42%)] Loss: -773.097290\n",
      "Train Epoch: 1549 [33792/54000 (63%)] Loss: -777.581238\n",
      "Train Epoch: 1549 [45056/54000 (83%)] Loss: -760.270264\n",
      "    epoch          : 1549\n",
      "    loss           : -772.1151606721698\n",
      "    ess            : 1.9594491202876252\n",
      "    log_marginal   : 772.1534752036041\n",
      "    log_joint      : 980.7167364156471\n",
      "    val_loss       : -776.1195119222006\n",
      "    val_ess        : 1.9591566026210785\n",
      "    val_log_marginal: 776.1597442626953\n",
      "    val_log_joint  : 984.7877095540365\n",
      "Train Epoch: 1550 [0/54000 (0%)] Loss: -768.329468\n",
      "Train Epoch: 1550 [11264/54000 (21%)] Loss: -787.963257\n",
      "Train Epoch: 1550 [22528/54000 (42%)] Loss: -754.768799\n",
      "Train Epoch: 1550 [33792/54000 (63%)] Loss: -775.773254\n",
      "Train Epoch: 1550 [45056/54000 (83%)] Loss: -767.590576\n",
      "    epoch          : 1550\n",
      "    loss           : -772.1800272239828\n",
      "    ess            : 1.9596722294699471\n",
      "    log_marginal   : 772.2183682423718\n",
      "    log_joint      : 980.8088436486586\n",
      "    val_loss       : -776.8975016276041\n",
      "    val_ess        : 1.9617443879445393\n",
      "    val_log_marginal: 776.9332631429037\n",
      "    val_log_joint  : 985.1247762044271\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1550.pth ...\n",
      "Train Epoch: 1551 [0/54000 (0%)] Loss: -768.236145\n",
      "Train Epoch: 1551 [11264/54000 (21%)] Loss: -754.161743\n",
      "Train Epoch: 1551 [22528/54000 (42%)] Loss: -757.045227\n",
      "Train Epoch: 1551 [33792/54000 (63%)] Loss: -762.916809\n",
      "Train Epoch: 1551 [45056/54000 (83%)] Loss: -781.157532\n",
      "    epoch          : 1551\n",
      "    loss           : -772.0828247070312\n",
      "    ess            : 1.9601278901100159\n",
      "    log_marginal   : 772.1218526588297\n",
      "    log_joint      : 980.6357467939268\n",
      "    val_loss       : -776.6956583658854\n",
      "    val_ess        : 1.962560623884201\n",
      "    val_log_marginal: 776.7305704752604\n",
      "    val_log_joint  : 985.3363037109375\n",
      "Train Epoch: 1552 [0/54000 (0%)] Loss: -802.289856\n",
      "Train Epoch: 1552 [11264/54000 (21%)] Loss: -767.043152\n",
      "Train Epoch: 1552 [22528/54000 (42%)] Loss: -769.325439\n",
      "Train Epoch: 1552 [33792/54000 (63%)] Loss: -780.813232\n",
      "Train Epoch: 1552 [45056/54000 (83%)] Loss: -771.140747\n",
      "    epoch          : 1552\n",
      "    loss           : -772.2299718316996\n",
      "    ess            : 1.9588913760095272\n",
      "    log_marginal   : 772.2677479869915\n",
      "    log_joint      : 980.8402278108417\n",
      "    val_loss       : -777.2630869547526\n",
      "    val_ess        : 1.9581400056680043\n",
      "    val_log_marginal: 777.3060099283854\n",
      "    val_log_joint  : 985.5755208333334\n",
      "Train Epoch: 1553 [0/54000 (0%)] Loss: -773.788879\n",
      "Train Epoch: 1553 [11264/54000 (21%)] Loss: -783.451965\n",
      "Train Epoch: 1553 [22528/54000 (42%)] Loss: -771.829041\n",
      "Train Epoch: 1553 [33792/54000 (63%)] Loss: -759.985107\n",
      "Train Epoch: 1553 [45056/54000 (83%)] Loss: -774.365723\n",
      "    epoch          : 1553\n",
      "    loss           : -772.2440778624336\n",
      "    ess            : 1.9591586870967217\n",
      "    log_marginal   : 772.2836701015257\n",
      "    log_joint      : 980.8279516831884\n",
      "    val_loss       : -777.0157165527344\n",
      "    val_ess        : 1.9645985960960388\n",
      "    val_log_marginal: 777.0466766357422\n",
      "    val_log_joint  : 985.2687835693359\n",
      "Train Epoch: 1554 [0/54000 (0%)] Loss: -757.016357\n",
      "Train Epoch: 1554 [11264/54000 (21%)] Loss: -755.115234\n",
      "Train Epoch: 1554 [22528/54000 (42%)] Loss: -766.767029\n",
      "Train Epoch: 1554 [33792/54000 (63%)] Loss: -764.554077\n",
      "Train Epoch: 1554 [45056/54000 (83%)] Loss: -764.025696\n",
      "    epoch          : 1554\n",
      "    loss           : -772.0890704460863\n",
      "    ess            : 1.9613882865545884\n",
      "    log_marginal   : 772.1244892624189\n",
      "    log_joint      : 980.6932563061985\n",
      "    val_loss       : -776.3735504150391\n",
      "    val_ess        : 1.960587739944458\n",
      "    val_log_marginal: 776.4092610677084\n",
      "    val_log_joint  : 984.9777577718099\n",
      "Train Epoch: 1555 [0/54000 (0%)] Loss: -756.947571\n",
      "Train Epoch: 1555 [11264/54000 (21%)] Loss: -748.120300\n",
      "Train Epoch: 1555 [22528/54000 (42%)] Loss: -762.974731\n",
      "Train Epoch: 1555 [33792/54000 (63%)] Loss: -749.036316\n",
      "Train Epoch: 1555 [45056/54000 (83%)] Loss: -777.183228\n",
      "    epoch          : 1555\n",
      "    loss           : -772.3945439176739\n",
      "    ess            : 1.9600299270647876\n",
      "    log_marginal   : 772.432497420401\n",
      "    log_joint      : 980.9269806484007\n",
      "    val_loss       : -776.1722056070963\n",
      "    val_ess        : 1.959067314863205\n",
      "    val_log_marginal: 776.2104949951172\n",
      "    val_log_joint  : 984.8747863769531\n",
      "Train Epoch: 1556 [0/54000 (0%)] Loss: -770.599182\n",
      "Train Epoch: 1556 [11264/54000 (21%)] Loss: -781.756470\n",
      "Train Epoch: 1556 [22528/54000 (42%)] Loss: -801.380859\n",
      "Train Epoch: 1556 [33792/54000 (63%)] Loss: -767.637878\n",
      "Train Epoch: 1556 [45056/54000 (83%)] Loss: -776.999878\n",
      "    epoch          : 1556\n",
      "    loss           : -772.3140178176592\n",
      "    ess            : 1.9591829068255875\n",
      "    log_marginal   : 772.3528010530292\n",
      "    log_joint      : 980.8237661685583\n",
      "    val_loss       : -775.8359985351562\n",
      "    val_ess        : 1.9590951402982075\n",
      "    val_log_marginal: 775.8740183512369\n",
      "    val_log_joint  : 984.3343454996744\n",
      "Train Epoch: 1557 [0/54000 (0%)] Loss: -753.377441\n",
      "Train Epoch: 1557 [11264/54000 (21%)] Loss: -766.089905\n",
      "Train Epoch: 1557 [22528/54000 (42%)] Loss: -765.849792\n",
      "Train Epoch: 1557 [33792/54000 (63%)] Loss: -782.411621\n",
      "Train Epoch: 1557 [45056/54000 (83%)] Loss: -766.242920\n",
      "    epoch          : 1557\n",
      "    loss           : -772.3018798828125\n",
      "    ess            : 1.9602649785437674\n",
      "    log_marginal   : 772.3391522101637\n",
      "    log_joint      : 980.8424360167305\n",
      "    val_loss       : -776.8428751627604\n",
      "    val_ess        : 1.9587103227774303\n",
      "    val_log_marginal: 776.8876444498698\n",
      "    val_log_joint  : 985.5619099934896\n",
      "Train Epoch: 1558 [0/54000 (0%)] Loss: -764.046265\n",
      "Train Epoch: 1558 [11264/54000 (21%)] Loss: -768.729126\n",
      "Train Epoch: 1558 [22528/54000 (42%)] Loss: -744.835693\n",
      "Train Epoch: 1558 [33792/54000 (63%)] Loss: -774.155640\n",
      "Train Epoch: 1558 [45056/54000 (83%)] Loss: -810.981812\n",
      "    epoch          : 1558\n",
      "    loss           : -772.3781093381485\n",
      "    ess            : 1.9610635773190912\n",
      "    log_marginal   : 772.413859817217\n",
      "    log_joint      : 980.9825779177108\n",
      "    val_loss       : -777.3536783854166\n",
      "    val_ess        : 1.961642901102702\n",
      "    val_log_marginal: 777.3911285400391\n",
      "    val_log_joint  : 985.7955627441406\n",
      "Train Epoch: 1559 [0/54000 (0%)] Loss: -768.643433\n",
      "Train Epoch: 1559 [11264/54000 (21%)] Loss: -788.347229\n",
      "Train Epoch: 1559 [22528/54000 (42%)] Loss: -756.372253\n",
      "Train Epoch: 1559 [33792/54000 (63%)] Loss: -787.645630\n",
      "Train Epoch: 1559 [45056/54000 (83%)] Loss: -766.970581\n",
      "    epoch          : 1559\n",
      "    loss           : -772.4254444050339\n",
      "    ess            : 1.9599044210505936\n",
      "    log_marginal   : 772.4633293871609\n",
      "    log_joint      : 980.9928548560953\n",
      "    val_loss       : -776.0363464355469\n",
      "    val_ess        : 1.958830992380778\n",
      "    val_log_marginal: 776.0780181884766\n",
      "    val_log_joint  : 985.1229298909506\n",
      "Train Epoch: 1560 [0/54000 (0%)] Loss: -762.851990\n",
      "Train Epoch: 1560 [11264/54000 (21%)] Loss: -774.577393\n",
      "Train Epoch: 1560 [22528/54000 (42%)] Loss: -801.672363\n",
      "Train Epoch: 1560 [33792/54000 (63%)] Loss: -765.561646\n",
      "Train Epoch: 1560 [45056/54000 (83%)] Loss: -766.436707\n",
      "    epoch          : 1560\n",
      "    loss           : -772.5345309275501\n",
      "    ess            : 1.9599628853348066\n",
      "    log_marginal   : 772.5714520148512\n",
      "    log_joint      : 981.1410315171728\n",
      "    val_loss       : -777.0634155273438\n",
      "    val_ess        : 1.9584290484587352\n",
      "    val_log_marginal: 777.1017506917318\n",
      "    val_log_joint  : 985.4535624186198\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1560.pth ...\n",
      "Train Epoch: 1561 [0/54000 (0%)] Loss: -783.635254\n",
      "Train Epoch: 1561 [11264/54000 (21%)] Loss: -788.484070\n",
      "Train Epoch: 1561 [22528/54000 (42%)] Loss: -761.210205\n",
      "Train Epoch: 1561 [33792/54000 (63%)] Loss: -769.803223\n",
      "Train Epoch: 1561 [45056/54000 (83%)] Loss: -771.338806\n",
      "    epoch          : 1561\n",
      "    loss           : -772.4278881144974\n",
      "    ess            : 1.9597596110038038\n",
      "    log_marginal   : 772.4673738299675\n",
      "    log_joint      : 980.9178104040758\n",
      "    val_loss       : -776.8901621500651\n",
      "    val_ess        : 1.960283527771632\n",
      "    val_log_marginal: 776.9313151041666\n",
      "    val_log_joint  : 985.2286020914713\n",
      "Train Epoch: 1562 [0/54000 (0%)] Loss: -767.747864\n",
      "Train Epoch: 1562 [11264/54000 (21%)] Loss: -789.649170\n",
      "Train Epoch: 1562 [22528/54000 (42%)] Loss: -770.251770\n",
      "Train Epoch: 1562 [33792/54000 (63%)] Loss: -772.323303\n",
      "Train Epoch: 1562 [45056/54000 (83%)] Loss: -774.995361\n",
      "    epoch          : 1562\n",
      "    loss           : -772.4632101958653\n",
      "    ess            : 1.9609362921624813\n",
      "    log_marginal   : 772.499329764888\n",
      "    log_joint      : 981.0163090543927\n",
      "    val_loss       : -776.5956115722656\n",
      "    val_ess        : 1.9575185179710388\n",
      "    val_log_marginal: 776.6374206542969\n",
      "    val_log_joint  : 985.4626515706381\n",
      "Train Epoch: 1563 [0/54000 (0%)] Loss: -751.365601\n",
      "Train Epoch: 1563 [11264/54000 (21%)] Loss: -746.319275\n",
      "Train Epoch: 1563 [22528/54000 (42%)] Loss: -758.459229\n",
      "Train Epoch: 1563 [33792/54000 (63%)] Loss: -749.818237\n",
      "Train Epoch: 1563 [45056/54000 (83%)] Loss: -786.503784\n",
      "    epoch          : 1563\n",
      "    loss           : -772.4226085734817\n",
      "    ess            : 1.9595536049806848\n",
      "    log_marginal   : 772.4599148732311\n",
      "    log_joint      : 981.013127740824\n",
      "    val_loss       : -776.9577891031901\n",
      "    val_ess        : 1.961348791917165\n",
      "    val_log_marginal: 776.9972127278646\n",
      "    val_log_joint  : 985.3889567057291\n",
      "Train Epoch: 1564 [0/54000 (0%)] Loss: -770.145996\n",
      "Train Epoch: 1564 [11264/54000 (21%)] Loss: -781.456177\n",
      "Train Epoch: 1564 [22528/54000 (42%)] Loss: -772.045166\n",
      "Train Epoch: 1564 [33792/54000 (63%)] Loss: -767.801636\n",
      "Train Epoch: 1564 [45056/54000 (83%)] Loss: -749.271729\n",
      "    epoch          : 1564\n",
      "    loss           : -772.4472535331295\n",
      "    ess            : 1.9605780187642798\n",
      "    log_marginal   : 772.4845523474352\n",
      "    log_joint      : 980.9499690217792\n",
      "    val_loss       : -776.6396077473959\n",
      "    val_ess        : 1.9574306507905324\n",
      "    val_log_marginal: 776.6779530843099\n",
      "    val_log_joint  : 985.2001241048177\n",
      "Train Epoch: 1565 [0/54000 (0%)] Loss: -767.762329\n",
      "Train Epoch: 1565 [11264/54000 (21%)] Loss: -767.704956\n",
      "Train Epoch: 1565 [22528/54000 (42%)] Loss: -775.439514\n",
      "Train Epoch: 1565 [33792/54000 (63%)] Loss: -784.636963\n",
      "Train Epoch: 1565 [45056/54000 (83%)] Loss: -771.637451\n",
      "    epoch          : 1565\n",
      "    loss           : -772.486001068691\n",
      "    ess            : 1.9607791169634405\n",
      "    log_marginal   : 772.5232158157061\n",
      "    log_joint      : 981.0230787745062\n",
      "    val_loss       : -776.9787343343099\n",
      "    val_ess        : 1.9611037969589233\n",
      "    val_log_marginal: 777.0165252685547\n",
      "    val_log_joint  : 985.7691090901693\n",
      "Train Epoch: 1566 [0/54000 (0%)] Loss: -798.812073\n",
      "Train Epoch: 1566 [11264/54000 (21%)] Loss: -781.226196\n",
      "Train Epoch: 1566 [22528/54000 (42%)] Loss: -778.557556\n",
      "Train Epoch: 1566 [33792/54000 (63%)] Loss: -780.079590\n",
      "Train Epoch: 1566 [45056/54000 (83%)] Loss: -788.959595\n",
      "    epoch          : 1566\n",
      "    loss           : -772.4458405116819\n",
      "    ess            : 1.9601751667148661\n",
      "    log_marginal   : 772.4830852004717\n",
      "    log_joint      : 981.0881215221477\n",
      "    val_loss       : -776.639638264974\n",
      "    val_ess        : 1.9655704498291016\n",
      "    val_log_marginal: 776.6672058105469\n",
      "    val_log_joint  : 984.9855804443359\n",
      "Train Epoch: 1567 [0/54000 (0%)] Loss: -788.914673\n",
      "Train Epoch: 1567 [11264/54000 (21%)] Loss: -769.728638\n",
      "Train Epoch: 1567 [22528/54000 (42%)] Loss: -788.671875\n",
      "Train Epoch: 1567 [33792/54000 (63%)] Loss: -769.310791\n",
      "Train Epoch: 1567 [45056/54000 (83%)] Loss: -762.538208\n",
      "    epoch          : 1567\n",
      "    loss           : -772.4825255196049\n",
      "    ess            : 1.9599869352466655\n",
      "    log_marginal   : 772.5203321924749\n",
      "    log_joint      : 981.0533533636129\n",
      "    val_loss       : -776.0608876546224\n",
      "    val_ess        : 1.9621235926946003\n",
      "    val_log_marginal: 776.0968475341797\n",
      "    val_log_joint  : 984.8810170491537\n",
      "Train Epoch: 1568 [0/54000 (0%)] Loss: -789.590210\n",
      "Train Epoch: 1568 [11264/54000 (21%)] Loss: -764.310120\n",
      "Train Epoch: 1568 [22528/54000 (42%)] Loss: -772.124390\n",
      "Train Epoch: 1568 [33792/54000 (63%)] Loss: -778.257385\n",
      "Train Epoch: 1568 [45056/54000 (83%)] Loss: -784.209534\n",
      "    epoch          : 1568\n",
      "    loss           : -772.4841055240271\n",
      "    ess            : 1.9604293287925\n",
      "    log_marginal   : 772.5214170060068\n",
      "    log_joint      : 981.1051940917969\n",
      "    val_loss       : -776.9818216959635\n",
      "    val_ess        : 1.9617464542388916\n",
      "    val_log_marginal: 777.0190989176432\n",
      "    val_log_joint  : 985.5583902994791\n",
      "Train Epoch: 1569 [0/54000 (0%)] Loss: -783.524841\n",
      "Train Epoch: 1569 [11264/54000 (21%)] Loss: -785.350891\n",
      "Train Epoch: 1569 [22528/54000 (42%)] Loss: -781.060913\n",
      "Train Epoch: 1569 [33792/54000 (63%)] Loss: -778.300293\n",
      "Train Epoch: 1569 [45056/54000 (83%)] Loss: -776.584473\n",
      "    epoch          : 1569\n",
      "    loss           : -772.6089212669516\n",
      "    ess            : 1.9603201364571194\n",
      "    log_marginal   : 772.6480367408609\n",
      "    log_joint      : 981.2519698232975\n",
      "    val_loss       : -776.9200337727865\n",
      "    val_ess        : 1.959805856148402\n",
      "    val_log_marginal: 776.9586741129557\n",
      "    val_log_joint  : 985.5408528645834\n",
      "Train Epoch: 1570 [0/54000 (0%)] Loss: -777.196899\n",
      "Train Epoch: 1570 [11264/54000 (21%)] Loss: -777.551147\n",
      "Train Epoch: 1570 [22528/54000 (42%)] Loss: -765.258545\n",
      "Train Epoch: 1570 [33792/54000 (63%)] Loss: -771.040527\n",
      "Train Epoch: 1570 [45056/54000 (83%)] Loss: -752.317139\n",
      "    epoch          : 1570\n",
      "    loss           : -772.6280995494915\n",
      "    ess            : 1.9599081907632216\n",
      "    log_marginal   : 772.6660323232975\n",
      "    log_joint      : 981.1518479833063\n",
      "    val_loss       : -776.5854797363281\n",
      "    val_ess        : 1.961440900961558\n",
      "    val_log_marginal: 776.6175842285156\n",
      "    val_log_joint  : 985.5508829752604\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1570.pth ...\n",
      "Train Epoch: 1571 [0/54000 (0%)] Loss: -786.748779\n",
      "Train Epoch: 1571 [11264/54000 (21%)] Loss: -779.992798\n",
      "Train Epoch: 1571 [22528/54000 (42%)] Loss: -785.294922\n",
      "Train Epoch: 1571 [33792/54000 (63%)] Loss: -787.216309\n",
      "Train Epoch: 1571 [45056/54000 (83%)] Loss: -785.026001\n",
      "    epoch          : 1571\n",
      "    loss           : -772.5577438642393\n",
      "    ess            : 1.9600964773376033\n",
      "    log_marginal   : 772.5957480376621\n",
      "    log_joint      : 981.0638018913988\n",
      "    val_loss       : -777.1659342447916\n",
      "    val_ess        : 1.964372495810191\n",
      "    val_log_marginal: 777.2012176513672\n",
      "    val_log_joint  : 985.8003082275391\n",
      "Train Epoch: 1572 [0/54000 (0%)] Loss: -763.131348\n",
      "Train Epoch: 1572 [11264/54000 (21%)] Loss: -773.645752\n",
      "Train Epoch: 1572 [22528/54000 (42%)] Loss: -781.389893\n",
      "Train Epoch: 1572 [33792/54000 (63%)] Loss: -764.537048\n",
      "Train Epoch: 1572 [45056/54000 (83%)] Loss: -748.361572\n",
      "    epoch          : 1572\n",
      "    loss           : -772.6197003058668\n",
      "    ess            : 1.9612165093421936\n",
      "    log_marginal   : 772.6560415591833\n",
      "    log_joint      : 981.1668931493219\n",
      "    val_loss       : -777.0800832112631\n",
      "    val_ess        : 1.96234526236852\n",
      "    val_log_marginal: 777.117421468099\n",
      "    val_log_joint  : 985.5237731933594\n",
      "Train Epoch: 1573 [0/54000 (0%)] Loss: -768.273804\n",
      "Train Epoch: 1573 [11264/54000 (21%)] Loss: -789.332336\n",
      "Train Epoch: 1573 [22528/54000 (42%)] Loss: -770.625000\n",
      "Train Epoch: 1573 [33792/54000 (63%)] Loss: -786.229858\n",
      "Train Epoch: 1573 [45056/54000 (83%)] Loss: -777.195129\n",
      "    epoch          : 1573\n",
      "    loss           : -772.5249271032945\n",
      "    ess            : 1.95871165675937\n",
      "    log_marginal   : 772.5649022516214\n",
      "    log_joint      : 981.086585278781\n",
      "    val_loss       : -776.4715423583984\n",
      "    val_ess        : 1.957740326722463\n",
      "    val_log_marginal: 776.5171101888021\n",
      "    val_log_joint  : 985.3393147786459\n",
      "Train Epoch: 1574 [0/54000 (0%)] Loss: -801.585632\n",
      "Train Epoch: 1574 [11264/54000 (21%)] Loss: -768.887817\n",
      "Train Epoch: 1574 [22528/54000 (42%)] Loss: -769.247314\n",
      "Train Epoch: 1574 [33792/54000 (63%)] Loss: -778.761536\n",
      "Train Epoch: 1574 [45056/54000 (83%)] Loss: -772.864624\n",
      "    epoch          : 1574\n",
      "    loss           : -772.5429203825177\n",
      "    ess            : 1.960724394276457\n",
      "    log_marginal   : 772.5797712218086\n",
      "    log_joint      : 981.0964712466833\n",
      "    val_loss       : -776.5429128011068\n",
      "    val_ess        : 1.957553098599116\n",
      "    val_log_marginal: 776.5841318766276\n",
      "    val_log_joint  : 985.2046712239584\n",
      "Train Epoch: 1575 [0/54000 (0%)] Loss: -761.521240\n",
      "Train Epoch: 1575 [11264/54000 (21%)] Loss: -779.197632\n",
      "Train Epoch: 1575 [22528/54000 (42%)] Loss: -766.512939\n",
      "Train Epoch: 1575 [33792/54000 (63%)] Loss: -772.844299\n",
      "Train Epoch: 1575 [45056/54000 (83%)] Loss: -773.276855\n",
      "    epoch          : 1575\n",
      "    loss           : -772.6269830667748\n",
      "    ess            : 1.959361215807357\n",
      "    log_marginal   : 772.6652319566259\n",
      "    log_joint      : 981.2739712697155\n",
      "    val_loss       : -776.9761505126953\n",
      "    val_ess        : 1.9623661041259766\n",
      "    val_log_marginal: 777.0105031331381\n",
      "    val_log_joint  : 985.2991383870443\n",
      "Train Epoch: 1576 [0/54000 (0%)] Loss: -780.193542\n",
      "Train Epoch: 1576 [11264/54000 (21%)] Loss: -753.033691\n",
      "Train Epoch: 1576 [22528/54000 (42%)] Loss: -777.956909\n",
      "Train Epoch: 1576 [33792/54000 (63%)] Loss: -753.971924\n",
      "Train Epoch: 1576 [45056/54000 (83%)] Loss: -784.056030\n",
      "    epoch          : 1576\n",
      "    loss           : -772.6270164633697\n",
      "    ess            : 1.9587087113902253\n",
      "    log_marginal   : 772.6686671994767\n",
      "    log_joint      : 981.2285910552403\n",
      "    val_loss       : -777.0395151774088\n",
      "    val_ess        : 1.963094304005305\n",
      "    val_log_marginal: 777.0702362060547\n",
      "    val_log_joint  : 985.4310048421224\n",
      "Train Epoch: 1577 [0/54000 (0%)] Loss: -790.906433\n",
      "Train Epoch: 1577 [11264/54000 (21%)] Loss: -796.923462\n",
      "Train Epoch: 1577 [22528/54000 (42%)] Loss: -774.959717\n",
      "Train Epoch: 1577 [33792/54000 (63%)] Loss: -773.385864\n",
      "Train Epoch: 1577 [45056/54000 (83%)] Loss: -777.466003\n",
      "    epoch          : 1577\n",
      "    loss           : -772.6997536713222\n",
      "    ess            : 1.9603227781799604\n",
      "    log_marginal   : 772.7375948923939\n",
      "    log_joint      : 981.306249654518\n",
      "    val_loss       : -776.2743988037109\n",
      "    val_ess        : 1.9635532995065053\n",
      "    val_log_marginal: 776.3096059163412\n",
      "    val_log_joint  : 984.8457489013672\n",
      "Train Epoch: 1578 [0/54000 (0%)] Loss: -795.248657\n",
      "Train Epoch: 1578 [11264/54000 (21%)] Loss: -774.876404\n",
      "Train Epoch: 1578 [22528/54000 (42%)] Loss: -786.551575\n",
      "Train Epoch: 1578 [33792/54000 (63%)] Loss: -766.647156\n",
      "Train Epoch: 1578 [45056/54000 (83%)] Loss: -758.495911\n",
      "    epoch          : 1578\n",
      "    loss           : -772.8655919488871\n",
      "    ess            : 1.9611679023166873\n",
      "    log_marginal   : 772.9024289688974\n",
      "    log_joint      : 981.5001474056604\n",
      "    val_loss       : -776.625\n",
      "    val_ess        : 1.959005703528722\n",
      "    val_log_marginal: 776.6613159179688\n",
      "    val_log_joint  : 985.1691385904948\n",
      "Train Epoch: 1579 [0/54000 (0%)] Loss: -797.060608\n",
      "Train Epoch: 1579 [11264/54000 (21%)] Loss: -793.223083\n",
      "Train Epoch: 1579 [22528/54000 (42%)] Loss: -786.626770\n",
      "Train Epoch: 1579 [33792/54000 (63%)] Loss: -792.383789\n",
      "Train Epoch: 1579 [45056/54000 (83%)] Loss: -770.139221\n",
      "    epoch          : 1579\n",
      "    loss           : -772.8077404094192\n",
      "    ess            : 1.9600023334881045\n",
      "    log_marginal   : 772.8456651219782\n",
      "    log_joint      : 981.3383863916937\n",
      "    val_loss       : -776.9766184488932\n",
      "    val_ess        : 1.9611633121967316\n",
      "    val_log_marginal: 777.0118967692057\n",
      "    val_log_joint  : 985.2358601888021\n",
      "Train Epoch: 1580 [0/54000 (0%)] Loss: -769.713684\n",
      "Train Epoch: 1580 [11264/54000 (21%)] Loss: -790.446533\n",
      "Train Epoch: 1580 [22528/54000 (42%)] Loss: -779.019775\n",
      "Train Epoch: 1580 [33792/54000 (63%)] Loss: -770.036987\n",
      "Train Epoch: 1580 [45056/54000 (83%)] Loss: -779.775146\n",
      "    epoch          : 1580\n",
      "    loss           : -772.9004729648806\n",
      "    ess            : 1.9602391146263987\n",
      "    log_marginal   : 772.937353170143\n",
      "    log_joint      : 981.421908396595\n",
      "    val_loss       : -776.6815083821615\n",
      "    val_ess        : 1.9611673553784688\n",
      "    val_log_marginal: 776.7233734130859\n",
      "    val_log_joint  : 985.1662190755209\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1580.pth ...\n",
      "Train Epoch: 1581 [0/54000 (0%)] Loss: -749.858032\n",
      "Train Epoch: 1581 [11264/54000 (21%)] Loss: -752.380859\n",
      "Train Epoch: 1581 [22528/54000 (42%)] Loss: -779.959045\n",
      "Train Epoch: 1581 [33792/54000 (63%)] Loss: -788.429321\n",
      "Train Epoch: 1581 [45056/54000 (83%)] Loss: -759.601074\n",
      "    epoch          : 1581\n",
      "    loss           : -773.0680294396742\n",
      "    ess            : 1.9597304857002114\n",
      "    log_marginal   : 773.1061977170548\n",
      "    log_joint      : 981.6447074458284\n",
      "    val_loss       : -776.9930369059244\n",
      "    val_ess        : 1.9595603942871094\n",
      "    val_log_marginal: 777.0309549967448\n",
      "    val_log_joint  : 985.4119211832682\n",
      "Train Epoch: 1582 [0/54000 (0%)] Loss: -755.505676\n",
      "Train Epoch: 1582 [11264/54000 (21%)] Loss: -779.517944\n",
      "Train Epoch: 1582 [22528/54000 (42%)] Loss: -780.277100\n",
      "Train Epoch: 1582 [33792/54000 (63%)] Loss: -768.704834\n",
      "Train Epoch: 1582 [45056/54000 (83%)] Loss: -773.933594\n",
      "    epoch          : 1582\n",
      "    loss           : -772.9836028476931\n",
      "    ess            : 1.9610056281089783\n",
      "    log_marginal   : 773.0201617546801\n",
      "    log_joint      : 981.5590083284198\n",
      "    val_loss       : -776.1989542643229\n",
      "    val_ess        : 1.9605266749858856\n",
      "    val_log_marginal: 776.2386271158854\n",
      "    val_log_joint  : 984.8143361409506\n",
      "Train Epoch: 1583 [0/54000 (0%)] Loss: -787.120605\n",
      "Train Epoch: 1583 [11264/54000 (21%)] Loss: -757.200134\n",
      "Train Epoch: 1583 [22528/54000 (42%)] Loss: -766.557434\n",
      "Train Epoch: 1583 [33792/54000 (63%)] Loss: -774.561035\n",
      "Train Epoch: 1583 [45056/54000 (83%)] Loss: -761.370178\n",
      "    epoch          : 1583\n",
      "    loss           : -772.7253262501843\n",
      "    ess            : 1.9602250456809998\n",
      "    log_marginal   : 772.7625473310362\n",
      "    log_joint      : 981.3463077185289\n",
      "    val_loss       : -776.7830403645834\n",
      "    val_ess        : 1.9602222740650177\n",
      "    val_log_marginal: 776.8177235921224\n",
      "    val_log_joint  : 985.1276652018229\n",
      "Train Epoch: 1584 [0/54000 (0%)] Loss: -800.020752\n",
      "Train Epoch: 1584 [11264/54000 (21%)] Loss: -784.607910\n",
      "Train Epoch: 1584 [22528/54000 (42%)] Loss: -769.454956\n",
      "Train Epoch: 1584 [33792/54000 (63%)] Loss: -759.075500\n",
      "Train Epoch: 1584 [45056/54000 (83%)] Loss: -782.147644\n",
      "    epoch          : 1584\n",
      "    loss           : -773.040484158498\n",
      "    ess            : 1.9593495299231332\n",
      "    log_marginal   : 773.0793382176813\n",
      "    log_joint      : 981.6071328217129\n",
      "    val_loss       : -776.3681437174479\n",
      "    val_ess        : 1.9593775471051533\n",
      "    val_log_marginal: 776.4117533365885\n",
      "    val_log_joint  : 984.9539998372396\n",
      "Train Epoch: 1585 [0/54000 (0%)] Loss: -760.296814\n",
      "Train Epoch: 1585 [11264/54000 (21%)] Loss: -779.074707\n",
      "Train Epoch: 1585 [22528/54000 (42%)] Loss: -770.444824\n",
      "Train Epoch: 1585 [33792/54000 (63%)] Loss: -795.195923\n",
      "Train Epoch: 1585 [45056/54000 (83%)] Loss: -777.583252\n",
      "    epoch          : 1585\n",
      "    loss           : -772.9448869813164\n",
      "    ess            : 1.9581914229213067\n",
      "    log_marginal   : 772.9841135852741\n",
      "    log_joint      : 981.4727691074587\n",
      "    val_loss       : -776.8500315348307\n",
      "    val_ess        : 1.9627567827701569\n",
      "    val_log_marginal: 776.8834838867188\n",
      "    val_log_joint  : 985.6279805501302\n",
      "Train Epoch: 1586 [0/54000 (0%)] Loss: -794.675049\n",
      "Train Epoch: 1586 [11264/54000 (21%)] Loss: -780.494873\n",
      "Train Epoch: 1586 [22528/54000 (42%)] Loss: -767.279663\n",
      "Train Epoch: 1586 [33792/54000 (63%)] Loss: -775.561584\n",
      "Train Epoch: 1586 [45056/54000 (83%)] Loss: -753.308594\n",
      "    epoch          : 1586\n",
      "    loss           : -772.6609721633623\n",
      "    ess            : 1.9606747222396563\n",
      "    log_marginal   : 772.6973658147848\n",
      "    log_joint      : 981.2619145231427\n",
      "    val_loss       : -776.5576121012369\n",
      "    val_ess        : 1.9592973589897156\n",
      "    val_log_marginal: 776.5954895019531\n",
      "    val_log_joint  : 985.0616353352865\n",
      "Train Epoch: 1587 [0/54000 (0%)] Loss: -782.330444\n",
      "Train Epoch: 1587 [11264/54000 (21%)] Loss: -788.558594\n",
      "Train Epoch: 1587 [22528/54000 (42%)] Loss: -779.237183\n",
      "Train Epoch: 1587 [33792/54000 (63%)] Loss: -797.266846\n",
      "Train Epoch: 1587 [45056/54000 (83%)] Loss: -754.174622\n",
      "    epoch          : 1587\n",
      "    loss           : -773.0808001824145\n",
      "    ess            : 1.9604807597286296\n",
      "    log_marginal   : 773.1182170364092\n",
      "    log_joint      : 981.7224719929245\n",
      "    val_loss       : -777.2552744547526\n",
      "    val_ess        : 1.9611209432284038\n",
      "    val_log_marginal: 777.2891031901041\n",
      "    val_log_joint  : 985.6848754882812\n",
      "Train Epoch: 1588 [0/54000 (0%)] Loss: -782.274902\n",
      "Train Epoch: 1588 [11264/54000 (21%)] Loss: -774.547485\n",
      "Train Epoch: 1588 [22528/54000 (42%)] Loss: -791.496460\n",
      "Train Epoch: 1588 [33792/54000 (63%)] Loss: -785.927124\n",
      "Train Epoch: 1588 [45056/54000 (83%)] Loss: -798.719482\n",
      "    epoch          : 1588\n",
      "    loss           : -772.8959811228626\n",
      "    ess            : 1.960095058072288\n",
      "    log_marginal   : 772.9342501658314\n",
      "    log_joint      : 981.4921990160672\n",
      "    val_loss       : -777.6052856445312\n",
      "    val_ess        : 1.9617825349171956\n",
      "    val_log_marginal: 777.6416676839193\n",
      "    val_log_joint  : 985.9682057698568\n",
      "Train Epoch: 1589 [0/54000 (0%)] Loss: -769.164612\n",
      "Train Epoch: 1589 [11264/54000 (21%)] Loss: -764.804321\n",
      "Train Epoch: 1589 [22528/54000 (42%)] Loss: -754.165405\n",
      "Train Epoch: 1589 [33792/54000 (63%)] Loss: -803.608826\n",
      "Train Epoch: 1589 [45056/54000 (83%)] Loss: -780.469971\n",
      "    epoch          : 1589\n",
      "    loss           : -773.0200517762382\n",
      "    ess            : 1.9604615445406932\n",
      "    log_marginal   : 773.0561609808004\n",
      "    log_joint      : 981.5764609282871\n",
      "    val_loss       : -777.8272094726562\n",
      "    val_ess        : 1.9578539530436199\n",
      "    val_log_marginal: 777.8629302978516\n",
      "    val_log_joint  : 986.2506764729818\n",
      "Train Epoch: 1590 [0/54000 (0%)] Loss: -782.522095\n",
      "Train Epoch: 1590 [11264/54000 (21%)] Loss: -776.849548\n",
      "Train Epoch: 1590 [22528/54000 (42%)] Loss: -755.096069\n",
      "Train Epoch: 1590 [33792/54000 (63%)] Loss: -772.709961\n",
      "Train Epoch: 1590 [45056/54000 (83%)] Loss: -774.415405\n",
      "    epoch          : 1590\n",
      "    loss           : -772.9878252137382\n",
      "    ess            : 1.9603800964805316\n",
      "    log_marginal   : 773.0245303747789\n",
      "    log_joint      : 981.6037672510687\n",
      "    val_loss       : -777.4447377522787\n",
      "    val_ess        : 1.960691104332606\n",
      "    val_log_marginal: 777.4817097981771\n",
      "    val_log_joint  : 985.7344055175781\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1590.pth ...\n",
      "Train Epoch: 1591 [0/54000 (0%)] Loss: -763.193604\n",
      "Train Epoch: 1591 [11264/54000 (21%)] Loss: -779.082031\n",
      "Train Epoch: 1591 [22528/54000 (42%)] Loss: -781.360718\n",
      "Train Epoch: 1591 [33792/54000 (63%)] Loss: -766.093750\n",
      "Train Epoch: 1591 [45056/54000 (83%)] Loss: -768.602234\n",
      "    epoch          : 1591\n",
      "    loss           : -773.1446406526386\n",
      "    ess            : 1.960769552104878\n",
      "    log_marginal   : 773.1809594496241\n",
      "    log_joint      : 981.635798040426\n",
      "    val_loss       : -777.4970143636068\n",
      "    val_ess        : 1.9615972936153412\n",
      "    val_log_marginal: 777.5331064860026\n",
      "    val_log_joint  : 985.746815999349\n",
      "Train Epoch: 1592 [0/54000 (0%)] Loss: -777.652405\n",
      "Train Epoch: 1592 [11264/54000 (21%)] Loss: -775.971252\n",
      "Train Epoch: 1592 [22528/54000 (42%)] Loss: -758.350586\n",
      "Train Epoch: 1592 [33792/54000 (63%)] Loss: -764.680847\n",
      "Train Epoch: 1592 [45056/54000 (83%)] Loss: -781.097412\n",
      "    epoch          : 1592\n",
      "    loss           : -772.8819033064932\n",
      "    ess            : 1.9606622221334926\n",
      "    log_marginal   : 772.9199909714033\n",
      "    log_joint      : 981.4303030337927\n",
      "    val_loss       : -776.9402923583984\n",
      "    val_ess        : 1.9607414503892262\n",
      "    val_log_marginal: 776.9765014648438\n",
      "    val_log_joint  : 985.4969380696615\n",
      "Train Epoch: 1593 [0/54000 (0%)] Loss: -768.132812\n",
      "Train Epoch: 1593 [11264/54000 (21%)] Loss: -778.992554\n",
      "Train Epoch: 1593 [22528/54000 (42%)] Loss: -772.793457\n",
      "Train Epoch: 1593 [33792/54000 (63%)] Loss: -787.786499\n",
      "Train Epoch: 1593 [45056/54000 (83%)] Loss: -758.487915\n",
      "    epoch          : 1593\n",
      "    loss           : -773.1810890053803\n",
      "    ess            : 1.959487981391403\n",
      "    log_marginal   : 773.2202902739903\n",
      "    log_joint      : 981.7315103782797\n",
      "    val_loss       : -777.0067392985026\n",
      "    val_ess        : 1.9594512085119884\n",
      "    val_log_marginal: 777.0446116129557\n",
      "    val_log_joint  : 985.6078236897787\n",
      "Train Epoch: 1594 [0/54000 (0%)] Loss: -756.813599\n",
      "Train Epoch: 1594 [11264/54000 (21%)] Loss: -760.662842\n",
      "Train Epoch: 1594 [22528/54000 (42%)] Loss: -739.014282\n",
      "Train Epoch: 1594 [33792/54000 (63%)] Loss: -788.976074\n",
      "Train Epoch: 1594 [45056/54000 (83%)] Loss: -787.939575\n",
      "    epoch          : 1594\n",
      "    loss           : -772.9955812850088\n",
      "    ess            : 1.9610007067896285\n",
      "    log_marginal   : 773.0319484494767\n",
      "    log_joint      : 981.6315336407356\n",
      "    val_loss       : -777.2463175455729\n",
      "    val_ess        : 1.9618313511212666\n",
      "    val_log_marginal: 777.2831624348959\n",
      "    val_log_joint  : 986.0267486572266\n",
      "Train Epoch: 1595 [0/54000 (0%)] Loss: -785.817810\n",
      "Train Epoch: 1595 [11264/54000 (21%)] Loss: -803.727905\n",
      "Train Epoch: 1595 [22528/54000 (42%)] Loss: -770.013916\n",
      "Train Epoch: 1595 [33792/54000 (63%)] Loss: -772.398987\n",
      "Train Epoch: 1595 [45056/54000 (83%)] Loss: -787.765137\n",
      "    epoch          : 1595\n",
      "    loss           : -772.9005213323629\n",
      "    ess            : 1.9604291016200803\n",
      "    log_marginal   : 772.9387759802477\n",
      "    log_joint      : 981.5573598033977\n",
      "    val_loss       : -776.6571350097656\n",
      "    val_ess        : 1.958027442296346\n",
      "    val_log_marginal: 776.6959482828776\n",
      "    val_log_joint  : 985.4174194335938\n",
      "Train Epoch: 1596 [0/54000 (0%)] Loss: -766.941895\n",
      "Train Epoch: 1596 [11264/54000 (21%)] Loss: -775.344116\n",
      "Train Epoch: 1596 [22528/54000 (42%)] Loss: -753.457092\n",
      "Train Epoch: 1596 [33792/54000 (63%)] Loss: -761.728027\n",
      "Train Epoch: 1596 [45056/54000 (83%)] Loss: -763.841797\n",
      "    epoch          : 1596\n",
      "    loss           : -773.0517123240345\n",
      "    ess            : 1.9608686015291035\n",
      "    log_marginal   : 773.0875952378759\n",
      "    log_joint      : 981.569677388893\n",
      "    val_loss       : -777.071055094401\n",
      "    val_ess        : 1.9633644322554271\n",
      "    val_log_marginal: 777.1099904378256\n",
      "    val_log_joint  : 985.3399556477865\n",
      "Train Epoch: 1597 [0/54000 (0%)] Loss: -772.352539\n",
      "Train Epoch: 1597 [11264/54000 (21%)] Loss: -773.370911\n",
      "Train Epoch: 1597 [22528/54000 (42%)] Loss: -763.589111\n",
      "Train Epoch: 1597 [33792/54000 (63%)] Loss: -770.885742\n",
      "Train Epoch: 1597 [45056/54000 (83%)] Loss: -773.180298\n",
      "    epoch          : 1597\n",
      "    loss           : -773.2218754606427\n",
      "    ess            : 1.9600165283904885\n",
      "    log_marginal   : 773.2598209021227\n",
      "    log_joint      : 981.7710127920475\n",
      "    val_loss       : -777.4342193603516\n",
      "    val_ess        : 1.9639067649841309\n",
      "    val_log_marginal: 777.4679107666016\n",
      "    val_log_joint  : 985.8969523111979\n",
      "Train Epoch: 1598 [0/54000 (0%)] Loss: -763.559814\n",
      "Train Epoch: 1598 [11264/54000 (21%)] Loss: -765.208984\n",
      "Train Epoch: 1598 [22528/54000 (42%)] Loss: -772.737183\n",
      "Train Epoch: 1598 [33792/54000 (63%)] Loss: -769.028198\n",
      "Train Epoch: 1598 [45056/54000 (83%)] Loss: -784.580139\n",
      "    epoch          : 1598\n",
      "    loss           : -773.204471804061\n",
      "    ess            : 1.9609445873296485\n",
      "    log_marginal   : 773.2417752247936\n",
      "    log_joint      : 981.7134468510466\n",
      "    val_loss       : -777.3313191731771\n",
      "    val_ess        : 1.96214097738266\n",
      "    val_log_marginal: 777.3664143880209\n",
      "    val_log_joint  : 985.9029947916666\n",
      "Train Epoch: 1599 [0/54000 (0%)] Loss: -760.381226\n",
      "Train Epoch: 1599 [11264/54000 (21%)] Loss: -768.650208\n",
      "Train Epoch: 1599 [22528/54000 (42%)] Loss: -767.350220\n",
      "Train Epoch: 1599 [33792/54000 (63%)] Loss: -806.609070\n",
      "Train Epoch: 1599 [45056/54000 (83%)] Loss: -781.717285\n",
      "    epoch          : 1599\n",
      "    loss           : -773.1574672483048\n",
      "    ess            : 1.960537074871783\n",
      "    log_marginal   : 773.1937728018131\n",
      "    log_joint      : 981.7542494288031\n",
      "    val_loss       : -776.7766265869141\n",
      "    val_ess        : 1.9600045184294383\n",
      "    val_log_marginal: 776.8150227864584\n",
      "    val_log_joint  : 985.5380096435547\n",
      "Train Epoch: 1600 [0/54000 (0%)] Loss: -766.533569\n",
      "Train Epoch: 1600 [11264/54000 (21%)] Loss: -756.769287\n",
      "Train Epoch: 1600 [22528/54000 (42%)] Loss: -784.547974\n",
      "Train Epoch: 1600 [33792/54000 (63%)] Loss: -782.892578\n",
      "Train Epoch: 1600 [45056/54000 (83%)] Loss: -772.685791\n",
      "    epoch          : 1600\n",
      "    loss           : -773.3489880831736\n",
      "    ess            : 1.9616727986425724\n",
      "    log_marginal   : 773.385134139151\n",
      "    log_joint      : 981.9068666853995\n",
      "    val_loss       : -777.7957458496094\n",
      "    val_ess        : 1.9622035125891368\n",
      "    val_log_marginal: 777.8332366943359\n",
      "    val_log_joint  : 986.2489776611328\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1600.pth ...\n",
      "Train Epoch: 1601 [0/54000 (0%)] Loss: -786.290833\n",
      "Train Epoch: 1601 [11264/54000 (21%)] Loss: -770.769409\n",
      "Train Epoch: 1601 [22528/54000 (42%)] Loss: -746.557556\n",
      "Train Epoch: 1601 [33792/54000 (63%)] Loss: -753.275085\n",
      "Train Epoch: 1601 [45056/54000 (83%)] Loss: -780.520508\n",
      "    epoch          : 1601\n",
      "    loss           : -773.1366991726858\n",
      "    ess            : 1.9602386355400085\n",
      "    log_marginal   : 773.1730317889519\n",
      "    log_joint      : 981.7868260797464\n",
      "    val_loss       : -776.8598327636719\n",
      "    val_ess        : 1.958570549885432\n",
      "    val_log_marginal: 776.8983713785807\n",
      "    val_log_joint  : 985.5581715901693\n",
      "Train Epoch: 1602 [0/54000 (0%)] Loss: -779.703857\n",
      "Train Epoch: 1602 [11264/54000 (21%)] Loss: -781.607422\n",
      "Train Epoch: 1602 [22528/54000 (42%)] Loss: -782.573303\n",
      "Train Epoch: 1602 [33792/54000 (63%)] Loss: -760.962769\n",
      "Train Epoch: 1602 [45056/54000 (83%)] Loss: -781.553589\n",
      "    epoch          : 1602\n",
      "    loss           : -773.2326556511645\n",
      "    ess            : 1.9600183007852086\n",
      "    log_marginal   : 773.2701381467423\n",
      "    log_joint      : 981.8263336757444\n",
      "    val_loss       : -777.6522165934244\n",
      "    val_ess        : 1.9638921320438385\n",
      "    val_log_marginal: 777.68408203125\n",
      "    val_log_joint  : 986.2850545247396\n",
      "Train Epoch: 1603 [0/54000 (0%)] Loss: -759.005554\n",
      "Train Epoch: 1603 [11264/54000 (21%)] Loss: -778.351013\n",
      "Train Epoch: 1603 [22528/54000 (42%)] Loss: -765.315796\n",
      "Train Epoch: 1603 [33792/54000 (63%)] Loss: -756.693237\n",
      "Train Epoch: 1603 [45056/54000 (83%)] Loss: -748.542725\n",
      "    epoch          : 1603\n",
      "    loss           : -773.4167658967792\n",
      "    ess            : 1.9605175133021373\n",
      "    log_marginal   : 773.4537733545843\n",
      "    log_joint      : 982.0051373175855\n",
      "    val_loss       : -777.5972391764323\n",
      "    val_ess        : 1.9589079817136128\n",
      "    val_log_marginal: 777.6398366292318\n",
      "    val_log_joint  : 986.0438588460287\n",
      "Train Epoch: 1604 [0/54000 (0%)] Loss: -766.480042\n",
      "Train Epoch: 1604 [11264/54000 (21%)] Loss: -781.896851\n",
      "Train Epoch: 1604 [22528/54000 (42%)] Loss: -773.868042\n",
      "Train Epoch: 1604 [33792/54000 (63%)] Loss: -772.406860\n",
      "Train Epoch: 1604 [45056/54000 (83%)] Loss: -748.202820\n",
      "    epoch          : 1604\n",
      "    loss           : -773.1157779333727\n",
      "    ess            : 1.9599325758106303\n",
      "    log_marginal   : 773.1546538730837\n",
      "    log_joint      : 981.7598698454083\n",
      "    val_loss       : -777.3287607828776\n",
      "    val_ess        : 1.962431122859319\n",
      "    val_log_marginal: 777.3632965087891\n",
      "    val_log_joint  : 985.8382161458334\n",
      "Train Epoch: 1605 [0/54000 (0%)] Loss: -771.162842\n",
      "Train Epoch: 1605 [11264/54000 (21%)] Loss: -751.033569\n",
      "Train Epoch: 1605 [22528/54000 (42%)] Loss: -771.019775\n",
      "Train Epoch: 1605 [33792/54000 (63%)] Loss: -764.591919\n",
      "Train Epoch: 1605 [45056/54000 (83%)] Loss: -768.892822\n",
      "    epoch          : 1605\n",
      "    loss           : -773.4474412450251\n",
      "    ess            : 1.9622500280164323\n",
      "    log_marginal   : 773.4836063025133\n",
      "    log_joint      : 982.0097984457916\n",
      "    val_loss       : -778.0032755533854\n",
      "    val_ess        : 1.960301826397578\n",
      "    val_log_marginal: 778.0436299641927\n",
      "    val_log_joint  : 986.3857879638672\n",
      "Train Epoch: 1606 [0/54000 (0%)] Loss: -798.726074\n",
      "Train Epoch: 1606 [11264/54000 (21%)] Loss: -794.755371\n",
      "Train Epoch: 1606 [22528/54000 (42%)] Loss: -782.132812\n",
      "Train Epoch: 1606 [33792/54000 (63%)] Loss: -767.925781\n",
      "Train Epoch: 1606 [45056/54000 (83%)] Loss: -775.244812\n",
      "    epoch          : 1606\n",
      "    loss           : -773.269769056788\n",
      "    ess            : 1.9608590749074828\n",
      "    log_marginal   : 773.3067120246168\n",
      "    log_joint      : 981.8350288822966\n",
      "    val_loss       : -776.8264770507812\n",
      "    val_ess        : 1.961750437815984\n",
      "    val_log_marginal: 776.8618520100912\n",
      "    val_log_joint  : 985.4264933268229\n",
      "Train Epoch: 1607 [0/54000 (0%)] Loss: -769.389526\n",
      "Train Epoch: 1607 [11264/54000 (21%)] Loss: -777.989380\n",
      "Train Epoch: 1607 [22528/54000 (42%)] Loss: -764.225647\n",
      "Train Epoch: 1607 [33792/54000 (63%)] Loss: -772.502136\n",
      "Train Epoch: 1607 [45056/54000 (83%)] Loss: -781.490845\n",
      "    epoch          : 1607\n",
      "    loss           : -773.3576366496536\n",
      "    ess            : 1.9608728323342666\n",
      "    log_marginal   : 773.395282673386\n",
      "    log_joint      : 981.9429868302255\n",
      "    val_loss       : -777.6301778157552\n",
      "    val_ess        : 1.9612103700637817\n",
      "    val_log_marginal: 777.6654612223307\n",
      "    val_log_joint  : 986.0490926106771\n",
      "Train Epoch: 1608 [0/54000 (0%)] Loss: -786.142944\n",
      "Train Epoch: 1608 [11264/54000 (21%)] Loss: -768.068970\n",
      "Train Epoch: 1608 [22528/54000 (42%)] Loss: -754.695679\n",
      "Train Epoch: 1608 [33792/54000 (63%)] Loss: -769.038086\n",
      "Train Epoch: 1608 [45056/54000 (83%)] Loss: -774.784180\n",
      "    epoch          : 1608\n",
      "    loss           : -773.1110626796507\n",
      "    ess            : 1.9612176193381257\n",
      "    log_marginal   : 773.1474574826798\n",
      "    log_joint      : 981.7076082049675\n",
      "    val_loss       : -778.1089833577474\n",
      "    val_ess        : 1.9628731608390808\n",
      "    val_log_marginal: 778.1419677734375\n",
      "    val_log_joint  : 986.5697784423828\n",
      "Train Epoch: 1609 [0/54000 (0%)] Loss: -786.065308\n",
      "Train Epoch: 1609 [11264/54000 (21%)] Loss: -786.711487\n",
      "Train Epoch: 1609 [22528/54000 (42%)] Loss: -777.044434\n",
      "Train Epoch: 1609 [33792/54000 (63%)] Loss: -750.349915\n",
      "Train Epoch: 1609 [45056/54000 (83%)] Loss: -735.226562\n",
      "    epoch          : 1609\n",
      "    loss           : -773.2843708542158\n",
      "    ess            : 1.960612640065967\n",
      "    log_marginal   : 773.3206291918484\n",
      "    log_joint      : 981.7895145056383\n",
      "    val_loss       : -777.6709747314453\n",
      "    val_ess        : 1.9626907606919606\n",
      "    val_log_marginal: 777.7061564127604\n",
      "    val_log_joint  : 986.3329772949219\n",
      "Train Epoch: 1610 [0/54000 (0%)] Loss: -769.840271\n",
      "Train Epoch: 1610 [11264/54000 (21%)] Loss: -773.474731\n",
      "Train Epoch: 1610 [22528/54000 (42%)] Loss: -782.953003\n",
      "Train Epoch: 1610 [33792/54000 (63%)] Loss: -758.772522\n",
      "Train Epoch: 1610 [45056/54000 (83%)] Loss: -771.822144\n",
      "    epoch          : 1610\n",
      "    loss           : -773.1871159391583\n",
      "    ess            : 1.9613037772898405\n",
      "    log_marginal   : 773.2237145765772\n",
      "    log_joint      : 981.7625680599573\n",
      "    val_loss       : -778.0940348307291\n",
      "    val_ess        : 1.961091786623001\n",
      "    val_log_marginal: 778.1280161539713\n",
      "    val_log_joint  : 986.4120025634766\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1610.pth ...\n",
      "Train Epoch: 1611 [0/54000 (0%)] Loss: -773.833008\n",
      "Train Epoch: 1611 [11264/54000 (21%)] Loss: -756.384949\n",
      "Train Epoch: 1611 [22528/54000 (42%)] Loss: -766.985962\n",
      "Train Epoch: 1611 [33792/54000 (63%)] Loss: -762.808716\n",
      "Train Epoch: 1611 [45056/54000 (83%)] Loss: -778.819641\n",
      "    epoch          : 1611\n",
      "    loss           : -773.1833933704304\n",
      "    ess            : 1.9611402401384317\n",
      "    log_marginal   : 773.2194035368145\n",
      "    log_joint      : 981.656752676334\n",
      "    val_loss       : -777.5879313151041\n",
      "    val_ess        : 1.9633341034253438\n",
      "    val_log_marginal: 777.6230214436849\n",
      "    val_log_joint  : 986.134765625\n",
      "Train Epoch: 1612 [0/54000 (0%)] Loss: -774.863403\n",
      "Train Epoch: 1612 [11264/54000 (21%)] Loss: -765.908447\n",
      "Train Epoch: 1612 [22528/54000 (42%)] Loss: -777.320923\n",
      "Train Epoch: 1612 [33792/54000 (63%)] Loss: -736.038513\n",
      "Train Epoch: 1612 [45056/54000 (83%)] Loss: -784.343567\n",
      "    epoch          : 1612\n",
      "    loss           : -773.0731143591539\n",
      "    ess            : 1.9605303395469234\n",
      "    log_marginal   : 773.1096346873157\n",
      "    log_joint      : 981.7258174104511\n",
      "    val_loss       : -777.3671264648438\n",
      "    val_ess        : 1.958324134349823\n",
      "    val_log_marginal: 777.4106903076172\n",
      "    val_log_joint  : 986.0188395182291\n",
      "Train Epoch: 1613 [0/54000 (0%)] Loss: -767.405029\n",
      "Train Epoch: 1613 [11264/54000 (21%)] Loss: -788.403442\n",
      "Train Epoch: 1613 [22528/54000 (42%)] Loss: -774.951294\n",
      "Train Epoch: 1613 [33792/54000 (63%)] Loss: -756.099304\n",
      "Train Epoch: 1613 [45056/54000 (83%)] Loss: -778.229187\n",
      "    epoch          : 1613\n",
      "    loss           : -773.3123007720371\n",
      "    ess            : 1.961119089486464\n",
      "    log_marginal   : 773.3500216502064\n",
      "    log_joint      : 981.8551808483196\n",
      "    val_loss       : -777.4249521891276\n",
      "    val_ess        : 1.96115838487943\n",
      "    val_log_marginal: 777.4614766438802\n",
      "    val_log_joint  : 986.1385040283203\n",
      "Train Epoch: 1614 [0/54000 (0%)] Loss: -797.337769\n",
      "Train Epoch: 1614 [11264/54000 (21%)] Loss: -771.197266\n",
      "Train Epoch: 1614 [22528/54000 (42%)] Loss: -752.694031\n",
      "Train Epoch: 1614 [33792/54000 (63%)] Loss: -760.056274\n",
      "Train Epoch: 1614 [45056/54000 (83%)] Loss: -753.352051\n",
      "    epoch          : 1614\n",
      "    loss           : -773.3457935261276\n",
      "    ess            : 1.9612478827530484\n",
      "    log_marginal   : 773.3822568497568\n",
      "    log_joint      : 981.9768331275797\n",
      "    val_loss       : -777.3773956298828\n",
      "    val_ess        : 1.9586118360360463\n",
      "    val_log_marginal: 777.4174753824869\n",
      "    val_log_joint  : 986.0797475179037\n",
      "Train Epoch: 1615 [0/54000 (0%)] Loss: -780.532043\n",
      "Train Epoch: 1615 [11264/54000 (21%)] Loss: -766.877563\n",
      "Train Epoch: 1615 [22528/54000 (42%)] Loss: -788.427002\n",
      "Train Epoch: 1615 [33792/54000 (63%)] Loss: -770.289429\n",
      "Train Epoch: 1615 [45056/54000 (83%)] Loss: -763.552979\n",
      "    epoch          : 1615\n",
      "    loss           : -773.3762817382812\n",
      "    ess            : 1.960290087843841\n",
      "    log_marginal   : 773.4141937831663\n",
      "    log_joint      : 981.9332137197819\n",
      "    val_loss       : -777.6943715413412\n",
      "    val_ess        : 1.958507627248764\n",
      "    val_log_marginal: 777.7321065266927\n",
      "    val_log_joint  : 986.3412322998047\n",
      "Train Epoch: 1616 [0/54000 (0%)] Loss: -764.003296\n",
      "Train Epoch: 1616 [11264/54000 (21%)] Loss: -749.523315\n",
      "Train Epoch: 1616 [22528/54000 (42%)] Loss: -779.154785\n",
      "Train Epoch: 1616 [33792/54000 (63%)] Loss: -789.849609\n",
      "Train Epoch: 1616 [45056/54000 (83%)] Loss: -775.214050\n",
      "    epoch          : 1616\n",
      "    loss           : -773.0935997153229\n",
      "    ess            : 1.9602254359227307\n",
      "    log_marginal   : 773.1306411455263\n",
      "    log_joint      : 981.6374091382297\n",
      "    val_loss       : -777.5411834716797\n",
      "    val_ess        : 1.9623684485753377\n",
      "    val_log_marginal: 777.5759226481119\n",
      "    val_log_joint  : 986.1717631022135\n",
      "Train Epoch: 1617 [0/54000 (0%)] Loss: -772.424744\n",
      "Train Epoch: 1617 [11264/54000 (21%)] Loss: -772.582275\n",
      "Train Epoch: 1617 [22528/54000 (42%)] Loss: -773.820190\n",
      "Train Epoch: 1617 [33792/54000 (63%)] Loss: -763.929199\n",
      "Train Epoch: 1617 [45056/54000 (83%)] Loss: -771.973755\n",
      "    epoch          : 1617\n",
      "    loss           : -773.254317949403\n",
      "    ess            : 1.9601663497259032\n",
      "    log_marginal   : 773.2933476286114\n",
      "    log_joint      : 981.7735290527344\n",
      "    val_loss       : -777.3257293701172\n",
      "    val_ess        : 1.9604471226533253\n",
      "    val_log_marginal: 777.3598937988281\n",
      "    val_log_joint  : 985.9887135823568\n",
      "Train Epoch: 1618 [0/54000 (0%)] Loss: -784.924194\n",
      "Train Epoch: 1618 [11264/54000 (21%)] Loss: -800.055786\n",
      "Train Epoch: 1618 [22528/54000 (42%)] Loss: -772.451416\n",
      "Train Epoch: 1618 [33792/54000 (63%)] Loss: -778.714966\n",
      "Train Epoch: 1618 [45056/54000 (83%)] Loss: -770.869263\n",
      "    epoch          : 1618\n",
      "    loss           : -773.1159840709759\n",
      "    ess            : 1.961350440979004\n",
      "    log_marginal   : 773.1521157318691\n",
      "    log_joint      : 981.743890150538\n",
      "    val_loss       : -777.6391347249349\n",
      "    val_ess        : 1.9589651226997375\n",
      "    val_log_marginal: 777.6794128417969\n",
      "    val_log_joint  : 986.1670633951823\n",
      "Train Epoch: 1619 [0/54000 (0%)] Loss: -765.451233\n",
      "Train Epoch: 1619 [11264/54000 (21%)] Loss: -778.394043\n",
      "Train Epoch: 1619 [22528/54000 (42%)] Loss: -802.772339\n",
      "Train Epoch: 1619 [33792/54000 (63%)] Loss: -776.493408\n",
      "Train Epoch: 1619 [45056/54000 (83%)] Loss: -775.843811\n",
      "    epoch          : 1619\n",
      "    loss           : -773.2828363382591\n",
      "    ess            : 1.9600157580285702\n",
      "    log_marginal   : 773.3219155365566\n",
      "    log_joint      : 981.8428770821049\n",
      "    val_loss       : -777.3107859293619\n",
      "    val_ess        : 1.9575047294298809\n",
      "    val_log_marginal: 777.3516489664713\n",
      "    val_log_joint  : 985.5123647054037\n",
      "Train Epoch: 1620 [0/54000 (0%)] Loss: -790.614990\n",
      "Train Epoch: 1620 [11264/54000 (21%)] Loss: -780.523560\n",
      "Train Epoch: 1620 [22528/54000 (42%)] Loss: -772.635376\n",
      "Train Epoch: 1620 [33792/54000 (63%)] Loss: -777.024902\n",
      "Train Epoch: 1620 [45056/54000 (83%)] Loss: -764.686890\n",
      "    epoch          : 1620\n",
      "    loss           : -773.2758829368735\n",
      "    ess            : 1.9604253307828363\n",
      "    log_marginal   : 773.3129830990198\n",
      "    log_joint      : 981.8751479814638\n",
      "    val_loss       : -778.0866394042969\n",
      "    val_ess        : 1.9622438649336498\n",
      "    val_log_marginal: 778.1230010986328\n",
      "    val_log_joint  : 986.4534352620443\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1620.pth ...\n",
      "Train Epoch: 1621 [0/54000 (0%)] Loss: -784.690186\n",
      "Train Epoch: 1621 [11264/54000 (21%)] Loss: -758.743774\n",
      "Train Epoch: 1621 [22528/54000 (42%)] Loss: -776.864319\n",
      "Train Epoch: 1621 [33792/54000 (63%)] Loss: -802.435852\n",
      "Train Epoch: 1621 [45056/54000 (83%)] Loss: -755.012512\n",
      "    epoch          : 1621\n",
      "    loss           : -773.1789464410746\n",
      "    ess            : 1.9607894150715954\n",
      "    log_marginal   : 773.2158260705336\n",
      "    log_joint      : 981.7953675468013\n",
      "    val_loss       : -778.1960042317709\n",
      "    val_ess        : 1.9609326819578807\n",
      "    val_log_marginal: 778.2324574788412\n",
      "    val_log_joint  : 986.594228108724\n",
      "Train Epoch: 1622 [0/54000 (0%)] Loss: -767.250671\n",
      "Train Epoch: 1622 [11264/54000 (21%)] Loss: -786.436584\n",
      "Train Epoch: 1622 [22528/54000 (42%)] Loss: -764.474792\n",
      "Train Epoch: 1622 [33792/54000 (63%)] Loss: -757.653992\n",
      "Train Epoch: 1622 [45056/54000 (83%)] Loss: -763.730469\n",
      "    epoch          : 1622\n",
      "    loss           : -773.4724921460422\n",
      "    ess            : 1.9594057663431708\n",
      "    log_marginal   : 773.5113024441702\n",
      "    log_joint      : 982.0746292977963\n",
      "    val_loss       : -777.4071655273438\n",
      "    val_ess        : 1.958889087041219\n",
      "    val_log_marginal: 777.443613688151\n",
      "    val_log_joint  : 986.0251007080078\n",
      "Train Epoch: 1623 [0/54000 (0%)] Loss: -780.282776\n",
      "Train Epoch: 1623 [11264/54000 (21%)] Loss: -784.890503\n",
      "Train Epoch: 1623 [22528/54000 (42%)] Loss: -760.207275\n",
      "Train Epoch: 1623 [33792/54000 (63%)] Loss: -773.927124\n",
      "Train Epoch: 1623 [45056/54000 (83%)] Loss: -759.848816\n",
      "    epoch          : 1623\n",
      "    loss           : -773.4309214466023\n",
      "    ess            : 1.9586080009082578\n",
      "    log_marginal   : 773.471234591502\n",
      "    log_joint      : 982.1134096541495\n",
      "    val_loss       : -777.9053039550781\n",
      "    val_ess        : 1.9595204989115398\n",
      "    val_log_marginal: 777.9416097005209\n",
      "    val_log_joint  : 986.5388539632162\n",
      "Train Epoch: 1624 [0/54000 (0%)] Loss: -741.735718\n",
      "Train Epoch: 1624 [11264/54000 (21%)] Loss: -747.788330\n",
      "Train Epoch: 1624 [22528/54000 (42%)] Loss: -786.397583\n",
      "Train Epoch: 1624 [33792/54000 (63%)] Loss: -780.875671\n",
      "Train Epoch: 1624 [45056/54000 (83%)] Loss: -771.063416\n",
      "    epoch          : 1624\n",
      "    loss           : -773.2370000875221\n",
      "    ess            : 1.9612095873310882\n",
      "    log_marginal   : 773.2734202258991\n",
      "    log_joint      : 981.7816726396669\n",
      "    val_loss       : -777.519276936849\n",
      "    val_ess        : 1.9603568812211354\n",
      "    val_log_marginal: 777.5576426188151\n",
      "    val_log_joint  : 985.7743733723959\n",
      "Train Epoch: 1625 [0/54000 (0%)] Loss: -782.171143\n",
      "Train Epoch: 1625 [11264/54000 (21%)] Loss: -766.572998\n",
      "Train Epoch: 1625 [22528/54000 (42%)] Loss: -780.836548\n",
      "Train Epoch: 1625 [33792/54000 (63%)] Loss: -754.488281\n",
      "Train Epoch: 1625 [45056/54000 (83%)] Loss: -772.852722\n",
      "    epoch          : 1625\n",
      "    loss           : -773.4661479446123\n",
      "    ess            : 1.9610011993714098\n",
      "    log_marginal   : 773.5035083698776\n",
      "    log_joint      : 982.0456917240934\n",
      "    val_loss       : -777.2345072428385\n",
      "    val_ess        : 1.9586033423741658\n",
      "    val_log_marginal: 777.2751057942709\n",
      "    val_log_joint  : 985.8274383544922\n",
      "Train Epoch: 1626 [0/54000 (0%)] Loss: -777.506348\n",
      "Train Epoch: 1626 [11264/54000 (21%)] Loss: -802.054932\n",
      "Train Epoch: 1626 [22528/54000 (42%)] Loss: -779.697693\n",
      "Train Epoch: 1626 [33792/54000 (63%)] Loss: -767.551453\n",
      "Train Epoch: 1626 [45056/54000 (83%)] Loss: -766.844788\n",
      "    epoch          : 1626\n",
      "    loss           : -773.5322018029555\n",
      "    ess            : 1.9594136060408827\n",
      "    log_marginal   : 773.5717157327904\n",
      "    log_joint      : 982.1566547897627\n",
      "    val_loss       : -777.0001424153646\n",
      "    val_ess        : 1.959608515103658\n",
      "    val_log_marginal: 777.0362904866537\n",
      "    val_log_joint  : 985.534657796224\n",
      "Train Epoch: 1627 [0/54000 (0%)] Loss: -783.443726\n",
      "Train Epoch: 1627 [11264/54000 (21%)] Loss: -766.627747\n",
      "Train Epoch: 1627 [22528/54000 (42%)] Loss: -781.177734\n",
      "Train Epoch: 1627 [33792/54000 (63%)] Loss: -753.034912\n",
      "Train Epoch: 1627 [45056/54000 (83%)] Loss: -762.278198\n",
      "    epoch          : 1627\n",
      "    loss           : -773.3675819253021\n",
      "    ess            : 1.9597315192222595\n",
      "    log_marginal   : 773.4077016002727\n",
      "    log_joint      : 981.9912518195387\n",
      "    val_loss       : -777.1963043212891\n",
      "    val_ess        : 1.9612571497758229\n",
      "    val_log_marginal: 777.2336222330729\n",
      "    val_log_joint  : 985.4142100016276\n",
      "Train Epoch: 1628 [0/54000 (0%)] Loss: -781.460449\n",
      "Train Epoch: 1628 [11264/54000 (21%)] Loss: -769.748718\n",
      "Train Epoch: 1628 [22528/54000 (42%)] Loss: -770.500732\n",
      "Train Epoch: 1628 [33792/54000 (63%)] Loss: -785.386841\n",
      "Train Epoch: 1628 [45056/54000 (83%)] Loss: -763.541626\n",
      "    epoch          : 1628\n",
      "    loss           : -773.3740015569723\n",
      "    ess            : 1.9602858300478954\n",
      "    log_marginal   : 773.413301287957\n",
      "    log_joint      : 981.9854246895268\n",
      "    val_loss       : -777.6219482421875\n",
      "    val_ess        : 1.9632290204366047\n",
      "    val_log_marginal: 777.6553599039713\n",
      "    val_log_joint  : 986.2123565673828\n",
      "Train Epoch: 1629 [0/54000 (0%)] Loss: -800.163330\n",
      "Train Epoch: 1629 [11264/54000 (21%)] Loss: -767.348022\n",
      "Train Epoch: 1629 [22528/54000 (42%)] Loss: -774.963135\n",
      "Train Epoch: 1629 [33792/54000 (63%)] Loss: -786.323242\n",
      "Train Epoch: 1629 [45056/54000 (83%)] Loss: -765.265991\n",
      "    epoch          : 1629\n",
      "    loss           : -773.3865431299749\n",
      "    ess            : 1.9591160169187583\n",
      "    log_marginal   : 773.4256516942438\n",
      "    log_joint      : 982.0377727004717\n",
      "    val_loss       : -777.7343190511068\n",
      "    val_ess        : 1.960587352514267\n",
      "    val_log_marginal: 777.7707366943359\n",
      "    val_log_joint  : 986.0298919677734\n",
      "Train Epoch: 1630 [0/54000 (0%)] Loss: -782.848450\n",
      "Train Epoch: 1630 [11264/54000 (21%)] Loss: -747.956299\n",
      "Train Epoch: 1630 [22528/54000 (42%)] Loss: -777.521973\n",
      "Train Epoch: 1630 [33792/54000 (63%)] Loss: -777.051697\n",
      "Train Epoch: 1630 [45056/54000 (83%)] Loss: -787.750366\n",
      "    epoch          : 1630\n",
      "    loss           : -773.4223039735039\n",
      "    ess            : 1.958707388841881\n",
      "    log_marginal   : 773.4613860508181\n",
      "    log_joint      : 982.0608704764888\n",
      "    val_loss       : -777.9612070719401\n",
      "    val_ess        : 1.960975448290507\n",
      "    val_log_marginal: 777.9989115397135\n",
      "    val_log_joint  : 986.6712188720703\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1630.pth ...\n",
      "Train Epoch: 1631 [0/54000 (0%)] Loss: -750.036865\n",
      "Train Epoch: 1631 [11264/54000 (21%)] Loss: -775.554810\n",
      "Train Epoch: 1631 [22528/54000 (42%)] Loss: -765.168579\n",
      "Train Epoch: 1631 [33792/54000 (63%)] Loss: -782.669189\n",
      "Train Epoch: 1631 [45056/54000 (83%)] Loss: -763.041504\n",
      "    epoch          : 1631\n",
      "    loss           : -773.4096961831146\n",
      "    ess            : 1.961659383099034\n",
      "    log_marginal   : 773.4463633411335\n",
      "    log_joint      : 981.8943982394236\n",
      "    val_loss       : -777.2120208740234\n",
      "    val_ess        : 1.9605187276999156\n",
      "    val_log_marginal: 777.2508443196615\n",
      "    val_log_joint  : 985.8114827473959\n",
      "Train Epoch: 1632 [0/54000 (0%)] Loss: -778.570618\n",
      "Train Epoch: 1632 [11264/54000 (21%)] Loss: -780.136597\n",
      "Train Epoch: 1632 [22528/54000 (42%)] Loss: -772.510376\n",
      "Train Epoch: 1632 [33792/54000 (63%)] Loss: -784.327087\n",
      "Train Epoch: 1632 [45056/54000 (83%)] Loss: -776.176147\n",
      "    epoch          : 1632\n",
      "    loss           : -773.6060261276533\n",
      "    ess            : 1.9604531886442653\n",
      "    log_marginal   : 773.6424687223614\n",
      "    log_joint      : 982.166379532724\n",
      "    val_loss       : -777.2880045572916\n",
      "    val_ess        : 1.9602517485618591\n",
      "    val_log_marginal: 777.323964436849\n",
      "    val_log_joint  : 986.0134480794271\n",
      "Train Epoch: 1633 [0/54000 (0%)] Loss: -783.408813\n",
      "Train Epoch: 1633 [11264/54000 (21%)] Loss: -748.483765\n",
      "Train Epoch: 1633 [22528/54000 (42%)] Loss: -786.925720\n",
      "Train Epoch: 1633 [33792/54000 (63%)] Loss: -768.374084\n",
      "Train Epoch: 1633 [45056/54000 (83%)] Loss: -757.417480\n",
      "    epoch          : 1633\n",
      "    loss           : -773.5990830907282\n",
      "    ess            : 1.9616735341413967\n",
      "    log_marginal   : 773.636139491819\n",
      "    log_joint      : 982.2158957427403\n",
      "    val_loss       : -777.9994354248047\n",
      "    val_ess        : 1.9623320599397023\n",
      "    val_log_marginal: 778.0370890299479\n",
      "    val_log_joint  : 986.6226399739584\n",
      "Train Epoch: 1634 [0/54000 (0%)] Loss: -766.557129\n",
      "Train Epoch: 1634 [11264/54000 (21%)] Loss: -766.190247\n",
      "Train Epoch: 1634 [22528/54000 (42%)] Loss: -776.310303\n",
      "Train Epoch: 1634 [33792/54000 (63%)] Loss: -775.367615\n",
      "Train Epoch: 1634 [45056/54000 (83%)] Loss: -775.388184\n",
      "    epoch          : 1634\n",
      "    loss           : -773.6167481620357\n",
      "    ess            : 1.9608675308947294\n",
      "    log_marginal   : 773.6545001335863\n",
      "    log_joint      : 982.2391725936026\n",
      "    val_loss       : -777.3368275960287\n",
      "    val_ess        : 1.9586283961931865\n",
      "    val_log_marginal: 777.3789672851562\n",
      "    val_log_joint  : 985.8301696777344\n",
      "Train Epoch: 1635 [0/54000 (0%)] Loss: -777.696899\n",
      "Train Epoch: 1635 [11264/54000 (21%)] Loss: -774.150635\n",
      "Train Epoch: 1635 [22528/54000 (42%)] Loss: -781.346680\n",
      "Train Epoch: 1635 [33792/54000 (63%)] Loss: -779.738037\n",
      "Train Epoch: 1635 [45056/54000 (83%)] Loss: -781.946289\n",
      "    epoch          : 1635\n",
      "    loss           : -773.753662109375\n",
      "    ess            : 1.9597399077325497\n",
      "    log_marginal   : 773.7916639795843\n",
      "    log_joint      : 982.2376524727299\n",
      "    val_loss       : -777.2188568115234\n",
      "    val_ess        : 1.9592482050259907\n",
      "    val_log_marginal: 777.2620442708334\n",
      "    val_log_joint  : 985.8231150309244\n",
      "Train Epoch: 1636 [0/54000 (0%)] Loss: -779.251465\n",
      "Train Epoch: 1636 [11264/54000 (21%)] Loss: -777.425293\n",
      "Train Epoch: 1636 [22528/54000 (42%)] Loss: -770.320801\n",
      "Train Epoch: 1636 [33792/54000 (63%)] Loss: -768.017700\n",
      "Train Epoch: 1636 [45056/54000 (83%)] Loss: -777.776123\n",
      "    epoch          : 1636\n",
      "    loss           : -773.5640229998894\n",
      "    ess            : 1.9614793422087184\n",
      "    log_marginal   : 773.5998569704452\n",
      "    log_joint      : 982.1626322044516\n",
      "    val_loss       : -777.0071207682291\n",
      "    val_ess        : 1.9621627231438954\n",
      "    val_log_marginal: 777.0418802897135\n",
      "    val_log_joint  : 985.5415649414062\n",
      "Train Epoch: 1637 [0/54000 (0%)] Loss: -769.839172\n",
      "Train Epoch: 1637 [11264/54000 (21%)] Loss: -788.788818\n",
      "Train Epoch: 1637 [22528/54000 (42%)] Loss: -780.270020\n",
      "Train Epoch: 1637 [33792/54000 (63%)] Loss: -784.204407\n",
      "Train Epoch: 1637 [45056/54000 (83%)] Loss: -792.059570\n",
      "    epoch          : 1637\n",
      "    loss           : -773.6493415112766\n",
      "    ess            : 1.960204543932429\n",
      "    log_marginal   : 773.6872017338591\n",
      "    log_joint      : 982.2441129864387\n",
      "    val_loss       : -777.3144734700521\n",
      "    val_ess        : 1.9585186143716176\n",
      "    val_log_marginal: 777.3545633951823\n",
      "    val_log_joint  : 985.8280232747396\n",
      "Train Epoch: 1638 [0/54000 (0%)] Loss: -759.545349\n",
      "Train Epoch: 1638 [11264/54000 (21%)] Loss: -777.374146\n",
      "Train Epoch: 1638 [22528/54000 (42%)] Loss: -775.746216\n",
      "Train Epoch: 1638 [33792/54000 (63%)] Loss: -769.350281\n",
      "Train Epoch: 1638 [45056/54000 (83%)] Loss: -778.317993\n",
      "    epoch          : 1638\n",
      "    loss           : -773.5563740280439\n",
      "    ess            : 1.960905765587429\n",
      "    log_marginal   : 773.594219279739\n",
      "    log_joint      : 981.9752703972582\n",
      "    val_loss       : -777.4500630696615\n",
      "    val_ess        : 1.9623591502507527\n",
      "    val_log_marginal: 777.4850056966146\n",
      "    val_log_joint  : 985.9665069580078\n",
      "Train Epoch: 1639 [0/54000 (0%)] Loss: -796.446045\n",
      "Train Epoch: 1639 [11264/54000 (21%)] Loss: -758.682251\n",
      "Train Epoch: 1639 [22528/54000 (42%)] Loss: -778.946655\n",
      "Train Epoch: 1639 [33792/54000 (63%)] Loss: -755.662781\n",
      "Train Epoch: 1639 [45056/54000 (83%)] Loss: -774.772278\n",
      "    epoch          : 1639\n",
      "    loss           : -773.4938717248305\n",
      "    ess            : 1.961658553132471\n",
      "    log_marginal   : 773.5289991846624\n",
      "    log_joint      : 982.0579977935215\n",
      "    val_loss       : -777.3320058186849\n",
      "    val_ess        : 1.9585307240486145\n",
      "    val_log_marginal: 777.3712870279948\n",
      "    val_log_joint  : 986.0613911946615\n",
      "Train Epoch: 1640 [0/54000 (0%)] Loss: -773.140808\n",
      "Train Epoch: 1640 [11264/54000 (21%)] Loss: -762.965698\n",
      "Train Epoch: 1640 [22528/54000 (42%)] Loss: -762.376099\n",
      "Train Epoch: 1640 [33792/54000 (63%)] Loss: -761.981079\n",
      "Train Epoch: 1640 [45056/54000 (83%)] Loss: -780.072327\n",
      "    epoch          : 1640\n",
      "    loss           : -773.3623824209537\n",
      "    ess            : 1.9599144784909375\n",
      "    log_marginal   : 773.4008005969929\n",
      "    log_joint      : 981.9432211821934\n",
      "    val_loss       : -777.4977264404297\n",
      "    val_ess        : 1.9600509504477184\n",
      "    val_log_marginal: 777.5367075602213\n",
      "    val_log_joint  : 986.0881652832031\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1640.pth ...\n",
      "Train Epoch: 1641 [0/54000 (0%)] Loss: -767.343018\n",
      "Train Epoch: 1641 [11264/54000 (21%)] Loss: -761.479736\n",
      "Train Epoch: 1641 [22528/54000 (42%)] Loss: -776.856323\n",
      "Train Epoch: 1641 [33792/54000 (63%)] Loss: -760.474609\n",
      "Train Epoch: 1641 [45056/54000 (83%)] Loss: -786.595398\n",
      "    epoch          : 1641\n",
      "    loss           : -773.343987806788\n",
      "    ess            : 1.9605797068128046\n",
      "    log_marginal   : 773.382624212301\n",
      "    log_joint      : 981.9507486595297\n",
      "    val_loss       : -777.7917683919271\n",
      "    val_ess        : 1.9624806642532349\n",
      "    val_log_marginal: 777.8271535237631\n",
      "    val_log_joint  : 986.4473368326823\n",
      "Train Epoch: 1642 [0/54000 (0%)] Loss: -774.041748\n",
      "Train Epoch: 1642 [11264/54000 (21%)] Loss: -765.157776\n",
      "Train Epoch: 1642 [22528/54000 (42%)] Loss: -771.746704\n",
      "Train Epoch: 1642 [33792/54000 (63%)] Loss: -767.435303\n",
      "Train Epoch: 1642 [45056/54000 (83%)] Loss: -755.283386\n",
      "    epoch          : 1642\n",
      "    loss           : -773.4265798892615\n",
      "    ess            : 1.9599713761851472\n",
      "    log_marginal   : 773.4639276468529\n",
      "    log_joint      : 981.9589423413547\n",
      "    val_loss       : -778.4918924967448\n",
      "    val_ess        : 1.9589162170886993\n",
      "    val_log_marginal: 778.5305124918619\n",
      "    val_log_joint  : 986.9094594319662\n",
      "Train Epoch: 1643 [0/54000 (0%)] Loss: -769.930542\n",
      "Train Epoch: 1643 [11264/54000 (21%)] Loss: -769.265381\n",
      "Train Epoch: 1643 [22528/54000 (42%)] Loss: -759.749146\n",
      "Train Epoch: 1643 [33792/54000 (63%)] Loss: -765.752686\n",
      "Train Epoch: 1643 [45056/54000 (83%)] Loss: -780.468506\n",
      "    epoch          : 1643\n",
      "    loss           : -773.6635540656324\n",
      "    ess            : 1.9605543849603184\n",
      "    log_marginal   : 773.7004797593603\n",
      "    log_joint      : 982.221038242556\n",
      "    val_loss       : -777.4539693196615\n",
      "    val_ess        : 1.9590233365694683\n",
      "    val_log_marginal: 777.4927368164062\n",
      "    val_log_joint  : 986.2379252115885\n",
      "Train Epoch: 1644 [0/54000 (0%)] Loss: -777.896912\n",
      "Train Epoch: 1644 [11264/54000 (21%)] Loss: -795.450317\n",
      "Train Epoch: 1644 [22528/54000 (42%)] Loss: -743.396606\n",
      "Train Epoch: 1644 [33792/54000 (63%)] Loss: -764.735962\n",
      "Train Epoch: 1644 [45056/54000 (83%)] Loss: -767.664001\n",
      "    epoch          : 1644\n",
      "    loss           : -773.5737333477668\n",
      "    ess            : 1.9610629565310929\n",
      "    log_marginal   : 773.6101517587338\n",
      "    log_joint      : 982.0997533258402\n",
      "    val_loss       : -778.0575103759766\n",
      "    val_ess        : 1.957210123538971\n",
      "    val_log_marginal: 778.0958964029948\n",
      "    val_log_joint  : 986.6189829508463\n",
      "Train Epoch: 1645 [0/54000 (0%)] Loss: -760.934692\n",
      "Train Epoch: 1645 [11264/54000 (21%)] Loss: -770.499634\n",
      "Train Epoch: 1645 [22528/54000 (42%)] Loss: -776.816406\n",
      "Train Epoch: 1645 [33792/54000 (63%)] Loss: -766.358948\n",
      "Train Epoch: 1645 [45056/54000 (83%)] Loss: -769.354980\n",
      "    epoch          : 1645\n",
      "    loss           : -773.5261869610481\n",
      "    ess            : 1.9614282655266095\n",
      "    log_marginal   : 773.5623203493515\n",
      "    log_joint      : 982.025914030255\n",
      "    val_loss       : -778.0226796468099\n",
      "    val_ess        : 1.9597127238909404\n",
      "    val_log_marginal: 778.0612233479818\n",
      "    val_log_joint  : 986.5558420817057\n",
      "Train Epoch: 1646 [0/54000 (0%)] Loss: -758.043457\n",
      "Train Epoch: 1646 [11264/54000 (21%)] Loss: -781.596558\n",
      "Train Epoch: 1646 [22528/54000 (42%)] Loss: -751.794434\n",
      "Train Epoch: 1646 [33792/54000 (63%)] Loss: -784.234436\n",
      "Train Epoch: 1646 [45056/54000 (83%)] Loss: -764.648865\n",
      "    epoch          : 1646\n",
      "    loss           : -773.5270950029482\n",
      "    ess            : 1.9613168655701403\n",
      "    log_marginal   : 773.5631932672464\n",
      "    log_joint      : 982.1440539090139\n",
      "    val_loss       : -776.5139719645182\n",
      "    val_ess        : 1.962951769431432\n",
      "    val_log_marginal: 776.5473683675131\n",
      "    val_log_joint  : 985.1485392252604\n",
      "Train Epoch: 1647 [0/54000 (0%)] Loss: -775.144409\n",
      "Train Epoch: 1647 [11264/54000 (21%)] Loss: -756.563904\n",
      "Train Epoch: 1647 [22528/54000 (42%)] Loss: -752.439514\n",
      "Train Epoch: 1647 [33792/54000 (63%)] Loss: -789.490479\n",
      "Train Epoch: 1647 [45056/54000 (83%)] Loss: -757.379761\n",
      "    epoch          : 1647\n",
      "    loss           : -773.5279736788767\n",
      "    ess            : 1.961869736887374\n",
      "    log_marginal   : 773.562870241561\n",
      "    log_joint      : 982.0223037431825\n",
      "    val_loss       : -778.1738586425781\n",
      "    val_ess        : 1.9609192311763763\n",
      "    val_log_marginal: 778.2095235188802\n",
      "    val_log_joint  : 986.6295674641927\n",
      "Train Epoch: 1648 [0/54000 (0%)] Loss: -785.293152\n",
      "Train Epoch: 1648 [11264/54000 (21%)] Loss: -758.131836\n",
      "Train Epoch: 1648 [22528/54000 (42%)] Loss: -782.212158\n",
      "Train Epoch: 1648 [33792/54000 (63%)] Loss: -765.449036\n",
      "Train Epoch: 1648 [45056/54000 (83%)] Loss: -759.340576\n",
      "    epoch          : 1648\n",
      "    loss           : -773.3720461287588\n",
      "    ess            : 1.9602012263154083\n",
      "    log_marginal   : 773.409423828125\n",
      "    log_joint      : 982.0517624189268\n",
      "    val_loss       : -777.8640848795573\n",
      "    val_ess        : 1.9619871477286022\n",
      "    val_log_marginal: 777.8959554036459\n",
      "    val_log_joint  : 986.4070434570312\n",
      "Train Epoch: 1649 [0/54000 (0%)] Loss: -760.198730\n",
      "Train Epoch: 1649 [11264/54000 (21%)] Loss: -774.932129\n",
      "Train Epoch: 1649 [22528/54000 (42%)] Loss: -772.922791\n",
      "Train Epoch: 1649 [33792/54000 (63%)] Loss: -780.998291\n",
      "Train Epoch: 1649 [45056/54000 (83%)] Loss: -774.841064\n",
      "    epoch          : 1649\n",
      "    loss           : -773.9199126621462\n",
      "    ess            : 1.960426925488238\n",
      "    log_marginal   : 773.9574118560215\n",
      "    log_joint      : 982.462255513893\n",
      "    val_loss       : -777.6363423665365\n",
      "    val_ess        : 1.960226575533549\n",
      "    val_log_marginal: 777.6752471923828\n",
      "    val_log_joint  : 986.186269124349\n",
      "Train Epoch: 1650 [0/54000 (0%)] Loss: -782.994263\n",
      "Train Epoch: 1650 [11264/54000 (21%)] Loss: -760.223633\n",
      "Train Epoch: 1650 [22528/54000 (42%)] Loss: -797.371094\n",
      "Train Epoch: 1650 [33792/54000 (63%)] Loss: -773.442261\n",
      "Train Epoch: 1650 [45056/54000 (83%)] Loss: -778.460144\n",
      "    epoch          : 1650\n",
      "    loss           : -773.7149226350605\n",
      "    ess            : 1.9605834765254326\n",
      "    log_marginal   : 773.7523475503021\n",
      "    log_joint      : 982.2256550339033\n",
      "    val_loss       : -777.3869120279948\n",
      "    val_ess        : 1.9630123376846313\n",
      "    val_log_marginal: 777.4220886230469\n",
      "    val_log_joint  : 986.1897430419922\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1650.pth ...\n",
      "Train Epoch: 1651 [0/54000 (0%)] Loss: -777.200562\n",
      "Train Epoch: 1651 [11264/54000 (21%)] Loss: -787.531189\n",
      "Train Epoch: 1651 [22528/54000 (42%)] Loss: -792.541870\n",
      "Train Epoch: 1651 [33792/54000 (63%)] Loss: -772.614746\n",
      "Train Epoch: 1651 [45056/54000 (83%)] Loss: -786.283997\n",
      "    epoch          : 1651\n",
      "    loss           : -773.7451494324882\n",
      "    ess            : 1.9608139755590908\n",
      "    log_marginal   : 773.781549993551\n",
      "    log_joint      : 982.3531557478995\n",
      "    val_loss       : -777.4495697021484\n",
      "    val_ess        : 1.9622397025426228\n",
      "    val_log_marginal: 777.4876963297526\n",
      "    val_log_joint  : 986.0580393473307\n",
      "Train Epoch: 1652 [0/54000 (0%)] Loss: -764.327637\n",
      "Train Epoch: 1652 [11264/54000 (21%)] Loss: -761.069458\n",
      "Train Epoch: 1652 [22528/54000 (42%)] Loss: -779.116455\n",
      "Train Epoch: 1652 [33792/54000 (63%)] Loss: -765.138550\n",
      "Train Epoch: 1652 [45056/54000 (83%)] Loss: -779.074097\n",
      "    epoch          : 1652\n",
      "    loss           : -773.6649440549454\n",
      "    ess            : 1.9607822254018963\n",
      "    log_marginal   : 773.7012870356722\n",
      "    log_joint      : 982.1819515588148\n",
      "    val_loss       : -778.1855061848959\n",
      "    val_ess        : 1.9635313550631206\n",
      "    val_log_marginal: 778.2197774251302\n",
      "    val_log_joint  : 986.6207885742188\n",
      "Train Epoch: 1653 [0/54000 (0%)] Loss: -787.739380\n",
      "Train Epoch: 1653 [11264/54000 (21%)] Loss: -801.939148\n",
      "Train Epoch: 1653 [22528/54000 (42%)] Loss: -781.353760\n",
      "Train Epoch: 1653 [33792/54000 (63%)] Loss: -776.873047\n",
      "Train Epoch: 1653 [45056/54000 (83%)] Loss: -781.426697\n",
      "    epoch          : 1653\n",
      "    loss           : -773.6399703115787\n",
      "    ess            : 1.9605454363912906\n",
      "    log_marginal   : 773.6780919488871\n",
      "    log_joint      : 982.1953723835495\n",
      "    val_loss       : -777.8387858072916\n",
      "    val_ess        : 1.9601415892442067\n",
      "    val_log_marginal: 777.8781178792318\n",
      "    val_log_joint  : 986.4419606526693\n",
      "Train Epoch: 1654 [0/54000 (0%)] Loss: -776.886963\n",
      "Train Epoch: 1654 [11264/54000 (21%)] Loss: -792.239136\n",
      "Train Epoch: 1654 [22528/54000 (42%)] Loss: -774.521606\n",
      "Train Epoch: 1654 [33792/54000 (63%)] Loss: -782.164246\n",
      "Train Epoch: 1654 [45056/54000 (83%)] Loss: -785.952026\n",
      "    epoch          : 1654\n",
      "    loss           : -773.7293562979069\n",
      "    ess            : 1.9602600459782582\n",
      "    log_marginal   : 773.7667564536041\n",
      "    log_joint      : 982.2837593510466\n",
      "    val_loss       : -777.2677968343099\n",
      "    val_ess        : 1.9581747551759083\n",
      "    val_log_marginal: 777.3090565999349\n",
      "    val_log_joint  : 985.7762095133463\n",
      "Train Epoch: 1655 [0/54000 (0%)] Loss: -767.536377\n",
      "Train Epoch: 1655 [11264/54000 (21%)] Loss: -748.201538\n",
      "Train Epoch: 1655 [22528/54000 (42%)] Loss: -790.688232\n",
      "Train Epoch: 1655 [33792/54000 (63%)] Loss: -768.874023\n",
      "Train Epoch: 1655 [45056/54000 (83%)] Loss: -766.507996\n",
      "    epoch          : 1655\n",
      "    loss           : -773.5814560224425\n",
      "    ess            : 1.9611797557686859\n",
      "    log_marginal   : 773.6188095380675\n",
      "    log_joint      : 982.1226328723835\n",
      "    val_loss       : -777.9296569824219\n",
      "    val_ess        : 1.9622751573721569\n",
      "    val_log_marginal: 777.9677022298177\n",
      "    val_log_joint  : 986.5475819905599\n",
      "Train Epoch: 1656 [0/54000 (0%)] Loss: -791.214233\n",
      "Train Epoch: 1656 [11264/54000 (21%)] Loss: -773.981323\n",
      "Train Epoch: 1656 [22528/54000 (42%)] Loss: -803.034424\n",
      "Train Epoch: 1656 [33792/54000 (63%)] Loss: -783.091187\n",
      "Train Epoch: 1656 [45056/54000 (83%)] Loss: -776.549561\n",
      "    epoch          : 1656\n",
      "    loss           : -773.4540128887825\n",
      "    ess            : 1.9607526491273124\n",
      "    log_marginal   : 773.491616303066\n",
      "    log_joint      : 982.0541347287735\n",
      "    val_loss       : -777.9682312011719\n",
      "    val_ess        : 1.959414501984914\n",
      "    val_log_marginal: 778.0069376627604\n",
      "    val_log_joint  : 986.6521759033203\n",
      "Train Epoch: 1657 [0/54000 (0%)] Loss: -785.625061\n",
      "Train Epoch: 1657 [11264/54000 (21%)] Loss: -777.577393\n",
      "Train Epoch: 1657 [22528/54000 (42%)] Loss: -793.817505\n",
      "Train Epoch: 1657 [33792/54000 (63%)] Loss: -768.084167\n",
      "Train Epoch: 1657 [45056/54000 (83%)] Loss: -775.191833\n",
      "    epoch          : 1657\n",
      "    loss           : -773.5031012769016\n",
      "    ess            : 1.9603584532467824\n",
      "    log_marginal   : 773.5411814563679\n",
      "    log_joint      : 982.0936002911262\n",
      "    val_loss       : -777.8745371500651\n",
      "    val_ess        : 1.9612565338611603\n",
      "    val_log_marginal: 777.9086507161459\n",
      "    val_log_joint  : 986.6225535074869\n",
      "Train Epoch: 1658 [0/54000 (0%)] Loss: -784.132935\n",
      "Train Epoch: 1658 [11264/54000 (21%)] Loss: -767.921082\n",
      "Train Epoch: 1658 [22528/54000 (42%)] Loss: -776.549316\n",
      "Train Epoch: 1658 [33792/54000 (63%)] Loss: -782.882202\n",
      "Train Epoch: 1658 [45056/54000 (83%)] Loss: -778.269226\n",
      "    epoch          : 1658\n",
      "    loss           : -773.6258798275354\n",
      "    ess            : 1.9608299124915645\n",
      "    log_marginal   : 773.6623771235628\n",
      "    log_joint      : 982.1306250230322\n",
      "    val_loss       : -778.0444183349609\n",
      "    val_ess        : 1.9571786920229595\n",
      "    val_log_marginal: 778.0879414876302\n",
      "    val_log_joint  : 986.3914540608724\n",
      "Train Epoch: 1659 [0/54000 (0%)] Loss: -782.514282\n",
      "Train Epoch: 1659 [11264/54000 (21%)] Loss: -781.073059\n",
      "Train Epoch: 1659 [22528/54000 (42%)] Loss: -763.447693\n",
      "Train Epoch: 1659 [33792/54000 (63%)] Loss: -776.945557\n",
      "Train Epoch: 1659 [45056/54000 (83%)] Loss: -778.963806\n",
      "    epoch          : 1659\n",
      "    loss           : -773.7670432036778\n",
      "    ess            : 1.9611919218639158\n",
      "    log_marginal   : 773.8033971246683\n",
      "    log_joint      : 982.2567795087706\n",
      "    val_loss       : -777.909423828125\n",
      "    val_ess        : 1.9627674122651417\n",
      "    val_log_marginal: 777.9486440022787\n",
      "    val_log_joint  : 986.6663004557291\n",
      "Train Epoch: 1660 [0/54000 (0%)] Loss: -801.556458\n",
      "Train Epoch: 1660 [11264/54000 (21%)] Loss: -782.144409\n",
      "Train Epoch: 1660 [22528/54000 (42%)] Loss: -763.573730\n",
      "Train Epoch: 1660 [33792/54000 (63%)] Loss: -771.043823\n",
      "Train Epoch: 1660 [45056/54000 (83%)] Loss: -782.766174\n",
      "    epoch          : 1660\n",
      "    loss           : -773.5863054383476\n",
      "    ess            : 1.9608170525083002\n",
      "    log_marginal   : 773.6238835172833\n",
      "    log_joint      : 982.1818116385982\n",
      "    val_loss       : -778.6458180745443\n",
      "    val_ess        : 1.9627959728240967\n",
      "    val_log_marginal: 778.6837717692057\n",
      "    val_log_joint  : 987.0910034179688\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1660.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1661 [0/54000 (0%)] Loss: -779.699219\n",
      "Train Epoch: 1661 [11264/54000 (21%)] Loss: -774.641541\n",
      "Train Epoch: 1661 [22528/54000 (42%)] Loss: -781.257690\n",
      "Train Epoch: 1661 [33792/54000 (63%)] Loss: -753.006348\n",
      "Train Epoch: 1661 [45056/54000 (83%)] Loss: -786.594971\n",
      "    epoch          : 1661\n",
      "    loss           : -773.592653670401\n",
      "    ess            : 1.9590841149384122\n",
      "    log_marginal   : 773.6318572422243\n",
      "    log_joint      : 982.2197899008697\n",
      "    val_loss       : -777.8113301595052\n",
      "    val_ess        : 1.9626130163669586\n",
      "    val_log_marginal: 777.8452453613281\n",
      "    val_log_joint  : 986.5535939534506\n",
      "Train Epoch: 1662 [0/54000 (0%)] Loss: -793.435608\n",
      "Train Epoch: 1662 [11264/54000 (21%)] Loss: -760.506531\n",
      "Train Epoch: 1662 [22528/54000 (42%)] Loss: -803.106567\n",
      "Train Epoch: 1662 [33792/54000 (63%)] Loss: -780.710449\n",
      "Train Epoch: 1662 [45056/54000 (83%)] Loss: -758.345154\n",
      "    epoch          : 1662\n",
      "    loss           : -773.541330013635\n",
      "    ess            : 1.9606258700478751\n",
      "    log_marginal   : 773.5786109780365\n",
      "    log_joint      : 982.0862743449661\n",
      "    val_loss       : -777.5571492513021\n",
      "    val_ess        : 1.963228036959966\n",
      "    val_log_marginal: 777.5911254882812\n",
      "    val_log_joint  : 986.0305430094401\n",
      "Train Epoch: 1663 [0/54000 (0%)] Loss: -805.228577\n",
      "Train Epoch: 1663 [11264/54000 (21%)] Loss: -781.711670\n",
      "Train Epoch: 1663 [22528/54000 (42%)] Loss: -749.632446\n",
      "Train Epoch: 1663 [33792/54000 (63%)] Loss: -786.847778\n",
      "Train Epoch: 1663 [45056/54000 (83%)] Loss: -772.114380\n",
      "    epoch          : 1663\n",
      "    loss           : -773.6131810602152\n",
      "    ess            : 1.9612995959677786\n",
      "    log_marginal   : 773.6506773750737\n",
      "    log_joint      : 982.1846474701504\n",
      "    val_loss       : -777.7170003255209\n",
      "    val_ess        : 1.959616889556249\n",
      "    val_log_marginal: 777.7538553873698\n",
      "    val_log_joint  : 986.3360188802084\n",
      "Train Epoch: 1664 [0/54000 (0%)] Loss: -770.713623\n",
      "Train Epoch: 1664 [11264/54000 (21%)] Loss: -753.688110\n",
      "Train Epoch: 1664 [22528/54000 (42%)] Loss: -783.480225\n",
      "Train Epoch: 1664 [33792/54000 (63%)] Loss: -784.911133\n",
      "Train Epoch: 1664 [45056/54000 (83%)] Loss: -769.236084\n",
      "    epoch          : 1664\n",
      "    loss           : -773.5806481703272\n",
      "    ess            : 1.961179699537889\n",
      "    log_marginal   : 773.6162794580999\n",
      "    log_joint      : 982.1431982652197\n",
      "    val_loss       : -778.0607248942057\n",
      "    val_ess        : 1.960070163011551\n",
      "    val_log_marginal: 778.0978495279948\n",
      "    val_log_joint  : 986.5493825276693\n",
      "Train Epoch: 1665 [0/54000 (0%)] Loss: -783.182251\n",
      "Train Epoch: 1665 [11264/54000 (21%)] Loss: -781.366089\n",
      "Train Epoch: 1665 [22528/54000 (42%)] Loss: -760.616333\n",
      "Train Epoch: 1665 [33792/54000 (63%)] Loss: -747.336304\n",
      "Train Epoch: 1665 [45056/54000 (83%)] Loss: -770.460571\n",
      "    epoch          : 1665\n",
      "    loss           : -773.6603036556604\n",
      "    ess            : 1.960810456635817\n",
      "    log_marginal   : 773.6988139602373\n",
      "    log_joint      : 982.2640812711895\n",
      "    val_loss       : -777.2328898111979\n",
      "    val_ess        : 1.963133802016576\n",
      "    val_log_marginal: 777.271494547526\n",
      "    val_log_joint  : 985.9152781168619\n",
      "Train Epoch: 1666 [0/54000 (0%)] Loss: -775.044067\n",
      "Train Epoch: 1666 [11264/54000 (21%)] Loss: -774.825745\n",
      "Train Epoch: 1666 [22528/54000 (42%)] Loss: -777.782349\n",
      "Train Epoch: 1666 [33792/54000 (63%)] Loss: -783.280029\n",
      "Train Epoch: 1666 [45056/54000 (83%)] Loss: -751.715820\n",
      "    epoch          : 1666\n",
      "    loss           : -773.6700387630823\n",
      "    ess            : 1.961434838906774\n",
      "    log_marginal   : 773.705997107164\n",
      "    log_joint      : 982.1918582556383\n",
      "    val_loss       : -777.7024688720703\n",
      "    val_ess        : 1.960960070292155\n",
      "    val_log_marginal: 777.7372487386068\n",
      "    val_log_joint  : 986.3729705810547\n",
      "Train Epoch: 1667 [0/54000 (0%)] Loss: -788.216797\n",
      "Train Epoch: 1667 [11264/54000 (21%)] Loss: -783.599609\n",
      "Train Epoch: 1667 [22528/54000 (42%)] Loss: -750.116455\n",
      "Train Epoch: 1667 [33792/54000 (63%)] Loss: -784.018677\n",
      "Train Epoch: 1667 [45056/54000 (83%)] Loss: -768.065552\n",
      "    epoch          : 1667\n",
      "    loss           : -773.6513982808815\n",
      "    ess            : 1.9598685311821271\n",
      "    log_marginal   : 773.6896552319797\n",
      "    log_joint      : 982.2607341262529\n",
      "    val_loss       : -778.0606740315756\n",
      "    val_ess        : 1.9623837272326152\n",
      "    val_log_marginal: 778.0958099365234\n",
      "    val_log_joint  : 986.7396901448568\n",
      "Train Epoch: 1668 [0/54000 (0%)] Loss: -790.901733\n",
      "Train Epoch: 1668 [11264/54000 (21%)] Loss: -759.856140\n",
      "Train Epoch: 1668 [22528/54000 (42%)] Loss: -766.840942\n",
      "Train Epoch: 1668 [33792/54000 (63%)] Loss: -771.521484\n",
      "Train Epoch: 1668 [45056/54000 (83%)] Loss: -773.803833\n",
      "    epoch          : 1668\n",
      "    loss           : -773.7081212457621\n",
      "    ess            : 1.9609969696908627\n",
      "    log_marginal   : 773.7454799436173\n",
      "    log_joint      : 982.2031324854437\n",
      "    val_loss       : -777.9105936686198\n",
      "    val_ess        : 1.9628378053506215\n",
      "    val_log_marginal: 777.9441528320312\n",
      "    val_log_joint  : 986.4369455973307\n",
      "Train Epoch: 1669 [0/54000 (0%)] Loss: -765.168945\n",
      "Train Epoch: 1669 [11264/54000 (21%)] Loss: -770.614258\n",
      "Train Epoch: 1669 [22528/54000 (42%)] Loss: -764.120728\n",
      "Train Epoch: 1669 [33792/54000 (63%)] Loss: -759.031006\n",
      "Train Epoch: 1669 [45056/54000 (83%)] Loss: -775.574463\n",
      "    epoch          : 1669\n",
      "    loss           : -773.7372948988428\n",
      "    ess            : 1.9609698079667002\n",
      "    log_marginal   : 773.7741019770784\n",
      "    log_joint      : 982.1610331985186\n",
      "    val_loss       : -777.7040710449219\n",
      "    val_ess        : 1.9594441552956898\n",
      "    val_log_marginal: 777.7468872070312\n",
      "    val_log_joint  : 986.341552734375\n",
      "Train Epoch: 1670 [0/54000 (0%)] Loss: -777.315857\n",
      "Train Epoch: 1670 [11264/54000 (21%)] Loss: -794.752563\n",
      "Train Epoch: 1670 [22528/54000 (42%)] Loss: -772.617249\n",
      "Train Epoch: 1670 [33792/54000 (63%)] Loss: -768.957275\n",
      "Train Epoch: 1670 [45056/54000 (83%)] Loss: -763.224365\n",
      "    epoch          : 1670\n",
      "    loss           : -773.8355160119398\n",
      "    ess            : 1.9607228704218596\n",
      "    log_marginal   : 773.8726708754053\n",
      "    log_joint      : 982.4102069206957\n",
      "    val_loss       : -777.7496846516927\n",
      "    val_ess        : 1.9616135756174724\n",
      "    val_log_marginal: 777.7884267171224\n",
      "    val_log_joint  : 986.1184743245443\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1670.pth ...\n",
      "Train Epoch: 1671 [0/54000 (0%)] Loss: -781.098755\n",
      "Train Epoch: 1671 [11264/54000 (21%)] Loss: -767.346008\n",
      "Train Epoch: 1671 [22528/54000 (42%)] Loss: -759.521667\n",
      "Train Epoch: 1671 [33792/54000 (63%)] Loss: -773.673218\n",
      "Train Epoch: 1671 [45056/54000 (83%)] Loss: -757.250183\n",
      "    epoch          : 1671\n",
      "    loss           : -773.622515408498\n",
      "    ess            : 1.9611321170375031\n",
      "    log_marginal   : 773.6588462973541\n",
      "    log_joint      : 982.1815243127211\n",
      "    val_loss       : -778.1733957926432\n",
      "    val_ess        : 1.9612435698509216\n",
      "    val_log_marginal: 778.2056223551432\n",
      "    val_log_joint  : 986.5631052652994\n",
      "Train Epoch: 1672 [0/54000 (0%)] Loss: -793.858704\n",
      "Train Epoch: 1672 [11264/54000 (21%)] Loss: -808.490112\n",
      "Train Epoch: 1672 [22528/54000 (42%)] Loss: -783.500549\n",
      "Train Epoch: 1672 [33792/54000 (63%)] Loss: -767.434570\n",
      "Train Epoch: 1672 [45056/54000 (83%)] Loss: -764.847534\n",
      "    epoch          : 1672\n",
      "    loss           : -773.8197585771669\n",
      "    ess            : 1.9612829100410893\n",
      "    log_marginal   : 773.8568051896005\n",
      "    log_joint      : 982.3687156821197\n",
      "    val_loss       : -778.2859649658203\n",
      "    val_ess        : 1.9602777163187664\n",
      "    val_log_marginal: 778.3225504557291\n",
      "    val_log_joint  : 986.9404347737631\n",
      "Train Epoch: 1673 [0/54000 (0%)] Loss: -780.147827\n",
      "Train Epoch: 1673 [11264/54000 (21%)] Loss: -772.975952\n",
      "Train Epoch: 1673 [22528/54000 (42%)] Loss: -779.532288\n",
      "Train Epoch: 1673 [33792/54000 (63%)] Loss: -749.792358\n",
      "Train Epoch: 1673 [45056/54000 (83%)] Loss: -744.301392\n",
      "    epoch          : 1673\n",
      "    loss           : -773.681276717276\n",
      "    ess            : 1.9597969572499114\n",
      "    log_marginal   : 773.7196494048496\n",
      "    log_joint      : 982.3048556345814\n",
      "    val_loss       : -777.5383656819662\n",
      "    val_ess        : 1.9618804256121318\n",
      "    val_log_marginal: 777.5733642578125\n",
      "    val_log_joint  : 985.9661102294922\n",
      "Train Epoch: 1674 [0/54000 (0%)] Loss: -754.305298\n",
      "Train Epoch: 1674 [11264/54000 (21%)] Loss: -781.405762\n",
      "Train Epoch: 1674 [22528/54000 (42%)] Loss: -791.699951\n",
      "Train Epoch: 1674 [33792/54000 (63%)] Loss: -738.624023\n",
      "Train Epoch: 1674 [45056/54000 (83%)] Loss: -780.477905\n",
      "    epoch          : 1674\n",
      "    loss           : -773.7637795502285\n",
      "    ess            : 1.960382545894047\n",
      "    log_marginal   : 773.8021372669148\n",
      "    log_joint      : 982.2629503933889\n",
      "    val_loss       : -777.5649719238281\n",
      "    val_ess        : 1.9592849214871724\n",
      "    val_log_marginal: 777.6044514973959\n",
      "    val_log_joint  : 985.9937642415365\n",
      "Train Epoch: 1675 [0/54000 (0%)] Loss: -739.491638\n",
      "Train Epoch: 1675 [11264/54000 (21%)] Loss: -782.281555\n",
      "Train Epoch: 1675 [22528/54000 (42%)] Loss: -772.606323\n",
      "Train Epoch: 1675 [33792/54000 (63%)] Loss: -791.666870\n",
      "Train Epoch: 1675 [45056/54000 (83%)] Loss: -766.612915\n",
      "    epoch          : 1675\n",
      "    loss           : -773.5731028430866\n",
      "    ess            : 1.9609543467467685\n",
      "    log_marginal   : 773.6108887870357\n",
      "    log_joint      : 982.139669166421\n",
      "    val_loss       : -778.2812347412109\n",
      "    val_ess        : 1.9594266215960185\n",
      "    val_log_marginal: 778.3229217529297\n",
      "    val_log_joint  : 986.6907806396484\n",
      "Train Epoch: 1676 [0/54000 (0%)] Loss: -759.458252\n",
      "Train Epoch: 1676 [11264/54000 (21%)] Loss: -767.996826\n",
      "Train Epoch: 1676 [22528/54000 (42%)] Loss: -766.608826\n",
      "Train Epoch: 1676 [33792/54000 (63%)] Loss: -769.303345\n",
      "Train Epoch: 1676 [45056/54000 (83%)] Loss: -769.507568\n",
      "    epoch          : 1676\n",
      "    loss           : -773.5712833044664\n",
      "    ess            : 1.9606975496939893\n",
      "    log_marginal   : 773.6086604280292\n",
      "    log_joint      : 982.2043336112545\n",
      "    val_loss       : -778.0136108398438\n",
      "    val_ess        : 1.960866282383601\n",
      "    val_log_marginal: 778.0511423746744\n",
      "    val_log_joint  : 986.5007680257162\n",
      "Train Epoch: 1677 [0/54000 (0%)] Loss: -794.921021\n",
      "Train Epoch: 1677 [11264/54000 (21%)] Loss: -774.330750\n",
      "Train Epoch: 1677 [22528/54000 (42%)] Loss: -773.448975\n",
      "Train Epoch: 1677 [33792/54000 (63%)] Loss: -779.093201\n",
      "Train Epoch: 1677 [45056/54000 (83%)] Loss: -781.752869\n",
      "    epoch          : 1677\n",
      "    loss           : -773.6844833661925\n",
      "    ess            : 1.9610347714064256\n",
      "    log_marginal   : 773.7221731509802\n",
      "    log_joint      : 982.2850739101194\n",
      "    val_loss       : -777.2286834716797\n",
      "    val_ess        : 1.959586371978124\n",
      "    val_log_marginal: 777.2649332682291\n",
      "    val_log_joint  : 985.7637278238932\n",
      "Train Epoch: 1678 [0/54000 (0%)] Loss: -773.703857\n",
      "Train Epoch: 1678 [11264/54000 (21%)] Loss: -774.449768\n",
      "Train Epoch: 1678 [22528/54000 (42%)] Loss: -778.072998\n",
      "Train Epoch: 1678 [33792/54000 (63%)] Loss: -767.746887\n",
      "Train Epoch: 1678 [45056/54000 (83%)] Loss: -761.517212\n",
      "    epoch          : 1678\n",
      "    loss           : -773.7966798026607\n",
      "    ess            : 1.9611377187494963\n",
      "    log_marginal   : 773.8324400703862\n",
      "    log_joint      : 982.2979223863134\n",
      "    val_loss       : -777.4381510416666\n",
      "    val_ess        : 1.9617749055226643\n",
      "    val_log_marginal: 777.4719848632812\n",
      "    val_log_joint  : 986.2040863037109\n",
      "Train Epoch: 1679 [0/54000 (0%)] Loss: -767.946838\n",
      "Train Epoch: 1679 [11264/54000 (21%)] Loss: -768.699829\n",
      "Train Epoch: 1679 [22528/54000 (42%)] Loss: -789.665161\n",
      "Train Epoch: 1679 [33792/54000 (63%)] Loss: -791.235229\n",
      "Train Epoch: 1679 [45056/54000 (83%)] Loss: -794.148010\n",
      "    epoch          : 1679\n",
      "    loss           : -773.6197158525575\n",
      "    ess            : 1.96042174888107\n",
      "    log_marginal   : 773.657185104658\n",
      "    log_joint      : 982.1640262243883\n",
      "    val_loss       : -778.3918151855469\n",
      "    val_ess        : 1.9612435400485992\n",
      "    val_log_marginal: 778.427500406901\n",
      "    val_log_joint  : 987.0435485839844\n",
      "Train Epoch: 1680 [0/54000 (0%)] Loss: -779.592346\n",
      "Train Epoch: 1680 [11264/54000 (21%)] Loss: -791.166748\n",
      "Train Epoch: 1680 [22528/54000 (42%)] Loss: -792.220337\n",
      "Train Epoch: 1680 [33792/54000 (63%)] Loss: -773.065918\n",
      "Train Epoch: 1680 [45056/54000 (83%)] Loss: -793.322754\n",
      "    epoch          : 1680\n",
      "    loss           : -773.656843653265\n",
      "    ess            : 1.9602287951505408\n",
      "    log_marginal   : 773.6948679798054\n",
      "    log_joint      : 982.2298019697081\n",
      "    val_loss       : -777.3644765218099\n",
      "    val_ess        : 1.9619991580645244\n",
      "    val_log_marginal: 777.4013519287109\n",
      "    val_log_joint  : 985.8938852945963\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1680.pth ...\n",
      "Train Epoch: 1681 [0/54000 (0%)] Loss: -772.389099\n",
      "Train Epoch: 1681 [11264/54000 (21%)] Loss: -774.974792\n",
      "Train Epoch: 1681 [22528/54000 (42%)] Loss: -776.954712\n",
      "Train Epoch: 1681 [33792/54000 (63%)] Loss: -776.952942\n",
      "Train Epoch: 1681 [45056/54000 (83%)] Loss: -758.426819\n",
      "    epoch          : 1681\n",
      "    loss           : -773.768569082584\n",
      "    ess            : 1.9610757456635528\n",
      "    log_marginal   : 773.805746978184\n",
      "    log_joint      : 982.2929906305277\n",
      "    val_loss       : -777.5635681152344\n",
      "    val_ess        : 1.9620960056781769\n",
      "    val_log_marginal: 777.5967000325521\n",
      "    val_log_joint  : 986.1961517333984\n",
      "Train Epoch: 1682 [0/54000 (0%)] Loss: -776.083374\n",
      "Train Epoch: 1682 [11264/54000 (21%)] Loss: -782.405273\n",
      "Train Epoch: 1682 [22528/54000 (42%)] Loss: -773.179016\n",
      "Train Epoch: 1682 [33792/54000 (63%)] Loss: -781.996155\n",
      "Train Epoch: 1682 [45056/54000 (83%)] Loss: -783.688171\n",
      "    epoch          : 1682\n",
      "    loss           : -773.9607670622052\n",
      "    ess            : 1.9609076358237356\n",
      "    log_marginal   : 773.9976397820238\n",
      "    log_joint      : 982.510051223467\n",
      "    val_loss       : -778.2573038736979\n",
      "    val_ess        : 1.9627721309661865\n",
      "    val_log_marginal: 778.2933654785156\n",
      "    val_log_joint  : 986.7689971923828\n",
      "Train Epoch: 1683 [0/54000 (0%)] Loss: -773.859497\n",
      "Train Epoch: 1683 [11264/54000 (21%)] Loss: -811.574158\n",
      "Train Epoch: 1683 [22528/54000 (42%)] Loss: -778.781799\n",
      "Train Epoch: 1683 [33792/54000 (63%)] Loss: -772.322876\n",
      "Train Epoch: 1683 [45056/54000 (83%)] Loss: -761.416260\n",
      "    epoch          : 1683\n",
      "    loss           : -773.8896161925118\n",
      "    ess            : 1.9623641765342568\n",
      "    log_marginal   : 773.9246734043337\n",
      "    log_joint      : 982.4020126630675\n",
      "    val_loss       : -778.4039052327474\n",
      "    val_ess        : 1.9608402649561565\n",
      "    val_log_marginal: 778.4409383138021\n",
      "    val_log_joint  : 987.1051381429037\n",
      "Train Epoch: 1684 [0/54000 (0%)] Loss: -765.037720\n",
      "Train Epoch: 1684 [11264/54000 (21%)] Loss: -794.380432\n",
      "Train Epoch: 1684 [22528/54000 (42%)] Loss: -763.641724\n",
      "Train Epoch: 1684 [33792/54000 (63%)] Loss: -767.012268\n",
      "Train Epoch: 1684 [45056/54000 (83%)] Loss: -764.282654\n",
      "    epoch          : 1684\n",
      "    loss           : -773.9168275077388\n",
      "    ess            : 1.9615248801573268\n",
      "    log_marginal   : 773.9524110038326\n",
      "    log_joint      : 982.3964958910672\n",
      "    val_loss       : -777.5701497395834\n",
      "    val_ess        : 1.9647470812002819\n",
      "    val_log_marginal: 777.6030782063802\n",
      "    val_log_joint  : 986.5575968424479\n",
      "Train Epoch: 1685 [0/54000 (0%)] Loss: -782.640930\n",
      "Train Epoch: 1685 [11264/54000 (21%)] Loss: -776.582825\n",
      "Train Epoch: 1685 [22528/54000 (42%)] Loss: -766.339905\n",
      "Train Epoch: 1685 [33792/54000 (63%)] Loss: -783.048828\n",
      "Train Epoch: 1685 [45056/54000 (83%)] Loss: -762.793396\n",
      "    epoch          : 1685\n",
      "    loss           : -773.6812197127432\n",
      "    ess            : 1.9603352400491822\n",
      "    log_marginal   : 773.7197622623083\n",
      "    log_joint      : 982.2632993302255\n",
      "    val_loss       : -778.0523122151693\n",
      "    val_ess        : 1.961716204881668\n",
      "    val_log_marginal: 778.0871022542318\n",
      "    val_log_joint  : 986.5141245524088\n",
      "Train Epoch: 1686 [0/54000 (0%)] Loss: -790.641724\n",
      "Train Epoch: 1686 [11264/54000 (21%)] Loss: -771.426453\n",
      "Train Epoch: 1686 [22528/54000 (42%)] Loss: -783.409546\n",
      "Train Epoch: 1686 [33792/54000 (63%)] Loss: -767.177979\n",
      "Train Epoch: 1686 [45056/54000 (83%)] Loss: -774.985413\n",
      "    epoch          : 1686\n",
      "    loss           : -773.8537505527712\n",
      "    ess            : 1.9605356780987866\n",
      "    log_marginal   : 773.8937274285082\n",
      "    log_joint      : 982.3556184588738\n",
      "    val_loss       : -778.2344156901041\n",
      "    val_ess        : 1.9562156697114308\n",
      "    val_log_marginal: 778.2759704589844\n",
      "    val_log_joint  : 986.8002115885416\n",
      "Train Epoch: 1687 [0/54000 (0%)] Loss: -773.238708\n",
      "Train Epoch: 1687 [11264/54000 (21%)] Loss: -768.678406\n",
      "Train Epoch: 1687 [22528/54000 (42%)] Loss: -785.461792\n",
      "Train Epoch: 1687 [33792/54000 (63%)] Loss: -792.582275\n",
      "Train Epoch: 1687 [45056/54000 (83%)] Loss: -765.168945\n",
      "    epoch          : 1687\n",
      "    loss           : -773.504456718013\n",
      "    ess            : 1.960791771141988\n",
      "    log_marginal   : 773.5416985277859\n",
      "    log_joint      : 982.2201630214475\n",
      "    val_loss       : -777.89453125\n",
      "    val_ess        : 1.96054740746816\n",
      "    val_log_marginal: 777.9316202799479\n",
      "    val_log_joint  : 986.5261586507162\n",
      "Train Epoch: 1688 [0/54000 (0%)] Loss: -775.102173\n",
      "Train Epoch: 1688 [11264/54000 (21%)] Loss: -769.673340\n",
      "Train Epoch: 1688 [22528/54000 (42%)] Loss: -762.064697\n",
      "Train Epoch: 1688 [33792/54000 (63%)] Loss: -759.946655\n",
      "Train Epoch: 1688 [45056/54000 (83%)] Loss: -763.613281\n",
      "    epoch          : 1688\n",
      "    loss           : -773.7862070911335\n",
      "    ess            : 1.960770405688376\n",
      "    log_marginal   : 773.824448495541\n",
      "    log_joint      : 982.4400404444281\n",
      "    val_loss       : -777.9819386800131\n",
      "    val_ess        : 1.9614001909891765\n",
      "    val_log_marginal: 778.0177612304688\n",
      "    val_log_joint  : 986.341064453125\n",
      "Train Epoch: 1689 [0/54000 (0%)] Loss: -770.193970\n",
      "Train Epoch: 1689 [11264/54000 (21%)] Loss: -761.678711\n",
      "Train Epoch: 1689 [22528/54000 (42%)] Loss: -767.584961\n",
      "Train Epoch: 1689 [33792/54000 (63%)] Loss: -790.478943\n",
      "Train Epoch: 1689 [45056/54000 (83%)] Loss: -778.669312\n",
      "    epoch          : 1689\n",
      "    loss           : -773.8957300725973\n",
      "    ess            : 1.9604120884301528\n",
      "    log_marginal   : 773.9325457878832\n",
      "    log_joint      : 982.4818454958358\n",
      "    val_loss       : -777.8024139404297\n",
      "    val_ess        : 1.9621820549170177\n",
      "    val_log_marginal: 777.8358205159506\n",
      "    val_log_joint  : 986.5456593831381\n",
      "Train Epoch: 1690 [0/54000 (0%)] Loss: -791.459106\n",
      "Train Epoch: 1690 [11264/54000 (21%)] Loss: -788.891541\n",
      "Train Epoch: 1690 [22528/54000 (42%)] Loss: -793.351562\n",
      "Train Epoch: 1690 [33792/54000 (63%)] Loss: -788.723022\n",
      "Train Epoch: 1690 [45056/54000 (83%)] Loss: -771.717346\n",
      "    epoch          : 1690\n",
      "    loss           : -773.8033539394163\n",
      "    ess            : 1.960625654121615\n",
      "    log_marginal   : 773.8405128335053\n",
      "    log_joint      : 982.4089758531103\n",
      "    val_loss       : -777.6660715738932\n",
      "    val_ess        : 1.9644051690896351\n",
      "    val_log_marginal: 777.6953379313151\n",
      "    val_log_joint  : 986.3595275878906\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1690.pth ...\n",
      "Train Epoch: 1691 [0/54000 (0%)] Loss: -774.989136\n",
      "Train Epoch: 1691 [11264/54000 (21%)] Loss: -769.382935\n",
      "Train Epoch: 1691 [22528/54000 (42%)] Loss: -759.512512\n",
      "Train Epoch: 1691 [33792/54000 (63%)] Loss: -771.584839\n",
      "Train Epoch: 1691 [45056/54000 (83%)] Loss: -762.975159\n",
      "    epoch          : 1691\n",
      "    loss           : -773.8791066295696\n",
      "    ess            : 1.9616849591147225\n",
      "    log_marginal   : 773.9158710983564\n",
      "    log_joint      : 982.3751502846771\n",
      "    val_loss       : -778.0228017171224\n",
      "    val_ess        : 1.9614737729231517\n",
      "    val_log_marginal: 778.0584055582682\n",
      "    val_log_joint  : 986.68115234375\n",
      "Train Epoch: 1692 [0/54000 (0%)] Loss: -759.697266\n",
      "Train Epoch: 1692 [11264/54000 (21%)] Loss: -796.809570\n",
      "Train Epoch: 1692 [22528/54000 (42%)] Loss: -759.244568\n",
      "Train Epoch: 1692 [33792/54000 (63%)] Loss: -775.618042\n",
      "Train Epoch: 1692 [45056/54000 (83%)] Loss: -792.760193\n",
      "    epoch          : 1692\n",
      "    loss           : -773.7414942327536\n",
      "    ess            : 1.9620169682322808\n",
      "    log_marginal   : 773.7763165168043\n",
      "    log_joint      : 982.4093063642393\n",
      "    val_loss       : -777.8438059488932\n",
      "    val_ess        : 1.9643199543158214\n",
      "    val_log_marginal: 777.8783213297526\n",
      "    val_log_joint  : 986.5997619628906\n",
      "Train Epoch: 1693 [0/54000 (0%)] Loss: -788.937500\n",
      "Train Epoch: 1693 [11264/54000 (21%)] Loss: -774.308716\n",
      "Train Epoch: 1693 [22528/54000 (42%)] Loss: -768.543640\n",
      "Train Epoch: 1693 [33792/54000 (63%)] Loss: -765.434692\n",
      "Train Epoch: 1693 [45056/54000 (83%)] Loss: -780.941895\n",
      "    epoch          : 1693\n",
      "    loss           : -773.961454571418\n",
      "    ess            : 1.9618345105423118\n",
      "    log_marginal   : 773.9966286713222\n",
      "    log_joint      : 982.5360942336748\n",
      "    val_loss       : -777.9188435872396\n",
      "    val_ess        : 1.9606683452924092\n",
      "    val_log_marginal: 777.9549814860026\n",
      "    val_log_joint  : 986.4637756347656\n",
      "Train Epoch: 1694 [0/54000 (0%)] Loss: -770.440613\n",
      "Train Epoch: 1694 [11264/54000 (21%)] Loss: -757.178223\n",
      "Train Epoch: 1694 [22528/54000 (42%)] Loss: -771.132690\n",
      "Train Epoch: 1694 [33792/54000 (63%)] Loss: -798.506104\n",
      "Train Epoch: 1694 [45056/54000 (83%)] Loss: -772.525269\n",
      "    epoch          : 1694\n",
      "    loss           : -773.953774506191\n",
      "    ess            : 1.9605730333418216\n",
      "    log_marginal   : 773.9910272562279\n",
      "    log_joint      : 982.4734427973909\n",
      "    val_loss       : -778.7384643554688\n",
      "    val_ess        : 1.961198220650355\n",
      "    val_log_marginal: 778.7780812581381\n",
      "    val_log_joint  : 987.3119099934896\n",
      "Train Epoch: 1695 [0/54000 (0%)] Loss: -754.838013\n",
      "Train Epoch: 1695 [11264/54000 (21%)] Loss: -771.809326\n",
      "Train Epoch: 1695 [22528/54000 (42%)] Loss: -750.749756\n",
      "Train Epoch: 1695 [33792/54000 (63%)] Loss: -786.048889\n",
      "Train Epoch: 1695 [45056/54000 (83%)] Loss: -755.281067\n",
      "    epoch          : 1695\n",
      "    loss           : -773.9436501556972\n",
      "    ess            : 1.9602522186513216\n",
      "    log_marginal   : 773.9811954138414\n",
      "    log_joint      : 982.5263003943102\n",
      "    val_loss       : -778.2487386067709\n",
      "    val_ess        : 1.964066396156947\n",
      "    val_log_marginal: 778.2752329508463\n",
      "    val_log_joint  : 986.6454366048177\n",
      "Train Epoch: 1696 [0/54000 (0%)] Loss: -776.476746\n",
      "Train Epoch: 1696 [11264/54000 (21%)] Loss: -772.588867\n",
      "Train Epoch: 1696 [22528/54000 (42%)] Loss: -754.469910\n",
      "Train Epoch: 1696 [33792/54000 (63%)] Loss: -768.089539\n",
      "Train Epoch: 1696 [45056/54000 (83%)] Loss: -766.542053\n",
      "    epoch          : 1696\n",
      "    loss           : -773.7821044921875\n",
      "    ess            : 1.9610288795435205\n",
      "    log_marginal   : 773.8194551287957\n",
      "    log_joint      : 982.3122310998305\n",
      "    val_loss       : -778.3410593668619\n",
      "    val_ess        : 1.9637738267580669\n",
      "    val_log_marginal: 778.3741963704427\n",
      "    val_log_joint  : 986.6570587158203\n",
      "Train Epoch: 1697 [0/54000 (0%)] Loss: -760.107849\n",
      "Train Epoch: 1697 [11264/54000 (21%)] Loss: -762.779297\n",
      "Train Epoch: 1697 [22528/54000 (42%)] Loss: -763.039062\n",
      "Train Epoch: 1697 [33792/54000 (63%)] Loss: -785.682251\n",
      "Train Epoch: 1697 [45056/54000 (83%)] Loss: -778.244812\n",
      "    epoch          : 1697\n",
      "    loss           : -774.0646615658167\n",
      "    ess            : 1.9605333906299662\n",
      "    log_marginal   : 774.1022609494767\n",
      "    log_joint      : 982.6513303360849\n",
      "    val_loss       : -777.6835174560547\n",
      "    val_ess        : 1.9612610936164856\n",
      "    val_log_marginal: 777.7184753417969\n",
      "    val_log_joint  : 986.2221628824869\n",
      "Train Epoch: 1698 [0/54000 (0%)] Loss: -773.619507\n",
      "Train Epoch: 1698 [11264/54000 (21%)] Loss: -760.412720\n",
      "Train Epoch: 1698 [22528/54000 (42%)] Loss: -780.235657\n",
      "Train Epoch: 1698 [33792/54000 (63%)] Loss: -774.903198\n",
      "Train Epoch: 1698 [45056/54000 (83%)] Loss: -747.705750\n",
      "    epoch          : 1698\n",
      "    loss           : -773.9926740538399\n",
      "    ess            : 1.9604203611050013\n",
      "    log_marginal   : 774.0306949255602\n",
      "    log_joint      : 982.5696480229216\n",
      "    val_loss       : -779.3931427001953\n",
      "    val_ess        : 1.9637636343638103\n",
      "    val_log_marginal: 779.4283854166666\n",
      "    val_log_joint  : 987.8136138916016\n",
      "Train Epoch: 1699 [0/54000 (0%)] Loss: -783.636108\n",
      "Train Epoch: 1699 [11264/54000 (21%)] Loss: -766.498291\n",
      "Train Epoch: 1699 [22528/54000 (42%)] Loss: -758.731323\n",
      "Train Epoch: 1699 [33792/54000 (63%)] Loss: -774.666321\n",
      "Train Epoch: 1699 [45056/54000 (83%)] Loss: -767.293579\n",
      "    epoch          : 1699\n",
      "    loss           : -773.9857747779703\n",
      "    ess            : 1.9601868469760102\n",
      "    log_marginal   : 774.023394314748\n",
      "    log_joint      : 982.5255984900133\n",
      "    val_loss       : -777.9560902913412\n",
      "    val_ess        : 1.962816059589386\n",
      "    val_log_marginal: 777.9908040364584\n",
      "    val_log_joint  : 986.5936330159506\n",
      "Train Epoch: 1700 [0/54000 (0%)] Loss: -816.686279\n",
      "Train Epoch: 1700 [11264/54000 (21%)] Loss: -754.005554\n",
      "Train Epoch: 1700 [22528/54000 (42%)] Loss: -780.948608\n",
      "Train Epoch: 1700 [33792/54000 (63%)] Loss: -787.431274\n",
      "Train Epoch: 1700 [45056/54000 (83%)] Loss: -779.073486\n",
      "    epoch          : 1700\n",
      "    loss           : -773.7765980846477\n",
      "    ess            : 1.960026278810681\n",
      "    log_marginal   : 773.8156507959906\n",
      "    log_joint      : 982.3070615372568\n",
      "    val_loss       : -777.9652506510416\n",
      "    val_ess        : 1.9598780671755474\n",
      "    val_log_marginal: 778.0016886393229\n",
      "    val_log_joint  : 986.4697774251302\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1700.pth ...\n",
      "Train Epoch: 1701 [0/54000 (0%)] Loss: -777.760254\n",
      "Train Epoch: 1701 [11264/54000 (21%)] Loss: -773.507935\n",
      "Train Epoch: 1701 [22528/54000 (42%)] Loss: -776.250244\n",
      "Train Epoch: 1701 [33792/54000 (63%)] Loss: -779.115845\n",
      "Train Epoch: 1701 [45056/54000 (83%)] Loss: -769.121277\n",
      "    epoch          : 1701\n",
      "    loss           : -774.0038014537884\n",
      "    ess            : 1.9602265492925104\n",
      "    log_marginal   : 774.0409568930572\n",
      "    log_joint      : 982.5807846357237\n",
      "    val_loss       : -778.0825754801432\n",
      "    val_ess        : 1.9599652191003163\n",
      "    val_log_marginal: 778.1209869384766\n",
      "    val_log_joint  : 986.7116394042969\n",
      "Train Epoch: 1702 [0/54000 (0%)] Loss: -779.061157\n",
      "Train Epoch: 1702 [11264/54000 (21%)] Loss: -776.055786\n",
      "Train Epoch: 1702 [22528/54000 (42%)] Loss: -785.632446\n",
      "Train Epoch: 1702 [33792/54000 (63%)] Loss: -766.419067\n",
      "Train Epoch: 1702 [45056/54000 (83%)] Loss: -789.274780\n",
      "    epoch          : 1702\n",
      "    loss           : -773.9820821510172\n",
      "    ess            : 1.961822068916177\n",
      "    log_marginal   : 774.0202360333137\n",
      "    log_joint      : 982.5017302890993\n",
      "    val_loss       : -778.2664896647135\n",
      "    val_ess        : 1.9622390965620677\n",
      "    val_log_marginal: 778.3012898763021\n",
      "    val_log_joint  : 986.6498107910156\n",
      "Train Epoch: 1703 [0/54000 (0%)] Loss: -777.116821\n",
      "Train Epoch: 1703 [11264/54000 (21%)] Loss: -777.261475\n",
      "Train Epoch: 1703 [22528/54000 (42%)] Loss: -777.924866\n",
      "Train Epoch: 1703 [33792/54000 (63%)] Loss: -756.143677\n",
      "Train Epoch: 1703 [45056/54000 (83%)] Loss: -788.710815\n",
      "    epoch          : 1703\n",
      "    loss           : -773.9584183602963\n",
      "    ess            : 1.9619002657116584\n",
      "    log_marginal   : 773.9939949467497\n",
      "    log_joint      : 982.4855266067217\n",
      "    val_loss       : -777.4617207845052\n",
      "    val_ess        : 1.9608622292677562\n",
      "    val_log_marginal: 777.4956258138021\n",
      "    val_log_joint  : 986.1205902099609\n",
      "Train Epoch: 1704 [0/54000 (0%)] Loss: -769.850220\n",
      "Train Epoch: 1704 [11264/54000 (21%)] Loss: -789.485718\n",
      "Train Epoch: 1704 [22528/54000 (42%)] Loss: -779.796875\n",
      "Train Epoch: 1704 [33792/54000 (63%)] Loss: -782.839661\n",
      "Train Epoch: 1704 [45056/54000 (83%)] Loss: -764.033447\n",
      "    epoch          : 1704\n",
      "    loss           : -773.9883094643646\n",
      "    ess            : 1.96048396938252\n",
      "    log_marginal   : 774.0262992427034\n",
      "    log_joint      : 982.5885539504717\n",
      "    val_loss       : -777.7457173665365\n",
      "    val_ess        : 1.9595905343691509\n",
      "    val_log_marginal: 777.7831522623698\n",
      "    val_log_joint  : 986.1706848144531\n",
      "Train Epoch: 1705 [0/54000 (0%)] Loss: -795.249207\n",
      "Train Epoch: 1705 [11264/54000 (21%)] Loss: -777.432312\n",
      "Train Epoch: 1705 [22528/54000 (42%)] Loss: -762.268311\n",
      "Train Epoch: 1705 [33792/54000 (63%)] Loss: -789.690186\n",
      "Train Epoch: 1705 [45056/54000 (83%)] Loss: -765.371704\n",
      "    epoch          : 1705\n",
      "    loss           : -773.9711631918854\n",
      "    ess            : 1.9597929288756173\n",
      "    log_marginal   : 774.0092790711601\n",
      "    log_joint      : 982.5468986079378\n",
      "    val_loss       : -777.7537841796875\n",
      "    val_ess        : 1.9617028435071309\n",
      "    val_log_marginal: 777.7898254394531\n",
      "    val_log_joint  : 986.3599904378256\n",
      "Train Epoch: 1706 [0/54000 (0%)] Loss: -789.241089\n",
      "Train Epoch: 1706 [11264/54000 (21%)] Loss: -799.019531\n",
      "Train Epoch: 1706 [22528/54000 (42%)] Loss: -749.340637\n",
      "Train Epoch: 1706 [33792/54000 (63%)] Loss: -748.802368\n",
      "Train Epoch: 1706 [45056/54000 (83%)] Loss: -759.868652\n",
      "    epoch          : 1706\n",
      "    loss           : -773.9655231979658\n",
      "    ess            : 1.9605630546245936\n",
      "    log_marginal   : 774.0045223595961\n",
      "    log_joint      : 982.583084394347\n",
      "    val_loss       : -777.4740651448568\n",
      "    val_ess        : 1.9624031782150269\n",
      "    val_log_marginal: 777.5095621744791\n",
      "    val_log_joint  : 985.9081980387369\n",
      "Train Epoch: 1707 [0/54000 (0%)] Loss: -771.182129\n",
      "Train Epoch: 1707 [11264/54000 (21%)] Loss: -776.035645\n",
      "Train Epoch: 1707 [22528/54000 (42%)] Loss: -781.030945\n",
      "Train Epoch: 1707 [33792/54000 (63%)] Loss: -777.963257\n",
      "Train Epoch: 1707 [45056/54000 (83%)] Loss: -780.166870\n",
      "    epoch          : 1707\n",
      "    loss           : -774.1753603377432\n",
      "    ess            : 1.9606153402688369\n",
      "    log_marginal   : 774.2126562730322\n",
      "    log_joint      : 982.6951178784641\n",
      "    val_loss       : -777.6931304931641\n",
      "    val_ess        : 1.9633765816688538\n",
      "    val_log_marginal: 777.7263234456381\n",
      "    val_log_joint  : 986.5158640543619\n",
      "Train Epoch: 1708 [0/54000 (0%)] Loss: -778.634338\n",
      "Train Epoch: 1708 [11264/54000 (21%)] Loss: -773.018433\n",
      "Train Epoch: 1708 [22528/54000 (42%)] Loss: -768.960144\n",
      "Train Epoch: 1708 [33792/54000 (63%)] Loss: -784.507507\n",
      "Train Epoch: 1708 [45056/54000 (83%)] Loss: -778.781067\n",
      "    epoch          : 1708\n",
      "    loss           : -773.8290019485186\n",
      "    ess            : 1.9604945913800653\n",
      "    log_marginal   : 773.8661602668043\n",
      "    log_joint      : 982.5754475143721\n",
      "    val_loss       : -777.5103200276693\n",
      "    val_ess        : 1.9623749057451885\n",
      "    val_log_marginal: 777.5462493896484\n",
      "    val_log_joint  : 985.9639282226562\n",
      "Train Epoch: 1709 [0/54000 (0%)] Loss: -783.365601\n",
      "Train Epoch: 1709 [11264/54000 (21%)] Loss: -759.190491\n",
      "Train Epoch: 1709 [22528/54000 (42%)] Loss: -758.542725\n",
      "Train Epoch: 1709 [33792/54000 (63%)] Loss: -798.392578\n",
      "Train Epoch: 1709 [45056/54000 (83%)] Loss: -761.203918\n",
      "    epoch          : 1709\n",
      "    loss           : -774.0078389869547\n",
      "    ess            : 1.9605872552349883\n",
      "    log_marginal   : 774.0451044046654\n",
      "    log_joint      : 982.5563481168927\n",
      "    val_loss       : -778.8350474039713\n",
      "    val_ess        : 1.9618087112903595\n",
      "    val_log_marginal: 778.8694407145182\n",
      "    val_log_joint  : 987.2854817708334\n",
      "Train Epoch: 1710 [0/54000 (0%)] Loss: -772.770874\n",
      "Train Epoch: 1710 [11264/54000 (21%)] Loss: -767.162231\n",
      "Train Epoch: 1710 [22528/54000 (42%)] Loss: -767.781982\n",
      "Train Epoch: 1710 [33792/54000 (63%)] Loss: -760.647095\n",
      "Train Epoch: 1710 [45056/54000 (83%)] Loss: -779.570801\n",
      "    epoch          : 1710\n",
      "    loss           : -774.2426003510097\n",
      "    ess            : 1.960433744034677\n",
      "    log_marginal   : 774.2799411989608\n",
      "    log_joint      : 982.7309840940079\n",
      "    val_loss       : -778.0151316324869\n",
      "    val_ess        : 1.9607227842013042\n",
      "    val_log_marginal: 778.0522257486979\n",
      "    val_log_joint  : 986.6292622884115\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1710.pth ...\n",
      "Train Epoch: 1711 [0/54000 (0%)] Loss: -783.560303\n",
      "Train Epoch: 1711 [11264/54000 (21%)] Loss: -761.296753\n",
      "Train Epoch: 1711 [22528/54000 (42%)] Loss: -789.086182\n",
      "Train Epoch: 1711 [33792/54000 (63%)] Loss: -775.507812\n",
      "Train Epoch: 1711 [45056/54000 (83%)] Loss: -765.803284\n",
      "    epoch          : 1711\n",
      "    loss           : -774.0866273124263\n",
      "    ess            : 1.9614977060623888\n",
      "    log_marginal   : 774.1220346126917\n",
      "    log_joint      : 982.7668451273216\n",
      "    val_loss       : -778.2089284261068\n",
      "    val_ess        : 1.9628650943438213\n",
      "    val_log_marginal: 778.2416127522787\n",
      "    val_log_joint  : 987.0053761800131\n",
      "Train Epoch: 1712 [0/54000 (0%)] Loss: -777.628784\n",
      "Train Epoch: 1712 [11264/54000 (21%)] Loss: -785.909424\n",
      "Train Epoch: 1712 [22528/54000 (42%)] Loss: -793.247070\n",
      "Train Epoch: 1712 [33792/54000 (63%)] Loss: -775.025146\n",
      "Train Epoch: 1712 [45056/54000 (83%)] Loss: -788.979858\n",
      "    epoch          : 1712\n",
      "    loss           : -773.9720142292526\n",
      "    ess            : 1.960431122554923\n",
      "    log_marginal   : 774.009647585311\n",
      "    log_joint      : 982.6409411160452\n",
      "    val_loss       : -778.1839599609375\n",
      "    val_ess        : 1.9616853296756744\n",
      "    val_log_marginal: 778.2200927734375\n",
      "    val_log_joint  : 986.9236297607422\n",
      "Train Epoch: 1713 [0/54000 (0%)] Loss: -773.736572\n",
      "Train Epoch: 1713 [11264/54000 (21%)] Loss: -757.803955\n",
      "Train Epoch: 1713 [22528/54000 (42%)] Loss: -776.044922\n",
      "Train Epoch: 1713 [33792/54000 (63%)] Loss: -786.131470\n",
      "Train Epoch: 1713 [45056/54000 (83%)] Loss: -781.154541\n",
      "    epoch          : 1713\n",
      "    loss           : -774.048306447155\n",
      "    ess            : 1.96182958697373\n",
      "    log_marginal   : 774.0840695938974\n",
      "    log_joint      : 982.5985395323555\n",
      "    val_loss       : -777.9861399332682\n",
      "    val_ess        : 1.963492790857951\n",
      "    val_log_marginal: 778.0177510579427\n",
      "    val_log_joint  : 986.7775573730469\n",
      "Train Epoch: 1714 [0/54000 (0%)] Loss: -754.936523\n",
      "Train Epoch: 1714 [11264/54000 (21%)] Loss: -759.506714\n",
      "Train Epoch: 1714 [22528/54000 (42%)] Loss: -739.038696\n",
      "Train Epoch: 1714 [33792/54000 (63%)] Loss: -768.196411\n",
      "Train Epoch: 1714 [45056/54000 (83%)] Loss: -798.338135\n",
      "    epoch          : 1714\n",
      "    loss           : -774.1629788380749\n",
      "    ess            : 1.9613150099538408\n",
      "    log_marginal   : 774.1989792158018\n",
      "    log_joint      : 982.642276404039\n",
      "    val_loss       : -778.2693481445312\n",
      "    val_ess        : 1.9575426280498505\n",
      "    val_log_marginal: 778.3139394124349\n",
      "    val_log_joint  : 986.7170257568359\n",
      "Train Epoch: 1715 [0/54000 (0%)] Loss: -782.222656\n",
      "Train Epoch: 1715 [11264/54000 (21%)] Loss: -789.524536\n",
      "Train Epoch: 1715 [22528/54000 (42%)] Loss: -760.799805\n",
      "Train Epoch: 1715 [33792/54000 (63%)] Loss: -776.129150\n",
      "Train Epoch: 1715 [45056/54000 (83%)] Loss: -758.684021\n",
      "    epoch          : 1715\n",
      "    loss           : -774.0951710826946\n",
      "    ess            : 1.960471046420763\n",
      "    log_marginal   : 774.1331251612249\n",
      "    log_joint      : 982.6603451135023\n",
      "    val_loss       : -777.8583679199219\n",
      "    val_ess        : 1.9551541308561962\n",
      "    val_log_marginal: 777.9008076985677\n",
      "    val_log_joint  : 986.5970865885416\n",
      "Train Epoch: 1716 [0/54000 (0%)] Loss: -772.982544\n",
      "Train Epoch: 1716 [11264/54000 (21%)] Loss: -779.635498\n",
      "Train Epoch: 1716 [22528/54000 (42%)] Loss: -770.845154\n",
      "Train Epoch: 1716 [33792/54000 (63%)] Loss: -765.245972\n",
      "Train Epoch: 1716 [45056/54000 (83%)] Loss: -777.627808\n",
      "    epoch          : 1716\n",
      "    loss           : -773.9647596827093\n",
      "    ess            : 1.961016739314457\n",
      "    log_marginal   : 774.0017492906103\n",
      "    log_joint      : 982.5969952277418\n",
      "    val_loss       : -778.6154174804688\n",
      "    val_ess        : 1.9630768299102783\n",
      "    val_log_marginal: 778.6487884521484\n",
      "    val_log_joint  : 987.1836242675781\n",
      "Train Epoch: 1717 [0/54000 (0%)] Loss: -779.481079\n",
      "Train Epoch: 1717 [11264/54000 (21%)] Loss: -752.222290\n",
      "Train Epoch: 1717 [22528/54000 (42%)] Loss: -778.324341\n",
      "Train Epoch: 1717 [33792/54000 (63%)] Loss: -770.271606\n",
      "Train Epoch: 1717 [45056/54000 (83%)] Loss: -771.100708\n",
      "    epoch          : 1717\n",
      "    loss           : -773.9610376897848\n",
      "    ess            : 1.9599256166871988\n",
      "    log_marginal   : 773.9993435841686\n",
      "    log_joint      : 982.6628268259876\n",
      "    val_loss       : -778.7061157226562\n",
      "    val_ess        : 1.963316281636556\n",
      "    val_log_marginal: 778.7402903238932\n",
      "    val_log_joint  : 987.4153188069662\n",
      "Train Epoch: 1718 [0/54000 (0%)] Loss: -779.128662\n",
      "Train Epoch: 1718 [11264/54000 (21%)] Loss: -775.630798\n",
      "Train Epoch: 1718 [22528/54000 (42%)] Loss: -785.626099\n",
      "Train Epoch: 1718 [33792/54000 (63%)] Loss: -765.004211\n",
      "Train Epoch: 1718 [45056/54000 (83%)] Loss: -795.408936\n",
      "    epoch          : 1718\n",
      "    loss           : -774.1280678803066\n",
      "    ess            : 1.96024674402093\n",
      "    log_marginal   : 774.1653275399838\n",
      "    log_joint      : 982.69524225199\n",
      "    val_loss       : -778.6024373372396\n",
      "    val_ess        : 1.9610870480537415\n",
      "    val_log_marginal: 778.6375885009766\n",
      "    val_log_joint  : 987.1638641357422\n",
      "Train Epoch: 1719 [0/54000 (0%)] Loss: -763.087463\n",
      "Train Epoch: 1719 [11264/54000 (21%)] Loss: -757.431458\n",
      "Train Epoch: 1719 [22528/54000 (42%)] Loss: -792.950195\n",
      "Train Epoch: 1719 [33792/54000 (63%)] Loss: -789.020630\n",
      "Train Epoch: 1719 [45056/54000 (83%)] Loss: -792.541504\n",
      "    epoch          : 1719\n",
      "    loss           : -774.193959362102\n",
      "    ess            : 1.96116334312367\n",
      "    log_marginal   : 774.2304814176739\n",
      "    log_joint      : 982.7324990326504\n",
      "    val_loss       : -777.8744659423828\n",
      "    val_ess        : 1.9604490995407104\n",
      "    val_log_marginal: 777.9087575276693\n",
      "    val_log_joint  : 986.3568267822266\n",
      "Train Epoch: 1720 [0/54000 (0%)] Loss: -758.222778\n",
      "Train Epoch: 1720 [11264/54000 (21%)] Loss: -773.714478\n",
      "Train Epoch: 1720 [22528/54000 (42%)] Loss: -785.177673\n",
      "Train Epoch: 1720 [33792/54000 (63%)] Loss: -780.004517\n",
      "Train Epoch: 1720 [45056/54000 (83%)] Loss: -764.432129\n",
      "    epoch          : 1720\n",
      "    loss           : -774.1604700628317\n",
      "    ess            : 1.9606420453989282\n",
      "    log_marginal   : 774.1978587024616\n",
      "    log_joint      : 982.6766610775354\n",
      "    val_loss       : -778.079579671224\n",
      "    val_ess        : 1.9615951081116993\n",
      "    val_log_marginal: 778.116455078125\n",
      "    val_log_joint  : 987.0004069010416\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1720.pth ...\n",
      "Train Epoch: 1721 [0/54000 (0%)] Loss: -767.343140\n",
      "Train Epoch: 1721 [11264/54000 (21%)] Loss: -773.849854\n",
      "Train Epoch: 1721 [22528/54000 (42%)] Loss: -765.148193\n",
      "Train Epoch: 1721 [33792/54000 (63%)] Loss: -763.702515\n",
      "Train Epoch: 1721 [45056/54000 (83%)] Loss: -778.168579\n",
      "    epoch          : 1721\n",
      "    loss           : -774.1610631402933\n",
      "    ess            : 1.962025910053613\n",
      "    log_marginal   : 774.1965769641804\n",
      "    log_joint      : 982.6694664145416\n",
      "    val_loss       : -778.0205281575521\n",
      "    val_ess        : 1.9622817635536194\n",
      "    val_log_marginal: 778.0567067464193\n",
      "    val_log_joint  : 986.7081807454427\n",
      "Train Epoch: 1722 [0/54000 (0%)] Loss: -763.770508\n",
      "Train Epoch: 1722 [11264/54000 (21%)] Loss: -765.589783\n",
      "Train Epoch: 1722 [22528/54000 (42%)] Loss: -779.215332\n",
      "Train Epoch: 1722 [33792/54000 (63%)] Loss: -788.762451\n",
      "Train Epoch: 1722 [45056/54000 (83%)] Loss: -790.713806\n",
      "    epoch          : 1722\n",
      "    loss           : -774.3290405273438\n",
      "    ess            : 1.9610924383379378\n",
      "    log_marginal   : 774.3648255546138\n",
      "    log_joint      : 982.7897880122347\n",
      "    val_loss       : -778.8850657145182\n",
      "    val_ess        : 1.9599822560946147\n",
      "    val_log_marginal: 778.9216257731119\n",
      "    val_log_joint  : 987.3272298177084\n",
      "Train Epoch: 1723 [0/54000 (0%)] Loss: -785.284912\n",
      "Train Epoch: 1723 [11264/54000 (21%)] Loss: -776.177734\n",
      "Train Epoch: 1723 [22528/54000 (42%)] Loss: -754.710815\n",
      "Train Epoch: 1723 [33792/54000 (63%)] Loss: -802.971558\n",
      "Train Epoch: 1723 [45056/54000 (83%)] Loss: -787.063110\n",
      "    epoch          : 1723\n",
      "    loss           : -774.263303360849\n",
      "    ess            : 1.960395390132688\n",
      "    log_marginal   : 774.3007564904555\n",
      "    log_joint      : 982.8683293180645\n",
      "    val_loss       : -779.1196085611979\n",
      "    val_ess        : 1.9598549008369446\n",
      "    val_log_marginal: 779.1605072021484\n",
      "    val_log_joint  : 987.9142812093099\n",
      "Train Epoch: 1724 [0/54000 (0%)] Loss: -756.863159\n",
      "Train Epoch: 1724 [11264/54000 (21%)] Loss: -773.621887\n",
      "Train Epoch: 1724 [22528/54000 (42%)] Loss: -760.834167\n",
      "Train Epoch: 1724 [33792/54000 (63%)] Loss: -770.427734\n",
      "Train Epoch: 1724 [45056/54000 (83%)] Loss: -785.337280\n",
      "    epoch          : 1724\n",
      "    loss           : -774.3073091327019\n",
      "    ess            : 1.9608758508034472\n",
      "    log_marginal   : 774.3445307893573\n",
      "    log_joint      : 982.7670552955484\n",
      "    val_loss       : -778.7790120442709\n",
      "    val_ess        : 1.9631293416023254\n",
      "    val_log_marginal: 778.8118031819662\n",
      "    val_log_joint  : 987.1585235595703\n",
      "Train Epoch: 1725 [0/54000 (0%)] Loss: -767.022644\n",
      "Train Epoch: 1725 [11264/54000 (21%)] Loss: -771.593872\n",
      "Train Epoch: 1725 [22528/54000 (42%)] Loss: -776.944763\n",
      "Train Epoch: 1725 [33792/54000 (63%)] Loss: -779.943970\n",
      "Train Epoch: 1725 [45056/54000 (83%)] Loss: -770.202026\n",
      "    epoch          : 1725\n",
      "    loss           : -774.0751262160967\n",
      "    ess            : 1.960677126668534\n",
      "    log_marginal   : 774.1135835467644\n",
      "    log_joint      : 982.6708022783388\n",
      "    val_loss       : -778.0577494303385\n",
      "    val_ess        : 1.961300532023112\n",
      "    val_log_marginal: 778.0929616292318\n",
      "    val_log_joint  : 986.7572428385416\n",
      "Train Epoch: 1726 [0/54000 (0%)] Loss: -772.759766\n",
      "Train Epoch: 1726 [11264/54000 (21%)] Loss: -784.419434\n",
      "Train Epoch: 1726 [22528/54000 (42%)] Loss: -777.139099\n",
      "Train Epoch: 1726 [33792/54000 (63%)] Loss: -783.320068\n",
      "Train Epoch: 1726 [45056/54000 (83%)] Loss: -783.057068\n",
      "    epoch          : 1726\n",
      "    loss           : -774.3453063964844\n",
      "    ess            : 1.9617511281427347\n",
      "    log_marginal   : 774.3816942898733\n",
      "    log_joint      : 982.8705156434257\n",
      "    val_loss       : -778.9364674886068\n",
      "    val_ess        : 1.9595110217730205\n",
      "    val_log_marginal: 778.9737091064453\n",
      "    val_log_joint  : 987.6916758219401\n",
      "Train Epoch: 1727 [0/54000 (0%)] Loss: -793.600342\n",
      "Train Epoch: 1727 [11264/54000 (21%)] Loss: -801.901123\n",
      "Train Epoch: 1727 [22528/54000 (42%)] Loss: -783.901917\n",
      "Train Epoch: 1727 [33792/54000 (63%)] Loss: -788.795471\n",
      "Train Epoch: 1727 [45056/54000 (83%)] Loss: -763.273010\n",
      "    epoch          : 1727\n",
      "    loss           : -774.2179254495873\n",
      "    ess            : 1.960795393529928\n",
      "    log_marginal   : 774.2552288703199\n",
      "    log_joint      : 982.7774686993293\n",
      "    val_loss       : -778.4629923502604\n",
      "    val_ess        : 1.9616487324237823\n",
      "    val_log_marginal: 778.4988962809244\n",
      "    val_log_joint  : 987.0815277099609\n",
      "Train Epoch: 1728 [0/54000 (0%)] Loss: -776.099365\n",
      "Train Epoch: 1728 [11264/54000 (21%)] Loss: -784.469666\n",
      "Train Epoch: 1728 [22528/54000 (42%)] Loss: -761.354065\n",
      "Train Epoch: 1728 [33792/54000 (63%)] Loss: -772.378662\n",
      "Train Epoch: 1728 [45056/54000 (83%)] Loss: -767.078369\n",
      "    epoch          : 1728\n",
      "    loss           : -774.2752674030808\n",
      "    ess            : 1.9598506497886945\n",
      "    log_marginal   : 774.3134420142984\n",
      "    log_joint      : 982.9239041310436\n",
      "    val_loss       : -778.0862986246744\n",
      "    val_ess        : 1.9593096872170765\n",
      "    val_log_marginal: 778.1229248046875\n",
      "    val_log_joint  : 986.6659138997396\n",
      "Train Epoch: 1729 [0/54000 (0%)] Loss: -775.016602\n",
      "Train Epoch: 1729 [11264/54000 (21%)] Loss: -774.620667\n",
      "Train Epoch: 1729 [22528/54000 (42%)] Loss: -773.228882\n",
      "Train Epoch: 1729 [33792/54000 (63%)] Loss: -777.244995\n",
      "Train Epoch: 1729 [45056/54000 (83%)] Loss: -782.096924\n",
      "    epoch          : 1729\n",
      "    loss           : -774.4494640422317\n",
      "    ess            : 1.961390936149741\n",
      "    log_marginal   : 774.4855404260023\n",
      "    log_joint      : 983.0307853266878\n",
      "    val_loss       : -778.2102305094401\n",
      "    val_ess        : 1.9595951636632283\n",
      "    val_log_marginal: 778.251708984375\n",
      "    val_log_joint  : 986.719248453776\n",
      "Train Epoch: 1730 [0/54000 (0%)] Loss: -781.253845\n",
      "Train Epoch: 1730 [11264/54000 (21%)] Loss: -764.345337\n",
      "Train Epoch: 1730 [22528/54000 (42%)] Loss: -776.171387\n",
      "Train Epoch: 1730 [33792/54000 (63%)] Loss: -771.675659\n",
      "Train Epoch: 1730 [45056/54000 (83%)] Loss: -782.646973\n",
      "    epoch          : 1730\n",
      "    loss           : -774.4137964788473\n",
      "    ess            : 1.9616872308389195\n",
      "    log_marginal   : 774.4499793862396\n",
      "    log_joint      : 982.982455271595\n",
      "    val_loss       : -778.9640757242838\n",
      "    val_ess        : 1.9585429231325786\n",
      "    val_log_marginal: 779.0000915527344\n",
      "    val_log_joint  : 987.2960611979166\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1730.pth ...\n",
      "Train Epoch: 1731 [0/54000 (0%)] Loss: -792.075623\n",
      "Train Epoch: 1731 [11264/54000 (21%)] Loss: -792.604797\n",
      "Train Epoch: 1731 [22528/54000 (42%)] Loss: -787.069336\n",
      "Train Epoch: 1731 [33792/54000 (63%)] Loss: -787.768921\n",
      "Train Epoch: 1731 [45056/54000 (83%)] Loss: -781.770508\n",
      "    epoch          : 1731\n",
      "    loss           : -774.3044341465212\n",
      "    ess            : 1.9624255445768248\n",
      "    log_marginal   : 774.3387537542379\n",
      "    log_joint      : 982.8292006006781\n",
      "    val_loss       : -779.2023976643881\n",
      "    val_ess        : 1.9618489444255829\n",
      "    val_log_marginal: 779.2372792561849\n",
      "    val_log_joint  : 987.7460479736328\n",
      "Train Epoch: 1732 [0/54000 (0%)] Loss: -763.457275\n",
      "Train Epoch: 1732 [11264/54000 (21%)] Loss: -780.927368\n",
      "Train Epoch: 1732 [22528/54000 (42%)] Loss: -761.287292\n",
      "Train Epoch: 1732 [33792/54000 (63%)] Loss: -778.621582\n",
      "Train Epoch: 1732 [45056/54000 (83%)] Loss: -776.050293\n",
      "    epoch          : 1732\n",
      "    loss           : -774.2563919931088\n",
      "    ess            : 1.9601713790083832\n",
      "    log_marginal   : 774.2949109347361\n",
      "    log_joint      : 982.8802933602963\n",
      "    val_loss       : -779.1644388834635\n",
      "    val_ess        : 1.962542752424876\n",
      "    val_log_marginal: 779.2006988525391\n",
      "    val_log_joint  : 987.7657674153646\n",
      "Train Epoch: 1733 [0/54000 (0%)] Loss: -740.812866\n",
      "Train Epoch: 1733 [11264/54000 (21%)] Loss: -788.981812\n",
      "Train Epoch: 1733 [22528/54000 (42%)] Loss: -782.469360\n",
      "Train Epoch: 1733 [33792/54000 (63%)] Loss: -783.922729\n",
      "Train Epoch: 1733 [45056/54000 (83%)] Loss: -777.075378\n",
      "    epoch          : 1733\n",
      "    loss           : -774.3026808252874\n",
      "    ess            : 1.9605572684755865\n",
      "    log_marginal   : 774.339963517099\n",
      "    log_joint      : 982.9103969358048\n",
      "    val_loss       : -778.6295318603516\n",
      "    val_ess        : 1.962825616200765\n",
      "    val_log_marginal: 778.6627197265625\n",
      "    val_log_joint  : 987.1164499918619\n",
      "Train Epoch: 1734 [0/54000 (0%)] Loss: -780.735474\n",
      "Train Epoch: 1734 [11264/54000 (21%)] Loss: -763.949463\n",
      "Train Epoch: 1734 [22528/54000 (42%)] Loss: -789.699036\n",
      "Train Epoch: 1734 [33792/54000 (63%)] Loss: -790.410950\n",
      "Train Epoch: 1734 [45056/54000 (83%)] Loss: -759.908447\n",
      "    epoch          : 1734\n",
      "    loss           : -774.2702976442733\n",
      "    ess            : 1.9600210785865784\n",
      "    log_marginal   : 774.3085258052034\n",
      "    log_joint      : 982.8669727253464\n",
      "    val_loss       : -778.1553649902344\n",
      "    val_ess        : 1.9588059186935425\n",
      "    val_log_marginal: 778.1945190429688\n",
      "    val_log_joint  : 986.7025807698568\n",
      "Train Epoch: 1735 [0/54000 (0%)] Loss: -793.259094\n",
      "Train Epoch: 1735 [11264/54000 (21%)] Loss: -795.060669\n",
      "Train Epoch: 1735 [22528/54000 (42%)] Loss: -774.569641\n",
      "Train Epoch: 1735 [33792/54000 (63%)] Loss: -774.637695\n",
      "Train Epoch: 1735 [45056/54000 (83%)] Loss: -787.664734\n",
      "    epoch          : 1735\n",
      "    loss           : -774.3849423966318\n",
      "    ess            : 1.960881993455707\n",
      "    log_marginal   : 774.4212485259434\n",
      "    log_joint      : 983.0321804982311\n",
      "    val_loss       : -779.0886993408203\n",
      "    val_ess        : 1.9606876373291016\n",
      "    val_log_marginal: 779.1267038981119\n",
      "    val_log_joint  : 987.266367594401\n",
      "Train Epoch: 1736 [0/54000 (0%)] Loss: -765.909607\n",
      "Train Epoch: 1736 [11264/54000 (21%)] Loss: -762.026855\n",
      "Train Epoch: 1736 [22528/54000 (42%)] Loss: -773.407837\n",
      "Train Epoch: 1736 [33792/54000 (63%)] Loss: -783.426270\n",
      "Train Epoch: 1736 [45056/54000 (83%)] Loss: -800.644592\n",
      "    epoch          : 1736\n",
      "    loss           : -774.297189388635\n",
      "    ess            : 1.9604428849130306\n",
      "    log_marginal   : 774.333669986365\n",
      "    log_joint      : 982.944985443691\n",
      "    val_loss       : -778.1145985921224\n",
      "    val_ess        : 1.960209200779597\n",
      "    val_log_marginal: 778.1482340494791\n",
      "    val_log_joint  : 986.8539886474609\n",
      "Train Epoch: 1737 [0/54000 (0%)] Loss: -785.549255\n",
      "Train Epoch: 1737 [11264/54000 (21%)] Loss: -774.930420\n",
      "Train Epoch: 1737 [22528/54000 (42%)] Loss: -785.970947\n",
      "Train Epoch: 1737 [33792/54000 (63%)] Loss: -798.301575\n",
      "Train Epoch: 1737 [45056/54000 (83%)] Loss: -777.054565\n",
      "    epoch          : 1737\n",
      "    loss           : -774.2604519826061\n",
      "    ess            : 1.9616087697586924\n",
      "    log_marginal   : 774.2956220518868\n",
      "    log_joint      : 982.7277618984007\n",
      "    val_loss       : -778.2485911051432\n",
      "    val_ess        : 1.9603304068247478\n",
      "    val_log_marginal: 778.2898457845052\n",
      "    val_log_joint  : 986.7152353922526\n",
      "Train Epoch: 1738 [0/54000 (0%)] Loss: -782.738525\n",
      "Train Epoch: 1738 [11264/54000 (21%)] Loss: -769.981689\n",
      "Train Epoch: 1738 [22528/54000 (42%)] Loss: -794.465027\n",
      "Train Epoch: 1738 [33792/54000 (63%)] Loss: -786.811890\n",
      "Train Epoch: 1738 [45056/54000 (83%)] Loss: -772.214417\n",
      "    epoch          : 1738\n",
      "    loss           : -774.431493795143\n",
      "    ess            : 1.9608439117107752\n",
      "    log_marginal   : 774.4666989884287\n",
      "    log_joint      : 983.1361003371904\n",
      "    val_loss       : -778.3744150797526\n",
      "    val_ess        : 1.9667604565620422\n",
      "    val_log_marginal: 778.4037526448568\n",
      "    val_log_joint  : 987.1672007242838\n",
      "Train Epoch: 1739 [0/54000 (0%)] Loss: -762.054382\n",
      "Train Epoch: 1739 [11264/54000 (21%)] Loss: -777.803406\n",
      "Train Epoch: 1739 [22528/54000 (42%)] Loss: -776.046204\n",
      "Train Epoch: 1739 [33792/54000 (63%)] Loss: -784.656921\n",
      "Train Epoch: 1739 [45056/54000 (83%)] Loss: -784.188354\n",
      "    epoch          : 1739\n",
      "    loss           : -774.3538703198703\n",
      "    ess            : 1.9614589079371039\n",
      "    log_marginal   : 774.3901539928509\n",
      "    log_joint      : 982.9821685215212\n",
      "    val_loss       : -779.0366414388021\n",
      "    val_ess        : 1.961413751045863\n",
      "    val_log_marginal: 779.0748697916666\n",
      "    val_log_joint  : 987.6879526774088\n",
      "Train Epoch: 1740 [0/54000 (0%)] Loss: -767.693298\n",
      "Train Epoch: 1740 [11264/54000 (21%)] Loss: -779.377441\n",
      "Train Epoch: 1740 [22528/54000 (42%)] Loss: -798.440796\n",
      "Train Epoch: 1740 [33792/54000 (63%)] Loss: -780.341248\n",
      "Train Epoch: 1740 [45056/54000 (83%)] Loss: -797.704590\n",
      "    epoch          : 1740\n",
      "    loss           : -774.3359369241966\n",
      "    ess            : 1.9604416714524322\n",
      "    log_marginal   : 774.372935169148\n",
      "    log_joint      : 982.8810729980469\n",
      "    val_loss       : -779.3127899169922\n",
      "    val_ess        : 1.9601387182871501\n",
      "    val_log_marginal: 779.3539479573568\n",
      "    val_log_joint  : 987.803476969401\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1740.pth ...\n",
      "Train Epoch: 1741 [0/54000 (0%)] Loss: -798.256409\n",
      "Train Epoch: 1741 [11264/54000 (21%)] Loss: -791.849670\n",
      "Train Epoch: 1741 [22528/54000 (42%)] Loss: -784.771301\n",
      "Train Epoch: 1741 [33792/54000 (63%)] Loss: -766.243530\n",
      "Train Epoch: 1741 [45056/54000 (83%)] Loss: -784.560303\n",
      "    epoch          : 1741\n",
      "    loss           : -774.4286268702093\n",
      "    ess            : 1.9619107595029868\n",
      "    log_marginal   : 774.4640715976931\n",
      "    log_joint      : 983.0127551960495\n",
      "    val_loss       : -778.5370330810547\n",
      "    val_ess        : 1.962203323841095\n",
      "    val_log_marginal: 778.5695190429688\n",
      "    val_log_joint  : 987.2482350667318\n",
      "Train Epoch: 1742 [0/54000 (0%)] Loss: -778.953125\n",
      "Train Epoch: 1742 [11264/54000 (21%)] Loss: -780.681335\n",
      "Train Epoch: 1742 [22528/54000 (42%)] Loss: -766.842773\n",
      "Train Epoch: 1742 [33792/54000 (63%)] Loss: -772.358398\n",
      "Train Epoch: 1742 [45056/54000 (83%)] Loss: -772.122375\n",
      "    epoch          : 1742\n",
      "    loss           : -774.3061978322155\n",
      "    ess            : 1.9613948408162818\n",
      "    log_marginal   : 774.3434275501179\n",
      "    log_joint      : 982.8594239432857\n",
      "    val_loss       : -778.9664815266927\n",
      "    val_ess        : 1.964634507894516\n",
      "    val_log_marginal: 778.9967193603516\n",
      "    val_log_joint  : 987.6670786539713\n",
      "Train Epoch: 1743 [0/54000 (0%)] Loss: -781.076660\n",
      "Train Epoch: 1743 [11264/54000 (21%)] Loss: -765.993042\n",
      "Train Epoch: 1743 [22528/54000 (42%)] Loss: -755.738281\n",
      "Train Epoch: 1743 [33792/54000 (63%)] Loss: -792.331665\n",
      "Train Epoch: 1743 [45056/54000 (83%)] Loss: -762.030396\n",
      "    epoch          : 1743\n",
      "    loss           : -774.2752328548792\n",
      "    ess            : 1.9611679146874625\n",
      "    log_marginal   : 774.311955865824\n",
      "    log_joint      : 982.8889995071123\n",
      "    val_loss       : -778.9154663085938\n",
      "    val_ess        : 1.9613933662573497\n",
      "    val_log_marginal: 778.9547068277994\n",
      "    val_log_joint  : 987.5035909016927\n",
      "Train Epoch: 1744 [0/54000 (0%)] Loss: -764.700684\n",
      "Train Epoch: 1744 [11264/54000 (21%)] Loss: -789.696411\n",
      "Train Epoch: 1744 [22528/54000 (42%)] Loss: -774.839722\n",
      "Train Epoch: 1744 [33792/54000 (63%)] Loss: -756.029541\n",
      "Train Epoch: 1744 [45056/54000 (83%)] Loss: -763.307739\n",
      "    epoch          : 1744\n",
      "    loss           : -774.4393667544958\n",
      "    ess            : 1.9611602684236922\n",
      "    log_marginal   : 774.4775730348983\n",
      "    log_joint      : 982.9582767126695\n",
      "    val_loss       : -778.8068644205729\n",
      "    val_ess        : 1.9614183803399403\n",
      "    val_log_marginal: 778.8449452718099\n",
      "    val_log_joint  : 987.503163655599\n",
      "Train Epoch: 1745 [0/54000 (0%)] Loss: -775.838013\n",
      "Train Epoch: 1745 [11264/54000 (21%)] Loss: -784.821960\n",
      "Train Epoch: 1745 [22528/54000 (42%)] Loss: -749.473816\n",
      "Train Epoch: 1745 [33792/54000 (63%)] Loss: -759.581665\n",
      "Train Epoch: 1745 [45056/54000 (83%)] Loss: -772.179932\n",
      "    epoch          : 1745\n",
      "    loss           : -774.3109436035156\n",
      "    ess            : 1.9612926986982238\n",
      "    log_marginal   : 774.3465063706884\n",
      "    log_joint      : 982.8997117528376\n",
      "    val_loss       : -779.0662740071615\n",
      "    val_ess        : 1.9601292610168457\n",
      "    val_log_marginal: 779.106201171875\n",
      "    val_log_joint  : 987.7958780924479\n",
      "Train Epoch: 1746 [0/54000 (0%)] Loss: -758.018494\n",
      "Train Epoch: 1746 [11264/54000 (21%)] Loss: -768.365295\n",
      "Train Epoch: 1746 [22528/54000 (42%)] Loss: -784.000732\n",
      "Train Epoch: 1746 [33792/54000 (63%)] Loss: -767.025330\n",
      "Train Epoch: 1746 [45056/54000 (83%)] Loss: -771.317749\n",
      "    epoch          : 1746\n",
      "    loss           : -774.333796087301\n",
      "    ess            : 1.9609087615642908\n",
      "    log_marginal   : 774.3707471163767\n",
      "    log_joint      : 982.8792298514888\n",
      "    val_loss       : -778.3802947998047\n",
      "    val_ess        : 1.9607178568840027\n",
      "    val_log_marginal: 778.4163411458334\n",
      "    val_log_joint  : 987.0713806152344\n",
      "Train Epoch: 1747 [0/54000 (0%)] Loss: -769.665283\n",
      "Train Epoch: 1747 [11264/54000 (21%)] Loss: -776.913330\n",
      "Train Epoch: 1747 [22528/54000 (42%)] Loss: -782.256836\n",
      "Train Epoch: 1747 [33792/54000 (63%)] Loss: -766.866394\n",
      "Train Epoch: 1747 [45056/54000 (83%)] Loss: -772.699829\n",
      "    epoch          : 1747\n",
      "    loss           : -774.1391636110702\n",
      "    ess            : 1.9597152055434461\n",
      "    log_marginal   : 774.1776975235849\n",
      "    log_joint      : 982.8646395701282\n",
      "    val_loss       : -778.9500376383463\n",
      "    val_ess        : 1.9628534813721974\n",
      "    val_log_marginal: 778.9849446614584\n",
      "    val_log_joint  : 987.4410196940104\n",
      "Train Epoch: 1748 [0/54000 (0%)] Loss: -774.257019\n",
      "Train Epoch: 1748 [11264/54000 (21%)] Loss: -765.605591\n",
      "Train Epoch: 1748 [22528/54000 (42%)] Loss: -777.695312\n",
      "Train Epoch: 1748 [33792/54000 (63%)] Loss: -781.857300\n",
      "Train Epoch: 1748 [45056/54000 (83%)] Loss: -755.127197\n",
      "    epoch          : 1748\n",
      "    loss           : -774.5262157512161\n",
      "    ess            : 1.9603622229594104\n",
      "    log_marginal   : 774.5631823269827\n",
      "    log_joint      : 983.0613668189859\n",
      "    val_loss       : -779.6702321370443\n",
      "    val_ess        : 1.9592177371184032\n",
      "    val_log_marginal: 779.708750406901\n",
      "    val_log_joint  : 988.1693776448568\n",
      "Train Epoch: 1749 [0/54000 (0%)] Loss: -743.268494\n",
      "Train Epoch: 1749 [11264/54000 (21%)] Loss: -782.513000\n",
      "Train Epoch: 1749 [22528/54000 (42%)] Loss: -761.021790\n",
      "Train Epoch: 1749 [33792/54000 (63%)] Loss: -777.090820\n",
      "Train Epoch: 1749 [45056/54000 (83%)] Loss: -766.496704\n",
      "    epoch          : 1749\n",
      "    loss           : -774.378424302587\n",
      "    ess            : 1.9612924062980797\n",
      "    log_marginal   : 774.4147287044885\n",
      "    log_joint      : 983.026129380712\n",
      "    val_loss       : -779.0201772054037\n",
      "    val_ess        : 1.9585045178731282\n",
      "    val_log_marginal: 779.0604248046875\n",
      "    val_log_joint  : 987.4504038492838\n",
      "Train Epoch: 1750 [0/54000 (0%)] Loss: -764.198303\n",
      "Train Epoch: 1750 [11264/54000 (21%)] Loss: -785.032837\n",
      "Train Epoch: 1750 [22528/54000 (42%)] Loss: -794.136841\n",
      "Train Epoch: 1750 [33792/54000 (63%)] Loss: -778.675415\n",
      "Train Epoch: 1750 [45056/54000 (83%)] Loss: -768.563538\n",
      "    epoch          : 1750\n",
      "    loss           : -774.4398193359375\n",
      "    ess            : 1.9604391736804314\n",
      "    log_marginal   : 774.4776755278965\n",
      "    log_joint      : 982.9922663850605\n",
      "    val_loss       : -778.7393035888672\n",
      "    val_ess        : 1.9639167090257008\n",
      "    val_log_marginal: 778.7733103434244\n",
      "    val_log_joint  : 987.320078531901\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1750.pth ...\n",
      "Train Epoch: 1751 [0/54000 (0%)] Loss: -782.358032\n",
      "Train Epoch: 1751 [11264/54000 (21%)] Loss: -769.414307\n",
      "Train Epoch: 1751 [22528/54000 (42%)] Loss: -780.593872\n",
      "Train Epoch: 1751 [33792/54000 (63%)] Loss: -753.856079\n",
      "Train Epoch: 1751 [45056/54000 (83%)] Loss: -774.045532\n",
      "    epoch          : 1751\n",
      "    loss           : -774.4371366680793\n",
      "    ess            : 1.9616778380465958\n",
      "    log_marginal   : 774.4723752579599\n",
      "    log_joint      : 983.0497286814564\n",
      "    val_loss       : -779.335927327474\n",
      "    val_ess        : 1.9593520561854045\n",
      "    val_log_marginal: 779.3779500325521\n",
      "    val_log_joint  : 987.692616780599\n",
      "Train Epoch: 1752 [0/54000 (0%)] Loss: -778.080200\n",
      "Train Epoch: 1752 [11264/54000 (21%)] Loss: -785.464966\n",
      "Train Epoch: 1752 [22528/54000 (42%)] Loss: -767.169556\n",
      "Train Epoch: 1752 [33792/54000 (63%)] Loss: -779.980164\n",
      "Train Epoch: 1752 [45056/54000 (83%)] Loss: -788.498291\n",
      "    epoch          : 1752\n",
      "    loss           : -774.2941019310141\n",
      "    ess            : 1.961278663491303\n",
      "    log_marginal   : 774.3312683105469\n",
      "    log_joint      : 982.8886643895563\n",
      "    val_loss       : -779.1236470540365\n",
      "    val_ess        : 1.9594833155473073\n",
      "    val_log_marginal: 779.1585540771484\n",
      "    val_log_joint  : 987.7434488932291\n",
      "Train Epoch: 1753 [0/54000 (0%)] Loss: -767.524292\n",
      "Train Epoch: 1753 [11264/54000 (21%)] Loss: -792.159668\n",
      "Train Epoch: 1753 [22528/54000 (42%)] Loss: -778.955444\n",
      "Train Epoch: 1753 [33792/54000 (63%)] Loss: -752.029541\n",
      "Train Epoch: 1753 [45056/54000 (83%)] Loss: -780.928467\n",
      "    epoch          : 1753\n",
      "    loss           : -774.5246466870578\n",
      "    ess            : 1.9614864576537654\n",
      "    log_marginal   : 774.5608065623157\n",
      "    log_joint      : 983.0344595279333\n",
      "    val_loss       : -779.6818898518881\n",
      "    val_ess        : 1.9629339476426442\n",
      "    val_log_marginal: 779.7139892578125\n",
      "    val_log_joint  : 988.4903513590494\n",
      "Train Epoch: 1754 [0/54000 (0%)] Loss: -757.833435\n",
      "Train Epoch: 1754 [11264/54000 (21%)] Loss: -763.978943\n",
      "Train Epoch: 1754 [22528/54000 (42%)] Loss: -784.994629\n",
      "Train Epoch: 1754 [33792/54000 (63%)] Loss: -781.445679\n",
      "Train Epoch: 1754 [45056/54000 (83%)] Loss: -763.174316\n",
      "    epoch          : 1754\n",
      "    loss           : -774.3978058437132\n",
      "    ess            : 1.9612807968877397\n",
      "    log_marginal   : 774.4342852898363\n",
      "    log_joint      : 982.9246739801371\n",
      "    val_loss       : -779.0832316080729\n",
      "    val_ess        : 1.9620671172936757\n",
      "    val_log_marginal: 779.1189931233724\n",
      "    val_log_joint  : 987.5800577799479\n",
      "Train Epoch: 1755 [0/54000 (0%)] Loss: -799.910034\n",
      "Train Epoch: 1755 [11264/54000 (21%)] Loss: -777.575500\n",
      "Train Epoch: 1755 [22528/54000 (42%)] Loss: -773.958374\n",
      "Train Epoch: 1755 [33792/54000 (63%)] Loss: -759.648743\n",
      "Train Epoch: 1755 [45056/54000 (83%)] Loss: -763.854248\n",
      "    epoch          : 1755\n",
      "    loss           : -774.3291401413252\n",
      "    ess            : 1.9606231653465416\n",
      "    log_marginal   : 774.3673349056604\n",
      "    log_joint      : 982.8956874631485\n",
      "    val_loss       : -779.0293477376302\n",
      "    val_ess        : 1.9622587164243062\n",
      "    val_log_marginal: 779.0687713623047\n",
      "    val_log_joint  : 987.4878743489584\n",
      "Train Epoch: 1756 [0/54000 (0%)] Loss: -760.549377\n",
      "Train Epoch: 1756 [11264/54000 (21%)] Loss: -776.401794\n",
      "Train Epoch: 1756 [22528/54000 (42%)] Loss: -800.059937\n",
      "Train Epoch: 1756 [33792/54000 (63%)] Loss: -756.796448\n",
      "Train Epoch: 1756 [45056/54000 (83%)] Loss: -766.357544\n",
      "    epoch          : 1756\n",
      "    loss           : -774.309940554061\n",
      "    ess            : 1.9606952655990169\n",
      "    log_marginal   : 774.347881389114\n",
      "    log_joint      : 982.9701895084021\n",
      "    val_loss       : -779.2003580729166\n",
      "    val_ess        : 1.9612482190132141\n",
      "    val_log_marginal: 779.2347208658854\n",
      "    val_log_joint  : 987.7217102050781\n",
      "Train Epoch: 1757 [0/54000 (0%)] Loss: -783.454834\n",
      "Train Epoch: 1757 [11264/54000 (21%)] Loss: -785.595825\n",
      "Train Epoch: 1757 [22528/54000 (42%)] Loss: -766.220825\n",
      "Train Epoch: 1757 [33792/54000 (63%)] Loss: -783.730286\n",
      "Train Epoch: 1757 [45056/54000 (83%)] Loss: -790.019653\n",
      "    epoch          : 1757\n",
      "    loss           : -774.2629463627653\n",
      "    ess            : 1.9613716017525151\n",
      "    log_marginal   : 774.3003401846256\n",
      "    log_joint      : 982.6965182322376\n",
      "    val_loss       : -778.5713348388672\n",
      "    val_ess        : 1.961555818716685\n",
      "    val_log_marginal: 778.6103820800781\n",
      "    val_log_joint  : 987.0593821207682\n",
      "Train Epoch: 1758 [0/54000 (0%)] Loss: -783.061523\n",
      "Train Epoch: 1758 [11264/54000 (21%)] Loss: -790.636597\n",
      "Train Epoch: 1758 [22528/54000 (42%)] Loss: -792.945801\n",
      "Train Epoch: 1758 [33792/54000 (63%)] Loss: -749.702881\n",
      "Train Epoch: 1758 [45056/54000 (83%)] Loss: -766.529419\n",
      "    epoch          : 1758\n",
      "    loss           : -774.3620369389372\n",
      "    ess            : 1.9605905379889146\n",
      "    log_marginal   : 774.3992332602447\n",
      "    log_joint      : 982.9430755039431\n",
      "    val_loss       : -778.4897054036459\n",
      "    val_ess        : 1.960698922475179\n",
      "    val_log_marginal: 778.5285034179688\n",
      "    val_log_joint  : 987.3153279622396\n",
      "Train Epoch: 1759 [0/54000 (0%)] Loss: -788.618042\n",
      "Train Epoch: 1759 [11264/54000 (21%)] Loss: -764.974243\n",
      "Train Epoch: 1759 [22528/54000 (42%)] Loss: -777.082642\n",
      "Train Epoch: 1759 [33792/54000 (63%)] Loss: -765.051819\n",
      "Train Epoch: 1759 [45056/54000 (83%)] Loss: -787.319092\n",
      "    epoch          : 1759\n",
      "    loss           : -774.4565423929466\n",
      "    ess            : 1.9606643330376103\n",
      "    log_marginal   : 774.4931393029555\n",
      "    log_joint      : 982.9965353911778\n",
      "    val_loss       : -778.2970174153646\n",
      "    val_ess        : 1.956516683101654\n",
      "    val_log_marginal: 778.3414154052734\n",
      "    val_log_joint  : 987.1305694580078\n",
      "Train Epoch: 1760 [0/54000 (0%)] Loss: -754.853394\n",
      "Train Epoch: 1760 [11264/54000 (21%)] Loss: -792.539246\n",
      "Train Epoch: 1760 [22528/54000 (42%)] Loss: -777.823730\n",
      "Train Epoch: 1760 [33792/54000 (63%)] Loss: -764.329529\n",
      "Train Epoch: 1760 [45056/54000 (83%)] Loss: -779.327759\n",
      "    epoch          : 1760\n",
      "    loss           : -774.3807223338001\n",
      "    ess            : 1.9610769062672022\n",
      "    log_marginal   : 774.4178501345077\n",
      "    log_joint      : 983.0207692272259\n",
      "    val_loss       : -779.2826894124349\n",
      "    val_ess        : 1.963548978169759\n",
      "    val_log_marginal: 779.3163146972656\n",
      "    val_log_joint  : 988.0225016276041\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1760.pth ...\n",
      "Train Epoch: 1761 [0/54000 (0%)] Loss: -787.525757\n",
      "Train Epoch: 1761 [11264/54000 (21%)] Loss: -777.826477\n",
      "Train Epoch: 1761 [22528/54000 (42%)] Loss: -739.229065\n",
      "Train Epoch: 1761 [33792/54000 (63%)] Loss: -775.740845\n",
      "Train Epoch: 1761 [45056/54000 (83%)] Loss: -773.452271\n",
      "    epoch          : 1761\n",
      "    loss           : -774.522413145821\n",
      "    ess            : 1.9600939413286604\n",
      "    log_marginal   : 774.5588292535746\n",
      "    log_joint      : 983.0880748820755\n",
      "    val_loss       : -779.5766805013021\n",
      "    val_ess        : 1.9585327406724293\n",
      "    val_log_marginal: 779.6164499918619\n",
      "    val_log_joint  : 988.3600006103516\n",
      "Train Epoch: 1762 [0/54000 (0%)] Loss: -749.464111\n",
      "Train Epoch: 1762 [11264/54000 (21%)] Loss: -777.973328\n",
      "Train Epoch: 1762 [22528/54000 (42%)] Loss: -777.603088\n",
      "Train Epoch: 1762 [33792/54000 (63%)] Loss: -781.401489\n",
      "Train Epoch: 1762 [45056/54000 (83%)] Loss: -773.215332\n",
      "    epoch          : 1762\n",
      "    loss           : -774.2342454442438\n",
      "    ess            : 1.960769439643284\n",
      "    log_marginal   : 774.2709016619988\n",
      "    log_joint      : 982.8431143130896\n",
      "    val_loss       : -779.1243336995443\n",
      "    val_ess        : 1.9607410232226055\n",
      "    val_log_marginal: 779.1595458984375\n",
      "    val_log_joint  : 987.6158345540365\n",
      "Train Epoch: 1763 [0/54000 (0%)] Loss: -785.365845\n",
      "Train Epoch: 1763 [11264/54000 (21%)] Loss: -765.218750\n",
      "Train Epoch: 1763 [22528/54000 (42%)] Loss: -762.034729\n",
      "Train Epoch: 1763 [33792/54000 (63%)] Loss: -779.811523\n",
      "Train Epoch: 1763 [45056/54000 (83%)] Loss: -773.994263\n",
      "    epoch          : 1763\n",
      "    loss           : -774.4808706607458\n",
      "    ess            : 1.9613865917583682\n",
      "    log_marginal   : 774.518198841023\n",
      "    log_joint      : 983.0841968464401\n",
      "    val_loss       : -779.2088419596354\n",
      "    val_ess        : 1.960644394159317\n",
      "    val_log_marginal: 779.2451527913412\n",
      "    val_log_joint  : 987.7295583089193\n",
      "Train Epoch: 1764 [0/54000 (0%)] Loss: -763.249573\n",
      "Train Epoch: 1764 [11264/54000 (21%)] Loss: -753.335022\n",
      "Train Epoch: 1764 [22528/54000 (42%)] Loss: -776.147278\n",
      "Train Epoch: 1764 [33792/54000 (63%)] Loss: -787.423035\n",
      "Train Epoch: 1764 [45056/54000 (83%)] Loss: -771.936523\n",
      "    epoch          : 1764\n",
      "    loss           : -774.4813169083505\n",
      "    ess            : 1.96127276825455\n",
      "    log_marginal   : 774.5174180516657\n",
      "    log_joint      : 983.0976263082252\n",
      "    val_loss       : -778.2204081217448\n",
      "    val_ess        : 1.9592765768369038\n",
      "    val_log_marginal: 778.2597808837891\n",
      "    val_log_joint  : 987.0092061360677\n",
      "Train Epoch: 1765 [0/54000 (0%)] Loss: -778.367432\n",
      "Train Epoch: 1765 [11264/54000 (21%)] Loss: -751.472046\n",
      "Train Epoch: 1765 [22528/54000 (42%)] Loss: -763.260925\n",
      "Train Epoch: 1765 [33792/54000 (63%)] Loss: -774.491211\n",
      "Train Epoch: 1765 [45056/54000 (83%)] Loss: -766.719238\n",
      "    epoch          : 1765\n",
      "    loss           : -774.5042707335274\n",
      "    ess            : 1.9616948231211249\n",
      "    log_marginal   : 774.5399780273438\n",
      "    log_joint      : 983.0948071749705\n",
      "    val_loss       : -778.833974202474\n",
      "    val_ess        : 1.9571293791135151\n",
      "    val_log_marginal: 778.8745371500651\n",
      "    val_log_joint  : 987.4394734700521\n",
      "Train Epoch: 1766 [0/54000 (0%)] Loss: -782.838745\n",
      "Train Epoch: 1766 [11264/54000 (21%)] Loss: -770.574707\n",
      "Train Epoch: 1766 [22528/54000 (42%)] Loss: -787.192261\n",
      "Train Epoch: 1766 [33792/54000 (63%)] Loss: -769.769043\n",
      "Train Epoch: 1766 [45056/54000 (83%)] Loss: -797.570496\n",
      "    epoch          : 1766\n",
      "    loss           : -774.4977912183078\n",
      "    ess            : 1.9606791374818333\n",
      "    log_marginal   : 774.5351101857311\n",
      "    log_joint      : 983.0835156710642\n",
      "    val_loss       : -778.4739430745443\n",
      "    val_ess        : 1.959435224533081\n",
      "    val_log_marginal: 778.5107727050781\n",
      "    val_log_joint  : 987.1683044433594\n",
      "Train Epoch: 1767 [0/54000 (0%)] Loss: -745.503235\n",
      "Train Epoch: 1767 [11264/54000 (21%)] Loss: -786.668701\n",
      "Train Epoch: 1767 [22528/54000 (42%)] Loss: -773.091187\n",
      "Train Epoch: 1767 [33792/54000 (63%)] Loss: -779.046509\n",
      "Train Epoch: 1767 [45056/54000 (83%)] Loss: -769.387451\n",
      "    epoch          : 1767\n",
      "    loss           : -774.5900717681309\n",
      "    ess            : 1.960219736369151\n",
      "    log_marginal   : 774.6283868753685\n",
      "    log_joint      : 983.0906429650648\n",
      "    val_loss       : -779.1026509602865\n",
      "    val_ess        : 1.9569444954395294\n",
      "    val_log_marginal: 779.1473846435547\n",
      "    val_log_joint  : 987.7481028238932\n",
      "Train Epoch: 1768 [0/54000 (0%)] Loss: -784.217651\n",
      "Train Epoch: 1768 [11264/54000 (21%)] Loss: -780.150391\n",
      "Train Epoch: 1768 [22528/54000 (42%)] Loss: -774.059998\n",
      "Train Epoch: 1768 [33792/54000 (63%)] Loss: -767.640686\n",
      "Train Epoch: 1768 [45056/54000 (83%)] Loss: -772.625000\n",
      "    epoch          : 1768\n",
      "    loss           : -774.6437723411703\n",
      "    ess            : 1.961127518482928\n",
      "    log_marginal   : 774.6807728893352\n",
      "    log_joint      : 983.2106576595667\n",
      "    val_loss       : -779.0542856852213\n",
      "    val_ess        : 1.961241364479065\n",
      "    val_log_marginal: 779.0898030598959\n",
      "    val_log_joint  : 987.6786193847656\n",
      "Train Epoch: 1769 [0/54000 (0%)] Loss: -772.512207\n",
      "Train Epoch: 1769 [11264/54000 (21%)] Loss: -766.728455\n",
      "Train Epoch: 1769 [22528/54000 (42%)] Loss: -771.720154\n",
      "Train Epoch: 1769 [33792/54000 (63%)] Loss: -788.469482\n",
      "Train Epoch: 1769 [45056/54000 (83%)] Loss: -772.443237\n",
      "    epoch          : 1769\n",
      "    loss           : -774.6191089558151\n",
      "    ess            : 1.9613103866577148\n",
      "    log_marginal   : 774.6560150722288\n",
      "    log_joint      : 983.1668338415758\n",
      "    val_loss       : -778.5590616861979\n",
      "    val_ess        : 1.9615122179190319\n",
      "    val_log_marginal: 778.5920969645182\n",
      "    val_log_joint  : 987.3501942952474\n",
      "Train Epoch: 1770 [0/54000 (0%)] Loss: -761.192566\n",
      "Train Epoch: 1770 [11264/54000 (21%)] Loss: -782.188843\n",
      "Train Epoch: 1770 [22528/54000 (42%)] Loss: -781.713928\n",
      "Train Epoch: 1770 [33792/54000 (63%)] Loss: -750.657227\n",
      "Train Epoch: 1770 [45056/54000 (83%)] Loss: -766.406921\n",
      "    epoch          : 1770\n",
      "    loss           : -774.5675382794075\n",
      "    ess            : 1.9608969755892485\n",
      "    log_marginal   : 774.605098508439\n",
      "    log_joint      : 983.1652388662662\n",
      "    val_loss       : -778.6420237223307\n",
      "    val_ess        : 1.9655383328596752\n",
      "    val_log_marginal: 778.6722157796224\n",
      "    val_log_joint  : 987.0402018229166\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1770.pth ...\n",
      "Train Epoch: 1771 [0/54000 (0%)] Loss: -778.226746\n",
      "Train Epoch: 1771 [11264/54000 (21%)] Loss: -771.685669\n",
      "Train Epoch: 1771 [22528/54000 (42%)] Loss: -773.398254\n",
      "Train Epoch: 1771 [33792/54000 (63%)] Loss: -780.901306\n",
      "Train Epoch: 1771 [45056/54000 (83%)] Loss: -788.354675\n",
      "    epoch          : 1771\n",
      "    loss           : -774.7366131476637\n",
      "    ess            : 1.9599708105033298\n",
      "    log_marginal   : 774.7767604611954\n",
      "    log_joint      : 983.2406103745947\n",
      "    val_loss       : -779.9795074462891\n",
      "    val_ess        : 1.96018581589063\n",
      "    val_log_marginal: 780.0179595947266\n",
      "    val_log_joint  : 988.3429311116537\n",
      "Train Epoch: 1772 [0/54000 (0%)] Loss: -763.428650\n",
      "Train Epoch: 1772 [11264/54000 (21%)] Loss: -786.237915\n",
      "Train Epoch: 1772 [22528/54000 (42%)] Loss: -771.226746\n",
      "Train Epoch: 1772 [33792/54000 (63%)] Loss: -775.816528\n",
      "Train Epoch: 1772 [45056/54000 (83%)] Loss: -763.531006\n",
      "    epoch          : 1772\n",
      "    loss           : -774.6110598006338\n",
      "    ess            : 1.9611132707235948\n",
      "    log_marginal   : 774.6478242694207\n",
      "    log_joint      : 983.0242159861439\n",
      "    val_loss       : -779.5206146240234\n",
      "    val_ess        : 1.9573674996693928\n",
      "    val_log_marginal: 779.5621337890625\n",
      "    val_log_joint  : 988.0880737304688\n",
      "Train Epoch: 1773 [0/54000 (0%)] Loss: -737.751831\n",
      "Train Epoch: 1773 [11264/54000 (21%)] Loss: -766.407104\n",
      "Train Epoch: 1773 [22528/54000 (42%)] Loss: -770.636597\n",
      "Train Epoch: 1773 [33792/54000 (63%)] Loss: -771.344666\n",
      "Train Epoch: 1773 [45056/54000 (83%)] Loss: -772.018005\n",
      "    epoch          : 1773\n",
      "    loss           : -774.5535859881707\n",
      "    ess            : 1.9597253102176595\n",
      "    log_marginal   : 774.5915308538473\n",
      "    log_joint      : 983.1597474296138\n",
      "    val_loss       : -778.9902648925781\n",
      "    val_ess        : 1.957688311735789\n",
      "    val_log_marginal: 779.0289560953776\n",
      "    val_log_joint  : 987.5561676025391\n",
      "Train Epoch: 1774 [0/54000 (0%)] Loss: -770.326477\n",
      "Train Epoch: 1774 [11264/54000 (21%)] Loss: -781.583008\n",
      "Train Epoch: 1774 [22528/54000 (42%)] Loss: -758.783813\n",
      "Train Epoch: 1774 [33792/54000 (63%)] Loss: -797.082642\n",
      "Train Epoch: 1774 [45056/54000 (83%)] Loss: -763.876221\n",
      "    epoch          : 1774\n",
      "    loss           : -774.4074649450914\n",
      "    ess            : 1.9605505893815238\n",
      "    log_marginal   : 774.4450723899985\n",
      "    log_joint      : 983.079631301592\n",
      "    val_loss       : -779.4300333658854\n",
      "    val_ess        : 1.960105945666631\n",
      "    val_log_marginal: 779.4653472900391\n",
      "    val_log_joint  : 988.1271514892578\n",
      "Train Epoch: 1775 [0/54000 (0%)] Loss: -769.275879\n",
      "Train Epoch: 1775 [11264/54000 (21%)] Loss: -753.932129\n",
      "Train Epoch: 1775 [22528/54000 (42%)] Loss: -767.656860\n",
      "Train Epoch: 1775 [33792/54000 (63%)] Loss: -772.651611\n",
      "Train Epoch: 1775 [45056/54000 (83%)] Loss: -765.862183\n",
      "    epoch          : 1775\n",
      "    loss           : -774.5482379265551\n",
      "    ess            : 1.9614868433970325\n",
      "    log_marginal   : 774.5853444225384\n",
      "    log_joint      : 983.0927912874042\n",
      "    val_loss       : -779.6569112141927\n",
      "    val_ess        : 1.9606608947118123\n",
      "    val_log_marginal: 779.6935323079427\n",
      "    val_log_joint  : 988.1180979410807\n",
      "Train Epoch: 1776 [0/54000 (0%)] Loss: -781.682678\n",
      "Train Epoch: 1776 [11264/54000 (21%)] Loss: -748.478271\n",
      "Train Epoch: 1776 [22528/54000 (42%)] Loss: -750.163513\n",
      "Train Epoch: 1776 [33792/54000 (63%)] Loss: -786.173035\n",
      "Train Epoch: 1776 [45056/54000 (83%)] Loss: -775.851318\n",
      "    epoch          : 1776\n",
      "    loss           : -774.719747291421\n",
      "    ess            : 1.9622761483462352\n",
      "    log_marginal   : 774.7549277251621\n",
      "    log_joint      : 983.2821476774395\n",
      "    val_loss       : -779.2273457845052\n",
      "    val_ess        : 1.9643842180569966\n",
      "    val_log_marginal: 779.2615814208984\n",
      "    val_log_joint  : 987.7570851643881\n",
      "Train Epoch: 1777 [0/54000 (0%)] Loss: -788.811646\n",
      "Train Epoch: 1777 [11264/54000 (21%)] Loss: -785.478149\n",
      "Train Epoch: 1777 [22528/54000 (42%)] Loss: -771.748291\n",
      "Train Epoch: 1777 [33792/54000 (63%)] Loss: -770.377441\n",
      "Train Epoch: 1777 [45056/54000 (83%)] Loss: -777.254211\n",
      "    epoch          : 1777\n",
      "    loss           : -774.5580795575987\n",
      "    ess            : 1.9604212214361947\n",
      "    log_marginal   : 774.5956564849278\n",
      "    log_joint      : 983.117773092018\n",
      "    val_loss       : -779.3133036295573\n",
      "    val_ess        : 1.9600989818572998\n",
      "    val_log_marginal: 779.3526560465494\n",
      "    val_log_joint  : 988.0609995524088\n",
      "Train Epoch: 1778 [0/54000 (0%)] Loss: -796.815674\n",
      "Train Epoch: 1778 [11264/54000 (21%)] Loss: -773.569336\n",
      "Train Epoch: 1778 [22528/54000 (42%)] Loss: -773.890503\n",
      "Train Epoch: 1778 [33792/54000 (63%)] Loss: -753.296082\n",
      "Train Epoch: 1778 [45056/54000 (83%)] Loss: -782.297424\n",
      "    epoch          : 1778\n",
      "    loss           : -774.6191607781176\n",
      "    ess            : 1.960784009042776\n",
      "    log_marginal   : 774.6563927992335\n",
      "    log_joint      : 983.1853706791716\n",
      "    val_loss       : -778.5088094075521\n",
      "    val_ess        : 1.9599857926368713\n",
      "    val_log_marginal: 778.5531717936198\n",
      "    val_log_joint  : 987.382314046224\n",
      "Train Epoch: 1779 [0/54000 (0%)] Loss: -762.770996\n",
      "Train Epoch: 1779 [11264/54000 (21%)] Loss: -786.243225\n",
      "Train Epoch: 1779 [22528/54000 (42%)] Loss: -770.029907\n",
      "Train Epoch: 1779 [33792/54000 (63%)] Loss: -775.826721\n",
      "Train Epoch: 1779 [45056/54000 (83%)] Loss: -777.570129\n",
      "    epoch          : 1779\n",
      "    loss           : -774.8012476507223\n",
      "    ess            : 1.9604154004240937\n",
      "    log_marginal   : 774.8378457123379\n",
      "    log_joint      : 983.3436624778891\n",
      "    val_loss       : -779.4252878824869\n",
      "    val_ess        : 1.962158481280009\n",
      "    val_log_marginal: 779.4630432128906\n",
      "    val_log_joint  : 988.0970662434896\n",
      "Train Epoch: 1780 [0/54000 (0%)] Loss: -778.792114\n",
      "Train Epoch: 1780 [11264/54000 (21%)] Loss: -754.701599\n",
      "Train Epoch: 1780 [22528/54000 (42%)] Loss: -767.239990\n",
      "Train Epoch: 1780 [33792/54000 (63%)] Loss: -763.278442\n",
      "Train Epoch: 1780 [45056/54000 (83%)] Loss: -756.500854\n",
      "    epoch          : 1780\n",
      "    loss           : -774.9334831957547\n",
      "    ess            : 1.9601681142483118\n",
      "    log_marginal   : 774.9715979234228\n",
      "    log_joint      : 983.420083099941\n",
      "    val_loss       : -779.3569793701172\n",
      "    val_ess        : 1.9632089932759602\n",
      "    val_log_marginal: 779.3919474283854\n",
      "    val_log_joint  : 987.7510681152344\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1780.pth ...\n",
      "Train Epoch: 1781 [0/54000 (0%)] Loss: -771.989502\n",
      "Train Epoch: 1781 [11264/54000 (21%)] Loss: -783.695679\n",
      "Train Epoch: 1781 [22528/54000 (42%)] Loss: -786.340027\n",
      "Train Epoch: 1781 [33792/54000 (63%)] Loss: -764.709106\n",
      "Train Epoch: 1781 [45056/54000 (83%)] Loss: -779.445862\n",
      "    epoch          : 1781\n",
      "    loss           : -774.588769876732\n",
      "    ess            : 1.9610560716323133\n",
      "    log_marginal   : 774.6268120531765\n",
      "    log_joint      : 983.1612186072008\n",
      "    val_loss       : -779.5048014322916\n",
      "    val_ess        : 1.9605475862820942\n",
      "    val_log_marginal: 779.5444488525391\n",
      "    val_log_joint  : 988.1096801757812\n",
      "Train Epoch: 1782 [0/54000 (0%)] Loss: -770.966187\n",
      "Train Epoch: 1782 [11264/54000 (21%)] Loss: -763.139648\n",
      "Train Epoch: 1782 [22528/54000 (42%)] Loss: -776.486572\n",
      "Train Epoch: 1782 [33792/54000 (63%)] Loss: -776.171631\n",
      "Train Epoch: 1782 [45056/54000 (83%)] Loss: -772.323975\n",
      "    epoch          : 1782\n",
      "    loss           : -774.8859264445755\n",
      "    ess            : 1.960076832546378\n",
      "    log_marginal   : 774.9240941461527\n",
      "    log_joint      : 983.4649848218235\n",
      "    val_loss       : -778.9704284667969\n",
      "    val_ess        : 1.960969905058543\n",
      "    val_log_marginal: 779.0050862630209\n",
      "    val_log_joint  : 987.518798828125\n",
      "Train Epoch: 1783 [0/54000 (0%)] Loss: -765.412354\n",
      "Train Epoch: 1783 [11264/54000 (21%)] Loss: -775.813599\n",
      "Train Epoch: 1783 [22528/54000 (42%)] Loss: -772.610779\n",
      "Train Epoch: 1783 [33792/54000 (63%)] Loss: -789.952515\n",
      "Train Epoch: 1783 [45056/54000 (83%)] Loss: -760.035278\n",
      "    epoch          : 1783\n",
      "    loss           : -774.7268837982754\n",
      "    ess            : 1.9608565321508444\n",
      "    log_marginal   : 774.7635970205631\n",
      "    log_joint      : 983.2850272700472\n",
      "    val_loss       : -779.4593454996744\n",
      "    val_ess        : 1.9594352940718334\n",
      "    val_log_marginal: 779.4988708496094\n",
      "    val_log_joint  : 988.0057525634766\n",
      "Train Epoch: 1784 [0/54000 (0%)] Loss: -764.224976\n",
      "Train Epoch: 1784 [11264/54000 (21%)] Loss: -776.242188\n",
      "Train Epoch: 1784 [22528/54000 (42%)] Loss: -777.408630\n",
      "Train Epoch: 1784 [33792/54000 (63%)] Loss: -766.542908\n",
      "Train Epoch: 1784 [45056/54000 (83%)] Loss: -784.486328\n",
      "    epoch          : 1784\n",
      "    loss           : -774.9150972186394\n",
      "    ess            : 1.9605003764044564\n",
      "    log_marginal   : 774.9523470896595\n",
      "    log_joint      : 983.4119907595077\n",
      "    val_loss       : -778.7530364990234\n",
      "    val_ess        : 1.964946856101354\n",
      "    val_log_marginal: 778.7837829589844\n",
      "    val_log_joint  : 987.3305969238281\n",
      "Train Epoch: 1785 [0/54000 (0%)] Loss: -756.529846\n",
      "Train Epoch: 1785 [11264/54000 (21%)] Loss: -780.371338\n",
      "Train Epoch: 1785 [22528/54000 (42%)] Loss: -756.879272\n",
      "Train Epoch: 1785 [33792/54000 (63%)] Loss: -770.024780\n",
      "Train Epoch: 1785 [45056/54000 (83%)] Loss: -755.890686\n",
      "    epoch          : 1785\n",
      "    loss           : -774.7124034953567\n",
      "    ess            : 1.9616505346208248\n",
      "    log_marginal   : 774.7488627883623\n",
      "    log_joint      : 983.2443196998453\n",
      "    val_loss       : -778.6933848063151\n",
      "    val_ess        : 1.9621813396612804\n",
      "    val_log_marginal: 778.7323404947916\n",
      "    val_log_joint  : 987.1341807047526\n",
      "Train Epoch: 1786 [0/54000 (0%)] Loss: -785.030823\n",
      "Train Epoch: 1786 [11264/54000 (21%)] Loss: -795.644836\n",
      "Train Epoch: 1786 [22528/54000 (42%)] Loss: -755.296875\n",
      "Train Epoch: 1786 [33792/54000 (63%)] Loss: -773.933228\n",
      "Train Epoch: 1786 [45056/54000 (83%)] Loss: -778.432983\n",
      "    epoch          : 1786\n",
      "    loss           : -774.6379020259066\n",
      "    ess            : 1.9610583377334307\n",
      "    log_marginal   : 774.6741033590065\n",
      "    log_joint      : 983.1744085347877\n",
      "    val_loss       : -778.9800720214844\n",
      "    val_ess        : 1.9589184323946636\n",
      "    val_log_marginal: 779.0222829182943\n",
      "    val_log_joint  : 987.4161732991537\n",
      "Train Epoch: 1787 [0/54000 (0%)] Loss: -793.791199\n",
      "Train Epoch: 1787 [11264/54000 (21%)] Loss: -758.161438\n",
      "Train Epoch: 1787 [22528/54000 (42%)] Loss: -783.312256\n",
      "Train Epoch: 1787 [33792/54000 (63%)] Loss: -757.446167\n",
      "Train Epoch: 1787 [45056/54000 (83%)] Loss: -776.711182\n",
      "    epoch          : 1787\n",
      "    loss           : -774.7527235498968\n",
      "    ess            : 1.9601153573899899\n",
      "    log_marginal   : 774.7900500027639\n",
      "    log_joint      : 983.3071836075693\n",
      "    val_loss       : -778.021738688151\n",
      "    val_ess        : 1.9650740722815196\n",
      "    val_log_marginal: 778.0526885986328\n",
      "    val_log_joint  : 986.8772837320963\n",
      "Train Epoch: 1788 [0/54000 (0%)] Loss: -770.845825\n",
      "Train Epoch: 1788 [11264/54000 (21%)] Loss: -750.894226\n",
      "Train Epoch: 1788 [22528/54000 (42%)] Loss: -783.852539\n",
      "Train Epoch: 1788 [33792/54000 (63%)] Loss: -776.226257\n",
      "Train Epoch: 1788 [45056/54000 (83%)] Loss: -771.659363\n",
      "    epoch          : 1788\n",
      "    loss           : -774.7934213314417\n",
      "    ess            : 1.9609422076423213\n",
      "    log_marginal   : 774.8302618062721\n",
      "    log_joint      : 983.3332415886645\n",
      "    val_loss       : -779.3280232747396\n",
      "    val_ess        : 1.9625786642233531\n",
      "    val_log_marginal: 779.3678588867188\n",
      "    val_log_joint  : 987.8059132893881\n",
      "Train Epoch: 1789 [0/54000 (0%)] Loss: -765.907104\n",
      "Train Epoch: 1789 [11264/54000 (21%)] Loss: -794.296936\n",
      "Train Epoch: 1789 [22528/54000 (42%)] Loss: -794.025024\n",
      "Train Epoch: 1789 [33792/54000 (63%)] Loss: -779.722412\n",
      "Train Epoch: 1789 [45056/54000 (83%)] Loss: -767.059021\n",
      "    epoch          : 1789\n",
      "    loss           : -774.7826584150206\n",
      "    ess            : 1.9602562863871735\n",
      "    log_marginal   : 774.819623263377\n",
      "    log_joint      : 983.2935324614903\n",
      "    val_loss       : -778.6139780680338\n",
      "    val_ess        : 1.9593061705430348\n",
      "    val_log_marginal: 778.654551188151\n",
      "    val_log_joint  : 987.2373962402344\n",
      "Train Epoch: 1790 [0/54000 (0%)] Loss: -776.617371\n",
      "Train Epoch: 1790 [11264/54000 (21%)] Loss: -747.527832\n",
      "Train Epoch: 1790 [22528/54000 (42%)] Loss: -738.152100\n",
      "Train Epoch: 1790 [33792/54000 (63%)] Loss: -767.645630\n",
      "Train Epoch: 1790 [45056/54000 (83%)] Loss: -801.820801\n",
      "    epoch          : 1790\n",
      "    loss           : -774.79659573537\n",
      "    ess            : 1.9612052328181717\n",
      "    log_marginal   : 774.8328039781103\n",
      "    log_joint      : 983.3748485637161\n",
      "    val_loss       : -779.1719919840494\n",
      "    val_ess        : 1.9616987605889638\n",
      "    val_log_marginal: 779.2059478759766\n",
      "    val_log_joint  : 987.8575286865234\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1790.pth ...\n",
      "Train Epoch: 1791 [0/54000 (0%)] Loss: -768.316528\n",
      "Train Epoch: 1791 [11264/54000 (21%)] Loss: -784.067871\n",
      "Train Epoch: 1791 [22528/54000 (42%)] Loss: -785.729004\n",
      "Train Epoch: 1791 [33792/54000 (63%)] Loss: -787.960571\n",
      "Train Epoch: 1791 [45056/54000 (83%)] Loss: -790.726929\n",
      "    epoch          : 1791\n",
      "    loss           : -774.7912223384066\n",
      "    ess            : 1.961465931163644\n",
      "    log_marginal   : 774.828131333837\n",
      "    log_joint      : 983.3132940328346\n",
      "    val_loss       : -779.3102416992188\n",
      "    val_ess        : 1.9608878195285797\n",
      "    val_log_marginal: 779.3461659749349\n",
      "    val_log_joint  : 988.0877380371094\n",
      "Train Epoch: 1792 [0/54000 (0%)] Loss: -778.047119\n",
      "Train Epoch: 1792 [11264/54000 (21%)] Loss: -768.965149\n",
      "Train Epoch: 1792 [22528/54000 (42%)] Loss: -770.716675\n",
      "Train Epoch: 1792 [33792/54000 (63%)] Loss: -766.195923\n",
      "Train Epoch: 1792 [45056/54000 (83%)] Loss: -775.659058\n",
      "    epoch          : 1792\n",
      "    loss           : -774.8173373240345\n",
      "    ess            : 1.9606149781425044\n",
      "    log_marginal   : 774.8544311523438\n",
      "    log_joint      : 983.3867233564268\n",
      "    val_loss       : -779.8438720703125\n",
      "    val_ess        : 1.9605040550231934\n",
      "    val_log_marginal: 779.8824412027994\n",
      "    val_log_joint  : 988.3258412679037\n",
      "Train Epoch: 1793 [0/54000 (0%)] Loss: -787.885864\n",
      "Train Epoch: 1793 [11264/54000 (21%)] Loss: -753.147278\n",
      "Train Epoch: 1793 [22528/54000 (42%)] Loss: -752.067261\n",
      "Train Epoch: 1793 [33792/54000 (63%)] Loss: -763.075012\n",
      "Train Epoch: 1793 [45056/54000 (83%)] Loss: -772.250366\n",
      "    epoch          : 1793\n",
      "    loss           : -774.8807804899395\n",
      "    ess            : 1.9603303772098613\n",
      "    log_marginal   : 774.9185940724499\n",
      "    log_joint      : 983.4433680120504\n",
      "    val_loss       : -779.0243937174479\n",
      "    val_ess        : 1.959541767835617\n",
      "    val_log_marginal: 779.0640513102213\n",
      "    val_log_joint  : 987.6913045247396\n",
      "Train Epoch: 1794 [0/54000 (0%)] Loss: -782.429871\n",
      "Train Epoch: 1794 [11264/54000 (21%)] Loss: -768.024902\n",
      "Train Epoch: 1794 [22528/54000 (42%)] Loss: -774.362305\n",
      "Train Epoch: 1794 [33792/54000 (63%)] Loss: -774.012207\n",
      "Train Epoch: 1794 [45056/54000 (83%)] Loss: -746.622070\n",
      "    epoch          : 1794\n",
      "    loss           : -774.9586953217129\n",
      "    ess            : 1.961370125131787\n",
      "    log_marginal   : 774.996323495541\n",
      "    log_joint      : 983.4253436394457\n",
      "    val_loss       : -778.8830617268881\n",
      "    val_ess        : 1.9583129386107128\n",
      "    val_log_marginal: 778.9219512939453\n",
      "    val_log_joint  : 987.1728210449219\n",
      "Train Epoch: 1795 [0/54000 (0%)] Loss: -763.645020\n",
      "Train Epoch: 1795 [11264/54000 (21%)] Loss: -779.938721\n",
      "Train Epoch: 1795 [22528/54000 (42%)] Loss: -781.096802\n",
      "Train Epoch: 1795 [33792/54000 (63%)] Loss: -776.037354\n",
      "Train Epoch: 1795 [45056/54000 (83%)] Loss: -752.965454\n",
      "    epoch          : 1795\n",
      "    loss           : -774.7090920502285\n",
      "    ess            : 1.961004467505329\n",
      "    log_marginal   : 774.7458000902859\n",
      "    log_joint      : 983.2979062638193\n",
      "    val_loss       : -779.4821268717448\n",
      "    val_ess        : 1.9607623318831127\n",
      "    val_log_marginal: 779.5181681315104\n",
      "    val_log_joint  : 987.9728597005209\n",
      "Train Epoch: 1796 [0/54000 (0%)] Loss: -806.738647\n",
      "Train Epoch: 1796 [11264/54000 (21%)] Loss: -761.528931\n",
      "Train Epoch: 1796 [22528/54000 (42%)] Loss: -778.004395\n",
      "Train Epoch: 1796 [33792/54000 (63%)] Loss: -784.303833\n",
      "Train Epoch: 1796 [45056/54000 (83%)] Loss: -750.539429\n",
      "    epoch          : 1796\n",
      "    loss           : -774.6859136617409\n",
      "    ess            : 1.9619496745883294\n",
      "    log_marginal   : 774.720988723467\n",
      "    log_joint      : 983.2193666853995\n",
      "    val_loss       : -779.3038686116537\n",
      "    val_ess        : 1.9604904452959697\n",
      "    val_log_marginal: 779.3432159423828\n",
      "    val_log_joint  : 987.6995493570963\n",
      "Train Epoch: 1797 [0/54000 (0%)] Loss: -781.785034\n",
      "Train Epoch: 1797 [11264/54000 (21%)] Loss: -772.321167\n",
      "Train Epoch: 1797 [22528/54000 (42%)] Loss: -772.949219\n",
      "Train Epoch: 1797 [33792/54000 (63%)] Loss: -747.243713\n",
      "Train Epoch: 1797 [45056/54000 (83%)] Loss: -766.516174\n",
      "    epoch          : 1797\n",
      "    loss           : -774.7465566959021\n",
      "    ess            : 1.9614561233880385\n",
      "    log_marginal   : 774.7835601230837\n",
      "    log_joint      : 983.274267232643\n",
      "    val_loss       : -778.7556966145834\n",
      "    val_ess        : 1.9624026914437611\n",
      "    val_log_marginal: 778.7902119954427\n",
      "    val_log_joint  : 987.0894877115885\n",
      "Train Epoch: 1798 [0/54000 (0%)] Loss: -770.512573\n",
      "Train Epoch: 1798 [11264/54000 (21%)] Loss: -781.600220\n",
      "Train Epoch: 1798 [22528/54000 (42%)] Loss: -756.351807\n",
      "Train Epoch: 1798 [33792/54000 (63%)] Loss: -774.013794\n",
      "Train Epoch: 1798 [45056/54000 (83%)] Loss: -784.952393\n",
      "    epoch          : 1798\n",
      "    loss           : -774.830204225936\n",
      "    ess            : 1.9611111125856076\n",
      "    log_marginal   : 774.8680373857607\n",
      "    log_joint      : 983.3615486576872\n",
      "    val_loss       : -779.3931223551432\n",
      "    val_ess        : 1.9602524240811665\n",
      "    val_log_marginal: 779.4319661458334\n",
      "    val_log_joint  : 987.9426472981771\n",
      "Train Epoch: 1799 [0/54000 (0%)] Loss: -797.931763\n",
      "Train Epoch: 1799 [11264/54000 (21%)] Loss: -758.334473\n",
      "Train Epoch: 1799 [22528/54000 (42%)] Loss: -780.224976\n",
      "Train Epoch: 1799 [33792/54000 (63%)] Loss: -791.700317\n",
      "Train Epoch: 1799 [45056/54000 (83%)] Loss: -775.643127\n",
      "    epoch          : 1799\n",
      "    loss           : -774.5381855514814\n",
      "    ess            : 1.9610075050929807\n",
      "    log_marginal   : 774.5753173828125\n",
      "    log_joint      : 983.1538425661483\n",
      "    val_loss       : -778.7161356608073\n",
      "    val_ess        : 1.9637027283509572\n",
      "    val_log_marginal: 778.7507069905599\n",
      "    val_log_joint  : 987.0557759602865\n",
      "Train Epoch: 1800 [0/54000 (0%)] Loss: -789.670654\n",
      "Train Epoch: 1800 [11264/54000 (21%)] Loss: -775.698792\n",
      "Train Epoch: 1800 [22528/54000 (42%)] Loss: -748.562744\n",
      "Train Epoch: 1800 [33792/54000 (63%)] Loss: -781.473389\n",
      "Train Epoch: 1800 [45056/54000 (83%)] Loss: -779.689392\n",
      "    epoch          : 1800\n",
      "    loss           : -774.7099096910009\n",
      "    ess            : 1.9609539621281173\n",
      "    log_marginal   : 774.7471981408461\n",
      "    log_joint      : 983.1846411363134\n",
      "    val_loss       : -779.2311299641927\n",
      "    val_ess        : 1.9634829461574554\n",
      "    val_log_marginal: 779.2660217285156\n",
      "    val_log_joint  : 988.1369425455729\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1800.pth ...\n",
      "Train Epoch: 1801 [0/54000 (0%)] Loss: -767.898438\n",
      "Train Epoch: 1801 [11264/54000 (21%)] Loss: -773.861084\n",
      "Train Epoch: 1801 [22528/54000 (42%)] Loss: -775.757874\n",
      "Train Epoch: 1801 [33792/54000 (63%)] Loss: -792.968445\n",
      "Train Epoch: 1801 [45056/54000 (83%)] Loss: -764.487549\n",
      "    epoch          : 1801\n",
      "    loss           : -774.8084037348909\n",
      "    ess            : 1.9619969343239407\n",
      "    log_marginal   : 774.8440764805056\n",
      "    log_joint      : 983.3380967626032\n",
      "    val_loss       : -778.6531016031901\n",
      "    val_ess        : 1.9636665781339009\n",
      "    val_log_marginal: 778.689707438151\n",
      "    val_log_joint  : 987.0707956949869\n",
      "Train Epoch: 1802 [0/54000 (0%)] Loss: -777.308838\n",
      "Train Epoch: 1802 [11264/54000 (21%)] Loss: -785.867310\n",
      "Train Epoch: 1802 [22528/54000 (42%)] Loss: -791.168091\n",
      "Train Epoch: 1802 [33792/54000 (63%)] Loss: -794.280518\n",
      "Train Epoch: 1802 [45056/54000 (83%)] Loss: -764.058472\n",
      "    epoch          : 1802\n",
      "    loss           : -774.6154157530586\n",
      "    ess            : 1.9610785178418428\n",
      "    log_marginal   : 774.6530922943691\n",
      "    log_joint      : 983.2030939066185\n",
      "    val_loss       : -779.1732228597006\n",
      "    val_ess        : 1.9612791736920674\n",
      "    val_log_marginal: 779.2097625732422\n",
      "    val_log_joint  : 987.4407297770182\n",
      "Train Epoch: 1803 [0/54000 (0%)] Loss: -777.283203\n",
      "Train Epoch: 1803 [11264/54000 (21%)] Loss: -791.848022\n",
      "Train Epoch: 1803 [22528/54000 (42%)] Loss: -756.339722\n",
      "Train Epoch: 1803 [33792/54000 (63%)] Loss: -753.970398\n",
      "Train Epoch: 1803 [45056/54000 (83%)] Loss: -790.828369\n",
      "    epoch          : 1803\n",
      "    loss           : -774.8684012934847\n",
      "    ess            : 1.9603456652389382\n",
      "    log_marginal   : 774.9064342570755\n",
      "    log_joint      : 983.4278213213075\n",
      "    val_loss       : -779.5844065348307\n",
      "    val_ess        : 1.961990475654602\n",
      "    val_log_marginal: 779.6208902994791\n",
      "    val_log_joint  : 988.2610727945963\n",
      "Train Epoch: 1804 [0/54000 (0%)] Loss: -764.554565\n",
      "Train Epoch: 1804 [11264/54000 (21%)] Loss: -764.930542\n",
      "Train Epoch: 1804 [22528/54000 (42%)] Loss: -778.310669\n",
      "Train Epoch: 1804 [33792/54000 (63%)] Loss: -773.106323\n",
      "Train Epoch: 1804 [45056/54000 (83%)] Loss: -753.518066\n",
      "    epoch          : 1804\n",
      "    loss           : -774.9752502441406\n",
      "    ess            : 1.9601871090115242\n",
      "    log_marginal   : 775.0144589981943\n",
      "    log_joint      : 983.5333585919075\n",
      "    val_loss       : -779.0589803059896\n",
      "    val_ess        : 1.965194175640742\n",
      "    val_log_marginal: 779.093007405599\n",
      "    val_log_joint  : 987.4334513346354\n",
      "Train Epoch: 1805 [0/54000 (0%)] Loss: -764.425659\n",
      "Train Epoch: 1805 [11264/54000 (21%)] Loss: -773.683350\n",
      "Train Epoch: 1805 [22528/54000 (42%)] Loss: -775.928589\n",
      "Train Epoch: 1805 [33792/54000 (63%)] Loss: -778.875793\n",
      "Train Epoch: 1805 [45056/54000 (83%)] Loss: -755.656128\n",
      "    epoch          : 1805\n",
      "    loss           : -774.8920017458358\n",
      "    ess            : 1.9616388431135214\n",
      "    log_marginal   : 774.9282669931088\n",
      "    log_joint      : 983.4147223706516\n",
      "    val_loss       : -779.4716237386068\n",
      "    val_ess        : 1.9610756039619446\n",
      "    val_log_marginal: 779.5108489990234\n",
      "    val_log_joint  : 988.2955474853516\n",
      "Train Epoch: 1806 [0/54000 (0%)] Loss: -778.477661\n",
      "Train Epoch: 1806 [11264/54000 (21%)] Loss: -781.187805\n",
      "Train Epoch: 1806 [22528/54000 (42%)] Loss: -755.752563\n",
      "Train Epoch: 1806 [33792/54000 (63%)] Loss: -788.689453\n",
      "Train Epoch: 1806 [45056/54000 (83%)] Loss: -768.742615\n",
      "    epoch          : 1806\n",
      "    loss           : -774.7738031351341\n",
      "    ess            : 1.9604876210104745\n",
      "    log_marginal   : 774.8123525943396\n",
      "    log_joint      : 983.4189320690227\n",
      "    val_loss       : -779.656982421875\n",
      "    val_ess        : 1.9572003881136577\n",
      "    val_log_marginal: 779.7015329996744\n",
      "    val_log_joint  : 988.3289947509766\n",
      "Train Epoch: 1807 [0/54000 (0%)] Loss: -775.056396\n",
      "Train Epoch: 1807 [11264/54000 (21%)] Loss: -786.883667\n",
      "Train Epoch: 1807 [22528/54000 (42%)] Loss: -779.783020\n",
      "Train Epoch: 1807 [33792/54000 (63%)] Loss: -744.180359\n",
      "Train Epoch: 1807 [45056/54000 (83%)] Loss: -766.709900\n",
      "    epoch          : 1807\n",
      "    loss           : -774.8500101341391\n",
      "    ess            : 1.9610796761962603\n",
      "    log_marginal   : 774.8875790002211\n",
      "    log_joint      : 983.448645825656\n",
      "    val_loss       : -779.5069885253906\n",
      "    val_ess        : 1.9589204688866932\n",
      "    val_log_marginal: 779.5451405843099\n",
      "    val_log_joint  : 987.9595998128256\n",
      "Train Epoch: 1808 [0/54000 (0%)] Loss: -795.594727\n",
      "Train Epoch: 1808 [11264/54000 (21%)] Loss: -754.768555\n",
      "Train Epoch: 1808 [22528/54000 (42%)] Loss: -771.411255\n",
      "Train Epoch: 1808 [33792/54000 (63%)] Loss: -779.852539\n",
      "Train Epoch: 1808 [45056/54000 (83%)] Loss: -784.328064\n",
      "    epoch          : 1808\n",
      "    loss           : -775.1352308741156\n",
      "    ess            : 1.9605166237309295\n",
      "    log_marginal   : 775.1721916918484\n",
      "    log_joint      : 983.632142264888\n",
      "    val_loss       : -779.0252634684244\n",
      "    val_ess        : 1.9635568658510845\n",
      "    val_log_marginal: 779.0605316162109\n",
      "    val_log_joint  : 987.7350006103516\n",
      "Train Epoch: 1809 [0/54000 (0%)] Loss: -789.477173\n",
      "Train Epoch: 1809 [11264/54000 (21%)] Loss: -776.077637\n",
      "Train Epoch: 1809 [22528/54000 (42%)] Loss: -773.126648\n",
      "Train Epoch: 1809 [33792/54000 (63%)] Loss: -788.584778\n",
      "Train Epoch: 1809 [45056/54000 (83%)] Loss: -788.687134\n",
      "    epoch          : 1809\n",
      "    loss           : -774.8328120393573\n",
      "    ess            : 1.9614133137576986\n",
      "    log_marginal   : 774.869829861623\n",
      "    log_joint      : 983.3496963213075\n",
      "    val_loss       : -779.6143391927084\n",
      "    val_ess        : 1.9631715416908264\n",
      "    val_log_marginal: 779.6473236083984\n",
      "    val_log_joint  : 988.0743103027344\n",
      "Train Epoch: 1810 [0/54000 (0%)] Loss: -782.725403\n",
      "Train Epoch: 1810 [11264/54000 (21%)] Loss: -817.413208\n",
      "Train Epoch: 1810 [22528/54000 (42%)] Loss: -777.456909\n",
      "Train Epoch: 1810 [33792/54000 (63%)] Loss: -755.912292\n",
      "Train Epoch: 1810 [45056/54000 (83%)] Loss: -760.715454\n",
      "    epoch          : 1810\n",
      "    loss           : -774.8707574808373\n",
      "    ess            : 1.9593862947428002\n",
      "    log_marginal   : 774.9098372549381\n",
      "    log_joint      : 983.3874333219708\n",
      "    val_loss       : -779.0927276611328\n",
      "    val_ess        : 1.9648145139217377\n",
      "    val_log_marginal: 779.1256561279297\n",
      "    val_log_joint  : 987.7172241210938\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1810.pth ...\n",
      "Train Epoch: 1811 [0/54000 (0%)] Loss: -797.126709\n",
      "Train Epoch: 1811 [11264/54000 (21%)] Loss: -784.352295\n",
      "Train Epoch: 1811 [22528/54000 (42%)] Loss: -779.773499\n",
      "Train Epoch: 1811 [33792/54000 (63%)] Loss: -769.990356\n",
      "Train Epoch: 1811 [45056/54000 (83%)] Loss: -769.294312\n",
      "    epoch          : 1811\n",
      "    loss           : -774.9917395249853\n",
      "    ess            : 1.9595674523767435\n",
      "    log_marginal   : 775.0301116367556\n",
      "    log_joint      : 983.4978574356943\n",
      "    val_loss       : -778.8513132731119\n",
      "    val_ess        : 1.9637028276920319\n",
      "    val_log_marginal: 778.8830159505209\n",
      "    val_log_joint  : 987.4217987060547\n",
      "Train Epoch: 1812 [0/54000 (0%)] Loss: -769.818848\n",
      "Train Epoch: 1812 [11264/54000 (21%)] Loss: -756.371216\n",
      "Train Epoch: 1812 [22528/54000 (42%)] Loss: -774.788757\n",
      "Train Epoch: 1812 [33792/54000 (63%)] Loss: -769.763428\n",
      "Train Epoch: 1812 [45056/54000 (83%)] Loss: -792.353027\n",
      "    epoch          : 1812\n",
      "    loss           : -775.048213742814\n",
      "    ess            : 1.9610637988684312\n",
      "    log_marginal   : 775.0854336720593\n",
      "    log_joint      : 983.657582408977\n",
      "    val_loss       : -779.5083312988281\n",
      "    val_ess        : 1.9617265164852142\n",
      "    val_log_marginal: 779.5491587320963\n",
      "    val_log_joint  : 988.1427510579427\n",
      "Train Epoch: 1813 [0/54000 (0%)] Loss: -770.464172\n",
      "Train Epoch: 1813 [11264/54000 (21%)] Loss: -798.104919\n",
      "Train Epoch: 1813 [22528/54000 (42%)] Loss: -779.306946\n",
      "Train Epoch: 1813 [33792/54000 (63%)] Loss: -767.921631\n",
      "Train Epoch: 1813 [45056/54000 (83%)] Loss: -764.245789\n",
      "    epoch          : 1813\n",
      "    loss           : -775.0033379320828\n",
      "    ess            : 1.9608181939934783\n",
      "    log_marginal   : 775.0406845380675\n",
      "    log_joint      : 983.6615969100088\n",
      "    val_loss       : -779.0270487467448\n",
      "    val_ess        : 1.959831843773524\n",
      "    val_log_marginal: 779.0670522054037\n",
      "    val_log_joint  : 987.6565297444662\n",
      "Train Epoch: 1814 [0/54000 (0%)] Loss: -796.707642\n",
      "Train Epoch: 1814 [11264/54000 (21%)] Loss: -776.575867\n",
      "Train Epoch: 1814 [22528/54000 (42%)] Loss: -769.057800\n",
      "Train Epoch: 1814 [33792/54000 (63%)] Loss: -774.214233\n",
      "Train Epoch: 1814 [45056/54000 (83%)] Loss: -797.933594\n",
      "    epoch          : 1814\n",
      "    loss           : -774.995843275538\n",
      "    ess            : 1.9607958085132096\n",
      "    log_marginal   : 775.0337092561542\n",
      "    log_joint      : 983.6607890578936\n",
      "    val_loss       : -778.6403096516927\n",
      "    val_ess        : 1.9624969164530437\n",
      "    val_log_marginal: 778.6740010579427\n",
      "    val_log_joint  : 987.2864990234375\n",
      "Train Epoch: 1815 [0/54000 (0%)] Loss: -778.611328\n",
      "Train Epoch: 1815 [11264/54000 (21%)] Loss: -770.229004\n",
      "Train Epoch: 1815 [22528/54000 (42%)] Loss: -774.118958\n",
      "Train Epoch: 1815 [33792/54000 (63%)] Loss: -769.626892\n",
      "Train Epoch: 1815 [45056/54000 (83%)] Loss: -787.943237\n",
      "    epoch          : 1815\n",
      "    loss           : -774.9800605054172\n",
      "    ess            : 1.961063895585402\n",
      "    log_marginal   : 775.0173115280439\n",
      "    log_joint      : 983.6860737350752\n",
      "    val_loss       : -779.3418426513672\n",
      "    val_ess        : 1.9604516625404358\n",
      "    val_log_marginal: 779.3798370361328\n",
      "    val_log_joint  : 988.0140635172526\n",
      "Train Epoch: 1816 [0/54000 (0%)] Loss: -765.101074\n",
      "Train Epoch: 1816 [11264/54000 (21%)] Loss: -790.532959\n",
      "Train Epoch: 1816 [22528/54000 (42%)] Loss: -773.460205\n",
      "Train Epoch: 1816 [33792/54000 (63%)] Loss: -808.966797\n",
      "Train Epoch: 1816 [45056/54000 (83%)] Loss: -782.730347\n",
      "    epoch          : 1816\n",
      "    loss           : -775.1092252911262\n",
      "    ess            : 1.96111402534089\n",
      "    log_marginal   : 775.1454686578714\n",
      "    log_joint      : 983.7117165619472\n",
      "    val_loss       : -779.6246185302734\n",
      "    val_ess        : 1.9616368412971497\n",
      "    val_log_marginal: 779.6627756754557\n",
      "    val_log_joint  : 988.3228658040365\n",
      "Train Epoch: 1817 [0/54000 (0%)] Loss: -783.340027\n",
      "Train Epoch: 1817 [11264/54000 (21%)] Loss: -769.909546\n",
      "Train Epoch: 1817 [22528/54000 (42%)] Loss: -772.942261\n",
      "Train Epoch: 1817 [33792/54000 (63%)] Loss: -771.488525\n",
      "Train Epoch: 1817 [45056/54000 (83%)] Loss: -755.808716\n",
      "    epoch          : 1817\n",
      "    loss           : -775.2106927835716\n",
      "    ess            : 1.9611912887051421\n",
      "    log_marginal   : 775.2475102262677\n",
      "    log_joint      : 983.7263719090876\n",
      "    val_loss       : -779.2845611572266\n",
      "    val_ess        : 1.9627225995063782\n",
      "    val_log_marginal: 779.3229726155599\n",
      "    val_log_joint  : 987.9494069417318\n",
      "Train Epoch: 1818 [0/54000 (0%)] Loss: -785.556519\n",
      "Train Epoch: 1818 [11264/54000 (21%)] Loss: -776.698425\n",
      "Train Epoch: 1818 [22528/54000 (42%)] Loss: -762.733887\n",
      "Train Epoch: 1818 [33792/54000 (63%)] Loss: -761.269165\n",
      "Train Epoch: 1818 [45056/54000 (83%)] Loss: -786.918945\n",
      "    epoch          : 1818\n",
      "    loss           : -775.1018981933594\n",
      "    ess            : 1.9613440756527882\n",
      "    log_marginal   : 775.1381795631265\n",
      "    log_joint      : 983.6839829930719\n",
      "    val_loss       : -778.9164123535156\n",
      "    val_ess        : 1.96065886815389\n",
      "    val_log_marginal: 778.9550933837891\n",
      "    val_log_joint  : 987.5067596435547\n",
      "Train Epoch: 1819 [0/54000 (0%)] Loss: -782.293091\n",
      "Train Epoch: 1819 [11264/54000 (21%)] Loss: -783.359009\n",
      "Train Epoch: 1819 [22528/54000 (42%)] Loss: -786.755737\n",
      "Train Epoch: 1819 [33792/54000 (63%)] Loss: -758.261108\n",
      "Train Epoch: 1819 [45056/54000 (83%)] Loss: -794.869141\n",
      "    epoch          : 1819\n",
      "    loss           : -774.9982201918116\n",
      "    ess            : 1.9603230289693148\n",
      "    log_marginal   : 775.0365450877064\n",
      "    log_joint      : 983.524072611107\n",
      "    val_loss       : -779.6498870849609\n",
      "    val_ess        : 1.9639391700426738\n",
      "    val_log_marginal: 779.6851043701172\n",
      "    val_log_joint  : 988.1927591959635\n",
      "Train Epoch: 1820 [0/54000 (0%)] Loss: -784.376221\n",
      "Train Epoch: 1820 [11264/54000 (21%)] Loss: -750.053833\n",
      "Train Epoch: 1820 [22528/54000 (42%)] Loss: -765.303345\n",
      "Train Epoch: 1820 [33792/54000 (63%)] Loss: -790.426392\n",
      "Train Epoch: 1820 [45056/54000 (83%)] Loss: -756.911011\n",
      "    epoch          : 1820\n",
      "    loss           : -775.1727623129791\n",
      "    ess            : 1.9608825636359881\n",
      "    log_marginal   : 775.2084091474425\n",
      "    log_joint      : 983.7914929659861\n",
      "    val_loss       : -779.6714375813802\n",
      "    val_ess        : 1.9590933521588643\n",
      "    val_log_marginal: 779.7114969889323\n",
      "    val_log_joint  : 988.1779123942057\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1820.pth ...\n",
      "Train Epoch: 1821 [0/54000 (0%)] Loss: -783.361572\n",
      "Train Epoch: 1821 [11264/54000 (21%)] Loss: -772.268188\n",
      "Train Epoch: 1821 [22528/54000 (42%)] Loss: -771.282104\n",
      "Train Epoch: 1821 [33792/54000 (63%)] Loss: -785.509399\n",
      "Train Epoch: 1821 [45056/54000 (83%)] Loss: -771.846680\n",
      "    epoch          : 1821\n",
      "    loss           : -775.2748700987618\n",
      "    ess            : 1.9613204935811601\n",
      "    log_marginal   : 775.3103044617851\n",
      "    log_joint      : 983.8731942806604\n",
      "    val_loss       : -779.8029276529948\n",
      "    val_ess        : 1.9628400107224782\n",
      "    val_log_marginal: 779.8413238525391\n",
      "    val_log_joint  : 988.1653798421224\n",
      "Train Epoch: 1822 [0/54000 (0%)] Loss: -795.755920\n",
      "Train Epoch: 1822 [11264/54000 (21%)] Loss: -748.336914\n",
      "Train Epoch: 1822 [22528/54000 (42%)] Loss: -761.028320\n",
      "Train Epoch: 1822 [33792/54000 (63%)] Loss: -772.387512\n",
      "Train Epoch: 1822 [45056/54000 (83%)] Loss: -767.764465\n",
      "    epoch          : 1822\n",
      "    loss           : -775.2212783525575\n",
      "    ess            : 1.9605322896309618\n",
      "    log_marginal   : 775.2591731233417\n",
      "    log_joint      : 983.8522834058078\n",
      "    val_loss       : -779.6639099121094\n",
      "    val_ess        : 1.959321031967799\n",
      "    val_log_marginal: 779.7020365397135\n",
      "    val_log_joint  : 988.1901550292969\n",
      "Train Epoch: 1823 [0/54000 (0%)] Loss: -786.514038\n",
      "Train Epoch: 1823 [11264/54000 (21%)] Loss: -773.774475\n",
      "Train Epoch: 1823 [22528/54000 (42%)] Loss: -769.157471\n",
      "Train Epoch: 1823 [33792/54000 (63%)] Loss: -765.797485\n",
      "Train Epoch: 1823 [45056/54000 (83%)] Loss: -758.579834\n",
      "    epoch          : 1823\n",
      "    loss           : -775.0470396797612\n",
      "    ess            : 1.9608935859968077\n",
      "    log_marginal   : 775.0832410128611\n",
      "    log_joint      : 983.6846958376327\n",
      "    val_loss       : -779.4308827718099\n",
      "    val_ess        : 1.9596639672915142\n",
      "    val_log_marginal: 779.4666493733724\n",
      "    val_log_joint  : 987.8851216634115\n",
      "Train Epoch: 1824 [0/54000 (0%)] Loss: -808.949158\n",
      "Train Epoch: 1824 [11264/54000 (21%)] Loss: -791.207458\n",
      "Train Epoch: 1824 [22528/54000 (42%)] Loss: -796.713013\n",
      "Train Epoch: 1824 [33792/54000 (63%)] Loss: -760.692627\n",
      "Train Epoch: 1824 [45056/54000 (83%)] Loss: -779.203125\n",
      "    epoch          : 1824\n",
      "    loss           : -775.0654112617924\n",
      "    ess            : 1.9606669320250458\n",
      "    log_marginal   : 775.1020576908903\n",
      "    log_joint      : 983.6327595260908\n",
      "    val_loss       : -779.0047963460287\n",
      "    val_ess        : 1.9590454697608948\n",
      "    val_log_marginal: 779.0448354085287\n",
      "    val_log_joint  : 987.719960530599\n",
      "Train Epoch: 1825 [0/54000 (0%)] Loss: -763.868286\n",
      "Train Epoch: 1825 [11264/54000 (21%)] Loss: -793.594360\n",
      "Train Epoch: 1825 [22528/54000 (42%)] Loss: -752.110535\n",
      "Train Epoch: 1825 [33792/54000 (63%)] Loss: -787.629761\n",
      "Train Epoch: 1825 [45056/54000 (83%)] Loss: -756.955444\n",
      "    epoch          : 1825\n",
      "    loss           : -775.1717811440521\n",
      "    ess            : 1.9611842587309063\n",
      "    log_marginal   : 775.2095313881928\n",
      "    log_joint      : 983.8369382462412\n",
      "    val_loss       : -778.8019968668619\n",
      "    val_ess        : 1.9581930041313171\n",
      "    val_log_marginal: 778.8393758138021\n",
      "    val_log_joint  : 987.5784810384115\n",
      "Train Epoch: 1826 [0/54000 (0%)] Loss: -766.347900\n",
      "Train Epoch: 1826 [11264/54000 (21%)] Loss: -778.118042\n",
      "Train Epoch: 1826 [22528/54000 (42%)] Loss: -769.209839\n",
      "Train Epoch: 1826 [33792/54000 (63%)] Loss: -786.715698\n",
      "Train Epoch: 1826 [45056/54000 (83%)] Loss: -771.676819\n",
      "    epoch          : 1826\n",
      "    loss           : -775.312673892615\n",
      "    ess            : 1.9627322993188534\n",
      "    log_marginal   : 775.3480017320165\n",
      "    log_joint      : 983.8200234467129\n",
      "    val_loss       : -779.370859781901\n",
      "    val_ess        : 1.9589942395687103\n",
      "    val_log_marginal: 779.4103953043619\n",
      "    val_log_joint  : 988.1580403645834\n",
      "Train Epoch: 1827 [0/54000 (0%)] Loss: -802.661377\n",
      "Train Epoch: 1827 [11264/54000 (21%)] Loss: -774.603271\n",
      "Train Epoch: 1827 [22528/54000 (42%)] Loss: -765.276184\n",
      "Train Epoch: 1827 [33792/54000 (63%)] Loss: -763.593445\n",
      "Train Epoch: 1827 [45056/54000 (83%)] Loss: -769.490356\n",
      "    epoch          : 1827\n",
      "    loss           : -775.4076549602005\n",
      "    ess            : 1.961688146276294\n",
      "    log_marginal   : 775.4429862544222\n",
      "    log_joint      : 983.9188301518278\n",
      "    val_loss       : -779.7440795898438\n",
      "    val_ess        : 1.9617778956890106\n",
      "    val_log_marginal: 779.7884063720703\n",
      "    val_log_joint  : 988.4388732910156\n",
      "Train Epoch: 1828 [0/54000 (0%)] Loss: -762.773926\n",
      "Train Epoch: 1828 [11264/54000 (21%)] Loss: -807.828247\n",
      "Train Epoch: 1828 [22528/54000 (42%)] Loss: -789.829346\n",
      "Train Epoch: 1828 [33792/54000 (63%)] Loss: -778.039673\n",
      "Train Epoch: 1828 [45056/54000 (83%)] Loss: -778.242065\n",
      "    epoch          : 1828\n",
      "    loss           : -775.367733361586\n",
      "    ess            : 1.9616568830778014\n",
      "    log_marginal   : 775.4041402564859\n",
      "    log_joint      : 983.958371720224\n",
      "    val_loss       : -779.9134063720703\n",
      "    val_ess        : 1.9607723355293274\n",
      "    val_log_marginal: 779.9490610758463\n",
      "    val_log_joint  : 988.2146199544271\n",
      "Train Epoch: 1829 [0/54000 (0%)] Loss: -774.529785\n",
      "Train Epoch: 1829 [11264/54000 (21%)] Loss: -796.454834\n",
      "Train Epoch: 1829 [22528/54000 (42%)] Loss: -770.749939\n",
      "Train Epoch: 1829 [33792/54000 (63%)] Loss: -766.752441\n",
      "Train Epoch: 1829 [45056/54000 (83%)] Loss: -789.589722\n",
      "    epoch          : 1829\n",
      "    loss           : -775.1598493468086\n",
      "    ess            : 1.9603935716287144\n",
      "    log_marginal   : 775.1982542793705\n",
      "    log_joint      : 983.8384652767542\n",
      "    val_loss       : -779.0573679606119\n",
      "    val_ess        : 1.9605690042177837\n",
      "    val_log_marginal: 779.0970865885416\n",
      "    val_log_joint  : 987.5786895751953\n",
      "Train Epoch: 1830 [0/54000 (0%)] Loss: -782.263550\n",
      "Train Epoch: 1830 [11264/54000 (21%)] Loss: -781.244873\n",
      "Train Epoch: 1830 [22528/54000 (42%)] Loss: -801.316162\n",
      "Train Epoch: 1830 [33792/54000 (63%)] Loss: -772.641663\n",
      "Train Epoch: 1830 [45056/54000 (83%)] Loss: -780.522339\n",
      "    epoch          : 1830\n",
      "    loss           : -775.2476322965802\n",
      "    ess            : 1.961914930703505\n",
      "    log_marginal   : 775.2838992712633\n",
      "    log_joint      : 983.8603383190227\n",
      "    val_loss       : -779.6876525878906\n",
      "    val_ess        : 1.9625763197739918\n",
      "    val_log_marginal: 779.7262115478516\n",
      "    val_log_joint  : 988.3918253580729\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1830.pth ...\n",
      "Train Epoch: 1831 [0/54000 (0%)] Loss: -793.167847\n",
      "Train Epoch: 1831 [11264/54000 (21%)] Loss: -785.107788\n",
      "Train Epoch: 1831 [22528/54000 (42%)] Loss: -774.045410\n",
      "Train Epoch: 1831 [33792/54000 (63%)] Loss: -775.416504\n",
      "Train Epoch: 1831 [45056/54000 (83%)] Loss: -767.322754\n",
      "    epoch          : 1831\n",
      "    loss           : -775.4262712586601\n",
      "    ess            : 1.9623240187483013\n",
      "    log_marginal   : 775.4619750976562\n",
      "    log_joint      : 983.9340267541273\n",
      "    val_loss       : -779.5413513183594\n",
      "    val_ess        : 1.9599261780579884\n",
      "    val_log_marginal: 779.5776875813802\n",
      "    val_log_joint  : 988.0817667643229\n",
      "Train Epoch: 1832 [0/54000 (0%)] Loss: -802.723389\n",
      "Train Epoch: 1832 [11264/54000 (21%)] Loss: -787.815857\n",
      "Train Epoch: 1832 [22528/54000 (42%)] Loss: -772.744385\n",
      "Train Epoch: 1832 [33792/54000 (63%)] Loss: -762.136963\n",
      "Train Epoch: 1832 [45056/54000 (83%)] Loss: -751.563232\n",
      "    epoch          : 1832\n",
      "    loss           : -775.1281030043116\n",
      "    ess            : 1.9610739282841951\n",
      "    log_marginal   : 775.1653666946123\n",
      "    log_joint      : 983.6919169875811\n",
      "    val_loss       : -778.9111378987631\n",
      "    val_ess        : 1.9582087695598602\n",
      "    val_log_marginal: 778.9538370768229\n",
      "    val_log_joint  : 987.5617218017578\n",
      "Train Epoch: 1833 [0/54000 (0%)] Loss: -775.422119\n",
      "Train Epoch: 1833 [11264/54000 (21%)] Loss: -772.817627\n",
      "Train Epoch: 1833 [22528/54000 (42%)] Loss: -761.993530\n",
      "Train Epoch: 1833 [33792/54000 (63%)] Loss: -765.742981\n",
      "Train Epoch: 1833 [45056/54000 (83%)] Loss: -770.104614\n",
      "    epoch          : 1833\n",
      "    loss           : -775.466174431567\n",
      "    ess            : 1.9608853054496478\n",
      "    log_marginal   : 775.5030051177403\n",
      "    log_joint      : 984.0000760060436\n",
      "    val_loss       : -779.4098510742188\n",
      "    val_ess        : 1.961398681004842\n",
      "    val_log_marginal: 779.4470520019531\n",
      "    val_log_joint  : 988.3131866455078\n",
      "Train Epoch: 1834 [0/54000 (0%)] Loss: -776.873901\n",
      "Train Epoch: 1834 [11264/54000 (21%)] Loss: -765.308960\n",
      "Train Epoch: 1834 [22528/54000 (42%)] Loss: -766.514709\n",
      "Train Epoch: 1834 [33792/54000 (63%)] Loss: -770.052307\n",
      "Train Epoch: 1834 [45056/54000 (83%)] Loss: -785.223938\n",
      "    epoch          : 1834\n",
      "    loss           : -775.5837724793632\n",
      "    ess            : 1.96077398534091\n",
      "    log_marginal   : 775.6220973752579\n",
      "    log_joint      : 984.1525291586822\n",
      "    val_loss       : -779.7995147705078\n",
      "    val_ess        : 1.9616830547650654\n",
      "    val_log_marginal: 779.8345336914062\n",
      "    val_log_joint  : 988.3847401936849\n",
      "Train Epoch: 1835 [0/54000 (0%)] Loss: -768.491638\n",
      "Train Epoch: 1835 [11264/54000 (21%)] Loss: -759.199829\n",
      "Train Epoch: 1835 [22528/54000 (42%)] Loss: -764.715637\n",
      "Train Epoch: 1835 [33792/54000 (63%)] Loss: -799.747559\n",
      "Train Epoch: 1835 [45056/54000 (83%)] Loss: -784.838257\n",
      "    epoch          : 1835\n",
      "    loss           : -775.2546467331221\n",
      "    ess            : 1.9608435001013413\n",
      "    log_marginal   : 775.2930142384655\n",
      "    log_joint      : 983.8330406332916\n",
      "    val_loss       : -779.3895924886068\n",
      "    val_ess        : 1.9602596859137218\n",
      "    val_log_marginal: 779.4274648030599\n",
      "    val_log_joint  : 987.9721221923828\n",
      "Train Epoch: 1836 [0/54000 (0%)] Loss: -761.364319\n",
      "Train Epoch: 1836 [11264/54000 (21%)] Loss: -782.619019\n",
      "Train Epoch: 1836 [22528/54000 (42%)] Loss: -787.191772\n",
      "Train Epoch: 1836 [33792/54000 (63%)] Loss: -774.793762\n",
      "Train Epoch: 1836 [45056/54000 (83%)] Loss: -773.693237\n",
      "    epoch          : 1836\n",
      "    loss           : -775.1053046460422\n",
      "    ess            : 1.9599059561513505\n",
      "    log_marginal   : 775.1433076678582\n",
      "    log_joint      : 983.6848374852594\n",
      "    val_loss       : -779.3868865966797\n",
      "    val_ess        : 1.9599634110927582\n",
      "    val_log_marginal: 779.4248555501302\n",
      "    val_log_joint  : 987.9325052897135\n",
      "Train Epoch: 1837 [0/54000 (0%)] Loss: -783.110840\n",
      "Train Epoch: 1837 [11264/54000 (21%)] Loss: -771.466003\n",
      "Train Epoch: 1837 [22528/54000 (42%)] Loss: -790.171265\n",
      "Train Epoch: 1837 [33792/54000 (63%)] Loss: -773.595581\n",
      "Train Epoch: 1837 [45056/54000 (83%)] Loss: -775.695435\n",
      "    epoch          : 1837\n",
      "    loss           : -775.2141510585569\n",
      "    ess            : 1.9608654154921479\n",
      "    log_marginal   : 775.251959458837\n",
      "    log_joint      : 983.7544734163105\n",
      "    val_loss       : -779.8340657552084\n",
      "    val_ess        : 1.9598202804724376\n",
      "    val_log_marginal: 779.8734537760416\n",
      "    val_log_joint  : 988.5172424316406\n",
      "Train Epoch: 1838 [0/54000 (0%)] Loss: -789.957520\n",
      "Train Epoch: 1838 [11264/54000 (21%)] Loss: -787.944092\n",
      "Train Epoch: 1838 [22528/54000 (42%)] Loss: -779.839966\n",
      "Train Epoch: 1838 [33792/54000 (63%)] Loss: -761.767700\n",
      "Train Epoch: 1838 [45056/54000 (83%)] Loss: -764.633057\n",
      "    epoch          : 1838\n",
      "    loss           : -775.2061514224646\n",
      "    ess            : 1.960900494512522\n",
      "    log_marginal   : 775.2437726866524\n",
      "    log_joint      : 983.870152311505\n",
      "    val_loss       : -780.0723673502604\n",
      "    val_ess        : 1.9607906142870586\n",
      "    val_log_marginal: 780.1092376708984\n",
      "    val_log_joint  : 988.5423278808594\n",
      "Train Epoch: 1839 [0/54000 (0%)] Loss: -767.153198\n",
      "Train Epoch: 1839 [11264/54000 (21%)] Loss: -773.378357\n",
      "Train Epoch: 1839 [22528/54000 (42%)] Loss: -777.730164\n",
      "Train Epoch: 1839 [33792/54000 (63%)] Loss: -773.463013\n",
      "Train Epoch: 1839 [45056/54000 (83%)] Loss: -778.318115\n",
      "    epoch          : 1839\n",
      "    loss           : -775.5470149202167\n",
      "    ess            : 1.9610364437103271\n",
      "    log_marginal   : 775.5843989534198\n",
      "    log_joint      : 984.11983792287\n",
      "    val_loss       : -779.3824310302734\n",
      "    val_ess        : 1.9637838800748189\n",
      "    val_log_marginal: 779.4130198160807\n",
      "    val_log_joint  : 988.00927734375\n",
      "Train Epoch: 1840 [0/54000 (0%)] Loss: -796.882019\n",
      "Train Epoch: 1840 [11264/54000 (21%)] Loss: -791.892578\n",
      "Train Epoch: 1840 [22528/54000 (42%)] Loss: -773.205933\n",
      "Train Epoch: 1840 [33792/54000 (63%)] Loss: -787.258057\n",
      "Train Epoch: 1840 [45056/54000 (83%)] Loss: -789.242920\n",
      "    epoch          : 1840\n",
      "    loss           : -775.1451220242483\n",
      "    ess            : 1.9611508936252233\n",
      "    log_marginal   : 775.1809421755233\n",
      "    log_joint      : 983.7048472278523\n",
      "    val_loss       : -780.1482798258463\n",
      "    val_ess        : 1.9596377313137054\n",
      "    val_log_marginal: 780.1878763834635\n",
      "    val_log_joint  : 988.6112365722656\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1840.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1841 [0/54000 (0%)] Loss: -793.078491\n",
      "Train Epoch: 1841 [11264/54000 (21%)] Loss: -785.240967\n",
      "Train Epoch: 1841 [22528/54000 (42%)] Loss: -787.033813\n",
      "Train Epoch: 1841 [33792/54000 (63%)] Loss: -778.011719\n",
      "Train Epoch: 1841 [45056/54000 (83%)] Loss: -781.129272\n",
      "    epoch          : 1841\n",
      "    loss           : -775.3262524874705\n",
      "    ess            : 1.9611886762223154\n",
      "    log_marginal   : 775.3627555415316\n",
      "    log_joint      : 983.9167877773069\n",
      "    val_loss       : -780.1242472330729\n",
      "    val_ess        : 1.9611495633920033\n",
      "    val_log_marginal: 780.1604970296224\n",
      "    val_log_joint  : 988.4087473551432\n",
      "Train Epoch: 1842 [0/54000 (0%)] Loss: -785.069092\n",
      "Train Epoch: 1842 [11264/54000 (21%)] Loss: -759.734863\n",
      "Train Epoch: 1842 [22528/54000 (42%)] Loss: -771.398926\n",
      "Train Epoch: 1842 [33792/54000 (63%)] Loss: -789.080200\n",
      "Train Epoch: 1842 [45056/54000 (83%)] Loss: -774.442139\n",
      "    epoch          : 1842\n",
      "    loss           : -775.208280743293\n",
      "    ess            : 1.9611089544476203\n",
      "    log_marginal   : 775.245160372752\n",
      "    log_joint      : 983.7842188421286\n",
      "    val_loss       : -779.7311350504557\n",
      "    val_ess        : 1.9592911303043365\n",
      "    val_log_marginal: 779.7727711995443\n",
      "    val_log_joint  : 988.5653127034506\n",
      "Train Epoch: 1843 [0/54000 (0%)] Loss: -783.693481\n",
      "Train Epoch: 1843 [11264/54000 (21%)] Loss: -781.011719\n",
      "Train Epoch: 1843 [22528/54000 (42%)] Loss: -784.406372\n",
      "Train Epoch: 1843 [33792/54000 (63%)] Loss: -790.585693\n",
      "Train Epoch: 1843 [45056/54000 (83%)] Loss: -760.572205\n",
      "    epoch          : 1843\n",
      "    loss           : -775.3804177338222\n",
      "    ess            : 1.9617156959929556\n",
      "    log_marginal   : 775.4168637833505\n",
      "    log_joint      : 983.95675371278\n",
      "    val_loss       : -780.3540191650391\n",
      "    val_ess        : 1.957287202278773\n",
      "    val_log_marginal: 780.3982289632162\n",
      "    val_log_joint  : 988.8605906168619\n",
      "Train Epoch: 1844 [0/54000 (0%)] Loss: -780.671143\n",
      "Train Epoch: 1844 [11264/54000 (21%)] Loss: -774.665894\n",
      "Train Epoch: 1844 [22528/54000 (42%)] Loss: -761.639648\n",
      "Train Epoch: 1844 [33792/54000 (63%)] Loss: -764.329468\n",
      "Train Epoch: 1844 [45056/54000 (83%)] Loss: -751.410645\n",
      "    epoch          : 1844\n",
      "    loss           : -775.443562057783\n",
      "    ess            : 1.9608763456344604\n",
      "    log_marginal   : 775.4808862074366\n",
      "    log_joint      : 984.0250745089548\n",
      "    val_loss       : -779.3711598714193\n",
      "    val_ess        : 1.9613844255606334\n",
      "    val_log_marginal: 779.4045359293619\n",
      "    val_log_joint  : 988.0489451090494\n",
      "Train Epoch: 1845 [0/54000 (0%)] Loss: -776.434204\n",
      "Train Epoch: 1845 [11264/54000 (21%)] Loss: -762.365479\n",
      "Train Epoch: 1845 [22528/54000 (42%)] Loss: -770.500977\n",
      "Train Epoch: 1845 [33792/54000 (63%)] Loss: -766.501587\n",
      "Train Epoch: 1845 [45056/54000 (83%)] Loss: -784.294922\n",
      "    epoch          : 1845\n",
      "    loss           : -775.3570286013046\n",
      "    ess            : 1.9603869206500504\n",
      "    log_marginal   : 775.3941857679835\n",
      "    log_joint      : 983.9181869794737\n",
      "    val_loss       : -779.6603597005209\n",
      "    val_ess        : 1.9593520263830821\n",
      "    val_log_marginal: 779.6992441813151\n",
      "    val_log_joint  : 988.2893727620443\n",
      "Train Epoch: 1846 [0/54000 (0%)] Loss: -776.448547\n",
      "Train Epoch: 1846 [11264/54000 (21%)] Loss: -773.500427\n",
      "Train Epoch: 1846 [22528/54000 (42%)] Loss: -777.333862\n",
      "Train Epoch: 1846 [33792/54000 (63%)] Loss: -764.759033\n",
      "Train Epoch: 1846 [45056/54000 (83%)] Loss: -768.339417\n",
      "    epoch          : 1846\n",
      "    loss           : -775.1081669645489\n",
      "    ess            : 1.9604841999287874\n",
      "    log_marginal   : 775.1444857615345\n",
      "    log_joint      : 983.7798104915979\n",
      "    val_loss       : -779.8349253336588\n",
      "    val_ess        : 1.962293952703476\n",
      "    val_log_marginal: 779.8695627848307\n",
      "    val_log_joint  : 988.3153330485026\n",
      "Train Epoch: 1847 [0/54000 (0%)] Loss: -792.028687\n",
      "Train Epoch: 1847 [11264/54000 (21%)] Loss: -771.031372\n",
      "Train Epoch: 1847 [22528/54000 (42%)] Loss: -775.303101\n",
      "Train Epoch: 1847 [33792/54000 (63%)] Loss: -764.746460\n",
      "Train Epoch: 1847 [45056/54000 (83%)] Loss: -781.292542\n",
      "    epoch          : 1847\n",
      "    loss           : -775.2278298431972\n",
      "    ess            : 1.9616042881641749\n",
      "    log_marginal   : 775.2633753362692\n",
      "    log_joint      : 983.8318239607901\n",
      "    val_loss       : -779.372314453125\n",
      "    val_ess        : 1.9597835342089336\n",
      "    val_log_marginal: 779.4122568766276\n",
      "    val_log_joint  : 987.8087361653646\n",
      "Train Epoch: 1848 [0/54000 (0%)] Loss: -784.826660\n",
      "Train Epoch: 1848 [11264/54000 (21%)] Loss: -778.887573\n",
      "Train Epoch: 1848 [22528/54000 (42%)] Loss: -778.170654\n",
      "Train Epoch: 1848 [33792/54000 (63%)] Loss: -788.708008\n",
      "Train Epoch: 1848 [45056/54000 (83%)] Loss: -779.937500\n",
      "    epoch          : 1848\n",
      "    loss           : -775.1978466105911\n",
      "    ess            : 1.9606302189377118\n",
      "    log_marginal   : 775.2363644006117\n",
      "    log_joint      : 983.8677402712265\n",
      "    val_loss       : -779.6243743896484\n",
      "    val_ess        : 1.961123565832774\n",
      "    val_log_marginal: 779.6636199951172\n",
      "    val_log_joint  : 988.2711232503256\n",
      "Train Epoch: 1849 [0/54000 (0%)] Loss: -780.637268\n",
      "Train Epoch: 1849 [11264/54000 (21%)] Loss: -775.336670\n",
      "Train Epoch: 1849 [22528/54000 (42%)] Loss: -764.028076\n",
      "Train Epoch: 1849 [33792/54000 (63%)] Loss: -776.974670\n",
      "Train Epoch: 1849 [45056/54000 (83%)] Loss: -793.195557\n",
      "    epoch          : 1849\n",
      "    loss           : -775.2265342856354\n",
      "    ess            : 1.9601879918350364\n",
      "    log_marginal   : 775.2651603266878\n",
      "    log_joint      : 983.8523997180866\n",
      "    val_loss       : -779.2056325276693\n",
      "    val_ess        : 1.9581850667794545\n",
      "    val_log_marginal: 779.2475941975912\n",
      "    val_log_joint  : 987.6165771484375\n",
      "Train Epoch: 1850 [0/54000 (0%)] Loss: -775.668945\n",
      "Train Epoch: 1850 [11264/54000 (21%)] Loss: -776.358521\n",
      "Train Epoch: 1850 [22528/54000 (42%)] Loss: -788.329102\n",
      "Train Epoch: 1850 [33792/54000 (63%)] Loss: -760.026978\n",
      "Train Epoch: 1850 [45056/54000 (83%)] Loss: -789.067444\n",
      "    epoch          : 1850\n",
      "    loss           : -775.2062498848393\n",
      "    ess            : 1.9592950276608736\n",
      "    log_marginal   : 775.2462595813679\n",
      "    log_joint      : 983.7669787137014\n",
      "    val_loss       : -779.5211130777994\n",
      "    val_ess        : 1.961166501045227\n",
      "    val_log_marginal: 779.5544484456381\n",
      "    val_log_joint  : 988.2017923990885\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1850.pth ...\n",
      "Train Epoch: 1851 [0/54000 (0%)] Loss: -770.530640\n",
      "Train Epoch: 1851 [11264/54000 (21%)] Loss: -756.135315\n",
      "Train Epoch: 1851 [22528/54000 (42%)] Loss: -780.938660\n",
      "Train Epoch: 1851 [33792/54000 (63%)] Loss: -783.207031\n",
      "Train Epoch: 1851 [45056/54000 (83%)] Loss: -771.796875\n",
      "    epoch          : 1851\n",
      "    loss           : -775.3506573371168\n",
      "    ess            : 1.963153232943337\n",
      "    log_marginal   : 775.3848151440891\n",
      "    log_joint      : 983.9261831607458\n",
      "    val_loss       : -779.5481211344401\n",
      "    val_ess        : 1.961200346549352\n",
      "    val_log_marginal: 779.5869801839193\n",
      "    val_log_joint  : 988.296620686849\n",
      "Train Epoch: 1852 [0/54000 (0%)] Loss: -777.056396\n",
      "Train Epoch: 1852 [11264/54000 (21%)] Loss: -780.601074\n",
      "Train Epoch: 1852 [22528/54000 (42%)] Loss: -760.842163\n",
      "Train Epoch: 1852 [33792/54000 (63%)] Loss: -783.962952\n",
      "Train Epoch: 1852 [45056/54000 (83%)] Loss: -783.866943\n",
      "    epoch          : 1852\n",
      "    loss           : -775.2765975088444\n",
      "    ess            : 1.9610002974294267\n",
      "    log_marginal   : 775.313538749263\n",
      "    log_joint      : 983.842131992556\n",
      "    val_loss       : -779.1949361165365\n",
      "    val_ess        : 1.9602860510349274\n",
      "    val_log_marginal: 779.2320760091146\n",
      "    val_log_joint  : 988.054453531901\n",
      "Train Epoch: 1853 [0/54000 (0%)] Loss: -762.025269\n",
      "Train Epoch: 1853 [11264/54000 (21%)] Loss: -768.139160\n",
      "Train Epoch: 1853 [22528/54000 (42%)] Loss: -760.303589\n",
      "Train Epoch: 1853 [33792/54000 (63%)] Loss: -782.229370\n",
      "Train Epoch: 1853 [45056/54000 (83%)] Loss: -776.152893\n",
      "    epoch          : 1853\n",
      "    loss           : -775.125363907724\n",
      "    ess            : 1.9608499508983683\n",
      "    log_marginal   : 775.1618013202019\n",
      "    log_joint      : 983.7622513681088\n",
      "    val_loss       : -779.2982279459635\n",
      "    val_ess        : 1.9618952870368958\n",
      "    val_log_marginal: 779.3355051676432\n",
      "    val_log_joint  : 988.0544484456381\n",
      "Train Epoch: 1854 [0/54000 (0%)] Loss: -781.573975\n",
      "Train Epoch: 1854 [11264/54000 (21%)] Loss: -777.254883\n",
      "Train Epoch: 1854 [22528/54000 (42%)] Loss: -780.010986\n",
      "Train Epoch: 1854 [33792/54000 (63%)] Loss: -768.448425\n",
      "Train Epoch: 1854 [45056/54000 (83%)] Loss: -760.532593\n",
      "    epoch          : 1854\n",
      "    loss           : -775.3709947118219\n",
      "    ess            : 1.9604674161605116\n",
      "    log_marginal   : 775.4091376538547\n",
      "    log_joint      : 983.8859869039284\n",
      "    val_loss       : -779.6045837402344\n",
      "    val_ess        : 1.9586602846781414\n",
      "    val_log_marginal: 779.6422373453776\n",
      "    val_log_joint  : 987.9877065022787\n",
      "Train Epoch: 1855 [0/54000 (0%)] Loss: -774.777466\n",
      "Train Epoch: 1855 [11264/54000 (21%)] Loss: -766.907654\n",
      "Train Epoch: 1855 [22528/54000 (42%)] Loss: -769.346802\n",
      "Train Epoch: 1855 [33792/54000 (63%)] Loss: -793.926453\n",
      "Train Epoch: 1855 [45056/54000 (83%)] Loss: -776.069336\n",
      "    epoch          : 1855\n",
      "    loss           : -775.3016006181825\n",
      "    ess            : 1.9617619885588593\n",
      "    log_marginal   : 775.3366854685657\n",
      "    log_joint      : 983.8646965746609\n",
      "    val_loss       : -780.4180755615234\n",
      "    val_ess        : 1.9621800382932026\n",
      "    val_log_marginal: 780.4538828531901\n",
      "    val_log_joint  : 988.7688802083334\n",
      "Train Epoch: 1856 [0/54000 (0%)] Loss: -775.148499\n",
      "Train Epoch: 1856 [11264/54000 (21%)] Loss: -769.577087\n",
      "Train Epoch: 1856 [22528/54000 (42%)] Loss: -768.525024\n",
      "Train Epoch: 1856 [33792/54000 (63%)] Loss: -773.895752\n",
      "Train Epoch: 1856 [45056/54000 (83%)] Loss: -785.801758\n",
      "    epoch          : 1856\n",
      "    loss           : -775.3337649939195\n",
      "    ess            : 1.9605091551564775\n",
      "    log_marginal   : 775.3716551582768\n",
      "    log_joint      : 983.91713095611\n",
      "    val_loss       : -779.8280893961588\n",
      "    val_ess        : 1.960290213425954\n",
      "    val_log_marginal: 779.8643086751302\n",
      "    val_log_joint  : 988.4390767415365\n",
      "Train Epoch: 1857 [0/54000 (0%)] Loss: -747.395142\n",
      "Train Epoch: 1857 [11264/54000 (21%)] Loss: -775.448486\n",
      "Train Epoch: 1857 [22528/54000 (42%)] Loss: -783.594360\n",
      "Train Epoch: 1857 [33792/54000 (63%)] Loss: -766.619080\n",
      "Train Epoch: 1857 [45056/54000 (83%)] Loss: -773.094910\n",
      "    epoch          : 1857\n",
      "    loss           : -775.1552434957252\n",
      "    ess            : 1.9610637246437792\n",
      "    log_marginal   : 775.1929730109449\n",
      "    log_joint      : 983.7302153965212\n",
      "    val_loss       : -780.2147216796875\n",
      "    val_ess        : 1.9630539615948994\n",
      "    val_log_marginal: 780.2491099039713\n",
      "    val_log_joint  : 989.0573933919271\n",
      "Train Epoch: 1858 [0/54000 (0%)] Loss: -786.797119\n",
      "Train Epoch: 1858 [11264/54000 (21%)] Loss: -770.001038\n",
      "Train Epoch: 1858 [22528/54000 (42%)] Loss: -767.443787\n",
      "Train Epoch: 1858 [33792/54000 (63%)] Loss: -762.129150\n",
      "Train Epoch: 1858 [45056/54000 (83%)] Loss: -775.276062\n",
      "    epoch          : 1858\n",
      "    loss           : -775.4158578548792\n",
      "    ess            : 1.9609515914377176\n",
      "    log_marginal   : 775.4533743228552\n",
      "    log_joint      : 983.9679939701872\n",
      "    val_loss       : -779.6663869222006\n",
      "    val_ess        : 1.9614472289880116\n",
      "    val_log_marginal: 779.7046712239584\n",
      "    val_log_joint  : 988.4043884277344\n",
      "Train Epoch: 1859 [0/54000 (0%)] Loss: -781.811951\n",
      "Train Epoch: 1859 [11264/54000 (21%)] Loss: -764.814575\n",
      "Train Epoch: 1859 [22528/54000 (42%)] Loss: -781.263062\n",
      "Train Epoch: 1859 [33792/54000 (63%)] Loss: -791.483215\n",
      "Train Epoch: 1859 [45056/54000 (83%)] Loss: -778.687378\n",
      "    epoch          : 1859\n",
      "    loss           : -775.4159355883328\n",
      "    ess            : 1.9610558579552848\n",
      "    log_marginal   : 775.4524593713148\n",
      "    log_joint      : 984.0352414688974\n",
      "    val_loss       : -779.562255859375\n",
      "    val_ess        : 1.9628206590811412\n",
      "    val_log_marginal: 779.5982767740885\n",
      "    val_log_joint  : 988.0349273681641\n",
      "Train Epoch: 1860 [0/54000 (0%)] Loss: -765.423340\n",
      "Train Epoch: 1860 [11264/54000 (21%)] Loss: -783.230469\n",
      "Train Epoch: 1860 [22528/54000 (42%)] Loss: -788.330078\n",
      "Train Epoch: 1860 [33792/54000 (63%)] Loss: -768.900146\n",
      "Train Epoch: 1860 [45056/54000 (83%)] Loss: -766.776367\n",
      "    epoch          : 1860\n",
      "    loss           : -775.2117361392615\n",
      "    ess            : 1.9608399170749593\n",
      "    log_marginal   : 775.2501439508402\n",
      "    log_joint      : 983.8382643213812\n",
      "    val_loss       : -780.2611897786459\n",
      "    val_ess        : 1.9616658091545105\n",
      "    val_log_marginal: 780.2946828206381\n",
      "    val_log_joint  : 988.80908203125\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1860.pth ...\n",
      "Train Epoch: 1861 [0/54000 (0%)] Loss: -760.636353\n",
      "Train Epoch: 1861 [11264/54000 (21%)] Loss: -769.376953\n",
      "Train Epoch: 1861 [22528/54000 (42%)] Loss: -764.165039\n",
      "Train Epoch: 1861 [33792/54000 (63%)] Loss: -749.549683\n",
      "Train Epoch: 1861 [45056/54000 (83%)] Loss: -777.226624\n",
      "    epoch          : 1861\n",
      "    loss           : -775.2541509664284\n",
      "    ess            : 1.9603537635983161\n",
      "    log_marginal   : 775.2923106067585\n",
      "    log_joint      : 983.7798081883844\n",
      "    val_loss       : -779.1071065266927\n",
      "    val_ess        : 1.9625037709871929\n",
      "    val_log_marginal: 779.1451161702474\n",
      "    val_log_joint  : 987.8536580403646\n",
      "Train Epoch: 1862 [0/54000 (0%)] Loss: -776.153931\n",
      "Train Epoch: 1862 [11264/54000 (21%)] Loss: -773.107117\n",
      "Train Epoch: 1862 [22528/54000 (42%)] Loss: -766.643433\n",
      "Train Epoch: 1862 [33792/54000 (63%)] Loss: -791.825317\n",
      "Train Epoch: 1862 [45056/54000 (83%)] Loss: -782.057129\n",
      "    epoch          : 1862\n",
      "    loss           : -775.2968393001917\n",
      "    ess            : 1.960489866868505\n",
      "    log_marginal   : 775.3353553628021\n",
      "    log_joint      : 983.8180950812574\n",
      "    val_loss       : -779.2828369140625\n",
      "    val_ess        : 1.9570476114749908\n",
      "    val_log_marginal: 779.3258565266927\n",
      "    val_log_joint  : 988.1369934082031\n",
      "Train Epoch: 1863 [0/54000 (0%)] Loss: -771.373535\n",
      "Train Epoch: 1863 [11264/54000 (21%)] Loss: -773.901245\n",
      "Train Epoch: 1863 [22528/54000 (42%)] Loss: -767.450806\n",
      "Train Epoch: 1863 [33792/54000 (63%)] Loss: -795.992676\n",
      "Train Epoch: 1863 [45056/54000 (83%)] Loss: -762.980713\n",
      "    epoch          : 1863\n",
      "    loss           : -775.1069698693617\n",
      "    ess            : 1.9615259631624762\n",
      "    log_marginal   : 775.1433911593455\n",
      "    log_joint      : 983.7003415665537\n",
      "    val_loss       : -779.6645863850912\n",
      "    val_ess        : 1.9579423069953918\n",
      "    val_log_marginal: 779.7067108154297\n",
      "    val_log_joint  : 988.1018269856771\n",
      "Train Epoch: 1864 [0/54000 (0%)] Loss: -784.871826\n",
      "Train Epoch: 1864 [11264/54000 (21%)] Loss: -791.252380\n",
      "Train Epoch: 1864 [22528/54000 (42%)] Loss: -786.730286\n",
      "Train Epoch: 1864 [33792/54000 (63%)] Loss: -766.860107\n",
      "Train Epoch: 1864 [45056/54000 (83%)] Loss: -772.349670\n",
      "    epoch          : 1864\n",
      "    loss           : -775.5310628639078\n",
      "    ess            : 1.960656633916891\n",
      "    log_marginal   : 775.568171087301\n",
      "    log_joint      : 984.0086583551371\n",
      "    val_loss       : -779.7618611653646\n",
      "    val_ess        : 1.9626552661259968\n",
      "    val_log_marginal: 779.7975209554037\n",
      "    val_log_joint  : 988.4483083089193\n",
      "Train Epoch: 1865 [0/54000 (0%)] Loss: -769.530029\n",
      "Train Epoch: 1865 [11264/54000 (21%)] Loss: -777.392822\n",
      "Train Epoch: 1865 [22528/54000 (42%)] Loss: -789.741455\n",
      "Train Epoch: 1865 [33792/54000 (63%)] Loss: -767.944702\n",
      "Train Epoch: 1865 [45056/54000 (83%)] Loss: -790.657227\n",
      "    epoch          : 1865\n",
      "    loss           : -775.3643453346109\n",
      "    ess            : 1.9604618571839243\n",
      "    log_marginal   : 775.4027946040316\n",
      "    log_joint      : 983.8806186891952\n",
      "    val_loss       : -779.731699625651\n",
      "    val_ess        : 1.9625306129455566\n",
      "    val_log_marginal: 779.7654927571615\n",
      "    val_log_joint  : 988.4241892496744\n",
      "Train Epoch: 1866 [0/54000 (0%)] Loss: -772.025391\n",
      "Train Epoch: 1866 [11264/54000 (21%)] Loss: -770.367249\n",
      "Train Epoch: 1866 [22528/54000 (42%)] Loss: -793.548279\n",
      "Train Epoch: 1866 [33792/54000 (63%)] Loss: -787.120544\n",
      "Train Epoch: 1866 [45056/54000 (83%)] Loss: -764.991943\n",
      "    epoch          : 1866\n",
      "    loss           : -775.0565790140404\n",
      "    ess            : 1.9605994292025297\n",
      "    log_marginal   : 775.0943125598835\n",
      "    log_joint      : 983.6875996139814\n",
      "    val_loss       : -779.9301350911459\n",
      "    val_ess        : 1.9612128635247548\n",
      "    val_log_marginal: 779.9676411946615\n",
      "    val_log_joint  : 988.3842468261719\n",
      "Train Epoch: 1867 [0/54000 (0%)] Loss: -797.250305\n",
      "Train Epoch: 1867 [11264/54000 (21%)] Loss: -780.668518\n",
      "Train Epoch: 1867 [22528/54000 (42%)] Loss: -788.622070\n",
      "Train Epoch: 1867 [33792/54000 (63%)] Loss: -784.087463\n",
      "Train Epoch: 1867 [45056/54000 (83%)] Loss: -790.602051\n",
      "    epoch          : 1867\n",
      "    loss           : -775.228563416679\n",
      "    ess            : 1.9613640949411213\n",
      "    log_marginal   : 775.2650946851047\n",
      "    log_joint      : 983.7425968961895\n",
      "    val_loss       : -779.4709981282552\n",
      "    val_ess        : 1.960329959789912\n",
      "    val_log_marginal: 779.51171875\n",
      "    val_log_joint  : 988.1122538248698\n",
      "Train Epoch: 1868 [0/54000 (0%)] Loss: -774.875366\n",
      "Train Epoch: 1868 [11264/54000 (21%)] Loss: -764.379517\n",
      "Train Epoch: 1868 [22528/54000 (42%)] Loss: -771.297607\n",
      "Train Epoch: 1868 [33792/54000 (63%)] Loss: -758.142212\n",
      "Train Epoch: 1868 [45056/54000 (83%)] Loss: -762.576477\n",
      "    epoch          : 1868\n",
      "    loss           : -775.3443517145121\n",
      "    ess            : 1.9614228088900727\n",
      "    log_marginal   : 775.3811847038988\n",
      "    log_joint      : 983.8628367298054\n",
      "    val_loss       : -779.4982655843099\n",
      "    val_ess        : 1.96452996134758\n",
      "    val_log_marginal: 779.5298309326172\n",
      "    val_log_joint  : 987.9692789713541\n",
      "Train Epoch: 1869 [0/54000 (0%)] Loss: -777.410828\n",
      "Train Epoch: 1869 [11264/54000 (21%)] Loss: -769.541687\n",
      "Train Epoch: 1869 [22528/54000 (42%)] Loss: -788.284180\n",
      "Train Epoch: 1869 [33792/54000 (63%)] Loss: -790.378723\n",
      "Train Epoch: 1869 [45056/54000 (83%)] Loss: -797.062134\n",
      "    epoch          : 1869\n",
      "    loss           : -775.1776359126253\n",
      "    ess            : 1.961995486943227\n",
      "    log_marginal   : 775.213010392099\n",
      "    log_joint      : 983.7908457630085\n",
      "    val_loss       : -779.9585673014323\n",
      "    val_ess        : 1.961190104484558\n",
      "    val_log_marginal: 779.995371500651\n",
      "    val_log_joint  : 988.1854349772135\n",
      "Train Epoch: 1870 [0/54000 (0%)] Loss: -790.902954\n",
      "Train Epoch: 1870 [11264/54000 (21%)] Loss: -767.131714\n",
      "Train Epoch: 1870 [22528/54000 (42%)] Loss: -765.633728\n",
      "Train Epoch: 1870 [33792/54000 (63%)] Loss: -781.547119\n",
      "Train Epoch: 1870 [45056/54000 (83%)] Loss: -787.190735\n",
      "    epoch          : 1870\n",
      "    loss           : -775.2955322265625\n",
      "    ess            : 1.9597337763264495\n",
      "    log_marginal   : 775.3350139114092\n",
      "    log_joint      : 983.791880481648\n",
      "    val_loss       : -779.6731160481771\n",
      "    val_ess        : 1.9621947010358174\n",
      "    val_log_marginal: 779.7080078125\n",
      "    val_log_joint  : 988.3846130371094\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1870.pth ...\n",
      "Train Epoch: 1871 [0/54000 (0%)] Loss: -773.256470\n",
      "Train Epoch: 1871 [11264/54000 (21%)] Loss: -775.444214\n",
      "Train Epoch: 1871 [22528/54000 (42%)] Loss: -769.227905\n",
      "Train Epoch: 1871 [33792/54000 (63%)] Loss: -770.057007\n",
      "Train Epoch: 1871 [45056/54000 (83%)] Loss: -755.753723\n",
      "    epoch          : 1871\n",
      "    loss           : -775.1223616690006\n",
      "    ess            : 1.9615930802417252\n",
      "    log_marginal   : 775.159709426592\n",
      "    log_joint      : 983.7882799832327\n",
      "    val_loss       : -779.2386169433594\n",
      "    val_ess        : 1.961484541495641\n",
      "    val_log_marginal: 779.2736104329427\n",
      "    val_log_joint  : 987.8272145589193\n",
      "Train Epoch: 1872 [0/54000 (0%)] Loss: -773.590576\n",
      "Train Epoch: 1872 [11264/54000 (21%)] Loss: -780.415588\n",
      "Train Epoch: 1872 [22528/54000 (42%)] Loss: -783.504761\n",
      "Train Epoch: 1872 [33792/54000 (63%)] Loss: -775.671936\n",
      "Train Epoch: 1872 [45056/54000 (83%)] Loss: -788.339417\n",
      "    epoch          : 1872\n",
      "    loss           : -775.3001300163988\n",
      "    ess            : 1.961377537475442\n",
      "    log_marginal   : 775.3366658912515\n",
      "    log_joint      : 983.8482372355911\n",
      "    val_loss       : -779.1237843831381\n",
      "    val_ess        : 1.962920904159546\n",
      "    val_log_marginal: 779.1562550862631\n",
      "    val_log_joint  : 987.7172902425131\n",
      "Train Epoch: 1873 [0/54000 (0%)] Loss: -784.216919\n",
      "Train Epoch: 1873 [11264/54000 (21%)] Loss: -764.281616\n",
      "Train Epoch: 1873 [22528/54000 (42%)] Loss: -798.726807\n",
      "Train Epoch: 1873 [33792/54000 (63%)] Loss: -780.375854\n",
      "Train Epoch: 1873 [45056/54000 (83%)] Loss: -774.725647\n",
      "    epoch          : 1873\n",
      "    loss           : -775.2676224618588\n",
      "    ess            : 1.9617419029181857\n",
      "    log_marginal   : 775.303203654739\n",
      "    log_joint      : 983.757061076614\n",
      "    val_loss       : -779.9300079345703\n",
      "    val_ess        : 1.9617331524689992\n",
      "    val_log_marginal: 779.9680379231771\n",
      "    val_log_joint  : 988.3016306559244\n",
      "Train Epoch: 1874 [0/54000 (0%)] Loss: -763.048218\n",
      "Train Epoch: 1874 [11264/54000 (21%)] Loss: -776.052368\n",
      "Train Epoch: 1874 [22528/54000 (42%)] Loss: -779.219360\n",
      "Train Epoch: 1874 [33792/54000 (63%)] Loss: -775.038574\n",
      "Train Epoch: 1874 [45056/54000 (83%)] Loss: -774.046204\n",
      "    epoch          : 1874\n",
      "    loss           : -775.2657666476267\n",
      "    ess            : 1.9613445311222437\n",
      "    log_marginal   : 775.302045138377\n",
      "    log_joint      : 983.8362616772922\n",
      "    val_loss       : -779.5088755289713\n",
      "    val_ess        : 1.9597261647383373\n",
      "    val_log_marginal: 779.5460103352865\n",
      "    val_log_joint  : 988.3619537353516\n",
      "Train Epoch: 1875 [0/54000 (0%)] Loss: -785.357422\n",
      "Train Epoch: 1875 [11264/54000 (21%)] Loss: -774.522705\n",
      "Train Epoch: 1875 [22528/54000 (42%)] Loss: -765.127136\n",
      "Train Epoch: 1875 [33792/54000 (63%)] Loss: -757.117432\n",
      "Train Epoch: 1875 [45056/54000 (83%)] Loss: -788.311646\n",
      "    epoch          : 1875\n",
      "    loss           : -775.3202030973614\n",
      "    ess            : 1.960713730668122\n",
      "    log_marginal   : 775.3578733048349\n",
      "    log_joint      : 983.8634862359964\n",
      "    val_loss       : -779.4794972737631\n",
      "    val_ess        : 1.964782824118932\n",
      "    val_log_marginal: 779.5138498942057\n",
      "    val_log_joint  : 988.0360310872396\n",
      "Train Epoch: 1876 [0/54000 (0%)] Loss: -775.071289\n",
      "Train Epoch: 1876 [11264/54000 (21%)] Loss: -784.930115\n",
      "Train Epoch: 1876 [22528/54000 (42%)] Loss: -772.819580\n",
      "Train Epoch: 1876 [33792/54000 (63%)] Loss: -766.110352\n",
      "Train Epoch: 1876 [45056/54000 (83%)] Loss: -769.716980\n",
      "    epoch          : 1876\n",
      "    loss           : -775.4785605376621\n",
      "    ess            : 1.9618120800774053\n",
      "    log_marginal   : 775.5148384526091\n",
      "    log_joint      : 984.0005683179172\n",
      "    val_loss       : -779.502187093099\n",
      "    val_ess        : 1.9609295924504597\n",
      "    val_log_marginal: 779.5369059244791\n",
      "    val_log_joint  : 987.9912872314453\n",
      "Train Epoch: 1877 [0/54000 (0%)] Loss: -779.651001\n",
      "Train Epoch: 1877 [11264/54000 (21%)] Loss: -787.654175\n",
      "Train Epoch: 1877 [22528/54000 (42%)] Loss: -764.117371\n",
      "Train Epoch: 1877 [33792/54000 (63%)] Loss: -768.785889\n",
      "Train Epoch: 1877 [45056/54000 (83%)] Loss: -794.426514\n",
      "    epoch          : 1877\n",
      "    loss           : -775.3826403347952\n",
      "    ess            : 1.9609110085469372\n",
      "    log_marginal   : 775.4209681097067\n",
      "    log_joint      : 983.9121963213075\n",
      "    val_loss       : -780.4861806233724\n",
      "    val_ess        : 1.9642292161782582\n",
      "    val_log_marginal: 780.5194142659506\n",
      "    val_log_joint  : 988.8671112060547\n",
      "Train Epoch: 1878 [0/54000 (0%)] Loss: -788.368835\n",
      "Train Epoch: 1878 [11264/54000 (21%)] Loss: -780.747559\n",
      "Train Epoch: 1878 [22528/54000 (42%)] Loss: -805.694763\n",
      "Train Epoch: 1878 [33792/54000 (63%)] Loss: -771.105347\n",
      "Train Epoch: 1878 [45056/54000 (83%)] Loss: -791.318787\n",
      "    epoch          : 1878\n",
      "    loss           : -775.2120033120209\n",
      "    ess            : 1.9609540757143273\n",
      "    log_marginal   : 775.2488794866598\n",
      "    log_joint      : 983.7414539265183\n",
      "    val_loss       : -780.1266021728516\n",
      "    val_ess        : 1.96267964442571\n",
      "    val_log_marginal: 780.1618448893229\n",
      "    val_log_joint  : 988.2864023844401\n",
      "Train Epoch: 1879 [0/54000 (0%)] Loss: -792.676147\n",
      "Train Epoch: 1879 [11264/54000 (21%)] Loss: -777.544922\n",
      "Train Epoch: 1879 [22528/54000 (42%)] Loss: -774.164124\n",
      "Train Epoch: 1879 [33792/54000 (63%)] Loss: -769.894653\n",
      "Train Epoch: 1879 [45056/54000 (83%)] Loss: -776.838013\n",
      "    epoch          : 1879\n",
      "    loss           : -775.3752694759729\n",
      "    ess            : 1.9615813190082334\n",
      "    log_marginal   : 775.4123840332031\n",
      "    log_joint      : 983.8737614469708\n",
      "    val_loss       : -780.4902140299479\n",
      "    val_ess        : 1.9615327715873718\n",
      "    val_log_marginal: 780.5292409261068\n",
      "    val_log_joint  : 988.9073232014974\n",
      "Train Epoch: 1880 [0/54000 (0%)] Loss: -753.787354\n",
      "Train Epoch: 1880 [11264/54000 (21%)] Loss: -767.718628\n",
      "Train Epoch: 1880 [22528/54000 (42%)] Loss: -775.049194\n",
      "Train Epoch: 1880 [33792/54000 (63%)] Loss: -757.841492\n",
      "Train Epoch: 1880 [45056/54000 (83%)] Loss: -782.236450\n",
      "    epoch          : 1880\n",
      "    loss           : -775.2904150620947\n",
      "    ess            : 1.9608653322705683\n",
      "    log_marginal   : 775.327349392873\n",
      "    log_joint      : 983.8757790619472\n",
      "    val_loss       : -780.0738779703776\n",
      "    val_ess        : 1.9598908424377441\n",
      "    val_log_marginal: 780.1137898763021\n",
      "    val_log_joint  : 988.8170522054037\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1880.pth ...\n",
      "Train Epoch: 1881 [0/54000 (0%)] Loss: -768.026062\n",
      "Train Epoch: 1881 [11264/54000 (21%)] Loss: -770.723999\n",
      "Train Epoch: 1881 [22528/54000 (42%)] Loss: -774.846802\n",
      "Train Epoch: 1881 [33792/54000 (63%)] Loss: -762.035095\n",
      "Train Epoch: 1881 [45056/54000 (83%)] Loss: -775.461182\n",
      "    epoch          : 1881\n",
      "    loss           : -775.3693968574955\n",
      "    ess            : 1.9607144830361851\n",
      "    log_marginal   : 775.4063150657797\n",
      "    log_joint      : 983.9361923505675\n",
      "    val_loss       : -779.823720296224\n",
      "    val_ess        : 1.9625483353932698\n",
      "    val_log_marginal: 779.8577931722006\n",
      "    val_log_joint  : 988.1207885742188\n",
      "Train Epoch: 1882 [0/54000 (0%)] Loss: -772.980042\n",
      "Train Epoch: 1882 [11264/54000 (21%)] Loss: -782.376892\n",
      "Train Epoch: 1882 [22528/54000 (42%)] Loss: -779.365112\n",
      "Train Epoch: 1882 [33792/54000 (63%)] Loss: -778.332886\n",
      "Train Epoch: 1882 [45056/54000 (83%)] Loss: -764.812988\n",
      "    epoch          : 1882\n",
      "    loss           : -775.4801963950104\n",
      "    ess            : 1.9609581873102009\n",
      "    log_marginal   : 775.5182092054835\n",
      "    log_joint      : 984.0083220859743\n",
      "    val_loss       : -779.9582977294922\n",
      "    val_ess        : 1.9587465325991313\n",
      "    val_log_marginal: 779.9936014811198\n",
      "    val_log_joint  : 988.7447255452474\n",
      "Train Epoch: 1883 [0/54000 (0%)] Loss: -779.117065\n",
      "Train Epoch: 1883 [11264/54000 (21%)] Loss: -765.662659\n",
      "Train Epoch: 1883 [22528/54000 (42%)] Loss: -776.054749\n",
      "Train Epoch: 1883 [33792/54000 (63%)] Loss: -771.133301\n",
      "Train Epoch: 1883 [45056/54000 (83%)] Loss: -791.481567\n",
      "    epoch          : 1883\n",
      "    loss           : -775.1409111742703\n",
      "    ess            : 1.9607198991865482\n",
      "    log_marginal   : 775.1787765790831\n",
      "    log_joint      : 983.746519844487\n",
      "    val_loss       : -779.597157796224\n",
      "    val_ess        : 1.963688353697459\n",
      "    val_log_marginal: 779.6305135091146\n",
      "    val_log_joint  : 988.2869008382162\n",
      "Train Epoch: 1884 [0/54000 (0%)] Loss: -774.506348\n",
      "Train Epoch: 1884 [11264/54000 (21%)] Loss: -749.846008\n",
      "Train Epoch: 1884 [22528/54000 (42%)] Loss: -799.221802\n",
      "Train Epoch: 1884 [33792/54000 (63%)] Loss: -770.065857\n",
      "Train Epoch: 1884 [45056/54000 (83%)] Loss: -769.087891\n",
      "    epoch          : 1884\n",
      "    loss           : -775.5172735250221\n",
      "    ess            : 1.9605026807425157\n",
      "    log_marginal   : 775.5556594560732\n",
      "    log_joint      : 984.0277255076282\n",
      "    val_loss       : -780.1783752441406\n",
      "    val_ess        : 1.9606982072194417\n",
      "    val_log_marginal: 780.2154083251953\n",
      "    val_log_joint  : 988.5270792643229\n",
      "Train Epoch: 1885 [0/54000 (0%)] Loss: -781.884583\n",
      "Train Epoch: 1885 [11264/54000 (21%)] Loss: -766.247986\n",
      "Train Epoch: 1885 [22528/54000 (42%)] Loss: -790.034058\n",
      "Train Epoch: 1885 [33792/54000 (63%)] Loss: -758.306030\n",
      "Train Epoch: 1885 [45056/54000 (83%)] Loss: -790.503784\n",
      "    epoch          : 1885\n",
      "    loss           : -775.2765278366377\n",
      "    ess            : 1.9606621636534638\n",
      "    log_marginal   : 775.3137500690964\n",
      "    log_joint      : 983.8033251492483\n",
      "    val_loss       : -779.8915506998698\n",
      "    val_ess        : 1.9614597658316295\n",
      "    val_log_marginal: 779.9305979410807\n",
      "    val_log_joint  : 988.2716878255209\n",
      "Train Epoch: 1886 [0/54000 (0%)] Loss: -761.974121\n",
      "Train Epoch: 1886 [11264/54000 (21%)] Loss: -798.856689\n",
      "Train Epoch: 1886 [22528/54000 (42%)] Loss: -797.172668\n",
      "Train Epoch: 1886 [33792/54000 (63%)] Loss: -785.594971\n",
      "Train Epoch: 1886 [45056/54000 (83%)] Loss: -772.422668\n",
      "    epoch          : 1886\n",
      "    loss           : -775.434208132186\n",
      "    ess            : 1.961686188319944\n",
      "    log_marginal   : 775.4715627994177\n",
      "    log_joint      : 983.954554719745\n",
      "    val_loss       : -779.7124633789062\n",
      "    val_ess        : 1.9626203676064808\n",
      "    val_log_marginal: 779.7436269124349\n",
      "    val_log_joint  : 988.3112843831381\n",
      "Train Epoch: 1887 [0/54000 (0%)] Loss: -780.185974\n",
      "Train Epoch: 1887 [11264/54000 (21%)] Loss: -766.231079\n",
      "Train Epoch: 1887 [22528/54000 (42%)] Loss: -775.609375\n",
      "Train Epoch: 1887 [33792/54000 (63%)] Loss: -759.642700\n",
      "Train Epoch: 1887 [45056/54000 (83%)] Loss: -775.946899\n",
      "    epoch          : 1887\n",
      "    loss           : -775.4011506854363\n",
      "    ess            : 1.9621074795722961\n",
      "    log_marginal   : 775.4375869463075\n",
      "    log_joint      : 983.9945482937795\n",
      "    val_loss       : -779.9706013997396\n",
      "    val_ess        : 1.961057076851527\n",
      "    val_log_marginal: 780.0120188395182\n",
      "    val_log_joint  : 988.5050303141276\n",
      "Train Epoch: 1888 [0/54000 (0%)] Loss: -779.437256\n",
      "Train Epoch: 1888 [11264/54000 (21%)] Loss: -794.626465\n",
      "Train Epoch: 1888 [22528/54000 (42%)] Loss: -774.066162\n",
      "Train Epoch: 1888 [33792/54000 (63%)] Loss: -784.507019\n",
      "Train Epoch: 1888 [45056/54000 (83%)] Loss: -748.593018\n",
      "    epoch          : 1888\n",
      "    loss           : -775.2261438909567\n",
      "    ess            : 1.9608766953900176\n",
      "    log_marginal   : 775.2628974194797\n",
      "    log_joint      : 983.8533791596035\n",
      "    val_loss       : -778.2437744140625\n",
      "    val_ess        : 1.959795077641805\n",
      "    val_log_marginal: 778.2793273925781\n",
      "    val_log_joint  : 986.9375508626302\n",
      "Train Epoch: 1889 [0/54000 (0%)] Loss: -782.414001\n",
      "Train Epoch: 1889 [11264/54000 (21%)] Loss: -773.983765\n",
      "Train Epoch: 1889 [22528/54000 (42%)] Loss: -783.948792\n",
      "Train Epoch: 1889 [33792/54000 (63%)] Loss: -767.727783\n",
      "Train Epoch: 1889 [45056/54000 (83%)] Loss: -780.871216\n",
      "    epoch          : 1889\n",
      "    loss           : -775.4300134047022\n",
      "    ess            : 1.9603386442616302\n",
      "    log_marginal   : 775.4675465709759\n",
      "    log_joint      : 983.9870438485775\n",
      "    val_loss       : -779.8094685872396\n",
      "    val_ess        : 1.9599019587039948\n",
      "    val_log_marginal: 779.8433583577474\n",
      "    val_log_joint  : 988.2492879231771\n",
      "Train Epoch: 1890 [0/54000 (0%)] Loss: -793.326416\n",
      "Train Epoch: 1890 [11264/54000 (21%)] Loss: -784.044373\n",
      "Train Epoch: 1890 [22528/54000 (42%)] Loss: -792.423340\n",
      "Train Epoch: 1890 [33792/54000 (63%)] Loss: -782.603943\n",
      "Train Epoch: 1890 [45056/54000 (83%)] Loss: -783.486572\n",
      "    epoch          : 1890\n",
      "    loss           : -775.3624762769016\n",
      "    ess            : 1.9617848722439892\n",
      "    log_marginal   : 775.3986914292822\n",
      "    log_joint      : 983.9121174362471\n",
      "    val_loss       : -779.3788706461588\n",
      "    val_ess        : 1.9630765716234844\n",
      "    val_log_marginal: 779.4132944742838\n",
      "    val_log_joint  : 987.9625905354818\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1890.pth ...\n",
      "Train Epoch: 1891 [0/54000 (0%)] Loss: -775.281006\n",
      "Train Epoch: 1891 [11264/54000 (21%)] Loss: -766.446167\n",
      "Train Epoch: 1891 [22528/54000 (42%)] Loss: -781.338806\n",
      "Train Epoch: 1891 [33792/54000 (63%)] Loss: -788.886536\n",
      "Train Epoch: 1891 [45056/54000 (83%)] Loss: -755.302490\n",
      "    epoch          : 1891\n",
      "    loss           : -775.3915031001253\n",
      "    ess            : 1.9618094484761077\n",
      "    log_marginal   : 775.4279514528671\n",
      "    log_joint      : 983.8865581008623\n",
      "    val_loss       : -779.4443715413412\n",
      "    val_ess        : 1.9615996479988098\n",
      "    val_log_marginal: 779.4847717285156\n",
      "    val_log_joint  : 988.077402750651\n",
      "Train Epoch: 1892 [0/54000 (0%)] Loss: -758.000977\n",
      "Train Epoch: 1892 [11264/54000 (21%)] Loss: -782.781799\n",
      "Train Epoch: 1892 [22528/54000 (42%)] Loss: -786.488892\n",
      "Train Epoch: 1892 [33792/54000 (63%)] Loss: -780.205383\n",
      "Train Epoch: 1892 [45056/54000 (83%)] Loss: -784.892334\n",
      "    epoch          : 1892\n",
      "    loss           : -775.4379312767172\n",
      "    ess            : 1.9620263497784454\n",
      "    log_marginal   : 775.4740669682341\n",
      "    log_joint      : 984.0133816701061\n",
      "    val_loss       : -779.5878499348959\n",
      "    val_ess        : 1.9597604473431904\n",
      "    val_log_marginal: 779.6267395019531\n",
      "    val_log_joint  : 988.0741373697916\n",
      "Train Epoch: 1893 [0/54000 (0%)] Loss: -757.451538\n",
      "Train Epoch: 1893 [11264/54000 (21%)] Loss: -775.965942\n",
      "Train Epoch: 1893 [22528/54000 (42%)] Loss: -757.911011\n",
      "Train Epoch: 1893 [33792/54000 (63%)] Loss: -770.988037\n",
      "Train Epoch: 1893 [45056/54000 (83%)] Loss: -761.500732\n",
      "    epoch          : 1893\n",
      "    loss           : -775.2945015385466\n",
      "    ess            : 1.9609981786529973\n",
      "    log_marginal   : 775.3328926518278\n",
      "    log_joint      : 983.914362493551\n",
      "    val_loss       : -780.0345865885416\n",
      "    val_ess        : 1.9576417406400044\n",
      "    val_log_marginal: 780.0753835042318\n",
      "    val_log_joint  : 988.6898752848307\n",
      "Train Epoch: 1894 [0/54000 (0%)] Loss: -778.949768\n",
      "Train Epoch: 1894 [11264/54000 (21%)] Loss: -771.653809\n",
      "Train Epoch: 1894 [22528/54000 (42%)] Loss: -771.831055\n",
      "Train Epoch: 1894 [33792/54000 (63%)] Loss: -770.676086\n",
      "Train Epoch: 1894 [45056/54000 (83%)] Loss: -790.616394\n",
      "    epoch          : 1894\n",
      "    loss           : -775.4571216511276\n",
      "    ess            : 1.9613243105276577\n",
      "    log_marginal   : 775.4937479271078\n",
      "    log_joint      : 984.0359520102447\n",
      "    val_loss       : -779.6823984781901\n",
      "    val_ess        : 1.9631688296794891\n",
      "    val_log_marginal: 779.7186787923177\n",
      "    val_log_joint  : 988.5337422688802\n",
      "Train Epoch: 1895 [0/54000 (0%)] Loss: -786.407104\n",
      "Train Epoch: 1895 [11264/54000 (21%)] Loss: -759.822144\n",
      "Train Epoch: 1895 [22528/54000 (42%)] Loss: -780.042786\n",
      "Train Epoch: 1895 [33792/54000 (63%)] Loss: -790.562988\n",
      "Train Epoch: 1895 [45056/54000 (83%)] Loss: -754.514893\n",
      "    epoch          : 1895\n",
      "    loss           : -775.4041863207547\n",
      "    ess            : 1.962204117819948\n",
      "    log_marginal   : 775.4400715378096\n",
      "    log_joint      : 983.9186251658314\n",
      "    val_loss       : -779.3223114013672\n",
      "    val_ess        : 1.9601141313711803\n",
      "    val_log_marginal: 779.3613230387369\n",
      "    val_log_joint  : 988.3264211018881\n",
      "Train Epoch: 1896 [0/54000 (0%)] Loss: -763.553833\n",
      "Train Epoch: 1896 [11264/54000 (21%)] Loss: -751.362732\n",
      "Train Epoch: 1896 [22528/54000 (42%)] Loss: -780.850952\n",
      "Train Epoch: 1896 [33792/54000 (63%)] Loss: -795.717041\n",
      "Train Epoch: 1896 [45056/54000 (83%)] Loss: -776.077881\n",
      "    epoch          : 1896\n",
      "    loss           : -775.4056799546728\n",
      "    ess            : 1.960590274828785\n",
      "    log_marginal   : 775.4447614561836\n",
      "    log_joint      : 983.963910372752\n",
      "    val_loss       : -780.2692260742188\n",
      "    val_ess        : 1.9624358812967937\n",
      "    val_log_marginal: 780.3034159342448\n",
      "    val_log_joint  : 988.8106435139974\n",
      "Train Epoch: 1897 [0/54000 (0%)] Loss: -770.185669\n",
      "Train Epoch: 1897 [11264/54000 (21%)] Loss: -797.432495\n",
      "Train Epoch: 1897 [22528/54000 (42%)] Loss: -763.416077\n",
      "Train Epoch: 1897 [33792/54000 (63%)] Loss: -781.622681\n",
      "Train Epoch: 1897 [45056/54000 (83%)] Loss: -766.947021\n",
      "    epoch          : 1897\n",
      "    loss           : -775.4147384931456\n",
      "    ess            : 1.9612825973978583\n",
      "    log_marginal   : 775.4511540250958\n",
      "    log_joint      : 983.9069542075104\n",
      "    val_loss       : -779.8780975341797\n",
      "    val_ess        : 1.9617782533168793\n",
      "    val_log_marginal: 779.9160766601562\n",
      "    val_log_joint  : 988.2431233723959\n",
      "Train Epoch: 1898 [0/54000 (0%)] Loss: -783.586792\n",
      "Train Epoch: 1898 [11264/54000 (21%)] Loss: -774.324280\n",
      "Train Epoch: 1898 [22528/54000 (42%)] Loss: -777.676697\n",
      "Train Epoch: 1898 [33792/54000 (63%)] Loss: -749.793457\n",
      "Train Epoch: 1898 [45056/54000 (83%)] Loss: -765.973755\n",
      "    epoch          : 1898\n",
      "    loss           : -775.3428540499705\n",
      "    ess            : 1.962207832426395\n",
      "    log_marginal   : 775.3781922538326\n",
      "    log_joint      : 983.8759195579672\n",
      "    val_loss       : -779.7944742838541\n",
      "    val_ess        : 1.9599067469437916\n",
      "    val_log_marginal: 779.8324788411459\n",
      "    val_log_joint  : 988.5096638997396\n",
      "Train Epoch: 1899 [0/54000 (0%)] Loss: -786.616699\n",
      "Train Epoch: 1899 [11264/54000 (21%)] Loss: -769.601318\n",
      "Train Epoch: 1899 [22528/54000 (42%)] Loss: -770.633545\n",
      "Train Epoch: 1899 [33792/54000 (63%)] Loss: -774.569458\n",
      "Train Epoch: 1899 [45056/54000 (83%)] Loss: -803.140808\n",
      "    epoch          : 1899\n",
      "    loss           : -775.4509571003464\n",
      "    ess            : 1.960722899661874\n",
      "    log_marginal   : 775.4889111788767\n",
      "    log_joint      : 983.9295970988724\n",
      "    val_loss       : -779.9482625325521\n",
      "    val_ess        : 1.960854132970174\n",
      "    val_log_marginal: 779.985107421875\n",
      "    val_log_joint  : 988.3380584716797\n",
      "Train Epoch: 1900 [0/54000 (0%)] Loss: -770.713013\n",
      "Train Epoch: 1900 [11264/54000 (21%)] Loss: -758.329529\n",
      "Train Epoch: 1900 [22528/54000 (42%)] Loss: -803.099365\n",
      "Train Epoch: 1900 [33792/54000 (63%)] Loss: -784.603027\n",
      "Train Epoch: 1900 [45056/54000 (83%)] Loss: -780.956909\n",
      "    epoch          : 1900\n",
      "    loss           : -775.398396042158\n",
      "    ess            : 1.9614267315504685\n",
      "    log_marginal   : 775.4355837264151\n",
      "    log_joint      : 983.9646376123968\n",
      "    val_loss       : -779.802978515625\n",
      "    val_ess        : 1.9592383205890656\n",
      "    val_log_marginal: 779.8412170410156\n",
      "    val_log_joint  : 988.6765645345052\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1900.pth ...\n",
      "Train Epoch: 1901 [0/54000 (0%)] Loss: -776.600281\n",
      "Train Epoch: 1901 [11264/54000 (21%)] Loss: -758.001404\n",
      "Train Epoch: 1901 [22528/54000 (42%)] Loss: -760.506958\n",
      "Train Epoch: 1901 [33792/54000 (63%)] Loss: -783.950623\n",
      "Train Epoch: 1901 [45056/54000 (83%)] Loss: -771.275024\n",
      "    epoch          : 1901\n",
      "    loss           : -775.2730505601415\n",
      "    ess            : 1.9610038242250118\n",
      "    log_marginal   : 775.3101132950693\n",
      "    log_joint      : 983.7353768978479\n",
      "    val_loss       : -779.712656656901\n",
      "    val_ess        : 1.958527535200119\n",
      "    val_log_marginal: 779.7512257893881\n",
      "    val_log_joint  : 988.4034016927084\n",
      "Train Epoch: 1902 [0/54000 (0%)] Loss: -778.476074\n",
      "Train Epoch: 1902 [11264/54000 (21%)] Loss: -774.609314\n",
      "Train Epoch: 1902 [22528/54000 (42%)] Loss: -765.084167\n",
      "Train Epoch: 1902 [33792/54000 (63%)] Loss: -779.160217\n",
      "Train Epoch: 1902 [45056/54000 (83%)] Loss: -788.661499\n",
      "    epoch          : 1902\n",
      "    loss           : -775.5272308925413\n",
      "    ess            : 1.9617134996180265\n",
      "    log_marginal   : 775.5640293337265\n",
      "    log_joint      : 984.072027818212\n",
      "    val_loss       : -779.5142161051432\n",
      "    val_ess        : 1.9580859045187633\n",
      "    val_log_marginal: 779.5502421061198\n",
      "    val_log_joint  : 988.2549235026041\n",
      "Train Epoch: 1903 [0/54000 (0%)] Loss: -759.540344\n",
      "Train Epoch: 1903 [11264/54000 (21%)] Loss: -789.234497\n",
      "Train Epoch: 1903 [22528/54000 (42%)] Loss: -788.527100\n",
      "Train Epoch: 1903 [33792/54000 (63%)] Loss: -786.906372\n",
      "Train Epoch: 1903 [45056/54000 (83%)] Loss: -784.954712\n",
      "    epoch          : 1903\n",
      "    loss           : -775.3681686689268\n",
      "    ess            : 1.9599751369008478\n",
      "    log_marginal   : 775.4059523096624\n",
      "    log_joint      : 984.0215834131781\n",
      "    val_loss       : -780.0755462646484\n",
      "    val_ess        : 1.9612740476926167\n",
      "    val_log_marginal: 780.1117146809896\n",
      "    val_log_joint  : 988.7952779134115\n",
      "Train Epoch: 1904 [0/54000 (0%)] Loss: -763.222168\n",
      "Train Epoch: 1904 [11264/54000 (21%)] Loss: -758.341797\n",
      "Train Epoch: 1904 [22528/54000 (42%)] Loss: -762.171021\n",
      "Train Epoch: 1904 [33792/54000 (63%)] Loss: -784.538818\n",
      "Train Epoch: 1904 [45056/54000 (83%)] Loss: -770.703674\n",
      "    epoch          : 1904\n",
      "    loss           : -775.3890190844265\n",
      "    ess            : 1.9612770001843292\n",
      "    log_marginal   : 775.4266075278229\n",
      "    log_joint      : 984.0147088968529\n",
      "    val_loss       : -780.2988688151041\n",
      "    val_ess        : 1.957899163166682\n",
      "    val_log_marginal: 780.3360493977865\n",
      "    val_log_joint  : 988.839599609375\n",
      "Train Epoch: 1905 [0/54000 (0%)] Loss: -775.847351\n",
      "Train Epoch: 1905 [11264/54000 (21%)] Loss: -773.185059\n",
      "Train Epoch: 1905 [22528/54000 (42%)] Loss: -785.676025\n",
      "Train Epoch: 1905 [33792/54000 (63%)] Loss: -779.457336\n",
      "Train Epoch: 1905 [45056/54000 (83%)] Loss: -773.806274\n",
      "    epoch          : 1905\n",
      "    loss           : -775.5151689637382\n",
      "    ess            : 1.9613016540149473\n",
      "    log_marginal   : 775.5523526173718\n",
      "    log_joint      : 984.1061107707474\n",
      "    val_loss       : -780.3539581298828\n",
      "    val_ess        : 1.9572542905807495\n",
      "    val_log_marginal: 780.3971201578776\n",
      "    val_log_joint  : 989.1526438395182\n",
      "Train Epoch: 1906 [0/54000 (0%)] Loss: -782.855347\n",
      "Train Epoch: 1906 [11264/54000 (21%)] Loss: -780.990234\n",
      "Train Epoch: 1906 [22528/54000 (42%)] Loss: -787.559387\n",
      "Train Epoch: 1906 [33792/54000 (63%)] Loss: -783.784180\n",
      "Train Epoch: 1906 [45056/54000 (83%)] Loss: -760.036499\n",
      "    epoch          : 1906\n",
      "    loss           : -775.439335085311\n",
      "    ess            : 1.9605789364508863\n",
      "    log_marginal   : 775.4778465414947\n",
      "    log_joint      : 984.0212131716171\n",
      "    val_loss       : -780.0769856770834\n",
      "    val_ess        : 1.959651509920756\n",
      "    val_log_marginal: 780.1130828857422\n",
      "    val_log_joint  : 988.7218322753906\n",
      "Train Epoch: 1907 [0/54000 (0%)] Loss: -767.754883\n",
      "Train Epoch: 1907 [11264/54000 (21%)] Loss: -781.124023\n",
      "Train Epoch: 1907 [22528/54000 (42%)] Loss: -795.009460\n",
      "Train Epoch: 1907 [33792/54000 (63%)] Loss: -788.682373\n",
      "Train Epoch: 1907 [45056/54000 (83%)] Loss: -781.646301\n",
      "    epoch          : 1907\n",
      "    loss           : -775.4745794332252\n",
      "    ess            : 1.960592510565272\n",
      "    log_marginal   : 775.5124206542969\n",
      "    log_joint      : 984.1096905402418\n",
      "    val_loss       : -779.5065053304037\n",
      "    val_ess        : 1.9614443083604176\n",
      "    val_log_marginal: 779.542734781901\n",
      "    val_log_joint  : 988.1962076822916\n",
      "Train Epoch: 1908 [0/54000 (0%)] Loss: -771.703003\n",
      "Train Epoch: 1908 [11264/54000 (21%)] Loss: -791.912231\n",
      "Train Epoch: 1908 [22528/54000 (42%)] Loss: -750.643066\n",
      "Train Epoch: 1908 [33792/54000 (63%)] Loss: -766.711548\n",
      "Train Epoch: 1908 [45056/54000 (83%)] Loss: -787.199280\n",
      "    epoch          : 1908\n",
      "    loss           : -775.2090281360554\n",
      "    ess            : 1.9607061361366849\n",
      "    log_marginal   : 775.2458760963297\n",
      "    log_joint      : 983.8358004588001\n",
      "    val_loss       : -779.8525899251302\n",
      "    val_ess        : 1.9596564968427022\n",
      "    val_log_marginal: 779.8956400553385\n",
      "    val_log_joint  : 988.4230804443359\n",
      "Train Epoch: 1909 [0/54000 (0%)] Loss: -770.257996\n",
      "Train Epoch: 1909 [11264/54000 (21%)] Loss: -797.356445\n",
      "Train Epoch: 1909 [22528/54000 (42%)] Loss: -780.157104\n",
      "Train Epoch: 1909 [33792/54000 (63%)] Loss: -784.820068\n",
      "Train Epoch: 1909 [45056/54000 (83%)] Loss: -765.527466\n",
      "    epoch          : 1909\n",
      "    loss           : -775.2469390293337\n",
      "    ess            : 1.961410273920815\n",
      "    log_marginal   : 775.2823935454746\n",
      "    log_joint      : 983.733356979658\n",
      "    val_loss       : -779.6804809570312\n",
      "    val_ess        : 1.961709479490916\n",
      "    val_log_marginal: 779.7157948811849\n",
      "    val_log_joint  : 988.4035949707031\n",
      "Train Epoch: 1910 [0/54000 (0%)] Loss: -796.245422\n",
      "Train Epoch: 1910 [11264/54000 (21%)] Loss: -756.031494\n",
      "Train Epoch: 1910 [22528/54000 (42%)] Loss: -791.837280\n",
      "Train Epoch: 1910 [33792/54000 (63%)] Loss: -788.932678\n",
      "Train Epoch: 1910 [45056/54000 (83%)] Loss: -761.621948\n",
      "    epoch          : 1910\n",
      "    loss           : -775.4179013810068\n",
      "    ess            : 1.9611585837490153\n",
      "    log_marginal   : 775.4552203484301\n",
      "    log_joint      : 984.0241186753759\n",
      "    val_loss       : -779.3847605387369\n",
      "    val_ess        : 1.9631228546301525\n",
      "    val_log_marginal: 779.4238332112631\n",
      "    val_log_joint  : 987.8217264811198\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1910.pth ...\n",
      "Train Epoch: 1911 [0/54000 (0%)] Loss: -781.378052\n",
      "Train Epoch: 1911 [11264/54000 (21%)] Loss: -760.309448\n",
      "Train Epoch: 1911 [22528/54000 (42%)] Loss: -779.714844\n",
      "Train Epoch: 1911 [33792/54000 (63%)] Loss: -780.919312\n",
      "Train Epoch: 1911 [45056/54000 (83%)] Loss: -771.945801\n",
      "    epoch          : 1911\n",
      "    loss           : -775.700487244804\n",
      "    ess            : 1.9615581249291043\n",
      "    log_marginal   : 775.7369494168264\n",
      "    log_joint      : 984.2008419396742\n",
      "    val_loss       : -779.9834645589193\n",
      "    val_ess        : 1.9613870282967885\n",
      "    val_log_marginal: 780.0209910074869\n",
      "    val_log_joint  : 988.588857014974\n",
      "Train Epoch: 1912 [0/54000 (0%)] Loss: -759.494629\n",
      "Train Epoch: 1912 [11264/54000 (21%)] Loss: -790.495972\n",
      "Train Epoch: 1912 [22528/54000 (42%)] Loss: -779.143372\n",
      "Train Epoch: 1912 [33792/54000 (63%)] Loss: -787.492554\n",
      "Train Epoch: 1912 [45056/54000 (83%)] Loss: -767.776978\n",
      "    epoch          : 1912\n",
      "    loss           : -775.4131446694428\n",
      "    ess            : 1.9616614805077606\n",
      "    log_marginal   : 775.4500663325472\n",
      "    log_joint      : 984.0233574633328\n",
      "    val_loss       : -779.7232462565104\n",
      "    val_ess        : 1.9597536027431488\n",
      "    val_log_marginal: 779.7634226481119\n",
      "    val_log_joint  : 988.426025390625\n",
      "Train Epoch: 1913 [0/54000 (0%)] Loss: -778.526855\n",
      "Train Epoch: 1913 [11264/54000 (21%)] Loss: -788.528809\n",
      "Train Epoch: 1913 [22528/54000 (42%)] Loss: -757.869385\n",
      "Train Epoch: 1913 [33792/54000 (63%)] Loss: -774.928589\n",
      "Train Epoch: 1913 [45056/54000 (83%)] Loss: -771.640503\n",
      "    epoch          : 1913\n",
      "    loss           : -775.4993389777418\n",
      "    ess            : 1.9611757959959641\n",
      "    log_marginal   : 775.5359393425707\n",
      "    log_joint      : 984.0092514325987\n",
      "    val_loss       : -780.3638966878256\n",
      "    val_ess        : 1.9629743695259094\n",
      "    val_log_marginal: 780.4028828938802\n",
      "    val_log_joint  : 988.4339040120443\n",
      "Train Epoch: 1914 [0/54000 (0%)] Loss: -794.174744\n",
      "Train Epoch: 1914 [11264/54000 (21%)] Loss: -748.100098\n",
      "Train Epoch: 1914 [22528/54000 (42%)] Loss: -781.785156\n",
      "Train Epoch: 1914 [33792/54000 (63%)] Loss: -778.972229\n",
      "Train Epoch: 1914 [45056/54000 (83%)] Loss: -750.994019\n",
      "    epoch          : 1914\n",
      "    loss           : -775.282939982864\n",
      "    ess            : 1.9593611100934587\n",
      "    log_marginal   : 775.3225454654333\n",
      "    log_joint      : 983.9444522497789\n",
      "    val_loss       : -779.8629506429037\n",
      "    val_ess        : 1.9598557750384014\n",
      "    val_log_marginal: 779.8998057047526\n",
      "    val_log_joint  : 988.5574798583984\n",
      "Train Epoch: 1915 [0/54000 (0%)] Loss: -766.592468\n",
      "Train Epoch: 1915 [11264/54000 (21%)] Loss: -760.238098\n",
      "Train Epoch: 1915 [22528/54000 (42%)] Loss: -760.929749\n",
      "Train Epoch: 1915 [33792/54000 (63%)] Loss: -787.728149\n",
      "Train Epoch: 1915 [45056/54000 (83%)] Loss: -766.572571\n",
      "    epoch          : 1915\n",
      "    loss           : -775.5823099388266\n",
      "    ess            : 1.9595806643647968\n",
      "    log_marginal   : 775.6217553480616\n",
      "    log_joint      : 984.2867748332474\n",
      "    val_loss       : -779.7770487467448\n",
      "    val_ess        : 1.9608607490857441\n",
      "    val_log_marginal: 779.8153788248698\n",
      "    val_log_joint  : 988.1900329589844\n",
      "Train Epoch: 1916 [0/54000 (0%)] Loss: -796.202393\n",
      "Train Epoch: 1916 [11264/54000 (21%)] Loss: -742.493652\n",
      "Train Epoch: 1916 [22528/54000 (42%)] Loss: -760.252563\n",
      "Train Epoch: 1916 [33792/54000 (63%)] Loss: -782.388306\n",
      "Train Epoch: 1916 [45056/54000 (83%)] Loss: -779.206665\n",
      "    epoch          : 1916\n",
      "    loss           : -775.520549270342\n",
      "    ess            : 1.9608824196851478\n",
      "    log_marginal   : 775.558459587817\n",
      "    log_joint      : 984.165556133918\n",
      "    val_loss       : -779.4742075602213\n",
      "    val_ess        : 1.9605236848195393\n",
      "    val_log_marginal: 779.5136515299479\n",
      "    val_log_joint  : 988.2617696126302\n",
      "Train Epoch: 1917 [0/54000 (0%)] Loss: -780.132629\n",
      "Train Epoch: 1917 [11264/54000 (21%)] Loss: -771.059753\n",
      "Train Epoch: 1917 [22528/54000 (42%)] Loss: -752.029053\n",
      "Train Epoch: 1917 [33792/54000 (63%)] Loss: -746.383118\n",
      "Train Epoch: 1917 [45056/54000 (83%)] Loss: -796.432495\n",
      "    epoch          : 1917\n",
      "    loss           : -775.8261551767025\n",
      "    ess            : 1.9607363601900496\n",
      "    log_marginal   : 775.8632582178656\n",
      "    log_joint      : 984.4374902113428\n",
      "    val_loss       : -779.9785410563151\n",
      "    val_ess        : 1.9585062563419342\n",
      "    val_log_marginal: 780.0174814860026\n",
      "    val_log_joint  : 988.5706278483073\n",
      "Train Epoch: 1918 [0/54000 (0%)] Loss: -773.639343\n",
      "Train Epoch: 1918 [11264/54000 (21%)] Loss: -784.258057\n",
      "Train Epoch: 1918 [22528/54000 (42%)] Loss: -788.407227\n",
      "Train Epoch: 1918 [33792/54000 (63%)] Loss: -793.984741\n",
      "Train Epoch: 1918 [45056/54000 (83%)] Loss: -752.904053\n",
      "    epoch          : 1918\n",
      "    loss           : -775.7729618864239\n",
      "    ess            : 1.9616041138487041\n",
      "    log_marginal   : 775.8092622577019\n",
      "    log_joint      : 984.3624590028007\n",
      "    val_loss       : -780.6920928955078\n",
      "    val_ess        : 1.9612808227539062\n",
      "    val_log_marginal: 780.7262115478516\n",
      "    val_log_joint  : 988.9181772867838\n",
      "Train Epoch: 1919 [0/54000 (0%)] Loss: -765.615967\n",
      "Train Epoch: 1919 [11264/54000 (21%)] Loss: -785.107056\n",
      "Train Epoch: 1919 [22528/54000 (42%)] Loss: -768.509583\n",
      "Train Epoch: 1919 [33792/54000 (63%)] Loss: -780.528564\n",
      "Train Epoch: 1919 [45056/54000 (83%)] Loss: -795.525818\n",
      "    epoch          : 1919\n",
      "    loss           : -775.8484145830263\n",
      "    ess            : 1.96076326775101\n",
      "    log_marginal   : 775.8854479519827\n",
      "    log_joint      : 984.466391509434\n",
      "    val_loss       : -779.6959381103516\n",
      "    val_ess        : 1.9595668613910675\n",
      "    val_log_marginal: 779.7343393961588\n",
      "    val_log_joint  : 988.3950856526693\n",
      "Train Epoch: 1920 [0/54000 (0%)] Loss: -779.773926\n",
      "Train Epoch: 1920 [11264/54000 (21%)] Loss: -762.586182\n",
      "Train Epoch: 1920 [22528/54000 (42%)] Loss: -773.381226\n",
      "Train Epoch: 1920 [33792/54000 (63%)] Loss: -757.419556\n",
      "Train Epoch: 1920 [45056/54000 (83%)] Loss: -775.200012\n",
      "    epoch          : 1920\n",
      "    loss           : -775.4779501860996\n",
      "    ess            : 1.9610394992918339\n",
      "    log_marginal   : 775.5149973743366\n",
      "    log_joint      : 984.0868328742262\n",
      "    val_loss       : -780.3324991861979\n",
      "    val_ess        : 1.9622474412123363\n",
      "    val_log_marginal: 780.3687438964844\n",
      "    val_log_joint  : 988.8670654296875\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1920.pth ...\n",
      "Train Epoch: 1921 [0/54000 (0%)] Loss: -764.204529\n",
      "Train Epoch: 1921 [11264/54000 (21%)] Loss: -754.799988\n",
      "Train Epoch: 1921 [22528/54000 (42%)] Loss: -772.759277\n",
      "Train Epoch: 1921 [33792/54000 (63%)] Loss: -777.382141\n",
      "Train Epoch: 1921 [45056/54000 (83%)] Loss: -785.113037\n",
      "    epoch          : 1921\n",
      "    loss           : -775.7256256679319\n",
      "    ess            : 1.9605046297019382\n",
      "    log_marginal   : 775.7633143011129\n",
      "    log_joint      : 984.2581021290905\n",
      "    val_loss       : -779.1134847005209\n",
      "    val_ess        : 1.9619765480359395\n",
      "    val_log_marginal: 779.1473897298177\n",
      "    val_log_joint  : 987.9508666992188\n",
      "Train Epoch: 1922 [0/54000 (0%)] Loss: -798.887390\n",
      "Train Epoch: 1922 [11264/54000 (21%)] Loss: -769.873047\n",
      "Train Epoch: 1922 [22528/54000 (42%)] Loss: -766.986694\n",
      "Train Epoch: 1922 [33792/54000 (63%)] Loss: -783.479858\n",
      "Train Epoch: 1922 [45056/54000 (83%)] Loss: -787.116211\n",
      "    epoch          : 1922\n",
      "    loss           : -775.6338771604142\n",
      "    ess            : 1.9609667175220993\n",
      "    log_marginal   : 775.6708684957252\n",
      "    log_joint      : 984.2194513284935\n",
      "    val_loss       : -780.0320841471354\n",
      "    val_ess        : 1.9642448425292969\n",
      "    val_log_marginal: 780.0643768310547\n",
      "    val_log_joint  : 988.7282460530599\n",
      "Train Epoch: 1923 [0/54000 (0%)] Loss: -776.618103\n",
      "Train Epoch: 1923 [11264/54000 (21%)] Loss: -803.382812\n",
      "Train Epoch: 1923 [22528/54000 (42%)] Loss: -768.405273\n",
      "Train Epoch: 1923 [33792/54000 (63%)] Loss: -793.457214\n",
      "Train Epoch: 1923 [45056/54000 (83%)] Loss: -753.733704\n",
      "    epoch          : 1923\n",
      "    loss           : -775.5662145074808\n",
      "    ess            : 1.9608849421986994\n",
      "    log_marginal   : 775.6036618790537\n",
      "    log_joint      : 984.2315368652344\n",
      "    val_loss       : -779.5738830566406\n",
      "    val_ess        : 1.9588371614615123\n",
      "    val_log_marginal: 779.6145477294922\n",
      "    val_log_joint  : 988.1454772949219\n",
      "Train Epoch: 1924 [0/54000 (0%)] Loss: -776.652283\n",
      "Train Epoch: 1924 [11264/54000 (21%)] Loss: -760.237549\n",
      "Train Epoch: 1924 [22528/54000 (42%)] Loss: -793.744629\n",
      "Train Epoch: 1924 [33792/54000 (63%)] Loss: -761.758545\n",
      "Train Epoch: 1924 [45056/54000 (83%)] Loss: -775.205139\n",
      "    epoch          : 1924\n",
      "    loss           : -775.4340238751106\n",
      "    ess            : 1.9603525883746598\n",
      "    log_marginal   : 775.4719508908829\n",
      "    log_joint      : 984.0810552633034\n",
      "    val_loss       : -779.8839213053385\n",
      "    val_ess        : 1.960221807161967\n",
      "    val_log_marginal: 779.9220479329427\n",
      "    val_log_joint  : 988.376953125\n",
      "Train Epoch: 1925 [0/54000 (0%)] Loss: -773.274658\n",
      "Train Epoch: 1925 [11264/54000 (21%)] Loss: -774.743896\n",
      "Train Epoch: 1925 [22528/54000 (42%)] Loss: -787.119690\n",
      "Train Epoch: 1925 [33792/54000 (63%)] Loss: -782.749939\n",
      "Train Epoch: 1925 [45056/54000 (83%)] Loss: -777.671265\n",
      "    epoch          : 1925\n",
      "    loss           : -775.7569654932562\n",
      "    ess            : 1.960752599644211\n",
      "    log_marginal   : 775.7953099664652\n",
      "    log_joint      : 984.2581355256855\n",
      "    val_loss       : -779.7658335367838\n",
      "    val_ess        : 1.9638642569382985\n",
      "    val_log_marginal: 779.8025919596354\n",
      "    val_log_joint  : 988.2010040283203\n",
      "Train Epoch: 1926 [0/54000 (0%)] Loss: -796.714233\n",
      "Train Epoch: 1926 [11264/54000 (21%)] Loss: -780.485352\n",
      "Train Epoch: 1926 [22528/54000 (42%)] Loss: -746.320801\n",
      "Train Epoch: 1926 [33792/54000 (63%)] Loss: -782.030029\n",
      "Train Epoch: 1926 [45056/54000 (83%)] Loss: -764.948608\n",
      "    epoch          : 1926\n",
      "    loss           : -775.7901663150427\n",
      "    ess            : 1.961433394899908\n",
      "    log_marginal   : 775.8278733739313\n",
      "    log_joint      : 984.3664308943838\n",
      "    val_loss       : -778.7411702473959\n",
      "    val_ess        : 1.9588905572891235\n",
      "    val_log_marginal: 778.7806599934896\n",
      "    val_log_joint  : 987.63232421875\n",
      "Train Epoch: 1927 [0/54000 (0%)] Loss: -777.395630\n",
      "Train Epoch: 1927 [11264/54000 (21%)] Loss: -784.773315\n",
      "Train Epoch: 1927 [22528/54000 (42%)] Loss: -779.613159\n",
      "Train Epoch: 1927 [33792/54000 (63%)] Loss: -779.427734\n",
      "Train Epoch: 1927 [45056/54000 (83%)] Loss: -774.432190\n",
      "    epoch          : 1927\n",
      "    loss           : -775.799910059515\n",
      "    ess            : 1.9607371980289243\n",
      "    log_marginal   : 775.8387635428951\n",
      "    log_joint      : 984.3371743256191\n",
      "    val_loss       : -779.8759714762369\n",
      "    val_ess        : 1.9632792274157207\n",
      "    val_log_marginal: 779.9076436360677\n",
      "    val_log_joint  : 988.509999593099\n",
      "Train Epoch: 1928 [0/54000 (0%)] Loss: -771.654480\n",
      "Train Epoch: 1928 [11264/54000 (21%)] Loss: -769.711792\n",
      "Train Epoch: 1928 [22528/54000 (42%)] Loss: -770.775879\n",
      "Train Epoch: 1928 [33792/54000 (63%)] Loss: -764.480713\n",
      "Train Epoch: 1928 [45056/54000 (83%)] Loss: -770.014771\n",
      "    epoch          : 1928\n",
      "    loss           : -775.3704960661114\n",
      "    ess            : 1.959190751021763\n",
      "    log_marginal   : 775.4092292065891\n",
      "    log_joint      : 983.9809731537441\n",
      "    val_loss       : -780.0885009765625\n",
      "    val_ess        : 1.9615215957164764\n",
      "    val_log_marginal: 780.1226043701172\n",
      "    val_log_joint  : 988.8634796142578\n",
      "Train Epoch: 1929 [0/54000 (0%)] Loss: -779.064087\n",
      "Train Epoch: 1929 [11264/54000 (21%)] Loss: -753.245728\n",
      "Train Epoch: 1929 [22528/54000 (42%)] Loss: -781.122925\n",
      "Train Epoch: 1929 [33792/54000 (63%)] Loss: -775.044739\n",
      "Train Epoch: 1929 [45056/54000 (83%)] Loss: -752.516235\n",
      "    epoch          : 1929\n",
      "    loss           : -775.723738184515\n",
      "    ess            : 1.9616437453144002\n",
      "    log_marginal   : 775.7607318230395\n",
      "    log_joint      : 984.3921883061247\n",
      "    val_loss       : -779.3426462809244\n",
      "    val_ess        : 1.9559771815935771\n",
      "    val_log_marginal: 779.3901926676432\n",
      "    val_log_joint  : 987.7167358398438\n",
      "Train Epoch: 1930 [0/54000 (0%)] Loss: -769.010986\n",
      "Train Epoch: 1930 [11264/54000 (21%)] Loss: -790.109802\n",
      "Train Epoch: 1930 [22528/54000 (42%)] Loss: -790.004761\n",
      "Train Epoch: 1930 [33792/54000 (63%)] Loss: -790.688232\n",
      "Train Epoch: 1930 [45056/54000 (83%)] Loss: -781.148926\n",
      "    epoch          : 1930\n",
      "    loss           : -775.8490462393131\n",
      "    ess            : 1.9614710965246525\n",
      "    log_marginal   : 775.886182677071\n",
      "    log_joint      : 984.409610388414\n",
      "    val_loss       : -779.9724375406901\n",
      "    val_ess        : 1.9618927041689556\n",
      "    val_log_marginal: 780.0101420084635\n",
      "    val_log_joint  : 988.5298207600912\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1930.pth ...\n",
      "Train Epoch: 1931 [0/54000 (0%)] Loss: -775.979858\n",
      "Train Epoch: 1931 [11264/54000 (21%)] Loss: -777.211304\n",
      "Train Epoch: 1931 [22528/54000 (42%)] Loss: -794.917603\n",
      "Train Epoch: 1931 [33792/54000 (63%)] Loss: -767.153931\n",
      "Train Epoch: 1931 [45056/54000 (83%)] Loss: -763.913940\n",
      "    epoch          : 1931\n",
      "    loss           : -775.5896226415094\n",
      "    ess            : 1.9615355358933502\n",
      "    log_marginal   : 775.625368514151\n",
      "    log_joint      : 984.238120025059\n",
      "    val_loss       : -780.7464090983073\n",
      "    val_ess        : 1.9563598334789276\n",
      "    val_log_marginal: 780.7848765055338\n",
      "    val_log_joint  : 989.3644002278646\n",
      "Train Epoch: 1932 [0/54000 (0%)] Loss: -781.163635\n",
      "Train Epoch: 1932 [11264/54000 (21%)] Loss: -758.264893\n",
      "Train Epoch: 1932 [22528/54000 (42%)] Loss: -771.143005\n",
      "Train Epoch: 1932 [33792/54000 (63%)] Loss: -774.345459\n",
      "Train Epoch: 1932 [45056/54000 (83%)] Loss: -783.319763\n",
      "    epoch          : 1932\n",
      "    loss           : -775.8658251492483\n",
      "    ess            : 1.9619385802520897\n",
      "    log_marginal   : 775.9018963507887\n",
      "    log_joint      : 984.4336772414873\n",
      "    val_loss       : -780.3253936767578\n",
      "    val_ess        : 1.9624884327252705\n",
      "    val_log_marginal: 780.3593393961588\n",
      "    val_log_joint  : 988.9098968505859\n",
      "Train Epoch: 1933 [0/54000 (0%)] Loss: -778.279114\n",
      "Train Epoch: 1933 [11264/54000 (21%)] Loss: -793.702942\n",
      "Train Epoch: 1933 [22528/54000 (42%)] Loss: -763.183960\n",
      "Train Epoch: 1933 [33792/54000 (63%)] Loss: -771.589600\n",
      "Train Epoch: 1933 [45056/54000 (83%)] Loss: -783.689941\n",
      "    epoch          : 1933\n",
      "    loss           : -775.8142562002506\n",
      "    ess            : 1.9615817643561453\n",
      "    log_marginal   : 775.8500406517172\n",
      "    log_joint      : 984.4097963728995\n",
      "    val_loss       : -779.6650899251302\n",
      "    val_ess        : 1.9612029989560444\n",
      "    val_log_marginal: 779.7029317220052\n",
      "    val_log_joint  : 988.3693339029948\n",
      "Train Epoch: 1934 [0/54000 (0%)] Loss: -801.716064\n",
      "Train Epoch: 1934 [11264/54000 (21%)] Loss: -782.557495\n",
      "Train Epoch: 1934 [22528/54000 (42%)] Loss: -763.933838\n",
      "Train Epoch: 1934 [33792/54000 (63%)] Loss: -799.230103\n",
      "Train Epoch: 1934 [45056/54000 (83%)] Loss: -773.443298\n",
      "    epoch          : 1934\n",
      "    loss           : -775.7814975954452\n",
      "    ess            : 1.9613394905936044\n",
      "    log_marginal   : 775.8183271300118\n",
      "    log_joint      : 984.3325869002432\n",
      "    val_loss       : -779.4257609049479\n",
      "    val_ess        : 1.9616071085135143\n",
      "    val_log_marginal: 779.4666798909506\n",
      "    val_log_joint  : 988.0542500813802\n",
      "Train Epoch: 1935 [0/54000 (0%)] Loss: -787.216187\n",
      "Train Epoch: 1935 [11264/54000 (21%)] Loss: -767.894165\n",
      "Train Epoch: 1935 [22528/54000 (42%)] Loss: -774.218750\n",
      "Train Epoch: 1935 [33792/54000 (63%)] Loss: -784.570557\n",
      "Train Epoch: 1935 [45056/54000 (83%)] Loss: -787.270569\n",
      "    epoch          : 1935\n",
      "    loss           : -775.6923920253538\n",
      "    ess            : 1.960893453292127\n",
      "    log_marginal   : 775.7295347969487\n",
      "    log_joint      : 984.2007878141583\n",
      "    val_loss       : -780.228769938151\n",
      "    val_ess        : 1.960174520810445\n",
      "    val_log_marginal: 780.2687835693359\n",
      "    val_log_joint  : 988.9024912516276\n",
      "Train Epoch: 1936 [0/54000 (0%)] Loss: -775.979126\n",
      "Train Epoch: 1936 [11264/54000 (21%)] Loss: -793.534424\n",
      "Train Epoch: 1936 [22528/54000 (42%)] Loss: -756.093384\n",
      "Train Epoch: 1936 [33792/54000 (63%)] Loss: -765.265991\n",
      "Train Epoch: 1936 [45056/54000 (83%)] Loss: -791.667114\n",
      "    epoch          : 1936\n",
      "    loss           : -775.915225622789\n",
      "    ess            : 1.9614484917442754\n",
      "    log_marginal   : 775.9522405660377\n",
      "    log_joint      : 984.4669615547612\n",
      "    val_loss       : -779.5341847737631\n",
      "    val_ess        : 1.9611414869626362\n",
      "    val_log_marginal: 779.5704243977865\n",
      "    val_log_joint  : 988.1422017415365\n",
      "Train Epoch: 1937 [0/54000 (0%)] Loss: -775.306030\n",
      "Train Epoch: 1937 [11264/54000 (21%)] Loss: -772.713135\n",
      "Train Epoch: 1937 [22528/54000 (42%)] Loss: -773.191040\n",
      "Train Epoch: 1937 [33792/54000 (63%)] Loss: -762.832153\n",
      "Train Epoch: 1937 [45056/54000 (83%)] Loss: -755.801147\n",
      "    epoch          : 1937\n",
      "    loss           : -775.761865579857\n",
      "    ess            : 1.9602245868376966\n",
      "    log_marginal   : 775.8005808704304\n",
      "    log_joint      : 984.4529154075766\n",
      "    val_loss       : -779.6835174560547\n",
      "    val_ess        : 1.9613066812356312\n",
      "    val_log_marginal: 779.7223866780599\n",
      "    val_log_joint  : 988.447021484375\n",
      "Train Epoch: 1938 [0/54000 (0%)] Loss: -801.825439\n",
      "Train Epoch: 1938 [11264/54000 (21%)] Loss: -761.528931\n",
      "Train Epoch: 1938 [22528/54000 (42%)] Loss: -791.056519\n",
      "Train Epoch: 1938 [33792/54000 (63%)] Loss: -781.281982\n",
      "Train Epoch: 1938 [45056/54000 (83%)] Loss: -753.782715\n",
      "    epoch          : 1938\n",
      "    loss           : -775.8655274589107\n",
      "    ess            : 1.9616669360196815\n",
      "    log_marginal   : 775.9018134351047\n",
      "    log_joint      : 984.4331705345297\n",
      "    val_loss       : -779.9471130371094\n",
      "    val_ess        : 1.9632982512315114\n",
      "    val_log_marginal: 779.9796803792318\n",
      "    val_log_joint  : 988.6590270996094\n",
      "Train Epoch: 1939 [0/54000 (0%)] Loss: -783.984497\n",
      "Train Epoch: 1939 [11264/54000 (21%)] Loss: -789.981934\n",
      "Train Epoch: 1939 [22528/54000 (42%)] Loss: -776.920654\n",
      "Train Epoch: 1939 [33792/54000 (63%)] Loss: -767.151672\n",
      "Train Epoch: 1939 [45056/54000 (83%)] Loss: -745.718262\n",
      "    epoch          : 1939\n",
      "    loss           : -775.4470727308741\n",
      "    ess            : 1.9601133162120603\n",
      "    log_marginal   : 775.4856377367703\n",
      "    log_joint      : 984.1440850023953\n",
      "    val_loss       : -780.2055867513021\n",
      "    val_ess        : 1.9631381233533223\n",
      "    val_log_marginal: 780.2435251871744\n",
      "    val_log_joint  : 988.7576649983724\n",
      "Train Epoch: 1940 [0/54000 (0%)] Loss: -786.483032\n",
      "Train Epoch: 1940 [11264/54000 (21%)] Loss: -774.920044\n",
      "Train Epoch: 1940 [22528/54000 (42%)] Loss: -773.231567\n",
      "Train Epoch: 1940 [33792/54000 (63%)] Loss: -760.514038\n",
      "Train Epoch: 1940 [45056/54000 (83%)] Loss: -750.568359\n",
      "    epoch          : 1940\n",
      "    loss           : -775.7183498166642\n",
      "    ess            : 1.961532322865612\n",
      "    log_marginal   : 775.7547100714918\n",
      "    log_joint      : 984.3445975825472\n",
      "    val_loss       : -779.7226104736328\n",
      "    val_ess        : 1.9586121837298076\n",
      "    val_log_marginal: 779.7622629801432\n",
      "    val_log_joint  : 988.2990112304688\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1940.pth ...\n",
      "Train Epoch: 1941 [0/54000 (0%)] Loss: -767.063599\n",
      "Train Epoch: 1941 [11264/54000 (21%)] Loss: -777.820435\n",
      "Train Epoch: 1941 [22528/54000 (42%)] Loss: -776.687134\n",
      "Train Epoch: 1941 [33792/54000 (63%)] Loss: -770.558716\n",
      "Train Epoch: 1941 [45056/54000 (83%)] Loss: -792.165588\n",
      "    epoch          : 1941\n",
      "    loss           : -775.8986188780586\n",
      "    ess            : 1.9611915990991413\n",
      "    log_marginal   : 775.9346808667453\n",
      "    log_joint      : 984.5066873802328\n",
      "    val_loss       : -779.6539510091146\n",
      "    val_ess        : 1.9621006846427917\n",
      "    val_log_marginal: 779.6896464029948\n",
      "    val_log_joint  : 988.3783060709635\n",
      "Train Epoch: 1942 [0/54000 (0%)] Loss: -762.422485\n",
      "Train Epoch: 1942 [11264/54000 (21%)] Loss: -757.619385\n",
      "Train Epoch: 1942 [22528/54000 (42%)] Loss: -774.665161\n",
      "Train Epoch: 1942 [33792/54000 (63%)] Loss: -782.298462\n",
      "Train Epoch: 1942 [45056/54000 (83%)] Loss: -776.106018\n",
      "    epoch          : 1942\n",
      "    loss           : -775.707819524801\n",
      "    ess            : 1.962210643966243\n",
      "    log_marginal   : 775.7428243385172\n",
      "    log_joint      : 984.2668059726931\n",
      "    val_loss       : -780.0033162434896\n",
      "    val_ess        : 1.957910309235255\n",
      "    val_log_marginal: 780.0468037923177\n",
      "    val_log_joint  : 988.7388814290365\n",
      "Train Epoch: 1943 [0/54000 (0%)] Loss: -768.901367\n",
      "Train Epoch: 1943 [11264/54000 (21%)] Loss: -792.903687\n",
      "Train Epoch: 1943 [22528/54000 (42%)] Loss: -765.464111\n",
      "Train Epoch: 1943 [33792/54000 (63%)] Loss: -771.025513\n",
      "Train Epoch: 1943 [45056/54000 (83%)] Loss: -796.720215\n",
      "    epoch          : 1943\n",
      "    loss           : -775.9741988272037\n",
      "    ess            : 1.9609766636254653\n",
      "    log_marginal   : 776.0108872899469\n",
      "    log_joint      : 984.4934698140846\n",
      "    val_loss       : -780.4964090983073\n",
      "    val_ess        : 1.9570504824320476\n",
      "    val_log_marginal: 780.5386301676432\n",
      "    val_log_joint  : 988.8666178385416\n",
      "Train Epoch: 1944 [0/54000 (0%)] Loss: -758.064331\n",
      "Train Epoch: 1944 [11264/54000 (21%)] Loss: -779.644653\n",
      "Train Epoch: 1944 [22528/54000 (42%)] Loss: -750.796753\n",
      "Train Epoch: 1944 [33792/54000 (63%)] Loss: -786.770508\n",
      "Train Epoch: 1944 [45056/54000 (83%)] Loss: -774.040039\n",
      "    epoch          : 1944\n",
      "    loss           : -775.7682909695608\n",
      "    ess            : 1.9607697061772615\n",
      "    log_marginal   : 775.8061903467718\n",
      "    log_joint      : 984.3963029969414\n",
      "    val_loss       : -780.3762919108073\n",
      "    val_ess        : 1.9594179689884186\n",
      "    val_log_marginal: 780.416514078776\n",
      "    val_log_joint  : 988.9151509602865\n",
      "Train Epoch: 1945 [0/54000 (0%)] Loss: -787.713013\n",
      "Train Epoch: 1945 [11264/54000 (21%)] Loss: -768.438843\n",
      "Train Epoch: 1945 [22528/54000 (42%)] Loss: -764.264954\n",
      "Train Epoch: 1945 [33792/54000 (63%)] Loss: -773.613831\n",
      "Train Epoch: 1945 [45056/54000 (83%)] Loss: -752.187134\n",
      "    epoch          : 1945\n",
      "    loss           : -775.9275898483564\n",
      "    ess            : 1.9607904497182593\n",
      "    log_marginal   : 775.9640215028007\n",
      "    log_joint      : 984.5720186053582\n",
      "    val_loss       : -780.5974070231119\n",
      "    val_ess        : 1.9605724811553955\n",
      "    val_log_marginal: 780.6328837076823\n",
      "    val_log_joint  : 988.9746551513672\n",
      "Train Epoch: 1946 [0/54000 (0%)] Loss: -770.056396\n",
      "Train Epoch: 1946 [11264/54000 (21%)] Loss: -782.153198\n",
      "Train Epoch: 1946 [22528/54000 (42%)] Loss: -779.473022\n",
      "Train Epoch: 1946 [33792/54000 (63%)] Loss: -788.812744\n",
      "Train Epoch: 1946 [45056/54000 (83%)] Loss: -784.873413\n",
      "    epoch          : 1946\n",
      "    loss           : -775.8417318092203\n",
      "    ess            : 1.9617302575201359\n",
      "    log_marginal   : 775.8778767135908\n",
      "    log_joint      : 984.4368574034493\n",
      "    val_loss       : -780.2518971761068\n",
      "    val_ess        : 1.9650396605332692\n",
      "    val_log_marginal: 780.2859954833984\n",
      "    val_log_joint  : 989.0504302978516\n",
      "Train Epoch: 1947 [0/54000 (0%)] Loss: -806.799988\n",
      "Train Epoch: 1947 [11264/54000 (21%)] Loss: -766.385925\n",
      "Train Epoch: 1947 [22528/54000 (42%)] Loss: -766.945496\n",
      "Train Epoch: 1947 [33792/54000 (63%)] Loss: -757.838745\n",
      "Train Epoch: 1947 [45056/54000 (83%)] Loss: -782.190674\n",
      "    epoch          : 1947\n",
      "    loss           : -775.6117006697745\n",
      "    ess            : 1.9611318032696563\n",
      "    log_marginal   : 775.6494019706295\n",
      "    log_joint      : 984.1868931032577\n",
      "    val_loss       : -779.2677001953125\n",
      "    val_ess        : 1.9615396161874135\n",
      "    val_log_marginal: 779.3076578776041\n",
      "    val_log_joint  : 988.0292460123698\n",
      "Train Epoch: 1948 [0/54000 (0%)] Loss: -766.283325\n",
      "Train Epoch: 1948 [11264/54000 (21%)] Loss: -766.209839\n",
      "Train Epoch: 1948 [22528/54000 (42%)] Loss: -789.338257\n",
      "Train Epoch: 1948 [33792/54000 (63%)] Loss: -790.968323\n",
      "Train Epoch: 1948 [45056/54000 (83%)] Loss: -763.112915\n",
      "    epoch          : 1948\n",
      "    loss           : -775.7514993919516\n",
      "    ess            : 1.9617688442176242\n",
      "    log_marginal   : 775.7877721246683\n",
      "    log_joint      : 984.3571339733196\n",
      "    val_loss       : -779.7701059977213\n",
      "    val_ess        : 1.95930481950442\n",
      "    val_log_marginal: 779.8090871175131\n",
      "    val_log_joint  : 988.3295237223307\n",
      "Train Epoch: 1949 [0/54000 (0%)] Loss: -798.466187\n",
      "Train Epoch: 1949 [11264/54000 (21%)] Loss: -778.367188\n",
      "Train Epoch: 1949 [22528/54000 (42%)] Loss: -783.378540\n",
      "Train Epoch: 1949 [33792/54000 (63%)] Loss: -781.789856\n",
      "Train Epoch: 1949 [45056/54000 (83%)] Loss: -768.736877\n",
      "    epoch          : 1949\n",
      "    loss           : -775.7043583707989\n",
      "    ess            : 1.9616239644446463\n",
      "    log_marginal   : 775.7418402905735\n",
      "    log_joint      : 984.2786778863871\n",
      "    val_loss       : -780.0939127604166\n",
      "    val_ess        : 1.9610048631827037\n",
      "    val_log_marginal: 780.1302541097006\n",
      "    val_log_joint  : 988.5648498535156\n",
      "Train Epoch: 1950 [0/54000 (0%)] Loss: -774.747620\n",
      "Train Epoch: 1950 [11264/54000 (21%)] Loss: -788.682983\n",
      "Train Epoch: 1950 [22528/54000 (42%)] Loss: -780.094116\n",
      "Train Epoch: 1950 [33792/54000 (63%)] Loss: -761.555420\n",
      "Train Epoch: 1950 [45056/54000 (83%)] Loss: -766.051697\n",
      "    epoch          : 1950\n",
      "    loss           : -775.7663758475826\n",
      "    ess            : 1.960692767827016\n",
      "    log_marginal   : 775.8044744527565\n",
      "    log_joint      : 984.2834299915241\n",
      "    val_loss       : -779.4766896565756\n",
      "    val_ess        : 1.9627998173236847\n",
      "    val_log_marginal: 779.5109456380209\n",
      "    val_log_joint  : 988.0278574625651\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1950.pth ...\n",
      "Train Epoch: 1951 [0/54000 (0%)] Loss: -767.984192\n",
      "Train Epoch: 1951 [11264/54000 (21%)] Loss: -772.422974\n",
      "Train Epoch: 1951 [22528/54000 (42%)] Loss: -769.748108\n",
      "Train Epoch: 1951 [33792/54000 (63%)] Loss: -763.468445\n",
      "Train Epoch: 1951 [45056/54000 (83%)] Loss: -789.554565\n",
      "    epoch          : 1951\n",
      "    loss           : -775.8244185537662\n",
      "    ess            : 1.9615801201676422\n",
      "    log_marginal   : 775.8614536501327\n",
      "    log_joint      : 984.4328826328493\n",
      "    val_loss       : -779.7627003987631\n",
      "    val_ess        : 1.9610595703125\n",
      "    val_log_marginal: 779.7960764567057\n",
      "    val_log_joint  : 988.0091451009115\n",
      "Train Epoch: 1952 [0/54000 (0%)] Loss: -783.374878\n",
      "Train Epoch: 1952 [11264/54000 (21%)] Loss: -778.707886\n",
      "Train Epoch: 1952 [22528/54000 (42%)] Loss: -785.233032\n",
      "Train Epoch: 1952 [33792/54000 (63%)] Loss: -762.242737\n",
      "Train Epoch: 1952 [45056/54000 (83%)] Loss: -779.486816\n",
      "    epoch          : 1952\n",
      "    loss           : -775.9548978985481\n",
      "    ess            : 1.9607106469712168\n",
      "    log_marginal   : 775.9922116837412\n",
      "    log_joint      : 984.514605252248\n",
      "    val_loss       : -779.6533660888672\n",
      "    val_ess        : 1.9606740772724152\n",
      "    val_log_marginal: 779.6905670166016\n",
      "    val_log_joint  : 988.2347768147787\n",
      "Train Epoch: 1953 [0/54000 (0%)] Loss: -782.991089\n",
      "Train Epoch: 1953 [11264/54000 (21%)] Loss: -751.885254\n",
      "Train Epoch: 1953 [22528/54000 (42%)] Loss: -784.113342\n",
      "Train Epoch: 1953 [33792/54000 (63%)] Loss: -784.113892\n",
      "Train Epoch: 1953 [45056/54000 (83%)] Loss: -768.294067\n",
      "    epoch          : 1953\n",
      "    loss           : -775.6727306437942\n",
      "    ess            : 1.9599012676275\n",
      "    log_marginal   : 775.7100277306898\n",
      "    log_joint      : 984.3113933059404\n",
      "    val_loss       : -779.4407450358073\n",
      "    val_ess        : 1.9611371258894603\n",
      "    val_log_marginal: 779.4805653889974\n",
      "    val_log_joint  : 988.0142262776693\n",
      "Train Epoch: 1954 [0/54000 (0%)] Loss: -787.949951\n",
      "Train Epoch: 1954 [11264/54000 (21%)] Loss: -783.113586\n",
      "Train Epoch: 1954 [22528/54000 (42%)] Loss: -781.146484\n",
      "Train Epoch: 1954 [33792/54000 (63%)] Loss: -764.846802\n",
      "Train Epoch: 1954 [45056/54000 (83%)] Loss: -778.730103\n",
      "    epoch          : 1954\n",
      "    loss           : -775.7567121397774\n",
      "    ess            : 1.9621429881959591\n",
      "    log_marginal   : 775.7923981288694\n",
      "    log_joint      : 984.2748804632223\n",
      "    val_loss       : -779.7320505777994\n",
      "    val_ess        : 1.9639540314674377\n",
      "    val_log_marginal: 779.7664540608724\n",
      "    val_log_joint  : 987.9740447998047\n",
      "Train Epoch: 1955 [0/54000 (0%)] Loss: -778.550537\n",
      "Train Epoch: 1955 [11264/54000 (21%)] Loss: -790.221008\n",
      "Train Epoch: 1955 [22528/54000 (42%)] Loss: -780.421875\n",
      "Train Epoch: 1955 [33792/54000 (63%)] Loss: -806.533325\n",
      "Train Epoch: 1955 [45056/54000 (83%)] Loss: -766.722412\n",
      "    epoch          : 1955\n",
      "    loss           : -775.5911560058594\n",
      "    ess            : 1.961387723122003\n",
      "    log_marginal   : 775.6284767006928\n",
      "    log_joint      : 984.2336823085569\n",
      "    val_loss       : -779.7731018066406\n",
      "    val_ess        : 1.9597646991411846\n",
      "    val_log_marginal: 779.8093414306641\n",
      "    val_log_joint  : 988.4544474283854\n",
      "Train Epoch: 1956 [0/54000 (0%)] Loss: -796.391113\n",
      "Train Epoch: 1956 [11264/54000 (21%)] Loss: -781.281006\n",
      "Train Epoch: 1956 [22528/54000 (42%)] Loss: -781.796509\n",
      "Train Epoch: 1956 [33792/54000 (63%)] Loss: -755.083679\n",
      "Train Epoch: 1956 [45056/54000 (83%)] Loss: -758.413147\n",
      "    epoch          : 1956\n",
      "    loss           : -775.7536494417011\n",
      "    ess            : 1.9611940665065117\n",
      "    log_marginal   : 775.7909263754791\n",
      "    log_joint      : 984.3630756882002\n",
      "    val_loss       : -779.1976572672526\n",
      "    val_ess        : 1.9611164331436157\n",
      "    val_log_marginal: 779.2357025146484\n",
      "    val_log_joint  : 987.7476196289062\n",
      "Train Epoch: 1957 [0/54000 (0%)] Loss: -790.976929\n",
      "Train Epoch: 1957 [11264/54000 (21%)] Loss: -762.198059\n",
      "Train Epoch: 1957 [22528/54000 (42%)] Loss: -771.917725\n",
      "Train Epoch: 1957 [33792/54000 (63%)] Loss: -792.281799\n",
      "Train Epoch: 1957 [45056/54000 (83%)] Loss: -787.160522\n",
      "    epoch          : 1957\n",
      "    loss           : -775.9389562066996\n",
      "    ess            : 1.9607978721834578\n",
      "    log_marginal   : 775.9754356528229\n",
      "    log_joint      : 984.4367059671654\n",
      "    val_loss       : -779.7076873779297\n",
      "    val_ess        : 1.9619464576244354\n",
      "    val_log_marginal: 779.7446034749349\n",
      "    val_log_joint  : 988.4209594726562\n",
      "Train Epoch: 1958 [0/54000 (0%)] Loss: -775.445374\n",
      "Train Epoch: 1958 [11264/54000 (21%)] Loss: -748.499390\n",
      "Train Epoch: 1958 [22528/54000 (42%)] Loss: -791.131348\n",
      "Train Epoch: 1958 [33792/54000 (63%)] Loss: -769.808350\n",
      "Train Epoch: 1958 [45056/54000 (83%)] Loss: -770.212769\n",
      "    epoch          : 1958\n",
      "    loss           : -775.7811089281765\n",
      "    ess            : 1.9612646237859186\n",
      "    log_marginal   : 775.8174473024765\n",
      "    log_joint      : 984.3137327949955\n",
      "    val_loss       : -779.6897226969401\n",
      "    val_ess        : 1.9637505213419597\n",
      "    val_log_marginal: 779.7218119303385\n",
      "    val_log_joint  : 988.2087860107422\n",
      "Train Epoch: 1959 [0/54000 (0%)] Loss: -761.708618\n",
      "Train Epoch: 1959 [11264/54000 (21%)] Loss: -782.410706\n",
      "Train Epoch: 1959 [22528/54000 (42%)] Loss: -745.968750\n",
      "Train Epoch: 1959 [33792/54000 (63%)] Loss: -776.695801\n",
      "Train Epoch: 1959 [45056/54000 (83%)] Loss: -784.530396\n",
      "    epoch          : 1959\n",
      "    loss           : -775.8944091796875\n",
      "    ess            : 1.9618083620971103\n",
      "    log_marginal   : 775.931750603442\n",
      "    log_joint      : 984.3641518646816\n",
      "    val_loss       : -780.0170542399088\n",
      "    val_ess        : 1.9631438354651134\n",
      "    val_log_marginal: 780.0509643554688\n",
      "    val_log_joint  : 988.4759826660156\n",
      "Train Epoch: 1960 [0/54000 (0%)] Loss: -793.090820\n",
      "Train Epoch: 1960 [11264/54000 (21%)] Loss: -764.036621\n",
      "Train Epoch: 1960 [22528/54000 (42%)] Loss: -768.307983\n",
      "Train Epoch: 1960 [33792/54000 (63%)] Loss: -789.634583\n",
      "Train Epoch: 1960 [45056/54000 (83%)] Loss: -769.988281\n",
      "    epoch          : 1960\n",
      "    loss           : -775.6325096274322\n",
      "    ess            : 1.9611037317311988\n",
      "    log_marginal   : 775.6696800375885\n",
      "    log_joint      : 984.1978345187205\n",
      "    val_loss       : -779.6958516438802\n",
      "    val_ess        : 1.9615624348322551\n",
      "    val_log_marginal: 779.7363891601562\n",
      "    val_log_joint  : 988.5947672526041\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1960.pth ...\n",
      "Train Epoch: 1961 [0/54000 (0%)] Loss: -758.982422\n",
      "Train Epoch: 1961 [11264/54000 (21%)] Loss: -738.952515\n",
      "Train Epoch: 1961 [22528/54000 (42%)] Loss: -784.205017\n",
      "Train Epoch: 1961 [33792/54000 (63%)] Loss: -748.639954\n",
      "Train Epoch: 1961 [45056/54000 (83%)] Loss: -761.171875\n",
      "    epoch          : 1961\n",
      "    loss           : -775.8278307644827\n",
      "    ess            : 1.9605894493606855\n",
      "    log_marginal   : 775.8662944289873\n",
      "    log_joint      : 984.3109752727005\n",
      "    val_loss       : -779.0051981608073\n",
      "    val_ess        : 1.9621830582618713\n",
      "    val_log_marginal: 779.0389963785807\n",
      "    val_log_joint  : 987.708984375\n",
      "Train Epoch: 1962 [0/54000 (0%)] Loss: -791.745483\n",
      "Train Epoch: 1962 [11264/54000 (21%)] Loss: -766.949585\n",
      "Train Epoch: 1962 [22528/54000 (42%)] Loss: -769.734375\n",
      "Train Epoch: 1962 [33792/54000 (63%)] Loss: -765.456055\n",
      "Train Epoch: 1962 [45056/54000 (83%)] Loss: -766.095337\n",
      "    epoch          : 1962\n",
      "    loss           : -775.5170092312795\n",
      "    ess            : 1.9613476924176485\n",
      "    log_marginal   : 775.5548159041495\n",
      "    log_joint      : 984.083098789431\n",
      "    val_loss       : -780.1898142496744\n",
      "    val_ess        : 1.962942858537038\n",
      "    val_log_marginal: 780.2259165445963\n",
      "    val_log_joint  : 988.7289683024088\n",
      "Train Epoch: 1963 [0/54000 (0%)] Loss: -775.736938\n",
      "Train Epoch: 1963 [11264/54000 (21%)] Loss: -782.546021\n",
      "Train Epoch: 1963 [22528/54000 (42%)] Loss: -768.508911\n",
      "Train Epoch: 1963 [33792/54000 (63%)] Loss: -764.778564\n",
      "Train Epoch: 1963 [45056/54000 (83%)] Loss: -782.332214\n",
      "    epoch          : 1963\n",
      "    loss           : -775.7618465783461\n",
      "    ess            : 1.959769198354685\n",
      "    log_marginal   : 775.8013322938164\n",
      "    log_joint      : 984.2894978073408\n",
      "    val_loss       : -779.9017028808594\n",
      "    val_ess        : 1.958401471376419\n",
      "    val_log_marginal: 779.9461619059244\n",
      "    val_log_joint  : 988.6231638590494\n",
      "Train Epoch: 1964 [0/54000 (0%)] Loss: -776.825806\n",
      "Train Epoch: 1964 [11264/54000 (21%)] Loss: -779.689026\n",
      "Train Epoch: 1964 [22528/54000 (42%)] Loss: -793.014893\n",
      "Train Epoch: 1964 [33792/54000 (63%)] Loss: -777.785217\n",
      "Train Epoch: 1964 [45056/54000 (83%)] Loss: -757.691040\n",
      "    epoch          : 1964\n",
      "    loss           : -775.5728535202314\n",
      "    ess            : 1.960483082060544\n",
      "    log_marginal   : 775.6113931907797\n",
      "    log_joint      : 984.1194043429392\n",
      "    val_loss       : -779.8277638753256\n",
      "    val_ess        : 1.9580017228921254\n",
      "    val_log_marginal: 779.8704833984375\n",
      "    val_log_joint  : 988.4036153157552\n",
      "Train Epoch: 1965 [0/54000 (0%)] Loss: -755.488281\n",
      "Train Epoch: 1965 [11264/54000 (21%)] Loss: -761.985413\n",
      "Train Epoch: 1965 [22528/54000 (42%)] Loss: -787.700562\n",
      "Train Epoch: 1965 [33792/54000 (63%)] Loss: -777.309082\n",
      "Train Epoch: 1965 [45056/54000 (83%)] Loss: -788.441284\n",
      "    epoch          : 1965\n",
      "    loss           : -775.6579163749263\n",
      "    ess            : 1.960416115679831\n",
      "    log_marginal   : 775.6962562417084\n",
      "    log_joint      : 984.2732613041716\n",
      "    val_loss       : -779.7385965983073\n",
      "    val_ess        : 1.960591346025467\n",
      "    val_log_marginal: 779.7761433919271\n",
      "    val_log_joint  : 988.4597422281901\n",
      "Train Epoch: 1966 [0/54000 (0%)] Loss: -784.675049\n",
      "Train Epoch: 1966 [11264/54000 (21%)] Loss: -791.594482\n",
      "Train Epoch: 1966 [22528/54000 (42%)] Loss: -750.446533\n",
      "Train Epoch: 1966 [33792/54000 (63%)] Loss: -809.574097\n",
      "Train Epoch: 1966 [45056/54000 (83%)] Loss: -781.801453\n",
      "    epoch          : 1966\n",
      "    loss           : -775.5206707648512\n",
      "    ess            : 1.9610682703414053\n",
      "    log_marginal   : 775.5584981666422\n",
      "    log_joint      : 984.1979634986734\n",
      "    val_loss       : -779.5703582763672\n",
      "    val_ess        : 1.964779684940974\n",
      "    val_log_marginal: 779.6018117268881\n",
      "    val_log_joint  : 988.0201263427734\n",
      "Train Epoch: 1967 [0/54000 (0%)] Loss: -776.083130\n",
      "Train Epoch: 1967 [11264/54000 (21%)] Loss: -783.904175\n",
      "Train Epoch: 1967 [22528/54000 (42%)] Loss: -773.988159\n",
      "Train Epoch: 1967 [33792/54000 (63%)] Loss: -753.910217\n",
      "Train Epoch: 1967 [45056/54000 (83%)] Loss: -785.117432\n",
      "    epoch          : 1967\n",
      "    loss           : -775.5588246471477\n",
      "    ess            : 1.9617481535335757\n",
      "    log_marginal   : 775.5954491957178\n",
      "    log_joint      : 984.0132791771078\n",
      "    val_loss       : -779.9886728922526\n",
      "    val_ess        : 1.957969864209493\n",
      "    val_log_marginal: 780.0275828043619\n",
      "    val_log_joint  : 988.4099578857422\n",
      "Train Epoch: 1968 [0/54000 (0%)] Loss: -773.718872\n",
      "Train Epoch: 1968 [11264/54000 (21%)] Loss: -779.150513\n",
      "Train Epoch: 1968 [22528/54000 (42%)] Loss: -748.345947\n",
      "Train Epoch: 1968 [33792/54000 (63%)] Loss: -789.521790\n",
      "Train Epoch: 1968 [45056/54000 (83%)] Loss: -761.009766\n",
      "    epoch          : 1968\n",
      "    loss           : -775.8539509323408\n",
      "    ess            : 1.9609918774298902\n",
      "    log_marginal   : 775.8917011764814\n",
      "    log_joint      : 984.408649948408\n",
      "    val_loss       : -779.8480733235677\n",
      "    val_ess        : 1.9617190062999725\n",
      "    val_log_marginal: 779.8827463785807\n",
      "    val_log_joint  : 988.5706685384115\n",
      "Train Epoch: 1969 [0/54000 (0%)] Loss: -767.109192\n",
      "Train Epoch: 1969 [11264/54000 (21%)] Loss: -776.903442\n",
      "Train Epoch: 1969 [22528/54000 (42%)] Loss: -784.093262\n",
      "Train Epoch: 1969 [33792/54000 (63%)] Loss: -763.832764\n",
      "Train Epoch: 1969 [45056/54000 (83%)] Loss: -750.021729\n",
      "    epoch          : 1969\n",
      "    loss           : -775.6392350106869\n",
      "    ess            : 1.9612227217206415\n",
      "    log_marginal   : 775.6752186901165\n",
      "    log_joint      : 984.1408184699293\n",
      "    val_loss       : -779.9830271402994\n",
      "    val_ess        : 1.9593669573465984\n",
      "    val_log_marginal: 780.0212351481119\n",
      "    val_log_joint  : 988.4915466308594\n",
      "Train Epoch: 1970 [0/54000 (0%)] Loss: -767.369324\n",
      "Train Epoch: 1970 [11264/54000 (21%)] Loss: -782.932312\n",
      "Train Epoch: 1970 [22528/54000 (42%)] Loss: -765.826416\n",
      "Train Epoch: 1970 [33792/54000 (63%)] Loss: -792.368042\n",
      "Train Epoch: 1970 [45056/54000 (83%)] Loss: -748.672607\n",
      "    epoch          : 1970\n",
      "    loss           : -775.6383736088591\n",
      "    ess            : 1.9610903454276751\n",
      "    log_marginal   : 775.6745933676666\n",
      "    log_joint      : 984.2337830741451\n",
      "    val_loss       : -779.9172414143881\n",
      "    val_ess        : 1.963453968365987\n",
      "    val_log_marginal: 779.9487559000651\n",
      "    val_log_joint  : 988.5215352376302\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1970.pth ...\n",
      "Train Epoch: 1971 [0/54000 (0%)] Loss: -775.685791\n",
      "Train Epoch: 1971 [11264/54000 (21%)] Loss: -751.385742\n",
      "Train Epoch: 1971 [22528/54000 (42%)] Loss: -770.859619\n",
      "Train Epoch: 1971 [33792/54000 (63%)] Loss: -799.339355\n",
      "Train Epoch: 1971 [45056/54000 (83%)] Loss: -770.157654\n",
      "    epoch          : 1971\n",
      "    loss           : -775.5699940807415\n",
      "    ess            : 1.9610621704245514\n",
      "    log_marginal   : 775.6076740768721\n",
      "    log_joint      : 984.0540765726341\n",
      "    val_loss       : -779.5745849609375\n",
      "    val_ess        : 1.9620458384354909\n",
      "    val_log_marginal: 779.6072082519531\n",
      "    val_log_joint  : 988.1806894938151\n",
      "Train Epoch: 1972 [0/54000 (0%)] Loss: -756.724365\n",
      "Train Epoch: 1972 [11264/54000 (21%)] Loss: -797.098999\n",
      "Train Epoch: 1972 [22528/54000 (42%)] Loss: -784.094482\n",
      "Train Epoch: 1972 [33792/54000 (63%)] Loss: -775.596191\n",
      "Train Epoch: 1972 [45056/54000 (83%)] Loss: -778.156250\n",
      "    epoch          : 1972\n",
      "    loss           : -775.529890528265\n",
      "    ess            : 1.9606372320427086\n",
      "    log_marginal   : 775.5667920382517\n",
      "    log_joint      : 984.1263456524543\n",
      "    val_loss       : -780.5407765706381\n",
      "    val_ess        : 1.959064741929372\n",
      "    val_log_marginal: 780.5782318115234\n",
      "    val_log_joint  : 989.1508483886719\n",
      "Train Epoch: 1973 [0/54000 (0%)] Loss: -765.506226\n",
      "Train Epoch: 1973 [11264/54000 (21%)] Loss: -780.880188\n",
      "Train Epoch: 1973 [22528/54000 (42%)] Loss: -762.834717\n",
      "Train Epoch: 1973 [33792/54000 (63%)] Loss: -777.625854\n",
      "Train Epoch: 1973 [45056/54000 (83%)] Loss: -772.437561\n",
      "    epoch          : 1973\n",
      "    loss           : -775.538607615345\n",
      "    ess            : 1.9608527748089917\n",
      "    log_marginal   : 775.5754267854511\n",
      "    log_joint      : 984.1320829571418\n",
      "    val_loss       : -779.7847798665365\n",
      "    val_ess        : 1.961923321088155\n",
      "    val_log_marginal: 779.8182423909506\n",
      "    val_log_joint  : 988.1620381673177\n",
      "Train Epoch: 1974 [0/54000 (0%)] Loss: -781.857910\n",
      "Train Epoch: 1974 [11264/54000 (21%)] Loss: -762.419800\n",
      "Train Epoch: 1974 [22528/54000 (42%)] Loss: -778.936035\n",
      "Train Epoch: 1974 [33792/54000 (63%)] Loss: -771.101929\n",
      "Train Epoch: 1974 [45056/54000 (83%)] Loss: -790.103271\n",
      "    epoch          : 1974\n",
      "    loss           : -775.6055315125664\n",
      "    ess            : 1.9597675507923342\n",
      "    log_marginal   : 775.6439450821787\n",
      "    log_joint      : 984.2079715368883\n",
      "    val_loss       : -779.2669830322266\n",
      "    val_ess        : 1.9577495455741882\n",
      "    val_log_marginal: 779.3059132893881\n",
      "    val_log_joint  : 988.0862223307291\n",
      "Train Epoch: 1975 [0/54000 (0%)] Loss: -772.268188\n",
      "Train Epoch: 1975 [11264/54000 (21%)] Loss: -758.983582\n",
      "Train Epoch: 1975 [22528/54000 (42%)] Loss: -766.902222\n",
      "Train Epoch: 1975 [33792/54000 (63%)] Loss: -779.371948\n",
      "Train Epoch: 1975 [45056/54000 (83%)] Loss: -781.877441\n",
      "    epoch          : 1975\n",
      "    loss           : -775.5224160248379\n",
      "    ess            : 1.9596128744899102\n",
      "    log_marginal   : 775.5610915849794\n",
      "    log_joint      : 984.0772975705704\n",
      "    val_loss       : -779.8811086018881\n",
      "    val_ess        : 1.960690677165985\n",
      "    val_log_marginal: 779.9217376708984\n",
      "    val_log_joint  : 988.679931640625\n",
      "Train Epoch: 1976 [0/54000 (0%)] Loss: -776.137512\n",
      "Train Epoch: 1976 [11264/54000 (21%)] Loss: -766.291870\n",
      "Train Epoch: 1976 [22528/54000 (42%)] Loss: -782.060791\n",
      "Train Epoch: 1976 [33792/54000 (63%)] Loss: -790.892700\n",
      "Train Epoch: 1976 [45056/54000 (83%)] Loss: -763.068970\n",
      "    epoch          : 1976\n",
      "    loss           : -775.4160524764151\n",
      "    ess            : 1.96022012436165\n",
      "    log_marginal   : 775.4550942474941\n",
      "    log_joint      : 984.0181746572819\n",
      "    val_loss       : -779.8412424723307\n",
      "    val_ess        : 1.9595121145248413\n",
      "    val_log_marginal: 779.8853658040365\n",
      "    val_log_joint  : 988.7189381917318\n",
      "Train Epoch: 1977 [0/54000 (0%)] Loss: -766.261292\n",
      "Train Epoch: 1977 [11264/54000 (21%)] Loss: -774.303589\n",
      "Train Epoch: 1977 [22528/54000 (42%)] Loss: -780.818848\n",
      "Train Epoch: 1977 [33792/54000 (63%)] Loss: -773.891663\n",
      "Train Epoch: 1977 [45056/54000 (83%)] Loss: -763.159912\n",
      "    epoch          : 1977\n",
      "    loss           : -775.5278562149912\n",
      "    ess            : 1.9600124786484916\n",
      "    log_marginal   : 775.5659553959684\n",
      "    log_joint      : 984.0551907521374\n",
      "    val_loss       : -779.9805450439453\n",
      "    val_ess        : 1.9613094826539357\n",
      "    val_log_marginal: 780.0191802978516\n",
      "    val_log_joint  : 988.2237192789713\n",
      "Train Epoch: 1978 [0/54000 (0%)] Loss: -787.742615\n",
      "Train Epoch: 1978 [11264/54000 (21%)] Loss: -778.601990\n",
      "Train Epoch: 1978 [22528/54000 (42%)] Loss: -779.508728\n",
      "Train Epoch: 1978 [33792/54000 (63%)] Loss: -776.558472\n",
      "Train Epoch: 1978 [45056/54000 (83%)] Loss: -768.408752\n",
      "    epoch          : 1978\n",
      "    loss           : -775.9251760806677\n",
      "    ess            : 1.9606594240890358\n",
      "    log_marginal   : 775.9627017614977\n",
      "    log_joint      : 984.470361673607\n",
      "    val_loss       : -779.8919677734375\n",
      "    val_ess        : 1.957598050435384\n",
      "    val_log_marginal: 779.9363199869791\n",
      "    val_log_joint  : 988.5411936442057\n",
      "Train Epoch: 1979 [0/54000 (0%)] Loss: -779.760132\n",
      "Train Epoch: 1979 [11264/54000 (21%)] Loss: -780.220581\n",
      "Train Epoch: 1979 [22528/54000 (42%)] Loss: -802.224609\n",
      "Train Epoch: 1979 [33792/54000 (63%)] Loss: -777.989868\n",
      "Train Epoch: 1979 [45056/54000 (83%)] Loss: -790.751709\n",
      "    epoch          : 1979\n",
      "    loss           : -775.6838845306972\n",
      "    ess            : 1.9612444830390643\n",
      "    log_marginal   : 775.7197288657135\n",
      "    log_joint      : 984.2402464668705\n",
      "    val_loss       : -780.2744903564453\n",
      "    val_ess        : 1.9630450308322906\n",
      "    val_log_marginal: 780.3117065429688\n",
      "    val_log_joint  : 988.906972249349\n",
      "Train Epoch: 1980 [0/54000 (0%)] Loss: -770.088440\n",
      "Train Epoch: 1980 [11264/54000 (21%)] Loss: -794.411438\n",
      "Train Epoch: 1980 [22528/54000 (42%)] Loss: -760.262573\n",
      "Train Epoch: 1980 [33792/54000 (63%)] Loss: -785.014221\n",
      "Train Epoch: 1980 [45056/54000 (83%)] Loss: -781.641235\n",
      "    epoch          : 1980\n",
      "    loss           : -775.7354292959537\n",
      "    ess            : 1.9600670877492652\n",
      "    log_marginal   : 775.7730793503096\n",
      "    log_joint      : 984.3485424113724\n",
      "    val_loss       : -779.3988901774088\n",
      "    val_ess        : 1.9583496153354645\n",
      "    val_log_marginal: 779.4433034261068\n",
      "    val_log_joint  : 987.9584248860677\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1980.pth ...\n",
      "Train Epoch: 1981 [0/54000 (0%)] Loss: -792.393494\n",
      "Train Epoch: 1981 [11264/54000 (21%)] Loss: -774.213318\n",
      "Train Epoch: 1981 [22528/54000 (42%)] Loss: -778.271667\n",
      "Train Epoch: 1981 [33792/54000 (63%)] Loss: -787.382080\n",
      "Train Epoch: 1981 [45056/54000 (83%)] Loss: -767.988647\n",
      "    epoch          : 1981\n",
      "    loss           : -775.4873651468529\n",
      "    ess            : 1.960391251546032\n",
      "    log_marginal   : 775.525690618551\n",
      "    log_joint      : 984.112917342276\n",
      "    val_loss       : -780.1197102864584\n",
      "    val_ess        : 1.9607519805431366\n",
      "    val_log_marginal: 780.1604715983073\n",
      "    val_log_joint  : 988.6149291992188\n",
      "Train Epoch: 1982 [0/54000 (0%)] Loss: -799.615906\n",
      "Train Epoch: 1982 [11264/54000 (21%)] Loss: -757.946594\n",
      "Train Epoch: 1982 [22528/54000 (42%)] Loss: -786.493774\n",
      "Train Epoch: 1982 [33792/54000 (63%)] Loss: -783.987610\n",
      "Train Epoch: 1982 [45056/54000 (83%)] Loss: -772.848145\n",
      "    epoch          : 1982\n",
      "    loss           : -775.7012904904923\n",
      "    ess            : 1.9603196000153165\n",
      "    log_marginal   : 775.7388628113945\n",
      "    log_joint      : 984.243017232643\n",
      "    val_loss       : -779.6197916666666\n",
      "    val_ess        : 1.9609610537687938\n",
      "    val_log_marginal: 779.6531219482422\n",
      "    val_log_joint  : 988.4552663167318\n",
      "Train Epoch: 1983 [0/54000 (0%)] Loss: -779.752747\n",
      "Train Epoch: 1983 [11264/54000 (21%)] Loss: -753.956604\n",
      "Train Epoch: 1983 [22528/54000 (42%)] Loss: -770.760620\n",
      "Train Epoch: 1983 [33792/54000 (63%)] Loss: -778.496094\n",
      "Train Epoch: 1983 [45056/54000 (83%)] Loss: -777.219604\n",
      "    epoch          : 1983\n",
      "    loss           : -775.6352372079525\n",
      "    ess            : 1.961174079832041\n",
      "    log_marginal   : 775.6738269733933\n",
      "    log_joint      : 984.1663000718603\n",
      "    val_loss       : -780.1862386067709\n",
      "    val_ess        : 1.9613620142141979\n",
      "    val_log_marginal: 780.2225443522135\n",
      "    val_log_joint  : 988.9446563720703\n",
      "Train Epoch: 1984 [0/54000 (0%)] Loss: -777.551392\n",
      "Train Epoch: 1984 [11264/54000 (21%)] Loss: -752.065430\n",
      "Train Epoch: 1984 [22528/54000 (42%)] Loss: -791.625122\n",
      "Train Epoch: 1984 [33792/54000 (63%)] Loss: -777.365234\n",
      "Train Epoch: 1984 [45056/54000 (83%)] Loss: -766.223755\n",
      "    epoch          : 1984\n",
      "    loss           : -775.6302968151165\n",
      "    ess            : 1.9605914646724485\n",
      "    log_marginal   : 775.6673762483417\n",
      "    log_joint      : 984.2886818939785\n",
      "    val_loss       : -779.9782663981119\n",
      "    val_ess        : 1.9606885214646657\n",
      "    val_log_marginal: 780.0168762207031\n",
      "    val_log_joint  : 988.4550374348959\n",
      "Train Epoch: 1985 [0/54000 (0%)] Loss: -768.648987\n",
      "Train Epoch: 1985 [11264/54000 (21%)] Loss: -780.012268\n",
      "Train Epoch: 1985 [22528/54000 (42%)] Loss: -767.350098\n",
      "Train Epoch: 1985 [33792/54000 (63%)] Loss: -767.792358\n",
      "Train Epoch: 1985 [45056/54000 (83%)] Loss: -770.246338\n",
      "    epoch          : 1985\n",
      "    loss           : -775.6418301564343\n",
      "    ess            : 1.961708425350909\n",
      "    log_marginal   : 775.6791243643131\n",
      "    log_joint      : 984.2330800182415\n",
      "    val_loss       : -779.840098063151\n",
      "    val_ess        : 1.956267903248469\n",
      "    val_log_marginal: 779.8856353759766\n",
      "    val_log_joint  : 988.4170888264974\n",
      "Train Epoch: 1986 [0/54000 (0%)] Loss: -768.697021\n",
      "Train Epoch: 1986 [11264/54000 (21%)] Loss: -756.169434\n",
      "Train Epoch: 1986 [22528/54000 (42%)] Loss: -772.318665\n",
      "Train Epoch: 1986 [33792/54000 (63%)] Loss: -787.798096\n",
      "Train Epoch: 1986 [45056/54000 (83%)] Loss: -795.787354\n",
      "    epoch          : 1986\n",
      "    loss           : -775.5868276919958\n",
      "    ess            : 1.961121069935133\n",
      "    log_marginal   : 775.6245393573113\n",
      "    log_joint      : 984.1246660340507\n",
      "    val_loss       : -780.2078145345052\n",
      "    val_ess        : 1.9575779636700947\n",
      "    val_log_marginal: 780.2478078206381\n",
      "    val_log_joint  : 988.6487019856771\n",
      "Train Epoch: 1987 [0/54000 (0%)] Loss: -790.626099\n",
      "Train Epoch: 1987 [11264/54000 (21%)] Loss: -779.517334\n",
      "Train Epoch: 1987 [22528/54000 (42%)] Loss: -788.986511\n",
      "Train Epoch: 1987 [33792/54000 (63%)] Loss: -758.262939\n",
      "Train Epoch: 1987 [45056/54000 (83%)] Loss: -773.130859\n",
      "    epoch          : 1987\n",
      "    loss           : -775.8971672777859\n",
      "    ess            : 1.9610151243659686\n",
      "    log_marginal   : 775.9348046644678\n",
      "    log_joint      : 984.3790358057562\n",
      "    val_loss       : -779.9406585693359\n",
      "    val_ess        : 1.9628662765026093\n",
      "    val_log_marginal: 779.9775695800781\n",
      "    val_log_joint  : 988.4184722900391\n",
      "Train Epoch: 1988 [0/54000 (0%)] Loss: -789.419556\n",
      "Train Epoch: 1988 [11264/54000 (21%)] Loss: -789.494568\n",
      "Train Epoch: 1988 [22528/54000 (42%)] Loss: -781.943604\n",
      "Train Epoch: 1988 [33792/54000 (63%)] Loss: -785.595703\n",
      "Train Epoch: 1988 [45056/54000 (83%)] Loss: -764.133423\n",
      "    epoch          : 1988\n",
      "    loss           : -775.7462296395931\n",
      "    ess            : 1.960779923313069\n",
      "    log_marginal   : 775.7827044792895\n",
      "    log_joint      : 984.3110057902786\n",
      "    val_loss       : -779.7724151611328\n",
      "    val_ess        : 1.9603383541107178\n",
      "    val_log_marginal: 779.8089192708334\n",
      "    val_log_joint  : 988.4878082275391\n",
      "Train Epoch: 1989 [0/54000 (0%)] Loss: -755.128479\n",
      "Train Epoch: 1989 [11264/54000 (21%)] Loss: -803.335571\n",
      "Train Epoch: 1989 [22528/54000 (42%)] Loss: -763.574158\n",
      "Train Epoch: 1989 [33792/54000 (63%)] Loss: -772.576050\n",
      "Train Epoch: 1989 [45056/54000 (83%)] Loss: -789.968872\n",
      "    epoch          : 1989\n",
      "    loss           : -775.5280957491892\n",
      "    ess            : 1.9604794889126185\n",
      "    log_marginal   : 775.5672676518278\n",
      "    log_joint      : 984.1226311449734\n",
      "    val_loss       : -780.5369669596354\n",
      "    val_ess        : 1.9620162745316823\n",
      "    val_log_marginal: 780.5724690755209\n",
      "    val_log_joint  : 988.9772745768229\n",
      "Train Epoch: 1990 [0/54000 (0%)] Loss: -781.351074\n",
      "Train Epoch: 1990 [11264/54000 (21%)] Loss: -760.521240\n",
      "Train Epoch: 1990 [22528/54000 (42%)] Loss: -763.069336\n",
      "Train Epoch: 1990 [33792/54000 (63%)] Loss: -768.901367\n",
      "Train Epoch: 1990 [45056/54000 (83%)] Loss: -775.695435\n",
      "    epoch          : 1990\n",
      "    loss           : -775.6378801453789\n",
      "    ess            : 1.9607753483754284\n",
      "    log_marginal   : 775.6756868182488\n",
      "    log_joint      : 984.1997300633844\n",
      "    val_loss       : -779.765879313151\n",
      "    val_ess        : 1.962644338607788\n",
      "    val_log_marginal: 779.8045857747396\n",
      "    val_log_joint  : 988.3797709147135\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch1990.pth ...\n",
      "Train Epoch: 1991 [0/54000 (0%)] Loss: -780.335876\n",
      "Train Epoch: 1991 [11264/54000 (21%)] Loss: -794.279297\n",
      "Train Epoch: 1991 [22528/54000 (42%)] Loss: -781.417358\n",
      "Train Epoch: 1991 [33792/54000 (63%)] Loss: -804.847534\n",
      "Train Epoch: 1991 [45056/54000 (83%)] Loss: -761.011841\n",
      "    epoch          : 1991\n",
      "    loss           : -775.8329542627874\n",
      "    ess            : 1.9616497867512253\n",
      "    log_marginal   : 775.8685366072745\n",
      "    log_joint      : 984.4147097029776\n",
      "    val_loss       : -779.5356190999349\n",
      "    val_ess        : 1.9647371172904968\n",
      "    val_log_marginal: 779.5677235921224\n",
      "    val_log_joint  : 988.1022084554037\n",
      "Train Epoch: 1992 [0/54000 (0%)] Loss: -753.689209\n",
      "Train Epoch: 1992 [11264/54000 (21%)] Loss: -778.987549\n",
      "Train Epoch: 1992 [22528/54000 (42%)] Loss: -762.442383\n",
      "Train Epoch: 1992 [33792/54000 (63%)] Loss: -773.702271\n",
      "Train Epoch: 1992 [45056/54000 (83%)] Loss: -762.246155\n",
      "    epoch          : 1992\n",
      "    loss           : -775.6304217644457\n",
      "    ess            : 1.961520956372315\n",
      "    log_marginal   : 775.6658636129127\n",
      "    log_joint      : 984.2006738050928\n",
      "    val_loss       : -780.1695404052734\n",
      "    val_ess        : 1.9621622761090596\n",
      "    val_log_marginal: 780.2080891927084\n",
      "    val_log_joint  : 988.9077758789062\n",
      "Train Epoch: 1993 [0/54000 (0%)] Loss: -764.267212\n",
      "Train Epoch: 1993 [11264/54000 (21%)] Loss: -811.346191\n",
      "Train Epoch: 1993 [22528/54000 (42%)] Loss: -788.774170\n",
      "Train Epoch: 1993 [33792/54000 (63%)] Loss: -787.518433\n",
      "Train Epoch: 1993 [45056/54000 (83%)] Loss: -771.694519\n",
      "    epoch          : 1993\n",
      "    loss           : -775.4829832832768\n",
      "    ess            : 1.9614137208686684\n",
      "    log_marginal   : 775.5202153043927\n",
      "    log_joint      : 984.132247636903\n",
      "    val_loss       : -780.040283203125\n",
      "    val_ess        : 1.957770476738612\n",
      "    val_log_marginal: 780.080312093099\n",
      "    val_log_joint  : 988.8356272379557\n",
      "Train Epoch: 1994 [0/54000 (0%)] Loss: -770.463806\n",
      "Train Epoch: 1994 [11264/54000 (21%)] Loss: -767.743225\n",
      "Train Epoch: 1994 [22528/54000 (42%)] Loss: -768.340088\n",
      "Train Epoch: 1994 [33792/54000 (63%)] Loss: -758.351624\n",
      "Train Epoch: 1994 [45056/54000 (83%)] Loss: -782.636963\n",
      "    epoch          : 1994\n",
      "    loss           : -775.5680968086674\n",
      "    ess            : 1.9602934403239556\n",
      "    log_marginal   : 775.6060992546801\n",
      "    log_joint      : 984.2225998212706\n",
      "    val_loss       : -779.6991628011068\n",
      "    val_ess        : 1.9614823460578918\n",
      "    val_log_marginal: 779.7340189615885\n",
      "    val_log_joint  : 988.3442942301432\n",
      "Train Epoch: 1995 [0/54000 (0%)] Loss: -795.324280\n",
      "Train Epoch: 1995 [11264/54000 (21%)] Loss: -803.183167\n",
      "Train Epoch: 1995 [22528/54000 (42%)] Loss: -766.941162\n",
      "Train Epoch: 1995 [33792/54000 (63%)] Loss: -774.679138\n",
      "Train Epoch: 1995 [45056/54000 (83%)] Loss: -801.805725\n",
      "    epoch          : 1995\n",
      "    loss           : -775.8944005426371\n",
      "    ess            : 1.9602881703736648\n",
      "    log_marginal   : 775.931891099462\n",
      "    log_joint      : 984.461816751732\n",
      "    val_loss       : -780.7978973388672\n",
      "    val_ess        : 1.9618720412254333\n",
      "    val_log_marginal: 780.8357289632162\n",
      "    val_log_joint  : 989.3791453043619\n",
      "Train Epoch: 1996 [0/54000 (0%)] Loss: -781.962097\n",
      "Train Epoch: 1996 [11264/54000 (21%)] Loss: -786.780884\n",
      "Train Epoch: 1996 [22528/54000 (42%)] Loss: -791.036743\n",
      "Train Epoch: 1996 [33792/54000 (63%)] Loss: -768.094727\n",
      "Train Epoch: 1996 [45056/54000 (83%)] Loss: -764.914429\n",
      "    epoch          : 1996\n",
      "    loss           : -775.7559054392689\n",
      "    ess            : 1.9619128276716988\n",
      "    log_marginal   : 775.7922109927771\n",
      "    log_joint      : 984.286014772811\n",
      "    val_loss       : -780.0098317464193\n",
      "    val_ess        : 1.9619126319885254\n",
      "    val_log_marginal: 780.0476684570312\n",
      "    val_log_joint  : 988.3660634358724\n",
      "Train Epoch: 1997 [0/54000 (0%)] Loss: -770.196777\n",
      "Train Epoch: 1997 [11264/54000 (21%)] Loss: -761.967773\n",
      "Train Epoch: 1997 [22528/54000 (42%)] Loss: -779.236877\n",
      "Train Epoch: 1997 [33792/54000 (63%)] Loss: -755.268860\n",
      "Train Epoch: 1997 [45056/54000 (83%)] Loss: -772.871338\n",
      "    epoch          : 1997\n",
      "    loss           : -775.58426363963\n",
      "    ess            : 1.960623340786628\n",
      "    log_marginal   : 775.6220242482311\n",
      "    log_joint      : 984.145048321418\n",
      "    val_loss       : -780.4450429280599\n",
      "    val_ess        : 1.961701234181722\n",
      "    val_log_marginal: 780.4794972737631\n",
      "    val_log_joint  : 989.1131591796875\n",
      "Train Epoch: 1998 [0/54000 (0%)] Loss: -787.812439\n",
      "Train Epoch: 1998 [11264/54000 (21%)] Loss: -797.591003\n",
      "Train Epoch: 1998 [22528/54000 (42%)] Loss: -761.696838\n",
      "Train Epoch: 1998 [33792/54000 (63%)] Loss: -771.957153\n",
      "Train Epoch: 1998 [45056/54000 (83%)] Loss: -796.248047\n",
      "    epoch          : 1998\n",
      "    loss           : -775.6322297869988\n",
      "    ess            : 1.9624802593914967\n",
      "    log_marginal   : 775.6674119481501\n",
      "    log_joint      : 984.1617379818323\n",
      "    val_loss       : -779.8231099446615\n",
      "    val_ess        : 1.9615474144617717\n",
      "    val_log_marginal: 779.8595326741537\n",
      "    val_log_joint  : 988.1829681396484\n",
      "Train Epoch: 1999 [0/54000 (0%)] Loss: -787.955078\n",
      "Train Epoch: 1999 [11264/54000 (21%)] Loss: -772.981445\n",
      "Train Epoch: 1999 [22528/54000 (42%)] Loss: -776.500977\n",
      "Train Epoch: 1999 [33792/54000 (63%)] Loss: -755.022766\n",
      "Train Epoch: 1999 [45056/54000 (83%)] Loss: -785.586060\n",
      "    epoch          : 1999\n",
      "    loss           : -775.6377471348025\n",
      "    ess            : 1.960986631096534\n",
      "    log_marginal   : 775.67494345611\n",
      "    log_joint      : 984.1556926223467\n",
      "    val_loss       : -780.4849853515625\n",
      "    val_ess        : 1.9651922583580017\n",
      "    val_log_marginal: 780.5173950195312\n",
      "    val_log_joint  : 988.7957865397135\n",
      "Train Epoch: 2000 [0/54000 (0%)] Loss: -770.802551\n",
      "Train Epoch: 2000 [11264/54000 (21%)] Loss: -771.131592\n",
      "Train Epoch: 2000 [22528/54000 (42%)] Loss: -797.097534\n",
      "Train Epoch: 2000 [33792/54000 (63%)] Loss: -781.396851\n",
      "Train Epoch: 2000 [45056/54000 (83%)] Loss: -763.807495\n",
      "    epoch          : 2000\n",
      "    loss           : -775.7765462623453\n",
      "    ess            : 1.9609147096579929\n",
      "    log_marginal   : 775.8132830925707\n",
      "    log_joint      : 984.324084587817\n",
      "    val_loss       : -779.7482604980469\n",
      "    val_ess        : 1.9599410394827526\n",
      "    val_log_marginal: 779.7874399820963\n",
      "    val_log_joint  : 988.4526672363281\n",
      "Saving checkpoint: saved/models/FashionMnist_Ppc/0505_172452/checkpoint-epoch2000.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa5b900-0121-4cf6-91b6-2c9b0b12716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParticleDict(\n",
       "    (z1): Parameter containing: [torch.FloatTensor of size 2x6000x20]\n",
       "    (z2): Parameter containing: [torch.FloatTensor of size 2x6000x128]\n",
       "    (z3): Parameter containing: [torch.FloatTensor of size 2x6000x256]\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.eval()\n",
    "trainer.model.cpu()\n",
    "trainer.cpu()\n",
    "trainer.train_particles.cpu()\n",
    "trainer.valid_particles.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d528cb-d45e-4a37-be86-9622aec9ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.graph.clear()\n",
    "trainer._load_particles(range(trainer.data_loader.batch_size), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e26726a6-74e5-4e0f-81d5-746dba00f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in trainer.model.graph.nodes:\n",
    "    trainer.model.graph.nodes[site]['is_observed'] = trainer.model.graph.nodes[site]['value'] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb94c06-7112-4c5e-b781-0ac215a7e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a2eeb8-32e3-467e-9e9a-0ac1e2af9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate_stack(\"forward\", (trainer.num_particles, trainer.data_loader.batch_size)):\n",
    "    model = pyro.condition(trainer.model, data={k: v['value'] for k, v in trainer.model.graph.nodes.items()})\n",
    "    xs = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6e9ba59-7b26-4ef3-9bfd-23f7c8a26464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1509d2-9afc-444e-821f-b7ccda42aa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoKUlEQVR4nO3df3TU9Z3v8dd3JsmQhMlAgPyCEKOFasWyKyjI9Qe4NdfcW04Vu4t2uxe6rbcqcJZF1y3r3pX23iOurhzvWSq9tbsUVq3s7vHXWT1qugjUpbjIolC0FkqACMRIgEwIMMnMfO4fLGkjCHl/Tfjkx/NxzpwDk++Lzzff+U5eGWbmPYFzzgkAAA8ivncAADB4UUIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvMnxvQOflM1mdeDAAcXjcQVB4Ht3AABGzjm1traqoqJCkci5H+v0uRI6cOCAKisrfe8GAOAzamho0JgxY865TZ8roXg8Lkm6ITFbOUFet3MdX7jIvFbOu7vMGUlyqXZzJjKu2pzJ7t5nX6cg35zReX5T+TTu5El7pj1tzkTyY/Z1MhlzRgq3f9HiYfZ10vZ1gkL7bZttPmLOSFJk+DBzxg0tsC/U1GyOBENCnA8hMpIUhDiPXP4QeybMfbDhgD0jKcjNNWcyR46atk+7Dr2plzt/np9Lr5XQE088oUcffVQHDx7U5Zdfrscff1zXXXfdeXOn/wsuJ8gzlZDLsd/wln+/y1qBfdxeJGq/E2QD+8kSCfM9hS2hIBsiY/8v1jDfkwtCllCI/YtGQuxfiGMeRMKcQ+HO8UiItVyIc1whjl2Y4xBq3yQFLkQJhVgrVAmFvG2DiP3nShDiZ5GcuvWUSq+8MGHNmjVauHChHnjgAW3dulXXXXedamtrtW+f/Td7AMDA1SsltGzZMn3zm9/Ut771LV122WV6/PHHVVlZqRUrVvTGcgCAfqrHS6i9vV1btmxRTU1Nl+tramq0cePGM7ZPpVJKJpNdLgCAwaHHS+jQoUPKZDIqLS3tcn1paakaGxvP2H7p0qVKJBKdF14ZBwCDR6+9WfWTT0g55876JNXixYvV0tLSeWloaOitXQIA9DE9/uq4kSNHKhqNnvGop6mp6YxHR5IUi8UUi4V75QoAoH/r8UdCeXl5mjRpkurq6rpcX1dXp2nTpvX0cgCAfqxX3ie0aNEi/dEf/ZEmT56sa665Rj/84Q+1b98+3XXXXb2xHACgn+qVEpo9e7aam5v1ve99TwcPHtSECRP0yiuvqKqqqjeWAwD0U4Fzzv72/16UTCaVSCR0Y/wPbRMNOjrMa0UqyswZSUrvsb94InrxWHMm6LCPdsl+9LF9ncoKc0aSOkqLzJnc9+1vWA6G2KdhZI1jRk6LJOzf0/Evnns21tnkv73bnFGIETLZthP2dSRFiobaQ6UjzZGg5Zg5k022mjORoYXmjCS5dvuIriAvxCSDaNQcyR6yjzySpKDa/grkoPW4aft0NqWf7v+BWlpaVFR07vsUH+UAAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN70yhTtHnHRaCna/Q+76xieb14i97BtKN9p0XHV5kxw/KR9oRBDWYN43J5pbTNnJCn38FH7WmEGSabsQyRdiOGvkpQ9Zj8WBe/aB9pmWpLmTKjBmJEzP824O7Jh9u9kyp4ZPsycCTPI9aMv2++zktRWYT9+1ct/ac64E/afD5GyEnNGkjI76+1rFRSYtneu+/dZHgkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAmz47RTtoTyuIRru9fd4O+yRj19pqzkiSxpSbI9nhQ82ZYM8Be6Z4mDnjYiGmM0s6fslwc6ZwR6M544YXmTOReIhp3ZKCENO3M/vt31MkYf+ewkwgdyGmgkuScuw/GrLNh82ZzMeHzJlDX7/SnHnhfz1qzkjSf6Tsk6oXXnK7OXPpor3mTLb5iDkjSdHR9p9f7khLqLW6g0dCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOBNnx1gmtm5R0GQ2+3tg0hgX8QwIPW3RTJZcyb73i5zJhiWMGdc2wlzRmEykoYU5ZszrmCIPbN3vzkTjC4zZyRJIW5buRCZEINSFdjP8SC3+/eh35ZN2of7Bvn280EXjzFH/s/ivzdn7m+Yac5IUvkQ++DOktdCDAR2zp7JhjjvJGUP2QfNurTtfM26jm5vyyMhAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCmzw4wjRTmKxJ0fxBg9tgx+xp5IQYNSqEGB0bLQwzUNA4NlKTskaPmTKjBk5Ii9QfMmczho+ZMkGs/TbO76s0ZSYrG4+aMy4YYPlk60p4JMfQ03fiRfR1JOWNG20MhBqweudQ+pLc5M9SciQQhbiNJ7xyxD1gd8a/2cy87usScCfY3mTOSpJIR9rWM514kk5J2d3Nb894AANBDKCEAgDc9XkJLlixREARdLmVlIT/bBQAwoPXKc0KXX365fvrTn3b+PRryw+MAAANbr5RQTk4Oj34AAOfVK88J7dy5UxUVFaqurtbtt9+u3bs//WUSqVRKyWSyywUAMDj0eAlNmTJFq1ev1muvvaYnn3xSjY2NmjZtmpqbm8+6/dKlS5VIJDovlZWVPb1LAIA+qsdLqLa2VrfddpuuuOIKfelLX9LLL78sSVq1atVZt1+8eLFaWlo6Lw0NDT29SwCAPqrX36xaWFioK664Qjt37jzr12OxmGKxWG/vBgCgD+r19wmlUim9//77Ki8v7+2lAAD9TI+X0H333af169ervr5eb731lr761a8qmUxqzpw5Pb0UAKCf6/H/jvvwww91xx136NChQxo1apSmTp2qTZs2qaqqqqeXAgD0cz1eQs8++2yP/DuRorgiEcNzRZmMfY1EkTkjSZlG++DAIMRwR+fsQxcj+UPs66RS5ox06jayio4KMTxxSIjnDNP280GSMmXDzZlIyr5W20X2c2/o23vNmUf3bDJnJOmOHy4yZybN/IU589SYZeZMLLD/2Jo6xH7sJOl//vGfmDOZQ++aM5EQ9/Ugbh/kKkluv32orbuowra94S7B7DgAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8KbXP9QuLNd6TC5o7/72X7jYvsZe+yA/SQqiUXMmMqLYvlA2a8+EGZTakrSvE9aJk+ZIpvmwOdPyB5PNGUm6+6/+2Zz50d7rzJkvFtuHXF5b9CtzZmd7iTkjSZ+/+ewfQnkuf1v5mjlzIG2OqCxqDzVmCuwLSYo1HjNnglL7MXcJ+zBSdyDczy8XZtjzMdv9NpLt/lBkHgkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAm747Rbu9Xc4wEDp4v968RibERGdJigyJmTPuWJs5kw2RieQPMWfcye5PvO2SCzGxOyjIt2fauz9N/bRh74WbDL5m+iRzJu/S4ebMjtgIc2b3vrHmTOtlIaa3Syqst0+PHvIv9h8nlTn2ic67Ouzn3ZI53zRnJCny/jZ7JsTPh0iOfTK/iu3nnSQFIabzZ/YftG3vOrq9LY+EAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMCbPjvANBhdriDa/UGA2T0f2tfIDfftB/Gh5ky2+bB9oWiIoYYR+3DHaEWpfR1JrsU+JDTddMicCUIch+iRVnNGktzxE+ZM3ju/NmeCwkJzJpu0f09FR0Meh+KEOXPLf/sf5sw//MuPzJltqSpzJm/Px+aMJLkR9gGw7vhxc8Y6IFSSIsPDDTBNjx9tzkQ/bjZtH7is1M25yDwSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABv+uwAU3fwI7kgr9vbR8tKzGukP9xvzoQVxLo/jPW0SLF9QGGYQanZEMMTJSkyzD7kMggxYDXIyzVn3JEWcyas7ImT5kwk6+zrtNkHY2Zbww0wzY4vN2dyt9oHuZ509uNwU8Eec+Z7D880ZyRp/J/sM2eCi8bYF9p3wBwpeM5+7CTpG+XPmjOLV/yxaftM6qT0tz/p1rY8EgIAeEMJAQC8MZfQhg0bNHPmTFVUVCgIAr3wwgtdvu6c05IlS1RRUaH8/HxNnz5dO3bs6Kn9BQAMIOYSamtr08SJE7V8+fKzfv2RRx7RsmXLtHz5cm3evFllZWW66aab1Bry/6YBAAOX+YUJtbW1qq2tPevXnHN6/PHH9cADD2jWrFmSpFWrVqm0tFTPPPOMvv3tb3+2vQUADCg9+pxQfX29GhsbVVNT03ldLBbTDTfcoI0bN541k0qllEwmu1wAAINDj5ZQY2OjJKm0tLTL9aWlpZ1f+6SlS5cqkUh0XiorK3tylwAAfVivvDouCLq+F8Q5d8Z1py1evFgtLS2dl4aGht7YJQBAH9Sjb1YtKyuTdOoRUXn5b97s1tTUdMajo9NisZhiId7ICQDo/3r0kVB1dbXKyspUV1fXeV17e7vWr1+vadOm9eRSAIABwPxI6NixY9q1a1fn3+vr6/XOO++ouLhYY8eO1cKFC/XQQw9p3LhxGjdunB566CEVFBToa1/7Wo/uOACg/zOX0Ntvv60ZM2Z0/n3RokWSpDlz5ujHP/6x7r//fp04cUL33HOPjhw5oilTpuj1119XPB7vub0GAAwIgXMhJgj2omQyqUQiod8r+rpyDANMVTLCvFZ2b7gBptEx9uGOmQ/tQ0KDIfbnyoKyUeaMQp4CQdsJcybd+FGotawi+fmhcmEGzWaP2weLRocPM2fcSfugVOWEfNq3eJg903TIHKlfeLk589zcvzFndnaMNGck6c/fuc2cKXx1qDlz3/32oaJfLgw3ePiDDvuzMH9561zT9ulMSmu3/bVaWlpUVFR0zm2ZHQcA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvevSTVXtSMKxIQcQw0ThrnwQdGVpozpxaK2tfK8RUYneszZwJTqTMmeyRo+aMJCkaNUeCPMNk9NPLVJSZM9lDh80ZSQpCnBNBe7s5447bJ5C7dNqciYT8CJXs/kZzJsyxq75hjznzo+ZrzZlIEG5S/NopK8yZzBT7Oj89frE58267/b4kSQ0d9k8ccDt2nX+j397edXR7Wx4JAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3fXaAqWttkwu6PwRPmYx5jey4SnNGkiK7D9hDUXvfR4rswyezw+yZSBCYM5KUKR1mX6v1pDnjmprNmWBshTkjSe7QEXMmEh9qX6fDcG6fVj3anjl6zJ6RFBQU2EMhhgg3PVVlzvzh/W+ZMzfk7zVnJOmtlH147p+uu8OcWT7jH8yZ5oz9vJOk7y/+A3MmPmy3aftItl061M1tzXsDAEAPoYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3fXaAafbYcWUNA0yDEANC0/GYOSNJsUSIwaKNTeZMx5TLzJncHfvMmewJ+1BRSYq0JC/IWkFerj2Ttg+0lSSlUuZIJsT3FCkqMmeC+v3mTGb8WHNGkiKtIe4bIQbNjp2zy5x56vdvMmeerLTfZyUpPcT+c+ULb9sHHH+3YqY58y9f/LE5I0l5R9PmjPXnaxB0f3seCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN312gGmQl6Mg6P7gyiDX/q3k/NsvzBlJUslIcyS4pMqcydtrHwipXPuwz9TEi+zrSMr791/ZQxPHmyOR/YfMmcyv95gzkhRJ2AeLRocPM2eybcfNmSCWZ85EDx42ZyQpvd8+hDMy4VJzZmyhfYDprxrsAzhj235pzkhSfmGhOZO6+vPmzIg/t58PL/zTOHNGkvI2vW/OZIPAtr1r7/a2PBICAHhDCQEAvDGX0IYNGzRz5kxVVFQoCAK98MILXb4+d+5cBUHQ5TJ16tSe2l8AwABiLqG2tjZNnDhRy5cv/9Rtbr75Zh08eLDz8sorr3ymnQQADEzmZ/Nra2tVW1t7zm1isZjKyspC7xQAYHDoleeE1q1bp5KSEo0fP1533nmnmpo+/aOtU6mUkslklwsAYHDo8RKqra3V008/rbVr1+qxxx7T5s2bdeONNyqVSp11+6VLlyqRSHReKisre3qXAAB9VI+/T2j27Nmdf54wYYImT56sqqoqvfzyy5o1a9YZ2y9evFiLFi3q/HsymaSIAGCQ6PU3q5aXl6uqqko7d+4869djsZhisVhv7wYAoA/q9fcJNTc3q6GhQeXl5b29FACgnzE/Ejp27Jh27frNqI36+nq98847Ki4uVnFxsZYsWaLbbrtN5eXl2rNnj/7iL/5CI0eO1K233tqjOw4A6P/MJfT2229rxowZnX8//XzOnDlztGLFCm3fvl2rV6/W0aNHVV5erhkzZmjNmjWKx+M9t9cAgAEhcM453zvx25LJpBKJhG78wp8pJ2p4rmjXHvtiIYZ9SpJr7/5wvtOi5aXmTLbJPrizfepl5kzs3XpzRpLUYR8kqTz7MQ+GDDFnXMp+G0lSNsRbBCLDEiEWCnG3GznMHAmOttrXkTTmxRZz5t3/O9GcGbrffjvlvLnNnAny880ZSYoUD7OHQpx7f/ZvdebMX//OfzFnpHCDcBWNmjZPZ9v1r00/UktLi4qKzj0UmNlxAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8KbXP1k1tGhw6tJNQdUY+xqH7ZOCJSnbdtyccbn2Qx2MLjNn8ja9b86cnGafvC1JUx/dbM5svdb+kR5ujH0CefDhR+aMJEXiQ+1rhZjGnj3UbM7o5ElzZNeT1fZ1JO38qT138T9usS80YZw5EuSEuC8VhJuirUzWHEmPLTFnKnLs086DCvv9QpKyu/eFypnWcB3d3pZHQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgTd8dYLq7QQryur25C7FEpMg+TFOSoqNGmDMNjwwxZzZM/pE5cyDT/aGvp+1o32HOSNJXCg+ZM3/15lXmzC9m2gfNpg8fNWckKSfEIFx3NGnOZFMpc+bI7N81Z/5m0ipzRpIee+rr5kyQZx/k6t7bZV9naKE5o/buD9TsIsRw2sMT7ENw7955hzkTCzmAOQgxTDlSZhvK6rIpqb6b/7Z5bwAA6CGUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8KbvDjCNRKSg+x0ZBPbBndljbeaMJEWKh5kzMy/6hTlTFLEPPW3MnDRnrortN2ckqTVrP+YLR7xpzswdc485E021mzOS5HKi9lDEfhxyxtoHpf7z/37UnLln9++bM5I09O295kwmnTZnXIc9E0qI4aqSlPnYPqQ3r9V+2x49Yb+vl1SEGOQqKZtfbs64t98zbZ9x3R8YyyMhAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCm7w4w7eiQLENJq+xDA9VwwJ6RlN7bYM78+59ONmd+vern5szXt3/DnLmmzD6sUpJG5B0zZ37y/iRzZvh4+6DG9ivHmTOSVPHiHnsoL88c2T230px5sfVyc8bNCXcXd+nj5kwk3z6EUzFnjgRD7eeDS9rPVUmKxIeaM21l9iG4z3/x782Z+R/dZs5IUpDJ2kOfv8S0eSSTkt7v5rb2vQEAoGdQQgAAb0wltHTpUl111VWKx+MqKSnRLbfcog8++KDLNs45LVmyRBUVFcrPz9f06dO1Y8eOHt1pAMDAYCqh9evXa968edq0aZPq6uqUTqdVU1OjtrbffDjcI488omXLlmn58uXavHmzysrKdNNNN6m1tbXHdx4A0L+ZnrV89dVXu/x95cqVKikp0ZYtW3T99dfLOafHH39cDzzwgGbNmiVJWrVqlUpLS/XMM8/o29/+ds/tOQCg3/tMzwm1tLRIkoqLiyVJ9fX1amxsVE1NTec2sVhMN9xwgzZu3HjWfyOVSimZTHa5AAAGh9Al5JzTokWLdO2112rChAmSpMbGRklSaWlpl21LS0s7v/ZJS5cuVSKR6LxUVtpfugoA6J9Cl9D8+fO1bds2/eQnPznja8En3t/jnDvjutMWL16slpaWzktDg/09OACA/inUO9kWLFigl156SRs2bNCYMb95k2hZWZmkU4+IysvLO69vamo649HRabFYTLFYLMxuAAD6OdMjIeec5s+fr+eee05r165VdXV1l69XV1errKxMdXV1nde1t7dr/fr1mjZtWs/sMQBgwDA9Epo3b56eeeYZvfjii4rH453P8yQSCeXn5ysIAi1cuFAPPfSQxo0bp3Hjxumhhx5SQUGBvva1r/XKNwAA6L9MJbRixQpJ0vTp07tcv3LlSs2dO1eSdP/99+vEiRO65557dOTIEU2ZMkWvv/664vF4j+wwAGDgCJxz9gmCvSiZTCqRSGjal76rnNzuD0TM//P95rW+f/E/mjOSdPdX7zZnFvzkn8yZiXmHzJmWrH144j+32IeKStK1Qz84/0af8OKRK82Zb438mTmz6cTF5owkrf7LmebMwesMg3b/07tffdycmT1lljmjTMaekaQc+9PF6QNnfwXsuUSHJ8wZdzJlzkRGFpszknTycyXmzIjv7jFnpg3/tTnz2tWjzRlJcum0PdPebto+7Tq0zr2glpYWFRUVnXNbZscBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAmz47RXtG7u8rJ8jtdm7Gfxwxr/W7+XvMGUk6mi0wZ4ZFjpszu9vtE3xvLPyVOTMqYp8CLUkfZ+2nTkFwYU63UdFwn9a7/oT9tg3jqliLOXPH52aYM0FenjkjSUFBvj104qQ5kk2FmIh9nqnMZ+NaW80ZSQqqxpx/o084dpl9YveGJ35ozvz3a+wT3yUp+3GzORMYP/067dr1r0dWMUUbANC3UUIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMCbHN878GkiVaMVMQyhfDdZaF4j7ADTy/MazZkOZ+/7vz5Qa84UjLEPhPxibL85I0mxIGPOjMm1305bUu3mzFsnR5gzknTVkAPmTEFgHwA76bl7zZnP5+0wZ1y7/dhJkjo6zJFgqP22jY4Ybs50VNgzOTvqzRlJcg328yE/YR/+ejxrv51c8pg5I0mKRs2R7LE22/au++cPj4QAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwJs+O8DUffSxXJDX7e1bbk+Y19jz+ihzRpKujB01Z447+7DP5y5dY868224fnlgQSZszkrSzwz4ktCFtPw5Hs/bb9oq8g+aMJP3sRJU589Wh9oG243/cas4omzVHIhePta8jSR32c8Id+Micab3uc+ZM/JeHzRkF4X7fDi4aY840XR03Z1Ynq82ZzJEj5owkRQoKzJloqe1npcumpG7OReaREADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB402cHmOqi0VI01u3NXdo+3PGf7vqv5owkvfDe5ebMd96qM2fyZB/2eXHOMXOmNGofeipJhzNt5kwikjJnLgqOmjNHs90ffvvbwgwj/caeGnMmsueAOROMsg+Mze7t5hTJT3AhBphGCu3nUdHP95gzrtg+0DYY0v2fJb8t86vd5kzrHxebM788UW7OREcUmTOSlD1mv98qany8YhgYyyMhAIA3lBAAwBtTCS1dulRXXXWV4vG4SkpKdMstt+iDDz7oss3cuXMVBEGXy9SpU3t0pwEAA4OphNavX6958+Zp06ZNqqurUzqdVk1Njdrauv4f480336yDBw92Xl555ZUe3WkAwMBgemHCq6++2uXvK1euVElJibZs2aLrr7++8/pYLKaysrKe2UMAwID1mZ4TamlpkSQVF3d9Nci6detUUlKi8ePH684771RTU9On/hupVErJZLLLBQAwOIQuIeecFi1apGuvvVYTJkzovL62tlZPP/201q5dq8cee0ybN2/WjTfeqFTq7C/NXbp0qRKJROelsrIy7C4BAPqZ0O8Tmj9/vrZt26Y333yzy/WzZ8/u/POECRM0efJkVVVV6eWXX9asWbPO+HcWL16sRYsWdf49mUxSRAAwSIQqoQULFuill17Shg0bNGbMmHNuW15erqqqKu3cufOsX4/FYorFwr2RDADQv5lKyDmnBQsW6Pnnn9e6detUXV193kxzc7MaGhpUXm5/RzAAYGAzPSc0b948PfXUU3rmmWcUj8fV2NioxsZGnThxQpJ07Ngx3Xffffr5z3+uPXv2aN26dZo5c6ZGjhypW2+9tVe+AQBA/2V6JLRixQpJ0vTp07tcv3LlSs2dO1fRaFTbt2/X6tWrdfToUZWXl2vGjBlas2aN4vF4j+00AGBgMP933Lnk5+frtdde+0w7BAAYPPrsFO0gnVXguj8ZO1U61LxG7oZ3zRlJcnn2Cc0PX/175ky21T4RO3nr75ozjdPO/cvFpxk/4UNz5oNfjjZnVt38Q3Pmmph9ArkkffH/LTBnin9pn+A+9MgmcyZqnWQsKTLCPtH5VDAwR9IN9sngkZP2qeo62mLPJMJNnA5C3Nczw+0TyF+vv9ScqTpZb86E1t5h2z7b/WPAAFMAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8CZw5xuNfYElk0klEgn93ohvKCfS/eGBwZAh5rUyjR+ZM5IUKSgwZ1x7uzkTFNrXUY59Jm328FH7OpIiRfahsWH2L8jNNWfcf37GldnIEAM/s/YBptmh+eZMpN4+MNZ12Idpnlrswvx+mv6dz5kzeXs+Nmdca6s5I0kK8anPLsTg4cjwYeZMer99YKwk5Vw01pw58blRpu3T6ZP6tze+q5aWFhUVnXt4LI+EAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN/ZBXr3s9Ci7dNY2ay3IBua1Mq7DnJGkiLPPgXMhMkE2xM0TZo5Z2ONgvI1OLWbfvyBExoXZN0nKpOyZMMc8Y//9L9x5F3J2nLtAs+PSJ82ZSNZ+G4W5/0mSQvxcCbNWmO8pHfJ+qzBrGW+ndPrUGt0ZTdrnBph++OGHqqys9L0bAIDPqKGhQWPGjDnnNn2uhLLZrA4cOKB4PK4g6PpbSDKZVGVlpRoaGs47mXUg4zicwnE4heNwCsfhlL5wHJxzam1tVUVFhSLnmcje5/47LhKJnLc5i4qKBvVJdhrH4RSOwykch1M4Dqf4Pg6JRKJb2/HCBACAN5QQAMCbflVCsVhMDz74oGIhPu1wIOE4nMJxOIXjcArH4ZT+dhz63AsTAACDR796JAQAGFgoIQCAN5QQAMAbSggA4E2/KqEnnnhC1dXVGjJkiCZNmqSf/exnvnfpglqyZImCIOhyKSsr871bvW7Dhg2aOXOmKioqFASBXnjhhS5fd85pyZIlqqioUH5+vqZPn64dO3b42dledL7jMHfu3DPOj6lTp/rZ2V6ydOlSXXXVVYrH4yopKdEtt9yiDz74oMs2g+F86M5x6C/nQ78poTVr1mjhwoV64IEHtHXrVl133XWqra3Vvn37fO/aBXX55Zfr4MGDnZft27f73qVe19bWpokTJ2r58uVn/fojjzyiZcuWafny5dq8ebPKysp00003qbW19QLvae8633GQpJtvvrnL+fHKK69cwD3sfevXr9e8efO0adMm1dXVKZ1Oq6amRm1tbZ3bDIbzoTvHQeon54PrJ66++mp31113dbnu0ksvdd/5znc87dGF9+CDD7qJEyf63g2vJLnnn3++8+/ZbNaVlZW5hx9+uPO6kydPukQi4X7wgx942MML45PHwTnn5syZ477yla942R9fmpqanCS3fv1659zgPR8+eRyc6z/nQ794JNTe3q4tW7aopqamy/U1NTXauHGjp73yY+fOnaqoqFB1dbVuv/127d692/cueVVfX6/GxsYu50YsFtMNN9ww6M4NSVq3bp1KSko0fvx43XnnnWpqavK9S72qpaVFklRcXCxp8J4PnzwOp/WH86FflNChQ4eUyWRUWlra5frS0lI1NjZ62qsLb8qUKVq9erVee+01Pfnkk2psbNS0adPU3Nzse9e8OX37D/ZzQ5Jqa2v19NNPa+3atXrssce0efNm3XjjjUqlQnxGUj/gnNOiRYt07bXXasKECZIG5/lwtuMg9Z/zoc9N0T6XT360g3PujOsGstra2s4/X3HFFbrmmmt0ySWXaNWqVVq0aJHHPfNvsJ8bkjR79uzOP0+YMEGTJ09WVVWVXn75Zc2aNcvjnvWO+fPna9u2bXrzzTfP+NpgOh8+7Tj0l/OhXzwSGjlypKLR6Bm/yTQ1NZ3xG89gUlhYqCuuuEI7d+70vSvenH51IOfGmcrLy1VVVTUgz48FCxbopZde0htvvNHlo18G2/nwacfhbPrq+dAvSigvL0+TJk1SXV1dl+vr6uo0bdo0T3vlXyqV0vvvv6/y8nLfu+JNdXW1ysrKupwb7e3tWr9+/aA+NySpublZDQ0NA+r8cM5p/vz5eu6557R27VpVV1d3+fpgOR/OdxzOps+eDx5fFGHy7LPPutzcXPd3f/d37r333nMLFy50hYWFbs+ePb537YK599573bp169zu3bvdpk2b3Je//GUXj8cH/DFobW11W7dudVu3bnWS3LJly9zWrVvd3r17nXPOPfzwwy6RSLjnnnvObd++3d1xxx2uvLzcJZNJz3ves851HFpbW929997rNm7c6Orr690bb7zhrrnmGjd69OgBdRzuvvtul0gk3Lp169zBgwc7L8ePH+/cZjCcD+c7Dv3pfOg3JeScc9///vddVVWVy8vLc1deeWWXlyMOBrNnz3bl5eUuNzfXVVRUuFmzZrkdO3b43q1e98YbbzhJZ1zmzJnjnDv1stwHH3zQlZWVuVgs5q6//nq3fft2vzvdC851HI4fP+5qamrcqFGjXG5urhs7dqybM2eO27dvn+/d7lFn+/4luZUrV3ZuMxjOh/Mdh/50PvBRDgAAb/rFc0IAgIGJEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN78f5Dq5Ts6VQe6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(xs.mean(dim=0)[i].squeeze().detach().cpu().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2029315-afe9-4ae8-9f64-c342ef8b830b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34a71d-84a2-48f0-8150-3607e77ed6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
