{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596d192c-de00-40b4-a8b3-25e6b01e1e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/shai_hulud/ppc_experiments\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94520ed3-45be-4735-a0f2-b8f380838c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import pyro\n",
    "import torch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "import trainer.trainer as module_trainer\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac4be4-19eb-4713-a88d-9bec118c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642d3c75-693c-4a96-b3cc-d42229ea74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75ea7b9-6fe5-4f8a-a825-3572e421242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab1445d1-45bb-43f9-893d-7a2b2bad1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "\n",
    "config = read_json(\"experiments/ppc_celeba_config.json\")\n",
    "config = ConfigParser(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca35026-5f64-47f8-98c7-a5e228013d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CelebAPpc(\n",
      "  (prior): GaussianPrior()\n",
      "  (likelihood): ConvolutionalDecoder(\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=40, out_features=256, bias=True)\n",
      "      (1): SiLU()\n",
      "    )\n",
      "    (convs): Sequential(\n",
      "      (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(1, 1))\n",
      "      (1): SiLU()\n",
      "      (2): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (3): SiLU()\n",
      "      (4): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (5): SiLU()\n",
      "      (6): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (7): SiLU()\n",
      "      (8): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (9): SiLU()\n",
      "      (10): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (graph): PpcGraphicalModel()\n",
      ")\n",
      "Trainable parameters: 454627\n",
      "Initialize particles: train batch 0\n",
      "Initialize particles: train batch 1\n",
      "Initialize particles: train batch 2\n",
      "Initialize particles: train batch 3\n",
      "Initialize particles: train batch 4\n",
      "Initialize particles: train batch 5\n",
      "Initialize particles: train batch 6\n",
      "Initialize particles: train batch 7\n",
      "Initialize particles: train batch 8\n",
      "Initialize particles: train batch 9\n",
      "Initialize particles: train batch 10\n",
      "Initialize particles: train batch 11\n",
      "Initialize particles: train batch 12\n",
      "Initialize particles: train batch 13\n",
      "Initialize particles: train batch 14\n",
      "Initialize particles: train batch 15\n",
      "Initialize particles: train batch 16\n",
      "Initialize particles: train batch 17\n",
      "Initialize particles: train batch 18\n",
      "Initialize particles: train batch 19\n",
      "Initialize particles: train batch 20\n",
      "Initialize particles: train batch 21\n",
      "Initialize particles: train batch 22\n",
      "Initialize particles: train batch 23\n",
      "Initialize particles: train batch 24\n",
      "Initialize particles: train batch 25\n",
      "Initialize particles: train batch 26\n",
      "Initialize particles: train batch 27\n",
      "Initialize particles: train batch 28\n",
      "Initialize particles: train batch 29\n",
      "Initialize particles: train batch 30\n",
      "Initialize particles: train batch 31\n",
      "Initialize particles: train batch 32\n",
      "Initialize particles: train batch 33\n",
      "Initialize particles: train batch 34\n",
      "Initialize particles: train batch 35\n",
      "Initialize particles: train batch 36\n",
      "Initialize particles: train batch 37\n",
      "Initialize particles: train batch 38\n",
      "Initialize particles: train batch 39\n",
      "Initialize particles: train batch 40\n",
      "Initialize particles: train batch 41\n",
      "Initialize particles: train batch 42\n",
      "Initialize particles: train batch 43\n",
      "Initialize particles: train batch 44\n",
      "Initialize particles: train batch 45\n",
      "Initialize particles: train batch 46\n",
      "Initialize particles: train batch 47\n",
      "Initialize particles: train batch 48\n",
      "Initialize particles: train batch 49\n",
      "Initialize particles: train batch 50\n",
      "Initialize particles: train batch 51\n",
      "Initialize particles: train batch 52\n",
      "Initialize particles: train batch 53\n",
      "Initialize particles: train batch 54\n",
      "Initialize particles: train batch 55\n",
      "Initialize particles: train batch 56\n",
      "Initialize particles: train batch 57\n",
      "Initialize particles: train batch 58\n",
      "Initialize particles: train batch 59\n",
      "Initialize particles: train batch 60\n",
      "Initialize particles: train batch 61\n",
      "Initialize particles: train batch 62\n",
      "Initialize particles: train batch 63\n",
      "Initialize particles: train batch 64\n",
      "Initialize particles: train batch 65\n",
      "Initialize particles: train batch 66\n",
      "Initialize particles: train batch 67\n",
      "Initialize particles: train batch 68\n",
      "Initialize particles: train batch 69\n",
      "Initialize particles: train batch 70\n",
      "Initialize particles: train batch 71\n",
      "Initialize particles: train batch 72\n",
      "Initialize particles: train batch 73\n",
      "Initialize particles: train batch 74\n",
      "Initialize particles: train batch 75\n",
      "Initialize particles: train batch 76\n",
      "Initialize particles: train batch 77\n",
      "Initialize particles: train batch 78\n",
      "Initialize particles: train batch 79\n",
      "Initialize particles: train batch 80\n",
      "Initialize particles: train batch 81\n",
      "Initialize particles: train batch 82\n",
      "Initialize particles: train batch 83\n",
      "Initialize particles: train batch 84\n",
      "Initialize particles: train batch 85\n",
      "Initialize particles: train batch 86\n",
      "Initialize particles: train batch 87\n",
      "Initialize particles: train batch 88\n",
      "Initialize particles: train batch 89\n",
      "Initialize particles: train batch 90\n",
      "Initialize particles: train batch 91\n",
      "Initialize particles: train batch 92\n",
      "Initialize particles: train batch 93\n",
      "Initialize particles: train batch 94\n",
      "Initialize particles: train batch 95\n",
      "Initialize particles: train batch 96\n",
      "Initialize particles: train batch 97\n",
      "Initialize particles: train batch 98\n",
      "Initialize particles: train batch 99\n",
      "Initialize particles: train batch 100\n",
      "Initialize particles: train batch 101\n",
      "Initialize particles: train batch 102\n",
      "Initialize particles: train batch 103\n",
      "Initialize particles: train batch 104\n",
      "Initialize particles: train batch 105\n",
      "Initialize particles: train batch 106\n",
      "Initialize particles: train batch 107\n",
      "Initialize particles: train batch 108\n",
      "Initialize particles: train batch 109\n",
      "Initialize particles: train batch 110\n",
      "Initialize particles: train batch 111\n",
      "Initialize particles: train batch 112\n",
      "Initialize particles: train batch 113\n",
      "Initialize particles: train batch 114\n",
      "Initialize particles: train batch 115\n",
      "Initialize particles: train batch 116\n",
      "Initialize particles: train batch 117\n",
      "Initialize particles: train batch 118\n",
      "Initialize particles: train batch 119\n",
      "Initialize particles: train batch 120\n",
      "Initialize particles: train batch 121\n",
      "Initialize particles: train batch 122\n",
      "Initialize particles: train batch 123\n",
      "Initialize particles: train batch 124\n",
      "Initialize particles: train batch 125\n",
      "Initialize particles: train batch 126\n",
      "Initialize particles: train batch 127\n",
      "Initialize particles: train batch 128\n",
      "Initialize particles: train batch 129\n",
      "Initialize particles: train batch 130\n",
      "Initialize particles: train batch 131\n",
      "Initialize particles: train batch 132\n",
      "Initialize particles: train batch 133\n",
      "Initialize particles: train batch 134\n",
      "Initialize particles: train batch 135\n",
      "Initialize particles: train batch 136\n",
      "Initialize particles: train batch 137\n",
      "Initialize particles: train batch 138\n",
      "Initialize particles: train batch 139\n",
      "Initialize particles: train batch 140\n",
      "Initialize particles: train batch 141\n",
      "Initialize particles: train batch 142\n",
      "Initialize particles: train batch 143\n",
      "Initialize particles: valid batch 0\n",
      "Initialize particles: valid batch 1\n",
      "Initialize particles: valid batch 2\n",
      "Initialize particles: valid batch 3\n",
      "Initialize particles: valid batch 4\n",
      "Initialize particles: valid batch 5\n",
      "Initialize particles: valid batch 6\n",
      "Initialize particles: valid batch 7\n",
      "Initialize particles: valid batch 8\n",
      "Initialize particles: valid batch 9\n",
      "Initialize particles: valid batch 10\n",
      "Initialize particles: valid batch 11\n",
      "Initialize particles: valid batch 12\n",
      "Initialize particles: valid batch 13\n",
      "Initialize particles: valid batch 14\n",
      "Initialize particles: valid batch 15\n",
      "Loading checkpoint: saved/models/CelebA_Ppc/0503_230620/checkpoint-epoch250.pth ...\n",
      "Checkpoint loaded. Resume training from epoch 251\n"
     ]
    }
   ],
   "source": [
    "logger = config.get_logger('train')\n",
    "\n",
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()\n",
    "\n",
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)\n",
    "logger.info(model)\n",
    "\n",
    "# get function handles of metrics\n",
    "metrics = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# build optimizer.\n",
    "optimizer = config.init_obj('optimizer', pyro.optim)\n",
    "\n",
    "# build trainer\n",
    "# kwargs = config['trainer'].pop('args')\n",
    "trainer = config.init_obj('trainer', module_trainer, model, metrics, optimizer,\n",
    "                          config=config, data_loader=data_loader,\n",
    "                          valid_data_loader=valid_data_loader,\n",
    "                          lr_scheduler=None)\n",
    "\n",
    "trainer._resume_checkpoint(\"saved/models/CelebA_Ppc/0503_230620/checkpoint-epoch250.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa5b900-0121-4cf6-91b6-2c9b0b12716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParticleDict(  (z): Parameter containing: [torch.FloatTensor of size 2x16277x40])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.eval()\n",
    "trainer.cpu()\n",
    "trainer.valid_particles.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8f27b30-f96c-4b88-8915-c90b844f7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in trainer.model.graph.nodes:\n",
    "    trainer.model.graph.nodes[site]['is_observed'] = trainer.model.graph.nodes[site]['value'] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ba74ac-4973-49b2-8f08-89364422027a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000"
     ]
    }
   ],
   "source": [
    "xs, _, indices = list(trainer.valid_data_loader)[0]\n",
    "trainer._load_particles(indices, False)\n",
    "with pyro.plate_stack(\"forward\", (trainer.num_particles, len(xs))):\n",
    "    model = pyro.condition(trainer.model, data={k: v['value'] for k, v in trainer.model.graph.nodes.items()})\n",
    "    x_hats = model().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c76257-aef8-40e3-934a-a1e534924256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f750bfb2-80aa-4fad-885e-752772706a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=8, sharex=\"all\", sharey=\"all\", layout=\"compressed\")\n",
    "\n",
    "for i in range(8):\n",
    "    orgs = xs[i].squeeze().detach().transpose(0, -1)\n",
    "    estimates = x_hats[i].squeeze().detach().transpose(0, -1)\n",
    "    axes[0, i].imshow(orgs)\n",
    "    axes[1, i].imshow(estimates)\n",
    "\n",
    "fig.savefig(\"ppc_celeba_recons.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f8050d-f8c0-440a-9bbd-d7fb8a904249",
   "metadata": {},
   "outputs": [],
   "source": [
    "del xs\n",
    "del x_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cbde7-57f0-48fb-956e-7ab6016f34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in trainer.model.graph.nodes:\n",
    "    trainer.model.graph.unclamp(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c48c964-fc69-4cad-bfe5-e456ac545d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate_stack(\"forward\", (trainer.num_particles, 8)):\n",
    "    x_hats = trainer.model().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d52c91-326b-469a-954d-ca5b4e4c67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=8, sharex=\"all\", sharey=\"all\", layout=\"compressed\")\n",
    "\n",
    "for i in range(8):\n",
    "    estimates = x_hats[i].squeeze().detach().transpose(0, -1)\n",
    "    axes[i].imshow(estimates)\n",
    "\n",
    "fig.savefig(\"ppc_celeba_samples.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e8aef-77f3-483a-a4b8-b36b01fdffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7657733f-5780-47fc-a10e-a01fbac6b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [123, 456, 789, 101112, 131415]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d66fc2-7539-4ef9-ad74-1cc77a0e8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_LIKELIHOODS = torch.zeros(len(SEEDS), requires_grad=False)\n",
    "MEAN_SQUARED_ERROR = torch.zeros(len(SEEDS), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f3a60-5009-4238-9c1b-f1a2e7797546",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (s, SEED) in enumerate(SEEDS):\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    for b, (xs, target, indices) in enumerate(trainer.valid_data_loader):\n",
    "        trainer._load_particles(indices, False)\n",
    "    \n",
    "        with pyro.plate_stack(\"forward\", (trainer.num_particles, len(xs))):\n",
    "            model = pyro.condition(trainer.model, data={k: v['value'] for k, v in trainer.model.graph.nodes.items()})\n",
    "            trace = pyro.poutine.trace(model).get_trace()\n",
    "            x_hats = trace.nodes['X']['value'].mean(dim=0)\n",
    "        LOG_LIKELIHOODS[s] += trace.nodes['X']['fn'].log_prob(xs).sum()\n",
    "        MEAN_SQUARED_ERROR[s] += ((xs - x_hats) ** 2).sum(dim=0).mean()\n",
    "\n",
    "        del xs\n",
    "        del x_hats\n",
    "        logger.info(\"Evaluated likelihood for valid batch %d under seed %s\" % (b, s))\n",
    "\n",
    "    LOG_LIKELIHOODS[s] /= len(trainer.valid_data_loader.sampler)\n",
    "    MEAN_SQUARED_ERROR[s] /= len(trainer.valid_data_loader.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23203c5d-e7f0-4f5d-868b-a0ba77d1b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_LIKELIHOODS.mean(), LOG_LIKELIHOODS.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce608df3-f41d-4637-862c-7a825403f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_SQUARED_ERROR.mean(), MEAN_SQUARED_ERROR.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d787fd1-48f0-4ae8-82ae-fae7bffbc98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
