{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ef93e3-8eb5-4883-8265-5fbe97d06e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/ppc_experiments\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94520ed3-45be-4735-a0f2-b8f380838c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import pyro\n",
    "import torch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "import trainer.trainer as module_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac4be4-19eb-4713-a88d-9bec118c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75ea7b9-6fe5-4f8a-a825-3572e421242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1445d1-45bb-43f9-893d-7a2b2bad1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "\n",
    "config = read_json(\"experiments/ppc_mnist_config.json\")\n",
    "config = ConfigParser(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca35026-5f64-47f8-98c7-a5e228013d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistPpc(\n",
      "  (prior): GaussianPrior()\n",
      "  (decoder1): ConditionalGaussian(\n",
      "    (decoder): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=20, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder2): ConditionalGaussian(\n",
      "    (decoder): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (likelihood): MlpBernoulliLikelihood(\n",
      "    (decoder): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=256, out_features=784, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (graph): PpcGraphicalModel()\n",
      ")\n",
      "Trainable parameters: 319540\n",
      "Initialize particles: train batch 0\n",
      "Initialize particles: train batch 1\n",
      "Initialize particles: train batch 2\n",
      "Initialize particles: train batch 3\n",
      "Initialize particles: train batch 4\n",
      "Initialize particles: train batch 5\n",
      "Initialize particles: train batch 6\n",
      "Initialize particles: train batch 7\n",
      "Initialize particles: train batch 8\n",
      "Initialize particles: train batch 9\n",
      "Initialize particles: train batch 10\n",
      "Initialize particles: train batch 11\n",
      "Initialize particles: train batch 12\n",
      "Initialize particles: train batch 13\n",
      "Initialize particles: train batch 14\n",
      "Initialize particles: train batch 15\n",
      "Initialize particles: train batch 16\n",
      "Initialize particles: train batch 17\n",
      "Initialize particles: train batch 18\n",
      "Initialize particles: train batch 19\n",
      "Initialize particles: train batch 20\n",
      "Initialize particles: train batch 21\n",
      "Initialize particles: train batch 22\n",
      "Initialize particles: train batch 23\n",
      "Initialize particles: train batch 24\n",
      "Initialize particles: train batch 25\n",
      "Initialize particles: train batch 26\n",
      "Initialize particles: train batch 27\n",
      "Initialize particles: train batch 28\n",
      "Initialize particles: train batch 29\n",
      "Initialize particles: train batch 30\n",
      "Initialize particles: train batch 31\n",
      "Initialize particles: train batch 32\n",
      "Initialize particles: train batch 33\n",
      "Initialize particles: train batch 34\n",
      "Initialize particles: train batch 35\n",
      "Initialize particles: train batch 36\n",
      "Initialize particles: train batch 37\n",
      "Initialize particles: train batch 38\n",
      "Initialize particles: train batch 39\n",
      "Initialize particles: train batch 40\n",
      "Initialize particles: train batch 41\n",
      "Initialize particles: train batch 42\n",
      "Initialize particles: train batch 43\n",
      "Initialize particles: train batch 44\n",
      "Initialize particles: train batch 45\n",
      "Initialize particles: train batch 46\n",
      "Initialize particles: train batch 47\n",
      "Initialize particles: train batch 48\n",
      "Initialize particles: train batch 49\n",
      "Initialize particles: train batch 50\n",
      "Initialize particles: train batch 51\n",
      "Initialize particles: train batch 52\n",
      "Initialize particles: train batch 53\n",
      "Initialize particles: train batch 54\n",
      "Initialize particles: train batch 55\n",
      "Initialize particles: train batch 56\n",
      "Initialize particles: train batch 57\n",
      "Initialize particles: train batch 58\n",
      "Initialize particles: train batch 59\n",
      "Initialize particles: train batch 60\n",
      "Initialize particles: train batch 61\n",
      "Initialize particles: train batch 62\n",
      "Initialize particles: train batch 63\n",
      "Initialize particles: train batch 64\n",
      "Initialize particles: train batch 65\n",
      "Initialize particles: train batch 66\n",
      "Initialize particles: train batch 67\n",
      "Initialize particles: train batch 68\n",
      "Initialize particles: train batch 69\n",
      "Initialize particles: train batch 70\n",
      "Initialize particles: train batch 71\n",
      "Initialize particles: train batch 72\n",
      "Initialize particles: train batch 73\n",
      "Initialize particles: train batch 74\n",
      "Initialize particles: train batch 75\n",
      "Initialize particles: train batch 76\n",
      "Initialize particles: train batch 77\n",
      "Initialize particles: train batch 78\n",
      "Initialize particles: train batch 79\n",
      "Initialize particles: train batch 80\n",
      "Initialize particles: train batch 81\n",
      "Initialize particles: train batch 82\n",
      "Initialize particles: train batch 83\n",
      "Initialize particles: train batch 84\n",
      "Initialize particles: train batch 85\n",
      "Initialize particles: train batch 86\n",
      "Initialize particles: train batch 87\n",
      "Initialize particles: train batch 88\n",
      "Initialize particles: train batch 89\n",
      "Initialize particles: train batch 90\n",
      "Initialize particles: train batch 91\n",
      "Initialize particles: train batch 92\n",
      "Initialize particles: train batch 93\n",
      "Initialize particles: train batch 94\n",
      "Initialize particles: train batch 95\n",
      "Initialize particles: train batch 96\n",
      "Initialize particles: train batch 97\n",
      "Initialize particles: train batch 98\n",
      "Initialize particles: train batch 99\n",
      "Initialize particles: train batch 100\n",
      "Initialize particles: train batch 101\n",
      "Initialize particles: train batch 102\n",
      "Initialize particles: train batch 103\n",
      "Initialize particles: train batch 104\n",
      "Initialize particles: train batch 105\n",
      "Initialize particles: train batch 106\n",
      "Initialize particles: train batch 107\n",
      "Initialize particles: train batch 108\n",
      "Initialize particles: train batch 109\n",
      "Initialize particles: train batch 110\n",
      "Initialize particles: train batch 111\n",
      "Initialize particles: train batch 112\n",
      "Initialize particles: train batch 113\n",
      "Initialize particles: train batch 114\n",
      "Initialize particles: train batch 115\n",
      "Initialize particles: train batch 116\n",
      "Initialize particles: train batch 117\n",
      "Initialize particles: train batch 118\n",
      "Initialize particles: train batch 119\n",
      "Initialize particles: train batch 120\n",
      "Initialize particles: train batch 121\n",
      "Initialize particles: train batch 122\n",
      "Initialize particles: train batch 123\n",
      "Initialize particles: train batch 124\n",
      "Initialize particles: train batch 125\n",
      "Initialize particles: train batch 126\n",
      "Initialize particles: train batch 127\n",
      "Initialize particles: train batch 128\n",
      "Initialize particles: train batch 129\n",
      "Initialize particles: train batch 130\n",
      "Initialize particles: train batch 131\n",
      "Initialize particles: train batch 132\n",
      "Initialize particles: train batch 133\n",
      "Initialize particles: train batch 134\n",
      "Initialize particles: train batch 135\n",
      "Initialize particles: train batch 136\n",
      "Initialize particles: train batch 137\n",
      "Initialize particles: train batch 138\n",
      "Initialize particles: train batch 139\n",
      "Initialize particles: train batch 140\n",
      "Initialize particles: train batch 141\n",
      "Initialize particles: train batch 142\n",
      "Initialize particles: train batch 143\n",
      "Initialize particles: train batch 144\n",
      "Initialize particles: train batch 145\n",
      "Initialize particles: train batch 146\n",
      "Initialize particles: train batch 147\n",
      "Initialize particles: train batch 148\n",
      "Initialize particles: train batch 149\n",
      "Initialize particles: train batch 150\n",
      "Initialize particles: train batch 151\n",
      "Initialize particles: train batch 152\n",
      "Initialize particles: train batch 153\n",
      "Initialize particles: train batch 154\n",
      "Initialize particles: train batch 155\n",
      "Initialize particles: train batch 156\n",
      "Initialize particles: train batch 157\n",
      "Initialize particles: train batch 158\n",
      "Initialize particles: train batch 159\n",
      "Initialize particles: train batch 160\n",
      "Initialize particles: train batch 161\n",
      "Initialize particles: train batch 162\n",
      "Initialize particles: train batch 163\n",
      "Initialize particles: train batch 164\n",
      "Initialize particles: train batch 165\n",
      "Initialize particles: train batch 166\n",
      "Initialize particles: train batch 167\n",
      "Initialize particles: train batch 168\n",
      "Initialize particles: train batch 169\n",
      "Initialize particles: train batch 170\n",
      "Initialize particles: train batch 171\n",
      "Initialize particles: train batch 172\n",
      "Initialize particles: train batch 173\n",
      "Initialize particles: train batch 174\n",
      "Initialize particles: train batch 175\n",
      "Initialize particles: train batch 176\n",
      "Initialize particles: train batch 177\n",
      "Initialize particles: train batch 178\n",
      "Initialize particles: train batch 179\n",
      "Initialize particles: train batch 180\n",
      "Initialize particles: train batch 181\n",
      "Initialize particles: train batch 182\n",
      "Initialize particles: train batch 183\n",
      "Initialize particles: train batch 184\n",
      "Initialize particles: train batch 185\n",
      "Initialize particles: train batch 186\n",
      "Initialize particles: train batch 187\n",
      "Initialize particles: train batch 188\n",
      "Initialize particles: train batch 189\n",
      "Initialize particles: train batch 190\n",
      "Initialize particles: train batch 191\n",
      "Initialize particles: train batch 192\n",
      "Initialize particles: train batch 193\n",
      "Initialize particles: train batch 194\n",
      "Initialize particles: train batch 195\n",
      "Initialize particles: train batch 196\n",
      "Initialize particles: train batch 197\n",
      "Initialize particles: train batch 198\n",
      "Initialize particles: train batch 199\n",
      "Initialize particles: train batch 200\n",
      "Initialize particles: train batch 201\n",
      "Initialize particles: train batch 202\n",
      "Initialize particles: train batch 203\n",
      "Initialize particles: train batch 204\n",
      "Initialize particles: train batch 205\n",
      "Initialize particles: train batch 206\n",
      "Initialize particles: train batch 207\n",
      "Initialize particles: train batch 208\n",
      "Initialize particles: train batch 209\n",
      "Initialize particles: train batch 210\n",
      "Initialize particles: valid batch 0\n",
      "Initialize particles: valid batch 1\n",
      "Initialize particles: valid batch 2\n",
      "Initialize particles: valid batch 3\n",
      "Initialize particles: valid batch 4\n",
      "Initialize particles: valid batch 5\n",
      "Initialize particles: valid batch 6\n",
      "Initialize particles: valid batch 7\n",
      "Initialize particles: valid batch 8\n",
      "Initialize particles: valid batch 9\n",
      "Initialize particles: valid batch 10\n",
      "Initialize particles: valid batch 11\n",
      "Initialize particles: valid batch 12\n",
      "Initialize particles: valid batch 13\n",
      "Initialize particles: valid batch 14\n",
      "Initialize particles: valid batch 15\n",
      "Initialize particles: valid batch 16\n",
      "Initialize particles: valid batch 17\n",
      "Initialize particles: valid batch 18\n",
      "Initialize particles: valid batch 19\n",
      "Initialize particles: valid batch 20\n",
      "Initialize particles: valid batch 21\n",
      "Initialize particles: valid batch 22\n",
      "Initialize particles: valid batch 23\n"
     ]
    }
   ],
   "source": [
    "logger = config.get_logger('train')\n",
    "\n",
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()\n",
    "\n",
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)\n",
    "logger.info(model)\n",
    "\n",
    "# get function handles of metrics\n",
    "metrics = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# build optimizer.\n",
    "if \"lr_scheduler\" in config:\n",
    "    lr_scheduler = getattr(pyro.optim, config[\"lr_scheduler\"][\"type\"])\n",
    "    lr_scheduler = optimizer = lr_scheduler({\n",
    "        \"optimizer\": getattr(torch.optim, config[\"optimizer\"][\"type\"]),\n",
    "        \"optim_args\": config[\"optimizer\"][\"args\"][\"optim_args\"],\n",
    "        **config[\"lr_scheduler\"][\"args\"]\n",
    "    })\n",
    "else:\n",
    "    optimizer = config.init_obj('optimizer', pyro.optim)\n",
    "    lr_scheduler = None\n",
    "\n",
    "# build trainer\n",
    "# kwargs = config['trainer'].pop('args')\n",
    "trainer = config.init_obj('trainer', module_trainer, model, metrics, optimizer,\n",
    "                          config=config, data_loader=data_loader,\n",
    "                          valid_data_loader=valid_data_loader,\n",
    "                          lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5cdd31-7fae-4e6f-8fe2-ef5c023919de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved/log/Mnist_Ppc/0327_194126\n"
     ]
    }
   ],
   "source": [
    "logger.info(trainer.config.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820b982-1a39-4bde-850e-1a1d9a92557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/54000 (0%)] Loss: 767.783508\n",
      "Train Epoch: 1 [4096/54000 (8%)] Loss: -504.366394\n",
      "Train Epoch: 1 [8192/54000 (15%)] Loss: -561.750488\n",
      "Train Epoch: 1 [12288/54000 (23%)] Loss: -597.216248\n",
      "Train Epoch: 1 [16384/54000 (30%)] Loss: -603.443420\n",
      "Train Epoch: 1 [20480/54000 (38%)] Loss: -641.130493\n",
      "Train Epoch: 1 [24576/54000 (46%)] Loss: -645.749573\n",
      "Train Epoch: 1 [28672/54000 (53%)] Loss: -702.476318\n",
      "Train Epoch: 1 [32768/54000 (61%)] Loss: -710.776550\n",
      "Train Epoch: 1 [36864/54000 (68%)] Loss: -727.786621\n",
      "Train Epoch: 1 [40960/54000 (76%)] Loss: -759.938354\n",
      "Train Epoch: 1 [45056/54000 (83%)] Loss: -793.577148\n",
      "Train Epoch: 1 [49152/54000 (91%)] Loss: -793.875183\n",
      "Train Epoch: 1 [53248/54000 (99%)] Loss: -828.922119\n",
      "    epoch          : 1\n",
      "    loss           : -647.0783520468038\n",
      "    ess            : 3.8803834474482244\n",
      "    log_marginal   : 647.1240250646221\n",
      "    val_loss       : -805.2631200154623\n",
      "    val_ess        : 3.8806121249993644\n",
      "    val_log_marginal: 805.3075307210287\n",
      "Train Epoch: 2 [0/54000 (0%)] Loss: -828.087830\n",
      "Train Epoch: 2 [4096/54000 (8%)] Loss: -828.411133\n",
      "Train Epoch: 2 [8192/54000 (15%)] Loss: -860.679199\n",
      "Train Epoch: 2 [12288/54000 (23%)] Loss: -856.606812\n",
      "Train Epoch: 2 [16384/54000 (30%)] Loss: -849.785889\n",
      "Train Epoch: 2 [20480/54000 (38%)] Loss: -859.962158\n",
      "Train Epoch: 2 [24576/54000 (46%)] Loss: -877.042297\n",
      "Train Epoch: 2 [28672/54000 (53%)] Loss: -877.208984\n",
      "Train Epoch: 2 [32768/54000 (61%)] Loss: -901.834167\n",
      "Train Epoch: 2 [36864/54000 (68%)] Loss: -878.364624\n",
      "Train Epoch: 2 [40960/54000 (76%)] Loss: -908.031311\n",
      "Train Epoch: 2 [45056/54000 (83%)] Loss: -902.186157\n",
      "Train Epoch: 2 [49152/54000 (91%)] Loss: -913.147339\n",
      "Train Epoch: 2 [53248/54000 (99%)] Loss: -913.533325\n",
      "    epoch          : 2\n",
      "    loss           : -875.4098186764107\n",
      "    ess            : 3.8780529860636634\n",
      "    log_marginal   : 875.4556199204865\n",
      "    val_loss       : -923.991091410319\n",
      "    val_ess        : 3.861002564430237\n",
      "    val_log_marginal: 924.0440673828125\n",
      "Train Epoch: 3 [0/54000 (0%)] Loss: -944.999817\n",
      "Train Epoch: 3 [4096/54000 (8%)] Loss: -962.749207\n",
      "Train Epoch: 3 [8192/54000 (15%)] Loss: -940.303955\n",
      "Train Epoch: 3 [12288/54000 (23%)] Loss: -957.730347\n",
      "Train Epoch: 3 [16384/54000 (30%)] Loss: -956.538513\n",
      "Train Epoch: 3 [20480/54000 (38%)] Loss: -966.272400\n",
      "Train Epoch: 3 [24576/54000 (46%)] Loss: -956.533630\n",
      "Train Epoch: 3 [28672/54000 (53%)] Loss: -976.297119\n",
      "Train Epoch: 3 [32768/54000 (61%)] Loss: -959.707031\n",
      "Train Epoch: 3 [36864/54000 (68%)] Loss: -962.531372\n",
      "Train Epoch: 3 [40960/54000 (76%)] Loss: -975.101440\n",
      "Train Epoch: 3 [45056/54000 (83%)] Loss: -986.260803\n",
      "Train Epoch: 3 [49152/54000 (91%)] Loss: -986.763000\n",
      "Train Epoch: 3 [53248/54000 (99%)] Loss: -987.506958\n",
      "    epoch          : 3\n",
      "    loss           : -967.4436850886774\n",
      "    ess            : 3.8696132723189076\n",
      "    log_marginal   : 967.4922303113892\n",
      "    val_loss       : -994.2424341837565\n",
      "    val_ess        : 3.8775921165943146\n",
      "    val_log_marginal: 994.2884928385416\n",
      "Train Epoch: 4 [0/54000 (0%)] Loss: -1007.866333\n",
      "Train Epoch: 4 [4096/54000 (8%)] Loss: -1003.760010\n",
      "Train Epoch: 4 [8192/54000 (15%)] Loss: -1009.072937\n",
      "Train Epoch: 4 [12288/54000 (23%)] Loss: -1022.930908\n",
      "Train Epoch: 4 [16384/54000 (30%)] Loss: -1014.069458\n",
      "Train Epoch: 4 [20480/54000 (38%)] Loss: -1017.157532\n",
      "Train Epoch: 4 [24576/54000 (46%)] Loss: -1023.905029\n",
      "Train Epoch: 4 [28672/54000 (53%)] Loss: -1027.002197\n",
      "Train Epoch: 4 [32768/54000 (61%)] Loss: -1034.918701\n",
      "Train Epoch: 4 [36864/54000 (68%)] Loss: -1023.914612\n",
      "Train Epoch: 4 [40960/54000 (76%)] Loss: -1030.886475\n",
      "Train Epoch: 4 [45056/54000 (83%)] Loss: -1036.373901\n",
      "Train Epoch: 4 [49152/54000 (91%)] Loss: -1031.939209\n",
      "Train Epoch: 4 [53248/54000 (99%)] Loss: -1014.455078\n",
      "    epoch          : 4\n",
      "    loss           : -1022.7254132456125\n",
      "    ess            : 3.8629318108490858\n",
      "    log_marginal   : 1022.7773385432095\n",
      "    val_loss       : -1038.3155314127605\n",
      "    val_ess        : 3.8620196481545768\n",
      "    val_log_marginal: 1038.3652598063152\n",
      "Train Epoch: 5 [0/54000 (0%)] Loss: -1048.680664\n",
      "Train Epoch: 5 [4096/54000 (8%)] Loss: -1053.125732\n",
      "Train Epoch: 5 [8192/54000 (15%)] Loss: -1050.229736\n",
      "Train Epoch: 5 [12288/54000 (23%)] Loss: -1049.480225\n",
      "Train Epoch: 5 [16384/54000 (30%)] Loss: -1066.131470\n",
      "Train Epoch: 5 [20480/54000 (38%)] Loss: -1051.444092\n",
      "Train Epoch: 5 [24576/54000 (46%)] Loss: -1064.297974\n",
      "Train Epoch: 5 [28672/54000 (53%)] Loss: -1057.575317\n",
      "Train Epoch: 5 [32768/54000 (61%)] Loss: -1059.755981\n",
      "Train Epoch: 5 [36864/54000 (68%)] Loss: -1052.546387\n",
      "Train Epoch: 5 [40960/54000 (76%)] Loss: -1066.037231\n",
      "Train Epoch: 5 [45056/54000 (83%)] Loss: -1064.463623\n",
      "Train Epoch: 5 [49152/54000 (91%)] Loss: -1060.168701\n",
      "Train Epoch: 5 [53248/54000 (99%)] Loss: -1064.643555\n",
      "    epoch          : 5\n",
      "    loss           : -1057.9552968102043\n",
      "    ess            : 3.857174621374121\n",
      "    log_marginal   : 1058.0097176068202\n",
      "    val_loss       : -1066.8158111572266\n",
      "    val_ess        : 3.8617833256721497\n",
      "    val_log_marginal: 1066.8684895833333\n",
      "Train Epoch: 6 [0/54000 (0%)] Loss: -1075.029907\n",
      "Train Epoch: 6 [4096/54000 (8%)] Loss: -1082.777344\n",
      "Train Epoch: 6 [8192/54000 (15%)] Loss: -1070.765869\n",
      "Train Epoch: 6 [12288/54000 (23%)] Loss: -1073.249268\n",
      "Train Epoch: 6 [16384/54000 (30%)] Loss: -1076.176025\n",
      "Train Epoch: 6 [20480/54000 (38%)] Loss: -1082.700439\n",
      "Train Epoch: 6 [24576/54000 (46%)] Loss: -1079.577881\n",
      "Train Epoch: 6 [28672/54000 (53%)] Loss: -1091.964233\n",
      "Train Epoch: 6 [32768/54000 (61%)] Loss: -1084.869629\n",
      "Train Epoch: 6 [36864/54000 (68%)] Loss: -1081.631714\n",
      "Train Epoch: 6 [40960/54000 (76%)] Loss: -1083.688721\n",
      "Train Epoch: 6 [45056/54000 (83%)] Loss: -1091.929932\n",
      "Train Epoch: 6 [49152/54000 (91%)] Loss: -1085.713989\n",
      "Train Epoch: 6 [53248/54000 (99%)] Loss: -1085.749146\n",
      "    epoch          : 6\n",
      "    loss           : -1081.4045907694017\n",
      "    ess            : 3.8491753537507982\n",
      "    log_marginal   : 1081.4620922504444\n",
      "    val_loss       : -1086.637201944987\n",
      "    val_ess        : 3.8380805353323617\n",
      "    val_log_marginal: 1086.699722290039\n",
      "Train Epoch: 7 [0/54000 (0%)] Loss: -1093.657715\n",
      "Train Epoch: 7 [4096/54000 (8%)] Loss: -1093.039307\n",
      "Train Epoch: 7 [8192/54000 (15%)] Loss: -1098.415039\n",
      "Train Epoch: 7 [12288/54000 (23%)] Loss: -1098.587524\n",
      "Train Epoch: 7 [16384/54000 (30%)] Loss: -1091.611694\n",
      "Train Epoch: 7 [20480/54000 (38%)] Loss: -1107.746338\n",
      "Train Epoch: 7 [24576/54000 (46%)] Loss: -1095.788330\n",
      "Train Epoch: 7 [28672/54000 (53%)] Loss: -1094.853760\n",
      "Train Epoch: 7 [32768/54000 (61%)] Loss: -1093.982422\n",
      "Train Epoch: 7 [36864/54000 (68%)] Loss: -1099.349243\n",
      "Train Epoch: 7 [40960/54000 (76%)] Loss: -1091.710083\n",
      "Train Epoch: 7 [45056/54000 (83%)] Loss: -1090.325562\n",
      "Train Epoch: 7 [49152/54000 (91%)] Loss: -1096.222168\n",
      "Train Epoch: 7 [53248/54000 (99%)] Loss: -1097.979126\n",
      "    epoch          : 7\n",
      "    loss           : -1098.1493255470602\n",
      "    ess            : 3.8387950596651197\n",
      "    log_marginal   : 1098.2118544736745\n",
      "    val_loss       : -1101.3496348063152\n",
      "    val_ess        : 3.850298603375753\n",
      "    val_log_marginal: 1101.4073282877605\n",
      "Train Epoch: 8 [0/54000 (0%)] Loss: -1110.600342\n",
      "Train Epoch: 8 [4096/54000 (8%)] Loss: -1113.673096\n",
      "Train Epoch: 8 [8192/54000 (15%)] Loss: -1105.073730\n",
      "Train Epoch: 8 [12288/54000 (23%)] Loss: -1113.584351\n",
      "Train Epoch: 8 [16384/54000 (30%)] Loss: -1112.109131\n",
      "Train Epoch: 8 [20480/54000 (38%)] Loss: -1104.948364\n",
      "Train Epoch: 8 [24576/54000 (46%)] Loss: -1102.427246\n",
      "Train Epoch: 8 [28672/54000 (53%)] Loss: -1112.782837\n",
      "Train Epoch: 8 [32768/54000 (61%)] Loss: -1105.120117\n",
      "Train Epoch: 8 [36864/54000 (68%)] Loss: -1102.212646\n",
      "Train Epoch: 8 [40960/54000 (76%)] Loss: -1121.908936\n",
      "Train Epoch: 8 [45056/54000 (83%)] Loss: -1115.394287\n",
      "Train Epoch: 8 [49152/54000 (91%)] Loss: -1110.224365\n",
      "Train Epoch: 8 [53248/54000 (99%)] Loss: -1103.013550\n",
      "    epoch          : 8\n",
      "    loss           : -1110.934327907472\n",
      "    ess            : 3.8289571893158683\n",
      "    log_marginal   : 1111.0014955059612\n",
      "    val_loss       : -1112.0930633544922\n",
      "    val_ess        : 3.832959830760956\n",
      "    val_log_marginal: 1112.158711751302\n",
      "Train Epoch: 9 [0/54000 (0%)] Loss: -1116.389038\n",
      "Train Epoch: 9 [4096/54000 (8%)] Loss: -1118.075806\n",
      "Train Epoch: 9 [8192/54000 (15%)] Loss: -1120.299561\n",
      "Train Epoch: 9 [12288/54000 (23%)] Loss: -1116.315308\n",
      "Train Epoch: 9 [16384/54000 (30%)] Loss: -1119.391479\n",
      "Train Epoch: 9 [20480/54000 (38%)] Loss: -1120.548096\n",
      "Train Epoch: 9 [24576/54000 (46%)] Loss: -1123.964966\n",
      "Train Epoch: 9 [28672/54000 (53%)] Loss: -1125.478271\n",
      "Train Epoch: 9 [32768/54000 (61%)] Loss: -1121.168945\n",
      "Train Epoch: 9 [36864/54000 (68%)] Loss: -1112.398193\n",
      "Train Epoch: 9 [40960/54000 (76%)] Loss: -1128.035278\n",
      "Train Epoch: 9 [45056/54000 (83%)] Loss: -1131.183105\n",
      "Train Epoch: 9 [49152/54000 (91%)] Loss: -1130.786987\n",
      "Train Epoch: 9 [53248/54000 (99%)] Loss: -1124.573486\n",
      "    epoch          : 9\n",
      "    loss           : -1120.9844207040508\n",
      "    ess            : 3.827522972748743\n",
      "    log_marginal   : 1121.0527499953716\n",
      "    val_loss       : -1121.742182413737\n",
      "    val_ess        : 3.821175823609034\n",
      "    val_log_marginal: 1121.8127695719402\n",
      "Train Epoch: 10 [0/54000 (0%)] Loss: -1135.213135\n",
      "Train Epoch: 10 [4096/54000 (8%)] Loss: -1136.551025\n",
      "Train Epoch: 10 [8192/54000 (15%)] Loss: -1121.071533\n",
      "Train Epoch: 10 [12288/54000 (23%)] Loss: -1124.253174\n",
      "Train Epoch: 10 [16384/54000 (30%)] Loss: -1124.146484\n",
      "Train Epoch: 10 [20480/54000 (38%)] Loss: -1132.815430\n",
      "Train Epoch: 10 [24576/54000 (46%)] Loss: -1123.240845\n",
      "Train Epoch: 10 [28672/54000 (53%)] Loss: -1128.994873\n",
      "Train Epoch: 10 [32768/54000 (61%)] Loss: -1123.138184\n",
      "Train Epoch: 10 [36864/54000 (68%)] Loss: -1126.345215\n",
      "Train Epoch: 10 [40960/54000 (76%)] Loss: -1125.107422\n",
      "Train Epoch: 10 [45056/54000 (83%)] Loss: -1128.844116\n",
      "Train Epoch: 10 [49152/54000 (91%)] Loss: -1141.681396\n",
      "Train Epoch: 10 [53248/54000 (99%)] Loss: -1130.128906\n",
      "    epoch          : 10\n",
      "    loss           : -1129.4216088751482\n",
      "    ess            : 3.8116940468973457\n",
      "    log_marginal   : 1129.4984923448608\n",
      "    val_loss       : -1129.4190979003906\n",
      "    val_ess        : 3.82023161649704\n",
      "    val_log_marginal: 1129.4883371988933\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [0/54000 (0%)] Loss: -1131.572021\n",
      "Train Epoch: 11 [4096/54000 (8%)] Loss: -1133.697876\n",
      "Train Epoch: 11 [8192/54000 (15%)] Loss: -1135.805664\n",
      "Train Epoch: 11 [12288/54000 (23%)] Loss: -1129.158447\n",
      "Train Epoch: 11 [16384/54000 (30%)] Loss: -1134.926270\n",
      "Train Epoch: 11 [20480/54000 (38%)] Loss: -1132.694214\n",
      "Train Epoch: 11 [24576/54000 (46%)] Loss: -1138.126587\n",
      "Train Epoch: 11 [28672/54000 (53%)] Loss: -1134.765015\n",
      "Train Epoch: 11 [32768/54000 (61%)] Loss: -1141.045532\n",
      "Train Epoch: 11 [36864/54000 (68%)] Loss: -1145.695801\n",
      "Train Epoch: 11 [40960/54000 (76%)] Loss: -1140.822021\n",
      "Train Epoch: 11 [45056/54000 (83%)] Loss: -1137.192505\n",
      "Train Epoch: 11 [49152/54000 (91%)] Loss: -1138.699707\n",
      "Train Epoch: 11 [53248/54000 (99%)] Loss: -1139.488281\n",
      "    epoch          : 11\n",
      "    loss           : -1136.911346869446\n",
      "    ess            : 3.811141147432734\n",
      "    log_marginal   : 1136.989243927725\n",
      "    val_loss       : -1136.7540486653645\n",
      "    val_ess        : 3.807790299256643\n",
      "    val_log_marginal: 1136.828633626302\n",
      "Train Epoch: 12 [0/54000 (0%)] Loss: -1143.251343\n",
      "Train Epoch: 12 [4096/54000 (8%)] Loss: -1149.580322\n",
      "Train Epoch: 12 [8192/54000 (15%)] Loss: -1148.579102\n",
      "Train Epoch: 12 [12288/54000 (23%)] Loss: -1143.177002\n",
      "Train Epoch: 12 [16384/54000 (30%)] Loss: -1145.929443\n",
      "Train Epoch: 12 [20480/54000 (38%)] Loss: -1140.392456\n",
      "Train Epoch: 12 [24576/54000 (46%)] Loss: -1142.259521\n",
      "Train Epoch: 12 [28672/54000 (53%)] Loss: -1134.476562\n",
      "Train Epoch: 12 [32768/54000 (61%)] Loss: -1139.915894\n",
      "Train Epoch: 12 [36864/54000 (68%)] Loss: -1149.680420\n",
      "Train Epoch: 12 [40960/54000 (76%)] Loss: -1140.201660\n",
      "Train Epoch: 12 [45056/54000 (83%)] Loss: -1146.314697\n",
      "Train Epoch: 12 [49152/54000 (91%)] Loss: -1137.129761\n",
      "Train Epoch: 12 [53248/54000 (99%)] Loss: -1148.942139\n",
      "    epoch          : 12\n",
      "    loss           : -1143.1980501147807\n",
      "    ess            : 3.802467878395912\n",
      "    log_marginal   : 1143.2807686611375\n",
      "    val_loss       : -1141.9327748616536\n",
      "    val_ess        : 3.7894915342330933\n",
      "    val_log_marginal: 1142.0168050130208\n",
      "Train Epoch: 13 [0/54000 (0%)] Loss: -1155.217529\n",
      "Train Epoch: 13 [4096/54000 (8%)] Loss: -1145.784912\n",
      "Train Epoch: 13 [8192/54000 (15%)] Loss: -1150.599731\n",
      "Train Epoch: 13 [12288/54000 (23%)] Loss: -1148.952637\n",
      "Train Epoch: 13 [16384/54000 (30%)] Loss: -1148.770996\n",
      "Train Epoch: 13 [20480/54000 (38%)] Loss: -1148.664795\n",
      "Train Epoch: 13 [24576/54000 (46%)] Loss: -1145.645020\n",
      "Train Epoch: 13 [28672/54000 (53%)] Loss: -1140.415161\n",
      "Train Epoch: 13 [32768/54000 (61%)] Loss: -1155.340942\n",
      "Train Epoch: 13 [36864/54000 (68%)] Loss: -1145.407227\n",
      "Train Epoch: 13 [40960/54000 (76%)] Loss: -1144.105225\n",
      "Train Epoch: 13 [45056/54000 (83%)] Loss: -1156.687866\n",
      "Train Epoch: 13 [49152/54000 (91%)] Loss: -1155.819458\n",
      "Train Epoch: 13 [53248/54000 (99%)] Loss: -1144.344604\n",
      "    epoch          : 13\n",
      "    loss           : -1148.7771406851673\n",
      "    ess            : 3.798129880597806\n",
      "    log_marginal   : 1148.862601474563\n",
      "    val_loss       : -1148.2222290039062\n",
      "    val_ess        : 3.799038052558899\n",
      "    val_log_marginal: 1148.3046773274739\n",
      "Train Epoch: 14 [0/54000 (0%)] Loss: -1164.171875\n",
      "Train Epoch: 14 [4096/54000 (8%)] Loss: -1160.432129\n",
      "Train Epoch: 14 [8192/54000 (15%)] Loss: -1152.298462\n",
      "Train Epoch: 14 [12288/54000 (23%)] Loss: -1150.416992\n",
      "Train Epoch: 14 [16384/54000 (30%)] Loss: -1150.077881\n",
      "Train Epoch: 14 [20480/54000 (38%)] Loss: -1146.030518\n",
      "Train Epoch: 14 [24576/54000 (46%)] Loss: -1158.955078\n",
      "Train Epoch: 14 [28672/54000 (53%)] Loss: -1147.647339\n",
      "Train Epoch: 14 [32768/54000 (61%)] Loss: -1152.391235\n",
      "Train Epoch: 14 [36864/54000 (68%)] Loss: -1156.859131\n",
      "Train Epoch: 14 [40960/54000 (76%)] Loss: -1166.104248\n",
      "Train Epoch: 14 [45056/54000 (83%)] Loss: -1164.341187\n",
      "Train Epoch: 14 [49152/54000 (91%)] Loss: -1158.372559\n",
      "Train Epoch: 14 [53248/54000 (99%)] Loss: -1154.719604\n",
      "    epoch          : 14\n",
      "    loss           : -1155.5038588103525\n",
      "    ess            : 3.795984042199302\n",
      "    log_marginal   : 1155.5919843194608\n",
      "    val_loss       : -1155.5362599690754\n",
      "    val_ess        : 3.7955029805501304\n",
      "    val_log_marginal: 1155.6244455973308\n",
      "Train Epoch: 15 [0/54000 (0%)] Loss: -1167.078003\n",
      "Train Epoch: 15 [4096/54000 (8%)] Loss: -1162.392578\n",
      "Train Epoch: 15 [8192/54000 (15%)] Loss: -1160.292236\n",
      "Train Epoch: 15 [12288/54000 (23%)] Loss: -1158.542603\n",
      "Train Epoch: 15 [16384/54000 (30%)] Loss: -1159.429688\n",
      "Train Epoch: 15 [20480/54000 (38%)] Loss: -1162.877197\n",
      "Train Epoch: 15 [24576/54000 (46%)] Loss: -1167.646973\n",
      "Train Epoch: 15 [28672/54000 (53%)] Loss: -1163.895264\n",
      "Train Epoch: 15 [32768/54000 (61%)] Loss: -1164.765747\n",
      "Train Epoch: 15 [36864/54000 (68%)] Loss: -1156.745361\n",
      "Train Epoch: 15 [40960/54000 (76%)] Loss: -1162.368164\n",
      "Train Epoch: 15 [45056/54000 (83%)] Loss: -1169.094727\n",
      "Train Epoch: 15 [49152/54000 (91%)] Loss: -1164.035522\n",
      "Train Epoch: 15 [53248/54000 (99%)] Loss: -1159.640503\n",
      "    epoch          : 15\n",
      "    loss           : -1161.4514605626111\n",
      "    ess            : 3.790421716409837\n",
      "    log_marginal   : 1161.5434767013478\n",
      "    val_loss       : -1159.7457173665364\n",
      "    val_ess        : 3.7858648796876273\n",
      "    val_log_marginal: 1159.8417510986328\n",
      "Train Epoch: 16 [0/54000 (0%)] Loss: -1166.207031\n",
      "Train Epoch: 16 [4096/54000 (8%)] Loss: -1171.898804\n",
      "Train Epoch: 16 [8192/54000 (15%)] Loss: -1163.650391\n",
      "Train Epoch: 16 [12288/54000 (23%)] Loss: -1162.831299\n",
      "Train Epoch: 16 [16384/54000 (30%)] Loss: -1166.108276\n",
      "Train Epoch: 16 [20480/54000 (38%)] Loss: -1163.292480\n",
      "Train Epoch: 16 [24576/54000 (46%)] Loss: -1163.290649\n",
      "Train Epoch: 16 [28672/54000 (53%)] Loss: -1167.144287\n",
      "Train Epoch: 16 [32768/54000 (61%)] Loss: -1164.905396\n",
      "Train Epoch: 16 [36864/54000 (68%)] Loss: -1157.429443\n",
      "Train Epoch: 16 [40960/54000 (76%)] Loss: -1172.088135\n",
      "Train Epoch: 16 [45056/54000 (83%)] Loss: -1170.108521\n",
      "Train Epoch: 16 [49152/54000 (91%)] Loss: -1164.124023\n",
      "Train Epoch: 16 [53248/54000 (99%)] Loss: -1167.057617\n",
      "    epoch          : 16\n",
      "    loss           : -1165.317665136256\n",
      "    ess            : 3.791568141412961\n",
      "    log_marginal   : 1165.4107046986078\n",
      "    val_loss       : -1162.7558034261067\n",
      "    val_ess        : 3.7703492740790048\n",
      "    val_log_marginal: 1162.8620351155598\n",
      "Train Epoch: 17 [0/54000 (0%)] Loss: -1165.428589\n",
      "Train Epoch: 17 [4096/54000 (8%)] Loss: -1178.139404\n",
      "Train Epoch: 17 [8192/54000 (15%)] Loss: -1164.892334\n",
      "Train Epoch: 17 [12288/54000 (23%)] Loss: -1173.874146\n",
      "Train Epoch: 17 [16384/54000 (30%)] Loss: -1178.460938\n",
      "Train Epoch: 17 [20480/54000 (38%)] Loss: -1175.307617\n",
      "Train Epoch: 17 [24576/54000 (46%)] Loss: -1167.252686\n",
      "Train Epoch: 17 [28672/54000 (53%)] Loss: -1166.678711\n",
      "Train Epoch: 17 [32768/54000 (61%)] Loss: -1172.666260\n",
      "Train Epoch: 17 [36864/54000 (68%)] Loss: -1174.189941\n",
      "Train Epoch: 17 [40960/54000 (76%)] Loss: -1162.271484\n",
      "Train Epoch: 17 [45056/54000 (83%)] Loss: -1172.176392\n",
      "Train Epoch: 17 [49152/54000 (91%)] Loss: -1168.274414\n",
      "Train Epoch: 17 [53248/54000 (99%)] Loss: -1168.763672\n",
      "    epoch          : 17\n",
      "    loss           : -1168.6252753813685\n",
      "    ess            : 3.7783563555134414\n",
      "    log_marginal   : 1168.7262894327607\n",
      "    val_loss       : -1167.8809611002605\n",
      "    val_ess        : 3.7867807745933533\n",
      "    val_log_marginal: 1167.981653849284\n",
      "Train Epoch: 18 [0/54000 (0%)] Loss: -1170.100098\n",
      "Train Epoch: 18 [4096/54000 (8%)] Loss: -1178.492188\n",
      "Train Epoch: 18 [8192/54000 (15%)] Loss: -1175.669189\n",
      "Train Epoch: 18 [12288/54000 (23%)] Loss: -1176.009521\n",
      "Train Epoch: 18 [16384/54000 (30%)] Loss: -1173.614380\n",
      "Train Epoch: 18 [20480/54000 (38%)] Loss: -1173.510132\n",
      "Train Epoch: 18 [24576/54000 (46%)] Loss: -1177.383301\n",
      "Train Epoch: 18 [28672/54000 (53%)] Loss: -1169.520142\n",
      "Train Epoch: 18 [32768/54000 (61%)] Loss: -1169.845947\n",
      "Train Epoch: 18 [36864/54000 (68%)] Loss: -1175.115845\n",
      "Train Epoch: 18 [40960/54000 (76%)] Loss: -1169.919678\n",
      "Train Epoch: 18 [45056/54000 (83%)] Loss: -1176.119873\n",
      "Train Epoch: 18 [49152/54000 (91%)] Loss: -1167.281372\n",
      "Train Epoch: 18 [53248/54000 (99%)] Loss: -1177.825195\n",
      "    epoch          : 18\n",
      "    loss           : -1173.1307095351378\n",
      "    ess            : 3.779441158918408\n",
      "    log_marginal   : 1173.2310362901733\n",
      "    val_loss       : -1172.6426442464192\n",
      "    val_ess        : 3.7901198069254556\n",
      "    val_log_marginal: 1172.7342173258464\n",
      "Train Epoch: 19 [0/54000 (0%)] Loss: -1175.375732\n",
      "Train Epoch: 19 [4096/54000 (8%)] Loss: -1173.576904\n",
      "Train Epoch: 19 [8192/54000 (15%)] Loss: -1183.809082\n",
      "Train Epoch: 19 [12288/54000 (23%)] Loss: -1169.671875\n",
      "Train Epoch: 19 [16384/54000 (30%)] Loss: -1173.743164\n",
      "Train Epoch: 19 [20480/54000 (38%)] Loss: -1177.562256\n",
      "Train Epoch: 19 [24576/54000 (46%)] Loss: -1179.564575\n",
      "Train Epoch: 19 [28672/54000 (53%)] Loss: -1184.542480\n",
      "Train Epoch: 19 [32768/54000 (61%)] Loss: -1171.343994\n",
      "Train Epoch: 19 [36864/54000 (68%)] Loss: -1172.989258\n",
      "Train Epoch: 19 [40960/54000 (76%)] Loss: -1174.258667\n",
      "Train Epoch: 19 [45056/54000 (83%)] Loss: -1178.723389\n",
      "Train Epoch: 19 [49152/54000 (91%)] Loss: -1179.455322\n",
      "Train Epoch: 19 [53248/54000 (99%)] Loss: -1176.127686\n",
      "    epoch          : 19\n",
      "    loss           : -1176.3272519947793\n",
      "    ess            : 3.774094651660648\n",
      "    log_marginal   : 1176.4294300531324\n",
      "    val_loss       : -1174.0420583089192\n",
      "    val_ess        : 3.772412747144699\n",
      "    val_log_marginal: 1174.1451873779297\n",
      "Train Epoch: 20 [0/54000 (0%)] Loss: -1179.759521\n",
      "Train Epoch: 20 [4096/54000 (8%)] Loss: -1174.331055\n",
      "Train Epoch: 20 [8192/54000 (15%)] Loss: -1182.492188\n",
      "Train Epoch: 20 [12288/54000 (23%)] Loss: -1175.859741\n",
      "Train Epoch: 20 [16384/54000 (30%)] Loss: -1182.356934\n",
      "Train Epoch: 20 [20480/54000 (38%)] Loss: -1176.380737\n",
      "Train Epoch: 20 [24576/54000 (46%)] Loss: -1185.408936\n",
      "Train Epoch: 20 [28672/54000 (53%)] Loss: -1180.497559\n",
      "Train Epoch: 20 [32768/54000 (61%)] Loss: -1175.818359\n",
      "Train Epoch: 20 [36864/54000 (68%)] Loss: -1182.768555\n",
      "Train Epoch: 20 [40960/54000 (76%)] Loss: -1173.636230\n",
      "Train Epoch: 20 [45056/54000 (83%)] Loss: -1175.275391\n",
      "Train Epoch: 20 [49152/54000 (91%)] Loss: -1173.979736\n",
      "Train Epoch: 20 [53248/54000 (99%)] Loss: -1174.613770\n",
      "    epoch          : 20\n",
      "    loss           : -1178.2529985328422\n",
      "    ess            : 3.769633147388838\n",
      "    log_marginal   : 1178.3610504295023\n",
      "    val_loss       : -1176.1455637613933\n",
      "    val_ess        : 3.779089480638504\n",
      "    val_log_marginal: 1176.2491658528645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [0/54000 (0%)] Loss: -1180.704102\n",
      "Train Epoch: 21 [4096/54000 (8%)] Loss: -1183.347046\n",
      "Train Epoch: 21 [8192/54000 (15%)] Loss: -1181.520752\n",
      "Train Epoch: 21 [12288/54000 (23%)] Loss: -1178.232178\n",
      "Train Epoch: 21 [16384/54000 (30%)] Loss: -1180.693726\n",
      "Train Epoch: 21 [20480/54000 (38%)] Loss: -1181.561768\n",
      "Train Epoch: 21 [24576/54000 (46%)] Loss: -1178.874023\n",
      "Train Epoch: 21 [28672/54000 (53%)] Loss: -1183.013916\n",
      "Train Epoch: 21 [32768/54000 (61%)] Loss: -1182.609131\n",
      "Train Epoch: 21 [36864/54000 (68%)] Loss: -1188.393188\n",
      "Train Epoch: 21 [40960/54000 (76%)] Loss: -1179.403809\n",
      "Train Epoch: 21 [45056/54000 (83%)] Loss: -1183.159790\n",
      "Train Epoch: 21 [49152/54000 (91%)] Loss: -1185.304199\n",
      "Train Epoch: 21 [53248/54000 (99%)] Loss: -1176.714844\n",
      "    epoch          : 21\n",
      "    loss           : -1182.0193686824275\n",
      "    ess            : 3.7762454810300707\n",
      "    log_marginal   : 1182.1229415821238\n",
      "    val_loss       : -1181.8204549153645\n",
      "    val_ess        : 3.77406899134318\n",
      "    val_log_marginal: 1181.9289449055989\n",
      "Train Epoch: 22 [0/54000 (0%)] Loss: -1188.397461\n",
      "Train Epoch: 22 [4096/54000 (8%)] Loss: -1190.305786\n",
      "Train Epoch: 22 [8192/54000 (15%)] Loss: -1185.836060\n",
      "Train Epoch: 22 [12288/54000 (23%)] Loss: -1188.300049\n",
      "Train Epoch: 22 [16384/54000 (30%)] Loss: -1185.462769\n",
      "Train Epoch: 22 [20480/54000 (38%)] Loss: -1183.724854\n",
      "Train Epoch: 22 [24576/54000 (46%)] Loss: -1190.195312\n",
      "Train Epoch: 22 [28672/54000 (53%)] Loss: -1183.251099\n",
      "Train Epoch: 22 [32768/54000 (61%)] Loss: -1187.186768\n",
      "Train Epoch: 22 [36864/54000 (68%)] Loss: -1178.113770\n",
      "Train Epoch: 22 [40960/54000 (76%)] Loss: -1186.473145\n",
      "Train Epoch: 22 [45056/54000 (83%)] Loss: -1187.927246\n",
      "Train Epoch: 22 [49152/54000 (91%)] Loss: -1187.041504\n",
      "Train Epoch: 22 [53248/54000 (99%)] Loss: -1184.575928\n",
      "    epoch          : 22\n",
      "    loss           : -1185.8104734013996\n",
      "    ess            : 3.765320101055489\n",
      "    log_marginal   : 1185.9198437731413\n",
      "    val_loss       : -1184.9969329833984\n",
      "    val_ess        : 3.771872490644455\n",
      "    val_log_marginal: 1185.1014912923176\n",
      "Train Epoch: 23 [0/54000 (0%)] Loss: -1190.130127\n",
      "Train Epoch: 23 [4096/54000 (8%)] Loss: -1186.090332\n",
      "Train Epoch: 23 [8192/54000 (15%)] Loss: -1187.138916\n",
      "Train Epoch: 23 [12288/54000 (23%)] Loss: -1188.779053\n",
      "Train Epoch: 23 [16384/54000 (30%)] Loss: -1192.589111\n",
      "Train Epoch: 23 [20480/54000 (38%)] Loss: -1180.008667\n",
      "Train Epoch: 23 [24576/54000 (46%)] Loss: -1185.611816\n",
      "Train Epoch: 23 [28672/54000 (53%)] Loss: -1184.355957\n",
      "Train Epoch: 23 [32768/54000 (61%)] Loss: -1187.859619\n",
      "Train Epoch: 23 [36864/54000 (68%)] Loss: -1189.565308\n",
      "Train Epoch: 23 [40960/54000 (76%)] Loss: -1186.560547\n",
      "Train Epoch: 23 [45056/54000 (83%)] Loss: -1190.225586\n",
      "Train Epoch: 23 [49152/54000 (91%)] Loss: -1181.779785\n",
      "Train Epoch: 23 [53248/54000 (99%)] Loss: -1187.947144\n",
      "    epoch          : 23\n",
      "    loss           : -1187.952031573978\n",
      "    ess            : 3.761415862359142\n",
      "    log_marginal   : 1188.0642622093453\n",
      "    val_loss       : -1186.4306538899739\n",
      "    val_ess        : 3.7702874143918357\n",
      "    val_log_marginal: 1186.533432006836\n",
      "Train Epoch: 24 [0/54000 (0%)] Loss: -1188.497925\n",
      "Train Epoch: 24 [4096/54000 (8%)] Loss: -1190.657959\n",
      "Train Epoch: 24 [8192/54000 (15%)] Loss: -1196.827148\n",
      "Train Epoch: 24 [12288/54000 (23%)] Loss: -1192.074707\n",
      "Train Epoch: 24 [16384/54000 (30%)] Loss: -1196.649536\n",
      "Train Epoch: 24 [20480/54000 (38%)] Loss: -1184.463867\n",
      "Train Epoch: 24 [24576/54000 (46%)] Loss: -1178.855469\n",
      "Train Epoch: 24 [28672/54000 (53%)] Loss: -1189.817383\n",
      "Train Epoch: 24 [32768/54000 (61%)] Loss: -1197.540771\n",
      "Train Epoch: 24 [36864/54000 (68%)] Loss: -1198.401611\n",
      "Train Epoch: 24 [40960/54000 (76%)] Loss: -1194.088135\n",
      "Train Epoch: 24 [45056/54000 (83%)] Loss: -1193.340576\n",
      "Train Epoch: 24 [49152/54000 (91%)] Loss: -1189.545410\n",
      "Train Epoch: 24 [53248/54000 (99%)] Loss: -1193.869995\n",
      "    epoch          : 24\n",
      "    loss           : -1190.8615363966233\n",
      "    ess            : 3.762306578351423\n",
      "    log_marginal   : 1190.9727864197646\n",
      "    val_loss       : -1190.607162475586\n",
      "    val_ess        : 3.7690202991167703\n",
      "    val_log_marginal: 1190.717737833659\n",
      "Train Epoch: 25 [0/54000 (0%)] Loss: -1193.056396\n",
      "Train Epoch: 25 [4096/54000 (8%)] Loss: -1199.730835\n",
      "Train Epoch: 25 [8192/54000 (15%)] Loss: -1196.432007\n",
      "Train Epoch: 25 [12288/54000 (23%)] Loss: -1197.819336\n",
      "Train Epoch: 25 [16384/54000 (30%)] Loss: -1199.849976\n",
      "Train Epoch: 25 [20480/54000 (38%)] Loss: -1197.838623\n",
      "Train Epoch: 25 [24576/54000 (46%)] Loss: -1192.013794\n",
      "Train Epoch: 25 [28672/54000 (53%)] Loss: -1187.694336\n",
      "Train Epoch: 25 [32768/54000 (61%)] Loss: -1197.095215\n",
      "Train Epoch: 25 [36864/54000 (68%)] Loss: -1194.362183\n",
      "Train Epoch: 25 [40960/54000 (76%)] Loss: -1194.234131\n",
      "Train Epoch: 25 [45056/54000 (83%)] Loss: -1196.244507\n",
      "Train Epoch: 25 [49152/54000 (91%)] Loss: -1195.962402\n",
      "Train Epoch: 25 [53248/54000 (99%)] Loss: -1194.849365\n",
      "    epoch          : 25\n",
      "    loss           : -1194.956363623741\n",
      "    ess            : 3.761026212954408\n",
      "    log_marginal   : 1195.0686064082865\n",
      "    val_loss       : -1194.264424641927\n",
      "    val_ess        : 3.7534291744232178\n",
      "    val_log_marginal: 1194.379653930664\n",
      "Train Epoch: 26 [0/54000 (0%)] Loss: -1199.814209\n",
      "Train Epoch: 26 [4096/54000 (8%)] Loss: -1190.508789\n",
      "Train Epoch: 26 [8192/54000 (15%)] Loss: -1201.904907\n",
      "Train Epoch: 26 [12288/54000 (23%)] Loss: -1193.434814\n",
      "Train Epoch: 26 [16384/54000 (30%)] Loss: -1207.151123\n",
      "Train Epoch: 26 [20480/54000 (38%)] Loss: -1196.031982\n",
      "Train Epoch: 26 [24576/54000 (46%)] Loss: -1196.978027\n",
      "Train Epoch: 26 [28672/54000 (53%)] Loss: -1194.450317\n",
      "Train Epoch: 26 [32768/54000 (61%)] Loss: -1195.084717\n",
      "Train Epoch: 26 [36864/54000 (68%)] Loss: -1190.181885\n",
      "Train Epoch: 26 [40960/54000 (76%)] Loss: -1199.161133\n",
      "Train Epoch: 26 [45056/54000 (83%)] Loss: -1192.292480\n",
      "Train Epoch: 26 [49152/54000 (91%)] Loss: -1193.994141\n",
      "Train Epoch: 26 [53248/54000 (99%)] Loss: -1194.737061\n",
      "    epoch          : 26\n",
      "    loss           : -1197.3281313638552\n",
      "    ess            : 3.755221705866086\n",
      "    log_marginal   : 1197.4468207336715\n",
      "    val_loss       : -1195.7284596761067\n",
      "    val_ess        : 3.7622040609518685\n",
      "    val_log_marginal: 1195.8431447347004\n",
      "Train Epoch: 27 [0/54000 (0%)] Loss: -1186.997192\n",
      "Train Epoch: 27 [4096/54000 (8%)] Loss: -1205.973877\n",
      "Train Epoch: 27 [8192/54000 (15%)] Loss: -1203.595947\n",
      "Train Epoch: 27 [12288/54000 (23%)] Loss: -1207.273926\n",
      "Train Epoch: 27 [16384/54000 (30%)] Loss: -1206.240601\n",
      "Train Epoch: 27 [20480/54000 (38%)] Loss: -1200.791504\n",
      "Train Epoch: 27 [24576/54000 (46%)] Loss: -1199.543701\n",
      "Train Epoch: 27 [28672/54000 (53%)] Loss: -1192.859741\n",
      "Train Epoch: 27 [32768/54000 (61%)] Loss: -1195.150879\n",
      "Train Epoch: 27 [36864/54000 (68%)] Loss: -1199.902832\n",
      "Train Epoch: 27 [40960/54000 (76%)] Loss: -1199.056152\n",
      "Train Epoch: 27 [45056/54000 (83%)] Loss: -1202.190186\n",
      "Train Epoch: 27 [49152/54000 (91%)] Loss: -1197.129639\n",
      "Train Epoch: 27 [53248/54000 (99%)] Loss: -1205.499268\n",
      "    epoch          : 27\n",
      "    loss           : -1199.8302106088936\n",
      "    ess            : 3.753296547026431\n",
      "    log_marginal   : 1199.9458314434612\n",
      "    val_loss       : -1199.428258260091\n",
      "    val_ess        : 3.753979424635569\n",
      "    val_log_marginal: 1199.5445404052734\n",
      "Train Epoch: 28 [0/54000 (0%)] Loss: -1199.536377\n",
      "Train Epoch: 28 [4096/54000 (8%)] Loss: -1204.981079\n",
      "Train Epoch: 28 [8192/54000 (15%)] Loss: -1206.271729\n",
      "Train Epoch: 28 [12288/54000 (23%)] Loss: -1210.854980\n",
      "Train Epoch: 28 [16384/54000 (30%)] Loss: -1203.001221\n",
      "Train Epoch: 28 [20480/54000 (38%)] Loss: -1196.167725\n",
      "Train Epoch: 28 [24576/54000 (46%)] Loss: -1200.032104\n",
      "Train Epoch: 28 [28672/54000 (53%)] Loss: -1207.824829\n",
      "Train Epoch: 28 [32768/54000 (61%)] Loss: -1208.281616\n",
      "Train Epoch: 28 [36864/54000 (68%)] Loss: -1201.123169\n",
      "Train Epoch: 28 [40960/54000 (76%)] Loss: -1204.259766\n",
      "Train Epoch: 28 [45056/54000 (83%)] Loss: -1200.056885\n",
      "Train Epoch: 28 [49152/54000 (91%)] Loss: -1206.001953\n",
      "Train Epoch: 28 [53248/54000 (99%)] Loss: -1203.225464\n",
      "    epoch          : 28\n",
      "    loss           : -1204.1422315841603\n",
      "    ess            : 3.745976597211937\n",
      "    log_marginal   : 1204.2640913109078\n",
      "    val_loss       : -1204.1002349853516\n",
      "    val_ess        : 3.7588643531004586\n",
      "    val_log_marginal: 1204.2091267903645\n",
      "Train Epoch: 29 [0/54000 (0%)] Loss: -1217.799805\n",
      "Train Epoch: 29 [4096/54000 (8%)] Loss: -1208.850098\n",
      "Train Epoch: 29 [8192/54000 (15%)] Loss: -1211.992676\n",
      "Train Epoch: 29 [12288/54000 (23%)] Loss: -1200.737793\n",
      "Train Epoch: 29 [16384/54000 (30%)] Loss: -1207.139648\n",
      "Train Epoch: 29 [20480/54000 (38%)] Loss: -1205.584717\n",
      "Train Epoch: 29 [24576/54000 (46%)] Loss: -1197.506104\n",
      "Train Epoch: 29 [28672/54000 (53%)] Loss: -1209.950317\n",
      "Train Epoch: 29 [32768/54000 (61%)] Loss: -1212.888672\n",
      "Train Epoch: 29 [36864/54000 (68%)] Loss: -1209.291504\n",
      "Train Epoch: 29 [40960/54000 (76%)] Loss: -1210.119629\n",
      "Train Epoch: 29 [45056/54000 (83%)] Loss: -1213.483398\n",
      "Train Epoch: 29 [49152/54000 (91%)] Loss: -1203.534668\n",
      "Train Epoch: 29 [53248/54000 (99%)] Loss: -1204.337769\n",
      "    epoch          : 29\n",
      "    loss           : -1207.4993532009034\n",
      "    ess            : 3.7421177055033463\n",
      "    log_marginal   : 1207.6230503461936\n",
      "    val_loss       : -1206.1131286621094\n",
      "    val_ess        : 3.744323422511419\n",
      "    val_log_marginal: 1206.2325134277344\n",
      "Train Epoch: 30 [0/54000 (0%)] Loss: -1209.192505\n",
      "Train Epoch: 30 [4096/54000 (8%)] Loss: -1210.998901\n",
      "Train Epoch: 30 [8192/54000 (15%)] Loss: -1205.990479\n",
      "Train Epoch: 30 [12288/54000 (23%)] Loss: -1212.148926\n",
      "Train Epoch: 30 [16384/54000 (30%)] Loss: -1217.680054\n",
      "Train Epoch: 30 [20480/54000 (38%)] Loss: -1210.684082\n",
      "Train Epoch: 30 [24576/54000 (46%)] Loss: -1216.746338\n",
      "Train Epoch: 30 [28672/54000 (53%)] Loss: -1208.090576\n",
      "Train Epoch: 30 [32768/54000 (61%)] Loss: -1212.896240\n",
      "Train Epoch: 30 [36864/54000 (68%)] Loss: -1214.493286\n",
      "Train Epoch: 30 [40960/54000 (76%)] Loss: -1214.699341\n",
      "Train Epoch: 30 [45056/54000 (83%)] Loss: -1209.355103\n",
      "Train Epoch: 30 [49152/54000 (91%)] Loss: -1211.268433\n",
      "Train Epoch: 30 [53248/54000 (99%)] Loss: -1213.172729\n",
      "    epoch          : 30\n",
      "    loss           : -1210.4301699959271\n",
      "    ess            : 3.736361476482373\n",
      "    log_marginal   : 1210.556545745705\n",
      "    val_loss       : -1209.347396850586\n",
      "    val_ess        : 3.7441205084323883\n",
      "    val_log_marginal: 1209.469502766927\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [0/54000 (0%)] Loss: -1215.039551\n",
      "Train Epoch: 31 [4096/54000 (8%)] Loss: -1215.724121\n",
      "Train Epoch: 31 [8192/54000 (15%)] Loss: -1207.191406\n",
      "Train Epoch: 31 [12288/54000 (23%)] Loss: -1219.206299\n",
      "Train Epoch: 31 [16384/54000 (30%)] Loss: -1210.070435\n",
      "Train Epoch: 31 [20480/54000 (38%)] Loss: -1211.967529\n",
      "Train Epoch: 31 [24576/54000 (46%)] Loss: -1206.237061\n",
      "Train Epoch: 31 [28672/54000 (53%)] Loss: -1209.965820\n",
      "Train Epoch: 31 [32768/54000 (61%)] Loss: -1214.603882\n",
      "Train Epoch: 31 [36864/54000 (68%)] Loss: -1219.819580\n",
      "Train Epoch: 31 [40960/54000 (76%)] Loss: -1216.681396\n",
      "Train Epoch: 31 [45056/54000 (83%)] Loss: -1215.879517\n",
      "Train Epoch: 31 [49152/54000 (91%)] Loss: -1214.514893\n",
      "Train Epoch: 31 [53248/54000 (99%)] Loss: -1209.610229\n",
      "    epoch          : 31\n",
      "    loss           : -1214.2844041580272\n",
      "    ess            : 3.74175417366751\n",
      "    log_marginal   : 1214.405489230043\n",
      "    val_loss       : -1213.7261759440105\n",
      "    val_ess        : 3.729526807864507\n",
      "    val_log_marginal: 1213.8587544759114\n",
      "Train Epoch: 32 [0/54000 (0%)] Loss: -1218.867310\n",
      "Train Epoch: 32 [4096/54000 (8%)] Loss: -1217.405762\n",
      "Train Epoch: 32 [8192/54000 (15%)] Loss: -1218.629517\n",
      "Train Epoch: 32 [12288/54000 (23%)] Loss: -1215.197021\n",
      "Train Epoch: 32 [16384/54000 (30%)] Loss: -1222.777344\n",
      "Train Epoch: 32 [20480/54000 (38%)] Loss: -1230.284424\n",
      "Train Epoch: 32 [24576/54000 (46%)] Loss: -1209.460938\n",
      "Train Epoch: 32 [28672/54000 (53%)] Loss: -1217.268799\n",
      "Train Epoch: 32 [32768/54000 (61%)] Loss: -1221.222656\n",
      "Train Epoch: 32 [36864/54000 (68%)] Loss: -1219.765625\n",
      "Train Epoch: 32 [40960/54000 (76%)] Loss: -1212.533203\n",
      "Train Epoch: 32 [45056/54000 (83%)] Loss: -1216.106934\n",
      "Train Epoch: 32 [49152/54000 (91%)] Loss: -1216.645996\n",
      "Train Epoch: 32 [53248/54000 (99%)] Loss: -1216.022705\n",
      "    epoch          : 32\n",
      "    loss           : -1217.8803230755702\n",
      "    ess            : 3.730611348039166\n",
      "    log_marginal   : 1218.0095990077014\n",
      "    val_loss       : -1217.1363881429036\n",
      "    val_ess        : 3.7498828172683716\n",
      "    val_log_marginal: 1217.2547454833984\n",
      "Train Epoch: 33 [0/54000 (0%)] Loss: -1216.968384\n",
      "Train Epoch: 33 [4096/54000 (8%)] Loss: -1219.090332\n",
      "Train Epoch: 33 [8192/54000 (15%)] Loss: -1225.330811\n",
      "Train Epoch: 33 [12288/54000 (23%)] Loss: -1218.939331\n",
      "Train Epoch: 33 [16384/54000 (30%)] Loss: -1218.716553\n",
      "Train Epoch: 33 [20480/54000 (38%)] Loss: -1214.745605\n",
      "Train Epoch: 33 [24576/54000 (46%)] Loss: -1215.200195\n",
      "Train Epoch: 33 [28672/54000 (53%)] Loss: -1222.192993\n",
      "Train Epoch: 33 [32768/54000 (61%)] Loss: -1223.393799\n",
      "Train Epoch: 33 [36864/54000 (68%)] Loss: -1225.664551\n",
      "Train Epoch: 33 [40960/54000 (76%)] Loss: -1218.442871\n",
      "Train Epoch: 33 [45056/54000 (83%)] Loss: -1216.748535\n",
      "Train Epoch: 33 [49152/54000 (91%)] Loss: -1216.877197\n",
      "Train Epoch: 33 [53248/54000 (99%)] Loss: -1222.065796\n",
      "    epoch          : 33\n",
      "    loss           : -1220.9488328689647\n",
      "    ess            : 3.7247308351417288\n",
      "    log_marginal   : 1221.0830899640848\n",
      "    val_loss       : -1220.1018778483074\n",
      "    val_ess        : 3.729617247978846\n",
      "    val_log_marginal: 1220.2246653238933\n",
      "Train Epoch: 34 [0/54000 (0%)] Loss: -1222.031128\n",
      "Train Epoch: 34 [4096/54000 (8%)] Loss: -1223.427002\n",
      "Train Epoch: 34 [8192/54000 (15%)] Loss: -1226.685669\n",
      "Train Epoch: 34 [12288/54000 (23%)] Loss: -1224.314209\n",
      "Train Epoch: 34 [16384/54000 (30%)] Loss: -1227.179199\n",
      "Train Epoch: 34 [20480/54000 (38%)] Loss: -1220.948608\n",
      "Train Epoch: 34 [24576/54000 (46%)] Loss: -1218.270142\n",
      "Train Epoch: 34 [28672/54000 (53%)] Loss: -1224.815308\n",
      "Train Epoch: 34 [32768/54000 (61%)] Loss: -1228.907959\n",
      "Train Epoch: 34 [36864/54000 (68%)] Loss: -1227.015869\n",
      "Train Epoch: 34 [40960/54000 (76%)] Loss: -1221.305054\n",
      "Train Epoch: 34 [45056/54000 (83%)] Loss: -1228.602295\n",
      "Train Epoch: 34 [49152/54000 (91%)] Loss: -1231.215820\n",
      "Train Epoch: 34 [53248/54000 (99%)] Loss: -1226.181274\n",
      "    epoch          : 34\n",
      "    loss           : -1224.5692485791246\n",
      "    ess            : 3.7193014655632997\n",
      "    log_marginal   : 1224.7081703800725\n",
      "    val_loss       : -1224.312723795573\n",
      "    val_ess        : 3.7167014380296073\n",
      "    val_log_marginal: 1224.4487813313801\n",
      "Train Epoch: 35 [0/54000 (0%)] Loss: -1224.701904\n",
      "Train Epoch: 35 [4096/54000 (8%)] Loss: -1233.635986\n",
      "Train Epoch: 35 [8192/54000 (15%)] Loss: -1235.081055\n",
      "Train Epoch: 35 [12288/54000 (23%)] Loss: -1231.245605\n",
      "Train Epoch: 35 [16384/54000 (30%)] Loss: -1231.923828\n",
      "Train Epoch: 35 [20480/54000 (38%)] Loss: -1226.381348\n",
      "Train Epoch: 35 [24576/54000 (46%)] Loss: -1226.706543\n",
      "Train Epoch: 35 [28672/54000 (53%)] Loss: -1240.884766\n",
      "Train Epoch: 35 [32768/54000 (61%)] Loss: -1221.972656\n",
      "Train Epoch: 35 [36864/54000 (68%)] Loss: -1225.110107\n",
      "Train Epoch: 35 [40960/54000 (76%)] Loss: -1228.126465\n",
      "Train Epoch: 35 [45056/54000 (83%)] Loss: -1234.133423\n",
      "Train Epoch: 35 [49152/54000 (91%)] Loss: -1228.942871\n",
      "Train Epoch: 35 [53248/54000 (99%)] Loss: -1227.804077\n",
      "    epoch          : 35\n",
      "    loss           : -1228.5905119547913\n",
      "    ess            : 3.715171086279702\n",
      "    log_marginal   : 1228.7305283388255\n",
      "    val_loss       : -1227.899149576823\n",
      "    val_ess        : 3.7217781841754913\n",
      "    val_log_marginal: 1228.0370381673176\n",
      "Train Epoch: 36 [0/54000 (0%)] Loss: -1228.342163\n",
      "Train Epoch: 36 [4096/54000 (8%)] Loss: -1228.533813\n",
      "Train Epoch: 36 [8192/54000 (15%)] Loss: -1229.686890\n",
      "Train Epoch: 36 [12288/54000 (23%)] Loss: -1232.121948\n",
      "Train Epoch: 36 [16384/54000 (30%)] Loss: -1233.524048\n",
      "Train Epoch: 36 [20480/54000 (38%)] Loss: -1228.733521\n",
      "Train Epoch: 36 [24576/54000 (46%)] Loss: -1232.232666\n",
      "Train Epoch: 36 [28672/54000 (53%)] Loss: -1236.363647\n",
      "Train Epoch: 36 [32768/54000 (61%)] Loss: -1234.380493\n",
      "Train Epoch: 36 [36864/54000 (68%)] Loss: -1234.186890\n",
      "Train Epoch: 36 [40960/54000 (76%)] Loss: -1228.860352\n",
      "Train Epoch: 36 [45056/54000 (83%)] Loss: -1227.088257\n",
      "Train Epoch: 36 [49152/54000 (91%)] Loss: -1236.039551\n",
      "Train Epoch: 36 [53248/54000 (99%)] Loss: -1227.339355\n",
      "    epoch          : 36\n",
      "    loss           : -1232.4219421097453\n",
      "    ess            : 3.7092803112138504\n",
      "    log_marginal   : 1232.567510089603\n",
      "    val_loss       : -1231.1143697102864\n",
      "    val_ess        : 3.7161009212334952\n",
      "    val_log_marginal: 1231.258753458659\n",
      "Train Epoch: 37 [0/54000 (0%)] Loss: -1232.238647\n",
      "Train Epoch: 37 [4096/54000 (8%)] Loss: -1239.056763\n",
      "Train Epoch: 37 [8192/54000 (15%)] Loss: -1234.083496\n",
      "Train Epoch: 37 [12288/54000 (23%)] Loss: -1232.747314\n",
      "Train Epoch: 37 [16384/54000 (30%)] Loss: -1236.158569\n",
      "Train Epoch: 37 [20480/54000 (38%)] Loss: -1232.493408\n",
      "Train Epoch: 37 [24576/54000 (46%)] Loss: -1234.550049\n",
      "Train Epoch: 37 [28672/54000 (53%)] Loss: -1236.359619\n",
      "Train Epoch: 37 [32768/54000 (61%)] Loss: -1231.115479\n",
      "Train Epoch: 37 [36864/54000 (68%)] Loss: -1232.476074\n",
      "Train Epoch: 37 [40960/54000 (76%)] Loss: -1240.181885\n",
      "Train Epoch: 37 [45056/54000 (83%)] Loss: -1237.290405\n",
      "Train Epoch: 37 [49152/54000 (91%)] Loss: -1233.158936\n",
      "Train Epoch: 37 [53248/54000 (99%)] Loss: -1233.737671\n",
      "    epoch          : 37\n",
      "    loss           : -1236.0139489919654\n",
      "    ess            : 3.7051904258004864\n",
      "    log_marginal   : 1236.1623245890107\n",
      "    val_loss       : -1235.1017557779949\n",
      "    val_ess        : 3.6825099488099418\n",
      "    val_log_marginal: 1235.2611541748047\n",
      "Train Epoch: 38 [0/54000 (0%)] Loss: -1234.655518\n",
      "Train Epoch: 38 [4096/54000 (8%)] Loss: -1233.549805\n",
      "Train Epoch: 38 [8192/54000 (15%)] Loss: -1243.075684\n",
      "Train Epoch: 38 [12288/54000 (23%)] Loss: -1241.621826\n",
      "Train Epoch: 38 [16384/54000 (30%)] Loss: -1252.356567\n",
      "Train Epoch: 38 [20480/54000 (38%)] Loss: -1243.016602\n",
      "Train Epoch: 38 [24576/54000 (46%)] Loss: -1236.071045\n",
      "Train Epoch: 38 [28672/54000 (53%)] Loss: -1235.159668\n",
      "Train Epoch: 38 [32768/54000 (61%)] Loss: -1239.289917\n",
      "Train Epoch: 38 [36864/54000 (68%)] Loss: -1241.401855\n",
      "Train Epoch: 38 [40960/54000 (76%)] Loss: -1239.709229\n",
      "Train Epoch: 38 [45056/54000 (83%)] Loss: -1246.287842\n",
      "Train Epoch: 38 [49152/54000 (91%)] Loss: -1234.787231\n",
      "Train Epoch: 38 [53248/54000 (99%)] Loss: -1241.226807\n",
      "    epoch          : 38\n",
      "    loss           : -1240.0093988355302\n",
      "    ess            : 3.7041627185604584\n",
      "    log_marginal   : 1240.1581822978376\n",
      "    val_loss       : -1239.8600056966145\n",
      "    val_ess        : 3.697930415471395\n",
      "    val_log_marginal: 1240.0067240397136\n",
      "Train Epoch: 39 [0/54000 (0%)] Loss: -1245.152588\n",
      "Train Epoch: 39 [4096/54000 (8%)] Loss: -1249.695068\n",
      "Train Epoch: 39 [8192/54000 (15%)] Loss: -1249.340820\n",
      "Train Epoch: 39 [12288/54000 (23%)] Loss: -1243.029907\n",
      "Train Epoch: 39 [16384/54000 (30%)] Loss: -1243.242920\n",
      "Train Epoch: 39 [20480/54000 (38%)] Loss: -1241.355713\n",
      "Train Epoch: 39 [24576/54000 (46%)] Loss: -1252.788818\n",
      "Train Epoch: 39 [28672/54000 (53%)] Loss: -1248.568359\n",
      "Train Epoch: 39 [32768/54000 (61%)] Loss: -1244.385864\n",
      "Train Epoch: 39 [36864/54000 (68%)] Loss: -1245.051758\n",
      "Train Epoch: 39 [40960/54000 (76%)] Loss: -1236.349121\n",
      "Train Epoch: 39 [45056/54000 (83%)] Loss: -1244.311279\n",
      "Train Epoch: 39 [49152/54000 (91%)] Loss: -1240.760010\n",
      "Train Epoch: 39 [53248/54000 (99%)] Loss: -1243.226807\n",
      "    epoch          : 39\n",
      "    loss           : -1244.1111858060574\n",
      "    ess            : 3.6932433747567273\n",
      "    log_marginal   : 1244.2636163359005\n",
      "    val_loss       : -1243.7924346923828\n",
      "    val_ess        : 3.7080872853597007\n",
      "    val_log_marginal: 1243.9412587483723\n",
      "Train Epoch: 40 [0/54000 (0%)] Loss: -1247.429443\n",
      "Train Epoch: 40 [4096/54000 (8%)] Loss: -1246.693115\n",
      "Train Epoch: 40 [8192/54000 (15%)] Loss: -1250.796875\n",
      "Train Epoch: 40 [12288/54000 (23%)] Loss: -1255.314331\n",
      "Train Epoch: 40 [16384/54000 (30%)] Loss: -1243.872681\n",
      "Train Epoch: 40 [20480/54000 (38%)] Loss: -1257.199707\n",
      "Train Epoch: 40 [24576/54000 (46%)] Loss: -1248.742554\n",
      "Train Epoch: 40 [28672/54000 (53%)] Loss: -1252.000610\n",
      "Train Epoch: 40 [32768/54000 (61%)] Loss: -1249.367676\n",
      "Train Epoch: 40 [36864/54000 (68%)] Loss: -1242.671997\n",
      "Train Epoch: 40 [40960/54000 (76%)] Loss: -1250.154541\n",
      "Train Epoch: 40 [45056/54000 (83%)] Loss: -1248.690186\n",
      "Train Epoch: 40 [49152/54000 (91%)] Loss: -1248.837402\n",
      "Train Epoch: 40 [53248/54000 (99%)] Loss: -1249.030762\n",
      "    epoch          : 40\n",
      "    loss           : -1248.1196479978155\n",
      "    ess            : 3.687316374756149\n",
      "    log_marginal   : 1248.2792459641587\n",
      "    val_loss       : -1248.0218607584636\n",
      "    val_ess        : 3.7008776466051736\n",
      "    val_log_marginal: 1248.1688588460286\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [0/54000 (0%)] Loss: -1255.356689\n",
      "Train Epoch: 41 [4096/54000 (8%)] Loss: -1251.608521\n",
      "Train Epoch: 41 [8192/54000 (15%)] Loss: -1252.513672\n",
      "Train Epoch: 41 [12288/54000 (23%)] Loss: -1251.221191\n",
      "Train Epoch: 41 [16384/54000 (30%)] Loss: -1258.145508\n",
      "Train Epoch: 41 [20480/54000 (38%)] Loss: -1253.919434\n",
      "Train Epoch: 41 [24576/54000 (46%)] Loss: -1249.478271\n",
      "Train Epoch: 41 [28672/54000 (53%)] Loss: -1254.986572\n",
      "Train Epoch: 41 [32768/54000 (61%)] Loss: -1249.087891\n",
      "Train Epoch: 41 [36864/54000 (68%)] Loss: -1257.896729\n",
      "Train Epoch: 41 [40960/54000 (76%)] Loss: -1253.923828\n",
      "Train Epoch: 41 [45056/54000 (83%)] Loss: -1249.590820\n",
      "Train Epoch: 41 [49152/54000 (91%)] Loss: -1248.693970\n",
      "Train Epoch: 41 [53248/54000 (99%)] Loss: -1251.074219\n",
      "    epoch          : 41\n",
      "    loss           : -1252.348546032657\n",
      "    ess            : 3.679764322759981\n",
      "    log_marginal   : 1252.5137812176022\n",
      "    val_loss       : -1251.9395141601562\n",
      "    val_ess        : 3.682653764883677\n",
      "    val_log_marginal: 1252.0906473795574\n",
      "Train Epoch: 42 [0/54000 (0%)] Loss: -1252.397949\n",
      "Train Epoch: 42 [4096/54000 (8%)] Loss: -1256.473145\n",
      "Train Epoch: 42 [8192/54000 (15%)] Loss: -1252.547119\n",
      "Train Epoch: 42 [12288/54000 (23%)] Loss: -1261.291382\n",
      "Train Epoch: 42 [16384/54000 (30%)] Loss: -1253.339600\n",
      "Train Epoch: 42 [20480/54000 (38%)] Loss: -1252.777100\n",
      "Train Epoch: 42 [24576/54000 (46%)] Loss: -1263.127197\n",
      "Train Epoch: 42 [28672/54000 (53%)] Loss: -1260.302490\n",
      "Train Epoch: 42 [32768/54000 (61%)] Loss: -1250.599121\n",
      "Train Epoch: 42 [36864/54000 (68%)] Loss: -1255.098145\n",
      "Train Epoch: 42 [40960/54000 (76%)] Loss: -1251.719971\n",
      "Train Epoch: 42 [45056/54000 (83%)] Loss: -1251.261230\n",
      "Train Epoch: 42 [49152/54000 (91%)] Loss: -1252.389648\n",
      "Train Epoch: 42 [53248/54000 (99%)] Loss: -1255.625000\n",
      "    epoch          : 42\n",
      "    loss           : -1256.3544337557391\n",
      "    ess            : 3.6779604929883334\n",
      "    log_marginal   : 1256.5208705522439\n",
      "    val_loss       : -1255.7178700764973\n",
      "    val_ess        : 3.683499366044998\n",
      "    val_log_marginal: 1255.8840789794922\n",
      "Train Epoch: 43 [0/54000 (0%)] Loss: -1254.438477\n",
      "Train Epoch: 43 [4096/54000 (8%)] Loss: -1267.049194\n",
      "Train Epoch: 43 [8192/54000 (15%)] Loss: -1263.357666\n",
      "Train Epoch: 43 [12288/54000 (23%)] Loss: -1255.644531\n",
      "Train Epoch: 43 [16384/54000 (30%)] Loss: -1261.185303\n",
      "Train Epoch: 43 [20480/54000 (38%)] Loss: -1261.508545\n",
      "Train Epoch: 43 [24576/54000 (46%)] Loss: -1260.875244\n",
      "Train Epoch: 43 [28672/54000 (53%)] Loss: -1261.716797\n",
      "Train Epoch: 43 [32768/54000 (61%)] Loss: -1254.465942\n",
      "Train Epoch: 43 [36864/54000 (68%)] Loss: -1265.253418\n",
      "Train Epoch: 43 [40960/54000 (76%)] Loss: -1260.734375\n",
      "Train Epoch: 43 [45056/54000 (83%)] Loss: -1260.502319\n",
      "Train Epoch: 43 [49152/54000 (91%)] Loss: -1261.510010\n",
      "Train Epoch: 43 [53248/54000 (99%)] Loss: -1258.930908\n",
      "    epoch          : 43\n",
      "    loss           : -1260.1155317405953\n",
      "    ess            : 3.6706900461025147\n",
      "    log_marginal   : 1260.285949417765\n",
      "    val_loss       : -1260.0277099609375\n",
      "    val_ess        : 3.678775688012441\n",
      "    val_log_marginal: 1260.1985524495442\n",
      "Train Epoch: 44 [0/54000 (0%)] Loss: -1263.673584\n",
      "Train Epoch: 44 [4096/54000 (8%)] Loss: -1262.166382\n",
      "Train Epoch: 44 [8192/54000 (15%)] Loss: -1259.405273\n",
      "Train Epoch: 44 [12288/54000 (23%)] Loss: -1264.365723\n",
      "Train Epoch: 44 [16384/54000 (30%)] Loss: -1261.287109\n",
      "Train Epoch: 44 [20480/54000 (38%)] Loss: -1272.001831\n",
      "Train Epoch: 44 [24576/54000 (46%)] Loss: -1265.957520\n",
      "Train Epoch: 44 [28672/54000 (53%)] Loss: -1265.931641\n",
      "Train Epoch: 44 [32768/54000 (61%)] Loss: -1262.054199\n",
      "Train Epoch: 44 [36864/54000 (68%)] Loss: -1269.437500\n",
      "Train Epoch: 44 [40960/54000 (76%)] Loss: -1265.657959\n",
      "Train Epoch: 44 [45056/54000 (83%)] Loss: -1264.272461\n",
      "Train Epoch: 44 [49152/54000 (91%)] Loss: -1258.303955\n",
      "Train Epoch: 44 [53248/54000 (99%)] Loss: -1269.946777\n",
      "    epoch          : 44\n",
      "    loss           : -1264.2106019512737\n",
      "    ess            : 3.6713233830239536\n",
      "    log_marginal   : 1264.381567498519\n",
      "    val_loss       : -1264.0683339436848\n",
      "    val_ess        : 3.6786720355351767\n",
      "    val_log_marginal: 1264.236592610677\n",
      "Train Epoch: 45 [0/54000 (0%)] Loss: -1273.126099\n",
      "Train Epoch: 45 [4096/54000 (8%)] Loss: -1275.059570\n",
      "Train Epoch: 45 [8192/54000 (15%)] Loss: -1268.119629\n",
      "Train Epoch: 45 [12288/54000 (23%)] Loss: -1267.211060\n",
      "Train Epoch: 45 [16384/54000 (30%)] Loss: -1268.973389\n",
      "Train Epoch: 45 [20480/54000 (38%)] Loss: -1269.616211\n",
      "Train Epoch: 45 [24576/54000 (46%)] Loss: -1263.013916\n",
      "Train Epoch: 45 [28672/54000 (53%)] Loss: -1270.678955\n",
      "Train Epoch: 45 [32768/54000 (61%)] Loss: -1271.575317\n",
      "Train Epoch: 45 [36864/54000 (68%)] Loss: -1269.470337\n",
      "Train Epoch: 45 [40960/54000 (76%)] Loss: -1265.376343\n",
      "Train Epoch: 45 [45056/54000 (83%)] Loss: -1273.803467\n",
      "Train Epoch: 45 [49152/54000 (91%)] Loss: -1268.673340\n",
      "Train Epoch: 45 [53248/54000 (99%)] Loss: -1264.839844\n",
      "    epoch          : 45\n",
      "    loss           : -1268.3350974711198\n",
      "    ess            : 3.6629836977375625\n",
      "    log_marginal   : 1268.5150904361672\n",
      "    val_loss       : -1267.7689412434895\n",
      "    val_ess        : 3.6702178716659546\n",
      "    val_log_marginal: 1267.9412027994792\n",
      "Train Epoch: 46 [0/54000 (0%)] Loss: -1275.335205\n",
      "Train Epoch: 46 [4096/54000 (8%)] Loss: -1268.994263\n",
      "Train Epoch: 46 [8192/54000 (15%)] Loss: -1268.723999\n",
      "Train Epoch: 46 [12288/54000 (23%)] Loss: -1264.843262\n",
      "Train Epoch: 46 [16384/54000 (30%)] Loss: -1264.129883\n",
      "Train Epoch: 46 [20480/54000 (38%)] Loss: -1273.072998\n",
      "Train Epoch: 46 [24576/54000 (46%)] Loss: -1273.716309\n",
      "Train Epoch: 46 [28672/54000 (53%)] Loss: -1273.970947\n",
      "Train Epoch: 46 [32768/54000 (61%)] Loss: -1275.145874\n",
      "Train Epoch: 46 [36864/54000 (68%)] Loss: -1272.489502\n",
      "Train Epoch: 46 [40960/54000 (76%)] Loss: -1266.397705\n",
      "Train Epoch: 46 [45056/54000 (83%)] Loss: -1279.529907\n",
      "Train Epoch: 46 [49152/54000 (91%)] Loss: -1266.845215\n",
      "Train Epoch: 46 [53248/54000 (99%)] Loss: -1270.048828\n",
      "    epoch          : 46\n",
      "    loss           : -1272.070685653325\n",
      "    ess            : 3.659015949303505\n",
      "    log_marginal   : 1272.2563430279918\n",
      "    val_loss       : -1271.6115010579426\n",
      "    val_ess        : 3.6708191136519113\n",
      "    val_log_marginal: 1271.7906239827473\n",
      "Train Epoch: 47 [0/54000 (0%)] Loss: -1273.621094\n",
      "Train Epoch: 47 [4096/54000 (8%)] Loss: -1280.124512\n",
      "Train Epoch: 47 [8192/54000 (15%)] Loss: -1276.731934\n",
      "Train Epoch: 47 [12288/54000 (23%)] Loss: -1279.497314\n",
      "Train Epoch: 47 [16384/54000 (30%)] Loss: -1276.313843\n",
      "Train Epoch: 47 [20480/54000 (38%)] Loss: -1271.338379\n",
      "Train Epoch: 47 [24576/54000 (46%)] Loss: -1279.143799\n",
      "Train Epoch: 47 [28672/54000 (53%)] Loss: -1282.887695\n",
      "Train Epoch: 47 [32768/54000 (61%)] Loss: -1283.455811\n",
      "Train Epoch: 47 [36864/54000 (68%)] Loss: -1274.194458\n",
      "Train Epoch: 47 [40960/54000 (76%)] Loss: -1270.453369\n",
      "Train Epoch: 47 [45056/54000 (83%)] Loss: -1275.395752\n",
      "Train Epoch: 47 [49152/54000 (91%)] Loss: -1272.768921\n",
      "Train Epoch: 47 [53248/54000 (99%)] Loss: -1283.705078\n",
      "    epoch          : 47\n",
      "    loss           : -1275.6932714380923\n",
      "    ess            : 3.659347769208429\n",
      "    log_marginal   : 1275.8789560037767\n",
      "    val_loss       : -1275.509994506836\n",
      "    val_ess        : 3.6587663888931274\n",
      "    val_log_marginal: 1275.6997629801433\n",
      "Train Epoch: 48 [0/54000 (0%)] Loss: -1280.594482\n",
      "Train Epoch: 48 [4096/54000 (8%)] Loss: -1278.359375\n",
      "Train Epoch: 48 [8192/54000 (15%)] Loss: -1273.705566\n",
      "Train Epoch: 48 [12288/54000 (23%)] Loss: -1284.817749\n",
      "Train Epoch: 48 [16384/54000 (30%)] Loss: -1272.201660\n",
      "Train Epoch: 48 [20480/54000 (38%)] Loss: -1284.755127\n",
      "Train Epoch: 48 [24576/54000 (46%)] Loss: -1281.456787\n",
      "Train Epoch: 48 [28672/54000 (53%)] Loss: -1281.028564\n",
      "Train Epoch: 48 [32768/54000 (61%)] Loss: -1279.618896\n",
      "Train Epoch: 48 [36864/54000 (68%)] Loss: -1279.653320\n",
      "Train Epoch: 48 [40960/54000 (76%)] Loss: -1281.607544\n",
      "Train Epoch: 48 [45056/54000 (83%)] Loss: -1278.287109\n",
      "Train Epoch: 48 [49152/54000 (91%)] Loss: -1287.862183\n",
      "Train Epoch: 48 [53248/54000 (99%)] Loss: -1280.645020\n",
      "    epoch          : 48\n",
      "    loss           : -1279.4431262264884\n",
      "    ess            : 3.660201914502546\n",
      "    log_marginal   : 1279.6262137607375\n",
      "    val_loss       : -1279.0901285807292\n",
      "    val_ess        : 3.6496946215629578\n",
      "    val_log_marginal: 1279.2847951253254\n",
      "Train Epoch: 49 [0/54000 (0%)] Loss: -1278.695801\n",
      "Train Epoch: 49 [4096/54000 (8%)] Loss: -1284.949219\n",
      "Train Epoch: 49 [8192/54000 (15%)] Loss: -1285.271240\n",
      "Train Epoch: 49 [12288/54000 (23%)] Loss: -1278.599365\n",
      "Train Epoch: 49 [16384/54000 (30%)] Loss: -1277.953857\n",
      "Train Epoch: 49 [20480/54000 (38%)] Loss: -1281.670654\n",
      "Train Epoch: 49 [24576/54000 (46%)] Loss: -1278.045166\n",
      "Train Epoch: 49 [28672/54000 (53%)] Loss: -1288.796265\n",
      "Train Epoch: 49 [32768/54000 (61%)] Loss: -1287.612549\n",
      "Train Epoch: 49 [36864/54000 (68%)] Loss: -1287.127686\n",
      "Train Epoch: 49 [40960/54000 (76%)] Loss: -1280.047852\n",
      "Train Epoch: 49 [45056/54000 (83%)] Loss: -1285.100098\n",
      "Train Epoch: 49 [49152/54000 (91%)] Loss: -1280.961182\n",
      "Train Epoch: 49 [53248/54000 (99%)] Loss: -1285.944336\n",
      "    epoch          : 49\n",
      "    loss           : -1283.0039999722305\n",
      "    ess            : 3.6552310136822164\n",
      "    log_marginal   : 1283.1921866900548\n",
      "    val_loss       : -1281.6359405517578\n",
      "    val_ess        : 3.6664318641026816\n",
      "    val_log_marginal: 1281.8090209960938\n",
      "Train Epoch: 50 [0/54000 (0%)] Loss: -1284.965332\n",
      "Train Epoch: 50 [4096/54000 (8%)] Loss: -1284.348145\n",
      "Train Epoch: 50 [8192/54000 (15%)] Loss: -1286.500488\n",
      "Train Epoch: 50 [12288/54000 (23%)] Loss: -1282.877441\n",
      "Train Epoch: 50 [16384/54000 (30%)] Loss: -1287.876221\n",
      "Train Epoch: 50 [20480/54000 (38%)] Loss: -1283.229492\n",
      "Train Epoch: 50 [24576/54000 (46%)] Loss: -1285.943359\n",
      "Train Epoch: 50 [28672/54000 (53%)] Loss: -1293.604004\n",
      "Train Epoch: 50 [32768/54000 (61%)] Loss: -1287.849854\n",
      "Train Epoch: 50 [36864/54000 (68%)] Loss: -1283.449219\n",
      "Train Epoch: 50 [40960/54000 (76%)] Loss: -1291.106689\n",
      "Train Epoch: 50 [45056/54000 (83%)] Loss: -1288.060303\n",
      "Train Epoch: 50 [49152/54000 (91%)] Loss: -1283.237549\n",
      "Train Epoch: 50 [53248/54000 (99%)] Loss: -1288.227905\n",
      "    epoch          : 50\n",
      "    loss           : -1286.175743066869\n",
      "    ess            : 3.6576855284342833\n",
      "    log_marginal   : 1286.3574392309686\n",
      "    val_loss       : -1285.9050547281902\n",
      "    val_ess        : 3.6520169377326965\n",
      "    val_log_marginal: 1286.0807444254558\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [0/54000 (0%)] Loss: -1290.649170\n",
      "Train Epoch: 51 [4096/54000 (8%)] Loss: -1287.850342\n",
      "Train Epoch: 51 [8192/54000 (15%)] Loss: -1288.490479\n",
      "Train Epoch: 51 [12288/54000 (23%)] Loss: -1294.582031\n",
      "Train Epoch: 51 [16384/54000 (30%)] Loss: -1287.982544\n",
      "Train Epoch: 51 [20480/54000 (38%)] Loss: -1294.648682\n",
      "Train Epoch: 51 [24576/54000 (46%)] Loss: -1301.742676\n",
      "Train Epoch: 51 [28672/54000 (53%)] Loss: -1292.279907\n",
      "Train Epoch: 51 [32768/54000 (61%)] Loss: -1294.096924\n",
      "Train Epoch: 51 [36864/54000 (68%)] Loss: -1286.568115\n",
      "Train Epoch: 51 [40960/54000 (76%)] Loss: -1284.265259\n",
      "Train Epoch: 51 [45056/54000 (83%)] Loss: -1291.412598\n",
      "Train Epoch: 51 [49152/54000 (91%)] Loss: -1289.487305\n",
      "Train Epoch: 51 [53248/54000 (99%)] Loss: -1289.592041\n",
      "    epoch          : 51\n",
      "    loss           : -1289.0191158638181\n",
      "    ess            : 3.6517496312399045\n",
      "    log_marginal   : 1289.2087454411655\n",
      "    val_loss       : -1288.6123301188152\n",
      "    val_ess        : 3.6416151920954385\n",
      "    val_log_marginal: 1288.823735555013\n",
      "Train Epoch: 52 [0/54000 (0%)] Loss: -1289.607788\n",
      "Train Epoch: 52 [4096/54000 (8%)] Loss: -1293.455078\n",
      "Train Epoch: 52 [8192/54000 (15%)] Loss: -1287.333740\n",
      "Train Epoch: 52 [12288/54000 (23%)] Loss: -1297.111084\n",
      "Train Epoch: 52 [16384/54000 (30%)] Loss: -1293.966553\n",
      "Train Epoch: 52 [20480/54000 (38%)] Loss: -1291.451416\n",
      "Train Epoch: 52 [24576/54000 (46%)] Loss: -1294.063721\n",
      "Train Epoch: 52 [28672/54000 (53%)] Loss: -1291.724121\n",
      "Train Epoch: 52 [32768/54000 (61%)] Loss: -1295.145752\n",
      "Train Epoch: 52 [36864/54000 (68%)] Loss: -1299.900635\n",
      "Train Epoch: 52 [40960/54000 (76%)] Loss: -1294.082397\n",
      "Train Epoch: 52 [45056/54000 (83%)] Loss: -1292.860352\n",
      "Train Epoch: 52 [49152/54000 (91%)] Loss: -1295.408813\n",
      "Train Epoch: 52 [53248/54000 (99%)] Loss: -1293.545898\n",
      "    epoch          : 52\n",
      "    loss           : -1292.210911466047\n",
      "    ess            : 3.651467939123723\n",
      "    log_marginal   : 1292.402648636515\n",
      "    val_loss       : -1290.9459940592449\n",
      "    val_ess        : 3.6481000185012817\n",
      "    val_log_marginal: 1291.133076985677\n",
      "Train Epoch: 53 [0/54000 (0%)] Loss: -1289.224731\n",
      "Train Epoch: 53 [4096/54000 (8%)] Loss: -1290.703613\n",
      "Train Epoch: 53 [8192/54000 (15%)] Loss: -1300.116821\n",
      "Train Epoch: 53 [12288/54000 (23%)] Loss: -1290.076416\n",
      "Train Epoch: 53 [16384/54000 (30%)] Loss: -1296.081909\n",
      "Train Epoch: 53 [20480/54000 (38%)] Loss: -1294.783325\n",
      "Train Epoch: 53 [24576/54000 (46%)] Loss: -1294.704590\n",
      "Train Epoch: 53 [28672/54000 (53%)] Loss: -1299.020996\n",
      "Train Epoch: 53 [32768/54000 (61%)] Loss: -1295.287354\n",
      "Train Epoch: 53 [36864/54000 (68%)] Loss: -1297.544312\n",
      "Train Epoch: 53 [40960/54000 (76%)] Loss: -1292.542114\n",
      "Train Epoch: 53 [45056/54000 (83%)] Loss: -1294.851074\n",
      "Train Epoch: 53 [49152/54000 (91%)] Loss: -1298.774414\n",
      "Train Epoch: 53 [53248/54000 (99%)] Loss: -1287.033936\n",
      "    epoch          : 53\n",
      "    loss           : -1295.1191215334345\n",
      "    ess            : 3.654934853739083\n",
      "    log_marginal   : 1295.3041645068129\n",
      "    val_loss       : -1293.8627166748047\n",
      "    val_ess        : 3.6459700564543405\n",
      "    val_log_marginal: 1294.0467122395833\n",
      "Train Epoch: 54 [0/54000 (0%)] Loss: -1294.281372\n",
      "Train Epoch: 54 [4096/54000 (8%)] Loss: -1295.386963\n",
      "Train Epoch: 54 [8192/54000 (15%)] Loss: -1295.583008\n",
      "Train Epoch: 54 [12288/54000 (23%)] Loss: -1300.589355\n",
      "Train Epoch: 54 [16384/54000 (30%)] Loss: -1296.786377\n",
      "Train Epoch: 54 [20480/54000 (38%)] Loss: -1300.588745\n",
      "Train Epoch: 54 [24576/54000 (46%)] Loss: -1295.661011\n",
      "Train Epoch: 54 [28672/54000 (53%)] Loss: -1305.014648\n",
      "Train Epoch: 54 [32768/54000 (61%)] Loss: -1300.245361\n",
      "Train Epoch: 54 [36864/54000 (68%)] Loss: -1299.740723\n",
      "Train Epoch: 54 [40960/54000 (76%)] Loss: -1301.472534\n",
      "Train Epoch: 54 [45056/54000 (83%)] Loss: -1296.769531\n",
      "Train Epoch: 54 [49152/54000 (91%)] Loss: -1297.877930\n",
      "Train Epoch: 54 [53248/54000 (99%)] Loss: -1299.249390\n",
      "    epoch          : 54\n",
      "    loss           : -1297.7403037988745\n",
      "    ess            : 3.6602895384151224\n",
      "    log_marginal   : 1297.9227329633811\n",
      "    val_loss       : -1297.2712097167969\n",
      "    val_ess        : 3.6563370327154794\n",
      "    val_log_marginal: 1297.4537048339844\n",
      "Train Epoch: 55 [0/54000 (0%)] Loss: -1298.278564\n",
      "Train Epoch: 55 [4096/54000 (8%)] Loss: -1303.201172\n",
      "Train Epoch: 55 [8192/54000 (15%)] Loss: -1298.637573\n",
      "Train Epoch: 55 [12288/54000 (23%)] Loss: -1291.214111\n",
      "Train Epoch: 55 [16384/54000 (30%)] Loss: -1297.593262\n",
      "Train Epoch: 55 [20480/54000 (38%)] Loss: -1299.870483\n",
      "Train Epoch: 55 [24576/54000 (46%)] Loss: -1301.487549\n",
      "Train Epoch: 55 [28672/54000 (53%)] Loss: -1304.117554\n",
      "Train Epoch: 55 [32768/54000 (61%)] Loss: -1305.926514\n",
      "Train Epoch: 55 [36864/54000 (68%)] Loss: -1301.280273\n",
      "Train Epoch: 55 [40960/54000 (76%)] Loss: -1306.573486\n",
      "Train Epoch: 55 [45056/54000 (83%)] Loss: -1296.666382\n",
      "Train Epoch: 55 [49152/54000 (91%)] Loss: -1304.792969\n",
      "Train Epoch: 55 [53248/54000 (99%)] Loss: -1293.982666\n",
      "    epoch          : 55\n",
      "    loss           : -1300.5864830559465\n",
      "    ess            : 3.6629546569986933\n",
      "    log_marginal   : 1300.762320423578\n",
      "    val_loss       : -1299.489466349284\n",
      "    val_ess        : 3.65430357058843\n",
      "    val_log_marginal: 1299.6693013509114\n",
      "Train Epoch: 56 [0/54000 (0%)] Loss: -1305.302979\n",
      "Train Epoch: 56 [4096/54000 (8%)] Loss: -1301.803955\n",
      "Train Epoch: 56 [8192/54000 (15%)] Loss: -1299.716064\n",
      "Train Epoch: 56 [12288/54000 (23%)] Loss: -1307.685059\n",
      "Train Epoch: 56 [16384/54000 (30%)] Loss: -1303.105225\n",
      "Train Epoch: 56 [20480/54000 (38%)] Loss: -1304.198853\n",
      "Train Epoch: 56 [24576/54000 (46%)] Loss: -1300.524414\n",
      "Train Epoch: 56 [28672/54000 (53%)] Loss: -1302.747925\n",
      "Train Epoch: 56 [32768/54000 (61%)] Loss: -1298.519409\n",
      "Train Epoch: 56 [36864/54000 (68%)] Loss: -1300.649170\n",
      "Train Epoch: 56 [40960/54000 (76%)] Loss: -1305.468750\n",
      "Train Epoch: 56 [45056/54000 (83%)] Loss: -1304.329102\n",
      "Train Epoch: 56 [49152/54000 (91%)] Loss: -1301.539307\n",
      "Train Epoch: 56 [53248/54000 (99%)] Loss: -1299.988525\n",
      "    epoch          : 56\n",
      "    loss           : -1302.8658736531768\n",
      "    ess            : 3.6646326774669484\n",
      "    log_marginal   : 1303.0402612188982\n",
      "    val_loss       : -1301.1300455729167\n",
      "    val_ess        : 3.6617116232713065\n",
      "    val_log_marginal: 1301.3021443684895\n",
      "Train Epoch: 57 [0/54000 (0%)] Loss: -1304.541016\n",
      "Train Epoch: 57 [4096/54000 (8%)] Loss: -1301.477783\n",
      "Train Epoch: 57 [8192/54000 (15%)] Loss: -1308.958984\n",
      "Train Epoch: 57 [12288/54000 (23%)] Loss: -1303.726929\n",
      "Train Epoch: 57 [16384/54000 (30%)] Loss: -1307.926636\n",
      "Train Epoch: 57 [20480/54000 (38%)] Loss: -1305.894531\n",
      "Train Epoch: 57 [24576/54000 (46%)] Loss: -1306.542358\n",
      "Train Epoch: 57 [28672/54000 (53%)] Loss: -1299.658569\n",
      "Train Epoch: 57 [32768/54000 (61%)] Loss: -1305.797852\n",
      "Train Epoch: 57 [36864/54000 (68%)] Loss: -1307.843872\n",
      "Train Epoch: 57 [40960/54000 (76%)] Loss: -1303.958618\n",
      "Train Epoch: 57 [45056/54000 (83%)] Loss: -1304.644043\n",
      "Train Epoch: 57 [49152/54000 (91%)] Loss: -1308.807129\n",
      "Train Epoch: 57 [53248/54000 (99%)] Loss: -1302.605957\n",
      "    epoch          : 57\n",
      "    loss           : -1305.5323746667655\n",
      "    ess            : 3.664968675911709\n",
      "    log_marginal   : 1305.7074211807612\n",
      "    val_loss       : -1304.4471944173176\n",
      "    val_ess        : 3.674305945634842\n",
      "    val_log_marginal: 1304.6082661946614\n",
      "Train Epoch: 58 [0/54000 (0%)] Loss: -1309.097412\n",
      "Train Epoch: 58 [4096/54000 (8%)] Loss: -1306.417114\n",
      "Train Epoch: 58 [8192/54000 (15%)] Loss: -1306.497681\n",
      "Train Epoch: 58 [12288/54000 (23%)] Loss: -1306.570679\n",
      "Train Epoch: 58 [16384/54000 (30%)] Loss: -1312.258911\n",
      "Train Epoch: 58 [20480/54000 (38%)] Loss: -1309.134766\n",
      "Train Epoch: 58 [24576/54000 (46%)] Loss: -1305.482666\n",
      "Train Epoch: 58 [28672/54000 (53%)] Loss: -1313.489380\n",
      "Train Epoch: 58 [32768/54000 (61%)] Loss: -1316.953735\n",
      "Train Epoch: 58 [36864/54000 (68%)] Loss: -1310.091675\n",
      "Train Epoch: 58 [40960/54000 (76%)] Loss: -1310.724365\n",
      "Train Epoch: 58 [45056/54000 (83%)] Loss: -1310.363281\n",
      "Train Epoch: 58 [49152/54000 (91%)] Loss: -1313.001343\n",
      "Train Epoch: 58 [53248/54000 (99%)] Loss: -1311.760010\n",
      "    epoch          : 58\n",
      "    loss           : -1308.1106992604043\n",
      "    ess            : 3.6621255637345156\n",
      "    log_marginal   : 1308.2864689397586\n",
      "    val_loss       : -1307.8578592936199\n",
      "    val_ess        : 3.6708003083864846\n",
      "    val_log_marginal: 1308.0217895507812\n",
      "Train Epoch: 59 [0/54000 (0%)] Loss: -1307.580444\n",
      "Train Epoch: 59 [4096/54000 (8%)] Loss: -1304.386597\n",
      "Train Epoch: 59 [8192/54000 (15%)] Loss: -1304.929077\n",
      "Train Epoch: 59 [12288/54000 (23%)] Loss: -1309.694092\n",
      "Train Epoch: 59 [16384/54000 (30%)] Loss: -1315.643066\n",
      "Train Epoch: 59 [20480/54000 (38%)] Loss: -1306.171387\n",
      "Train Epoch: 59 [24576/54000 (46%)] Loss: -1306.734131\n",
      "Train Epoch: 59 [28672/54000 (53%)] Loss: -1302.508545\n",
      "Train Epoch: 59 [32768/54000 (61%)] Loss: -1306.947632\n",
      "Train Epoch: 59 [36864/54000 (68%)] Loss: -1310.945557\n",
      "Train Epoch: 59 [40960/54000 (76%)] Loss: -1305.790527\n",
      "Train Epoch: 59 [45056/54000 (83%)] Loss: -1313.973389\n",
      "Train Epoch: 59 [49152/54000 (91%)] Loss: -1315.026611\n",
      "Train Epoch: 59 [53248/54000 (99%)] Loss: -1310.354980\n",
      "    epoch          : 59\n",
      "    loss           : -1310.0022042080125\n",
      "    ess            : 3.663079448220854\n",
      "    log_marginal   : 1310.1758408388255\n",
      "    val_loss       : -1309.1194814046223\n",
      "    val_ess        : 3.6535118917624154\n",
      "    val_log_marginal: 1309.2965698242188\n",
      "Train Epoch: 60 [0/54000 (0%)] Loss: -1319.236816\n",
      "Train Epoch: 60 [4096/54000 (8%)] Loss: -1305.547241\n",
      "Train Epoch: 60 [8192/54000 (15%)] Loss: -1303.480347\n",
      "Train Epoch: 60 [12288/54000 (23%)] Loss: -1310.015381\n",
      "Train Epoch: 60 [16384/54000 (30%)] Loss: -1309.409180\n",
      "Train Epoch: 60 [20480/54000 (38%)] Loss: -1318.055664\n",
      "Train Epoch: 60 [24576/54000 (46%)] Loss: -1308.366089\n",
      "Train Epoch: 60 [28672/54000 (53%)] Loss: -1306.890625\n",
      "Train Epoch: 60 [32768/54000 (61%)] Loss: -1309.417725\n",
      "Train Epoch: 60 [36864/54000 (68%)] Loss: -1315.032959\n",
      "Train Epoch: 60 [40960/54000 (76%)] Loss: -1312.438232\n",
      "Train Epoch: 60 [45056/54000 (83%)] Loss: -1310.050049\n",
      "Train Epoch: 60 [49152/54000 (91%)] Loss: -1307.452881\n",
      "Train Epoch: 60 [53248/54000 (99%)] Loss: -1304.376709\n",
      "    epoch          : 60\n",
      "    loss           : -1312.263044167469\n",
      "    ess            : 3.665262957884802\n",
      "    log_marginal   : 1312.4342845175504\n",
      "    val_loss       : -1312.0058898925781\n",
      "    val_ess        : 3.66725155711174\n",
      "    val_log_marginal: 1312.1712697347004\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch60.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 61 [0/54000 (0%)] Loss: -1313.761597\n",
      "Train Epoch: 61 [4096/54000 (8%)] Loss: -1308.728394\n",
      "Train Epoch: 61 [8192/54000 (15%)] Loss: -1309.066772\n",
      "Train Epoch: 61 [12288/54000 (23%)] Loss: -1315.028564\n",
      "Train Epoch: 61 [16384/54000 (30%)] Loss: -1310.247559\n",
      "Train Epoch: 61 [20480/54000 (38%)] Loss: -1309.830322\n",
      "Train Epoch: 61 [24576/54000 (46%)] Loss: -1310.355957\n",
      "Train Epoch: 61 [28672/54000 (53%)] Loss: -1310.420898\n",
      "Train Epoch: 61 [32768/54000 (61%)] Loss: -1312.156494\n",
      "Train Epoch: 61 [36864/54000 (68%)] Loss: -1315.687500\n",
      "Train Epoch: 61 [40960/54000 (76%)] Loss: -1324.991455\n",
      "Train Epoch: 61 [45056/54000 (83%)] Loss: -1319.546631\n",
      "Train Epoch: 61 [49152/54000 (91%)] Loss: -1310.319702\n",
      "Train Epoch: 61 [53248/54000 (99%)] Loss: -1318.215576\n",
      "    epoch          : 61\n",
      "    loss           : -1314.3147736318867\n",
      "    ess            : 3.666558199019229\n",
      "    log_marginal   : 1314.48356794746\n",
      "    val_loss       : -1312.8119049072266\n",
      "    val_ess        : 3.6633456349372864\n",
      "    val_log_marginal: 1312.980224609375\n",
      "Train Epoch: 62 [0/54000 (0%)] Loss: -1319.810913\n",
      "Train Epoch: 62 [4096/54000 (8%)] Loss: -1321.724854\n",
      "Train Epoch: 62 [8192/54000 (15%)] Loss: -1316.158447\n",
      "Train Epoch: 62 [12288/54000 (23%)] Loss: -1319.881104\n",
      "Train Epoch: 62 [16384/54000 (30%)] Loss: -1312.412598\n",
      "Train Epoch: 62 [20480/54000 (38%)] Loss: -1315.055664\n",
      "Train Epoch: 62 [24576/54000 (46%)] Loss: -1318.925781\n",
      "Train Epoch: 62 [28672/54000 (53%)] Loss: -1315.920532\n",
      "Train Epoch: 62 [32768/54000 (61%)] Loss: -1313.578247\n",
      "Train Epoch: 62 [36864/54000 (68%)] Loss: -1320.046509\n",
      "Train Epoch: 62 [40960/54000 (76%)] Loss: -1318.720459\n",
      "Train Epoch: 62 [45056/54000 (83%)] Loss: -1308.169678\n",
      "Train Epoch: 62 [49152/54000 (91%)] Loss: -1315.357544\n",
      "Train Epoch: 62 [53248/54000 (99%)] Loss: -1313.970093\n",
      "    epoch          : 62\n",
      "    loss           : -1316.3335180779768\n",
      "    ess            : 3.669181705086152\n",
      "    log_marginal   : 1316.5005565480599\n",
      "    val_loss       : -1314.7046763102214\n",
      "    val_ess        : 3.6885434885819754\n",
      "    val_log_marginal: 1314.8492228190105\n",
      "Train Epoch: 63 [0/54000 (0%)] Loss: -1317.513184\n",
      "Train Epoch: 63 [4096/54000 (8%)] Loss: -1318.366455\n",
      "Train Epoch: 63 [8192/54000 (15%)] Loss: -1317.951416\n",
      "Train Epoch: 63 [12288/54000 (23%)] Loss: -1316.512817\n",
      "Train Epoch: 63 [16384/54000 (30%)] Loss: -1323.724365\n",
      "Train Epoch: 63 [20480/54000 (38%)] Loss: -1310.006836\n",
      "Train Epoch: 63 [24576/54000 (46%)] Loss: -1320.118774\n",
      "Train Epoch: 63 [28672/54000 (53%)] Loss: -1323.450195\n",
      "Train Epoch: 63 [32768/54000 (61%)] Loss: -1316.953369\n",
      "Train Epoch: 63 [36864/54000 (68%)] Loss: -1320.799072\n",
      "Train Epoch: 63 [40960/54000 (76%)] Loss: -1321.047241\n",
      "Train Epoch: 63 [45056/54000 (83%)] Loss: -1327.582764\n",
      "Train Epoch: 63 [49152/54000 (91%)] Loss: -1316.227539\n",
      "Train Epoch: 63 [53248/54000 (99%)] Loss: -1320.105347\n",
      "    epoch          : 63\n",
      "    loss           : -1318.3829623398622\n",
      "    ess            : 3.677580326089362\n",
      "    log_marginal   : 1318.539919884849\n",
      "    val_loss       : -1317.8783721923828\n",
      "    val_ess        : 3.6654083530108132\n",
      "    val_log_marginal: 1318.0391540527344\n",
      "Train Epoch: 64 [0/54000 (0%)] Loss: -1317.968384\n",
      "Train Epoch: 64 [4096/54000 (8%)] Loss: -1322.051758\n",
      "Train Epoch: 64 [8192/54000 (15%)] Loss: -1318.697144\n",
      "Train Epoch: 64 [12288/54000 (23%)] Loss: -1320.775391\n",
      "Train Epoch: 64 [16384/54000 (30%)] Loss: -1318.479492\n",
      "Train Epoch: 64 [20480/54000 (38%)] Loss: -1323.274048\n",
      "Train Epoch: 64 [24576/54000 (46%)] Loss: -1315.619629\n",
      "Train Epoch: 64 [28672/54000 (53%)] Loss: -1316.867920\n",
      "Train Epoch: 64 [32768/54000 (61%)] Loss: -1315.540405\n",
      "Train Epoch: 64 [36864/54000 (68%)] Loss: -1322.596680\n",
      "Train Epoch: 64 [40960/54000 (76%)] Loss: -1320.581055\n",
      "Train Epoch: 64 [45056/54000 (83%)] Loss: -1311.169800\n",
      "Train Epoch: 64 [49152/54000 (91%)] Loss: -1319.648682\n",
      "Train Epoch: 64 [53248/54000 (99%)] Loss: -1326.016479\n",
      "    epoch          : 64\n",
      "    loss           : -1320.0090181612854\n",
      "    ess            : 3.6782993309870715\n",
      "    log_marginal   : 1320.1645033416025\n",
      "    val_loss       : -1318.8286997477214\n",
      "    val_ess        : 3.6813478072484336\n",
      "    val_log_marginal: 1318.9803466796875\n",
      "Train Epoch: 65 [0/54000 (0%)] Loss: -1317.261230\n",
      "Train Epoch: 65 [4096/54000 (8%)] Loss: -1322.054077\n",
      "Train Epoch: 65 [8192/54000 (15%)] Loss: -1322.688965\n",
      "Train Epoch: 65 [12288/54000 (23%)] Loss: -1329.204590\n",
      "Train Epoch: 65 [16384/54000 (30%)] Loss: -1317.803955\n",
      "Train Epoch: 65 [20480/54000 (38%)] Loss: -1322.727539\n",
      "Train Epoch: 65 [24576/54000 (46%)] Loss: -1323.449463\n",
      "Train Epoch: 65 [28672/54000 (53%)] Loss: -1323.060791\n",
      "Train Epoch: 65 [32768/54000 (61%)] Loss: -1320.090576\n",
      "Train Epoch: 65 [36864/54000 (68%)] Loss: -1321.242310\n",
      "Train Epoch: 65 [40960/54000 (76%)] Loss: -1315.117920\n",
      "Train Epoch: 65 [45056/54000 (83%)] Loss: -1321.630127\n",
      "Train Epoch: 65 [49152/54000 (91%)] Loss: -1319.707764\n",
      "Train Epoch: 65 [53248/54000 (99%)] Loss: -1319.213623\n",
      "    epoch          : 65\n",
      "    loss           : -1321.6735284452755\n",
      "    ess            : 3.6799993639308695\n",
      "    log_marginal   : 1321.8256263190535\n",
      "    val_loss       : -1321.2849731445312\n",
      "    val_ess        : 3.67571492989858\n",
      "    val_log_marginal: 1321.4407297770183\n",
      "Train Epoch: 66 [0/54000 (0%)] Loss: -1323.904297\n",
      "Train Epoch: 66 [4096/54000 (8%)] Loss: -1318.768799\n",
      "Train Epoch: 66 [8192/54000 (15%)] Loss: -1323.942993\n",
      "Train Epoch: 66 [12288/54000 (23%)] Loss: -1323.997314\n",
      "Train Epoch: 66 [16384/54000 (30%)] Loss: -1329.702759\n",
      "Train Epoch: 66 [20480/54000 (38%)] Loss: -1331.612305\n",
      "Train Epoch: 66 [24576/54000 (46%)] Loss: -1322.431396\n",
      "Train Epoch: 66 [28672/54000 (53%)] Loss: -1325.219238\n",
      "Train Epoch: 66 [32768/54000 (61%)] Loss: -1319.406616\n",
      "Train Epoch: 66 [36864/54000 (68%)] Loss: -1320.512817\n",
      "Train Epoch: 66 [40960/54000 (76%)] Loss: -1324.474243\n",
      "Train Epoch: 66 [45056/54000 (83%)] Loss: -1322.501221\n",
      "Train Epoch: 66 [49152/54000 (91%)] Loss: -1318.301270\n",
      "Train Epoch: 66 [53248/54000 (99%)] Loss: -1324.795288\n",
      "    epoch          : 66\n",
      "    loss           : -1323.5120184297245\n",
      "    ess            : 3.6909840344252745\n",
      "    log_marginal   : 1323.6574128498962\n",
      "    val_loss       : -1322.9588979085286\n",
      "    val_ess        : 3.69581147034963\n",
      "    val_log_marginal: 1323.1039276123047\n",
      "Train Epoch: 67 [0/54000 (0%)] Loss: -1325.098999\n",
      "Train Epoch: 67 [4096/54000 (8%)] Loss: -1325.408691\n",
      "Train Epoch: 67 [8192/54000 (15%)] Loss: -1324.215698\n",
      "Train Epoch: 67 [12288/54000 (23%)] Loss: -1322.924683\n",
      "Train Epoch: 67 [16384/54000 (30%)] Loss: -1319.353394\n",
      "Train Epoch: 67 [20480/54000 (38%)] Loss: -1324.542847\n",
      "Train Epoch: 67 [24576/54000 (46%)] Loss: -1321.672729\n",
      "Train Epoch: 67 [28672/54000 (53%)] Loss: -1325.451904\n",
      "Train Epoch: 67 [32768/54000 (61%)] Loss: -1325.038330\n",
      "Train Epoch: 67 [36864/54000 (68%)] Loss: -1329.714844\n",
      "Train Epoch: 67 [40960/54000 (76%)] Loss: -1325.072144\n",
      "Train Epoch: 67 [45056/54000 (83%)] Loss: -1326.832764\n",
      "Train Epoch: 67 [49152/54000 (91%)] Loss: -1317.495361\n",
      "Train Epoch: 67 [53248/54000 (99%)] Loss: -1324.957520\n",
      "    epoch          : 67\n",
      "    loss           : -1325.0512220916025\n",
      "    ess            : 3.692760530806266\n",
      "    log_marginal   : 1325.1933206133367\n",
      "    val_loss       : -1324.7484436035156\n",
      "    val_ess        : 3.6791518231232962\n",
      "    val_log_marginal: 1324.9025980631511\n",
      "Train Epoch: 68 [0/54000 (0%)] Loss: -1324.891724\n",
      "Train Epoch: 68 [4096/54000 (8%)] Loss: -1328.955322\n",
      "Train Epoch: 68 [8192/54000 (15%)] Loss: -1325.377441\n",
      "Train Epoch: 68 [12288/54000 (23%)] Loss: -1329.459229\n",
      "Train Epoch: 68 [16384/54000 (30%)] Loss: -1328.066162\n",
      "Train Epoch: 68 [20480/54000 (38%)] Loss: -1322.810303\n",
      "Train Epoch: 68 [24576/54000 (46%)] Loss: -1329.786743\n",
      "Train Epoch: 68 [28672/54000 (53%)] Loss: -1326.970703\n",
      "Train Epoch: 68 [32768/54000 (61%)] Loss: -1327.667480\n",
      "Train Epoch: 68 [36864/54000 (68%)] Loss: -1327.320801\n",
      "Train Epoch: 68 [40960/54000 (76%)] Loss: -1328.537598\n",
      "Train Epoch: 68 [45056/54000 (83%)] Loss: -1326.262939\n",
      "Train Epoch: 68 [49152/54000 (91%)] Loss: -1323.156128\n",
      "Train Epoch: 68 [53248/54000 (99%)] Loss: -1328.764771\n",
      "    epoch          : 68\n",
      "    loss           : -1326.7587601358857\n",
      "    ess            : 3.696419914751821\n",
      "    log_marginal   : 1326.896726780028\n",
      "    val_loss       : -1325.9305419921875\n",
      "    val_ess        : 3.6984298626581826\n",
      "    val_log_marginal: 1326.0765991210938\n",
      "Train Epoch: 69 [0/54000 (0%)] Loss: -1334.565430\n",
      "Train Epoch: 69 [4096/54000 (8%)] Loss: -1334.487305\n",
      "Train Epoch: 69 [8192/54000 (15%)] Loss: -1325.663940\n",
      "Train Epoch: 69 [12288/54000 (23%)] Loss: -1329.363159\n",
      "Train Epoch: 69 [16384/54000 (30%)] Loss: -1325.706055\n",
      "Train Epoch: 69 [20480/54000 (38%)] Loss: -1327.717651\n",
      "Train Epoch: 69 [24576/54000 (46%)] Loss: -1324.740845\n",
      "Train Epoch: 69 [28672/54000 (53%)] Loss: -1330.447754\n",
      "Train Epoch: 69 [32768/54000 (61%)] Loss: -1329.645020\n",
      "Train Epoch: 69 [36864/54000 (68%)] Loss: -1323.963013\n",
      "Train Epoch: 69 [40960/54000 (76%)] Loss: -1329.689819\n",
      "Train Epoch: 69 [45056/54000 (83%)] Loss: -1328.256104\n",
      "Train Epoch: 69 [49152/54000 (91%)] Loss: -1324.755981\n",
      "Train Epoch: 69 [53248/54000 (99%)] Loss: -1329.686401\n",
      "    epoch          : 69\n",
      "    loss           : -1328.235831744298\n",
      "    ess            : 3.7056908019911057\n",
      "    log_marginal   : 1328.367469823756\n",
      "    val_loss       : -1327.654800415039\n",
      "    val_ess        : 3.69217985868454\n",
      "    val_log_marginal: 1327.7935791015625\n",
      "Train Epoch: 70 [0/54000 (0%)] Loss: -1328.873535\n",
      "Train Epoch: 70 [4096/54000 (8%)] Loss: -1325.835449\n",
      "Train Epoch: 70 [8192/54000 (15%)] Loss: -1331.610229\n",
      "Train Epoch: 70 [12288/54000 (23%)] Loss: -1329.955322\n",
      "Train Epoch: 70 [16384/54000 (30%)] Loss: -1323.163452\n",
      "Train Epoch: 70 [20480/54000 (38%)] Loss: -1331.439941\n",
      "Train Epoch: 70 [24576/54000 (46%)] Loss: -1333.885498\n",
      "Train Epoch: 70 [28672/54000 (53%)] Loss: -1324.769287\n",
      "Train Epoch: 70 [32768/54000 (61%)] Loss: -1327.600098\n",
      "Train Epoch: 70 [36864/54000 (68%)] Loss: -1324.757080\n",
      "Train Epoch: 70 [40960/54000 (76%)] Loss: -1328.562988\n",
      "Train Epoch: 70 [45056/54000 (83%)] Loss: -1329.082153\n",
      "Train Epoch: 70 [49152/54000 (91%)] Loss: -1335.674805\n",
      "Train Epoch: 70 [53248/54000 (99%)] Loss: -1330.340942\n",
      "    epoch          : 70\n",
      "    loss           : -1329.739037970231\n",
      "    ess            : 3.706670685402025\n",
      "    log_marginal   : 1329.8725805779768\n",
      "    val_loss       : -1328.9137522379558\n",
      "    val_ess        : 3.7047877609729767\n",
      "    val_log_marginal: 1329.0512949625652\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch70.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 71 [0/54000 (0%)] Loss: -1334.334717\n",
      "Train Epoch: 71 [4096/54000 (8%)] Loss: -1328.437256\n",
      "Train Epoch: 71 [8192/54000 (15%)] Loss: -1332.426758\n",
      "Train Epoch: 71 [12288/54000 (23%)] Loss: -1328.399902\n",
      "Train Epoch: 71 [16384/54000 (30%)] Loss: -1332.041992\n",
      "Train Epoch: 71 [20480/54000 (38%)] Loss: -1336.610107\n",
      "Train Epoch: 71 [24576/54000 (46%)] Loss: -1323.520142\n",
      "Train Epoch: 71 [28672/54000 (53%)] Loss: -1332.223145\n",
      "Train Epoch: 71 [32768/54000 (61%)] Loss: -1333.660034\n",
      "Train Epoch: 71 [36864/54000 (68%)] Loss: -1327.383789\n",
      "Train Epoch: 71 [40960/54000 (76%)] Loss: -1325.755005\n",
      "Train Epoch: 71 [45056/54000 (83%)] Loss: -1330.684326\n",
      "Train Epoch: 71 [49152/54000 (91%)] Loss: -1326.415894\n",
      "Train Epoch: 71 [53248/54000 (99%)] Loss: -1332.125488\n",
      "    epoch          : 71\n",
      "    loss           : -1331.1832853922913\n",
      "    ess            : 3.7145019933510732\n",
      "    log_marginal   : 1331.3108326699496\n",
      "    val_loss       : -1330.339619954427\n",
      "    val_ess        : 3.709751417239507\n",
      "    val_log_marginal: 1330.4781697591145\n",
      "Train Epoch: 72 [0/54000 (0%)] Loss: -1324.030518\n",
      "Train Epoch: 72 [4096/54000 (8%)] Loss: -1336.234863\n",
      "Train Epoch: 72 [8192/54000 (15%)] Loss: -1335.030151\n",
      "Train Epoch: 72 [12288/54000 (23%)] Loss: -1337.493408\n",
      "Train Epoch: 72 [16384/54000 (30%)] Loss: -1339.776611\n",
      "Train Epoch: 72 [20480/54000 (38%)] Loss: -1328.958618\n",
      "Train Epoch: 72 [24576/54000 (46%)] Loss: -1330.096924\n",
      "Train Epoch: 72 [28672/54000 (53%)] Loss: -1328.759766\n",
      "Train Epoch: 72 [32768/54000 (61%)] Loss: -1325.858643\n",
      "Train Epoch: 72 [36864/54000 (68%)] Loss: -1327.882935\n",
      "Train Epoch: 72 [40960/54000 (76%)] Loss: -1332.457031\n",
      "Train Epoch: 72 [45056/54000 (83%)] Loss: -1335.840820\n",
      "Train Epoch: 72 [49152/54000 (91%)] Loss: -1334.408447\n",
      "Train Epoch: 72 [53248/54000 (99%)] Loss: -1327.725220\n",
      "    epoch          : 72\n",
      "    loss           : -1332.350830078125\n",
      "    ess            : 3.7166797911386356\n",
      "    log_marginal   : 1332.4771184695276\n",
      "    val_loss       : -1332.3648935953777\n",
      "    val_ess        : 3.7129997313022614\n",
      "    val_log_marginal: 1332.4911448160808\n",
      "Train Epoch: 73 [0/54000 (0%)] Loss: -1333.638794\n",
      "Train Epoch: 73 [4096/54000 (8%)] Loss: -1333.346191\n",
      "Train Epoch: 73 [8192/54000 (15%)] Loss: -1330.584229\n",
      "Train Epoch: 73 [12288/54000 (23%)] Loss: -1334.899780\n",
      "Train Epoch: 73 [16384/54000 (30%)] Loss: -1334.021362\n",
      "Train Epoch: 73 [20480/54000 (38%)] Loss: -1335.000122\n",
      "Train Epoch: 73 [24576/54000 (46%)] Loss: -1336.716064\n",
      "Train Epoch: 73 [28672/54000 (53%)] Loss: -1330.819092\n",
      "Train Epoch: 73 [32768/54000 (61%)] Loss: -1338.683838\n",
      "Train Epoch: 73 [36864/54000 (68%)] Loss: -1333.450684\n",
      "Train Epoch: 73 [40960/54000 (76%)] Loss: -1333.674805\n",
      "Train Epoch: 73 [45056/54000 (83%)] Loss: -1336.230957\n",
      "Train Epoch: 73 [49152/54000 (91%)] Loss: -1341.890869\n",
      "Train Epoch: 73 [53248/54000 (99%)] Loss: -1330.030762\n",
      "    epoch          : 73\n",
      "    loss           : -1333.9264095360634\n",
      "    ess            : 3.719596685391467\n",
      "    log_marginal   : 1334.049984032509\n",
      "    val_loss       : -1333.2109629313152\n",
      "    val_ess        : 3.7284421424070993\n",
      "    val_log_marginal: 1333.3330942789714\n",
      "Train Epoch: 74 [0/54000 (0%)] Loss: -1337.471436\n",
      "Train Epoch: 74 [4096/54000 (8%)] Loss: -1341.023926\n",
      "Train Epoch: 74 [8192/54000 (15%)] Loss: -1332.861328\n",
      "Train Epoch: 74 [12288/54000 (23%)] Loss: -1342.031982\n",
      "Train Epoch: 74 [16384/54000 (30%)] Loss: -1336.636719\n",
      "Train Epoch: 74 [20480/54000 (38%)] Loss: -1339.606934\n",
      "Train Epoch: 74 [24576/54000 (46%)] Loss: -1336.461792\n",
      "Train Epoch: 74 [28672/54000 (53%)] Loss: -1327.174194\n",
      "Train Epoch: 74 [32768/54000 (61%)] Loss: -1336.020386\n",
      "Train Epoch: 74 [36864/54000 (68%)] Loss: -1331.885986\n",
      "Train Epoch: 74 [40960/54000 (76%)] Loss: -1337.369629\n",
      "Train Epoch: 74 [45056/54000 (83%)] Loss: -1333.126221\n",
      "Train Epoch: 74 [49152/54000 (91%)] Loss: -1339.253052\n",
      "Train Epoch: 74 [53248/54000 (99%)] Loss: -1332.885742\n",
      "    epoch          : 74\n",
      "    loss           : -1335.1948687657361\n",
      "    ess            : 3.724853700936123\n",
      "    log_marginal   : 1335.315033971416\n",
      "    val_loss       : -1334.3978068033855\n",
      "    val_ess        : 3.7305633624394736\n",
      "    val_log_marginal: 1334.5110575358074\n",
      "Train Epoch: 75 [0/54000 (0%)] Loss: -1338.942139\n",
      "Train Epoch: 75 [4096/54000 (8%)] Loss: -1335.649048\n",
      "Train Epoch: 75 [8192/54000 (15%)] Loss: -1331.388306\n",
      "Train Epoch: 75 [12288/54000 (23%)] Loss: -1326.087891\n",
      "Train Epoch: 75 [16384/54000 (30%)] Loss: -1336.526123\n",
      "Train Epoch: 75 [20480/54000 (38%)] Loss: -1342.448608\n",
      "Train Epoch: 75 [24576/54000 (46%)] Loss: -1330.677124\n",
      "Train Epoch: 75 [28672/54000 (53%)] Loss: -1342.279297\n",
      "Train Epoch: 75 [32768/54000 (61%)] Loss: -1334.784424\n",
      "Train Epoch: 75 [36864/54000 (68%)] Loss: -1332.459473\n",
      "Train Epoch: 75 [40960/54000 (76%)] Loss: -1333.325806\n",
      "Train Epoch: 75 [45056/54000 (83%)] Loss: -1346.605225\n",
      "Train Epoch: 75 [49152/54000 (91%)] Loss: -1339.540527\n",
      "Train Epoch: 75 [53248/54000 (99%)] Loss: -1336.961060\n",
      "    epoch          : 75\n",
      "    loss           : -1336.5151598600414\n",
      "    ess            : 3.733936283825698\n",
      "    log_marginal   : 1336.6301610865298\n",
      "    val_loss       : -1336.0080820719402\n",
      "    val_ess        : 3.738103230794271\n",
      "    val_log_marginal: 1336.1193949381511\n",
      "Train Epoch: 76 [0/54000 (0%)] Loss: -1338.394165\n",
      "Train Epoch: 76 [4096/54000 (8%)] Loss: -1338.222656\n",
      "Train Epoch: 76 [8192/54000 (15%)] Loss: -1342.619263\n",
      "Train Epoch: 76 [12288/54000 (23%)] Loss: -1341.542480\n",
      "Train Epoch: 76 [16384/54000 (30%)] Loss: -1334.024780\n",
      "Train Epoch: 76 [20480/54000 (38%)] Loss: -1341.613892\n",
      "Train Epoch: 76 [24576/54000 (46%)] Loss: -1342.083618\n",
      "Train Epoch: 76 [28672/54000 (53%)] Loss: -1332.847290\n",
      "Train Epoch: 76 [32768/54000 (61%)] Loss: -1341.566284\n",
      "Train Epoch: 76 [36864/54000 (68%)] Loss: -1338.297852\n",
      "Train Epoch: 76 [40960/54000 (76%)] Loss: -1341.335449\n",
      "Train Epoch: 76 [45056/54000 (83%)] Loss: -1339.491943\n",
      "Train Epoch: 76 [49152/54000 (91%)] Loss: -1336.672852\n",
      "Train Epoch: 76 [53248/54000 (99%)] Loss: -1341.584351\n",
      "    epoch          : 76\n",
      "    loss           : -1337.8917178474896\n",
      "    ess            : 3.7379194729701037\n",
      "    log_marginal   : 1338.0042730394698\n",
      "    val_loss       : -1337.6538645426433\n",
      "    val_ess        : 3.7414777974287667\n",
      "    val_log_marginal: 1337.7654876708984\n",
      "Train Epoch: 77 [0/54000 (0%)] Loss: -1348.219971\n",
      "Train Epoch: 77 [4096/54000 (8%)] Loss: -1340.723633\n",
      "Train Epoch: 77 [8192/54000 (15%)] Loss: -1337.507324\n",
      "Train Epoch: 77 [12288/54000 (23%)] Loss: -1341.662598\n",
      "Train Epoch: 77 [16384/54000 (30%)] Loss: -1337.932373\n",
      "Train Epoch: 77 [20480/54000 (38%)] Loss: -1335.587646\n",
      "Train Epoch: 77 [24576/54000 (46%)] Loss: -1339.887329\n",
      "Train Epoch: 77 [28672/54000 (53%)] Loss: -1337.590820\n",
      "Train Epoch: 77 [32768/54000 (61%)] Loss: -1335.126953\n",
      "Train Epoch: 77 [36864/54000 (68%)] Loss: -1339.283691\n",
      "Train Epoch: 77 [40960/54000 (76%)] Loss: -1337.324097\n",
      "Train Epoch: 77 [45056/54000 (83%)] Loss: -1340.713623\n",
      "Train Epoch: 77 [49152/54000 (91%)] Loss: -1335.796265\n",
      "Train Epoch: 77 [53248/54000 (99%)] Loss: -1340.011475\n",
      "    epoch          : 77\n",
      "    loss           : -1339.27568914766\n",
      "    ess            : 3.7444393894683694\n",
      "    log_marginal   : 1339.3847852950978\n",
      "    val_loss       : -1337.365514119466\n",
      "    val_ess        : 3.7469589511553445\n",
      "    val_log_marginal: 1337.4780680338542\n",
      "Train Epoch: 78 [0/54000 (0%)] Loss: -1337.343140\n",
      "Train Epoch: 78 [4096/54000 (8%)] Loss: -1333.857666\n",
      "Train Epoch: 78 [8192/54000 (15%)] Loss: -1343.657104\n",
      "Train Epoch: 78 [12288/54000 (23%)] Loss: -1336.887695\n",
      "Train Epoch: 78 [16384/54000 (30%)] Loss: -1341.073608\n",
      "Train Epoch: 78 [20480/54000 (38%)] Loss: -1336.854980\n",
      "Train Epoch: 78 [24576/54000 (46%)] Loss: -1334.714355\n",
      "Train Epoch: 78 [28672/54000 (53%)] Loss: -1337.838379\n",
      "Train Epoch: 78 [32768/54000 (61%)] Loss: -1333.130249\n",
      "Train Epoch: 78 [36864/54000 (68%)] Loss: -1339.089355\n",
      "Train Epoch: 78 [40960/54000 (76%)] Loss: -1345.576660\n",
      "Train Epoch: 78 [45056/54000 (83%)] Loss: -1344.773926\n",
      "Train Epoch: 78 [49152/54000 (91%)] Loss: -1345.410156\n",
      "Train Epoch: 78 [53248/54000 (99%)] Loss: -1344.347900\n",
      "    epoch          : 78\n",
      "    loss           : -1340.361659045468\n",
      "    ess            : 3.7496397789055704\n",
      "    log_marginal   : 1340.4676594666396\n",
      "    val_loss       : -1339.5194244384766\n",
      "    val_ess        : 3.756621758143107\n",
      "    val_log_marginal: 1339.6258036295574\n",
      "Train Epoch: 79 [0/54000 (0%)] Loss: -1346.457031\n",
      "Train Epoch: 79 [4096/54000 (8%)] Loss: -1339.832520\n",
      "Train Epoch: 79 [8192/54000 (15%)] Loss: -1339.671753\n",
      "Train Epoch: 79 [12288/54000 (23%)] Loss: -1345.861572\n",
      "Train Epoch: 79 [16384/54000 (30%)] Loss: -1339.936523\n",
      "Train Epoch: 79 [20480/54000 (38%)] Loss: -1340.330811\n",
      "Train Epoch: 79 [24576/54000 (46%)] Loss: -1343.672363\n",
      "Train Epoch: 79 [28672/54000 (53%)] Loss: -1347.236938\n",
      "Train Epoch: 79 [32768/54000 (61%)] Loss: -1338.865723\n",
      "Train Epoch: 79 [36864/54000 (68%)] Loss: -1343.053955\n",
      "Train Epoch: 79 [40960/54000 (76%)] Loss: -1341.966553\n",
      "Train Epoch: 79 [45056/54000 (83%)] Loss: -1339.318848\n",
      "Train Epoch: 79 [49152/54000 (91%)] Loss: -1339.936890\n",
      "Train Epoch: 79 [53248/54000 (99%)] Loss: -1338.302246\n",
      "    epoch          : 79\n",
      "    loss           : -1341.580709303725\n",
      "    ess            : 3.7523879157423408\n",
      "    log_marginal   : 1341.6911019420172\n",
      "    val_loss       : -1340.8043162027996\n",
      "    val_ess        : 3.7418299317359924\n",
      "    val_log_marginal: 1340.9216918945312\n",
      "Train Epoch: 80 [0/54000 (0%)] Loss: -1341.192261\n",
      "Train Epoch: 80 [4096/54000 (8%)] Loss: -1346.002197\n",
      "Train Epoch: 80 [8192/54000 (15%)] Loss: -1340.642944\n",
      "Train Epoch: 80 [12288/54000 (23%)] Loss: -1339.469604\n",
      "Train Epoch: 80 [16384/54000 (30%)] Loss: -1339.488770\n",
      "Train Epoch: 80 [20480/54000 (38%)] Loss: -1349.123047\n",
      "Train Epoch: 80 [24576/54000 (46%)] Loss: -1342.785278\n",
      "Train Epoch: 80 [28672/54000 (53%)] Loss: -1346.815186\n",
      "Train Epoch: 80 [32768/54000 (61%)] Loss: -1336.709351\n",
      "Train Epoch: 80 [36864/54000 (68%)] Loss: -1340.056274\n",
      "Train Epoch: 80 [40960/54000 (76%)] Loss: -1342.973755\n",
      "Train Epoch: 80 [45056/54000 (83%)] Loss: -1345.547974\n",
      "Train Epoch: 80 [49152/54000 (91%)] Loss: -1343.808350\n",
      "Train Epoch: 80 [53248/54000 (99%)] Loss: -1344.817627\n",
      "    epoch          : 80\n",
      "    loss           : -1342.6392706559168\n",
      "    ess            : 3.7609598388039105\n",
      "    log_marginal   : 1342.741309866521\n",
      "    val_loss       : -1341.4005788167317\n",
      "    val_ess        : 3.7824372053146362\n",
      "    val_log_marginal: 1341.4901275634766\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch80.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 81 [0/54000 (0%)] Loss: -1340.278564\n",
      "Train Epoch: 81 [4096/54000 (8%)] Loss: -1343.442139\n",
      "Train Epoch: 81 [8192/54000 (15%)] Loss: -1343.635132\n",
      "Train Epoch: 81 [12288/54000 (23%)] Loss: -1341.330200\n",
      "Train Epoch: 81 [16384/54000 (30%)] Loss: -1347.510620\n",
      "Train Epoch: 81 [20480/54000 (38%)] Loss: -1351.086182\n",
      "Train Epoch: 81 [24576/54000 (46%)] Loss: -1345.756348\n",
      "Train Epoch: 81 [28672/54000 (53%)] Loss: -1348.762817\n",
      "Train Epoch: 81 [32768/54000 (61%)] Loss: -1351.188110\n",
      "Train Epoch: 81 [36864/54000 (68%)] Loss: -1346.735474\n",
      "Train Epoch: 81 [40960/54000 (76%)] Loss: -1348.089844\n",
      "Train Epoch: 81 [45056/54000 (83%)] Loss: -1345.758057\n",
      "Train Epoch: 81 [49152/54000 (91%)] Loss: -1342.749268\n",
      "Train Epoch: 81 [53248/54000 (99%)] Loss: -1352.951538\n",
      "    epoch          : 81\n",
      "    loss           : -1344.0504156175948\n",
      "    ess            : 3.7619114475792617\n",
      "    log_marginal   : 1344.156169584012\n",
      "    val_loss       : -1343.016606648763\n",
      "    val_ess        : 3.773192514975866\n",
      "    val_log_marginal: 1343.1146596272786\n",
      "Train Epoch: 82 [0/54000 (0%)] Loss: -1343.879883\n",
      "Train Epoch: 82 [4096/54000 (8%)] Loss: -1337.371216\n",
      "Train Epoch: 82 [8192/54000 (15%)] Loss: -1342.748535\n",
      "Train Epoch: 82 [12288/54000 (23%)] Loss: -1345.769287\n",
      "Train Epoch: 82 [16384/54000 (30%)] Loss: -1350.474731\n",
      "Train Epoch: 82 [20480/54000 (38%)] Loss: -1348.405029\n",
      "Train Epoch: 82 [24576/54000 (46%)] Loss: -1345.603149\n",
      "Train Epoch: 82 [28672/54000 (53%)] Loss: -1345.345215\n",
      "Train Epoch: 82 [32768/54000 (61%)] Loss: -1345.479614\n",
      "Train Epoch: 82 [36864/54000 (68%)] Loss: -1339.111572\n",
      "Train Epoch: 82 [40960/54000 (76%)] Loss: -1348.118530\n",
      "Train Epoch: 82 [45056/54000 (83%)] Loss: -1346.013184\n",
      "Train Epoch: 82 [49152/54000 (91%)] Loss: -1349.109863\n",
      "Train Epoch: 82 [53248/54000 (99%)] Loss: -1341.969849\n",
      "    epoch          : 82\n",
      "    loss           : -1344.928813916247\n",
      "    ess            : 3.767925911040103\n",
      "    log_marginal   : 1345.0304198061685\n",
      "    val_loss       : -1344.6500600179036\n",
      "    val_ess        : 3.7717353800932565\n",
      "    val_log_marginal: 1344.7539164225261\n",
      "Train Epoch: 83 [0/54000 (0%)] Loss: -1346.413086\n",
      "Train Epoch: 83 [4096/54000 (8%)] Loss: -1342.839600\n",
      "Train Epoch: 83 [8192/54000 (15%)] Loss: -1345.028198\n",
      "Train Epoch: 83 [12288/54000 (23%)] Loss: -1337.472656\n",
      "Train Epoch: 83 [16384/54000 (30%)] Loss: -1345.175781\n",
      "Train Epoch: 83 [20480/54000 (38%)] Loss: -1345.979614\n",
      "Train Epoch: 83 [24576/54000 (46%)] Loss: -1349.501831\n",
      "Train Epoch: 83 [28672/54000 (53%)] Loss: -1349.243652\n",
      "Train Epoch: 83 [32768/54000 (61%)] Loss: -1349.158203\n",
      "Train Epoch: 83 [36864/54000 (68%)] Loss: -1353.409424\n",
      "Train Epoch: 83 [40960/54000 (76%)] Loss: -1347.021973\n",
      "Train Epoch: 83 [45056/54000 (83%)] Loss: -1341.153076\n",
      "Train Epoch: 83 [49152/54000 (91%)] Loss: -1348.959961\n",
      "Train Epoch: 83 [53248/54000 (99%)] Loss: -1349.957764\n",
      "    epoch          : 83\n",
      "    loss           : -1346.0447593074275\n",
      "    ess            : 3.76893454818364\n",
      "    log_marginal   : 1346.1471913414543\n",
      "    val_loss       : -1346.1771443684895\n",
      "    val_ess        : 3.7669502894083657\n",
      "    val_log_marginal: 1346.2774759928386\n",
      "Train Epoch: 84 [0/54000 (0%)] Loss: -1340.622803\n",
      "Train Epoch: 84 [4096/54000 (8%)] Loss: -1346.133667\n",
      "Train Epoch: 84 [8192/54000 (15%)] Loss: -1351.203613\n",
      "Train Epoch: 84 [12288/54000 (23%)] Loss: -1346.234619\n",
      "Train Epoch: 84 [16384/54000 (30%)] Loss: -1341.709961\n",
      "Train Epoch: 84 [20480/54000 (38%)] Loss: -1351.605713\n",
      "Train Epoch: 84 [24576/54000 (46%)] Loss: -1345.654297\n",
      "Train Epoch: 84 [28672/54000 (53%)] Loss: -1349.802612\n",
      "Train Epoch: 84 [32768/54000 (61%)] Loss: -1347.128784\n",
      "Train Epoch: 84 [36864/54000 (68%)] Loss: -1339.767578\n",
      "Train Epoch: 84 [40960/54000 (76%)] Loss: -1345.453491\n",
      "Train Epoch: 84 [45056/54000 (83%)] Loss: -1347.375000\n",
      "Train Epoch: 84 [49152/54000 (91%)] Loss: -1353.739014\n",
      "Train Epoch: 84 [53248/54000 (99%)] Loss: -1352.142090\n",
      "    epoch          : 84\n",
      "    loss           : -1347.2110636200384\n",
      "    ess            : 3.774483703324015\n",
      "    log_marginal   : 1347.3115512070497\n",
      "    val_loss       : -1346.8762766520183\n",
      "    val_ess        : 3.7782337069511414\n",
      "    val_log_marginal: 1346.9758046468098\n",
      "Train Epoch: 85 [0/54000 (0%)] Loss: -1349.660889\n",
      "Train Epoch: 85 [4096/54000 (8%)] Loss: -1342.273560\n",
      "Train Epoch: 85 [8192/54000 (15%)] Loss: -1352.808594\n",
      "Train Epoch: 85 [12288/54000 (23%)] Loss: -1340.292114\n",
      "Train Epoch: 85 [16384/54000 (30%)] Loss: -1342.716797\n",
      "Train Epoch: 85 [20480/54000 (38%)] Loss: -1345.822144\n",
      "Train Epoch: 85 [24576/54000 (46%)] Loss: -1346.921143\n",
      "Train Epoch: 85 [28672/54000 (53%)] Loss: -1349.233643\n",
      "Train Epoch: 85 [32768/54000 (61%)] Loss: -1353.986816\n",
      "Train Epoch: 85 [36864/54000 (68%)] Loss: -1347.501221\n",
      "Train Epoch: 85 [40960/54000 (76%)] Loss: -1346.150879\n",
      "Train Epoch: 85 [45056/54000 (83%)] Loss: -1349.291260\n",
      "Train Epoch: 85 [49152/54000 (91%)] Loss: -1352.831299\n",
      "Train Epoch: 85 [53248/54000 (99%)] Loss: -1350.185425\n",
      "    epoch          : 85\n",
      "    loss           : -1348.3775883534508\n",
      "    ess            : 3.7799428616654818\n",
      "    log_marginal   : 1348.4764062962827\n",
      "    val_loss       : -1347.3219604492188\n",
      "    val_ess        : 3.77996297677358\n",
      "    val_log_marginal: 1347.4224700927734\n",
      "Train Epoch: 86 [0/54000 (0%)] Loss: -1346.979980\n",
      "Train Epoch: 86 [4096/54000 (8%)] Loss: -1349.489502\n",
      "Train Epoch: 86 [8192/54000 (15%)] Loss: -1344.459229\n",
      "Train Epoch: 86 [12288/54000 (23%)] Loss: -1344.764893\n",
      "Train Epoch: 86 [16384/54000 (30%)] Loss: -1352.810059\n",
      "Train Epoch: 86 [20480/54000 (38%)] Loss: -1346.634277\n",
      "Train Epoch: 86 [24576/54000 (46%)] Loss: -1346.197754\n",
      "Train Epoch: 86 [28672/54000 (53%)] Loss: -1347.625977\n",
      "Train Epoch: 86 [32768/54000 (61%)] Loss: -1352.696289\n",
      "Train Epoch: 86 [36864/54000 (68%)] Loss: -1349.794189\n",
      "Train Epoch: 86 [40960/54000 (76%)] Loss: -1347.129028\n",
      "Train Epoch: 86 [45056/54000 (83%)] Loss: -1348.619751\n",
      "Train Epoch: 86 [49152/54000 (91%)] Loss: -1350.411255\n",
      "Train Epoch: 86 [53248/54000 (99%)] Loss: -1347.214844\n",
      "    epoch          : 86\n",
      "    loss           : -1349.4652510367298\n",
      "    ess            : 3.7840560092745235\n",
      "    log_marginal   : 1349.5607742381887\n",
      "    val_loss       : -1349.607945760091\n",
      "    val_ess        : 3.792630364497503\n",
      "    val_log_marginal: 1349.7017008463542\n",
      "Train Epoch: 87 [0/54000 (0%)] Loss: -1348.471558\n",
      "Train Epoch: 87 [4096/54000 (8%)] Loss: -1353.946533\n",
      "Train Epoch: 87 [8192/54000 (15%)] Loss: -1352.536743\n",
      "Train Epoch: 87 [12288/54000 (23%)] Loss: -1349.780151\n",
      "Train Epoch: 87 [16384/54000 (30%)] Loss: -1348.719482\n",
      "Train Epoch: 87 [20480/54000 (38%)] Loss: -1351.687866\n",
      "Train Epoch: 87 [24576/54000 (46%)] Loss: -1344.186523\n",
      "Train Epoch: 87 [28672/54000 (53%)] Loss: -1351.551392\n",
      "Train Epoch: 87 [32768/54000 (61%)] Loss: -1351.112549\n",
      "Train Epoch: 87 [36864/54000 (68%)] Loss: -1353.598511\n",
      "Train Epoch: 87 [40960/54000 (76%)] Loss: -1352.605835\n",
      "Train Epoch: 87 [45056/54000 (83%)] Loss: -1354.872070\n",
      "Train Epoch: 87 [49152/54000 (91%)] Loss: -1347.318115\n",
      "Train Epoch: 87 [53248/54000 (99%)] Loss: -1351.672607\n",
      "    epoch          : 87\n",
      "    loss           : -1350.6083382701422\n",
      "    ess            : 3.786093609027953\n",
      "    log_marginal   : 1350.7018828911805\n",
      "    val_loss       : -1350.1779276529949\n",
      "    val_ess        : 3.784072160720825\n",
      "    val_log_marginal: 1350.2725728352864\n",
      "Train Epoch: 88 [0/54000 (0%)] Loss: -1349.348145\n",
      "Train Epoch: 88 [4096/54000 (8%)] Loss: -1349.458130\n",
      "Train Epoch: 88 [8192/54000 (15%)] Loss: -1354.033447\n",
      "Train Epoch: 88 [12288/54000 (23%)] Loss: -1350.344238\n",
      "Train Epoch: 88 [16384/54000 (30%)] Loss: -1344.998047\n",
      "Train Epoch: 88 [20480/54000 (38%)] Loss: -1352.901367\n",
      "Train Epoch: 88 [24576/54000 (46%)] Loss: -1352.166382\n",
      "Train Epoch: 88 [28672/54000 (53%)] Loss: -1344.349854\n",
      "Train Epoch: 88 [32768/54000 (61%)] Loss: -1354.510620\n",
      "Train Epoch: 88 [36864/54000 (68%)] Loss: -1353.958008\n",
      "Train Epoch: 88 [40960/54000 (76%)] Loss: -1352.701904\n",
      "Train Epoch: 88 [45056/54000 (83%)] Loss: -1352.094604\n",
      "Train Epoch: 88 [49152/54000 (91%)] Loss: -1348.625000\n",
      "Train Epoch: 88 [53248/54000 (99%)] Loss: -1352.516968\n",
      "    epoch          : 88\n",
      "    loss           : -1351.5061567405953\n",
      "    ess            : 3.791414880074596\n",
      "    log_marginal   : 1351.6006854450534\n",
      "    val_loss       : -1351.0611012776692\n",
      "    val_ess        : 3.7854629357655845\n",
      "    val_log_marginal: 1351.1629842122395\n",
      "Train Epoch: 89 [0/54000 (0%)] Loss: -1354.375244\n",
      "Train Epoch: 89 [4096/54000 (8%)] Loss: -1346.551147\n",
      "Train Epoch: 89 [8192/54000 (15%)] Loss: -1352.977417\n",
      "Train Epoch: 89 [12288/54000 (23%)] Loss: -1352.812622\n",
      "Train Epoch: 89 [16384/54000 (30%)] Loss: -1353.329590\n",
      "Train Epoch: 89 [20480/54000 (38%)] Loss: -1352.366211\n",
      "Train Epoch: 89 [24576/54000 (46%)] Loss: -1348.266479\n",
      "Train Epoch: 89 [28672/54000 (53%)] Loss: -1349.044312\n",
      "Train Epoch: 89 [32768/54000 (61%)] Loss: -1348.541138\n",
      "Train Epoch: 89 [36864/54000 (68%)] Loss: -1350.592896\n",
      "Train Epoch: 89 [40960/54000 (76%)] Loss: -1353.782837\n",
      "Train Epoch: 89 [45056/54000 (83%)] Loss: -1357.407959\n",
      "Train Epoch: 89 [49152/54000 (91%)] Loss: -1344.318604\n",
      "Train Epoch: 89 [53248/54000 (99%)] Loss: -1349.179321\n",
      "    epoch          : 89\n",
      "    loss           : -1352.4906190989707\n",
      "    ess            : 3.791385179447337\n",
      "    log_marginal   : 1352.5832588955125\n",
      "    val_loss       : -1353.4198913574219\n",
      "    val_ess        : 3.7953662077585855\n",
      "    val_log_marginal: 1353.5105234781902\n",
      "Train Epoch: 90 [0/54000 (0%)] Loss: -1350.290527\n",
      "Train Epoch: 90 [4096/54000 (8%)] Loss: -1355.438721\n",
      "Train Epoch: 90 [8192/54000 (15%)] Loss: -1353.634033\n",
      "Train Epoch: 90 [12288/54000 (23%)] Loss: -1353.805908\n",
      "Train Epoch: 90 [16384/54000 (30%)] Loss: -1356.016968\n",
      "Train Epoch: 90 [20480/54000 (38%)] Loss: -1345.969482\n",
      "Train Epoch: 90 [24576/54000 (46%)] Loss: -1352.371582\n",
      "Train Epoch: 90 [28672/54000 (53%)] Loss: -1354.090698\n",
      "Train Epoch: 90 [32768/54000 (61%)] Loss: -1349.303833\n",
      "Train Epoch: 90 [36864/54000 (68%)] Loss: -1350.421631\n",
      "Train Epoch: 90 [40960/54000 (76%)] Loss: -1350.299438\n",
      "Train Epoch: 90 [45056/54000 (83%)] Loss: -1350.484619\n",
      "Train Epoch: 90 [49152/54000 (91%)] Loss: -1350.636475\n",
      "Train Epoch: 90 [53248/54000 (99%)] Loss: -1348.970215\n",
      "    epoch          : 90\n",
      "    loss           : -1353.444592227303\n",
      "    ess            : 3.798006924407742\n",
      "    log_marginal   : 1353.534774997223\n",
      "    val_loss       : -1353.0862681070964\n",
      "    val_ess        : 3.799988935391108\n",
      "    val_log_marginal: 1353.1842803955078\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch90.pth ...\n",
      "Train Epoch: 91 [0/54000 (0%)] Loss: -1354.704346\n",
      "Train Epoch: 91 [4096/54000 (8%)] Loss: -1354.355591\n",
      "Train Epoch: 91 [8192/54000 (15%)] Loss: -1352.890259\n",
      "Train Epoch: 91 [12288/54000 (23%)] Loss: -1359.190552\n",
      "Train Epoch: 91 [16384/54000 (30%)] Loss: -1361.798584\n",
      "Train Epoch: 91 [20480/54000 (38%)] Loss: -1356.112793\n",
      "Train Epoch: 91 [24576/54000 (46%)] Loss: -1356.125488\n",
      "Train Epoch: 91 [28672/54000 (53%)] Loss: -1360.700195\n",
      "Train Epoch: 91 [32768/54000 (61%)] Loss: -1347.710938\n",
      "Train Epoch: 91 [36864/54000 (68%)] Loss: -1357.522583\n",
      "Train Epoch: 91 [40960/54000 (76%)] Loss: -1354.913818\n",
      "Train Epoch: 91 [45056/54000 (83%)] Loss: -1356.644287\n",
      "Train Epoch: 91 [49152/54000 (91%)] Loss: -1360.763916\n",
      "Train Epoch: 91 [53248/54000 (99%)] Loss: -1348.458984\n",
      "    epoch          : 91\n",
      "    loss           : -1354.3805209336122\n",
      "    ess            : 3.8014886379241943\n",
      "    log_marginal   : 1354.4689125675725\n",
      "    val_loss       : -1354.6837972005208\n",
      "    val_ess        : 3.78881565729777\n",
      "    val_log_marginal: 1354.7847951253254\n",
      "Train Epoch: 92 [0/54000 (0%)] Loss: -1356.362183\n",
      "Train Epoch: 92 [4096/54000 (8%)] Loss: -1358.931152\n",
      "Train Epoch: 92 [8192/54000 (15%)] Loss: -1355.417603\n",
      "Train Epoch: 92 [12288/54000 (23%)] Loss: -1359.950562\n",
      "Train Epoch: 92 [16384/54000 (30%)] Loss: -1354.773438\n",
      "Train Epoch: 92 [20480/54000 (38%)] Loss: -1353.060303\n",
      "Train Epoch: 92 [24576/54000 (46%)] Loss: -1360.406616\n",
      "Train Epoch: 92 [28672/54000 (53%)] Loss: -1355.975342\n",
      "Train Epoch: 92 [32768/54000 (61%)] Loss: -1356.561768\n",
      "Train Epoch: 92 [36864/54000 (68%)] Loss: -1357.551880\n",
      "Train Epoch: 92 [40960/54000 (76%)] Loss: -1353.303833\n",
      "Train Epoch: 92 [45056/54000 (83%)] Loss: -1359.465576\n",
      "Train Epoch: 92 [49152/54000 (91%)] Loss: -1360.175659\n",
      "Train Epoch: 92 [53248/54000 (99%)] Loss: -1354.744141\n",
      "    epoch          : 92\n",
      "    loss           : -1355.4968186509552\n",
      "    ess            : 3.797820894639074\n",
      "    log_marginal   : 1355.5906837788802\n",
      "    val_loss       : -1354.8252512613933\n",
      "    val_ess        : 3.8035141229629517\n",
      "    val_log_marginal: 1354.9091898600261\n",
      "Train Epoch: 93 [0/54000 (0%)] Loss: -1355.666748\n",
      "Train Epoch: 93 [4096/54000 (8%)] Loss: -1361.468018\n",
      "Train Epoch: 93 [8192/54000 (15%)] Loss: -1360.257324\n",
      "Train Epoch: 93 [12288/54000 (23%)] Loss: -1356.753906\n",
      "Train Epoch: 93 [16384/54000 (30%)] Loss: -1359.677979\n",
      "Train Epoch: 93 [20480/54000 (38%)] Loss: -1354.798096\n",
      "Train Epoch: 93 [24576/54000 (46%)] Loss: -1351.403687\n",
      "Train Epoch: 93 [28672/54000 (53%)] Loss: -1358.605713\n",
      "Train Epoch: 93 [32768/54000 (61%)] Loss: -1358.385254\n",
      "Train Epoch: 93 [36864/54000 (68%)] Loss: -1352.588379\n",
      "Train Epoch: 93 [40960/54000 (76%)] Loss: -1361.809814\n",
      "Train Epoch: 93 [45056/54000 (83%)] Loss: -1355.251953\n",
      "Train Epoch: 93 [49152/54000 (91%)] Loss: -1356.592773\n",
      "Train Epoch: 93 [53248/54000 (99%)] Loss: -1358.786865\n",
      "    epoch          : 93\n",
      "    loss           : -1356.4354126555095\n",
      "    ess            : 3.800036134313068\n",
      "    log_marginal   : 1356.528294278547\n",
      "    val_loss       : -1356.416732788086\n",
      "    val_ess        : 3.8024787505467734\n",
      "    val_log_marginal: 1356.5030975341797\n",
      "Train Epoch: 94 [0/54000 (0%)] Loss: -1361.931396\n",
      "Train Epoch: 94 [4096/54000 (8%)] Loss: -1361.506836\n",
      "Train Epoch: 94 [8192/54000 (15%)] Loss: -1355.790039\n",
      "Train Epoch: 94 [12288/54000 (23%)] Loss: -1362.127686\n",
      "Train Epoch: 94 [16384/54000 (30%)] Loss: -1356.052734\n",
      "Train Epoch: 94 [20480/54000 (38%)] Loss: -1354.900757\n",
      "Train Epoch: 94 [24576/54000 (46%)] Loss: -1358.235107\n",
      "Train Epoch: 94 [28672/54000 (53%)] Loss: -1358.677612\n",
      "Train Epoch: 94 [32768/54000 (61%)] Loss: -1358.303711\n",
      "Train Epoch: 94 [36864/54000 (68%)] Loss: -1361.718018\n",
      "Train Epoch: 94 [40960/54000 (76%)] Loss: -1359.328369\n",
      "Train Epoch: 94 [45056/54000 (83%)] Loss: -1360.699585\n",
      "Train Epoch: 94 [49152/54000 (91%)] Loss: -1358.816772\n",
      "Train Epoch: 94 [53248/54000 (99%)] Loss: -1358.550903\n",
      "    epoch          : 94\n",
      "    loss           : -1357.452985573719\n",
      "    ess            : 3.8024452207212764\n",
      "    log_marginal   : 1357.543864896512\n",
      "    val_loss       : -1357.3793284098308\n",
      "    val_ess        : 3.7828266819318137\n",
      "    val_log_marginal: 1357.4833119710286\n",
      "Train Epoch: 95 [0/54000 (0%)] Loss: -1355.494141\n",
      "Train Epoch: 95 [4096/54000 (8%)] Loss: -1362.674072\n",
      "Train Epoch: 95 [8192/54000 (15%)] Loss: -1359.225952\n",
      "Train Epoch: 95 [12288/54000 (23%)] Loss: -1355.546143\n",
      "Train Epoch: 95 [16384/54000 (30%)] Loss: -1353.942505\n",
      "Train Epoch: 95 [20480/54000 (38%)] Loss: -1355.937256\n",
      "Train Epoch: 95 [24576/54000 (46%)] Loss: -1356.248535\n",
      "Train Epoch: 95 [28672/54000 (53%)] Loss: -1360.743164\n",
      "Train Epoch: 95 [32768/54000 (61%)] Loss: -1363.900269\n",
      "Train Epoch: 95 [36864/54000 (68%)] Loss: -1363.235962\n",
      "Train Epoch: 95 [40960/54000 (76%)] Loss: -1356.459961\n",
      "Train Epoch: 95 [45056/54000 (83%)] Loss: -1358.155884\n",
      "Train Epoch: 95 [49152/54000 (91%)] Loss: -1360.735107\n",
      "Train Epoch: 95 [53248/54000 (99%)] Loss: -1365.023193\n",
      "    epoch          : 95\n",
      "    loss           : -1358.5263515671284\n",
      "    ess            : 3.8102991321075583\n",
      "    log_marginal   : 1358.6155809158397\n",
      "    val_loss       : -1358.289042154948\n",
      "    val_ess        : 3.8076002498467765\n",
      "    val_log_marginal: 1358.3804016113281\n",
      "Train Epoch: 96 [0/54000 (0%)] Loss: -1357.381104\n",
      "Train Epoch: 96 [4096/54000 (8%)] Loss: -1361.002075\n",
      "Train Epoch: 96 [8192/54000 (15%)] Loss: -1367.848389\n",
      "Train Epoch: 96 [12288/54000 (23%)] Loss: -1372.174683\n",
      "Train Epoch: 96 [16384/54000 (30%)] Loss: -1357.587891\n",
      "Train Epoch: 96 [20480/54000 (38%)] Loss: -1361.284912\n",
      "Train Epoch: 96 [24576/54000 (46%)] Loss: -1358.841675\n",
      "Train Epoch: 96 [28672/54000 (53%)] Loss: -1360.422363\n",
      "Train Epoch: 96 [32768/54000 (61%)] Loss: -1355.514160\n",
      "Train Epoch: 96 [36864/54000 (68%)] Loss: -1355.386230\n",
      "Train Epoch: 96 [40960/54000 (76%)] Loss: -1355.456665\n",
      "Train Epoch: 96 [45056/54000 (83%)] Loss: -1362.717773\n",
      "Train Epoch: 96 [49152/54000 (91%)] Loss: -1354.716553\n",
      "Train Epoch: 96 [53248/54000 (99%)] Loss: -1363.942627\n",
      "    epoch          : 96\n",
      "    loss           : -1359.7917856514737\n",
      "    ess            : 3.8060537333737052\n",
      "    log_marginal   : 1359.8850039803021\n",
      "    val_loss       : -1359.2815602620442\n",
      "    val_ess        : 3.8196226259072623\n",
      "    val_log_marginal: 1359.3642171223958\n",
      "Train Epoch: 97 [0/54000 (0%)] Loss: -1360.847900\n",
      "Train Epoch: 97 [4096/54000 (8%)] Loss: -1362.098999\n",
      "Train Epoch: 97 [8192/54000 (15%)] Loss: -1367.974121\n",
      "Train Epoch: 97 [12288/54000 (23%)] Loss: -1361.814941\n",
      "Train Epoch: 97 [16384/54000 (30%)] Loss: -1361.249023\n",
      "Train Epoch: 97 [20480/54000 (38%)] Loss: -1366.542480\n",
      "Train Epoch: 97 [24576/54000 (46%)] Loss: -1367.119385\n",
      "Train Epoch: 97 [28672/54000 (53%)] Loss: -1357.172363\n",
      "Train Epoch: 97 [32768/54000 (61%)] Loss: -1347.837036\n",
      "Train Epoch: 97 [36864/54000 (68%)] Loss: -1361.660400\n",
      "Train Epoch: 97 [40960/54000 (76%)] Loss: -1357.428833\n",
      "Train Epoch: 97 [45056/54000 (83%)] Loss: -1357.196289\n",
      "Train Epoch: 97 [49152/54000 (91%)] Loss: -1350.172363\n",
      "Train Epoch: 97 [53248/54000 (99%)] Loss: -1360.967529\n",
      "    epoch          : 97\n",
      "    loss           : -1360.3605771900918\n",
      "    ess            : 3.8082073717885674\n",
      "    log_marginal   : 1360.4515623842935\n",
      "    val_loss       : -1360.187484741211\n",
      "    val_ess        : 3.7987970610459647\n",
      "    val_log_marginal: 1360.2825978597004\n",
      "Train Epoch: 98 [0/54000 (0%)] Loss: -1361.097412\n",
      "Train Epoch: 98 [4096/54000 (8%)] Loss: -1360.159546\n",
      "Train Epoch: 98 [8192/54000 (15%)] Loss: -1356.452515\n",
      "Train Epoch: 98 [12288/54000 (23%)] Loss: -1367.436279\n",
      "Train Epoch: 98 [16384/54000 (30%)] Loss: -1360.886108\n",
      "Train Epoch: 98 [20480/54000 (38%)] Loss: -1358.317139\n",
      "Train Epoch: 98 [24576/54000 (46%)] Loss: -1362.759766\n",
      "Train Epoch: 98 [28672/54000 (53%)] Loss: -1361.026978\n",
      "Train Epoch: 98 [32768/54000 (61%)] Loss: -1361.824951\n",
      "Train Epoch: 98 [36864/54000 (68%)] Loss: -1358.368408\n",
      "Train Epoch: 98 [40960/54000 (76%)] Loss: -1363.979736\n",
      "Train Epoch: 98 [45056/54000 (83%)] Loss: -1359.294678\n",
      "Train Epoch: 98 [49152/54000 (91%)] Loss: -1356.717285\n",
      "Train Epoch: 98 [53248/54000 (99%)] Loss: -1359.959473\n",
      "    epoch          : 98\n",
      "    loss           : -1361.5365898530065\n",
      "    ess            : 3.8041547226114862\n",
      "    log_marginal   : 1361.6292018799986\n",
      "    val_loss       : -1361.6160736083984\n",
      "    val_ess        : 3.8086212376753488\n",
      "    val_log_marginal: 1361.707992553711\n",
      "Train Epoch: 99 [0/54000 (0%)] Loss: -1368.461060\n",
      "Train Epoch: 99 [4096/54000 (8%)] Loss: -1363.895996\n",
      "Train Epoch: 99 [8192/54000 (15%)] Loss: -1362.275269\n",
      "Train Epoch: 99 [12288/54000 (23%)] Loss: -1360.893799\n",
      "Train Epoch: 99 [16384/54000 (30%)] Loss: -1364.196045\n",
      "Train Epoch: 99 [20480/54000 (38%)] Loss: -1358.037842\n",
      "Train Epoch: 99 [24576/54000 (46%)] Loss: -1354.996704\n",
      "Train Epoch: 99 [28672/54000 (53%)] Loss: -1363.865601\n",
      "Train Epoch: 99 [32768/54000 (61%)] Loss: -1362.684448\n",
      "Train Epoch: 99 [36864/54000 (68%)] Loss: -1361.949463\n",
      "Train Epoch: 99 [40960/54000 (76%)] Loss: -1366.388306\n",
      "Train Epoch: 99 [45056/54000 (83%)] Loss: -1364.296143\n",
      "Train Epoch: 99 [49152/54000 (91%)] Loss: -1361.950928\n",
      "Train Epoch: 99 [53248/54000 (99%)] Loss: -1358.102783\n",
      "    epoch          : 99\n",
      "    loss           : -1362.4319721240004\n",
      "    ess            : 3.8071810735910425\n",
      "    log_marginal   : 1362.5245419181354\n",
      "    val_loss       : -1361.6230214436848\n",
      "    val_ess        : 3.815907637278239\n",
      "    val_log_marginal: 1361.7073516845703\n",
      "Train Epoch: 100 [0/54000 (0%)] Loss: -1367.492432\n",
      "Train Epoch: 100 [4096/54000 (8%)] Loss: -1360.312134\n",
      "Train Epoch: 100 [8192/54000 (15%)] Loss: -1358.073120\n",
      "Train Epoch: 100 [12288/54000 (23%)] Loss: -1362.693481\n",
      "Train Epoch: 100 [16384/54000 (30%)] Loss: -1362.021484\n",
      "Train Epoch: 100 [20480/54000 (38%)] Loss: -1362.111206\n",
      "Train Epoch: 100 [24576/54000 (46%)] Loss: -1365.734863\n",
      "Train Epoch: 100 [28672/54000 (53%)] Loss: -1361.961060\n",
      "Train Epoch: 100 [32768/54000 (61%)] Loss: -1364.692139\n",
      "Train Epoch: 100 [36864/54000 (68%)] Loss: -1363.697632\n",
      "Train Epoch: 100 [40960/54000 (76%)] Loss: -1365.404907\n",
      "Train Epoch: 100 [45056/54000 (83%)] Loss: -1363.545776\n",
      "Train Epoch: 100 [49152/54000 (91%)] Loss: -1362.337769\n",
      "Train Epoch: 100 [53248/54000 (99%)] Loss: -1366.996338\n",
      "    epoch          : 100\n",
      "    loss           : -1363.4860886126332\n",
      "    ess            : 3.8069074605878495\n",
      "    log_marginal   : 1363.5755048272733\n",
      "    val_loss       : -1363.7424621582031\n",
      "    val_ess        : 3.8025526106357574\n",
      "    val_log_marginal: 1363.8387247721355\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 101 [0/54000 (0%)] Loss: -1362.133667\n",
      "Train Epoch: 101 [4096/54000 (8%)] Loss: -1365.179443\n",
      "Train Epoch: 101 [8192/54000 (15%)] Loss: -1364.561279\n",
      "Train Epoch: 101 [12288/54000 (23%)] Loss: -1363.085327\n",
      "Train Epoch: 101 [16384/54000 (30%)] Loss: -1369.623535\n",
      "Train Epoch: 101 [20480/54000 (38%)] Loss: -1365.218628\n",
      "Train Epoch: 101 [24576/54000 (46%)] Loss: -1366.896484\n",
      "Train Epoch: 101 [28672/54000 (53%)] Loss: -1367.720947\n",
      "Train Epoch: 101 [32768/54000 (61%)] Loss: -1361.165771\n",
      "Train Epoch: 101 [36864/54000 (68%)] Loss: -1356.648438\n",
      "Train Epoch: 101 [40960/54000 (76%)] Loss: -1360.274902\n",
      "Train Epoch: 101 [45056/54000 (83%)] Loss: -1364.215088\n",
      "Train Epoch: 101 [49152/54000 (91%)] Loss: -1362.293091\n",
      "Train Epoch: 101 [53248/54000 (99%)] Loss: -1359.728638\n",
      "    epoch          : 101\n",
      "    loss           : -1364.4043327440017\n",
      "    ess            : 3.807558503761111\n",
      "    log_marginal   : 1364.4940503739633\n",
      "    val_loss       : -1363.8258005777996\n",
      "    val_ess        : 3.7999104062716165\n",
      "    val_log_marginal: 1363.9157307942708\n",
      "Train Epoch: 102 [0/54000 (0%)] Loss: -1366.831421\n",
      "Train Epoch: 102 [4096/54000 (8%)] Loss: -1359.795410\n",
      "Train Epoch: 102 [8192/54000 (15%)] Loss: -1366.000977\n",
      "Train Epoch: 102 [12288/54000 (23%)] Loss: -1363.154907\n",
      "Train Epoch: 102 [16384/54000 (30%)] Loss: -1362.113770\n",
      "Train Epoch: 102 [20480/54000 (38%)] Loss: -1361.112305\n",
      "Train Epoch: 102 [24576/54000 (46%)] Loss: -1365.785889\n",
      "Train Epoch: 102 [28672/54000 (53%)] Loss: -1367.076660\n",
      "Train Epoch: 102 [32768/54000 (61%)] Loss: -1363.965088\n",
      "Train Epoch: 102 [36864/54000 (68%)] Loss: -1364.609741\n",
      "Train Epoch: 102 [40960/54000 (76%)] Loss: -1365.956421\n",
      "Train Epoch: 102 [45056/54000 (83%)] Loss: -1358.045166\n",
      "Train Epoch: 102 [49152/54000 (91%)] Loss: -1368.016846\n",
      "Train Epoch: 102 [53248/54000 (99%)] Loss: -1367.921997\n",
      "    epoch          : 102\n",
      "    loss           : -1365.0759150066647\n",
      "    ess            : 3.8059791072285005\n",
      "    log_marginal   : 1365.1682626444017\n",
      "    val_loss       : -1364.438959757487\n",
      "    val_ess        : 3.807129214207331\n",
      "    val_log_marginal: 1364.5256601969402\n",
      "Train Epoch: 103 [0/54000 (0%)] Loss: -1363.355591\n",
      "Train Epoch: 103 [4096/54000 (8%)] Loss: -1367.351196\n",
      "Train Epoch: 103 [8192/54000 (15%)] Loss: -1367.959473\n",
      "Train Epoch: 103 [12288/54000 (23%)] Loss: -1365.853271\n",
      "Train Epoch: 103 [16384/54000 (30%)] Loss: -1363.744751\n",
      "Train Epoch: 103 [20480/54000 (38%)] Loss: -1364.046997\n",
      "Train Epoch: 103 [24576/54000 (46%)] Loss: -1365.786621\n",
      "Train Epoch: 103 [28672/54000 (53%)] Loss: -1369.367432\n",
      "Train Epoch: 103 [32768/54000 (61%)] Loss: -1369.969360\n",
      "Train Epoch: 103 [36864/54000 (68%)] Loss: -1361.277100\n",
      "Train Epoch: 103 [40960/54000 (76%)] Loss: -1360.830811\n",
      "Train Epoch: 103 [45056/54000 (83%)] Loss: -1365.501953\n",
      "Train Epoch: 103 [49152/54000 (91%)] Loss: -1366.584106\n",
      "Train Epoch: 103 [53248/54000 (99%)] Loss: -1363.798706\n",
      "    epoch          : 103\n",
      "    loss           : -1366.2405456253703\n",
      "    ess            : 3.8089787756662234\n",
      "    log_marginal   : 1366.329807950422\n",
      "    val_loss       : -1366.4335683186848\n",
      "    val_ess        : 3.8101995090643563\n",
      "    val_log_marginal: 1366.5183715820312\n",
      "Train Epoch: 104 [0/54000 (0%)] Loss: -1370.211914\n",
      "Train Epoch: 104 [4096/54000 (8%)] Loss: -1367.056152\n",
      "Train Epoch: 104 [8192/54000 (15%)] Loss: -1368.706177\n",
      "Train Epoch: 104 [12288/54000 (23%)] Loss: -1373.322998\n",
      "Train Epoch: 104 [16384/54000 (30%)] Loss: -1369.818726\n",
      "Train Epoch: 104 [20480/54000 (38%)] Loss: -1370.342529\n",
      "Train Epoch: 104 [24576/54000 (46%)] Loss: -1361.684326\n",
      "Train Epoch: 104 [28672/54000 (53%)] Loss: -1363.444336\n",
      "Train Epoch: 104 [32768/54000 (61%)] Loss: -1363.513428\n",
      "Train Epoch: 104 [36864/54000 (68%)] Loss: -1368.944336\n",
      "Train Epoch: 104 [40960/54000 (76%)] Loss: -1370.522949\n",
      "Train Epoch: 104 [45056/54000 (83%)] Loss: -1360.696899\n",
      "Train Epoch: 104 [49152/54000 (91%)] Loss: -1364.582520\n",
      "Train Epoch: 104 [53248/54000 (99%)] Loss: -1367.795288\n",
      "    epoch          : 104\n",
      "    loss           : -1367.532256646179\n",
      "    ess            : 3.8079596401955844\n",
      "    log_marginal   : 1367.6224318951793\n",
      "    val_loss       : -1367.2657979329426\n",
      "    val_ess        : 3.810125778118769\n",
      "    val_log_marginal: 1367.3562571207683\n",
      "Train Epoch: 105 [0/54000 (0%)] Loss: -1369.866089\n",
      "Train Epoch: 105 [4096/54000 (8%)] Loss: -1369.354980\n",
      "Train Epoch: 105 [8192/54000 (15%)] Loss: -1365.831787\n",
      "Train Epoch: 105 [12288/54000 (23%)] Loss: -1375.564209\n",
      "Train Epoch: 105 [16384/54000 (30%)] Loss: -1365.771729\n",
      "Train Epoch: 105 [20480/54000 (38%)] Loss: -1366.103271\n",
      "Train Epoch: 105 [24576/54000 (46%)] Loss: -1371.678589\n",
      "Train Epoch: 105 [28672/54000 (53%)] Loss: -1374.926270\n",
      "Train Epoch: 105 [32768/54000 (61%)] Loss: -1367.960815\n",
      "Train Epoch: 105 [36864/54000 (68%)] Loss: -1362.479248\n",
      "Train Epoch: 105 [40960/54000 (76%)] Loss: -1366.005249\n",
      "Train Epoch: 105 [45056/54000 (83%)] Loss: -1368.071289\n",
      "Train Epoch: 105 [49152/54000 (91%)] Loss: -1360.889160\n",
      "Train Epoch: 105 [53248/54000 (99%)] Loss: -1371.793579\n",
      "    epoch          : 105\n",
      "    loss           : -1368.329329504221\n",
      "    ess            : 3.8024657450581048\n",
      "    log_marginal   : 1368.4240369751556\n",
      "    val_loss       : -1367.9431050618489\n",
      "    val_ess        : 3.8043273588021598\n",
      "    val_log_marginal: 1368.0345357259114\n",
      "Train Epoch: 106 [0/54000 (0%)] Loss: -1368.983154\n",
      "Train Epoch: 106 [4096/54000 (8%)] Loss: -1362.912842\n",
      "Train Epoch: 106 [8192/54000 (15%)] Loss: -1370.693481\n",
      "Train Epoch: 106 [12288/54000 (23%)] Loss: -1371.111328\n",
      "Train Epoch: 106 [16384/54000 (30%)] Loss: -1368.407471\n",
      "Train Epoch: 106 [20480/54000 (38%)] Loss: -1368.164062\n",
      "Train Epoch: 106 [24576/54000 (46%)] Loss: -1369.592529\n",
      "Train Epoch: 106 [28672/54000 (53%)] Loss: -1368.932617\n",
      "Train Epoch: 106 [32768/54000 (61%)] Loss: -1366.932129\n",
      "Train Epoch: 106 [36864/54000 (68%)] Loss: -1363.808472\n",
      "Train Epoch: 106 [40960/54000 (76%)] Loss: -1370.049805\n",
      "Train Epoch: 106 [45056/54000 (83%)] Loss: -1384.168823\n",
      "Train Epoch: 106 [49152/54000 (91%)] Loss: -1369.125732\n",
      "Train Epoch: 106 [53248/54000 (99%)] Loss: -1373.791992\n",
      "    epoch          : 106\n",
      "    loss           : -1369.2020610791246\n",
      "    ess            : 3.8054560259055186\n",
      "    log_marginal   : 1369.2967691285914\n",
      "    val_loss       : -1369.0147959391277\n",
      "    val_ess        : 3.801680008570353\n",
      "    val_log_marginal: 1369.1097920735676\n",
      "Train Epoch: 107 [0/54000 (0%)] Loss: -1369.951172\n",
      "Train Epoch: 107 [4096/54000 (8%)] Loss: -1377.414795\n",
      "Train Epoch: 107 [8192/54000 (15%)] Loss: -1373.985596\n",
      "Train Epoch: 107 [12288/54000 (23%)] Loss: -1371.306885\n",
      "Train Epoch: 107 [16384/54000 (30%)] Loss: -1365.017090\n",
      "Train Epoch: 107 [20480/54000 (38%)] Loss: -1368.821655\n",
      "Train Epoch: 107 [24576/54000 (46%)] Loss: -1368.920654\n",
      "Train Epoch: 107 [28672/54000 (53%)] Loss: -1367.800659\n",
      "Train Epoch: 107 [32768/54000 (61%)] Loss: -1365.148804\n",
      "Train Epoch: 107 [36864/54000 (68%)] Loss: -1369.167969\n",
      "Train Epoch: 107 [40960/54000 (76%)] Loss: -1371.841553\n",
      "Train Epoch: 107 [45056/54000 (83%)] Loss: -1368.281128\n",
      "Train Epoch: 107 [49152/54000 (91%)] Loss: -1364.587402\n",
      "Train Epoch: 107 [53248/54000 (99%)] Loss: -1370.404907\n",
      "    epoch          : 107\n",
      "    loss           : -1370.2131926188538\n",
      "    ess            : 3.807739707530957\n",
      "    log_marginal   : 1370.3055755470602\n",
      "    val_loss       : -1370.026382446289\n",
      "    val_ess        : 3.7979643146197\n",
      "    val_log_marginal: 1370.1282450358074\n",
      "Train Epoch: 108 [0/54000 (0%)] Loss: -1367.887695\n",
      "Train Epoch: 108 [4096/54000 (8%)] Loss: -1371.024414\n",
      "Train Epoch: 108 [8192/54000 (15%)] Loss: -1368.998291\n",
      "Train Epoch: 108 [12288/54000 (23%)] Loss: -1365.455322\n",
      "Train Epoch: 108 [16384/54000 (30%)] Loss: -1375.427002\n",
      "Train Epoch: 108 [20480/54000 (38%)] Loss: -1368.333984\n",
      "Train Epoch: 108 [24576/54000 (46%)] Loss: -1369.715210\n",
      "Train Epoch: 108 [28672/54000 (53%)] Loss: -1374.637085\n",
      "Train Epoch: 108 [32768/54000 (61%)] Loss: -1368.541016\n",
      "Train Epoch: 108 [36864/54000 (68%)] Loss: -1367.846802\n",
      "Train Epoch: 108 [40960/54000 (76%)] Loss: -1369.899902\n",
      "Train Epoch: 108 [45056/54000 (83%)] Loss: -1379.748535\n",
      "Train Epoch: 108 [49152/54000 (91%)] Loss: -1376.040283\n",
      "Train Epoch: 108 [53248/54000 (99%)] Loss: -1373.309082\n",
      "    epoch          : 108\n",
      "    loss           : -1371.0914005803836\n",
      "    ess            : 3.8061503222768343\n",
      "    log_marginal   : 1371.1824563555242\n",
      "    val_loss       : -1370.540995279948\n",
      "    val_ess        : 3.7967518170674643\n",
      "    val_log_marginal: 1370.6424814860027\n",
      "Train Epoch: 109 [0/54000 (0%)] Loss: -1373.100830\n",
      "Train Epoch: 109 [4096/54000 (8%)] Loss: -1369.304199\n",
      "Train Epoch: 109 [8192/54000 (15%)] Loss: -1373.764404\n",
      "Train Epoch: 109 [12288/54000 (23%)] Loss: -1366.217285\n",
      "Train Epoch: 109 [16384/54000 (30%)] Loss: -1373.956543\n",
      "Train Epoch: 109 [20480/54000 (38%)] Loss: -1379.267944\n",
      "Train Epoch: 109 [24576/54000 (46%)] Loss: -1369.150146\n",
      "Train Epoch: 109 [28672/54000 (53%)] Loss: -1373.617920\n",
      "Train Epoch: 109 [32768/54000 (61%)] Loss: -1377.525146\n",
      "Train Epoch: 109 [36864/54000 (68%)] Loss: -1374.046387\n",
      "Train Epoch: 109 [40960/54000 (76%)] Loss: -1367.436279\n",
      "Train Epoch: 109 [45056/54000 (83%)] Loss: -1380.566040\n",
      "Train Epoch: 109 [49152/54000 (91%)] Loss: -1373.350830\n",
      "Train Epoch: 109 [53248/54000 (99%)] Loss: -1371.771362\n",
      "    epoch          : 109\n",
      "    loss           : -1372.3816068387146\n",
      "    ess            : 3.809018823207837\n",
      "    log_marginal   : 1372.4733510672763\n",
      "    val_loss       : -1371.7671966552734\n",
      "    val_ess        : 3.8192160626252494\n",
      "    val_log_marginal: 1371.849868774414\n",
      "Train Epoch: 110 [0/54000 (0%)] Loss: -1368.868164\n",
      "Train Epoch: 110 [4096/54000 (8%)] Loss: -1376.802368\n",
      "Train Epoch: 110 [8192/54000 (15%)] Loss: -1374.716919\n",
      "Train Epoch: 110 [12288/54000 (23%)] Loss: -1377.952026\n",
      "Train Epoch: 110 [16384/54000 (30%)] Loss: -1374.942871\n",
      "Train Epoch: 110 [20480/54000 (38%)] Loss: -1364.306641\n",
      "Train Epoch: 110 [24576/54000 (46%)] Loss: -1373.728760\n",
      "Train Epoch: 110 [28672/54000 (53%)] Loss: -1373.008789\n",
      "Train Epoch: 110 [32768/54000 (61%)] Loss: -1370.363525\n",
      "Train Epoch: 110 [36864/54000 (68%)] Loss: -1370.583008\n",
      "Train Epoch: 110 [40960/54000 (76%)] Loss: -1375.161499\n",
      "Train Epoch: 110 [45056/54000 (83%)] Loss: -1377.714722\n",
      "Train Epoch: 110 [49152/54000 (91%)] Loss: -1379.281250\n",
      "Train Epoch: 110 [53248/54000 (99%)] Loss: -1374.534180\n",
      "    epoch          : 110\n",
      "    loss           : -1373.1558166793172\n",
      "    ess            : 3.8043244845494275\n",
      "    log_marginal   : 1373.2500115706457\n",
      "    val_loss       : -1372.7068481445312\n",
      "    val_ess        : 3.810115933418274\n",
      "    val_log_marginal: 1372.7997385660808\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch110.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 111 [0/54000 (0%)] Loss: -1371.545288\n",
      "Train Epoch: 111 [4096/54000 (8%)] Loss: -1376.563354\n",
      "Train Epoch: 111 [8192/54000 (15%)] Loss: -1381.482056\n",
      "Train Epoch: 111 [12288/54000 (23%)] Loss: -1367.866211\n",
      "Train Epoch: 111 [16384/54000 (30%)] Loss: -1368.638672\n",
      "Train Epoch: 111 [20480/54000 (38%)] Loss: -1373.872559\n",
      "Train Epoch: 111 [24576/54000 (46%)] Loss: -1372.182983\n",
      "Train Epoch: 111 [28672/54000 (53%)] Loss: -1379.348389\n",
      "Train Epoch: 111 [32768/54000 (61%)] Loss: -1380.956665\n",
      "Train Epoch: 111 [36864/54000 (68%)] Loss: -1375.992065\n",
      "Train Epoch: 111 [40960/54000 (76%)] Loss: -1373.153809\n",
      "Train Epoch: 111 [45056/54000 (83%)] Loss: -1382.212280\n",
      "Train Epoch: 111 [49152/54000 (91%)] Loss: -1379.485596\n",
      "Train Epoch: 111 [53248/54000 (99%)] Loss: -1370.450928\n",
      "    epoch          : 111\n",
      "    loss           : -1374.2145972952458\n",
      "    ess            : 3.80983290740099\n",
      "    log_marginal   : 1374.3060325875667\n",
      "    val_loss       : -1373.4363047281902\n",
      "    val_ess        : 3.7973255018393197\n",
      "    val_log_marginal: 1373.5381418863933\n",
      "Train Epoch: 112 [0/54000 (0%)] Loss: -1373.169678\n",
      "Train Epoch: 112 [4096/54000 (8%)] Loss: -1378.447754\n",
      "Train Epoch: 112 [8192/54000 (15%)] Loss: -1377.786377\n",
      "Train Epoch: 112 [12288/54000 (23%)] Loss: -1381.295410\n",
      "Train Epoch: 112 [16384/54000 (30%)] Loss: -1376.813721\n",
      "Train Epoch: 112 [20480/54000 (38%)] Loss: -1368.233643\n",
      "Train Epoch: 112 [24576/54000 (46%)] Loss: -1375.416748\n",
      "Train Epoch: 112 [28672/54000 (53%)] Loss: -1376.964844\n",
      "Train Epoch: 112 [32768/54000 (61%)] Loss: -1378.597656\n",
      "Train Epoch: 112 [36864/54000 (68%)] Loss: -1373.628174\n",
      "Train Epoch: 112 [40960/54000 (76%)] Loss: -1375.666748\n",
      "Train Epoch: 112 [45056/54000 (83%)] Loss: -1384.967041\n",
      "Train Epoch: 112 [49152/54000 (91%)] Loss: -1371.510986\n",
      "Train Epoch: 112 [53248/54000 (99%)] Loss: -1378.666260\n",
      "    epoch          : 112\n",
      "    loss           : -1375.2684841065611\n",
      "    ess            : 3.802157614468398\n",
      "    log_marginal   : 1375.366236971453\n",
      "    val_loss       : -1373.6893310546875\n",
      "    val_ess        : 3.8009572625160217\n",
      "    val_log_marginal: 1373.7865346272786\n",
      "Train Epoch: 113 [0/54000 (0%)] Loss: -1368.816895\n",
      "Train Epoch: 113 [4096/54000 (8%)] Loss: -1376.715576\n",
      "Train Epoch: 113 [8192/54000 (15%)] Loss: -1378.671265\n",
      "Train Epoch: 113 [12288/54000 (23%)] Loss: -1369.891846\n",
      "Train Epoch: 113 [16384/54000 (30%)] Loss: -1374.728027\n",
      "Train Epoch: 113 [20480/54000 (38%)] Loss: -1380.303955\n",
      "Train Epoch: 113 [24576/54000 (46%)] Loss: -1373.720215\n",
      "Train Epoch: 113 [28672/54000 (53%)] Loss: -1370.615967\n",
      "Train Epoch: 113 [32768/54000 (61%)] Loss: -1381.182861\n",
      "Train Epoch: 113 [36864/54000 (68%)] Loss: -1377.674561\n",
      "Train Epoch: 113 [40960/54000 (76%)] Loss: -1378.450439\n",
      "Train Epoch: 113 [45056/54000 (83%)] Loss: -1372.304199\n",
      "Train Epoch: 113 [49152/54000 (91%)] Loss: -1374.259766\n",
      "Train Epoch: 113 [53248/54000 (99%)] Loss: -1379.324463\n",
      "    epoch          : 113\n",
      "    loss           : -1376.2694895956754\n",
      "    ess            : 3.8059265624855367\n",
      "    log_marginal   : 1376.3624649409435\n",
      "    val_loss       : -1376.095438639323\n",
      "    val_ess        : 3.8094943861166635\n",
      "    val_log_marginal: 1376.1896260579426\n",
      "Train Epoch: 114 [0/54000 (0%)] Loss: -1383.296387\n",
      "Train Epoch: 114 [4096/54000 (8%)] Loss: -1380.297607\n",
      "Train Epoch: 114 [8192/54000 (15%)] Loss: -1371.817139\n",
      "Train Epoch: 114 [12288/54000 (23%)] Loss: -1373.440674\n",
      "Train Epoch: 114 [16384/54000 (30%)] Loss: -1375.919312\n",
      "Train Epoch: 114 [20480/54000 (38%)] Loss: -1372.304932\n",
      "Train Epoch: 114 [24576/54000 (46%)] Loss: -1375.394287\n",
      "Train Epoch: 114 [28672/54000 (53%)] Loss: -1374.648438\n",
      "Train Epoch: 114 [32768/54000 (61%)] Loss: -1374.283447\n",
      "Train Epoch: 114 [36864/54000 (68%)] Loss: -1375.070190\n",
      "Train Epoch: 114 [40960/54000 (76%)] Loss: -1380.378174\n",
      "Train Epoch: 114 [45056/54000 (83%)] Loss: -1378.824219\n",
      "Train Epoch: 114 [49152/54000 (91%)] Loss: -1375.197876\n",
      "Train Epoch: 114 [53248/54000 (99%)] Loss: -1382.411743\n",
      "    epoch          : 114\n",
      "    loss           : -1377.2649631590639\n",
      "    ess            : 3.8052458797020936\n",
      "    log_marginal   : 1377.3601230422466\n",
      "    val_loss       : -1376.3247528076172\n",
      "    val_ess        : 3.80567075808843\n",
      "    val_log_marginal: 1376.4190368652344\n",
      "Train Epoch: 115 [0/54000 (0%)] Loss: -1382.570557\n",
      "Train Epoch: 115 [4096/54000 (8%)] Loss: -1378.447510\n",
      "Train Epoch: 115 [8192/54000 (15%)] Loss: -1383.938232\n",
      "Train Epoch: 115 [12288/54000 (23%)] Loss: -1382.267090\n",
      "Train Epoch: 115 [16384/54000 (30%)] Loss: -1374.936768\n",
      "Train Epoch: 115 [20480/54000 (38%)] Loss: -1370.918091\n",
      "Train Epoch: 115 [24576/54000 (46%)] Loss: -1379.222168\n",
      "Train Epoch: 115 [28672/54000 (53%)] Loss: -1377.792969\n",
      "Train Epoch: 115 [32768/54000 (61%)] Loss: -1374.903320\n",
      "Train Epoch: 115 [36864/54000 (68%)] Loss: -1381.178589\n",
      "Train Epoch: 115 [40960/54000 (76%)] Loss: -1387.401245\n",
      "Train Epoch: 115 [45056/54000 (83%)] Loss: -1382.363647\n",
      "Train Epoch: 115 [49152/54000 (91%)] Loss: -1379.249023\n",
      "Train Epoch: 115 [53248/54000 (99%)] Loss: -1379.923462\n",
      "    epoch          : 115\n",
      "    loss           : -1378.5015984847082\n",
      "    ess            : 3.802955433090716\n",
      "    log_marginal   : 1378.5987525686833\n",
      "    val_loss       : -1377.4195556640625\n",
      "    val_ess        : 3.806619167327881\n",
      "    val_log_marginal: 1377.521499633789\n",
      "Train Epoch: 116 [0/54000 (0%)] Loss: -1377.384644\n",
      "Train Epoch: 116 [4096/54000 (8%)] Loss: -1384.354492\n",
      "Train Epoch: 116 [8192/54000 (15%)] Loss: -1379.503906\n",
      "Train Epoch: 116 [12288/54000 (23%)] Loss: -1385.546997\n",
      "Train Epoch: 116 [16384/54000 (30%)] Loss: -1386.717407\n",
      "Train Epoch: 116 [20480/54000 (38%)] Loss: -1381.426514\n",
      "Train Epoch: 116 [24576/54000 (46%)] Loss: -1388.849609\n",
      "Train Epoch: 116 [28672/54000 (53%)] Loss: -1379.912842\n",
      "Train Epoch: 116 [32768/54000 (61%)] Loss: -1382.827026\n",
      "Train Epoch: 116 [36864/54000 (68%)] Loss: -1379.724976\n",
      "Train Epoch: 116 [40960/54000 (76%)] Loss: -1376.964600\n",
      "Train Epoch: 116 [45056/54000 (83%)] Loss: -1382.535400\n",
      "Train Epoch: 116 [49152/54000 (91%)] Loss: -1379.478638\n",
      "Train Epoch: 116 [53248/54000 (99%)] Loss: -1377.691772\n",
      "    epoch          : 116\n",
      "    loss           : -1379.6716059824867\n",
      "    ess            : 3.8063457181668396\n",
      "    log_marginal   : 1379.767529528288\n",
      "    val_loss       : -1378.5257568359375\n",
      "    val_ess        : 3.8016363779703775\n",
      "    val_log_marginal: 1378.6260019938152\n",
      "Train Epoch: 117 [0/54000 (0%)] Loss: -1383.378418\n",
      "Train Epoch: 117 [4096/54000 (8%)] Loss: -1377.659912\n",
      "Train Epoch: 117 [8192/54000 (15%)] Loss: -1380.729736\n",
      "Train Epoch: 117 [12288/54000 (23%)] Loss: -1385.066895\n",
      "Train Epoch: 117 [16384/54000 (30%)] Loss: -1378.144775\n",
      "Train Epoch: 117 [20480/54000 (38%)] Loss: -1379.164795\n",
      "Train Epoch: 117 [24576/54000 (46%)] Loss: -1386.339355\n",
      "Train Epoch: 117 [28672/54000 (53%)] Loss: -1380.725220\n",
      "Train Epoch: 117 [32768/54000 (61%)] Loss: -1386.232666\n",
      "Train Epoch: 117 [36864/54000 (68%)] Loss: -1380.104126\n",
      "Train Epoch: 117 [40960/54000 (76%)] Loss: -1374.425049\n",
      "Train Epoch: 117 [45056/54000 (83%)] Loss: -1383.158691\n",
      "Train Epoch: 117 [49152/54000 (91%)] Loss: -1377.068970\n",
      "Train Epoch: 117 [53248/54000 (99%)] Loss: -1377.599121\n",
      "    epoch          : 117\n",
      "    loss           : -1380.4686539636405\n",
      "    ess            : 3.805668149514221\n",
      "    log_marginal   : 1380.565250342491\n",
      "    val_loss       : -1379.6564534505208\n",
      "    val_ess        : 3.801269223292669\n",
      "    val_log_marginal: 1379.7576243082683\n",
      "Train Epoch: 118 [0/54000 (0%)] Loss: -1376.341309\n",
      "Train Epoch: 118 [4096/54000 (8%)] Loss: -1383.855713\n",
      "Train Epoch: 118 [8192/54000 (15%)] Loss: -1379.678589\n",
      "Train Epoch: 118 [12288/54000 (23%)] Loss: -1378.671631\n",
      "Train Epoch: 118 [16384/54000 (30%)] Loss: -1391.680176\n",
      "Train Epoch: 118 [20480/54000 (38%)] Loss: -1382.111328\n",
      "Train Epoch: 118 [24576/54000 (46%)] Loss: -1387.032715\n",
      "Train Epoch: 118 [28672/54000 (53%)] Loss: -1383.145264\n",
      "Train Epoch: 118 [32768/54000 (61%)] Loss: -1379.183228\n",
      "Train Epoch: 118 [36864/54000 (68%)] Loss: -1377.139404\n",
      "Train Epoch: 118 [40960/54000 (76%)] Loss: -1380.185059\n",
      "Train Epoch: 118 [45056/54000 (83%)] Loss: -1378.643677\n",
      "Train Epoch: 118 [49152/54000 (91%)] Loss: -1382.091064\n",
      "Train Epoch: 118 [53248/54000 (99%)] Loss: -1375.918701\n",
      "    epoch          : 118\n",
      "    loss           : -1381.6214923587456\n",
      "    ess            : 3.806761099828928\n",
      "    log_marginal   : 1381.7175865715715\n",
      "    val_loss       : -1381.7863006591797\n",
      "    val_ess        : 3.8068133890628815\n",
      "    val_log_marginal: 1381.8756154378254\n",
      "Train Epoch: 119 [0/54000 (0%)] Loss: -1384.845459\n",
      "Train Epoch: 119 [4096/54000 (8%)] Loss: -1383.601929\n",
      "Train Epoch: 119 [8192/54000 (15%)] Loss: -1392.337891\n",
      "Train Epoch: 119 [12288/54000 (23%)] Loss: -1379.015625\n",
      "Train Epoch: 119 [16384/54000 (30%)] Loss: -1386.047974\n",
      "Train Epoch: 119 [20480/54000 (38%)] Loss: -1379.583618\n",
      "Train Epoch: 119 [24576/54000 (46%)] Loss: -1385.622803\n",
      "Train Epoch: 119 [28672/54000 (53%)] Loss: -1381.333740\n",
      "Train Epoch: 119 [32768/54000 (61%)] Loss: -1389.339600\n",
      "Train Epoch: 119 [36864/54000 (68%)] Loss: -1382.968262\n",
      "Train Epoch: 119 [40960/54000 (76%)] Loss: -1376.859619\n",
      "Train Epoch: 119 [45056/54000 (83%)] Loss: -1384.958496\n",
      "Train Epoch: 119 [49152/54000 (91%)] Loss: -1383.138916\n",
      "Train Epoch: 119 [53248/54000 (99%)] Loss: -1381.041504\n",
      "    epoch          : 119\n",
      "    loss           : -1382.9322099007702\n",
      "    ess            : 3.799973032485817\n",
      "    log_marginal   : 1383.0312719842268\n",
      "    val_loss       : -1381.7652180989583\n",
      "    val_ess        : 3.8176462054252625\n",
      "    val_log_marginal: 1381.8590749104817\n",
      "Train Epoch: 120 [0/54000 (0%)] Loss: -1378.958252\n",
      "Train Epoch: 120 [4096/54000 (8%)] Loss: -1383.506104\n",
      "Train Epoch: 120 [8192/54000 (15%)] Loss: -1391.360596\n",
      "Train Epoch: 120 [12288/54000 (23%)] Loss: -1385.024292\n",
      "Train Epoch: 120 [16384/54000 (30%)] Loss: -1386.065430\n",
      "Train Epoch: 120 [20480/54000 (38%)] Loss: -1388.026123\n",
      "Train Epoch: 120 [24576/54000 (46%)] Loss: -1386.448608\n",
      "Train Epoch: 120 [28672/54000 (53%)] Loss: -1381.847900\n",
      "Train Epoch: 120 [32768/54000 (61%)] Loss: -1387.357056\n",
      "Train Epoch: 120 [36864/54000 (68%)] Loss: -1386.902832\n",
      "Train Epoch: 120 [40960/54000 (76%)] Loss: -1390.097168\n",
      "Train Epoch: 120 [45056/54000 (83%)] Loss: -1388.171265\n",
      "Train Epoch: 120 [49152/54000 (91%)] Loss: -1383.181152\n",
      "Train Epoch: 120 [53248/54000 (99%)] Loss: -1377.737549\n",
      "    epoch          : 120\n",
      "    loss           : -1383.8886498907732\n",
      "    ess            : 3.8013159562061185\n",
      "    log_marginal   : 1383.9878566073016\n",
      "    val_loss       : -1383.0161743164062\n",
      "    val_ess        : 3.8070062597592673\n",
      "    val_log_marginal: 1383.1070709228516\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch120.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 121 [0/54000 (0%)] Loss: -1384.977783\n",
      "Train Epoch: 121 [4096/54000 (8%)] Loss: -1391.875732\n",
      "Train Epoch: 121 [8192/54000 (15%)] Loss: -1385.450928\n",
      "Train Epoch: 121 [12288/54000 (23%)] Loss: -1392.279297\n",
      "Train Epoch: 121 [16384/54000 (30%)] Loss: -1386.069336\n",
      "Train Epoch: 121 [20480/54000 (38%)] Loss: -1384.975342\n",
      "Train Epoch: 121 [24576/54000 (46%)] Loss: -1384.798218\n",
      "Train Epoch: 121 [28672/54000 (53%)] Loss: -1390.267456\n",
      "Train Epoch: 121 [32768/54000 (61%)] Loss: -1385.337402\n",
      "Train Epoch: 121 [36864/54000 (68%)] Loss: -1383.348145\n",
      "Train Epoch: 121 [40960/54000 (76%)] Loss: -1390.587158\n",
      "Train Epoch: 121 [45056/54000 (83%)] Loss: -1385.866943\n",
      "Train Epoch: 121 [49152/54000 (91%)] Loss: -1380.747925\n",
      "Train Epoch: 121 [53248/54000 (99%)] Loss: -1380.854980\n",
      "    epoch          : 121\n",
      "    loss           : -1385.0748418292728\n",
      "    ess            : 3.805685806048425\n",
      "    log_marginal   : 1385.1707688462677\n",
      "    val_loss       : -1384.5128479003906\n",
      "    val_ess        : 3.8118534982204437\n",
      "    val_log_marginal: 1384.602066040039\n",
      "Train Epoch: 122 [0/54000 (0%)] Loss: -1393.074707\n",
      "Train Epoch: 122 [4096/54000 (8%)] Loss: -1382.315430\n",
      "Train Epoch: 122 [8192/54000 (15%)] Loss: -1389.628662\n",
      "Train Epoch: 122 [12288/54000 (23%)] Loss: -1387.502686\n",
      "Train Epoch: 122 [16384/54000 (30%)] Loss: -1386.703613\n",
      "Train Epoch: 122 [20480/54000 (38%)] Loss: -1381.045288\n",
      "Train Epoch: 122 [24576/54000 (46%)] Loss: -1389.120117\n",
      "Train Epoch: 122 [28672/54000 (53%)] Loss: -1390.848511\n",
      "Train Epoch: 122 [32768/54000 (61%)] Loss: -1381.579712\n",
      "Train Epoch: 122 [36864/54000 (68%)] Loss: -1389.483521\n",
      "Train Epoch: 122 [40960/54000 (76%)] Loss: -1389.338379\n",
      "Train Epoch: 122 [45056/54000 (83%)] Loss: -1378.739990\n",
      "Train Epoch: 122 [49152/54000 (91%)] Loss: -1387.824951\n",
      "Train Epoch: 122 [53248/54000 (99%)] Loss: -1385.222656\n",
      "    epoch          : 122\n",
      "    loss           : -1386.161685889366\n",
      "    ess            : 3.80040869328648\n",
      "    log_marginal   : 1386.2624743131664\n",
      "    val_loss       : -1385.2147827148438\n",
      "    val_ess        : 3.796037624279658\n",
      "    val_log_marginal: 1385.3175404866536\n",
      "Train Epoch: 123 [0/54000 (0%)] Loss: -1389.623535\n",
      "Train Epoch: 123 [4096/54000 (8%)] Loss: -1391.024414\n",
      "Train Epoch: 123 [8192/54000 (15%)] Loss: -1385.913574\n",
      "Train Epoch: 123 [12288/54000 (23%)] Loss: -1391.872925\n",
      "Train Epoch: 123 [16384/54000 (30%)] Loss: -1382.950073\n",
      "Train Epoch: 123 [20480/54000 (38%)] Loss: -1390.182373\n",
      "Train Epoch: 123 [24576/54000 (46%)] Loss: -1386.413574\n",
      "Train Epoch: 123 [28672/54000 (53%)] Loss: -1383.833862\n",
      "Train Epoch: 123 [32768/54000 (61%)] Loss: -1387.991699\n",
      "Train Epoch: 123 [36864/54000 (68%)] Loss: -1382.877686\n",
      "Train Epoch: 123 [40960/54000 (76%)] Loss: -1390.245605\n",
      "Train Epoch: 123 [45056/54000 (83%)] Loss: -1388.248535\n",
      "Train Epoch: 123 [49152/54000 (91%)] Loss: -1387.160156\n",
      "Train Epoch: 123 [53248/54000 (99%)] Loss: -1386.789062\n",
      "    epoch          : 123\n",
      "    loss           : -1387.162646252962\n",
      "    ess            : 3.798798583695109\n",
      "    log_marginal   : 1387.263942049578\n",
      "    val_loss       : -1386.3487701416016\n",
      "    val_ess        : 3.7941214044888816\n",
      "    val_log_marginal: 1386.450719197591\n",
      "Train Epoch: 124 [0/54000 (0%)] Loss: -1385.370239\n",
      "Train Epoch: 124 [4096/54000 (8%)] Loss: -1391.292725\n",
      "Train Epoch: 124 [8192/54000 (15%)] Loss: -1389.281006\n",
      "Train Epoch: 124 [12288/54000 (23%)] Loss: -1393.132202\n",
      "Train Epoch: 124 [16384/54000 (30%)] Loss: -1379.977539\n",
      "Train Epoch: 124 [20480/54000 (38%)] Loss: -1386.422852\n",
      "Train Epoch: 124 [24576/54000 (46%)] Loss: -1388.381592\n",
      "Train Epoch: 124 [28672/54000 (53%)] Loss: -1398.526611\n",
      "Train Epoch: 124 [32768/54000 (61%)] Loss: -1382.517334\n",
      "Train Epoch: 124 [36864/54000 (68%)] Loss: -1385.297729\n",
      "Train Epoch: 124 [40960/54000 (76%)] Loss: -1389.813477\n",
      "Train Epoch: 124 [45056/54000 (83%)] Loss: -1383.651611\n",
      "Train Epoch: 124 [49152/54000 (91%)] Loss: -1377.035156\n",
      "Train Epoch: 124 [53248/54000 (99%)] Loss: -1384.612305\n",
      "    epoch          : 124\n",
      "    loss           : -1388.1731066952384\n",
      "    ess            : 3.803143538569952\n",
      "    log_marginal   : 1388.2720305094788\n",
      "    val_loss       : -1388.015619913737\n",
      "    val_ess        : 3.7987679541110992\n",
      "    val_log_marginal: 1388.1238047281902\n",
      "Train Epoch: 125 [0/54000 (0%)] Loss: -1389.490356\n",
      "Train Epoch: 125 [4096/54000 (8%)] Loss: -1398.541504\n",
      "Train Epoch: 125 [8192/54000 (15%)] Loss: -1387.896973\n",
      "Train Epoch: 125 [12288/54000 (23%)] Loss: -1392.884766\n",
      "Train Epoch: 125 [16384/54000 (30%)] Loss: -1399.160889\n",
      "Train Epoch: 125 [20480/54000 (38%)] Loss: -1393.217529\n",
      "Train Epoch: 125 [24576/54000 (46%)] Loss: -1387.414307\n",
      "Train Epoch: 125 [28672/54000 (53%)] Loss: -1394.076416\n",
      "Train Epoch: 125 [32768/54000 (61%)] Loss: -1388.516846\n",
      "Train Epoch: 125 [36864/54000 (68%)] Loss: -1388.953735\n",
      "Train Epoch: 125 [40960/54000 (76%)] Loss: -1386.225098\n",
      "Train Epoch: 125 [45056/54000 (83%)] Loss: -1390.606689\n",
      "Train Epoch: 125 [49152/54000 (91%)] Loss: -1392.652832\n",
      "Train Epoch: 125 [53248/54000 (99%)] Loss: -1383.860107\n",
      "    epoch          : 125\n",
      "    loss           : -1389.62926551855\n",
      "    ess            : 3.7987314445712554\n",
      "    log_marginal   : 1389.7313897734005\n",
      "    val_loss       : -1388.7980702718098\n",
      "    val_ess        : 3.790399491786957\n",
      "    val_log_marginal: 1388.9121348063152\n",
      "Train Epoch: 126 [0/54000 (0%)] Loss: -1386.938477\n",
      "Train Epoch: 126 [4096/54000 (8%)] Loss: -1386.632202\n",
      "Train Epoch: 126 [8192/54000 (15%)] Loss: -1395.799927\n",
      "Train Epoch: 126 [12288/54000 (23%)] Loss: -1384.110107\n",
      "Train Epoch: 126 [16384/54000 (30%)] Loss: -1390.707764\n",
      "Train Epoch: 126 [20480/54000 (38%)] Loss: -1388.072021\n",
      "Train Epoch: 126 [24576/54000 (46%)] Loss: -1392.818237\n",
      "Train Epoch: 126 [28672/54000 (53%)] Loss: -1392.102295\n",
      "Train Epoch: 126 [32768/54000 (61%)] Loss: -1392.695801\n",
      "Train Epoch: 126 [36864/54000 (68%)] Loss: -1392.928833\n",
      "Train Epoch: 126 [40960/54000 (76%)] Loss: -1394.126343\n",
      "Train Epoch: 126 [45056/54000 (83%)] Loss: -1385.975952\n",
      "Train Epoch: 126 [49152/54000 (91%)] Loss: -1390.815063\n",
      "Train Epoch: 126 [53248/54000 (99%)] Loss: -1382.147949\n",
      "    epoch          : 126\n",
      "    loss           : -1390.545026589344\n",
      "    ess            : 3.7986114861275913\n",
      "    log_marginal   : 1390.6473128332345\n",
      "    val_loss       : -1390.0602569580078\n",
      "    val_ess        : 3.793071061372757\n",
      "    val_log_marginal: 1390.1684265136719\n",
      "Train Epoch: 127 [0/54000 (0%)] Loss: -1392.201660\n",
      "Train Epoch: 127 [4096/54000 (8%)] Loss: -1390.582031\n",
      "Train Epoch: 127 [8192/54000 (15%)] Loss: -1388.170044\n",
      "Train Epoch: 127 [12288/54000 (23%)] Loss: -1392.009521\n",
      "Train Epoch: 127 [16384/54000 (30%)] Loss: -1388.854126\n",
      "Train Epoch: 127 [20480/54000 (38%)] Loss: -1392.453003\n",
      "Train Epoch: 127 [24576/54000 (46%)] Loss: -1390.367920\n",
      "Train Epoch: 127 [28672/54000 (53%)] Loss: -1391.518555\n",
      "Train Epoch: 127 [32768/54000 (61%)] Loss: -1389.510986\n",
      "Train Epoch: 127 [36864/54000 (68%)] Loss: -1399.710449\n",
      "Train Epoch: 127 [40960/54000 (76%)] Loss: -1386.686279\n",
      "Train Epoch: 127 [45056/54000 (83%)] Loss: -1389.188965\n",
      "Train Epoch: 127 [49152/54000 (91%)] Loss: -1396.063843\n",
      "Train Epoch: 127 [53248/54000 (99%)] Loss: -1389.746338\n",
      "    epoch          : 127\n",
      "    loss           : -1391.7176571525104\n",
      "    ess            : 3.7982939250096326\n",
      "    log_marginal   : 1391.8197166117448\n",
      "    val_loss       : -1391.2589569091797\n",
      "    val_ess        : 3.8055092791716256\n",
      "    val_log_marginal: 1391.3553110758464\n",
      "Train Epoch: 128 [0/54000 (0%)] Loss: -1395.235352\n",
      "Train Epoch: 128 [4096/54000 (8%)] Loss: -1392.833618\n",
      "Train Epoch: 128 [8192/54000 (15%)] Loss: -1395.162109\n",
      "Train Epoch: 128 [12288/54000 (23%)] Loss: -1396.005615\n",
      "Train Epoch: 128 [16384/54000 (30%)] Loss: -1398.245117\n",
      "Train Epoch: 128 [20480/54000 (38%)] Loss: -1395.339600\n",
      "Train Epoch: 128 [24576/54000 (46%)] Loss: -1387.384766\n",
      "Train Epoch: 128 [28672/54000 (53%)] Loss: -1397.950073\n",
      "Train Epoch: 128 [32768/54000 (61%)] Loss: -1388.665527\n",
      "Train Epoch: 128 [36864/54000 (68%)] Loss: -1394.739990\n",
      "Train Epoch: 128 [40960/54000 (76%)] Loss: -1395.074707\n",
      "Train Epoch: 128 [45056/54000 (83%)] Loss: -1391.474609\n",
      "Train Epoch: 128 [49152/54000 (91%)] Loss: -1385.706421\n",
      "Train Epoch: 128 [53248/54000 (99%)] Loss: -1391.026123\n",
      "    epoch          : 128\n",
      "    loss           : -1392.917046569535\n",
      "    ess            : 3.8013313754474947\n",
      "    log_marginal   : 1393.0185350174022\n",
      "    val_loss       : -1393.4330393473308\n",
      "    val_ess        : 3.8049339254697165\n",
      "    val_log_marginal: 1393.5262654622395\n",
      "Train Epoch: 129 [0/54000 (0%)] Loss: -1394.298218\n",
      "Train Epoch: 129 [4096/54000 (8%)] Loss: -1391.011475\n",
      "Train Epoch: 129 [8192/54000 (15%)] Loss: -1393.168945\n",
      "Train Epoch: 129 [12288/54000 (23%)] Loss: -1401.432373\n",
      "Train Epoch: 129 [16384/54000 (30%)] Loss: -1392.912598\n",
      "Train Epoch: 129 [20480/54000 (38%)] Loss: -1396.342651\n",
      "Train Epoch: 129 [24576/54000 (46%)] Loss: -1401.106445\n",
      "Train Epoch: 129 [28672/54000 (53%)] Loss: -1391.908203\n",
      "Train Epoch: 129 [32768/54000 (61%)] Loss: -1386.121582\n",
      "Train Epoch: 129 [36864/54000 (68%)] Loss: -1395.491211\n",
      "Train Epoch: 129 [40960/54000 (76%)] Loss: -1391.197510\n",
      "Train Epoch: 129 [45056/54000 (83%)] Loss: -1391.943848\n",
      "Train Epoch: 129 [49152/54000 (91%)] Loss: -1396.550049\n",
      "Train Epoch: 129 [53248/54000 (99%)] Loss: -1394.519165\n",
      "    epoch          : 129\n",
      "    loss           : -1394.0750732421875\n",
      "    ess            : 3.7998413949216148\n",
      "    log_marginal   : 1394.1746583188315\n",
      "    val_loss       : -1393.7834218343098\n",
      "    val_ess        : 3.790632575750351\n",
      "    val_log_marginal: 1393.8925882975261\n",
      "Train Epoch: 130 [0/54000 (0%)] Loss: -1396.852783\n",
      "Train Epoch: 130 [4096/54000 (8%)] Loss: -1392.808350\n",
      "Train Epoch: 130 [8192/54000 (15%)] Loss: -1399.309326\n",
      "Train Epoch: 130 [12288/54000 (23%)] Loss: -1398.521851\n",
      "Train Epoch: 130 [16384/54000 (30%)] Loss: -1389.751465\n",
      "Train Epoch: 130 [20480/54000 (38%)] Loss: -1389.713013\n",
      "Train Epoch: 130 [24576/54000 (46%)] Loss: -1390.964478\n",
      "Train Epoch: 130 [28672/54000 (53%)] Loss: -1396.564819\n",
      "Train Epoch: 130 [32768/54000 (61%)] Loss: -1398.109863\n",
      "Train Epoch: 130 [36864/54000 (68%)] Loss: -1392.002686\n",
      "Train Epoch: 130 [40960/54000 (76%)] Loss: -1401.305420\n",
      "Train Epoch: 130 [45056/54000 (83%)] Loss: -1397.181152\n",
      "Train Epoch: 130 [49152/54000 (91%)] Loss: -1394.863281\n",
      "Train Epoch: 130 [53248/54000 (99%)] Loss: -1396.730103\n",
      "    epoch          : 130\n",
      "    loss           : -1395.388782953199\n",
      "    ess            : 3.796681734057964\n",
      "    log_marginal   : 1395.4912792043099\n",
      "    val_loss       : -1394.5827382405598\n",
      "    val_ess        : 3.7865211069583893\n",
      "    val_log_marginal: 1394.696792602539\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch130.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 131 [0/54000 (0%)] Loss: -1398.549561\n",
      "Train Epoch: 131 [4096/54000 (8%)] Loss: -1398.337769\n",
      "Train Epoch: 131 [8192/54000 (15%)] Loss: -1395.807373\n",
      "Train Epoch: 131 [12288/54000 (23%)] Loss: -1392.007568\n",
      "Train Epoch: 131 [16384/54000 (30%)] Loss: -1399.644897\n",
      "Train Epoch: 131 [20480/54000 (38%)] Loss: -1398.563965\n",
      "Train Epoch: 131 [24576/54000 (46%)] Loss: -1394.279785\n",
      "Train Epoch: 131 [28672/54000 (53%)] Loss: -1399.576538\n",
      "Train Epoch: 131 [32768/54000 (61%)] Loss: -1396.389404\n",
      "Train Epoch: 131 [36864/54000 (68%)] Loss: -1391.231323\n",
      "Train Epoch: 131 [40960/54000 (76%)] Loss: -1399.300049\n",
      "Train Epoch: 131 [45056/54000 (83%)] Loss: -1393.629639\n",
      "Train Epoch: 131 [49152/54000 (91%)] Loss: -1396.224365\n",
      "Train Epoch: 131 [53248/54000 (99%)] Loss: -1396.404053\n",
      "    epoch          : 131\n",
      "    loss           : -1396.4412344259108\n",
      "    ess            : 3.8015911172351564\n",
      "    log_marginal   : 1396.5445805409508\n",
      "    val_loss       : -1395.8202209472656\n",
      "    val_ess        : 3.7866977055867515\n",
      "    val_log_marginal: 1395.9303181966145\n",
      "Train Epoch: 132 [0/54000 (0%)] Loss: -1402.471069\n",
      "Train Epoch: 132 [4096/54000 (8%)] Loss: -1401.008667\n",
      "Train Epoch: 132 [8192/54000 (15%)] Loss: -1398.409546\n",
      "Train Epoch: 132 [12288/54000 (23%)] Loss: -1397.116577\n",
      "Train Epoch: 132 [16384/54000 (30%)] Loss: -1398.770752\n",
      "Train Epoch: 132 [20480/54000 (38%)] Loss: -1391.146729\n",
      "Train Epoch: 132 [24576/54000 (46%)] Loss: -1401.378906\n",
      "Train Epoch: 132 [28672/54000 (53%)] Loss: -1395.164795\n",
      "Train Epoch: 132 [32768/54000 (61%)] Loss: -1400.449219\n",
      "Train Epoch: 132 [36864/54000 (68%)] Loss: -1401.590088\n",
      "Train Epoch: 132 [40960/54000 (76%)] Loss: -1396.298462\n",
      "Train Epoch: 132 [45056/54000 (83%)] Loss: -1396.437744\n",
      "Train Epoch: 132 [49152/54000 (91%)] Loss: -1393.932373\n",
      "Train Epoch: 132 [53248/54000 (99%)] Loss: -1403.295654\n",
      "    epoch          : 132\n",
      "    loss           : -1397.505076620816\n",
      "    ess            : 3.796135674155719\n",
      "    log_marginal   : 1397.6105407425578\n",
      "    val_loss       : -1397.0589141845703\n",
      "    val_ess        : 3.7839980324109397\n",
      "    val_log_marginal: 1397.1746470133464\n",
      "Train Epoch: 133 [0/54000 (0%)] Loss: -1396.776611\n",
      "Train Epoch: 133 [4096/54000 (8%)] Loss: -1404.570068\n",
      "Train Epoch: 133 [8192/54000 (15%)] Loss: -1396.968506\n",
      "Train Epoch: 133 [12288/54000 (23%)] Loss: -1402.265869\n",
      "Train Epoch: 133 [16384/54000 (30%)] Loss: -1396.529297\n",
      "Train Epoch: 133 [20480/54000 (38%)] Loss: -1392.679688\n",
      "Train Epoch: 133 [24576/54000 (46%)] Loss: -1395.716797\n",
      "Train Epoch: 133 [28672/54000 (53%)] Loss: -1394.476562\n",
      "Train Epoch: 133 [32768/54000 (61%)] Loss: -1405.523682\n",
      "Train Epoch: 133 [36864/54000 (68%)] Loss: -1401.371094\n",
      "Train Epoch: 133 [40960/54000 (76%)] Loss: -1399.964600\n",
      "Train Epoch: 133 [45056/54000 (83%)] Loss: -1396.760986\n",
      "Train Epoch: 133 [49152/54000 (91%)] Loss: -1396.719238\n",
      "Train Epoch: 133 [53248/54000 (99%)] Loss: -1400.061279\n",
      "    epoch          : 133\n",
      "    loss           : -1398.9451192702163\n",
      "    ess            : 3.794439860429809\n",
      "    log_marginal   : 1399.0498295643883\n",
      "    val_loss       : -1397.8118998209636\n",
      "    val_ess        : 3.799683998028437\n",
      "    val_log_marginal: 1397.910380045573\n",
      "Train Epoch: 134 [0/54000 (0%)] Loss: -1392.708862\n",
      "Train Epoch: 134 [4096/54000 (8%)] Loss: -1400.473389\n",
      "Train Epoch: 134 [8192/54000 (15%)] Loss: -1403.017578\n",
      "Train Epoch: 134 [12288/54000 (23%)] Loss: -1399.046509\n",
      "Train Epoch: 134 [16384/54000 (30%)] Loss: -1400.492432\n",
      "Train Epoch: 134 [20480/54000 (38%)] Loss: -1402.951660\n",
      "Train Epoch: 134 [24576/54000 (46%)] Loss: -1397.134521\n",
      "Train Epoch: 134 [28672/54000 (53%)] Loss: -1400.024536\n",
      "Train Epoch: 134 [32768/54000 (61%)] Loss: -1391.383423\n",
      "Train Epoch: 134 [36864/54000 (68%)] Loss: -1402.472900\n",
      "Train Epoch: 134 [40960/54000 (76%)] Loss: -1396.576294\n",
      "Train Epoch: 134 [45056/54000 (83%)] Loss: -1396.409546\n",
      "Train Epoch: 134 [49152/54000 (91%)] Loss: -1394.953369\n",
      "Train Epoch: 134 [53248/54000 (99%)] Loss: -1400.623169\n",
      "    epoch          : 134\n",
      "    loss           : -1400.2150826838345\n",
      "    ess            : 3.795981304340453\n",
      "    log_marginal   : 1400.3210969897807\n",
      "    val_loss       : -1400.7278696695964\n",
      "    val_ess        : 3.794560263554255\n",
      "    val_log_marginal: 1400.8319854736328\n",
      "Train Epoch: 135 [0/54000 (0%)] Loss: -1405.683472\n",
      "Train Epoch: 135 [4096/54000 (8%)] Loss: -1405.139771\n",
      "Train Epoch: 135 [8192/54000 (15%)] Loss: -1398.954468\n",
      "Train Epoch: 135 [12288/54000 (23%)] Loss: -1398.724487\n",
      "Train Epoch: 135 [16384/54000 (30%)] Loss: -1400.391479\n",
      "Train Epoch: 135 [20480/54000 (38%)] Loss: -1404.856445\n",
      "Train Epoch: 135 [24576/54000 (46%)] Loss: -1402.465332\n",
      "Train Epoch: 135 [28672/54000 (53%)] Loss: -1401.382080\n",
      "Train Epoch: 135 [32768/54000 (61%)] Loss: -1399.917847\n",
      "Train Epoch: 135 [36864/54000 (68%)] Loss: -1399.925537\n",
      "Train Epoch: 135 [40960/54000 (76%)] Loss: -1399.289551\n",
      "Train Epoch: 135 [45056/54000 (83%)] Loss: -1404.478027\n",
      "Train Epoch: 135 [49152/54000 (91%)] Loss: -1401.317871\n",
      "Train Epoch: 135 [53248/54000 (99%)] Loss: -1400.742676\n",
      "    epoch          : 135\n",
      "    loss           : -1401.4756137070497\n",
      "    ess            : 3.7956663081996247\n",
      "    log_marginal   : 1401.5837332919875\n",
      "    val_loss       : -1401.2637023925781\n",
      "    val_ess        : 3.806215782960256\n",
      "    val_log_marginal: 1401.364985148112\n",
      "Train Epoch: 136 [0/54000 (0%)] Loss: -1406.450195\n",
      "Train Epoch: 136 [4096/54000 (8%)] Loss: -1398.495605\n",
      "Train Epoch: 136 [8192/54000 (15%)] Loss: -1412.300049\n",
      "Train Epoch: 136 [12288/54000 (23%)] Loss: -1404.381348\n",
      "Train Epoch: 136 [16384/54000 (30%)] Loss: -1400.778931\n",
      "Train Epoch: 136 [20480/54000 (38%)] Loss: -1404.415771\n",
      "Train Epoch: 136 [24576/54000 (46%)] Loss: -1402.447021\n",
      "Train Epoch: 136 [28672/54000 (53%)] Loss: -1404.224609\n",
      "Train Epoch: 136 [32768/54000 (61%)] Loss: -1403.450562\n",
      "Train Epoch: 136 [36864/54000 (68%)] Loss: -1401.307617\n",
      "Train Epoch: 136 [40960/54000 (76%)] Loss: -1401.363037\n",
      "Train Epoch: 136 [45056/54000 (83%)] Loss: -1402.748779\n",
      "Train Epoch: 136 [49152/54000 (91%)] Loss: -1406.418213\n",
      "Train Epoch: 136 [53248/54000 (99%)] Loss: -1408.223877\n",
      "    epoch          : 136\n",
      "    loss           : -1402.3433652760293\n",
      "    ess            : 3.792169586742094\n",
      "    log_marginal   : 1402.4518065249185\n",
      "    val_loss       : -1401.5801900227864\n",
      "    val_ess        : 3.7946514586607614\n",
      "    val_log_marginal: 1401.6876729329426\n",
      "Train Epoch: 137 [0/54000 (0%)] Loss: -1403.823486\n",
      "Train Epoch: 137 [4096/54000 (8%)] Loss: -1396.541626\n",
      "Train Epoch: 137 [8192/54000 (15%)] Loss: -1404.892212\n",
      "Train Epoch: 137 [12288/54000 (23%)] Loss: -1408.566406\n",
      "Train Epoch: 137 [16384/54000 (30%)] Loss: -1400.335327\n",
      "Train Epoch: 137 [20480/54000 (38%)] Loss: -1405.370850\n",
      "Train Epoch: 137 [24576/54000 (46%)] Loss: -1404.764160\n",
      "Train Epoch: 137 [28672/54000 (53%)] Loss: -1399.190430\n",
      "Train Epoch: 137 [32768/54000 (61%)] Loss: -1399.978271\n",
      "Train Epoch: 137 [36864/54000 (68%)] Loss: -1398.444824\n",
      "Train Epoch: 137 [40960/54000 (76%)] Loss: -1400.912842\n",
      "Train Epoch: 137 [45056/54000 (83%)] Loss: -1401.593018\n",
      "Train Epoch: 137 [49152/54000 (91%)] Loss: -1404.775635\n",
      "Train Epoch: 137 [53248/54000 (99%)] Loss: -1405.044922\n",
      "    epoch          : 137\n",
      "    loss           : -1403.5281583234598\n",
      "    ess            : 3.7933599700294964\n",
      "    log_marginal   : 1403.6363866724673\n",
      "    val_loss       : -1402.720494588216\n",
      "    val_ess        : 3.7744563023249307\n",
      "    val_log_marginal: 1402.8355509440105\n",
      "Train Epoch: 138 [0/54000 (0%)] Loss: -1405.020020\n",
      "Train Epoch: 138 [4096/54000 (8%)] Loss: -1402.040771\n",
      "Train Epoch: 138 [8192/54000 (15%)] Loss: -1405.659546\n",
      "Train Epoch: 138 [12288/54000 (23%)] Loss: -1400.753052\n",
      "Train Epoch: 138 [16384/54000 (30%)] Loss: -1410.465454\n",
      "Train Epoch: 138 [20480/54000 (38%)] Loss: -1398.885498\n",
      "Train Epoch: 138 [24576/54000 (46%)] Loss: -1403.251709\n",
      "Train Epoch: 138 [28672/54000 (53%)] Loss: -1398.590332\n",
      "Train Epoch: 138 [32768/54000 (61%)] Loss: -1406.309814\n",
      "Train Epoch: 138 [36864/54000 (68%)] Loss: -1404.446289\n",
      "Train Epoch: 138 [40960/54000 (76%)] Loss: -1403.522827\n",
      "Train Epoch: 138 [45056/54000 (83%)] Loss: -1406.146240\n",
      "Train Epoch: 138 [49152/54000 (91%)] Loss: -1403.149292\n",
      "Train Epoch: 138 [53248/54000 (99%)] Loss: -1403.875488\n",
      "    epoch          : 138\n",
      "    loss           : -1404.6722446821311\n",
      "    ess            : 3.7925580734325246\n",
      "    log_marginal   : 1404.7830272511849\n",
      "    val_loss       : -1404.2788645426433\n",
      "    val_ess        : 3.790339628855387\n",
      "    val_log_marginal: 1404.3943379720051\n",
      "Train Epoch: 139 [0/54000 (0%)] Loss: -1400.605591\n",
      "Train Epoch: 139 [4096/54000 (8%)] Loss: -1408.393555\n",
      "Train Epoch: 139 [8192/54000 (15%)] Loss: -1410.850342\n",
      "Train Epoch: 139 [12288/54000 (23%)] Loss: -1409.305176\n",
      "Train Epoch: 139 [16384/54000 (30%)] Loss: -1402.250854\n",
      "Train Epoch: 139 [20480/54000 (38%)] Loss: -1409.650635\n",
      "Train Epoch: 139 [24576/54000 (46%)] Loss: -1405.630859\n",
      "Train Epoch: 139 [28672/54000 (53%)] Loss: -1409.138306\n",
      "Train Epoch: 139 [32768/54000 (61%)] Loss: -1405.385620\n",
      "Train Epoch: 139 [36864/54000 (68%)] Loss: -1402.551270\n",
      "Train Epoch: 139 [40960/54000 (76%)] Loss: -1407.752441\n",
      "Train Epoch: 139 [45056/54000 (83%)] Loss: -1406.099121\n",
      "Train Epoch: 139 [49152/54000 (91%)] Loss: -1399.967529\n",
      "Train Epoch: 139 [53248/54000 (99%)] Loss: -1409.406128\n",
      "    epoch          : 139\n",
      "    loss           : -1405.9761656268513\n",
      "    ess            : 3.7923991047375574\n",
      "    log_marginal   : 1406.084476705976\n",
      "    val_loss       : -1406.0858510335286\n",
      "    val_ess        : 3.804119110107422\n",
      "    val_log_marginal: 1406.1891174316406\n",
      "Train Epoch: 140 [0/54000 (0%)] Loss: -1409.943848\n",
      "Train Epoch: 140 [4096/54000 (8%)] Loss: -1397.530273\n",
      "Train Epoch: 140 [8192/54000 (15%)] Loss: -1411.379272\n",
      "Train Epoch: 140 [12288/54000 (23%)] Loss: -1411.395264\n",
      "Train Epoch: 140 [16384/54000 (30%)] Loss: -1409.466309\n",
      "Train Epoch: 140 [20480/54000 (38%)] Loss: -1398.041748\n",
      "Train Epoch: 140 [24576/54000 (46%)] Loss: -1406.185181\n",
      "Train Epoch: 140 [28672/54000 (53%)] Loss: -1401.133057\n",
      "Train Epoch: 140 [32768/54000 (61%)] Loss: -1403.046875\n",
      "Train Epoch: 140 [36864/54000 (68%)] Loss: -1404.045776\n",
      "Train Epoch: 140 [40960/54000 (76%)] Loss: -1405.982422\n",
      "Train Epoch: 140 [45056/54000 (83%)] Loss: -1414.152954\n",
      "Train Epoch: 140 [49152/54000 (91%)] Loss: -1403.057251\n",
      "Train Epoch: 140 [53248/54000 (99%)] Loss: -1403.463623\n",
      "    epoch          : 140\n",
      "    loss           : -1407.0755800364707\n",
      "    ess            : 3.7924149160701517\n",
      "    log_marginal   : 1407.1833449811168\n",
      "    val_loss       : -1406.2778218587239\n",
      "    val_ess        : 3.785748819510142\n",
      "    val_log_marginal: 1406.3905131022136\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch140.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 141 [0/54000 (0%)] Loss: -1402.655762\n",
      "Train Epoch: 141 [4096/54000 (8%)] Loss: -1416.359131\n",
      "Train Epoch: 141 [8192/54000 (15%)] Loss: -1417.477783\n",
      "Train Epoch: 141 [12288/54000 (23%)] Loss: -1413.843506\n",
      "Train Epoch: 141 [16384/54000 (30%)] Loss: -1415.028076\n",
      "Train Epoch: 141 [20480/54000 (38%)] Loss: -1410.677002\n",
      "Train Epoch: 141 [24576/54000 (46%)] Loss: -1409.000244\n",
      "Train Epoch: 141 [28672/54000 (53%)] Loss: -1402.978760\n",
      "Train Epoch: 141 [32768/54000 (61%)] Loss: -1407.795044\n",
      "Train Epoch: 141 [36864/54000 (68%)] Loss: -1410.913574\n",
      "Train Epoch: 141 [40960/54000 (76%)] Loss: -1398.771606\n",
      "Train Epoch: 141 [45056/54000 (83%)] Loss: -1408.145020\n",
      "Train Epoch: 141 [49152/54000 (91%)] Loss: -1413.765137\n",
      "Train Epoch: 141 [53248/54000 (99%)] Loss: -1406.480957\n",
      "    epoch          : 141\n",
      "    loss           : -1408.4365367437426\n",
      "    ess            : 3.789963577595932\n",
      "    log_marginal   : 1408.5480060306206\n",
      "    val_loss       : -1407.9435119628906\n",
      "    val_ess        : 3.7873409191767373\n",
      "    val_log_marginal: 1408.057581583659\n",
      "Train Epoch: 142 [0/54000 (0%)] Loss: -1405.369751\n",
      "Train Epoch: 142 [4096/54000 (8%)] Loss: -1411.625977\n",
      "Train Epoch: 142 [8192/54000 (15%)] Loss: -1415.474609\n",
      "Train Epoch: 142 [12288/54000 (23%)] Loss: -1407.617920\n",
      "Train Epoch: 142 [16384/54000 (30%)] Loss: -1414.849854\n",
      "Train Epoch: 142 [20480/54000 (38%)] Loss: -1412.171631\n",
      "Train Epoch: 142 [24576/54000 (46%)] Loss: -1412.980225\n",
      "Train Epoch: 142 [28672/54000 (53%)] Loss: -1404.570679\n",
      "Train Epoch: 142 [32768/54000 (61%)] Loss: -1417.803223\n",
      "Train Epoch: 142 [36864/54000 (68%)] Loss: -1414.028320\n",
      "Train Epoch: 142 [40960/54000 (76%)] Loss: -1410.733887\n",
      "Train Epoch: 142 [45056/54000 (83%)] Loss: -1410.856201\n",
      "Train Epoch: 142 [49152/54000 (91%)] Loss: -1406.877563\n",
      "Train Epoch: 142 [53248/54000 (99%)] Loss: -1412.839844\n",
      "    epoch          : 142\n",
      "    loss           : -1409.6276409998889\n",
      "    ess            : 3.7916855902468423\n",
      "    log_marginal   : 1409.7360006757258\n",
      "    val_loss       : -1408.7927958170574\n",
      "    val_ess        : 3.797729402780533\n",
      "    val_log_marginal: 1408.9017181396484\n",
      "Train Epoch: 143 [0/54000 (0%)] Loss: -1414.588867\n",
      "Train Epoch: 143 [4096/54000 (8%)] Loss: -1411.959717\n",
      "Train Epoch: 143 [8192/54000 (15%)] Loss: -1416.746216\n",
      "Train Epoch: 143 [12288/54000 (23%)] Loss: -1415.162598\n",
      "Train Epoch: 143 [16384/54000 (30%)] Loss: -1411.675537\n",
      "Train Epoch: 143 [20480/54000 (38%)] Loss: -1411.780884\n",
      "Train Epoch: 143 [24576/54000 (46%)] Loss: -1410.272949\n",
      "Train Epoch: 143 [28672/54000 (53%)] Loss: -1408.322754\n",
      "Train Epoch: 143 [32768/54000 (61%)] Loss: -1404.534912\n",
      "Train Epoch: 143 [36864/54000 (68%)] Loss: -1407.091553\n",
      "Train Epoch: 143 [40960/54000 (76%)] Loss: -1401.515625\n",
      "Train Epoch: 143 [45056/54000 (83%)] Loss: -1409.002319\n",
      "Train Epoch: 143 [49152/54000 (91%)] Loss: -1408.240723\n",
      "Train Epoch: 143 [53248/54000 (99%)] Loss: -1410.792358\n",
      "    epoch          : 143\n",
      "    loss           : -1410.8883513681133\n",
      "    ess            : 3.788527905658523\n",
      "    log_marginal   : 1411.0018767587383\n",
      "    val_loss       : -1410.6668395996094\n",
      "    val_ess        : 3.784193923075994\n",
      "    val_log_marginal: 1410.7830607096355\n",
      "Train Epoch: 144 [0/54000 (0%)] Loss: -1412.675171\n",
      "Train Epoch: 144 [4096/54000 (8%)] Loss: -1417.889648\n",
      "Train Epoch: 144 [8192/54000 (15%)] Loss: -1411.438232\n",
      "Train Epoch: 144 [12288/54000 (23%)] Loss: -1411.026611\n",
      "Train Epoch: 144 [16384/54000 (30%)] Loss: -1407.727783\n",
      "Train Epoch: 144 [20480/54000 (38%)] Loss: -1413.557495\n",
      "Train Epoch: 144 [24576/54000 (46%)] Loss: -1407.609619\n",
      "Train Epoch: 144 [28672/54000 (53%)] Loss: -1411.723877\n",
      "Train Epoch: 144 [32768/54000 (61%)] Loss: -1415.756836\n",
      "Train Epoch: 144 [36864/54000 (68%)] Loss: -1408.391113\n",
      "Train Epoch: 144 [40960/54000 (76%)] Loss: -1414.022705\n",
      "Train Epoch: 144 [45056/54000 (83%)] Loss: -1412.912842\n",
      "Train Epoch: 144 [49152/54000 (91%)] Loss: -1411.965820\n",
      "Train Epoch: 144 [53248/54000 (99%)] Loss: -1404.770508\n",
      "    epoch          : 144\n",
      "    loss           : -1412.242080471527\n",
      "    ess            : 3.79155992331663\n",
      "    log_marginal   : 1412.352484680465\n",
      "    val_loss       : -1410.8978271484375\n",
      "    val_ess        : 3.7969077229499817\n",
      "    val_log_marginal: 1411.0091807047527\n",
      "Train Epoch: 145 [0/54000 (0%)] Loss: -1415.997314\n",
      "Train Epoch: 145 [4096/54000 (8%)] Loss: -1417.052490\n",
      "Train Epoch: 145 [8192/54000 (15%)] Loss: -1411.012695\n",
      "Train Epoch: 145 [12288/54000 (23%)] Loss: -1409.024292\n",
      "Train Epoch: 145 [16384/54000 (30%)] Loss: -1412.075928\n",
      "Train Epoch: 145 [20480/54000 (38%)] Loss: -1418.378418\n",
      "Train Epoch: 145 [24576/54000 (46%)] Loss: -1410.152954\n",
      "Train Epoch: 145 [28672/54000 (53%)] Loss: -1415.983032\n",
      "Train Epoch: 145 [32768/54000 (61%)] Loss: -1406.484985\n",
      "Train Epoch: 145 [36864/54000 (68%)] Loss: -1418.936035\n",
      "Train Epoch: 145 [40960/54000 (76%)] Loss: -1421.932617\n",
      "Train Epoch: 145 [45056/54000 (83%)] Loss: -1420.145508\n",
      "Train Epoch: 145 [49152/54000 (91%)] Loss: -1415.265381\n",
      "Train Epoch: 145 [53248/54000 (99%)] Loss: -1419.259033\n",
      "    epoch          : 145\n",
      "    loss           : -1413.3751758738151\n",
      "    ess            : 3.786883724809258\n",
      "    log_marginal   : 1413.4912630054057\n",
      "    val_loss       : -1412.6726735432942\n",
      "    val_ess        : 3.7852553029855094\n",
      "    val_log_marginal: 1412.78759765625\n",
      "Train Epoch: 146 [0/54000 (0%)] Loss: -1416.607910\n",
      "Train Epoch: 146 [4096/54000 (8%)] Loss: -1415.340088\n",
      "Train Epoch: 146 [8192/54000 (15%)] Loss: -1411.151489\n",
      "Train Epoch: 146 [12288/54000 (23%)] Loss: -1415.582153\n",
      "Train Epoch: 146 [16384/54000 (30%)] Loss: -1418.129150\n",
      "Train Epoch: 146 [20480/54000 (38%)] Loss: -1414.087646\n",
      "Train Epoch: 146 [24576/54000 (46%)] Loss: -1408.995605\n",
      "Train Epoch: 146 [28672/54000 (53%)] Loss: -1414.824097\n",
      "Train Epoch: 146 [32768/54000 (61%)] Loss: -1414.758789\n",
      "Train Epoch: 146 [36864/54000 (68%)] Loss: -1415.751465\n",
      "Train Epoch: 146 [40960/54000 (76%)] Loss: -1419.796021\n",
      "Train Epoch: 146 [45056/54000 (83%)] Loss: -1416.237183\n",
      "Train Epoch: 146 [49152/54000 (91%)] Loss: -1415.677002\n",
      "Train Epoch: 146 [53248/54000 (99%)] Loss: -1410.134644\n",
      "    epoch          : 146\n",
      "    loss           : -1414.6200188370112\n",
      "    ess            : 3.789957705267233\n",
      "    log_marginal   : 1414.7324160896771\n",
      "    val_loss       : -1414.4192606608074\n",
      "    val_ess        : 3.7980181872844696\n",
      "    val_log_marginal: 1414.526870727539\n",
      "Train Epoch: 147 [0/54000 (0%)] Loss: -1414.588623\n",
      "Train Epoch: 147 [4096/54000 (8%)] Loss: -1413.299927\n",
      "Train Epoch: 147 [8192/54000 (15%)] Loss: -1419.072144\n",
      "Train Epoch: 147 [12288/54000 (23%)] Loss: -1413.561523\n",
      "Train Epoch: 147 [16384/54000 (30%)] Loss: -1420.048340\n",
      "Train Epoch: 147 [20480/54000 (38%)] Loss: -1417.234619\n",
      "Train Epoch: 147 [24576/54000 (46%)] Loss: -1414.611572\n",
      "Train Epoch: 147 [28672/54000 (53%)] Loss: -1418.108154\n",
      "Train Epoch: 147 [32768/54000 (61%)] Loss: -1416.835938\n",
      "Train Epoch: 147 [36864/54000 (68%)] Loss: -1414.512451\n",
      "Train Epoch: 147 [40960/54000 (76%)] Loss: -1410.057251\n",
      "Train Epoch: 147 [45056/54000 (83%)] Loss: -1413.634033\n",
      "Train Epoch: 147 [49152/54000 (91%)] Loss: -1417.521240\n",
      "Train Epoch: 147 [53248/54000 (99%)] Loss: -1417.937256\n",
      "    epoch          : 147\n",
      "    loss           : -1415.6699473304207\n",
      "    ess            : 3.785710378845721\n",
      "    log_marginal   : 1415.7855346101155\n",
      "    val_loss       : -1416.1122792561848\n",
      "    val_ess        : 3.786256810029348\n",
      "    val_log_marginal: 1416.2247924804688\n",
      "Train Epoch: 148 [0/54000 (0%)] Loss: -1414.913818\n",
      "Train Epoch: 148 [4096/54000 (8%)] Loss: -1418.678101\n",
      "Train Epoch: 148 [8192/54000 (15%)] Loss: -1416.207031\n",
      "Train Epoch: 148 [12288/54000 (23%)] Loss: -1415.399780\n",
      "Train Epoch: 148 [16384/54000 (30%)] Loss: -1412.745850\n",
      "Train Epoch: 148 [20480/54000 (38%)] Loss: -1422.625366\n",
      "Train Epoch: 148 [24576/54000 (46%)] Loss: -1420.150391\n",
      "Train Epoch: 148 [28672/54000 (53%)] Loss: -1421.640137\n",
      "Train Epoch: 148 [32768/54000 (61%)] Loss: -1415.500977\n",
      "Train Epoch: 148 [36864/54000 (68%)] Loss: -1417.089844\n",
      "Train Epoch: 148 [40960/54000 (76%)] Loss: -1414.607788\n",
      "Train Epoch: 148 [45056/54000 (83%)] Loss: -1419.669678\n",
      "Train Epoch: 148 [49152/54000 (91%)] Loss: -1419.698975\n",
      "Train Epoch: 148 [53248/54000 (99%)] Loss: -1420.228516\n",
      "    epoch          : 148\n",
      "    loss           : -1417.0084575634996\n",
      "    ess            : 3.7877844069241347\n",
      "    log_marginal   : 1417.1228455457642\n",
      "    val_loss       : -1417.5100351969402\n",
      "    val_ess        : 3.7782660325368247\n",
      "    val_log_marginal: 1417.6348622639973\n",
      "Train Epoch: 149 [0/54000 (0%)] Loss: -1411.624756\n",
      "Train Epoch: 149 [4096/54000 (8%)] Loss: -1419.865234\n",
      "Train Epoch: 149 [8192/54000 (15%)] Loss: -1416.785400\n",
      "Train Epoch: 149 [12288/54000 (23%)] Loss: -1420.739502\n",
      "Train Epoch: 149 [16384/54000 (30%)] Loss: -1416.959473\n",
      "Train Epoch: 149 [20480/54000 (38%)] Loss: -1426.875244\n",
      "Train Epoch: 149 [24576/54000 (46%)] Loss: -1420.661621\n",
      "Train Epoch: 149 [28672/54000 (53%)] Loss: -1417.939575\n",
      "Train Epoch: 149 [32768/54000 (61%)] Loss: -1412.544678\n",
      "Train Epoch: 149 [36864/54000 (68%)] Loss: -1422.544800\n",
      "Train Epoch: 149 [40960/54000 (76%)] Loss: -1421.292236\n",
      "Train Epoch: 149 [45056/54000 (83%)] Loss: -1424.719360\n",
      "Train Epoch: 149 [49152/54000 (91%)] Loss: -1421.990723\n",
      "Train Epoch: 149 [53248/54000 (99%)] Loss: -1412.588989\n",
      "    epoch          : 149\n",
      "    loss           : -1418.401711992743\n",
      "    ess            : 3.784182974512543\n",
      "    log_marginal   : 1418.5184482375591\n",
      "    val_loss       : -1418.6641896565754\n",
      "    val_ess        : 3.782076140244802\n",
      "    val_log_marginal: 1418.7851257324219\n",
      "Train Epoch: 150 [0/54000 (0%)] Loss: -1414.600342\n",
      "Train Epoch: 150 [4096/54000 (8%)] Loss: -1418.706787\n",
      "Train Epoch: 150 [8192/54000 (15%)] Loss: -1418.281738\n",
      "Train Epoch: 150 [12288/54000 (23%)] Loss: -1414.597046\n",
      "Train Epoch: 150 [16384/54000 (30%)] Loss: -1418.301514\n",
      "Train Epoch: 150 [20480/54000 (38%)] Loss: -1423.021240\n",
      "Train Epoch: 150 [24576/54000 (46%)] Loss: -1415.306396\n",
      "Train Epoch: 150 [28672/54000 (53%)] Loss: -1419.070312\n",
      "Train Epoch: 150 [32768/54000 (61%)] Loss: -1417.385010\n",
      "Train Epoch: 150 [36864/54000 (68%)] Loss: -1418.954590\n",
      "Train Epoch: 150 [40960/54000 (76%)] Loss: -1418.385986\n",
      "Train Epoch: 150 [45056/54000 (83%)] Loss: -1408.502197\n",
      "Train Epoch: 150 [49152/54000 (91%)] Loss: -1421.003174\n",
      "Train Epoch: 150 [53248/54000 (99%)] Loss: -1421.881348\n",
      "    epoch          : 150\n",
      "    loss           : -1419.2247551651362\n",
      "    ess            : 3.784247704591796\n",
      "    log_marginal   : 1419.3402325236966\n",
      "    val_loss       : -1419.656753540039\n",
      "    val_ess        : 3.79901984333992\n",
      "    val_log_marginal: 1419.7599182128906\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch150.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 151 [0/54000 (0%)] Loss: -1420.467651\n",
      "Train Epoch: 151 [4096/54000 (8%)] Loss: -1423.993896\n",
      "Train Epoch: 151 [8192/54000 (15%)] Loss: -1420.402466\n",
      "Train Epoch: 151 [12288/54000 (23%)] Loss: -1419.131592\n",
      "Train Epoch: 151 [16384/54000 (30%)] Loss: -1419.479004\n",
      "Train Epoch: 151 [20480/54000 (38%)] Loss: -1420.968506\n",
      "Train Epoch: 151 [24576/54000 (46%)] Loss: -1414.888672\n",
      "Train Epoch: 151 [28672/54000 (53%)] Loss: -1423.246826\n",
      "Train Epoch: 151 [32768/54000 (61%)] Loss: -1414.441650\n",
      "Train Epoch: 151 [36864/54000 (68%)] Loss: -1424.341797\n",
      "Train Epoch: 151 [40960/54000 (76%)] Loss: -1416.056641\n",
      "Train Epoch: 151 [45056/54000 (83%)] Loss: -1415.366455\n",
      "Train Epoch: 151 [49152/54000 (91%)] Loss: -1424.071533\n",
      "Train Epoch: 151 [53248/54000 (99%)] Loss: -1421.580566\n",
      "    epoch          : 151\n",
      "    loss           : -1420.607857509812\n",
      "    ess            : 3.783368740036589\n",
      "    log_marginal   : 1420.726808376222\n",
      "    val_loss       : -1420.1571706136067\n",
      "    val_ess        : 3.7822925051053367\n",
      "    val_log_marginal: 1420.2726745605469\n",
      "Train Epoch: 152 [0/54000 (0%)] Loss: -1422.560303\n",
      "Train Epoch: 152 [4096/54000 (8%)] Loss: -1424.339233\n",
      "Train Epoch: 152 [8192/54000 (15%)] Loss: -1423.299072\n",
      "Train Epoch: 152 [12288/54000 (23%)] Loss: -1417.400391\n",
      "Train Epoch: 152 [16384/54000 (30%)] Loss: -1420.942627\n",
      "Train Epoch: 152 [20480/54000 (38%)] Loss: -1422.956787\n",
      "Train Epoch: 152 [24576/54000 (46%)] Loss: -1418.594727\n",
      "Train Epoch: 152 [28672/54000 (53%)] Loss: -1419.244995\n",
      "Train Epoch: 152 [32768/54000 (61%)] Loss: -1421.856934\n",
      "Train Epoch: 152 [36864/54000 (68%)] Loss: -1420.258789\n",
      "Train Epoch: 152 [40960/54000 (76%)] Loss: -1419.262939\n",
      "Train Epoch: 152 [45056/54000 (83%)] Loss: -1424.217407\n",
      "Train Epoch: 152 [49152/54000 (91%)] Loss: -1417.430908\n",
      "Train Epoch: 152 [53248/54000 (99%)] Loss: -1422.457031\n",
      "    epoch          : 152\n",
      "    loss           : -1421.7082878221267\n",
      "    ess            : 3.7824669415351906\n",
      "    log_marginal   : 1421.8297084428689\n",
      "    val_loss       : -1421.8365071614583\n",
      "    val_ess        : 3.7675399581591287\n",
      "    val_log_marginal: 1421.9683787027996\n",
      "Train Epoch: 153 [0/54000 (0%)] Loss: -1424.700439\n",
      "Train Epoch: 153 [4096/54000 (8%)] Loss: -1428.917480\n",
      "Train Epoch: 153 [8192/54000 (15%)] Loss: -1427.308350\n",
      "Train Epoch: 153 [12288/54000 (23%)] Loss: -1418.072510\n",
      "Train Epoch: 153 [16384/54000 (30%)] Loss: -1426.840576\n",
      "Train Epoch: 153 [20480/54000 (38%)] Loss: -1424.753174\n",
      "Train Epoch: 153 [24576/54000 (46%)] Loss: -1424.232666\n",
      "Train Epoch: 153 [28672/54000 (53%)] Loss: -1426.963257\n",
      "Train Epoch: 153 [32768/54000 (61%)] Loss: -1425.729736\n",
      "Train Epoch: 153 [36864/54000 (68%)] Loss: -1422.207153\n",
      "Train Epoch: 153 [40960/54000 (76%)] Loss: -1422.729492\n",
      "Train Epoch: 153 [45056/54000 (83%)] Loss: -1416.397461\n",
      "Train Epoch: 153 [49152/54000 (91%)] Loss: -1424.774048\n",
      "Train Epoch: 153 [53248/54000 (99%)] Loss: -1417.682617\n",
      "    epoch          : 153\n",
      "    loss           : -1422.8297558825163\n",
      "    ess            : 3.7796157570246836\n",
      "    log_marginal   : 1422.9513928743336\n",
      "    val_loss       : -1422.9497884114583\n",
      "    val_ess        : 3.7794276575247445\n",
      "    val_log_marginal: 1423.0758819580078\n",
      "Train Epoch: 154 [0/54000 (0%)] Loss: -1429.839233\n",
      "Train Epoch: 154 [4096/54000 (8%)] Loss: -1425.517334\n",
      "Train Epoch: 154 [8192/54000 (15%)] Loss: -1422.962158\n",
      "Train Epoch: 154 [12288/54000 (23%)] Loss: -1428.473267\n",
      "Train Epoch: 154 [16384/54000 (30%)] Loss: -1431.313965\n",
      "Train Epoch: 154 [20480/54000 (38%)] Loss: -1417.956543\n",
      "Train Epoch: 154 [24576/54000 (46%)] Loss: -1427.200928\n",
      "Train Epoch: 154 [28672/54000 (53%)] Loss: -1417.549927\n",
      "Train Epoch: 154 [32768/54000 (61%)] Loss: -1426.271484\n",
      "Train Epoch: 154 [36864/54000 (68%)] Loss: -1426.468262\n",
      "Train Epoch: 154 [40960/54000 (76%)] Loss: -1432.004272\n",
      "Train Epoch: 154 [45056/54000 (83%)] Loss: -1425.533691\n",
      "Train Epoch: 154 [49152/54000 (91%)] Loss: -1421.873413\n",
      "Train Epoch: 154 [53248/54000 (99%)] Loss: -1422.261719\n",
      "    epoch          : 154\n",
      "    loss           : -1423.9311430872335\n",
      "    ess            : 3.7817292168242105\n",
      "    log_marginal   : 1424.0513458975117\n",
      "    val_loss       : -1423.7464904785156\n",
      "    val_ess        : 3.7878613273302713\n",
      "    val_log_marginal: 1423.858154296875\n",
      "Train Epoch: 155 [0/54000 (0%)] Loss: -1423.934570\n",
      "Train Epoch: 155 [4096/54000 (8%)] Loss: -1427.983154\n",
      "Train Epoch: 155 [8192/54000 (15%)] Loss: -1424.467041\n",
      "Train Epoch: 155 [12288/54000 (23%)] Loss: -1421.328247\n",
      "Train Epoch: 155 [16384/54000 (30%)] Loss: -1427.621826\n",
      "Train Epoch: 155 [20480/54000 (38%)] Loss: -1427.283203\n",
      "Train Epoch: 155 [24576/54000 (46%)] Loss: -1432.442993\n",
      "Train Epoch: 155 [28672/54000 (53%)] Loss: -1432.195190\n",
      "Train Epoch: 155 [32768/54000 (61%)] Loss: -1422.634644\n",
      "Train Epoch: 155 [36864/54000 (68%)] Loss: -1420.189575\n",
      "Train Epoch: 155 [40960/54000 (76%)] Loss: -1416.039917\n",
      "Train Epoch: 155 [45056/54000 (83%)] Loss: -1430.050049\n",
      "Train Epoch: 155 [49152/54000 (91%)] Loss: -1429.693970\n",
      "Train Epoch: 155 [53248/54000 (99%)] Loss: -1425.160400\n",
      "    epoch          : 155\n",
      "    loss           : -1425.1517339769698\n",
      "    ess            : 3.7804661633279086\n",
      "    log_marginal   : 1425.2713247000888\n",
      "    val_loss       : -1424.9842274983723\n",
      "    val_ess        : 3.7858679989973703\n",
      "    val_log_marginal: 1425.1076914469402\n",
      "Train Epoch: 156 [0/54000 (0%)] Loss: -1426.132812\n",
      "Train Epoch: 156 [4096/54000 (8%)] Loss: -1426.698853\n",
      "Train Epoch: 156 [8192/54000 (15%)] Loss: -1423.633057\n",
      "Train Epoch: 156 [12288/54000 (23%)] Loss: -1426.143066\n",
      "Train Epoch: 156 [16384/54000 (30%)] Loss: -1422.785156\n",
      "Train Epoch: 156 [20480/54000 (38%)] Loss: -1428.776367\n",
      "Train Epoch: 156 [24576/54000 (46%)] Loss: -1424.517578\n",
      "Train Epoch: 156 [28672/54000 (53%)] Loss: -1423.825684\n",
      "Train Epoch: 156 [32768/54000 (61%)] Loss: -1426.781372\n",
      "Train Epoch: 156 [36864/54000 (68%)] Loss: -1433.846313\n",
      "Train Epoch: 156 [40960/54000 (76%)] Loss: -1434.876221\n",
      "Train Epoch: 156 [45056/54000 (83%)] Loss: -1425.043213\n",
      "Train Epoch: 156 [49152/54000 (91%)] Loss: -1426.031494\n",
      "Train Epoch: 156 [53248/54000 (99%)] Loss: -1423.953125\n",
      "    epoch          : 156\n",
      "    loss           : -1426.3359913035026\n",
      "    ess            : 3.782256387421305\n",
      "    log_marginal   : 1426.4544509960012\n",
      "    val_loss       : -1425.723409016927\n",
      "    val_ess        : 3.792114943265915\n",
      "    val_log_marginal: 1425.838399251302\n",
      "Train Epoch: 157 [0/54000 (0%)] Loss: -1423.512207\n",
      "Train Epoch: 157 [4096/54000 (8%)] Loss: -1433.056274\n",
      "Train Epoch: 157 [8192/54000 (15%)] Loss: -1418.995239\n",
      "Train Epoch: 157 [12288/54000 (23%)] Loss: -1423.505615\n",
      "Train Epoch: 157 [16384/54000 (30%)] Loss: -1434.839111\n",
      "Train Epoch: 157 [20480/54000 (38%)] Loss: -1424.202393\n",
      "Train Epoch: 157 [24576/54000 (46%)] Loss: -1429.486328\n",
      "Train Epoch: 157 [28672/54000 (53%)] Loss: -1429.817383\n",
      "Train Epoch: 157 [32768/54000 (61%)] Loss: -1428.386719\n",
      "Train Epoch: 157 [36864/54000 (68%)] Loss: -1432.290283\n",
      "Train Epoch: 157 [40960/54000 (76%)] Loss: -1428.358154\n",
      "Train Epoch: 157 [45056/54000 (83%)] Loss: -1422.169678\n",
      "Train Epoch: 157 [49152/54000 (91%)] Loss: -1429.318726\n",
      "Train Epoch: 157 [53248/54000 (99%)] Loss: -1426.819580\n",
      "    epoch          : 157\n",
      "    loss           : -1427.2266585363595\n",
      "    ess            : 3.780646499299325\n",
      "    log_marginal   : 1427.3468804382035\n",
      "    val_loss       : -1426.2353515625\n",
      "    val_ess        : 3.773628075917562\n",
      "    val_log_marginal: 1426.3583272298176\n",
      "Train Epoch: 158 [0/54000 (0%)] Loss: -1428.124512\n",
      "Train Epoch: 158 [4096/54000 (8%)] Loss: -1434.882812\n",
      "Train Epoch: 158 [8192/54000 (15%)] Loss: -1426.402588\n",
      "Train Epoch: 158 [12288/54000 (23%)] Loss: -1425.274658\n",
      "Train Epoch: 158 [16384/54000 (30%)] Loss: -1431.043335\n",
      "Train Epoch: 158 [20480/54000 (38%)] Loss: -1426.084229\n",
      "Train Epoch: 158 [24576/54000 (46%)] Loss: -1426.196289\n",
      "Train Epoch: 158 [28672/54000 (53%)] Loss: -1424.223389\n",
      "Train Epoch: 158 [32768/54000 (61%)] Loss: -1425.264771\n",
      "Train Epoch: 158 [36864/54000 (68%)] Loss: -1431.588501\n",
      "Train Epoch: 158 [40960/54000 (76%)] Loss: -1427.917969\n",
      "Train Epoch: 158 [45056/54000 (83%)] Loss: -1430.589600\n",
      "Train Epoch: 158 [49152/54000 (91%)] Loss: -1434.562378\n",
      "Train Epoch: 158 [53248/54000 (99%)] Loss: -1432.418213\n",
      "    epoch          : 158\n",
      "    loss           : -1428.5068961048578\n",
      "    ess            : 3.7746593986077333\n",
      "    log_marginal   : 1428.6346470258811\n",
      "    val_loss       : -1427.9500885009766\n",
      "    val_ess        : 3.786379406849543\n",
      "    val_log_marginal: 1428.064417521159\n",
      "Train Epoch: 159 [0/54000 (0%)] Loss: -1425.498535\n",
      "Train Epoch: 159 [4096/54000 (8%)] Loss: -1426.426514\n",
      "Train Epoch: 159 [8192/54000 (15%)] Loss: -1431.494385\n",
      "Train Epoch: 159 [12288/54000 (23%)] Loss: -1428.826782\n",
      "Train Epoch: 159 [16384/54000 (30%)] Loss: -1433.342896\n",
      "Train Epoch: 159 [20480/54000 (38%)] Loss: -1431.557373\n",
      "Train Epoch: 159 [24576/54000 (46%)] Loss: -1429.918945\n",
      "Train Epoch: 159 [28672/54000 (53%)] Loss: -1430.080200\n",
      "Train Epoch: 159 [32768/54000 (61%)] Loss: -1437.985596\n",
      "Train Epoch: 159 [36864/54000 (68%)] Loss: -1429.919434\n",
      "Train Epoch: 159 [40960/54000 (76%)] Loss: -1423.905762\n",
      "Train Epoch: 159 [45056/54000 (83%)] Loss: -1428.752686\n",
      "Train Epoch: 159 [49152/54000 (91%)] Loss: -1424.527588\n",
      "Train Epoch: 159 [53248/54000 (99%)] Loss: -1426.324829\n",
      "    epoch          : 159\n",
      "    loss           : -1429.4606013727414\n",
      "    ess            : 3.7805991624768875\n",
      "    log_marginal   : 1429.580840630554\n",
      "    val_loss       : -1430.3015034993489\n",
      "    val_ess        : 3.7934729556242623\n",
      "    val_log_marginal: 1430.4156138102214\n",
      "Train Epoch: 160 [0/54000 (0%)] Loss: -1426.966309\n",
      "Train Epoch: 160 [4096/54000 (8%)] Loss: -1432.484863\n",
      "Train Epoch: 160 [8192/54000 (15%)] Loss: -1423.540771\n",
      "Train Epoch: 160 [12288/54000 (23%)] Loss: -1438.334839\n",
      "Train Epoch: 160 [16384/54000 (30%)] Loss: -1431.979126\n",
      "Train Epoch: 160 [20480/54000 (38%)] Loss: -1431.464600\n",
      "Train Epoch: 160 [24576/54000 (46%)] Loss: -1434.853394\n",
      "Train Epoch: 160 [28672/54000 (53%)] Loss: -1433.861572\n",
      "Train Epoch: 160 [32768/54000 (61%)] Loss: -1423.072266\n",
      "Train Epoch: 160 [36864/54000 (68%)] Loss: -1431.019775\n",
      "Train Epoch: 160 [40960/54000 (76%)] Loss: -1429.564087\n",
      "Train Epoch: 160 [45056/54000 (83%)] Loss: -1428.005493\n",
      "Train Epoch: 160 [49152/54000 (91%)] Loss: -1430.135498\n",
      "Train Epoch: 160 [53248/54000 (99%)] Loss: -1435.988281\n",
      "    epoch          : 160\n",
      "    loss           : -1430.8828801882776\n",
      "    ess            : 3.779857357531362\n",
      "    log_marginal   : 1431.0066166737633\n",
      "    val_loss       : -1430.7750142415364\n",
      "    val_ess        : 3.77185266216596\n",
      "    val_log_marginal: 1430.8979237874348\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch160.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 161 [0/54000 (0%)] Loss: -1437.394775\n",
      "Train Epoch: 161 [4096/54000 (8%)] Loss: -1429.287354\n",
      "Train Epoch: 161 [8192/54000 (15%)] Loss: -1433.553467\n",
      "Train Epoch: 161 [12288/54000 (23%)] Loss: -1427.928101\n",
      "Train Epoch: 161 [16384/54000 (30%)] Loss: -1427.979492\n",
      "Train Epoch: 161 [20480/54000 (38%)] Loss: -1430.560181\n",
      "Train Epoch: 161 [24576/54000 (46%)] Loss: -1436.677490\n",
      "Train Epoch: 161 [28672/54000 (53%)] Loss: -1430.670654\n",
      "Train Epoch: 161 [32768/54000 (61%)] Loss: -1435.120728\n",
      "Train Epoch: 161 [36864/54000 (68%)] Loss: -1436.162231\n",
      "Train Epoch: 161 [40960/54000 (76%)] Loss: -1437.182617\n",
      "Train Epoch: 161 [45056/54000 (83%)] Loss: -1429.624023\n",
      "Train Epoch: 161 [49152/54000 (91%)] Loss: -1429.363159\n",
      "Train Epoch: 161 [53248/54000 (99%)] Loss: -1432.926025\n",
      "    epoch          : 161\n",
      "    loss           : -1431.9004878184242\n",
      "    ess            : 3.7784694992535486\n",
      "    log_marginal   : 1432.0254860828272\n",
      "    val_loss       : -1432.890172322591\n",
      "    val_ess        : 3.783151706059774\n",
      "    val_log_marginal: 1433.008544921875\n",
      "Train Epoch: 162 [0/54000 (0%)] Loss: -1440.910767\n",
      "Train Epoch: 162 [4096/54000 (8%)] Loss: -1431.973877\n",
      "Train Epoch: 162 [8192/54000 (15%)] Loss: -1436.352539\n",
      "Train Epoch: 162 [12288/54000 (23%)] Loss: -1431.488647\n",
      "Train Epoch: 162 [16384/54000 (30%)] Loss: -1433.074951\n",
      "Train Epoch: 162 [20480/54000 (38%)] Loss: -1427.527222\n",
      "Train Epoch: 162 [24576/54000 (46%)] Loss: -1432.393066\n",
      "Train Epoch: 162 [28672/54000 (53%)] Loss: -1434.544067\n",
      "Train Epoch: 162 [32768/54000 (61%)] Loss: -1436.837036\n",
      "Train Epoch: 162 [36864/54000 (68%)] Loss: -1433.600708\n",
      "Train Epoch: 162 [40960/54000 (76%)] Loss: -1434.712280\n",
      "Train Epoch: 162 [45056/54000 (83%)] Loss: -1431.878052\n",
      "Train Epoch: 162 [49152/54000 (91%)] Loss: -1434.696289\n",
      "Train Epoch: 162 [53248/54000 (99%)] Loss: -1430.692749\n",
      "    epoch          : 162\n",
      "    loss           : -1432.9539893272363\n",
      "    ess            : 3.7783724414228828\n",
      "    log_marginal   : 1433.0787012181577\n",
      "    val_loss       : -1433.9193725585938\n",
      "    val_ess        : 3.7657534082730613\n",
      "    val_log_marginal: 1434.0474395751953\n",
      "Train Epoch: 163 [0/54000 (0%)] Loss: -1432.531128\n",
      "Train Epoch: 163 [4096/54000 (8%)] Loss: -1433.624512\n",
      "Train Epoch: 163 [8192/54000 (15%)] Loss: -1431.659180\n",
      "Train Epoch: 163 [12288/54000 (23%)] Loss: -1430.425293\n",
      "Train Epoch: 163 [16384/54000 (30%)] Loss: -1439.188354\n",
      "Train Epoch: 163 [20480/54000 (38%)] Loss: -1439.358643\n",
      "Train Epoch: 163 [24576/54000 (46%)] Loss: -1431.846191\n",
      "Train Epoch: 163 [28672/54000 (53%)] Loss: -1432.752563\n",
      "Train Epoch: 163 [32768/54000 (61%)] Loss: -1432.640137\n",
      "Train Epoch: 163 [36864/54000 (68%)] Loss: -1431.423950\n",
      "Train Epoch: 163 [40960/54000 (76%)] Loss: -1434.804199\n",
      "Train Epoch: 163 [45056/54000 (83%)] Loss: -1437.210205\n",
      "Train Epoch: 163 [49152/54000 (91%)] Loss: -1441.299072\n",
      "Train Epoch: 163 [53248/54000 (99%)] Loss: -1436.243652\n",
      "    epoch          : 163\n",
      "    loss           : -1434.1278197663655\n",
      "    ess            : 3.7832960799972026\n",
      "    log_marginal   : 1434.2494417163432\n",
      "    val_loss       : -1433.5892893473308\n",
      "    val_ess        : 3.7918220857779183\n",
      "    val_log_marginal: 1433.7056986490886\n",
      "Train Epoch: 164 [0/54000 (0%)] Loss: -1440.684448\n",
      "Train Epoch: 164 [4096/54000 (8%)] Loss: -1441.996582\n",
      "Train Epoch: 164 [8192/54000 (15%)] Loss: -1436.662354\n",
      "Train Epoch: 164 [12288/54000 (23%)] Loss: -1431.907837\n",
      "Train Epoch: 164 [16384/54000 (30%)] Loss: -1435.145752\n",
      "Train Epoch: 164 [20480/54000 (38%)] Loss: -1433.770020\n",
      "Train Epoch: 164 [24576/54000 (46%)] Loss: -1430.014771\n",
      "Train Epoch: 164 [28672/54000 (53%)] Loss: -1432.426636\n",
      "Train Epoch: 164 [32768/54000 (61%)] Loss: -1440.458374\n",
      "Train Epoch: 164 [36864/54000 (68%)] Loss: -1436.484375\n",
      "Train Epoch: 164 [40960/54000 (76%)] Loss: -1435.483398\n",
      "Train Epoch: 164 [45056/54000 (83%)] Loss: -1437.005859\n",
      "Train Epoch: 164 [49152/54000 (91%)] Loss: -1434.162598\n",
      "Train Epoch: 164 [53248/54000 (99%)] Loss: -1435.331787\n",
      "    epoch          : 164\n",
      "    loss           : -1435.5841180159582\n",
      "    ess            : 3.7770585222831836\n",
      "    log_marginal   : 1435.707170676281\n",
      "    val_loss       : -1434.1917419433594\n",
      "    val_ess        : 3.7852363288402557\n",
      "    val_log_marginal: 1434.3104044596355\n",
      "Train Epoch: 165 [0/54000 (0%)] Loss: -1435.140869\n",
      "Train Epoch: 165 [4096/54000 (8%)] Loss: -1433.314209\n",
      "Train Epoch: 165 [8192/54000 (15%)] Loss: -1429.856567\n",
      "Train Epoch: 165 [12288/54000 (23%)] Loss: -1438.971558\n",
      "Train Epoch: 165 [16384/54000 (30%)] Loss: -1441.063721\n",
      "Train Epoch: 165 [20480/54000 (38%)] Loss: -1435.215942\n",
      "Train Epoch: 165 [24576/54000 (46%)] Loss: -1437.620117\n",
      "Train Epoch: 165 [28672/54000 (53%)] Loss: -1431.581909\n",
      "Train Epoch: 165 [32768/54000 (61%)] Loss: -1431.025635\n",
      "Train Epoch: 165 [36864/54000 (68%)] Loss: -1435.342407\n",
      "Train Epoch: 165 [40960/54000 (76%)] Loss: -1436.867065\n",
      "Train Epoch: 165 [45056/54000 (83%)] Loss: -1442.943726\n",
      "Train Epoch: 165 [49152/54000 (91%)] Loss: -1435.454590\n",
      "Train Epoch: 165 [53248/54000 (99%)] Loss: -1431.257202\n",
      "    epoch          : 165\n",
      "    loss           : -1436.442733981598\n",
      "    ess            : 3.774403897506931\n",
      "    log_marginal   : 1436.5702777880629\n",
      "    val_loss       : -1436.1419169108074\n",
      "    val_ess        : 3.7829083998998008\n",
      "    val_log_marginal: 1436.2566019694011\n",
      "Train Epoch: 166 [0/54000 (0%)] Loss: -1437.626831\n",
      "Train Epoch: 166 [4096/54000 (8%)] Loss: -1436.920898\n",
      "Train Epoch: 166 [8192/54000 (15%)] Loss: -1441.943237\n",
      "Train Epoch: 166 [12288/54000 (23%)] Loss: -1430.131714\n",
      "Train Epoch: 166 [16384/54000 (30%)] Loss: -1432.074707\n",
      "Train Epoch: 166 [20480/54000 (38%)] Loss: -1432.674683\n",
      "Train Epoch: 166 [24576/54000 (46%)] Loss: -1438.168579\n",
      "Train Epoch: 166 [28672/54000 (53%)] Loss: -1434.625244\n",
      "Train Epoch: 166 [32768/54000 (61%)] Loss: -1435.287109\n",
      "Train Epoch: 166 [36864/54000 (68%)] Loss: -1432.324829\n",
      "Train Epoch: 166 [40960/54000 (76%)] Loss: -1438.121582\n",
      "Train Epoch: 166 [45056/54000 (83%)] Loss: -1438.801025\n",
      "Train Epoch: 166 [49152/54000 (91%)] Loss: -1437.468750\n",
      "Train Epoch: 166 [53248/54000 (99%)] Loss: -1433.315674\n",
      "    epoch          : 166\n",
      "    loss           : -1437.1018685435797\n",
      "    ess            : 3.778649749349079\n",
      "    log_marginal   : 1437.2265353089824\n",
      "    val_loss       : -1437.739761352539\n",
      "    val_ess        : 3.7765860557556152\n",
      "    val_log_marginal: 1437.8655446370442\n",
      "Train Epoch: 167 [0/54000 (0%)] Loss: -1444.145264\n",
      "Train Epoch: 167 [4096/54000 (8%)] Loss: -1438.590088\n",
      "Train Epoch: 167 [8192/54000 (15%)] Loss: -1445.486206\n",
      "Train Epoch: 167 [12288/54000 (23%)] Loss: -1433.800903\n",
      "Train Epoch: 167 [16384/54000 (30%)] Loss: -1445.939331\n",
      "Train Epoch: 167 [20480/54000 (38%)] Loss: -1439.324829\n",
      "Train Epoch: 167 [24576/54000 (46%)] Loss: -1436.747559\n",
      "Train Epoch: 167 [28672/54000 (53%)] Loss: -1435.793091\n",
      "Train Epoch: 167 [32768/54000 (61%)] Loss: -1438.659546\n",
      "Train Epoch: 167 [36864/54000 (68%)] Loss: -1437.554077\n",
      "Train Epoch: 167 [40960/54000 (76%)] Loss: -1443.029541\n",
      "Train Epoch: 167 [45056/54000 (83%)] Loss: -1440.855835\n",
      "Train Epoch: 167 [49152/54000 (91%)] Loss: -1434.601440\n",
      "Train Epoch: 167 [53248/54000 (99%)] Loss: -1434.898193\n",
      "    epoch          : 167\n",
      "    loss           : -1438.215216903325\n",
      "    ess            : 3.776767505853662\n",
      "    log_marginal   : 1438.3419976257035\n",
      "    val_loss       : -1438.2242838541667\n",
      "    val_ess        : 3.767601360877355\n",
      "    val_log_marginal: 1438.3576253255208\n",
      "Train Epoch: 168 [0/54000 (0%)] Loss: -1439.353394\n",
      "Train Epoch: 168 [4096/54000 (8%)] Loss: -1434.480713\n",
      "Train Epoch: 168 [8192/54000 (15%)] Loss: -1439.148682\n",
      "Train Epoch: 168 [12288/54000 (23%)] Loss: -1444.442383\n",
      "Train Epoch: 168 [16384/54000 (30%)] Loss: -1441.153198\n",
      "Train Epoch: 168 [20480/54000 (38%)] Loss: -1441.294922\n",
      "Train Epoch: 168 [24576/54000 (46%)] Loss: -1434.279785\n",
      "Train Epoch: 168 [28672/54000 (53%)] Loss: -1437.456055\n",
      "Train Epoch: 168 [32768/54000 (61%)] Loss: -1431.782227\n",
      "Train Epoch: 168 [36864/54000 (68%)] Loss: -1439.270020\n",
      "Train Epoch: 168 [40960/54000 (76%)] Loss: -1444.510986\n",
      "Train Epoch: 168 [45056/54000 (83%)] Loss: -1434.109863\n",
      "Train Epoch: 168 [49152/54000 (91%)] Loss: -1433.385986\n",
      "Train Epoch: 168 [53248/54000 (99%)] Loss: -1439.921631\n",
      "    epoch          : 168\n",
      "    loss           : -1439.3256569812647\n",
      "    ess            : 3.774246585312613\n",
      "    log_marginal   : 1439.4546893513034\n",
      "    val_loss       : -1438.5492706298828\n",
      "    val_ess        : 3.7778770327568054\n",
      "    val_log_marginal: 1438.6846669514973\n",
      "Train Epoch: 169 [0/54000 (0%)] Loss: -1437.336426\n",
      "Train Epoch: 169 [4096/54000 (8%)] Loss: -1444.291138\n",
      "Train Epoch: 169 [8192/54000 (15%)] Loss: -1438.312866\n",
      "Train Epoch: 169 [12288/54000 (23%)] Loss: -1434.589233\n",
      "Train Epoch: 169 [16384/54000 (30%)] Loss: -1439.086182\n",
      "Train Epoch: 169 [20480/54000 (38%)] Loss: -1437.940918\n",
      "Train Epoch: 169 [24576/54000 (46%)] Loss: -1433.773071\n",
      "Train Epoch: 169 [28672/54000 (53%)] Loss: -1437.571289\n",
      "Train Epoch: 169 [32768/54000 (61%)] Loss: -1438.937378\n",
      "Train Epoch: 169 [36864/54000 (68%)] Loss: -1439.390747\n",
      "Train Epoch: 169 [40960/54000 (76%)] Loss: -1443.377441\n",
      "Train Epoch: 169 [45056/54000 (83%)] Loss: -1433.302734\n",
      "Train Epoch: 169 [49152/54000 (91%)] Loss: -1440.110229\n",
      "Train Epoch: 169 [53248/54000 (99%)] Loss: -1439.929199\n",
      "    epoch          : 169\n",
      "    loss           : -1440.3287498148698\n",
      "    ess            : 3.7762047939390935\n",
      "    log_marginal   : 1440.4574853978452\n",
      "    val_loss       : -1440.0091247558594\n",
      "    val_ess        : 3.7663344740867615\n",
      "    val_log_marginal: 1440.145736694336\n",
      "Train Epoch: 170 [0/54000 (0%)] Loss: -1449.058838\n",
      "Train Epoch: 170 [4096/54000 (8%)] Loss: -1442.350586\n",
      "Train Epoch: 170 [8192/54000 (15%)] Loss: -1440.670898\n",
      "Train Epoch: 170 [12288/54000 (23%)] Loss: -1437.592773\n",
      "Train Epoch: 170 [16384/54000 (30%)] Loss: -1436.514160\n",
      "Train Epoch: 170 [20480/54000 (38%)] Loss: -1442.175293\n",
      "Train Epoch: 170 [24576/54000 (46%)] Loss: -1442.391602\n",
      "Train Epoch: 170 [28672/54000 (53%)] Loss: -1435.832275\n",
      "Train Epoch: 170 [32768/54000 (61%)] Loss: -1441.455444\n",
      "Train Epoch: 170 [36864/54000 (68%)] Loss: -1441.882935\n",
      "Train Epoch: 170 [40960/54000 (76%)] Loss: -1444.366821\n",
      "Train Epoch: 170 [45056/54000 (83%)] Loss: -1442.955933\n",
      "Train Epoch: 170 [49152/54000 (91%)] Loss: -1443.810059\n",
      "Train Epoch: 170 [53248/54000 (99%)] Loss: -1440.716797\n",
      "    epoch          : 170\n",
      "    loss           : -1441.5062753397142\n",
      "    ess            : 3.7792863676333313\n",
      "    log_marginal   : 1441.6316270873444\n",
      "    val_loss       : -1440.5787200927734\n",
      "    val_ess        : 3.7575707832972207\n",
      "    val_log_marginal: 1440.7201639811199\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch170.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 171 [0/54000 (0%)] Loss: -1443.692505\n",
      "Train Epoch: 171 [4096/54000 (8%)] Loss: -1447.812988\n",
      "Train Epoch: 171 [8192/54000 (15%)] Loss: -1442.224854\n",
      "Train Epoch: 171 [12288/54000 (23%)] Loss: -1436.046143\n",
      "Train Epoch: 171 [16384/54000 (30%)] Loss: -1435.076172\n",
      "Train Epoch: 171 [20480/54000 (38%)] Loss: -1438.391357\n",
      "Train Epoch: 171 [24576/54000 (46%)] Loss: -1448.165649\n",
      "Train Epoch: 171 [28672/54000 (53%)] Loss: -1441.268799\n",
      "Train Epoch: 171 [32768/54000 (61%)] Loss: -1448.229736\n",
      "Train Epoch: 171 [36864/54000 (68%)] Loss: -1440.942383\n",
      "Train Epoch: 171 [40960/54000 (76%)] Loss: -1445.272217\n",
      "Train Epoch: 171 [45056/54000 (83%)] Loss: -1446.616211\n",
      "Train Epoch: 171 [49152/54000 (91%)] Loss: -1440.352905\n",
      "Train Epoch: 171 [53248/54000 (99%)] Loss: -1443.675415\n",
      "    epoch          : 171\n",
      "    loss           : -1442.5985026427354\n",
      "    ess            : 3.7698330348136864\n",
      "    log_marginal   : 1442.731031661915\n",
      "    val_loss       : -1441.8629964192708\n",
      "    val_ess        : 3.778472810983658\n",
      "    val_log_marginal: 1441.9825744628906\n",
      "Train Epoch: 172 [0/54000 (0%)] Loss: -1440.529541\n",
      "Train Epoch: 172 [4096/54000 (8%)] Loss: -1438.833740\n",
      "Train Epoch: 172 [8192/54000 (15%)] Loss: -1443.084351\n",
      "Train Epoch: 172 [12288/54000 (23%)] Loss: -1444.564941\n",
      "Train Epoch: 172 [16384/54000 (30%)] Loss: -1441.440186\n",
      "Train Epoch: 172 [20480/54000 (38%)] Loss: -1442.126465\n",
      "Train Epoch: 172 [24576/54000 (46%)] Loss: -1443.768433\n",
      "Train Epoch: 172 [28672/54000 (53%)] Loss: -1446.638550\n",
      "Train Epoch: 172 [32768/54000 (61%)] Loss: -1447.611084\n",
      "Train Epoch: 172 [36864/54000 (68%)] Loss: -1450.303833\n",
      "Train Epoch: 172 [40960/54000 (76%)] Loss: -1440.763916\n",
      "Train Epoch: 172 [45056/54000 (83%)] Loss: -1446.912231\n",
      "Train Epoch: 172 [49152/54000 (91%)] Loss: -1443.041504\n",
      "Train Epoch: 172 [53248/54000 (99%)] Loss: -1445.297119\n",
      "    epoch          : 172\n",
      "    loss           : -1443.288228834975\n",
      "    ess            : 3.775425016032576\n",
      "    log_marginal   : 1443.4189065508367\n",
      "    val_loss       : -1442.9740142822266\n",
      "    val_ess        : 3.765972743431727\n",
      "    val_log_marginal: 1443.1048075358074\n",
      "Train Epoch: 173 [0/54000 (0%)] Loss: -1440.477295\n",
      "Train Epoch: 173 [4096/54000 (8%)] Loss: -1451.927368\n",
      "Train Epoch: 173 [8192/54000 (15%)] Loss: -1442.285767\n",
      "Train Epoch: 173 [12288/54000 (23%)] Loss: -1448.799805\n",
      "Train Epoch: 173 [16384/54000 (30%)] Loss: -1447.898315\n",
      "Train Epoch: 173 [20480/54000 (38%)] Loss: -1445.763184\n",
      "Train Epoch: 173 [24576/54000 (46%)] Loss: -1447.722168\n",
      "Train Epoch: 173 [28672/54000 (53%)] Loss: -1447.580200\n",
      "Train Epoch: 173 [32768/54000 (61%)] Loss: -1442.840942\n",
      "Train Epoch: 173 [36864/54000 (68%)] Loss: -1441.648804\n",
      "Train Epoch: 173 [40960/54000 (76%)] Loss: -1436.803833\n",
      "Train Epoch: 173 [45056/54000 (83%)] Loss: -1445.615601\n",
      "Train Epoch: 173 [49152/54000 (91%)] Loss: -1448.627197\n",
      "Train Epoch: 173 [53248/54000 (99%)] Loss: -1447.964844\n",
      "    epoch          : 173\n",
      "    loss           : -1444.4762767050504\n",
      "    ess            : 3.774467482951015\n",
      "    log_marginal   : 1444.6057134691573\n",
      "    val_loss       : -1444.0674133300781\n",
      "    val_ess        : 3.788590004046758\n",
      "    val_log_marginal: 1444.1914723714192\n",
      "Train Epoch: 174 [0/54000 (0%)] Loss: -1440.808350\n",
      "Train Epoch: 174 [4096/54000 (8%)] Loss: -1445.428711\n",
      "Train Epoch: 174 [8192/54000 (15%)] Loss: -1442.829834\n",
      "Train Epoch: 174 [12288/54000 (23%)] Loss: -1442.752686\n",
      "Train Epoch: 174 [16384/54000 (30%)] Loss: -1437.625977\n",
      "Train Epoch: 174 [20480/54000 (38%)] Loss: -1446.975220\n",
      "Train Epoch: 174 [24576/54000 (46%)] Loss: -1447.011108\n",
      "Train Epoch: 174 [28672/54000 (53%)] Loss: -1446.320557\n",
      "Train Epoch: 174 [32768/54000 (61%)] Loss: -1447.429932\n",
      "Train Epoch: 174 [36864/54000 (68%)] Loss: -1453.394775\n",
      "Train Epoch: 174 [40960/54000 (76%)] Loss: -1446.819580\n",
      "Train Epoch: 174 [45056/54000 (83%)] Loss: -1440.068970\n",
      "Train Epoch: 174 [49152/54000 (91%)] Loss: -1441.864868\n",
      "Train Epoch: 174 [53248/54000 (99%)] Loss: -1446.294922\n",
      "    epoch          : 174\n",
      "    loss           : -1445.5943962205642\n",
      "    ess            : 3.7792898738553737\n",
      "    log_marginal   : 1445.7189096749112\n",
      "    val_loss       : -1444.7199452718098\n",
      "    val_ess        : 3.785038193066915\n",
      "    val_log_marginal: 1444.8377634684246\n",
      "Train Epoch: 175 [0/54000 (0%)] Loss: -1447.630615\n",
      "Train Epoch: 175 [4096/54000 (8%)] Loss: -1443.106567\n",
      "Train Epoch: 175 [8192/54000 (15%)] Loss: -1443.395996\n",
      "Train Epoch: 175 [12288/54000 (23%)] Loss: -1443.824463\n",
      "Train Epoch: 175 [16384/54000 (30%)] Loss: -1445.860840\n",
      "Train Epoch: 175 [20480/54000 (38%)] Loss: -1450.402832\n",
      "Train Epoch: 175 [24576/54000 (46%)] Loss: -1448.240356\n",
      "Train Epoch: 175 [28672/54000 (53%)] Loss: -1440.954834\n",
      "Train Epoch: 175 [32768/54000 (61%)] Loss: -1446.327393\n",
      "Train Epoch: 175 [36864/54000 (68%)] Loss: -1448.145020\n",
      "Train Epoch: 175 [40960/54000 (76%)] Loss: -1446.514404\n",
      "Train Epoch: 175 [45056/54000 (83%)] Loss: -1444.359375\n",
      "Train Epoch: 175 [49152/54000 (91%)] Loss: -1443.869385\n",
      "Train Epoch: 175 [53248/54000 (99%)] Loss: -1451.936035\n",
      "    epoch          : 175\n",
      "    loss           : -1446.7235928937723\n",
      "    ess            : 3.7730969275343473\n",
      "    log_marginal   : 1446.8552008895513\n",
      "    val_loss       : -1445.940200805664\n",
      "    val_ess        : 3.7790617446104684\n",
      "    val_log_marginal: 1446.0609334309895\n",
      "Train Epoch: 176 [0/54000 (0%)] Loss: -1447.140015\n",
      "Train Epoch: 176 [4096/54000 (8%)] Loss: -1450.654785\n",
      "Train Epoch: 176 [8192/54000 (15%)] Loss: -1447.012939\n",
      "Train Epoch: 176 [12288/54000 (23%)] Loss: -1444.755981\n",
      "Train Epoch: 176 [16384/54000 (30%)] Loss: -1451.775269\n",
      "Train Epoch: 176 [20480/54000 (38%)] Loss: -1442.126099\n",
      "Train Epoch: 176 [24576/54000 (46%)] Loss: -1452.697388\n",
      "Train Epoch: 176 [28672/54000 (53%)] Loss: -1454.524414\n",
      "Train Epoch: 176 [32768/54000 (61%)] Loss: -1453.018799\n",
      "Train Epoch: 176 [36864/54000 (68%)] Loss: -1442.994385\n",
      "Train Epoch: 176 [40960/54000 (76%)] Loss: -1446.880127\n",
      "Train Epoch: 176 [45056/54000 (83%)] Loss: -1446.971924\n",
      "Train Epoch: 176 [49152/54000 (91%)] Loss: -1446.604858\n",
      "Train Epoch: 176 [53248/54000 (99%)] Loss: -1444.125122\n",
      "    epoch          : 176\n",
      "    loss           : -1447.5252349998148\n",
      "    ess            : 3.776304017875997\n",
      "    log_marginal   : 1447.653792394846\n",
      "    val_loss       : -1447.6238454182942\n",
      "    val_ess        : 3.7838186820348105\n",
      "    val_log_marginal: 1447.7496744791667\n",
      "Train Epoch: 177 [0/54000 (0%)] Loss: -1453.993652\n",
      "Train Epoch: 177 [4096/54000 (8%)] Loss: -1452.101074\n",
      "Train Epoch: 177 [8192/54000 (15%)] Loss: -1448.260742\n",
      "Train Epoch: 177 [12288/54000 (23%)] Loss: -1448.787720\n",
      "Train Epoch: 177 [16384/54000 (30%)] Loss: -1444.570557\n",
      "Train Epoch: 177 [20480/54000 (38%)] Loss: -1446.911621\n",
      "Train Epoch: 177 [24576/54000 (46%)] Loss: -1452.055664\n",
      "Train Epoch: 177 [28672/54000 (53%)] Loss: -1447.310303\n",
      "Train Epoch: 177 [32768/54000 (61%)] Loss: -1450.966553\n",
      "Train Epoch: 177 [36864/54000 (68%)] Loss: -1447.490845\n",
      "Train Epoch: 177 [40960/54000 (76%)] Loss: -1446.249023\n",
      "Train Epoch: 177 [45056/54000 (83%)] Loss: -1453.490967\n",
      "Train Epoch: 177 [49152/54000 (91%)] Loss: -1449.565430\n",
      "Train Epoch: 177 [53248/54000 (99%)] Loss: -1446.041992\n",
      "    epoch          : 177\n",
      "    loss           : -1448.3323829976302\n",
      "    ess            : 3.77371094690115\n",
      "    log_marginal   : 1448.4629612059389\n",
      "    val_loss       : -1448.3235270182292\n",
      "    val_ess        : 3.773444801568985\n",
      "    val_log_marginal: 1448.452601114909\n",
      "Train Epoch: 178 [0/54000 (0%)] Loss: -1455.184326\n",
      "Train Epoch: 178 [4096/54000 (8%)] Loss: -1451.933960\n",
      "Train Epoch: 178 [8192/54000 (15%)] Loss: -1456.425781\n",
      "Train Epoch: 178 [12288/54000 (23%)] Loss: -1451.467896\n",
      "Train Epoch: 178 [16384/54000 (30%)] Loss: -1446.491211\n",
      "Train Epoch: 178 [20480/54000 (38%)] Loss: -1448.631592\n",
      "Train Epoch: 178 [24576/54000 (46%)] Loss: -1448.919434\n",
      "Train Epoch: 178 [28672/54000 (53%)] Loss: -1449.808960\n",
      "Train Epoch: 178 [32768/54000 (61%)] Loss: -1450.334961\n",
      "Train Epoch: 178 [36864/54000 (68%)] Loss: -1451.210449\n",
      "Train Epoch: 178 [40960/54000 (76%)] Loss: -1449.628418\n",
      "Train Epoch: 178 [45056/54000 (83%)] Loss: -1448.115112\n",
      "Train Epoch: 178 [49152/54000 (91%)] Loss: -1451.217285\n",
      "Train Epoch: 178 [53248/54000 (99%)] Loss: -1445.181152\n",
      "    epoch          : 178\n",
      "    loss           : -1449.5898350720156\n",
      "    ess            : 3.774500351946501\n",
      "    log_marginal   : 1449.7206128739633\n",
      "    val_loss       : -1448.5308736165364\n",
      "    val_ess        : 3.7814671198527017\n",
      "    val_log_marginal: 1448.6561330159504\n",
      "Train Epoch: 179 [0/54000 (0%)] Loss: -1448.533936\n",
      "Train Epoch: 179 [4096/54000 (8%)] Loss: -1452.941162\n",
      "Train Epoch: 179 [8192/54000 (15%)] Loss: -1450.775879\n",
      "Train Epoch: 179 [12288/54000 (23%)] Loss: -1451.013550\n",
      "Train Epoch: 179 [16384/54000 (30%)] Loss: -1451.605835\n",
      "Train Epoch: 179 [20480/54000 (38%)] Loss: -1452.881104\n",
      "Train Epoch: 179 [24576/54000 (46%)] Loss: -1453.797485\n",
      "Train Epoch: 179 [28672/54000 (53%)] Loss: -1446.946777\n",
      "Train Epoch: 179 [32768/54000 (61%)] Loss: -1452.666992\n",
      "Train Epoch: 179 [36864/54000 (68%)] Loss: -1451.957764\n",
      "Train Epoch: 179 [40960/54000 (76%)] Loss: -1450.350342\n",
      "Train Epoch: 179 [45056/54000 (83%)] Loss: -1450.611328\n",
      "Train Epoch: 179 [49152/54000 (91%)] Loss: -1447.637695\n",
      "Train Epoch: 179 [53248/54000 (99%)] Loss: -1455.208740\n",
      "    epoch          : 179\n",
      "    loss           : -1450.5738427040137\n",
      "    ess            : 3.775316675692373\n",
      "    log_marginal   : 1450.7046743094638\n",
      "    val_loss       : -1449.6182454427083\n",
      "    val_ess        : 3.767236848672231\n",
      "    val_log_marginal: 1449.7495371500652\n",
      "Train Epoch: 180 [0/54000 (0%)] Loss: -1446.666748\n",
      "Train Epoch: 180 [4096/54000 (8%)] Loss: -1454.185303\n",
      "Train Epoch: 180 [8192/54000 (15%)] Loss: -1455.168457\n",
      "Train Epoch: 180 [12288/54000 (23%)] Loss: -1451.162109\n",
      "Train Epoch: 180 [16384/54000 (30%)] Loss: -1452.819092\n",
      "Train Epoch: 180 [20480/54000 (38%)] Loss: -1455.081421\n",
      "Train Epoch: 180 [24576/54000 (46%)] Loss: -1452.430420\n",
      "Train Epoch: 180 [28672/54000 (53%)] Loss: -1451.418945\n",
      "Train Epoch: 180 [32768/54000 (61%)] Loss: -1444.840820\n",
      "Train Epoch: 180 [36864/54000 (68%)] Loss: -1450.409668\n",
      "Train Epoch: 180 [40960/54000 (76%)] Loss: -1452.441650\n",
      "Train Epoch: 180 [45056/54000 (83%)] Loss: -1450.621216\n",
      "Train Epoch: 180 [49152/54000 (91%)] Loss: -1450.877686\n",
      "Train Epoch: 180 [53248/54000 (99%)] Loss: -1446.797729\n",
      "    epoch          : 180\n",
      "    loss           : -1451.4456405278065\n",
      "    ess            : 3.771843309086081\n",
      "    log_marginal   : 1451.5776089492003\n",
      "    val_loss       : -1450.5994822184246\n",
      "    val_ess        : 3.7626615464687347\n",
      "    val_log_marginal: 1450.7367909749348\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch180.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 181 [0/54000 (0%)] Loss: -1455.455322\n",
      "Train Epoch: 181 [4096/54000 (8%)] Loss: -1451.252686\n",
      "Train Epoch: 181 [8192/54000 (15%)] Loss: -1458.335938\n",
      "Train Epoch: 181 [12288/54000 (23%)] Loss: -1453.638184\n",
      "Train Epoch: 181 [16384/54000 (30%)] Loss: -1455.782104\n",
      "Train Epoch: 181 [20480/54000 (38%)] Loss: -1449.585693\n",
      "Train Epoch: 181 [24576/54000 (46%)] Loss: -1453.447754\n",
      "Train Epoch: 181 [28672/54000 (53%)] Loss: -1451.878662\n",
      "Train Epoch: 181 [32768/54000 (61%)] Loss: -1457.275146\n",
      "Train Epoch: 181 [36864/54000 (68%)] Loss: -1447.297974\n",
      "Train Epoch: 181 [40960/54000 (76%)] Loss: -1460.536133\n",
      "Train Epoch: 181 [45056/54000 (83%)] Loss: -1453.864502\n",
      "Train Epoch: 181 [49152/54000 (91%)] Loss: -1452.755249\n",
      "Train Epoch: 181 [53248/54000 (99%)] Loss: -1450.389160\n",
      "    epoch          : 181\n",
      "    loss           : -1452.3959503896992\n",
      "    ess            : 3.771510079008708\n",
      "    log_marginal   : 1452.5282566739484\n",
      "    val_loss       : -1451.9784596761067\n",
      "    val_ess        : 3.7616087794303894\n",
      "    val_log_marginal: 1452.1155039469402\n",
      "Train Epoch: 182 [0/54000 (0%)] Loss: -1461.072266\n",
      "Train Epoch: 182 [4096/54000 (8%)] Loss: -1452.876465\n",
      "Train Epoch: 182 [8192/54000 (15%)] Loss: -1447.566650\n",
      "Train Epoch: 182 [12288/54000 (23%)] Loss: -1453.516113\n",
      "Train Epoch: 182 [16384/54000 (30%)] Loss: -1447.052490\n",
      "Train Epoch: 182 [20480/54000 (38%)] Loss: -1453.516113\n",
      "Train Epoch: 182 [24576/54000 (46%)] Loss: -1455.774170\n",
      "Train Epoch: 182 [28672/54000 (53%)] Loss: -1453.236572\n",
      "Train Epoch: 182 [32768/54000 (61%)] Loss: -1451.325195\n",
      "Train Epoch: 182 [36864/54000 (68%)] Loss: -1447.614502\n",
      "Train Epoch: 182 [40960/54000 (76%)] Loss: -1454.009521\n",
      "Train Epoch: 182 [45056/54000 (83%)] Loss: -1456.840088\n",
      "Train Epoch: 182 [49152/54000 (91%)] Loss: -1451.682251\n",
      "Train Epoch: 182 [53248/54000 (99%)] Loss: -1454.885986\n",
      "    epoch          : 182\n",
      "    loss           : -1453.299562282472\n",
      "    ess            : 3.7683401186884296\n",
      "    log_marginal   : 1453.4331141467344\n",
      "    val_loss       : -1453.1603495279949\n",
      "    val_ess        : 3.7758555511633554\n",
      "    val_log_marginal: 1453.2846272786458\n",
      "Train Epoch: 183 [0/54000 (0%)] Loss: -1449.772827\n",
      "Train Epoch: 183 [4096/54000 (8%)] Loss: -1460.141357\n",
      "Train Epoch: 183 [8192/54000 (15%)] Loss: -1450.758911\n",
      "Train Epoch: 183 [12288/54000 (23%)] Loss: -1445.202393\n",
      "Train Epoch: 183 [16384/54000 (30%)] Loss: -1449.907959\n",
      "Train Epoch: 183 [20480/54000 (38%)] Loss: -1461.563599\n",
      "Train Epoch: 183 [24576/54000 (46%)] Loss: -1453.071289\n",
      "Train Epoch: 183 [28672/54000 (53%)] Loss: -1450.230225\n",
      "Train Epoch: 183 [32768/54000 (61%)] Loss: -1462.342529\n",
      "Train Epoch: 183 [36864/54000 (68%)] Loss: -1456.105957\n",
      "Train Epoch: 183 [40960/54000 (76%)] Loss: -1448.213379\n",
      "Train Epoch: 183 [45056/54000 (83%)] Loss: -1452.587402\n",
      "Train Epoch: 183 [49152/54000 (91%)] Loss: -1451.470337\n",
      "Train Epoch: 183 [53248/54000 (99%)] Loss: -1455.392822\n",
      "    epoch          : 183\n",
      "    loss           : -1454.4159988475637\n",
      "    ess            : 3.772143017059254\n",
      "    log_marginal   : 1454.550212552762\n",
      "    val_loss       : -1454.3434193929036\n",
      "    val_ess        : 3.7668746014436087\n",
      "    val_log_marginal: 1454.4791615804036\n",
      "Train Epoch: 184 [0/54000 (0%)] Loss: -1451.746582\n",
      "Train Epoch: 184 [4096/54000 (8%)] Loss: -1454.092773\n",
      "Train Epoch: 184 [8192/54000 (15%)] Loss: -1457.821289\n",
      "Train Epoch: 184 [12288/54000 (23%)] Loss: -1457.251465\n",
      "Train Epoch: 184 [16384/54000 (30%)] Loss: -1456.119141\n",
      "Train Epoch: 184 [20480/54000 (38%)] Loss: -1456.298828\n",
      "Train Epoch: 184 [24576/54000 (46%)] Loss: -1451.596191\n",
      "Train Epoch: 184 [28672/54000 (53%)] Loss: -1457.705688\n",
      "Train Epoch: 184 [32768/54000 (61%)] Loss: -1456.609009\n",
      "Train Epoch: 184 [36864/54000 (68%)] Loss: -1458.253174\n",
      "Train Epoch: 184 [40960/54000 (76%)] Loss: -1458.242920\n",
      "Train Epoch: 184 [45056/54000 (83%)] Loss: -1450.156372\n",
      "Train Epoch: 184 [49152/54000 (91%)] Loss: -1459.031128\n",
      "Train Epoch: 184 [53248/54000 (99%)] Loss: -1456.575439\n",
      "    epoch          : 184\n",
      "    loss           : -1455.2429453772957\n",
      "    ess            : 3.7697410199314496\n",
      "    log_marginal   : 1455.379071710234\n",
      "    val_loss       : -1454.6738739013672\n",
      "    val_ess        : 3.7737807234128318\n",
      "    val_log_marginal: 1454.8028208414714\n",
      "Train Epoch: 185 [0/54000 (0%)] Loss: -1461.198730\n",
      "Train Epoch: 185 [4096/54000 (8%)] Loss: -1451.812256\n",
      "Train Epoch: 185 [8192/54000 (15%)] Loss: -1458.330078\n",
      "Train Epoch: 185 [12288/54000 (23%)] Loss: -1458.161743\n",
      "Train Epoch: 185 [16384/54000 (30%)] Loss: -1455.412842\n",
      "Train Epoch: 185 [20480/54000 (38%)] Loss: -1457.512695\n",
      "Train Epoch: 185 [24576/54000 (46%)] Loss: -1456.807373\n",
      "Train Epoch: 185 [28672/54000 (53%)] Loss: -1459.039917\n",
      "Train Epoch: 185 [32768/54000 (61%)] Loss: -1460.149170\n",
      "Train Epoch: 185 [36864/54000 (68%)] Loss: -1463.485840\n",
      "Train Epoch: 185 [40960/54000 (76%)] Loss: -1461.449463\n",
      "Train Epoch: 185 [45056/54000 (83%)] Loss: -1458.191772\n",
      "Train Epoch: 185 [49152/54000 (91%)] Loss: -1460.291138\n",
      "Train Epoch: 185 [53248/54000 (99%)] Loss: -1450.015137\n",
      "    epoch          : 185\n",
      "    loss           : -1456.4270731125962\n",
      "    ess            : 3.7708093837539165\n",
      "    log_marginal   : 1456.560915978599\n",
      "    val_loss       : -1455.6512807210286\n",
      "    val_ess        : 3.76748056213061\n",
      "    val_log_marginal: 1455.7882792154949\n",
      "Train Epoch: 186 [0/54000 (0%)] Loss: -1458.424316\n",
      "Train Epoch: 186 [4096/54000 (8%)] Loss: -1453.367676\n",
      "Train Epoch: 186 [8192/54000 (15%)] Loss: -1455.997559\n",
      "Train Epoch: 186 [12288/54000 (23%)] Loss: -1452.749878\n",
      "Train Epoch: 186 [16384/54000 (30%)] Loss: -1454.189209\n",
      "Train Epoch: 186 [20480/54000 (38%)] Loss: -1455.263672\n",
      "Train Epoch: 186 [24576/54000 (46%)] Loss: -1456.932617\n",
      "Train Epoch: 186 [28672/54000 (53%)] Loss: -1455.461914\n",
      "Train Epoch: 186 [32768/54000 (61%)] Loss: -1452.689575\n",
      "Train Epoch: 186 [36864/54000 (68%)] Loss: -1453.038452\n",
      "Train Epoch: 186 [40960/54000 (76%)] Loss: -1453.345581\n",
      "Train Epoch: 186 [45056/54000 (83%)] Loss: -1451.648560\n",
      "Train Epoch: 186 [49152/54000 (91%)] Loss: -1459.383545\n",
      "Train Epoch: 186 [53248/54000 (99%)] Loss: -1458.440918\n",
      "    epoch          : 186\n",
      "    loss           : -1457.1495644808945\n",
      "    ess            : 3.7742335649463237\n",
      "    log_marginal   : 1457.2827906314797\n",
      "    val_loss       : -1457.163823445638\n",
      "    val_ess        : 3.783855438232422\n",
      "    val_log_marginal: 1457.2955678304036\n",
      "Train Epoch: 187 [0/54000 (0%)] Loss: -1453.487305\n",
      "Train Epoch: 187 [4096/54000 (8%)] Loss: -1458.598389\n",
      "Train Epoch: 187 [8192/54000 (15%)] Loss: -1464.239502\n",
      "Train Epoch: 187 [12288/54000 (23%)] Loss: -1456.802368\n",
      "Train Epoch: 187 [16384/54000 (30%)] Loss: -1461.551758\n",
      "Train Epoch: 187 [20480/54000 (38%)] Loss: -1457.448486\n",
      "Train Epoch: 187 [24576/54000 (46%)] Loss: -1452.392578\n",
      "Train Epoch: 187 [28672/54000 (53%)] Loss: -1456.047852\n",
      "Train Epoch: 187 [32768/54000 (61%)] Loss: -1458.565186\n",
      "Train Epoch: 187 [36864/54000 (68%)] Loss: -1456.389893\n",
      "Train Epoch: 187 [40960/54000 (76%)] Loss: -1460.861938\n",
      "Train Epoch: 187 [45056/54000 (83%)] Loss: -1460.583984\n",
      "Train Epoch: 187 [49152/54000 (91%)] Loss: -1460.786865\n",
      "Train Epoch: 187 [53248/54000 (99%)] Loss: -1454.964722\n",
      "    epoch          : 187\n",
      "    loss           : -1458.3328787998\n",
      "    ess            : 3.7686330458564217\n",
      "    log_marginal   : 1458.4699805381738\n",
      "    val_loss       : -1458.101791381836\n",
      "    val_ess        : 3.7740560372670493\n",
      "    val_log_marginal: 1458.2384033203125\n",
      "Train Epoch: 188 [0/54000 (0%)] Loss: -1459.763672\n",
      "Train Epoch: 188 [4096/54000 (8%)] Loss: -1460.724365\n",
      "Train Epoch: 188 [8192/54000 (15%)] Loss: -1460.435059\n",
      "Train Epoch: 188 [12288/54000 (23%)] Loss: -1456.466553\n",
      "Train Epoch: 188 [16384/54000 (30%)] Loss: -1460.017456\n",
      "Train Epoch: 188 [20480/54000 (38%)] Loss: -1453.052490\n",
      "Train Epoch: 188 [24576/54000 (46%)] Loss: -1452.805420\n",
      "Train Epoch: 188 [28672/54000 (53%)] Loss: -1459.842529\n",
      "Train Epoch: 188 [32768/54000 (61%)] Loss: -1463.868774\n",
      "Train Epoch: 188 [36864/54000 (68%)] Loss: -1463.018677\n",
      "Train Epoch: 188 [40960/54000 (76%)] Loss: -1462.472656\n",
      "Train Epoch: 188 [45056/54000 (83%)] Loss: -1457.579956\n",
      "Train Epoch: 188 [49152/54000 (91%)] Loss: -1453.192139\n",
      "Train Epoch: 188 [53248/54000 (99%)] Loss: -1459.503052\n",
      "    epoch          : 188\n",
      "    loss           : -1459.2017978469341\n",
      "    ess            : 3.7763658462542495\n",
      "    log_marginal   : 1459.3329094620112\n",
      "    val_loss       : -1458.2618713378906\n",
      "    val_ess        : 3.779448449611664\n",
      "    val_log_marginal: 1458.3915608723958\n",
      "Train Epoch: 189 [0/54000 (0%)] Loss: -1455.375366\n",
      "Train Epoch: 189 [4096/54000 (8%)] Loss: -1461.112549\n",
      "Train Epoch: 189 [8192/54000 (15%)] Loss: -1465.575562\n",
      "Train Epoch: 189 [12288/54000 (23%)] Loss: -1462.755859\n",
      "Train Epoch: 189 [16384/54000 (30%)] Loss: -1462.805420\n",
      "Train Epoch: 189 [20480/54000 (38%)] Loss: -1450.496094\n",
      "Train Epoch: 189 [24576/54000 (46%)] Loss: -1467.255615\n",
      "Train Epoch: 189 [28672/54000 (53%)] Loss: -1466.954346\n",
      "Train Epoch: 189 [32768/54000 (61%)] Loss: -1457.479492\n",
      "Train Epoch: 189 [36864/54000 (68%)] Loss: -1452.989014\n",
      "Train Epoch: 189 [40960/54000 (76%)] Loss: -1458.635864\n",
      "Train Epoch: 189 [45056/54000 (83%)] Loss: -1458.727539\n",
      "Train Epoch: 189 [49152/54000 (91%)] Loss: -1457.420410\n",
      "Train Epoch: 189 [53248/54000 (99%)] Loss: -1461.990845\n",
      "    epoch          : 189\n",
      "    loss           : -1460.1397190184389\n",
      "    ess            : 3.7771276557615017\n",
      "    log_marginal   : 1460.269129748593\n",
      "    val_loss       : -1460.497522989909\n",
      "    val_ess        : 3.769723117351532\n",
      "    val_log_marginal: 1460.6340993245442\n",
      "Train Epoch: 190 [0/54000 (0%)] Loss: -1456.456909\n",
      "Train Epoch: 190 [4096/54000 (8%)] Loss: -1456.822266\n",
      "Train Epoch: 190 [8192/54000 (15%)] Loss: -1465.295166\n",
      "Train Epoch: 190 [12288/54000 (23%)] Loss: -1451.851318\n",
      "Train Epoch: 190 [16384/54000 (30%)] Loss: -1458.851685\n",
      "Train Epoch: 190 [20480/54000 (38%)] Loss: -1456.593994\n",
      "Train Epoch: 190 [24576/54000 (46%)] Loss: -1460.750244\n",
      "Train Epoch: 190 [28672/54000 (53%)] Loss: -1461.264771\n",
      "Train Epoch: 190 [32768/54000 (61%)] Loss: -1458.589600\n",
      "Train Epoch: 190 [36864/54000 (68%)] Loss: -1456.956787\n",
      "Train Epoch: 190 [40960/54000 (76%)] Loss: -1462.040894\n",
      "Train Epoch: 190 [45056/54000 (83%)] Loss: -1465.443604\n",
      "Train Epoch: 190 [49152/54000 (91%)] Loss: -1455.640259\n",
      "Train Epoch: 190 [53248/54000 (99%)] Loss: -1461.756226\n",
      "    epoch          : 190\n",
      "    loss           : -1460.9473448839233\n",
      "    ess            : 3.771165487325587\n",
      "    log_marginal   : 1461.0804518568573\n",
      "    val_loss       : -1461.3294423421223\n",
      "    val_ess        : 3.772123843431473\n",
      "    val_log_marginal: 1461.471430460612\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch190.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 191 [0/54000 (0%)] Loss: -1464.736084\n",
      "Train Epoch: 191 [4096/54000 (8%)] Loss: -1463.381958\n",
      "Train Epoch: 191 [8192/54000 (15%)] Loss: -1463.570190\n",
      "Train Epoch: 191 [12288/54000 (23%)] Loss: -1458.572998\n",
      "Train Epoch: 191 [16384/54000 (30%)] Loss: -1466.045898\n",
      "Train Epoch: 191 [20480/54000 (38%)] Loss: -1464.869873\n",
      "Train Epoch: 191 [24576/54000 (46%)] Loss: -1463.147217\n",
      "Train Epoch: 191 [28672/54000 (53%)] Loss: -1459.076416\n",
      "Train Epoch: 191 [32768/54000 (61%)] Loss: -1463.444336\n",
      "Train Epoch: 191 [36864/54000 (68%)] Loss: -1467.496094\n",
      "Train Epoch: 191 [40960/54000 (76%)] Loss: -1463.716309\n",
      "Train Epoch: 191 [45056/54000 (83%)] Loss: -1457.061279\n",
      "Train Epoch: 191 [49152/54000 (91%)] Loss: -1458.672363\n",
      "Train Epoch: 191 [53248/54000 (99%)] Loss: -1462.079346\n",
      "    epoch          : 191\n",
      "    loss           : -1461.904577463159\n",
      "    ess            : 3.7743375018874614\n",
      "    log_marginal   : 1462.0356514736375\n",
      "    val_loss       : -1461.4397481282551\n",
      "    val_ess        : 3.7769616742928824\n",
      "    val_log_marginal: 1461.5741068522136\n",
      "Train Epoch: 192 [0/54000 (0%)] Loss: -1456.689209\n",
      "Train Epoch: 192 [4096/54000 (8%)] Loss: -1456.316040\n",
      "Train Epoch: 192 [8192/54000 (15%)] Loss: -1471.122925\n",
      "Train Epoch: 192 [12288/54000 (23%)] Loss: -1462.859375\n",
      "Train Epoch: 192 [16384/54000 (30%)] Loss: -1462.548584\n",
      "Train Epoch: 192 [20480/54000 (38%)] Loss: -1464.252686\n",
      "Train Epoch: 192 [24576/54000 (46%)] Loss: -1471.938721\n",
      "Train Epoch: 192 [28672/54000 (53%)] Loss: -1466.842285\n",
      "Train Epoch: 192 [32768/54000 (61%)] Loss: -1459.422852\n",
      "Train Epoch: 192 [36864/54000 (68%)] Loss: -1465.105835\n",
      "Train Epoch: 192 [40960/54000 (76%)] Loss: -1457.417847\n",
      "Train Epoch: 192 [45056/54000 (83%)] Loss: -1456.064819\n",
      "Train Epoch: 192 [49152/54000 (91%)] Loss: -1462.539307\n",
      "Train Epoch: 192 [53248/54000 (99%)] Loss: -1470.637939\n",
      "    epoch          : 192\n",
      "    loss           : -1462.8601039506814\n",
      "    ess            : 3.772617155906713\n",
      "    log_marginal   : 1462.9943650955272\n",
      "    val_loss       : -1462.2466430664062\n",
      "    val_ess        : 3.7650986115137735\n",
      "    val_log_marginal: 1462.3778025309246\n",
      "Train Epoch: 193 [0/54000 (0%)] Loss: -1465.947510\n",
      "Train Epoch: 193 [4096/54000 (8%)] Loss: -1469.682861\n",
      "Train Epoch: 193 [8192/54000 (15%)] Loss: -1459.716309\n",
      "Train Epoch: 193 [12288/54000 (23%)] Loss: -1464.459229\n",
      "Train Epoch: 193 [16384/54000 (30%)] Loss: -1468.791504\n",
      "Train Epoch: 193 [20480/54000 (38%)] Loss: -1466.834473\n",
      "Train Epoch: 193 [24576/54000 (46%)] Loss: -1469.843994\n",
      "Train Epoch: 193 [28672/54000 (53%)] Loss: -1460.822388\n",
      "Train Epoch: 193 [32768/54000 (61%)] Loss: -1459.126587\n",
      "Train Epoch: 193 [36864/54000 (68%)] Loss: -1462.909790\n",
      "Train Epoch: 193 [40960/54000 (76%)] Loss: -1463.182373\n",
      "Train Epoch: 193 [45056/54000 (83%)] Loss: -1458.051392\n",
      "Train Epoch: 193 [49152/54000 (91%)] Loss: -1461.394775\n",
      "Train Epoch: 193 [53248/54000 (99%)] Loss: -1455.942505\n",
      "    epoch          : 193\n",
      "    loss           : -1463.321878008368\n",
      "    ess            : 3.7669537971370026\n",
      "    log_marginal   : 1463.4598857283027\n",
      "    val_loss       : -1462.6095733642578\n",
      "    val_ess        : 3.755595773458481\n",
      "    val_log_marginal: 1462.7568868001301\n",
      "Train Epoch: 194 [0/54000 (0%)] Loss: -1466.714233\n",
      "Train Epoch: 194 [4096/54000 (8%)] Loss: -1465.964478\n",
      "Train Epoch: 194 [8192/54000 (15%)] Loss: -1463.272583\n",
      "Train Epoch: 194 [12288/54000 (23%)] Loss: -1464.712158\n",
      "Train Epoch: 194 [16384/54000 (30%)] Loss: -1464.449707\n",
      "Train Epoch: 194 [20480/54000 (38%)] Loss: -1460.639404\n",
      "Train Epoch: 194 [24576/54000 (46%)] Loss: -1467.195557\n",
      "Train Epoch: 194 [28672/54000 (53%)] Loss: -1462.752563\n",
      "Train Epoch: 194 [32768/54000 (61%)] Loss: -1462.769531\n",
      "Train Epoch: 194 [36864/54000 (68%)] Loss: -1467.810303\n",
      "Train Epoch: 194 [40960/54000 (76%)] Loss: -1456.782715\n",
      "Train Epoch: 194 [45056/54000 (83%)] Loss: -1461.628784\n",
      "Train Epoch: 194 [49152/54000 (91%)] Loss: -1457.214600\n",
      "Train Epoch: 194 [53248/54000 (99%)] Loss: -1460.387695\n",
      "    epoch          : 194\n",
      "    loss           : -1464.21478300411\n",
      "    ess            : 3.771901541976567\n",
      "    log_marginal   : 1464.3506304844861\n",
      "    val_loss       : -1463.3817952473958\n",
      "    val_ess        : 3.78067809343338\n",
      "    val_log_marginal: 1463.5125834147136\n",
      "Train Epoch: 195 [0/54000 (0%)] Loss: -1463.696533\n",
      "Train Epoch: 195 [4096/54000 (8%)] Loss: -1462.157471\n",
      "Train Epoch: 195 [8192/54000 (15%)] Loss: -1458.913330\n",
      "Train Epoch: 195 [12288/54000 (23%)] Loss: -1462.458252\n",
      "Train Epoch: 195 [16384/54000 (30%)] Loss: -1463.158691\n",
      "Train Epoch: 195 [20480/54000 (38%)] Loss: -1467.147583\n",
      "Train Epoch: 195 [24576/54000 (46%)] Loss: -1468.903320\n",
      "Train Epoch: 195 [28672/54000 (53%)] Loss: -1468.745605\n",
      "Train Epoch: 195 [32768/54000 (61%)] Loss: -1462.548584\n",
      "Train Epoch: 195 [36864/54000 (68%)] Loss: -1463.752319\n",
      "Train Epoch: 195 [40960/54000 (76%)] Loss: -1467.251709\n",
      "Train Epoch: 195 [45056/54000 (83%)] Loss: -1455.754761\n",
      "Train Epoch: 195 [49152/54000 (91%)] Loss: -1465.613037\n",
      "Train Epoch: 195 [53248/54000 (99%)] Loss: -1460.013916\n",
      "    epoch          : 195\n",
      "    loss           : -1464.9743889541987\n",
      "    ess            : 3.770965408939886\n",
      "    log_marginal   : 1465.1097487318573\n",
      "    val_loss       : -1464.0148010253906\n",
      "    val_ess        : 3.7765184541543326\n",
      "    val_log_marginal: 1464.1464945475261\n",
      "Train Epoch: 196 [0/54000 (0%)] Loss: -1467.840576\n",
      "Train Epoch: 196 [4096/54000 (8%)] Loss: -1462.563232\n",
      "Train Epoch: 196 [8192/54000 (15%)] Loss: -1469.030762\n",
      "Train Epoch: 196 [12288/54000 (23%)] Loss: -1466.366455\n",
      "Train Epoch: 196 [16384/54000 (30%)] Loss: -1454.648804\n",
      "Train Epoch: 196 [20480/54000 (38%)] Loss: -1471.277100\n",
      "Train Epoch: 196 [24576/54000 (46%)] Loss: -1464.591553\n",
      "Train Epoch: 196 [28672/54000 (53%)] Loss: -1465.602295\n",
      "Train Epoch: 196 [32768/54000 (61%)] Loss: -1465.148926\n",
      "Train Epoch: 196 [36864/54000 (68%)] Loss: -1463.414551\n",
      "Train Epoch: 196 [40960/54000 (76%)] Loss: -1460.103760\n",
      "Train Epoch: 196 [45056/54000 (83%)] Loss: -1469.765869\n",
      "Train Epoch: 196 [49152/54000 (91%)] Loss: -1462.984497\n",
      "Train Epoch: 196 [53248/54000 (99%)] Loss: -1464.921509\n",
      "    epoch          : 196\n",
      "    loss           : -1465.8905486337383\n",
      "    ess            : 3.766082345591902\n",
      "    log_marginal   : 1466.0305065860116\n",
      "    val_loss       : -1465.6629638671875\n",
      "    val_ess        : 3.766137679417928\n",
      "    val_log_marginal: 1465.8008677164714\n",
      "Train Epoch: 197 [0/54000 (0%)] Loss: -1468.862061\n",
      "Train Epoch: 197 [4096/54000 (8%)] Loss: -1467.295410\n",
      "Train Epoch: 197 [8192/54000 (15%)] Loss: -1467.668457\n",
      "Train Epoch: 197 [12288/54000 (23%)] Loss: -1464.043091\n",
      "Train Epoch: 197 [16384/54000 (30%)] Loss: -1467.346436\n",
      "Train Epoch: 197 [20480/54000 (38%)] Loss: -1461.211914\n",
      "Train Epoch: 197 [24576/54000 (46%)] Loss: -1474.736328\n",
      "Train Epoch: 197 [28672/54000 (53%)] Loss: -1469.666748\n",
      "Train Epoch: 197 [32768/54000 (61%)] Loss: -1461.101074\n",
      "Train Epoch: 197 [36864/54000 (68%)] Loss: -1465.114380\n",
      "Train Epoch: 197 [40960/54000 (76%)] Loss: -1469.198975\n",
      "Train Epoch: 197 [45056/54000 (83%)] Loss: -1467.259888\n",
      "Train Epoch: 197 [49152/54000 (91%)] Loss: -1461.983643\n",
      "Train Epoch: 197 [53248/54000 (99%)] Loss: -1469.420898\n",
      "    epoch          : 197\n",
      "    loss           : -1466.4611180020734\n",
      "    ess            : 3.770285824463831\n",
      "    log_marginal   : 1466.596861346638\n",
      "    val_loss       : -1466.0748799641926\n",
      "    val_ess        : 3.7776265939076743\n",
      "    val_log_marginal: 1466.2020009358723\n",
      "Train Epoch: 198 [0/54000 (0%)] Loss: -1461.139893\n",
      "Train Epoch: 198 [4096/54000 (8%)] Loss: -1463.458984\n",
      "Train Epoch: 198 [8192/54000 (15%)] Loss: -1476.535889\n",
      "Train Epoch: 198 [12288/54000 (23%)] Loss: -1468.673584\n",
      "Train Epoch: 198 [16384/54000 (30%)] Loss: -1458.025146\n",
      "Train Epoch: 198 [20480/54000 (38%)] Loss: -1465.499512\n",
      "Train Epoch: 198 [24576/54000 (46%)] Loss: -1466.255127\n",
      "Train Epoch: 198 [28672/54000 (53%)] Loss: -1474.144653\n",
      "Train Epoch: 198 [32768/54000 (61%)] Loss: -1464.569336\n",
      "Train Epoch: 198 [36864/54000 (68%)] Loss: -1470.500732\n",
      "Train Epoch: 198 [40960/54000 (76%)] Loss: -1465.844482\n",
      "Train Epoch: 198 [45056/54000 (83%)] Loss: -1471.922852\n",
      "Train Epoch: 198 [49152/54000 (91%)] Loss: -1469.180542\n",
      "Train Epoch: 198 [53248/54000 (99%)] Loss: -1470.025146\n",
      "    epoch          : 198\n",
      "    loss           : -1467.4375323978081\n",
      "    ess            : 3.770536493916082\n",
      "    log_marginal   : 1467.5741556899807\n",
      "    val_loss       : -1467.5156148274739\n",
      "    val_ess        : 3.7662354906400046\n",
      "    val_log_marginal: 1467.6656036376953\n",
      "Train Epoch: 199 [0/54000 (0%)] Loss: -1472.726440\n",
      "Train Epoch: 199 [4096/54000 (8%)] Loss: -1470.084961\n",
      "Train Epoch: 199 [8192/54000 (15%)] Loss: -1474.583984\n",
      "Train Epoch: 199 [12288/54000 (23%)] Loss: -1467.638184\n",
      "Train Epoch: 199 [16384/54000 (30%)] Loss: -1467.621338\n",
      "Train Epoch: 199 [20480/54000 (38%)] Loss: -1464.907471\n",
      "Train Epoch: 199 [24576/54000 (46%)] Loss: -1478.012695\n",
      "Train Epoch: 199 [28672/54000 (53%)] Loss: -1470.788574\n",
      "Train Epoch: 199 [32768/54000 (61%)] Loss: -1474.260376\n",
      "Train Epoch: 199 [36864/54000 (68%)] Loss: -1465.240967\n",
      "Train Epoch: 199 [40960/54000 (76%)] Loss: -1469.887451\n",
      "Train Epoch: 199 [45056/54000 (83%)] Loss: -1465.130859\n",
      "Train Epoch: 199 [49152/54000 (91%)] Loss: -1471.030151\n",
      "Train Epoch: 199 [53248/54000 (99%)] Loss: -1471.900513\n",
      "    epoch          : 199\n",
      "    loss           : -1468.5483213307168\n",
      "    ess            : 3.7727148792754983\n",
      "    log_marginal   : 1468.6837638384923\n",
      "    val_loss       : -1467.5800476074219\n",
      "    val_ess        : 3.756810963153839\n",
      "    val_log_marginal: 1467.7227071126301\n",
      "Train Epoch: 200 [0/54000 (0%)] Loss: -1470.203369\n",
      "Train Epoch: 200 [4096/54000 (8%)] Loss: -1480.121460\n",
      "Train Epoch: 200 [8192/54000 (15%)] Loss: -1471.394531\n",
      "Train Epoch: 200 [12288/54000 (23%)] Loss: -1476.824219\n",
      "Train Epoch: 200 [16384/54000 (30%)] Loss: -1469.616211\n",
      "Train Epoch: 200 [20480/54000 (38%)] Loss: -1473.213867\n",
      "Train Epoch: 200 [24576/54000 (46%)] Loss: -1466.591675\n",
      "Train Epoch: 200 [28672/54000 (53%)] Loss: -1471.642090\n",
      "Train Epoch: 200 [32768/54000 (61%)] Loss: -1466.302368\n",
      "Train Epoch: 200 [36864/54000 (68%)] Loss: -1468.099854\n",
      "Train Epoch: 200 [40960/54000 (76%)] Loss: -1466.682617\n",
      "Train Epoch: 200 [45056/54000 (83%)] Loss: -1465.318604\n",
      "Train Epoch: 200 [49152/54000 (91%)] Loss: -1463.751953\n",
      "Train Epoch: 200 [53248/54000 (99%)] Loss: -1480.151611\n",
      "    epoch          : 200\n",
      "    loss           : -1469.2786124713048\n",
      "    ess            : 3.7714141590335357\n",
      "    log_marginal   : 1469.4161805067017\n",
      "    val_loss       : -1468.8026224772136\n",
      "    val_ess        : 3.7687168518702188\n",
      "    val_log_marginal: 1468.9511260986328\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch200.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 201 [0/54000 (0%)] Loss: -1473.325928\n",
      "Train Epoch: 201 [4096/54000 (8%)] Loss: -1468.706055\n",
      "Train Epoch: 201 [8192/54000 (15%)] Loss: -1468.646484\n",
      "Train Epoch: 201 [12288/54000 (23%)] Loss: -1474.262085\n",
      "Train Epoch: 201 [16384/54000 (30%)] Loss: -1464.651611\n",
      "Train Epoch: 201 [20480/54000 (38%)] Loss: -1465.747559\n",
      "Train Epoch: 201 [24576/54000 (46%)] Loss: -1470.626831\n",
      "Train Epoch: 201 [28672/54000 (53%)] Loss: -1472.036011\n",
      "Train Epoch: 201 [32768/54000 (61%)] Loss: -1475.054199\n",
      "Train Epoch: 201 [36864/54000 (68%)] Loss: -1468.508667\n",
      "Train Epoch: 201 [40960/54000 (76%)] Loss: -1472.788208\n",
      "Train Epoch: 201 [45056/54000 (83%)] Loss: -1465.559326\n",
      "Train Epoch: 201 [49152/54000 (91%)] Loss: -1468.415649\n",
      "Train Epoch: 201 [53248/54000 (99%)] Loss: -1476.063965\n",
      "    epoch          : 201\n",
      "    loss           : -1470.0212998232005\n",
      "    ess            : 3.77669874299759\n",
      "    log_marginal   : 1470.1522477136405\n",
      "    val_loss       : -1471.132359822591\n",
      "    val_ess        : 3.759058892726898\n",
      "    val_log_marginal: 1471.2823232014973\n",
      "Train Epoch: 202 [0/54000 (0%)] Loss: -1473.612061\n",
      "Train Epoch: 202 [4096/54000 (8%)] Loss: -1474.451904\n",
      "Train Epoch: 202 [8192/54000 (15%)] Loss: -1468.768188\n",
      "Train Epoch: 202 [12288/54000 (23%)] Loss: -1472.321045\n",
      "Train Epoch: 202 [16384/54000 (30%)] Loss: -1475.169922\n",
      "Train Epoch: 202 [20480/54000 (38%)] Loss: -1471.244873\n",
      "Train Epoch: 202 [24576/54000 (46%)] Loss: -1473.685791\n",
      "Train Epoch: 202 [28672/54000 (53%)] Loss: -1471.790039\n",
      "Train Epoch: 202 [32768/54000 (61%)] Loss: -1466.392700\n",
      "Train Epoch: 202 [36864/54000 (68%)] Loss: -1469.071777\n",
      "Train Epoch: 202 [40960/54000 (76%)] Loss: -1477.478760\n",
      "Train Epoch: 202 [45056/54000 (83%)] Loss: -1472.576050\n",
      "Train Epoch: 202 [49152/54000 (91%)] Loss: -1470.594971\n",
      "Train Epoch: 202 [53248/54000 (99%)] Loss: -1467.014404\n",
      "    epoch          : 202\n",
      "    loss           : -1470.6407216148918\n",
      "    ess            : 3.7705289763861924\n",
      "    log_marginal   : 1470.777630123482\n",
      "    val_loss       : -1470.6437581380208\n",
      "    val_ess        : 3.7686058481534324\n",
      "    val_log_marginal: 1470.7840983072917\n",
      "Train Epoch: 203 [0/54000 (0%)] Loss: -1477.251587\n",
      "Train Epoch: 203 [4096/54000 (8%)] Loss: -1470.391846\n",
      "Train Epoch: 203 [8192/54000 (15%)] Loss: -1473.553711\n",
      "Train Epoch: 203 [12288/54000 (23%)] Loss: -1470.365479\n",
      "Train Epoch: 203 [16384/54000 (30%)] Loss: -1472.100952\n",
      "Train Epoch: 203 [20480/54000 (38%)] Loss: -1475.221680\n",
      "Train Epoch: 203 [24576/54000 (46%)] Loss: -1469.842529\n",
      "Train Epoch: 203 [28672/54000 (53%)] Loss: -1470.467285\n",
      "Train Epoch: 203 [32768/54000 (61%)] Loss: -1469.782959\n",
      "Train Epoch: 203 [36864/54000 (68%)] Loss: -1477.004639\n",
      "Train Epoch: 203 [40960/54000 (76%)] Loss: -1465.080322\n",
      "Train Epoch: 203 [45056/54000 (83%)] Loss: -1469.623535\n",
      "Train Epoch: 203 [49152/54000 (91%)] Loss: -1465.657227\n",
      "Train Epoch: 203 [53248/54000 (99%)] Loss: -1472.562988\n",
      "    epoch          : 203\n",
      "    loss           : -1471.7226296375147\n",
      "    ess            : 3.774757123106464\n",
      "    log_marginal   : 1471.8568219370186\n",
      "    val_loss       : -1472.1601053873699\n",
      "    val_ess        : 3.7782776852448783\n",
      "    val_log_marginal: 1472.2958424886067\n",
      "Train Epoch: 204 [0/54000 (0%)] Loss: -1470.775146\n",
      "Train Epoch: 204 [4096/54000 (8%)] Loss: -1474.471558\n",
      "Train Epoch: 204 [8192/54000 (15%)] Loss: -1474.579346\n",
      "Train Epoch: 204 [12288/54000 (23%)] Loss: -1474.735962\n",
      "Train Epoch: 204 [16384/54000 (30%)] Loss: -1475.937012\n",
      "Train Epoch: 204 [20480/54000 (38%)] Loss: -1472.533203\n",
      "Train Epoch: 204 [24576/54000 (46%)] Loss: -1475.712891\n",
      "Train Epoch: 204 [28672/54000 (53%)] Loss: -1474.177368\n",
      "Train Epoch: 204 [32768/54000 (61%)] Loss: -1470.914307\n",
      "Train Epoch: 204 [36864/54000 (68%)] Loss: -1464.259521\n",
      "Train Epoch: 204 [40960/54000 (76%)] Loss: -1470.509521\n",
      "Train Epoch: 204 [45056/54000 (83%)] Loss: -1467.484619\n",
      "Train Epoch: 204 [49152/54000 (91%)] Loss: -1474.805420\n",
      "Train Epoch: 204 [53248/54000 (99%)] Loss: -1478.982910\n",
      "    epoch          : 204\n",
      "    loss           : -1472.2613768374185\n",
      "    ess            : 3.767629170304791\n",
      "    log_marginal   : 1472.4025485504294\n",
      "    val_loss       : -1472.9877065022786\n",
      "    val_ess        : 3.7699331839879355\n",
      "    val_log_marginal: 1473.1202290852864\n",
      "Train Epoch: 205 [0/54000 (0%)] Loss: -1473.740234\n",
      "Train Epoch: 205 [4096/54000 (8%)] Loss: -1471.397949\n",
      "Train Epoch: 205 [8192/54000 (15%)] Loss: -1473.197632\n",
      "Train Epoch: 205 [12288/54000 (23%)] Loss: -1466.806519\n",
      "Train Epoch: 205 [16384/54000 (30%)] Loss: -1470.062744\n",
      "Train Epoch: 205 [20480/54000 (38%)] Loss: -1475.867920\n",
      "Train Epoch: 205 [24576/54000 (46%)] Loss: -1475.231201\n",
      "Train Epoch: 205 [28672/54000 (53%)] Loss: -1476.945557\n",
      "Train Epoch: 205 [32768/54000 (61%)] Loss: -1470.167725\n",
      "Train Epoch: 205 [36864/54000 (68%)] Loss: -1466.167725\n",
      "Train Epoch: 205 [40960/54000 (76%)] Loss: -1468.958984\n",
      "Train Epoch: 205 [45056/54000 (83%)] Loss: -1478.137207\n",
      "Train Epoch: 205 [49152/54000 (91%)] Loss: -1470.845459\n",
      "Train Epoch: 205 [53248/54000 (99%)] Loss: -1469.461060\n",
      "    epoch          : 205\n",
      "    loss           : -1473.101219430354\n",
      "    ess            : 3.7625317539648986\n",
      "    log_marginal   : 1473.2467850960827\n",
      "    val_loss       : -1471.858678181966\n",
      "    val_ess        : 3.785154720147451\n",
      "    val_log_marginal: 1471.9847157796223\n",
      "Train Epoch: 206 [0/54000 (0%)] Loss: -1471.251587\n",
      "Train Epoch: 206 [4096/54000 (8%)] Loss: -1471.604370\n",
      "Train Epoch: 206 [8192/54000 (15%)] Loss: -1473.119995\n",
      "Train Epoch: 206 [12288/54000 (23%)] Loss: -1473.702393\n",
      "Train Epoch: 206 [16384/54000 (30%)] Loss: -1473.852417\n",
      "Train Epoch: 206 [20480/54000 (38%)] Loss: -1476.803467\n",
      "Train Epoch: 206 [24576/54000 (46%)] Loss: -1479.267822\n",
      "Train Epoch: 206 [28672/54000 (53%)] Loss: -1472.207520\n",
      "Train Epoch: 206 [32768/54000 (61%)] Loss: -1475.415283\n",
      "Train Epoch: 206 [36864/54000 (68%)] Loss: -1477.164429\n",
      "Train Epoch: 206 [40960/54000 (76%)] Loss: -1477.452881\n",
      "Train Epoch: 206 [45056/54000 (83%)] Loss: -1473.649902\n",
      "Train Epoch: 206 [49152/54000 (91%)] Loss: -1475.537964\n",
      "Train Epoch: 206 [53248/54000 (99%)] Loss: -1473.284180\n",
      "    epoch          : 206\n",
      "    loss           : -1473.6646664877073\n",
      "    ess            : 3.768304769461754\n",
      "    log_marginal   : 1473.8039157379294\n",
      "    val_loss       : -1473.572982788086\n",
      "    val_ess        : 3.779042055209478\n",
      "    val_log_marginal: 1473.7034708658855\n",
      "Train Epoch: 207 [0/54000 (0%)] Loss: -1476.627808\n",
      "Train Epoch: 207 [4096/54000 (8%)] Loss: -1471.090332\n",
      "Train Epoch: 207 [8192/54000 (15%)] Loss: -1475.843506\n",
      "Train Epoch: 207 [12288/54000 (23%)] Loss: -1482.050293\n",
      "Train Epoch: 207 [16384/54000 (30%)] Loss: -1478.855591\n",
      "Train Epoch: 207 [20480/54000 (38%)] Loss: -1481.395996\n",
      "Train Epoch: 207 [24576/54000 (46%)] Loss: -1474.077515\n",
      "Train Epoch: 207 [28672/54000 (53%)] Loss: -1470.681396\n",
      "Train Epoch: 207 [32768/54000 (61%)] Loss: -1474.499756\n",
      "Train Epoch: 207 [36864/54000 (68%)] Loss: -1476.169922\n",
      "Train Epoch: 207 [40960/54000 (76%)] Loss: -1475.219360\n",
      "Train Epoch: 207 [45056/54000 (83%)] Loss: -1469.045898\n",
      "Train Epoch: 207 [49152/54000 (91%)] Loss: -1473.546265\n",
      "Train Epoch: 207 [53248/54000 (99%)] Loss: -1477.826904\n",
      "    epoch          : 207\n",
      "    loss           : -1474.223408920505\n",
      "    ess            : 3.7745897363147463\n",
      "    log_marginal   : 1474.3583764532732\n",
      "    val_loss       : -1475.0153706868489\n",
      "    val_ess        : 3.7734366357326508\n",
      "    val_log_marginal: 1475.1492309570312\n",
      "Train Epoch: 208 [0/54000 (0%)] Loss: -1477.511719\n",
      "Train Epoch: 208 [4096/54000 (8%)] Loss: -1475.187988\n",
      "Train Epoch: 208 [8192/54000 (15%)] Loss: -1476.709473\n",
      "Train Epoch: 208 [12288/54000 (23%)] Loss: -1482.362305\n",
      "Train Epoch: 208 [16384/54000 (30%)] Loss: -1477.989014\n",
      "Train Epoch: 208 [20480/54000 (38%)] Loss: -1469.962158\n",
      "Train Epoch: 208 [24576/54000 (46%)] Loss: -1477.461670\n",
      "Train Epoch: 208 [28672/54000 (53%)] Loss: -1481.534058\n",
      "Train Epoch: 208 [32768/54000 (61%)] Loss: -1477.736816\n",
      "Train Epoch: 208 [36864/54000 (68%)] Loss: -1463.460205\n",
      "Train Epoch: 208 [40960/54000 (76%)] Loss: -1476.317993\n",
      "Train Epoch: 208 [45056/54000 (83%)] Loss: -1476.469116\n",
      "Train Epoch: 208 [49152/54000 (91%)] Loss: -1473.115967\n",
      "Train Epoch: 208 [53248/54000 (99%)] Loss: -1474.594727\n",
      "    epoch          : 208\n",
      "    loss           : -1475.1833299392772\n",
      "    ess            : 3.7696457745339633\n",
      "    log_marginal   : 1475.3204079578272\n",
      "    val_loss       : -1474.265401204427\n",
      "    val_ess        : 3.762935151656469\n",
      "    val_log_marginal: 1474.4113260904949\n",
      "Train Epoch: 209 [0/54000 (0%)] Loss: -1476.089844\n",
      "Train Epoch: 209 [4096/54000 (8%)] Loss: -1473.541626\n",
      "Train Epoch: 209 [8192/54000 (15%)] Loss: -1478.283203\n",
      "Train Epoch: 209 [12288/54000 (23%)] Loss: -1476.982178\n",
      "Train Epoch: 209 [16384/54000 (30%)] Loss: -1479.548584\n",
      "Train Epoch: 209 [20480/54000 (38%)] Loss: -1470.977783\n",
      "Train Epoch: 209 [24576/54000 (46%)] Loss: -1475.455322\n",
      "Train Epoch: 209 [28672/54000 (53%)] Loss: -1477.228027\n",
      "Train Epoch: 209 [32768/54000 (61%)] Loss: -1474.882568\n",
      "Train Epoch: 209 [36864/54000 (68%)] Loss: -1478.541748\n",
      "Train Epoch: 209 [40960/54000 (76%)] Loss: -1473.218506\n",
      "Train Epoch: 209 [45056/54000 (83%)] Loss: -1480.735840\n",
      "Train Epoch: 209 [49152/54000 (91%)] Loss: -1473.619385\n",
      "Train Epoch: 209 [53248/54000 (99%)] Loss: -1477.890869\n",
      "    epoch          : 209\n",
      "    loss           : -1475.7200031009331\n",
      "    ess            : 3.765301192541258\n",
      "    log_marginal   : 1475.8624770901215\n",
      "    val_loss       : -1476.363021850586\n",
      "    val_ess        : 3.771750887235006\n",
      "    val_log_marginal: 1476.5002950032551\n",
      "Train Epoch: 210 [0/54000 (0%)] Loss: -1476.431519\n",
      "Train Epoch: 210 [4096/54000 (8%)] Loss: -1478.831543\n",
      "Train Epoch: 210 [8192/54000 (15%)] Loss: -1477.239136\n",
      "Train Epoch: 210 [12288/54000 (23%)] Loss: -1480.216553\n",
      "Train Epoch: 210 [16384/54000 (30%)] Loss: -1467.671387\n",
      "Train Epoch: 210 [20480/54000 (38%)] Loss: -1475.226807\n",
      "Train Epoch: 210 [24576/54000 (46%)] Loss: -1475.711304\n",
      "Train Epoch: 210 [28672/54000 (53%)] Loss: -1475.752686\n",
      "Train Epoch: 210 [32768/54000 (61%)] Loss: -1477.628418\n",
      "Train Epoch: 210 [36864/54000 (68%)] Loss: -1475.561523\n",
      "Train Epoch: 210 [40960/54000 (76%)] Loss: -1471.783936\n",
      "Train Epoch: 210 [45056/54000 (83%)] Loss: -1469.764038\n",
      "Train Epoch: 210 [49152/54000 (91%)] Loss: -1477.134033\n",
      "Train Epoch: 210 [53248/54000 (99%)] Loss: -1473.660645\n",
      "    epoch          : 210\n",
      "    loss           : -1476.2488886394772\n",
      "    ess            : 3.770336096885645\n",
      "    log_marginal   : 1476.3885966658027\n",
      "    val_loss       : -1476.4070739746094\n",
      "    val_ess        : 3.774007519086202\n",
      "    val_log_marginal: 1476.548823038737\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch210.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 211 [0/54000 (0%)] Loss: -1476.766357\n",
      "Train Epoch: 211 [4096/54000 (8%)] Loss: -1474.270752\n",
      "Train Epoch: 211 [8192/54000 (15%)] Loss: -1479.601562\n",
      "Train Epoch: 211 [12288/54000 (23%)] Loss: -1481.047119\n",
      "Train Epoch: 211 [16384/54000 (30%)] Loss: -1480.327881\n",
      "Train Epoch: 211 [20480/54000 (38%)] Loss: -1472.163330\n",
      "Train Epoch: 211 [24576/54000 (46%)] Loss: -1471.028809\n",
      "Train Epoch: 211 [28672/54000 (53%)] Loss: -1478.838135\n",
      "Train Epoch: 211 [32768/54000 (61%)] Loss: -1484.108643\n",
      "Train Epoch: 211 [36864/54000 (68%)] Loss: -1481.852539\n",
      "Train Epoch: 211 [40960/54000 (76%)] Loss: -1473.315552\n",
      "Train Epoch: 211 [45056/54000 (83%)] Loss: -1474.992432\n",
      "Train Epoch: 211 [49152/54000 (91%)] Loss: -1477.896973\n",
      "Train Epoch: 211 [53248/54000 (99%)] Loss: -1481.876709\n",
      "    epoch          : 211\n",
      "    loss           : -1477.2184104015478\n",
      "    ess            : 3.7688807175622734\n",
      "    log_marginal   : 1477.359488392328\n",
      "    val_loss       : -1477.4036610921223\n",
      "    val_ess        : 3.7746422588825226\n",
      "    val_log_marginal: 1477.5357411702473\n",
      "Train Epoch: 212 [0/54000 (0%)] Loss: -1478.193848\n",
      "Train Epoch: 212 [4096/54000 (8%)] Loss: -1474.142212\n",
      "Train Epoch: 212 [8192/54000 (15%)] Loss: -1478.133057\n",
      "Train Epoch: 212 [12288/54000 (23%)] Loss: -1482.336670\n",
      "Train Epoch: 212 [16384/54000 (30%)] Loss: -1479.566650\n",
      "Train Epoch: 212 [20480/54000 (38%)] Loss: -1476.844849\n",
      "Train Epoch: 212 [24576/54000 (46%)] Loss: -1475.538696\n",
      "Train Epoch: 212 [28672/54000 (53%)] Loss: -1474.943604\n",
      "Train Epoch: 212 [32768/54000 (61%)] Loss: -1474.269043\n",
      "Train Epoch: 212 [36864/54000 (68%)] Loss: -1473.498779\n",
      "Train Epoch: 212 [40960/54000 (76%)] Loss: -1480.794434\n",
      "Train Epoch: 212 [45056/54000 (83%)] Loss: -1477.934326\n",
      "Train Epoch: 212 [49152/54000 (91%)] Loss: -1481.696289\n",
      "Train Epoch: 212 [53248/54000 (99%)] Loss: -1486.337646\n",
      "    epoch          : 212\n",
      "    loss           : -1477.8484546245556\n",
      "    ess            : 3.7706524749502752\n",
      "    log_marginal   : 1477.9847770799392\n",
      "    val_loss       : -1478.1950378417969\n",
      "    val_ess        : 3.7799533208211265\n",
      "    val_log_marginal: 1478.3284556070964\n",
      "Train Epoch: 213 [0/54000 (0%)] Loss: -1467.511719\n",
      "Train Epoch: 213 [4096/54000 (8%)] Loss: -1481.611084\n",
      "Train Epoch: 213 [8192/54000 (15%)] Loss: -1474.716797\n",
      "Train Epoch: 213 [12288/54000 (23%)] Loss: -1474.377197\n",
      "Train Epoch: 213 [16384/54000 (30%)] Loss: -1476.413574\n",
      "Train Epoch: 213 [20480/54000 (38%)] Loss: -1476.350098\n",
      "Train Epoch: 213 [24576/54000 (46%)] Loss: -1475.027222\n",
      "Train Epoch: 213 [28672/54000 (53%)] Loss: -1473.611816\n",
      "Train Epoch: 213 [32768/54000 (61%)] Loss: -1476.270874\n",
      "Train Epoch: 213 [36864/54000 (68%)] Loss: -1474.029541\n",
      "Train Epoch: 213 [40960/54000 (76%)] Loss: -1483.018921\n",
      "Train Epoch: 213 [45056/54000 (83%)] Loss: -1468.851685\n",
      "Train Epoch: 213 [49152/54000 (91%)] Loss: -1481.199951\n",
      "Train Epoch: 213 [53248/54000 (99%)] Loss: -1479.475342\n",
      "    epoch          : 213\n",
      "    loss           : -1478.2310750518366\n",
      "    ess            : 3.7657038476229845\n",
      "    log_marginal   : 1478.3737133441944\n",
      "    val_loss       : -1476.7122802734375\n",
      "    val_ess        : 3.752579689025879\n",
      "    val_log_marginal: 1476.8644205729167\n",
      "Train Epoch: 214 [0/54000 (0%)] Loss: -1479.479492\n",
      "Train Epoch: 214 [4096/54000 (8%)] Loss: -1480.835571\n",
      "Train Epoch: 214 [8192/54000 (15%)] Loss: -1474.252197\n",
      "Train Epoch: 214 [12288/54000 (23%)] Loss: -1484.864014\n",
      "Train Epoch: 214 [16384/54000 (30%)] Loss: -1480.336914\n",
      "Train Epoch: 214 [20480/54000 (38%)] Loss: -1481.118652\n",
      "Train Epoch: 214 [24576/54000 (46%)] Loss: -1479.220703\n",
      "Train Epoch: 214 [28672/54000 (53%)] Loss: -1485.575195\n",
      "Train Epoch: 214 [32768/54000 (61%)] Loss: -1474.760986\n",
      "Train Epoch: 214 [36864/54000 (68%)] Loss: -1476.795410\n",
      "Train Epoch: 214 [40960/54000 (76%)] Loss: -1470.937988\n",
      "Train Epoch: 214 [45056/54000 (83%)] Loss: -1471.792114\n",
      "Train Epoch: 214 [49152/54000 (91%)] Loss: -1478.298462\n",
      "Train Epoch: 214 [53248/54000 (99%)] Loss: -1483.288696\n",
      "    epoch          : 214\n",
      "    loss           : -1478.7661607208975\n",
      "    ess            : 3.771762137164437\n",
      "    log_marginal   : 1478.90576171875\n",
      "    val_loss       : -1479.1878814697266\n",
      "    val_ess        : 3.7744682331879935\n",
      "    val_log_marginal: 1479.3156077067058\n",
      "Train Epoch: 215 [0/54000 (0%)] Loss: -1484.390625\n",
      "Train Epoch: 215 [4096/54000 (8%)] Loss: -1473.206177\n",
      "Train Epoch: 215 [8192/54000 (15%)] Loss: -1483.327637\n",
      "Train Epoch: 215 [12288/54000 (23%)] Loss: -1477.758057\n",
      "Train Epoch: 215 [16384/54000 (30%)] Loss: -1481.569580\n",
      "Train Epoch: 215 [20480/54000 (38%)] Loss: -1477.882568\n",
      "Train Epoch: 215 [24576/54000 (46%)] Loss: -1479.879639\n",
      "Train Epoch: 215 [28672/54000 (53%)] Loss: -1475.267090\n",
      "Train Epoch: 215 [32768/54000 (61%)] Loss: -1475.526001\n",
      "Train Epoch: 215 [36864/54000 (68%)] Loss: -1479.046631\n",
      "Train Epoch: 215 [40960/54000 (76%)] Loss: -1475.520142\n",
      "Train Epoch: 215 [45056/54000 (83%)] Loss: -1481.859497\n",
      "Train Epoch: 215 [49152/54000 (91%)] Loss: -1483.998169\n",
      "Train Epoch: 215 [53248/54000 (99%)] Loss: -1476.892822\n",
      "    epoch          : 215\n",
      "    loss           : -1479.3812770753111\n",
      "    ess            : 3.770271853813063\n",
      "    log_marginal   : 1479.5202463159064\n",
      "    val_loss       : -1479.3269755045574\n",
      "    val_ess        : 3.758224695920944\n",
      "    val_log_marginal: 1479.4763946533203\n",
      "Train Epoch: 216 [0/54000 (0%)] Loss: -1482.580811\n",
      "Train Epoch: 216 [4096/54000 (8%)] Loss: -1490.359863\n",
      "Train Epoch: 216 [8192/54000 (15%)] Loss: -1481.354492\n",
      "Train Epoch: 216 [12288/54000 (23%)] Loss: -1486.681030\n",
      "Train Epoch: 216 [16384/54000 (30%)] Loss: -1477.552002\n",
      "Train Epoch: 216 [20480/54000 (38%)] Loss: -1477.929199\n",
      "Train Epoch: 216 [24576/54000 (46%)] Loss: -1481.090332\n",
      "Train Epoch: 216 [28672/54000 (53%)] Loss: -1477.706543\n",
      "Train Epoch: 216 [32768/54000 (61%)] Loss: -1480.950195\n",
      "Train Epoch: 216 [36864/54000 (68%)] Loss: -1481.308105\n",
      "Train Epoch: 216 [40960/54000 (76%)] Loss: -1483.760986\n",
      "Train Epoch: 216 [45056/54000 (83%)] Loss: -1481.982422\n",
      "Train Epoch: 216 [49152/54000 (91%)] Loss: -1481.383423\n",
      "Train Epoch: 216 [53248/54000 (99%)] Loss: -1480.603394\n",
      "    epoch          : 216\n",
      "    loss           : -1480.3727275251777\n",
      "    ess            : 3.7691174254033237\n",
      "    log_marginal   : 1480.5143568572275\n",
      "    val_loss       : -1480.0085856119792\n",
      "    val_ess        : 3.7781545519828796\n",
      "    val_log_marginal: 1480.1366221110027\n",
      "Train Epoch: 217 [0/54000 (0%)] Loss: -1484.164551\n",
      "Train Epoch: 217 [4096/54000 (8%)] Loss: -1478.561768\n",
      "Train Epoch: 217 [8192/54000 (15%)] Loss: -1472.687256\n",
      "Train Epoch: 217 [12288/54000 (23%)] Loss: -1483.696167\n",
      "Train Epoch: 217 [16384/54000 (30%)] Loss: -1479.358032\n",
      "Train Epoch: 217 [20480/54000 (38%)] Loss: -1480.279541\n",
      "Train Epoch: 217 [24576/54000 (46%)] Loss: -1477.240112\n",
      "Train Epoch: 217 [28672/54000 (53%)] Loss: -1488.692505\n",
      "Train Epoch: 217 [32768/54000 (61%)] Loss: -1480.050781\n",
      "Train Epoch: 217 [36864/54000 (68%)] Loss: -1484.112793\n",
      "Train Epoch: 217 [40960/54000 (76%)] Loss: -1475.748291\n",
      "Train Epoch: 217 [45056/54000 (83%)] Loss: -1480.526978\n",
      "Train Epoch: 217 [49152/54000 (91%)] Loss: -1481.622803\n",
      "Train Epoch: 217 [53248/54000 (99%)] Loss: -1483.802856\n",
      "    epoch          : 217\n",
      "    loss           : -1480.7332902519624\n",
      "    ess            : 3.7698632936342067\n",
      "    log_marginal   : 1480.8716375703495\n",
      "    val_loss       : -1480.3225758870442\n",
      "    val_ess        : 3.7544685701529183\n",
      "    val_log_marginal: 1480.4746602376301\n",
      "Train Epoch: 218 [0/54000 (0%)] Loss: -1486.251221\n",
      "Train Epoch: 218 [4096/54000 (8%)] Loss: -1479.103027\n",
      "Train Epoch: 218 [8192/54000 (15%)] Loss: -1485.521484\n",
      "Train Epoch: 218 [12288/54000 (23%)] Loss: -1484.490479\n",
      "Train Epoch: 218 [16384/54000 (30%)] Loss: -1474.373047\n",
      "Train Epoch: 218 [20480/54000 (38%)] Loss: -1490.437744\n",
      "Train Epoch: 218 [24576/54000 (46%)] Loss: -1484.727295\n",
      "Train Epoch: 218 [28672/54000 (53%)] Loss: -1483.229004\n",
      "Train Epoch: 218 [32768/54000 (61%)] Loss: -1484.678223\n",
      "Train Epoch: 218 [36864/54000 (68%)] Loss: -1482.218750\n",
      "Train Epoch: 218 [40960/54000 (76%)] Loss: -1480.986816\n",
      "Train Epoch: 218 [45056/54000 (83%)] Loss: -1484.326172\n",
      "Train Epoch: 218 [49152/54000 (91%)] Loss: -1488.295410\n",
      "Train Epoch: 218 [53248/54000 (99%)] Loss: -1478.317261\n",
      "    epoch          : 218\n",
      "    loss           : -1481.8687281314797\n",
      "    ess            : 3.768148909247882\n",
      "    log_marginal   : 1482.0098090149215\n",
      "    val_loss       : -1480.6609598795574\n",
      "    val_ess        : 3.7843955059846244\n",
      "    val_log_marginal: 1480.7859344482422\n",
      "Train Epoch: 219 [0/54000 (0%)] Loss: -1479.971924\n",
      "Train Epoch: 219 [4096/54000 (8%)] Loss: -1487.203369\n",
      "Train Epoch: 219 [8192/54000 (15%)] Loss: -1480.856934\n",
      "Train Epoch: 219 [12288/54000 (23%)] Loss: -1486.284912\n",
      "Train Epoch: 219 [16384/54000 (30%)] Loss: -1477.906494\n",
      "Train Epoch: 219 [20480/54000 (38%)] Loss: -1481.867188\n",
      "Train Epoch: 219 [24576/54000 (46%)] Loss: -1475.497192\n",
      "Train Epoch: 219 [28672/54000 (53%)] Loss: -1479.711426\n",
      "Train Epoch: 219 [32768/54000 (61%)] Loss: -1481.883667\n",
      "Train Epoch: 219 [36864/54000 (68%)] Loss: -1480.720825\n",
      "Train Epoch: 219 [40960/54000 (76%)] Loss: -1491.323608\n",
      "Train Epoch: 219 [45056/54000 (83%)] Loss: -1478.557373\n",
      "Train Epoch: 219 [49152/54000 (91%)] Loss: -1486.119873\n",
      "Train Epoch: 219 [53248/54000 (99%)] Loss: -1478.895508\n",
      "    epoch          : 219\n",
      "    loss           : -1482.1188276390328\n",
      "    ess            : 3.7646133323416326\n",
      "    log_marginal   : 1482.2640247796949\n",
      "    val_loss       : -1481.1746419270833\n",
      "    val_ess        : 3.777192533016205\n",
      "    val_log_marginal: 1481.3106180826824\n",
      "Train Epoch: 220 [0/54000 (0%)] Loss: -1480.119385\n",
      "Train Epoch: 220 [4096/54000 (8%)] Loss: -1481.936401\n",
      "Train Epoch: 220 [8192/54000 (15%)] Loss: -1484.623291\n",
      "Train Epoch: 220 [12288/54000 (23%)] Loss: -1475.952393\n",
      "Train Epoch: 220 [16384/54000 (30%)] Loss: -1485.884888\n",
      "Train Epoch: 220 [20480/54000 (38%)] Loss: -1476.950684\n",
      "Train Epoch: 220 [24576/54000 (46%)] Loss: -1479.247803\n",
      "Train Epoch: 220 [28672/54000 (53%)] Loss: -1484.888916\n",
      "Train Epoch: 220 [32768/54000 (61%)] Loss: -1480.890991\n",
      "Train Epoch: 220 [36864/54000 (68%)] Loss: -1485.670044\n",
      "Train Epoch: 220 [40960/54000 (76%)] Loss: -1485.484863\n",
      "Train Epoch: 220 [45056/54000 (83%)] Loss: -1485.494873\n",
      "Train Epoch: 220 [49152/54000 (91%)] Loss: -1479.239868\n",
      "Train Epoch: 220 [53248/54000 (99%)] Loss: -1481.124268\n",
      "    epoch          : 220\n",
      "    loss           : -1483.2091579346861\n",
      "    ess            : 3.766666303878712\n",
      "    log_marginal   : 1483.3526310491336\n",
      "    val_loss       : -1483.1724294026692\n",
      "    val_ess        : 3.767020752032598\n",
      "    val_log_marginal: 1483.3162333170574\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch220.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 221 [0/54000 (0%)] Loss: -1474.995605\n",
      "Train Epoch: 221 [4096/54000 (8%)] Loss: -1481.036743\n",
      "Train Epoch: 221 [8192/54000 (15%)] Loss: -1486.695190\n",
      "Train Epoch: 221 [12288/54000 (23%)] Loss: -1476.864014\n",
      "Train Epoch: 221 [16384/54000 (30%)] Loss: -1483.231445\n",
      "Train Epoch: 221 [20480/54000 (38%)] Loss: -1483.260864\n",
      "Train Epoch: 221 [24576/54000 (46%)] Loss: -1490.287354\n",
      "Train Epoch: 221 [28672/54000 (53%)] Loss: -1484.411377\n",
      "Train Epoch: 221 [32768/54000 (61%)] Loss: -1484.058960\n",
      "Train Epoch: 221 [36864/54000 (68%)] Loss: -1484.568604\n",
      "Train Epoch: 221 [40960/54000 (76%)] Loss: -1482.992432\n",
      "Train Epoch: 221 [45056/54000 (83%)] Loss: -1479.741089\n",
      "Train Epoch: 221 [49152/54000 (91%)] Loss: -1485.652588\n",
      "Train Epoch: 221 [53248/54000 (99%)] Loss: -1488.516479\n",
      "    epoch          : 221\n",
      "    loss           : -1483.9473119075828\n",
      "    ess            : 3.771193161959897\n",
      "    log_marginal   : 1484.0873815165876\n",
      "    val_loss       : -1482.5844014485676\n",
      "    val_ess        : 3.7545557022094727\n",
      "    val_log_marginal: 1482.7322031656902\n",
      "Train Epoch: 222 [0/54000 (0%)] Loss: -1485.487915\n",
      "Train Epoch: 222 [4096/54000 (8%)] Loss: -1485.726562\n",
      "Train Epoch: 222 [8192/54000 (15%)] Loss: -1484.953247\n",
      "Train Epoch: 222 [12288/54000 (23%)] Loss: -1484.862305\n",
      "Train Epoch: 222 [16384/54000 (30%)] Loss: -1485.419434\n",
      "Train Epoch: 222 [20480/54000 (38%)] Loss: -1487.544678\n",
      "Train Epoch: 222 [24576/54000 (46%)] Loss: -1483.943115\n",
      "Train Epoch: 222 [28672/54000 (53%)] Loss: -1483.844727\n",
      "Train Epoch: 222 [32768/54000 (61%)] Loss: -1489.629395\n",
      "Train Epoch: 222 [36864/54000 (68%)] Loss: -1489.921021\n",
      "Train Epoch: 222 [40960/54000 (76%)] Loss: -1487.339844\n",
      "Train Epoch: 222 [45056/54000 (83%)] Loss: -1483.890015\n",
      "Train Epoch: 222 [49152/54000 (91%)] Loss: -1485.293213\n",
      "Train Epoch: 222 [53248/54000 (99%)] Loss: -1482.401733\n",
      "    epoch          : 222\n",
      "    loss           : -1484.2633137635146\n",
      "    ess            : 3.7614879732448343\n",
      "    log_marginal   : 1484.4105878350858\n",
      "    val_loss       : -1483.8954772949219\n",
      "    val_ess        : 3.796308239301046\n",
      "    val_log_marginal: 1484.0191853841145\n",
      "Train Epoch: 223 [0/54000 (0%)] Loss: -1484.470947\n",
      "Train Epoch: 223 [4096/54000 (8%)] Loss: -1481.636353\n",
      "Train Epoch: 223 [8192/54000 (15%)] Loss: -1488.143677\n",
      "Train Epoch: 223 [12288/54000 (23%)] Loss: -1479.709961\n",
      "Train Epoch: 223 [16384/54000 (30%)] Loss: -1480.482666\n",
      "Train Epoch: 223 [20480/54000 (38%)] Loss: -1478.930786\n",
      "Train Epoch: 223 [24576/54000 (46%)] Loss: -1488.958496\n",
      "Train Epoch: 223 [28672/54000 (53%)] Loss: -1478.863037\n",
      "Train Epoch: 223 [32768/54000 (61%)] Loss: -1485.121948\n",
      "Train Epoch: 223 [36864/54000 (68%)] Loss: -1485.104004\n",
      "Train Epoch: 223 [40960/54000 (76%)] Loss: -1475.918213\n",
      "Train Epoch: 223 [45056/54000 (83%)] Loss: -1482.877686\n",
      "Train Epoch: 223 [49152/54000 (91%)] Loss: -1490.108032\n",
      "Train Epoch: 223 [53248/54000 (99%)] Loss: -1485.303223\n",
      "    epoch          : 223\n",
      "    loss           : -1484.9252819766366\n",
      "    ess            : 3.7667592769550486\n",
      "    log_marginal   : 1485.0707446636181\n",
      "    val_loss       : -1483.853495279948\n",
      "    val_ess        : 3.7536971171696982\n",
      "    val_log_marginal: 1484.0037689208984\n",
      "Train Epoch: 224 [0/54000 (0%)] Loss: -1485.398926\n",
      "Train Epoch: 224 [4096/54000 (8%)] Loss: -1485.972534\n",
      "Train Epoch: 224 [8192/54000 (15%)] Loss: -1481.128784\n",
      "Train Epoch: 224 [12288/54000 (23%)] Loss: -1485.271240\n",
      "Train Epoch: 224 [16384/54000 (30%)] Loss: -1482.678955\n",
      "Train Epoch: 224 [20480/54000 (38%)] Loss: -1488.712891\n",
      "Train Epoch: 224 [24576/54000 (46%)] Loss: -1485.248901\n",
      "Train Epoch: 224 [28672/54000 (53%)] Loss: -1480.417358\n",
      "Train Epoch: 224 [32768/54000 (61%)] Loss: -1481.182861\n",
      "Train Epoch: 224 [36864/54000 (68%)] Loss: -1487.193970\n",
      "Train Epoch: 224 [40960/54000 (76%)] Loss: -1489.493896\n",
      "Train Epoch: 224 [45056/54000 (83%)] Loss: -1486.161499\n",
      "Train Epoch: 224 [49152/54000 (91%)] Loss: -1483.487549\n",
      "Train Epoch: 224 [53248/54000 (99%)] Loss: -1487.941772\n",
      "    epoch          : 224\n",
      "    loss           : -1485.3814697265625\n",
      "    ess            : 3.7679159042394557\n",
      "    log_marginal   : 1485.523074181724\n",
      "    val_loss       : -1484.52734375\n",
      "    val_ess        : 3.770969162384669\n",
      "    val_log_marginal: 1484.6585540771484\n",
      "Train Epoch: 225 [0/54000 (0%)] Loss: -1485.835449\n",
      "Train Epoch: 225 [4096/54000 (8%)] Loss: -1486.114990\n",
      "Train Epoch: 225 [8192/54000 (15%)] Loss: -1486.519897\n",
      "Train Epoch: 225 [12288/54000 (23%)] Loss: -1487.477783\n",
      "Train Epoch: 225 [16384/54000 (30%)] Loss: -1478.760376\n",
      "Train Epoch: 225 [20480/54000 (38%)] Loss: -1490.441650\n",
      "Train Epoch: 225 [24576/54000 (46%)] Loss: -1490.671143\n",
      "Train Epoch: 225 [28672/54000 (53%)] Loss: -1488.659546\n",
      "Train Epoch: 225 [32768/54000 (61%)] Loss: -1480.368042\n",
      "Train Epoch: 225 [36864/54000 (68%)] Loss: -1490.292480\n",
      "Train Epoch: 225 [40960/54000 (76%)] Loss: -1484.650146\n",
      "Train Epoch: 225 [45056/54000 (83%)] Loss: -1488.343140\n",
      "Train Epoch: 225 [49152/54000 (91%)] Loss: -1484.962891\n",
      "Train Epoch: 225 [53248/54000 (99%)] Loss: -1485.110352\n",
      "    epoch          : 225\n",
      "    loss           : -1486.0859247722897\n",
      "    ess            : 3.767795276867835\n",
      "    log_marginal   : 1486.2285752138255\n",
      "    val_loss       : -1485.2908477783203\n",
      "    val_ess        : 3.7719417909781137\n",
      "    val_log_marginal: 1485.4361114501953\n",
      "Train Epoch: 226 [0/54000 (0%)] Loss: -1483.962891\n",
      "Train Epoch: 226 [4096/54000 (8%)] Loss: -1489.818604\n",
      "Train Epoch: 226 [8192/54000 (15%)] Loss: -1486.373291\n",
      "Train Epoch: 226 [12288/54000 (23%)] Loss: -1483.838867\n",
      "Train Epoch: 226 [16384/54000 (30%)] Loss: -1490.685913\n",
      "Train Epoch: 226 [20480/54000 (38%)] Loss: -1485.843506\n",
      "Train Epoch: 226 [24576/54000 (46%)] Loss: -1485.104736\n",
      "Train Epoch: 226 [28672/54000 (53%)] Loss: -1483.966553\n",
      "Train Epoch: 226 [32768/54000 (61%)] Loss: -1488.446411\n",
      "Train Epoch: 226 [36864/54000 (68%)] Loss: -1480.824585\n",
      "Train Epoch: 226 [40960/54000 (76%)] Loss: -1486.382446\n",
      "Train Epoch: 226 [45056/54000 (83%)] Loss: -1488.794189\n",
      "Train Epoch: 226 [49152/54000 (91%)] Loss: -1500.678711\n",
      "Train Epoch: 226 [53248/54000 (99%)] Loss: -1480.241089\n",
      "    epoch          : 226\n",
      "    loss           : -1486.4458904537544\n",
      "    ess            : 3.7667717481676437\n",
      "    log_marginal   : 1486.5882631997927\n",
      "    val_loss       : -1485.2122395833333\n",
      "    val_ess        : 3.774718761444092\n",
      "    val_log_marginal: 1485.3464762369792\n",
      "Train Epoch: 227 [0/54000 (0%)] Loss: -1493.668213\n",
      "Train Epoch: 227 [4096/54000 (8%)] Loss: -1486.982422\n",
      "Train Epoch: 227 [8192/54000 (15%)] Loss: -1489.047363\n",
      "Train Epoch: 227 [12288/54000 (23%)] Loss: -1484.109619\n",
      "Train Epoch: 227 [16384/54000 (30%)] Loss: -1490.123169\n",
      "Train Epoch: 227 [20480/54000 (38%)] Loss: -1493.752808\n",
      "Train Epoch: 227 [24576/54000 (46%)] Loss: -1493.585205\n",
      "Train Epoch: 227 [28672/54000 (53%)] Loss: -1489.682129\n",
      "Train Epoch: 227 [32768/54000 (61%)] Loss: -1491.124512\n",
      "Train Epoch: 227 [36864/54000 (68%)] Loss: -1486.178223\n",
      "Train Epoch: 227 [40960/54000 (76%)] Loss: -1488.676270\n",
      "Train Epoch: 227 [45056/54000 (83%)] Loss: -1485.484009\n",
      "Train Epoch: 227 [49152/54000 (91%)] Loss: -1489.980225\n",
      "Train Epoch: 227 [53248/54000 (99%)] Loss: -1487.322388\n",
      "    epoch          : 227\n",
      "    loss           : -1487.3542324265034\n",
      "    ess            : 3.7643446029645005\n",
      "    log_marginal   : 1487.4984593685203\n",
      "    val_loss       : -1486.900639851888\n",
      "    val_ess        : 3.767021636168162\n",
      "    val_log_marginal: 1487.0392303466797\n",
      "Train Epoch: 228 [0/54000 (0%)] Loss: -1489.082275\n",
      "Train Epoch: 228 [4096/54000 (8%)] Loss: -1488.834229\n",
      "Train Epoch: 228 [8192/54000 (15%)] Loss: -1485.746338\n",
      "Train Epoch: 228 [12288/54000 (23%)] Loss: -1486.388550\n",
      "Train Epoch: 228 [16384/54000 (30%)] Loss: -1487.201416\n",
      "Train Epoch: 228 [20480/54000 (38%)] Loss: -1487.655884\n",
      "Train Epoch: 228 [24576/54000 (46%)] Loss: -1480.284790\n",
      "Train Epoch: 228 [28672/54000 (53%)] Loss: -1491.200439\n",
      "Train Epoch: 228 [32768/54000 (61%)] Loss: -1490.958618\n",
      "Train Epoch: 228 [36864/54000 (68%)] Loss: -1481.959473\n",
      "Train Epoch: 228 [40960/54000 (76%)] Loss: -1499.150879\n",
      "Train Epoch: 228 [45056/54000 (83%)] Loss: -1490.562378\n",
      "Train Epoch: 228 [49152/54000 (91%)] Loss: -1489.793213\n",
      "Train Epoch: 228 [53248/54000 (99%)] Loss: -1484.301270\n",
      "    epoch          : 228\n",
      "    loss           : -1487.622419167469\n",
      "    ess            : 3.766063397529566\n",
      "    log_marginal   : 1487.768502041062\n",
      "    val_loss       : -1486.784428914388\n",
      "    val_ess        : 3.766958018143972\n",
      "    val_log_marginal: 1486.9288380940754\n",
      "Train Epoch: 229 [0/54000 (0%)] Loss: -1492.909912\n",
      "Train Epoch: 229 [4096/54000 (8%)] Loss: -1488.537842\n",
      "Train Epoch: 229 [8192/54000 (15%)] Loss: -1492.704590\n",
      "Train Epoch: 229 [12288/54000 (23%)] Loss: -1481.290283\n",
      "Train Epoch: 229 [16384/54000 (30%)] Loss: -1487.435791\n",
      "Train Epoch: 229 [20480/54000 (38%)] Loss: -1492.228516\n",
      "Train Epoch: 229 [24576/54000 (46%)] Loss: -1491.431641\n",
      "Train Epoch: 229 [28672/54000 (53%)] Loss: -1492.617188\n",
      "Train Epoch: 229 [32768/54000 (61%)] Loss: -1486.759766\n",
      "Train Epoch: 229 [36864/54000 (68%)] Loss: -1488.328857\n",
      "Train Epoch: 229 [40960/54000 (76%)] Loss: -1491.101929\n",
      "Train Epoch: 229 [45056/54000 (83%)] Loss: -1483.986084\n",
      "Train Epoch: 229 [49152/54000 (91%)] Loss: -1482.192383\n",
      "Train Epoch: 229 [53248/54000 (99%)] Loss: -1484.671875\n",
      "    epoch          : 229\n",
      "    loss           : -1488.3724301595823\n",
      "    ess            : 3.771365291134441\n",
      "    log_marginal   : 1488.5124488577458\n",
      "    val_loss       : -1487.6238708496094\n",
      "    val_ess        : 3.7678145269552865\n",
      "    val_log_marginal: 1487.7651824951172\n",
      "Train Epoch: 230 [0/54000 (0%)] Loss: -1484.201904\n",
      "Train Epoch: 230 [4096/54000 (8%)] Loss: -1487.069214\n",
      "Train Epoch: 230 [8192/54000 (15%)] Loss: -1481.273193\n",
      "Train Epoch: 230 [12288/54000 (23%)] Loss: -1493.984131\n",
      "Train Epoch: 230 [16384/54000 (30%)] Loss: -1489.893677\n",
      "Train Epoch: 230 [20480/54000 (38%)] Loss: -1491.800049\n",
      "Train Epoch: 230 [24576/54000 (46%)] Loss: -1485.358154\n",
      "Train Epoch: 230 [28672/54000 (53%)] Loss: -1489.284424\n",
      "Train Epoch: 230 [32768/54000 (61%)] Loss: -1484.471924\n",
      "Train Epoch: 230 [36864/54000 (68%)] Loss: -1492.311035\n",
      "Train Epoch: 230 [40960/54000 (76%)] Loss: -1491.297363\n",
      "Train Epoch: 230 [45056/54000 (83%)] Loss: -1493.910645\n",
      "Train Epoch: 230 [49152/54000 (91%)] Loss: -1488.543701\n",
      "Train Epoch: 230 [53248/54000 (99%)] Loss: -1486.090088\n",
      "    epoch          : 230\n",
      "    loss           : -1488.8402377304872\n",
      "    ess            : 3.7682043590816843\n",
      "    log_marginal   : 1488.9847001351452\n",
      "    val_loss       : -1488.501988728841\n",
      "    val_ess        : 3.775600790977478\n",
      "    val_log_marginal: 1488.640625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch230.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 231 [0/54000 (0%)] Loss: -1495.261841\n",
      "Train Epoch: 231 [4096/54000 (8%)] Loss: -1485.609375\n",
      "Train Epoch: 231 [8192/54000 (15%)] Loss: -1489.302734\n",
      "Train Epoch: 231 [12288/54000 (23%)] Loss: -1495.944580\n",
      "Train Epoch: 231 [16384/54000 (30%)] Loss: -1483.046143\n",
      "Train Epoch: 231 [20480/54000 (38%)] Loss: -1490.528076\n",
      "Train Epoch: 231 [24576/54000 (46%)] Loss: -1484.439087\n",
      "Train Epoch: 231 [28672/54000 (53%)] Loss: -1479.706055\n",
      "Train Epoch: 231 [32768/54000 (61%)] Loss: -1497.548340\n",
      "Train Epoch: 231 [36864/54000 (68%)] Loss: -1487.942383\n",
      "Train Epoch: 231 [40960/54000 (76%)] Loss: -1492.753906\n",
      "Train Epoch: 231 [45056/54000 (83%)] Loss: -1491.225830\n",
      "Train Epoch: 231 [49152/54000 (91%)] Loss: -1485.932495\n",
      "Train Epoch: 231 [53248/54000 (99%)] Loss: -1485.851074\n",
      "    epoch          : 231\n",
      "    loss           : -1489.2517946071534\n",
      "    ess            : 3.7685730197418357\n",
      "    log_marginal   : 1489.3952821849082\n",
      "    val_loss       : -1489.1261749267578\n",
      "    val_ess        : 3.769549955924352\n",
      "    val_log_marginal: 1489.2621002197266\n",
      "Train Epoch: 232 [0/54000 (0%)] Loss: -1499.160400\n",
      "Train Epoch: 232 [4096/54000 (8%)] Loss: -1492.931885\n",
      "Train Epoch: 232 [8192/54000 (15%)] Loss: -1491.426514\n",
      "Train Epoch: 232 [12288/54000 (23%)] Loss: -1492.233643\n",
      "Train Epoch: 232 [16384/54000 (30%)] Loss: -1489.711792\n",
      "Train Epoch: 232 [20480/54000 (38%)] Loss: -1496.282715\n",
      "Train Epoch: 232 [24576/54000 (46%)] Loss: -1487.829834\n",
      "Train Epoch: 232 [28672/54000 (53%)] Loss: -1491.722900\n",
      "Train Epoch: 232 [32768/54000 (61%)] Loss: -1492.551270\n",
      "Train Epoch: 232 [36864/54000 (68%)] Loss: -1490.205566\n",
      "Train Epoch: 232 [40960/54000 (76%)] Loss: -1493.385254\n",
      "Train Epoch: 232 [45056/54000 (83%)] Loss: -1496.313354\n",
      "Train Epoch: 232 [49152/54000 (91%)] Loss: -1486.936279\n",
      "Train Epoch: 232 [53248/54000 (99%)] Loss: -1488.785889\n",
      "    epoch          : 232\n",
      "    loss           : -1490.0036476460677\n",
      "    ess            : 3.766392097653936\n",
      "    log_marginal   : 1490.148181210197\n",
      "    val_loss       : -1489.6699930826824\n",
      "    val_ess        : 3.7640656729539237\n",
      "    val_log_marginal: 1489.8129374186199\n",
      "Train Epoch: 233 [0/54000 (0%)] Loss: -1491.487793\n",
      "Train Epoch: 233 [4096/54000 (8%)] Loss: -1486.990845\n",
      "Train Epoch: 233 [8192/54000 (15%)] Loss: -1485.848633\n",
      "Train Epoch: 233 [12288/54000 (23%)] Loss: -1497.353271\n",
      "Train Epoch: 233 [16384/54000 (30%)] Loss: -1490.814209\n",
      "Train Epoch: 233 [20480/54000 (38%)] Loss: -1493.258545\n",
      "Train Epoch: 233 [24576/54000 (46%)] Loss: -1486.782471\n",
      "Train Epoch: 233 [28672/54000 (53%)] Loss: -1490.716431\n",
      "Train Epoch: 233 [32768/54000 (61%)] Loss: -1485.878906\n",
      "Train Epoch: 233 [36864/54000 (68%)] Loss: -1490.677002\n",
      "Train Epoch: 233 [40960/54000 (76%)] Loss: -1491.025391\n",
      "Train Epoch: 233 [45056/54000 (83%)] Loss: -1486.558228\n",
      "Train Epoch: 233 [49152/54000 (91%)] Loss: -1487.246216\n",
      "Train Epoch: 233 [53248/54000 (99%)] Loss: -1494.336182\n",
      "    epoch          : 233\n",
      "    loss           : -1490.366249120631\n",
      "    ess            : 3.7690706637233355\n",
      "    log_marginal   : 1490.5086241807983\n",
      "    val_loss       : -1490.1174977620442\n",
      "    val_ess        : 3.7738213737805686\n",
      "    val_log_marginal: 1490.251968383789\n",
      "Train Epoch: 234 [0/54000 (0%)] Loss: -1495.701294\n",
      "Train Epoch: 234 [4096/54000 (8%)] Loss: -1489.638672\n",
      "Train Epoch: 234 [8192/54000 (15%)] Loss: -1495.079346\n",
      "Train Epoch: 234 [12288/54000 (23%)] Loss: -1488.534180\n",
      "Train Epoch: 234 [16384/54000 (30%)] Loss: -1492.524048\n",
      "Train Epoch: 234 [20480/54000 (38%)] Loss: -1490.417603\n",
      "Train Epoch: 234 [24576/54000 (46%)] Loss: -1493.518311\n",
      "Train Epoch: 234 [28672/54000 (53%)] Loss: -1493.495483\n",
      "Train Epoch: 234 [32768/54000 (61%)] Loss: -1493.782837\n",
      "Train Epoch: 234 [36864/54000 (68%)] Loss: -1489.244873\n",
      "Train Epoch: 234 [40960/54000 (76%)] Loss: -1488.870850\n",
      "Train Epoch: 234 [45056/54000 (83%)] Loss: -1487.999756\n",
      "Train Epoch: 234 [49152/54000 (91%)] Loss: -1491.512207\n",
      "Train Epoch: 234 [53248/54000 (99%)] Loss: -1495.718018\n",
      "    epoch          : 234\n",
      "    loss           : -1490.8559263690388\n",
      "    ess            : 3.7706898332207124\n",
      "    log_marginal   : 1490.9962736735413\n",
      "    val_loss       : -1489.9239095052083\n",
      "    val_ess        : 3.771835118532181\n",
      "    val_log_marginal: 1490.0635681152344\n",
      "Train Epoch: 235 [0/54000 (0%)] Loss: -1488.993042\n",
      "Train Epoch: 235 [4096/54000 (8%)] Loss: -1492.017578\n",
      "Train Epoch: 235 [8192/54000 (15%)] Loss: -1491.041626\n",
      "Train Epoch: 235 [12288/54000 (23%)] Loss: -1492.117554\n",
      "Train Epoch: 235 [16384/54000 (30%)] Loss: -1494.562378\n",
      "Train Epoch: 235 [20480/54000 (38%)] Loss: -1482.756470\n",
      "Train Epoch: 235 [24576/54000 (46%)] Loss: -1489.570068\n",
      "Train Epoch: 235 [28672/54000 (53%)] Loss: -1487.277588\n",
      "Train Epoch: 235 [32768/54000 (61%)] Loss: -1490.441895\n",
      "Train Epoch: 235 [36864/54000 (68%)] Loss: -1495.170044\n",
      "Train Epoch: 235 [40960/54000 (76%)] Loss: -1492.102173\n",
      "Train Epoch: 235 [45056/54000 (83%)] Loss: -1489.562744\n",
      "Train Epoch: 235 [49152/54000 (91%)] Loss: -1491.921387\n",
      "Train Epoch: 235 [53248/54000 (99%)] Loss: -1491.452637\n",
      "    epoch          : 235\n",
      "    loss           : -1491.0794197552577\n",
      "    ess            : 3.7678116509134734\n",
      "    log_marginal   : 1491.219779208938\n",
      "    val_loss       : -1490.7700805664062\n",
      "    val_ess        : 3.762012133995692\n",
      "    val_log_marginal: 1490.9104614257812\n",
      "Train Epoch: 236 [0/54000 (0%)] Loss: -1491.373657\n",
      "Train Epoch: 236 [4096/54000 (8%)] Loss: -1483.496826\n",
      "Train Epoch: 236 [8192/54000 (15%)] Loss: -1485.738281\n",
      "Train Epoch: 236 [12288/54000 (23%)] Loss: -1489.911743\n",
      "Train Epoch: 236 [16384/54000 (30%)] Loss: -1488.025635\n",
      "Train Epoch: 236 [20480/54000 (38%)] Loss: -1489.363770\n",
      "Train Epoch: 236 [24576/54000 (46%)] Loss: -1486.399170\n",
      "Train Epoch: 236 [28672/54000 (53%)] Loss: -1494.943848\n",
      "Train Epoch: 236 [32768/54000 (61%)] Loss: -1491.138916\n",
      "Train Epoch: 236 [36864/54000 (68%)] Loss: -1496.551880\n",
      "Train Epoch: 236 [40960/54000 (76%)] Loss: -1491.290527\n",
      "Train Epoch: 236 [45056/54000 (83%)] Loss: -1490.728760\n",
      "Train Epoch: 236 [49152/54000 (91%)] Loss: -1485.726562\n",
      "Train Epoch: 236 [53248/54000 (99%)] Loss: -1491.960815\n",
      "    epoch          : 236\n",
      "    loss           : -1491.7886239725267\n",
      "    ess            : 3.765269825243837\n",
      "    log_marginal   : 1491.930397359116\n",
      "    val_loss       : -1492.2987874348958\n",
      "    val_ess        : 3.768555243810018\n",
      "    val_log_marginal: 1492.4423828125\n",
      "Train Epoch: 237 [0/54000 (0%)] Loss: -1500.009888\n",
      "Train Epoch: 237 [4096/54000 (8%)] Loss: -1494.431519\n",
      "Train Epoch: 237 [8192/54000 (15%)] Loss: -1499.002563\n",
      "Train Epoch: 237 [12288/54000 (23%)] Loss: -1494.339844\n",
      "Train Epoch: 237 [16384/54000 (30%)] Loss: -1488.393677\n",
      "Train Epoch: 237 [20480/54000 (38%)] Loss: -1485.564819\n",
      "Train Epoch: 237 [24576/54000 (46%)] Loss: -1491.468750\n",
      "Train Epoch: 237 [28672/54000 (53%)] Loss: -1488.290039\n",
      "Train Epoch: 237 [32768/54000 (61%)] Loss: -1487.914551\n",
      "Train Epoch: 237 [36864/54000 (68%)] Loss: -1492.094849\n",
      "Train Epoch: 237 [40960/54000 (76%)] Loss: -1491.030029\n",
      "Train Epoch: 237 [45056/54000 (83%)] Loss: -1493.036011\n",
      "Train Epoch: 237 [49152/54000 (91%)] Loss: -1498.201782\n",
      "Train Epoch: 237 [53248/54000 (99%)] Loss: -1492.275269\n",
      "    epoch          : 237\n",
      "    loss           : -1492.2647872852488\n",
      "    ess            : 3.7701013031729023\n",
      "    log_marginal   : 1492.407547647919\n",
      "    val_loss       : -1493.1122741699219\n",
      "    val_ess        : 3.781374235947927\n",
      "    val_log_marginal: 1493.2403462727864\n",
      "Train Epoch: 238 [0/54000 (0%)] Loss: -1501.453125\n",
      "Train Epoch: 238 [4096/54000 (8%)] Loss: -1493.867676\n",
      "Train Epoch: 238 [8192/54000 (15%)] Loss: -1490.479248\n",
      "Train Epoch: 238 [12288/54000 (23%)] Loss: -1501.155762\n",
      "Train Epoch: 238 [16384/54000 (30%)] Loss: -1498.700195\n",
      "Train Epoch: 238 [20480/54000 (38%)] Loss: -1492.144287\n",
      "Train Epoch: 238 [24576/54000 (46%)] Loss: -1495.872192\n",
      "Train Epoch: 238 [28672/54000 (53%)] Loss: -1489.794922\n",
      "Train Epoch: 238 [32768/54000 (61%)] Loss: -1488.025635\n",
      "Train Epoch: 238 [36864/54000 (68%)] Loss: -1493.625488\n",
      "Train Epoch: 238 [40960/54000 (76%)] Loss: -1485.668945\n",
      "Train Epoch: 238 [45056/54000 (83%)] Loss: -1488.132935\n",
      "Train Epoch: 238 [49152/54000 (91%)] Loss: -1489.083740\n",
      "Train Epoch: 238 [53248/54000 (99%)] Loss: -1491.222656\n",
      "    epoch          : 238\n",
      "    loss           : -1492.6955693683353\n",
      "    ess            : 3.7699312067709827\n",
      "    log_marginal   : 1492.8368267041246\n",
      "    val_loss       : -1492.1866607666016\n",
      "    val_ess        : 3.7797183096408844\n",
      "    val_log_marginal: 1492.315185546875\n",
      "Train Epoch: 239 [0/54000 (0%)] Loss: -1489.699829\n",
      "Train Epoch: 239 [4096/54000 (8%)] Loss: -1495.228027\n",
      "Train Epoch: 239 [8192/54000 (15%)] Loss: -1499.195312\n",
      "Train Epoch: 239 [12288/54000 (23%)] Loss: -1495.064209\n",
      "Train Epoch: 239 [16384/54000 (30%)] Loss: -1489.429688\n",
      "Train Epoch: 239 [20480/54000 (38%)] Loss: -1493.659302\n",
      "Train Epoch: 239 [24576/54000 (46%)] Loss: -1496.442749\n",
      "Train Epoch: 239 [28672/54000 (53%)] Loss: -1497.513916\n",
      "Train Epoch: 239 [32768/54000 (61%)] Loss: -1495.398560\n",
      "Train Epoch: 239 [36864/54000 (68%)] Loss: -1494.375366\n",
      "Train Epoch: 239 [40960/54000 (76%)] Loss: -1494.295044\n",
      "Train Epoch: 239 [45056/54000 (83%)] Loss: -1492.243042\n",
      "Train Epoch: 239 [49152/54000 (91%)] Loss: -1494.340332\n",
      "Train Epoch: 239 [53248/54000 (99%)] Loss: -1492.144409\n",
      "    epoch          : 239\n",
      "    loss           : -1493.0578798411582\n",
      "    ess            : 3.7701644264691248\n",
      "    log_marginal   : 1493.19885948145\n",
      "    val_loss       : -1492.0948282877605\n",
      "    val_ess        : 3.7561164995034537\n",
      "    val_log_marginal: 1492.2541097005208\n",
      "Train Epoch: 240 [0/54000 (0%)] Loss: -1491.671143\n",
      "Train Epoch: 240 [4096/54000 (8%)] Loss: -1487.669922\n",
      "Train Epoch: 240 [8192/54000 (15%)] Loss: -1488.970215\n",
      "Train Epoch: 240 [12288/54000 (23%)] Loss: -1486.056030\n",
      "Train Epoch: 240 [16384/54000 (30%)] Loss: -1497.310303\n",
      "Train Epoch: 240 [20480/54000 (38%)] Loss: -1489.064209\n",
      "Train Epoch: 240 [24576/54000 (46%)] Loss: -1495.570923\n",
      "Train Epoch: 240 [28672/54000 (53%)] Loss: -1494.394165\n",
      "Train Epoch: 240 [32768/54000 (61%)] Loss: -1495.975708\n",
      "Train Epoch: 240 [36864/54000 (68%)] Loss: -1500.782471\n",
      "Train Epoch: 240 [40960/54000 (76%)] Loss: -1492.411621\n",
      "Train Epoch: 240 [45056/54000 (83%)] Loss: -1492.690186\n",
      "Train Epoch: 240 [49152/54000 (91%)] Loss: -1499.014160\n",
      "Train Epoch: 240 [53248/54000 (99%)] Loss: -1490.022583\n",
      "    epoch          : 240\n",
      "    loss           : -1493.5501870973414\n",
      "    ess            : 3.772269225233539\n",
      "    log_marginal   : 1493.6917927095676\n",
      "    val_loss       : -1493.384033203125\n",
      "    val_ess        : 3.7832875847816467\n",
      "    val_log_marginal: 1493.5198720296223\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch240.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 241 [0/54000 (0%)] Loss: -1498.677490\n",
      "Train Epoch: 241 [4096/54000 (8%)] Loss: -1494.359375\n",
      "Train Epoch: 241 [8192/54000 (15%)] Loss: -1492.756592\n",
      "Train Epoch: 241 [12288/54000 (23%)] Loss: -1493.451172\n",
      "Train Epoch: 241 [16384/54000 (30%)] Loss: -1489.794434\n",
      "Train Epoch: 241 [20480/54000 (38%)] Loss: -1497.091309\n",
      "Train Epoch: 241 [24576/54000 (46%)] Loss: -1499.834839\n",
      "Train Epoch: 241 [28672/54000 (53%)] Loss: -1492.437256\n",
      "Train Epoch: 241 [32768/54000 (61%)] Loss: -1487.464355\n",
      "Train Epoch: 241 [36864/54000 (68%)] Loss: -1495.601318\n",
      "Train Epoch: 241 [40960/54000 (76%)] Loss: -1494.064819\n",
      "Train Epoch: 241 [45056/54000 (83%)] Loss: -1494.996460\n",
      "Train Epoch: 241 [49152/54000 (91%)] Loss: -1500.358398\n",
      "Train Epoch: 241 [53248/54000 (99%)] Loss: -1499.084473\n",
      "    epoch          : 241\n",
      "    loss           : -1494.3311102265995\n",
      "    ess            : 3.7717580524101075\n",
      "    log_marginal   : 1494.4704786544728\n",
      "    val_loss       : -1493.498814900716\n",
      "    val_ess        : 3.7719902197519937\n",
      "    val_log_marginal: 1493.6355489095051\n",
      "Train Epoch: 242 [0/54000 (0%)] Loss: -1488.553711\n",
      "Train Epoch: 242 [4096/54000 (8%)] Loss: -1491.546509\n",
      "Train Epoch: 242 [8192/54000 (15%)] Loss: -1495.094238\n",
      "Train Epoch: 242 [12288/54000 (23%)] Loss: -1492.082275\n",
      "Train Epoch: 242 [16384/54000 (30%)] Loss: -1488.707397\n",
      "Train Epoch: 242 [20480/54000 (38%)] Loss: -1492.385254\n",
      "Train Epoch: 242 [24576/54000 (46%)] Loss: -1499.554443\n",
      "Train Epoch: 242 [28672/54000 (53%)] Loss: -1494.722656\n",
      "Train Epoch: 242 [32768/54000 (61%)] Loss: -1494.632324\n",
      "Train Epoch: 242 [36864/54000 (68%)] Loss: -1493.529785\n",
      "Train Epoch: 242 [40960/54000 (76%)] Loss: -1495.877930\n",
      "Train Epoch: 242 [45056/54000 (83%)] Loss: -1489.934937\n",
      "Train Epoch: 242 [49152/54000 (91%)] Loss: -1493.690430\n",
      "Train Epoch: 242 [53248/54000 (99%)] Loss: -1495.847778\n",
      "    epoch          : 242\n",
      "    loss           : -1494.9267485559835\n",
      "    ess            : 3.767018127215417\n",
      "    log_marginal   : 1495.0704808528953\n",
      "    val_loss       : -1494.6930135091145\n",
      "    val_ess        : 3.7724349399407706\n",
      "    val_log_marginal: 1494.8341369628906\n",
      "Train Epoch: 243 [0/54000 (0%)] Loss: -1488.874268\n",
      "Train Epoch: 243 [4096/54000 (8%)] Loss: -1495.936035\n",
      "Train Epoch: 243 [8192/54000 (15%)] Loss: -1497.243408\n",
      "Train Epoch: 243 [12288/54000 (23%)] Loss: -1499.743652\n",
      "Train Epoch: 243 [16384/54000 (30%)] Loss: -1495.083008\n",
      "Train Epoch: 243 [20480/54000 (38%)] Loss: -1496.335327\n",
      "Train Epoch: 243 [24576/54000 (46%)] Loss: -1492.839355\n",
      "Train Epoch: 243 [28672/54000 (53%)] Loss: -1492.907715\n",
      "Train Epoch: 243 [32768/54000 (61%)] Loss: -1496.375488\n",
      "Train Epoch: 243 [36864/54000 (68%)] Loss: -1499.280273\n",
      "Train Epoch: 243 [40960/54000 (76%)] Loss: -1493.477051\n",
      "Train Epoch: 243 [45056/54000 (83%)] Loss: -1497.053955\n",
      "Train Epoch: 243 [49152/54000 (91%)] Loss: -1496.703491\n",
      "Train Epoch: 243 [53248/54000 (99%)] Loss: -1498.647583\n",
      "    epoch          : 243\n",
      "    loss           : -1495.1923920690165\n",
      "    ess            : 3.7695767088523975\n",
      "    log_marginal   : 1495.333350882146\n",
      "    val_loss       : -1495.2167154947917\n",
      "    val_ess        : 3.7654712200164795\n",
      "    val_log_marginal: 1495.3607025146484\n",
      "Train Epoch: 244 [0/54000 (0%)] Loss: -1487.259888\n",
      "Train Epoch: 244 [4096/54000 (8%)] Loss: -1492.012695\n",
      "Train Epoch: 244 [8192/54000 (15%)] Loss: -1499.642334\n",
      "Train Epoch: 244 [12288/54000 (23%)] Loss: -1493.634644\n",
      "Train Epoch: 244 [16384/54000 (30%)] Loss: -1497.273438\n",
      "Train Epoch: 244 [20480/54000 (38%)] Loss: -1498.670410\n",
      "Train Epoch: 244 [24576/54000 (46%)] Loss: -1500.660889\n",
      "Train Epoch: 244 [28672/54000 (53%)] Loss: -1496.178101\n",
      "Train Epoch: 244 [32768/54000 (61%)] Loss: -1495.755371\n",
      "Train Epoch: 244 [36864/54000 (68%)] Loss: -1495.607056\n",
      "Train Epoch: 244 [40960/54000 (76%)] Loss: -1496.103516\n",
      "Train Epoch: 244 [45056/54000 (83%)] Loss: -1491.580811\n",
      "Train Epoch: 244 [49152/54000 (91%)] Loss: -1496.055176\n",
      "Train Epoch: 244 [53248/54000 (99%)] Loss: -1499.062866\n",
      "    epoch          : 244\n",
      "    loss           : -1495.7258711539173\n",
      "    ess            : 3.771526378477919\n",
      "    log_marginal   : 1495.868341671912\n",
      "    val_loss       : -1494.2305857340496\n",
      "    val_ess        : 3.7757977843284607\n",
      "    val_log_marginal: 1494.3706563313801\n",
      "Train Epoch: 245 [0/54000 (0%)] Loss: -1493.726807\n",
      "Train Epoch: 245 [4096/54000 (8%)] Loss: -1494.713623\n",
      "Train Epoch: 245 [8192/54000 (15%)] Loss: -1491.874512\n",
      "Train Epoch: 245 [12288/54000 (23%)] Loss: -1505.263672\n",
      "Train Epoch: 245 [16384/54000 (30%)] Loss: -1495.982666\n",
      "Train Epoch: 245 [20480/54000 (38%)] Loss: -1489.468506\n",
      "Train Epoch: 245 [24576/54000 (46%)] Loss: -1497.012939\n",
      "Train Epoch: 245 [28672/54000 (53%)] Loss: -1497.203369\n",
      "Train Epoch: 245 [32768/54000 (61%)] Loss: -1493.883057\n",
      "Train Epoch: 245 [36864/54000 (68%)] Loss: -1493.280762\n",
      "Train Epoch: 245 [40960/54000 (76%)] Loss: -1497.585693\n",
      "Train Epoch: 245 [45056/54000 (83%)] Loss: -1497.225098\n",
      "Train Epoch: 245 [49152/54000 (91%)] Loss: -1497.174072\n",
      "Train Epoch: 245 [53248/54000 (99%)] Loss: -1494.464233\n",
      "    epoch          : 245\n",
      "    loss           : -1496.1910521882405\n",
      "    ess            : 3.7669071687906275\n",
      "    log_marginal   : 1496.3343124028065\n",
      "    val_loss       : -1496.1071217854817\n",
      "    val_ess        : 3.77370023727417\n",
      "    val_log_marginal: 1496.2481638590496\n",
      "Train Epoch: 246 [0/54000 (0%)] Loss: -1496.855225\n",
      "Train Epoch: 246 [4096/54000 (8%)] Loss: -1497.920044\n",
      "Train Epoch: 246 [8192/54000 (15%)] Loss: -1498.827148\n",
      "Train Epoch: 246 [12288/54000 (23%)] Loss: -1499.805664\n",
      "Train Epoch: 246 [16384/54000 (30%)] Loss: -1495.828369\n",
      "Train Epoch: 246 [20480/54000 (38%)] Loss: -1501.569824\n",
      "Train Epoch: 246 [24576/54000 (46%)] Loss: -1497.983643\n",
      "Train Epoch: 246 [28672/54000 (53%)] Loss: -1495.813599\n",
      "Train Epoch: 246 [32768/54000 (61%)] Loss: -1503.128906\n",
      "Train Epoch: 246 [36864/54000 (68%)] Loss: -1497.990356\n",
      "Train Epoch: 246 [40960/54000 (76%)] Loss: -1494.772949\n",
      "Train Epoch: 246 [45056/54000 (83%)] Loss: -1493.872314\n",
      "Train Epoch: 246 [49152/54000 (91%)] Loss: -1496.945190\n",
      "Train Epoch: 246 [53248/54000 (99%)] Loss: -1494.791992\n",
      "    epoch          : 246\n",
      "    loss           : -1496.2027368048357\n",
      "    ess            : 3.765853042286154\n",
      "    log_marginal   : 1496.3495538359005\n",
      "    val_loss       : -1495.7153625488281\n",
      "    val_ess        : 3.773780047893524\n",
      "    val_log_marginal: 1495.8504994710286\n",
      "Train Epoch: 247 [0/54000 (0%)] Loss: -1496.737061\n",
      "Train Epoch: 247 [4096/54000 (8%)] Loss: -1500.910767\n",
      "Train Epoch: 247 [8192/54000 (15%)] Loss: -1492.468750\n",
      "Train Epoch: 247 [12288/54000 (23%)] Loss: -1494.978882\n",
      "Train Epoch: 247 [16384/54000 (30%)] Loss: -1494.270020\n",
      "Train Epoch: 247 [20480/54000 (38%)] Loss: -1502.037720\n",
      "Train Epoch: 247 [24576/54000 (46%)] Loss: -1497.591064\n",
      "Train Epoch: 247 [28672/54000 (53%)] Loss: -1502.601318\n",
      "Train Epoch: 247 [32768/54000 (61%)] Loss: -1497.962891\n",
      "Train Epoch: 247 [36864/54000 (68%)] Loss: -1500.464600\n",
      "Train Epoch: 247 [40960/54000 (76%)] Loss: -1490.091431\n",
      "Train Epoch: 247 [45056/54000 (83%)] Loss: -1489.185547\n",
      "Train Epoch: 247 [49152/54000 (91%)] Loss: -1502.023438\n",
      "Train Epoch: 247 [53248/54000 (99%)] Loss: -1494.081299\n",
      "    epoch          : 247\n",
      "    loss           : -1496.765124569572\n",
      "    ess            : 3.767251498326306\n",
      "    log_marginal   : 1496.9083784202828\n",
      "    val_loss       : -1495.3497772216797\n",
      "    val_ess        : 3.770340214172999\n",
      "    val_log_marginal: 1495.489990234375\n",
      "Train Epoch: 248 [0/54000 (0%)] Loss: -1499.489502\n",
      "Train Epoch: 248 [4096/54000 (8%)] Loss: -1494.794434\n",
      "Train Epoch: 248 [8192/54000 (15%)] Loss: -1499.967041\n",
      "Train Epoch: 248 [12288/54000 (23%)] Loss: -1493.958496\n",
      "Train Epoch: 248 [16384/54000 (30%)] Loss: -1500.943115\n",
      "Train Epoch: 248 [20480/54000 (38%)] Loss: -1494.358032\n",
      "Train Epoch: 248 [24576/54000 (46%)] Loss: -1498.090820\n",
      "Train Epoch: 248 [28672/54000 (53%)] Loss: -1498.002319\n",
      "Train Epoch: 248 [32768/54000 (61%)] Loss: -1491.536743\n",
      "Train Epoch: 248 [36864/54000 (68%)] Loss: -1492.793457\n",
      "Train Epoch: 248 [40960/54000 (76%)] Loss: -1497.357910\n",
      "Train Epoch: 248 [45056/54000 (83%)] Loss: -1495.791504\n",
      "Train Epoch: 248 [49152/54000 (91%)] Loss: -1497.657959\n",
      "Train Epoch: 248 [53248/54000 (99%)] Loss: -1496.322510\n",
      "    epoch          : 248\n",
      "    loss           : -1497.5490664803021\n",
      "    ess            : 3.767433141645097\n",
      "    log_marginal   : 1497.694334201903\n",
      "    val_loss       : -1496.4617360432942\n",
      "    val_ess        : 3.7685933907826743\n",
      "    val_log_marginal: 1496.596928914388\n",
      "Train Epoch: 249 [0/54000 (0%)] Loss: -1497.796387\n",
      "Train Epoch: 249 [4096/54000 (8%)] Loss: -1502.484863\n",
      "Train Epoch: 249 [8192/54000 (15%)] Loss: -1491.561768\n",
      "Train Epoch: 249 [12288/54000 (23%)] Loss: -1504.747803\n",
      "Train Epoch: 249 [16384/54000 (30%)] Loss: -1503.325562\n",
      "Train Epoch: 249 [20480/54000 (38%)] Loss: -1493.360352\n",
      "Train Epoch: 249 [24576/54000 (46%)] Loss: -1502.300903\n",
      "Train Epoch: 249 [28672/54000 (53%)] Loss: -1500.160278\n",
      "Train Epoch: 249 [32768/54000 (61%)] Loss: -1493.982666\n",
      "Train Epoch: 249 [36864/54000 (68%)] Loss: -1505.981812\n",
      "Train Epoch: 249 [40960/54000 (76%)] Loss: -1498.666870\n",
      "Train Epoch: 249 [45056/54000 (83%)] Loss: -1489.070923\n",
      "Train Epoch: 249 [49152/54000 (91%)] Loss: -1501.479492\n",
      "Train Epoch: 249 [53248/54000 (99%)] Loss: -1490.073608\n",
      "    epoch          : 249\n",
      "    loss           : -1498.1724876656917\n",
      "    ess            : 3.7633865207292456\n",
      "    log_marginal   : 1498.319358500259\n",
      "    val_loss       : -1496.9361673990886\n",
      "    val_ess        : 3.7620520691076913\n",
      "    val_log_marginal: 1497.085220336914\n",
      "Train Epoch: 250 [0/54000 (0%)] Loss: -1498.711670\n",
      "Train Epoch: 250 [4096/54000 (8%)] Loss: -1500.345215\n",
      "Train Epoch: 250 [8192/54000 (15%)] Loss: -1498.554932\n",
      "Train Epoch: 250 [12288/54000 (23%)] Loss: -1502.310303\n",
      "Train Epoch: 250 [16384/54000 (30%)] Loss: -1500.788818\n",
      "Train Epoch: 250 [20480/54000 (38%)] Loss: -1491.009888\n",
      "Train Epoch: 250 [24576/54000 (46%)] Loss: -1506.107056\n",
      "Train Epoch: 250 [28672/54000 (53%)] Loss: -1496.319946\n",
      "Train Epoch: 250 [32768/54000 (61%)] Loss: -1495.214111\n",
      "Train Epoch: 250 [36864/54000 (68%)] Loss: -1497.524048\n",
      "Train Epoch: 250 [40960/54000 (76%)] Loss: -1493.785156\n",
      "Train Epoch: 250 [45056/54000 (83%)] Loss: -1507.793213\n",
      "Train Epoch: 250 [49152/54000 (91%)] Loss: -1502.107178\n",
      "Train Epoch: 250 [53248/54000 (99%)] Loss: -1499.458252\n",
      "    epoch          : 250\n",
      "    loss           : -1498.2960448061685\n",
      "    ess            : 3.765194226215236\n",
      "    log_marginal   : 1498.4425690998962\n",
      "    val_loss       : -1498.486567179362\n",
      "    val_ess        : 3.7589527368545532\n",
      "    val_log_marginal: 1498.6354268391926\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch250.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 251 [0/54000 (0%)] Loss: -1506.963135\n",
      "Train Epoch: 251 [4096/54000 (8%)] Loss: -1500.880615\n",
      "Train Epoch: 251 [8192/54000 (15%)] Loss: -1505.648193\n",
      "Train Epoch: 251 [12288/54000 (23%)] Loss: -1504.547607\n",
      "Train Epoch: 251 [16384/54000 (30%)] Loss: -1496.807983\n",
      "Train Epoch: 251 [20480/54000 (38%)] Loss: -1502.080444\n",
      "Train Epoch: 251 [24576/54000 (46%)] Loss: -1500.716309\n",
      "Train Epoch: 251 [28672/54000 (53%)] Loss: -1504.399780\n",
      "Train Epoch: 251 [32768/54000 (61%)] Loss: -1493.556396\n",
      "Train Epoch: 251 [36864/54000 (68%)] Loss: -1499.257935\n",
      "Train Epoch: 251 [40960/54000 (76%)] Loss: -1496.705566\n",
      "Train Epoch: 251 [45056/54000 (83%)] Loss: -1495.532959\n",
      "Train Epoch: 251 [49152/54000 (91%)] Loss: -1498.262329\n",
      "Train Epoch: 251 [53248/54000 (99%)] Loss: -1500.817261\n",
      "    epoch          : 251\n",
      "    loss           : -1498.9818092093083\n",
      "    ess            : 3.765402210832207\n",
      "    log_marginal   : 1499.12860772734\n",
      "    val_loss       : -1499.9469960530598\n",
      "    val_ess        : 3.7676205237706504\n",
      "    val_log_marginal: 1500.0989888509114\n",
      "Train Epoch: 252 [0/54000 (0%)] Loss: -1500.152588\n",
      "Train Epoch: 252 [4096/54000 (8%)] Loss: -1497.849976\n",
      "Train Epoch: 252 [8192/54000 (15%)] Loss: -1498.375977\n",
      "Train Epoch: 252 [12288/54000 (23%)] Loss: -1504.294312\n",
      "Train Epoch: 252 [16384/54000 (30%)] Loss: -1499.549072\n",
      "Train Epoch: 252 [20480/54000 (38%)] Loss: -1496.015991\n",
      "Train Epoch: 252 [24576/54000 (46%)] Loss: -1491.867432\n",
      "Train Epoch: 252 [28672/54000 (53%)] Loss: -1498.259033\n",
      "Train Epoch: 252 [32768/54000 (61%)] Loss: -1500.276611\n",
      "Train Epoch: 252 [36864/54000 (68%)] Loss: -1493.480103\n",
      "Train Epoch: 252 [40960/54000 (76%)] Loss: -1490.148560\n",
      "Train Epoch: 252 [45056/54000 (83%)] Loss: -1492.441284\n",
      "Train Epoch: 252 [49152/54000 (91%)] Loss: -1505.825562\n",
      "Train Epoch: 252 [53248/54000 (99%)] Loss: -1494.031860\n",
      "    epoch          : 252\n",
      "    loss           : -1499.3541010996742\n",
      "    ess            : 3.768893108548711\n",
      "    log_marginal   : 1499.4986040015922\n",
      "    val_loss       : -1499.264124552409\n",
      "    val_ess        : 3.7812658150990806\n",
      "    val_log_marginal: 1499.3949686686199\n",
      "Train Epoch: 253 [0/54000 (0%)] Loss: -1496.907349\n",
      "Train Epoch: 253 [4096/54000 (8%)] Loss: -1497.572876\n",
      "Train Epoch: 253 [8192/54000 (15%)] Loss: -1506.505615\n",
      "Train Epoch: 253 [12288/54000 (23%)] Loss: -1501.438110\n",
      "Train Epoch: 253 [16384/54000 (30%)] Loss: -1503.348877\n",
      "Train Epoch: 253 [20480/54000 (38%)] Loss: -1501.889038\n",
      "Train Epoch: 253 [24576/54000 (46%)] Loss: -1494.577881\n",
      "Train Epoch: 253 [28672/54000 (53%)] Loss: -1509.232178\n",
      "Train Epoch: 253 [32768/54000 (61%)] Loss: -1490.983398\n",
      "Train Epoch: 253 [36864/54000 (68%)] Loss: -1500.824463\n",
      "Train Epoch: 253 [40960/54000 (76%)] Loss: -1494.102539\n",
      "Train Epoch: 253 [45056/54000 (83%)] Loss: -1495.363037\n",
      "Train Epoch: 253 [49152/54000 (91%)] Loss: -1502.865967\n",
      "Train Epoch: 253 [53248/54000 (99%)] Loss: -1496.885010\n",
      "    epoch          : 253\n",
      "    loss           : -1499.6949329828199\n",
      "    ess            : 3.770659360840422\n",
      "    log_marginal   : 1499.8392495973414\n",
      "    val_loss       : -1499.1219635009766\n",
      "    val_ess        : 3.782892187436422\n",
      "    val_log_marginal: 1499.261021931966\n",
      "Train Epoch: 254 [0/54000 (0%)] Loss: -1497.723877\n",
      "Train Epoch: 254 [4096/54000 (8%)] Loss: -1503.578613\n",
      "Train Epoch: 254 [8192/54000 (15%)] Loss: -1500.033203\n",
      "Train Epoch: 254 [12288/54000 (23%)] Loss: -1498.670166\n",
      "Train Epoch: 254 [16384/54000 (30%)] Loss: -1498.495117\n",
      "Train Epoch: 254 [20480/54000 (38%)] Loss: -1498.717773\n",
      "Train Epoch: 254 [24576/54000 (46%)] Loss: -1501.000610\n",
      "Train Epoch: 254 [28672/54000 (53%)] Loss: -1503.112793\n",
      "Train Epoch: 254 [32768/54000 (61%)] Loss: -1500.624634\n",
      "Train Epoch: 254 [36864/54000 (68%)] Loss: -1496.024780\n",
      "Train Epoch: 254 [40960/54000 (76%)] Loss: -1499.732544\n",
      "Train Epoch: 254 [45056/54000 (83%)] Loss: -1497.234863\n",
      "Train Epoch: 254 [49152/54000 (91%)] Loss: -1503.660400\n",
      "Train Epoch: 254 [53248/54000 (99%)] Loss: -1505.313721\n",
      "    epoch          : 254\n",
      "    loss           : -1500.1373782768069\n",
      "    ess            : 3.7717735722166665\n",
      "    log_marginal   : 1500.2810613984745\n",
      "    val_loss       : -1499.8303731282551\n",
      "    val_ess        : 3.745918313662211\n",
      "    val_log_marginal: 1499.9918467203777\n",
      "Train Epoch: 255 [0/54000 (0%)] Loss: -1495.596191\n",
      "Train Epoch: 255 [4096/54000 (8%)] Loss: -1500.708740\n",
      "Train Epoch: 255 [8192/54000 (15%)] Loss: -1501.330078\n",
      "Train Epoch: 255 [12288/54000 (23%)] Loss: -1496.018555\n",
      "Train Epoch: 255 [16384/54000 (30%)] Loss: -1499.508789\n",
      "Train Epoch: 255 [20480/54000 (38%)] Loss: -1505.104980\n",
      "Train Epoch: 255 [24576/54000 (46%)] Loss: -1500.056030\n",
      "Train Epoch: 255 [28672/54000 (53%)] Loss: -1495.838501\n",
      "Train Epoch: 255 [32768/54000 (61%)] Loss: -1504.951416\n",
      "Train Epoch: 255 [36864/54000 (68%)] Loss: -1497.796509\n",
      "Train Epoch: 255 [40960/54000 (76%)] Loss: -1503.044434\n",
      "Train Epoch: 255 [45056/54000 (83%)] Loss: -1503.387817\n",
      "Train Epoch: 255 [49152/54000 (91%)] Loss: -1503.815918\n",
      "Train Epoch: 255 [53248/54000 (99%)] Loss: -1496.251953\n",
      "    epoch          : 255\n",
      "    loss           : -1500.3920667024586\n",
      "    ess            : 3.771685312144564\n",
      "    log_marginal   : 1500.5354258460457\n",
      "    val_loss       : -1500.1663970947266\n",
      "    val_ess        : 3.766462047894796\n",
      "    val_log_marginal: 1500.3137613932292\n",
      "Train Epoch: 256 [0/54000 (0%)] Loss: -1503.254272\n",
      "Train Epoch: 256 [4096/54000 (8%)] Loss: -1505.555420\n",
      "Train Epoch: 256 [8192/54000 (15%)] Loss: -1506.227539\n",
      "Train Epoch: 256 [12288/54000 (23%)] Loss: -1501.538574\n",
      "Train Epoch: 256 [16384/54000 (30%)] Loss: -1501.621094\n",
      "Train Epoch: 256 [20480/54000 (38%)] Loss: -1504.798584\n",
      "Train Epoch: 256 [24576/54000 (46%)] Loss: -1496.549927\n",
      "Train Epoch: 256 [28672/54000 (53%)] Loss: -1507.424316\n",
      "Train Epoch: 256 [32768/54000 (61%)] Loss: -1501.166870\n",
      "Train Epoch: 256 [36864/54000 (68%)] Loss: -1500.086548\n",
      "Train Epoch: 256 [40960/54000 (76%)] Loss: -1499.356812\n",
      "Train Epoch: 256 [45056/54000 (83%)] Loss: -1504.489746\n",
      "Train Epoch: 256 [49152/54000 (91%)] Loss: -1499.606689\n",
      "Train Epoch: 256 [53248/54000 (99%)] Loss: -1505.080200\n",
      "    epoch          : 256\n",
      "    loss           : -1500.956673717047\n",
      "    ess            : 3.7679895959194236\n",
      "    log_marginal   : 1501.1015254739336\n",
      "    val_loss       : -1500.6931762695312\n",
      "    val_ess        : 3.77651709318161\n",
      "    val_log_marginal: 1500.829569498698\n",
      "Train Epoch: 257 [0/54000 (0%)] Loss: -1492.496460\n",
      "Train Epoch: 257 [4096/54000 (8%)] Loss: -1506.887451\n",
      "Train Epoch: 257 [8192/54000 (15%)] Loss: -1495.969238\n",
      "Train Epoch: 257 [12288/54000 (23%)] Loss: -1498.284790\n",
      "Train Epoch: 257 [16384/54000 (30%)] Loss: -1501.907471\n",
      "Train Epoch: 257 [20480/54000 (38%)] Loss: -1498.554199\n",
      "Train Epoch: 257 [24576/54000 (46%)] Loss: -1501.484619\n",
      "Train Epoch: 257 [28672/54000 (53%)] Loss: -1498.462891\n",
      "Train Epoch: 257 [32768/54000 (61%)] Loss: -1498.308594\n",
      "Train Epoch: 257 [36864/54000 (68%)] Loss: -1501.133301\n",
      "Train Epoch: 257 [40960/54000 (76%)] Loss: -1497.367188\n",
      "Train Epoch: 257 [45056/54000 (83%)] Loss: -1499.838989\n",
      "Train Epoch: 257 [49152/54000 (91%)] Loss: -1503.422607\n",
      "Train Epoch: 257 [53248/54000 (99%)] Loss: -1506.043335\n",
      "    epoch          : 257\n",
      "    loss           : -1501.4294531944238\n",
      "    ess            : 3.768978513247594\n",
      "    log_marginal   : 1501.5740741169284\n",
      "    val_loss       : -1501.0704294840496\n",
      "    val_ess        : 3.7699908713499704\n",
      "    val_log_marginal: 1501.225835164388\n",
      "Train Epoch: 258 [0/54000 (0%)] Loss: -1499.283203\n",
      "Train Epoch: 258 [4096/54000 (8%)] Loss: -1501.577393\n",
      "Train Epoch: 258 [8192/54000 (15%)] Loss: -1501.191895\n",
      "Train Epoch: 258 [12288/54000 (23%)] Loss: -1506.760376\n",
      "Train Epoch: 258 [16384/54000 (30%)] Loss: -1503.669434\n",
      "Train Epoch: 258 [20480/54000 (38%)] Loss: -1506.001709\n",
      "Train Epoch: 258 [24576/54000 (46%)] Loss: -1501.560547\n",
      "Train Epoch: 258 [28672/54000 (53%)] Loss: -1503.297241\n",
      "Train Epoch: 258 [32768/54000 (61%)] Loss: -1508.526245\n",
      "Train Epoch: 258 [36864/54000 (68%)] Loss: -1502.374390\n",
      "Train Epoch: 258 [40960/54000 (76%)] Loss: -1499.781982\n",
      "Train Epoch: 258 [45056/54000 (83%)] Loss: -1501.689697\n",
      "Train Epoch: 258 [49152/54000 (91%)] Loss: -1496.554199\n",
      "Train Epoch: 258 [53248/54000 (99%)] Loss: -1503.026123\n",
      "    epoch          : 258\n",
      "    loss           : -1501.702122403547\n",
      "    ess            : 3.766478152071695\n",
      "    log_marginal   : 1501.848287428725\n",
      "    val_loss       : -1501.4383850097656\n",
      "    val_ess        : 3.7825670739014945\n",
      "    val_log_marginal: 1501.5664723714192\n",
      "Train Epoch: 259 [0/54000 (0%)] Loss: -1495.817139\n",
      "Train Epoch: 259 [4096/54000 (8%)] Loss: -1505.536011\n",
      "Train Epoch: 259 [8192/54000 (15%)] Loss: -1501.620728\n",
      "Train Epoch: 259 [12288/54000 (23%)] Loss: -1500.947021\n",
      "Train Epoch: 259 [16384/54000 (30%)] Loss: -1512.876099\n",
      "Train Epoch: 259 [20480/54000 (38%)] Loss: -1504.256714\n",
      "Train Epoch: 259 [24576/54000 (46%)] Loss: -1505.159424\n",
      "Train Epoch: 259 [28672/54000 (53%)] Loss: -1509.608887\n",
      "Train Epoch: 259 [32768/54000 (61%)] Loss: -1506.096680\n",
      "Train Epoch: 259 [36864/54000 (68%)] Loss: -1503.089966\n",
      "Train Epoch: 259 [40960/54000 (76%)] Loss: -1505.013672\n",
      "Train Epoch: 259 [45056/54000 (83%)] Loss: -1503.759644\n",
      "Train Epoch: 259 [49152/54000 (91%)] Loss: -1501.866699\n",
      "Train Epoch: 259 [53248/54000 (99%)] Loss: -1501.999023\n",
      "    epoch          : 259\n",
      "    loss           : -1502.0765519707124\n",
      "    ess            : 3.7706336037242583\n",
      "    log_marginal   : 1502.2229217963195\n",
      "    val_loss       : -1503.150655110677\n",
      "    val_ess        : 3.7679798106352487\n",
      "    val_log_marginal: 1503.289098103841\n",
      "Train Epoch: 260 [0/54000 (0%)] Loss: -1497.053711\n",
      "Train Epoch: 260 [4096/54000 (8%)] Loss: -1502.907227\n",
      "Train Epoch: 260 [8192/54000 (15%)] Loss: -1504.002808\n",
      "Train Epoch: 260 [12288/54000 (23%)] Loss: -1504.484131\n",
      "Train Epoch: 260 [16384/54000 (30%)] Loss: -1501.356689\n",
      "Train Epoch: 260 [20480/54000 (38%)] Loss: -1503.353760\n",
      "Train Epoch: 260 [24576/54000 (46%)] Loss: -1494.270996\n",
      "Train Epoch: 260 [28672/54000 (53%)] Loss: -1504.422241\n",
      "Train Epoch: 260 [32768/54000 (61%)] Loss: -1502.143433\n",
      "Train Epoch: 260 [36864/54000 (68%)] Loss: -1490.885010\n",
      "Train Epoch: 260 [40960/54000 (76%)] Loss: -1502.702637\n",
      "Train Epoch: 260 [45056/54000 (83%)] Loss: -1499.891357\n",
      "Train Epoch: 260 [49152/54000 (91%)] Loss: -1506.941895\n",
      "Train Epoch: 260 [53248/54000 (99%)] Loss: -1496.987793\n",
      "    epoch          : 260\n",
      "    loss           : -1502.271853478599\n",
      "    ess            : 3.767605160084946\n",
      "    log_marginal   : 1502.4179577578866\n",
      "    val_loss       : -1502.0231272379558\n",
      "    val_ess        : 3.7687919437885284\n",
      "    val_log_marginal: 1502.165298461914\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch260.pth ...\n",
      "Train Epoch: 261 [0/54000 (0%)] Loss: -1504.033447\n",
      "Train Epoch: 261 [4096/54000 (8%)] Loss: -1502.565186\n",
      "Train Epoch: 261 [8192/54000 (15%)] Loss: -1501.553955\n",
      "Train Epoch: 261 [12288/54000 (23%)] Loss: -1500.972656\n",
      "Train Epoch: 261 [16384/54000 (30%)] Loss: -1500.453125\n",
      "Train Epoch: 261 [20480/54000 (38%)] Loss: -1506.049194\n",
      "Train Epoch: 261 [24576/54000 (46%)] Loss: -1499.000000\n",
      "Train Epoch: 261 [28672/54000 (53%)] Loss: -1506.480225\n",
      "Train Epoch: 261 [32768/54000 (61%)] Loss: -1506.932129\n",
      "Train Epoch: 261 [36864/54000 (68%)] Loss: -1501.106567\n",
      "Train Epoch: 261 [40960/54000 (76%)] Loss: -1503.292969\n",
      "Train Epoch: 261 [45056/54000 (83%)] Loss: -1501.073486\n",
      "Train Epoch: 261 [49152/54000 (91%)] Loss: -1502.517944\n",
      "Train Epoch: 261 [53248/54000 (99%)] Loss: -1503.953979\n",
      "    epoch          : 261\n",
      "    loss           : -1502.805806959975\n",
      "    ess            : 3.76350453001628\n",
      "    log_marginal   : 1502.9563966000815\n",
      "    val_loss       : -1502.6602935791016\n",
      "    val_ess        : 3.7757539252440133\n",
      "    val_log_marginal: 1502.8033142089844\n",
      "Train Epoch: 262 [0/54000 (0%)] Loss: -1497.486816\n",
      "Train Epoch: 262 [4096/54000 (8%)] Loss: -1512.036377\n",
      "Train Epoch: 262 [8192/54000 (15%)] Loss: -1503.910889\n",
      "Train Epoch: 262 [12288/54000 (23%)] Loss: -1506.329956\n",
      "Train Epoch: 262 [16384/54000 (30%)] Loss: -1501.977295\n",
      "Train Epoch: 262 [20480/54000 (38%)] Loss: -1504.538208\n",
      "Train Epoch: 262 [24576/54000 (46%)] Loss: -1503.464844\n",
      "Train Epoch: 262 [28672/54000 (53%)] Loss: -1501.148682\n",
      "Train Epoch: 262 [32768/54000 (61%)] Loss: -1500.239380\n",
      "Train Epoch: 262 [36864/54000 (68%)] Loss: -1508.049561\n",
      "Train Epoch: 262 [40960/54000 (76%)] Loss: -1508.245850\n",
      "Train Epoch: 262 [45056/54000 (83%)] Loss: -1498.825684\n",
      "Train Epoch: 262 [49152/54000 (91%)] Loss: -1505.618042\n",
      "Train Epoch: 262 [53248/54000 (99%)] Loss: -1500.958008\n",
      "    epoch          : 262\n",
      "    loss           : -1503.137859037137\n",
      "    ess            : 3.767054276443771\n",
      "    log_marginal   : 1503.2841322478525\n",
      "    val_loss       : -1503.4238586425781\n",
      "    val_ess        : 3.7518828312555947\n",
      "    val_log_marginal: 1503.5796457926433\n",
      "Train Epoch: 263 [0/54000 (0%)] Loss: -1504.541748\n",
      "Train Epoch: 263 [4096/54000 (8%)] Loss: -1499.857788\n",
      "Train Epoch: 263 [8192/54000 (15%)] Loss: -1503.402588\n",
      "Train Epoch: 263 [12288/54000 (23%)] Loss: -1504.370361\n",
      "Train Epoch: 263 [16384/54000 (30%)] Loss: -1501.924194\n",
      "Train Epoch: 263 [20480/54000 (38%)] Loss: -1506.232788\n",
      "Train Epoch: 263 [24576/54000 (46%)] Loss: -1502.419434\n",
      "Train Epoch: 263 [28672/54000 (53%)] Loss: -1509.840454\n",
      "Train Epoch: 263 [32768/54000 (61%)] Loss: -1507.686279\n",
      "Train Epoch: 263 [36864/54000 (68%)] Loss: -1511.536865\n",
      "Train Epoch: 263 [40960/54000 (76%)] Loss: -1505.954346\n",
      "Train Epoch: 263 [45056/54000 (83%)] Loss: -1513.779785\n",
      "Train Epoch: 263 [49152/54000 (91%)] Loss: -1504.551270\n",
      "Train Epoch: 263 [53248/54000 (99%)] Loss: -1498.415283\n",
      "    epoch          : 263\n",
      "    loss           : -1503.5416485393216\n",
      "    ess            : 3.7626079236161654\n",
      "    log_marginal   : 1503.6888774853746\n",
      "    val_loss       : -1502.7041625976562\n",
      "    val_ess        : 3.770362118879954\n",
      "    val_log_marginal: 1502.8391672770183\n",
      "Train Epoch: 264 [0/54000 (0%)] Loss: -1505.076904\n",
      "Train Epoch: 264 [4096/54000 (8%)] Loss: -1504.852661\n",
      "Train Epoch: 264 [8192/54000 (15%)] Loss: -1502.561279\n",
      "Train Epoch: 264 [12288/54000 (23%)] Loss: -1505.775513\n",
      "Train Epoch: 264 [16384/54000 (30%)] Loss: -1506.292969\n",
      "Train Epoch: 264 [20480/54000 (38%)] Loss: -1504.131836\n",
      "Train Epoch: 264 [24576/54000 (46%)] Loss: -1506.509033\n",
      "Train Epoch: 264 [28672/54000 (53%)] Loss: -1508.058716\n",
      "Train Epoch: 264 [32768/54000 (61%)] Loss: -1503.019653\n",
      "Train Epoch: 264 [36864/54000 (68%)] Loss: -1497.176636\n",
      "Train Epoch: 264 [40960/54000 (76%)] Loss: -1503.222168\n",
      "Train Epoch: 264 [45056/54000 (83%)] Loss: -1498.268311\n",
      "Train Epoch: 264 [49152/54000 (91%)] Loss: -1504.971924\n",
      "Train Epoch: 264 [53248/54000 (99%)] Loss: -1497.465820\n",
      "    epoch          : 264\n",
      "    loss           : -1503.9554339223564\n",
      "    ess            : 3.7620703642967186\n",
      "    log_marginal   : 1504.105585613522\n",
      "    val_loss       : -1503.3016459147136\n",
      "    val_ess        : 3.7724048693974814\n",
      "    val_log_marginal: 1503.4442291259766\n",
      "Train Epoch: 265 [0/54000 (0%)] Loss: -1506.164185\n",
      "Train Epoch: 265 [4096/54000 (8%)] Loss: -1500.032715\n",
      "Train Epoch: 265 [8192/54000 (15%)] Loss: -1499.408691\n",
      "Train Epoch: 265 [12288/54000 (23%)] Loss: -1502.069336\n",
      "Train Epoch: 265 [16384/54000 (30%)] Loss: -1499.866699\n",
      "Train Epoch: 265 [20480/54000 (38%)] Loss: -1506.821289\n",
      "Train Epoch: 265 [24576/54000 (46%)] Loss: -1503.663696\n",
      "Train Epoch: 265 [28672/54000 (53%)] Loss: -1508.892212\n",
      "Train Epoch: 265 [32768/54000 (61%)] Loss: -1501.196777\n",
      "Train Epoch: 265 [36864/54000 (68%)] Loss: -1498.009888\n",
      "Train Epoch: 265 [40960/54000 (76%)] Loss: -1508.574951\n",
      "Train Epoch: 265 [45056/54000 (83%)] Loss: -1503.458008\n",
      "Train Epoch: 265 [49152/54000 (91%)] Loss: -1508.529419\n",
      "Train Epoch: 265 [53248/54000 (99%)] Loss: -1499.412109\n",
      "    epoch          : 265\n",
      "    loss           : -1504.1146338584863\n",
      "    ess            : 3.767694672137075\n",
      "    log_marginal   : 1504.2618871028953\n",
      "    val_loss       : -1503.3921915690105\n",
      "    val_ess        : 3.766905019680659\n",
      "    val_log_marginal: 1503.5330505371094\n",
      "Train Epoch: 266 [0/54000 (0%)] Loss: -1507.413330\n",
      "Train Epoch: 266 [4096/54000 (8%)] Loss: -1504.260254\n",
      "Train Epoch: 266 [8192/54000 (15%)] Loss: -1504.445312\n",
      "Train Epoch: 266 [12288/54000 (23%)] Loss: -1509.368896\n",
      "Train Epoch: 266 [16384/54000 (30%)] Loss: -1505.216431\n",
      "Train Epoch: 266 [20480/54000 (38%)] Loss: -1504.407715\n",
      "Train Epoch: 266 [24576/54000 (46%)] Loss: -1503.684570\n",
      "Train Epoch: 266 [28672/54000 (53%)] Loss: -1513.222656\n",
      "Train Epoch: 266 [32768/54000 (61%)] Loss: -1507.140137\n",
      "Train Epoch: 266 [36864/54000 (68%)] Loss: -1506.221680\n",
      "Train Epoch: 266 [40960/54000 (76%)] Loss: -1502.086182\n",
      "Train Epoch: 266 [45056/54000 (83%)] Loss: -1508.775391\n",
      "Train Epoch: 266 [49152/54000 (91%)] Loss: -1505.661377\n",
      "Train Epoch: 266 [53248/54000 (99%)] Loss: -1500.638306\n",
      "    epoch          : 266\n",
      "    loss           : -1504.6134785295098\n",
      "    ess            : 3.7693420349139175\n",
      "    log_marginal   : 1504.756448320868\n",
      "    val_loss       : -1504.0433197021484\n",
      "    val_ess        : 3.752323309580485\n",
      "    val_log_marginal: 1504.2069549560547\n",
      "Train Epoch: 267 [0/54000 (0%)] Loss: -1506.640137\n",
      "Train Epoch: 267 [4096/54000 (8%)] Loss: -1505.848145\n",
      "Train Epoch: 267 [8192/54000 (15%)] Loss: -1507.304199\n",
      "Train Epoch: 267 [12288/54000 (23%)] Loss: -1503.260010\n",
      "Train Epoch: 267 [16384/54000 (30%)] Loss: -1506.337646\n",
      "Train Epoch: 267 [20480/54000 (38%)] Loss: -1510.963013\n",
      "Train Epoch: 267 [24576/54000 (46%)] Loss: -1498.275879\n",
      "Train Epoch: 267 [28672/54000 (53%)] Loss: -1506.558594\n",
      "Train Epoch: 267 [32768/54000 (61%)] Loss: -1506.292725\n",
      "Train Epoch: 267 [36864/54000 (68%)] Loss: -1507.985352\n",
      "Train Epoch: 267 [40960/54000 (76%)] Loss: -1503.354248\n",
      "Train Epoch: 267 [45056/54000 (83%)] Loss: -1507.601929\n",
      "Train Epoch: 267 [49152/54000 (91%)] Loss: -1505.730469\n",
      "Train Epoch: 267 [53248/54000 (99%)] Loss: -1502.545166\n",
      "    epoch          : 267\n",
      "    loss           : -1505.0338273613374\n",
      "    ess            : 3.77290841188476\n",
      "    log_marginal   : 1505.1767115299172\n",
      "    val_loss       : -1505.4087371826172\n",
      "    val_ess        : 3.760549316803614\n",
      "    val_log_marginal: 1505.5590718587239\n",
      "Train Epoch: 268 [0/54000 (0%)] Loss: -1511.957153\n",
      "Train Epoch: 268 [4096/54000 (8%)] Loss: -1506.043213\n",
      "Train Epoch: 268 [8192/54000 (15%)] Loss: -1502.288330\n",
      "Train Epoch: 268 [12288/54000 (23%)] Loss: -1501.426392\n",
      "Train Epoch: 268 [16384/54000 (30%)] Loss: -1508.362061\n",
      "Train Epoch: 268 [20480/54000 (38%)] Loss: -1506.287598\n",
      "Train Epoch: 268 [24576/54000 (46%)] Loss: -1505.959473\n",
      "Train Epoch: 268 [28672/54000 (53%)] Loss: -1504.942261\n",
      "Train Epoch: 268 [32768/54000 (61%)] Loss: -1502.733887\n",
      "Train Epoch: 268 [36864/54000 (68%)] Loss: -1506.644043\n",
      "Train Epoch: 268 [40960/54000 (76%)] Loss: -1504.629883\n",
      "Train Epoch: 268 [45056/54000 (83%)] Loss: -1507.138428\n",
      "Train Epoch: 268 [49152/54000 (91%)] Loss: -1504.188599\n",
      "Train Epoch: 268 [53248/54000 (99%)] Loss: -1503.123047\n",
      "    epoch          : 268\n",
      "    loss           : -1505.5961682649586\n",
      "    ess            : 3.7651332317370376\n",
      "    log_marginal   : 1505.7429795107005\n",
      "    val_loss       : -1505.8357340494792\n",
      "    val_ess        : 3.7717483242352805\n",
      "    val_log_marginal: 1505.9807586669922\n",
      "Train Epoch: 269 [0/54000 (0%)] Loss: -1508.099121\n",
      "Train Epoch: 269 [4096/54000 (8%)] Loss: -1503.149902\n",
      "Train Epoch: 269 [8192/54000 (15%)] Loss: -1510.725342\n",
      "Train Epoch: 269 [12288/54000 (23%)] Loss: -1513.829102\n",
      "Train Epoch: 269 [16384/54000 (30%)] Loss: -1507.057129\n",
      "Train Epoch: 269 [20480/54000 (38%)] Loss: -1494.145508\n",
      "Train Epoch: 269 [24576/54000 (46%)] Loss: -1498.895752\n",
      "Train Epoch: 269 [28672/54000 (53%)] Loss: -1504.094482\n",
      "Train Epoch: 269 [32768/54000 (61%)] Loss: -1508.613525\n",
      "Train Epoch: 269 [36864/54000 (68%)] Loss: -1508.045654\n",
      "Train Epoch: 269 [40960/54000 (76%)] Loss: -1506.817871\n",
      "Train Epoch: 269 [45056/54000 (83%)] Loss: -1507.915527\n",
      "Train Epoch: 269 [49152/54000 (91%)] Loss: -1506.882812\n",
      "Train Epoch: 269 [53248/54000 (99%)] Loss: -1502.631836\n",
      "    epoch          : 269\n",
      "    loss           : -1505.7600653047245\n",
      "    ess            : 3.768272599902763\n",
      "    log_marginal   : 1505.9049581374038\n",
      "    val_loss       : -1506.1336873372395\n",
      "    val_ess        : 3.779230276743571\n",
      "    val_log_marginal: 1506.2738087972004\n",
      "Train Epoch: 270 [0/54000 (0%)] Loss: -1501.919556\n",
      "Train Epoch: 270 [4096/54000 (8%)] Loss: -1504.414062\n",
      "Train Epoch: 270 [8192/54000 (15%)] Loss: -1505.458252\n",
      "Train Epoch: 270 [12288/54000 (23%)] Loss: -1505.828125\n",
      "Train Epoch: 270 [16384/54000 (30%)] Loss: -1505.541138\n",
      "Train Epoch: 270 [20480/54000 (38%)] Loss: -1508.172485\n",
      "Train Epoch: 270 [24576/54000 (46%)] Loss: -1514.422607\n",
      "Train Epoch: 270 [28672/54000 (53%)] Loss: -1509.649536\n",
      "Train Epoch: 270 [32768/54000 (61%)] Loss: -1498.961914\n",
      "Train Epoch: 270 [36864/54000 (68%)] Loss: -1511.532471\n",
      "Train Epoch: 270 [40960/54000 (76%)] Loss: -1511.354126\n",
      "Train Epoch: 270 [45056/54000 (83%)] Loss: -1501.169678\n",
      "Train Epoch: 270 [49152/54000 (91%)] Loss: -1503.303955\n",
      "Train Epoch: 270 [53248/54000 (99%)] Loss: -1502.240723\n",
      "    epoch          : 270\n",
      "    loss           : -1506.1145135237707\n",
      "    ess            : 3.76889120345997\n",
      "    log_marginal   : 1506.255833341047\n",
      "    val_loss       : -1507.2283274332683\n",
      "    val_ess        : 3.774220814307531\n",
      "    val_log_marginal: 1507.3664957682292\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch270.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 271 [0/54000 (0%)] Loss: -1509.262329\n",
      "Train Epoch: 271 [4096/54000 (8%)] Loss: -1504.871338\n",
      "Train Epoch: 271 [8192/54000 (15%)] Loss: -1509.305176\n",
      "Train Epoch: 271 [12288/54000 (23%)] Loss: -1501.963379\n",
      "Train Epoch: 271 [16384/54000 (30%)] Loss: -1510.941406\n",
      "Train Epoch: 271 [20480/54000 (38%)] Loss: -1506.414673\n",
      "Train Epoch: 271 [24576/54000 (46%)] Loss: -1503.545166\n",
      "Train Epoch: 271 [28672/54000 (53%)] Loss: -1506.546265\n",
      "Train Epoch: 271 [32768/54000 (61%)] Loss: -1503.057861\n",
      "Train Epoch: 271 [36864/54000 (68%)] Loss: -1506.668335\n",
      "Train Epoch: 271 [40960/54000 (76%)] Loss: -1504.721924\n",
      "Train Epoch: 271 [45056/54000 (83%)] Loss: -1505.949341\n",
      "Train Epoch: 271 [49152/54000 (91%)] Loss: -1502.512329\n",
      "Train Epoch: 271 [53248/54000 (99%)] Loss: -1509.637939\n",
      "    epoch          : 271\n",
      "    loss           : -1506.6450854839306\n",
      "    ess            : 3.7707572763000052\n",
      "    log_marginal   : 1506.7859453680392\n",
      "    val_loss       : -1505.9052988688152\n",
      "    val_ess        : 3.7671895821889243\n",
      "    val_log_marginal: 1506.0416971842449\n",
      "Train Epoch: 272 [0/54000 (0%)] Loss: -1502.568359\n",
      "Train Epoch: 272 [4096/54000 (8%)] Loss: -1505.820557\n",
      "Train Epoch: 272 [8192/54000 (15%)] Loss: -1502.549316\n",
      "Train Epoch: 272 [12288/54000 (23%)] Loss: -1507.416504\n",
      "Train Epoch: 272 [16384/54000 (30%)] Loss: -1496.134888\n",
      "Train Epoch: 272 [20480/54000 (38%)] Loss: -1512.209839\n",
      "Train Epoch: 272 [24576/54000 (46%)] Loss: -1511.972656\n",
      "Train Epoch: 272 [28672/54000 (53%)] Loss: -1508.437012\n",
      "Train Epoch: 272 [32768/54000 (61%)] Loss: -1504.901611\n",
      "Train Epoch: 272 [36864/54000 (68%)] Loss: -1508.899658\n",
      "Train Epoch: 272 [40960/54000 (76%)] Loss: -1507.552979\n",
      "Train Epoch: 272 [45056/54000 (83%)] Loss: -1507.492676\n",
      "Train Epoch: 272 [49152/54000 (91%)] Loss: -1504.410400\n",
      "Train Epoch: 272 [53248/54000 (99%)] Loss: -1510.030151\n",
      "    epoch          : 272\n",
      "    loss           : -1506.9345188231264\n",
      "    ess            : 3.766226987703152\n",
      "    log_marginal   : 1507.0799115077014\n",
      "    val_loss       : -1505.8984476725261\n",
      "    val_ess        : 3.7588411370913186\n",
      "    val_log_marginal: 1506.0531921386719\n",
      "Train Epoch: 273 [0/54000 (0%)] Loss: -1510.303345\n",
      "Train Epoch: 273 [4096/54000 (8%)] Loss: -1501.347900\n",
      "Train Epoch: 273 [8192/54000 (15%)] Loss: -1509.985352\n",
      "Train Epoch: 273 [12288/54000 (23%)] Loss: -1505.896240\n",
      "Train Epoch: 273 [16384/54000 (30%)] Loss: -1502.326172\n",
      "Train Epoch: 273 [20480/54000 (38%)] Loss: -1512.905396\n",
      "Train Epoch: 273 [24576/54000 (46%)] Loss: -1508.130371\n",
      "Train Epoch: 273 [28672/54000 (53%)] Loss: -1502.554932\n",
      "Train Epoch: 273 [32768/54000 (61%)] Loss: -1507.961914\n",
      "Train Epoch: 273 [36864/54000 (68%)] Loss: -1508.879395\n",
      "Train Epoch: 273 [40960/54000 (76%)] Loss: -1504.365845\n",
      "Train Epoch: 273 [45056/54000 (83%)] Loss: -1504.800049\n",
      "Train Epoch: 273 [49152/54000 (91%)] Loss: -1500.642090\n",
      "Train Epoch: 273 [53248/54000 (99%)] Loss: -1504.969238\n",
      "    epoch          : 273\n",
      "    loss           : -1507.6814959919284\n",
      "    ess            : 3.7702969148825694\n",
      "    log_marginal   : 1507.8246630627962\n",
      "    val_loss       : -1507.8188374837239\n",
      "    val_ess        : 3.7552449305852256\n",
      "    val_log_marginal: 1507.9700012207031\n",
      "Train Epoch: 274 [0/54000 (0%)] Loss: -1506.690674\n",
      "Train Epoch: 274 [4096/54000 (8%)] Loss: -1510.182373\n",
      "Train Epoch: 274 [8192/54000 (15%)] Loss: -1517.214233\n",
      "Train Epoch: 274 [12288/54000 (23%)] Loss: -1505.006714\n",
      "Train Epoch: 274 [16384/54000 (30%)] Loss: -1512.496582\n",
      "Train Epoch: 274 [20480/54000 (38%)] Loss: -1511.506592\n",
      "Train Epoch: 274 [24576/54000 (46%)] Loss: -1518.178223\n",
      "Train Epoch: 274 [28672/54000 (53%)] Loss: -1508.712158\n",
      "Train Epoch: 274 [32768/54000 (61%)] Loss: -1505.818604\n",
      "Train Epoch: 274 [36864/54000 (68%)] Loss: -1511.166504\n",
      "Train Epoch: 274 [40960/54000 (76%)] Loss: -1508.875977\n",
      "Train Epoch: 274 [45056/54000 (83%)] Loss: -1507.695923\n",
      "Train Epoch: 274 [49152/54000 (91%)] Loss: -1501.147095\n",
      "Train Epoch: 274 [53248/54000 (99%)] Loss: -1507.807129\n",
      "    epoch          : 274\n",
      "    loss           : -1507.5968439906694\n",
      "    ess            : 3.767544219844149\n",
      "    log_marginal   : 1507.7419902204902\n",
      "    val_loss       : -1507.487533569336\n",
      "    val_ess        : 3.7678929964701333\n",
      "    val_log_marginal: 1507.6322580973308\n",
      "Train Epoch: 275 [0/54000 (0%)] Loss: -1509.631836\n",
      "Train Epoch: 275 [4096/54000 (8%)] Loss: -1512.961426\n",
      "Train Epoch: 275 [8192/54000 (15%)] Loss: -1505.520386\n",
      "Train Epoch: 275 [12288/54000 (23%)] Loss: -1507.793701\n",
      "Train Epoch: 275 [16384/54000 (30%)] Loss: -1508.295410\n",
      "Train Epoch: 275 [20480/54000 (38%)] Loss: -1506.497559\n",
      "Train Epoch: 275 [24576/54000 (46%)] Loss: -1510.647217\n",
      "Train Epoch: 275 [28672/54000 (53%)] Loss: -1512.156860\n",
      "Train Epoch: 275 [32768/54000 (61%)] Loss: -1509.767212\n",
      "Train Epoch: 275 [36864/54000 (68%)] Loss: -1505.817627\n",
      "Train Epoch: 275 [40960/54000 (76%)] Loss: -1506.345947\n",
      "Train Epoch: 275 [45056/54000 (83%)] Loss: -1508.420166\n",
      "Train Epoch: 275 [49152/54000 (91%)] Loss: -1507.989380\n",
      "Train Epoch: 275 [53248/54000 (99%)] Loss: -1508.098022\n",
      "    epoch          : 275\n",
      "    loss           : -1507.914714505887\n",
      "    ess            : 3.7693964655365426\n",
      "    log_marginal   : 1508.056783522475\n",
      "    val_loss       : -1507.9068145751953\n",
      "    val_ess        : 3.755297223726908\n",
      "    val_log_marginal: 1508.0714365641277\n",
      "Train Epoch: 276 [0/54000 (0%)] Loss: -1511.354248\n",
      "Train Epoch: 276 [4096/54000 (8%)] Loss: -1502.666504\n",
      "Train Epoch: 276 [8192/54000 (15%)] Loss: -1502.565186\n",
      "Train Epoch: 276 [12288/54000 (23%)] Loss: -1505.889893\n",
      "Train Epoch: 276 [16384/54000 (30%)] Loss: -1508.539551\n",
      "Train Epoch: 276 [20480/54000 (38%)] Loss: -1506.795166\n",
      "Train Epoch: 276 [24576/54000 (46%)] Loss: -1508.031860\n",
      "Train Epoch: 276 [28672/54000 (53%)] Loss: -1503.670776\n",
      "Train Epoch: 276 [32768/54000 (61%)] Loss: -1505.679077\n",
      "Train Epoch: 276 [36864/54000 (68%)] Loss: -1509.730469\n",
      "Train Epoch: 276 [40960/54000 (76%)] Loss: -1511.436279\n",
      "Train Epoch: 276 [45056/54000 (83%)] Loss: -1509.108643\n",
      "Train Epoch: 276 [49152/54000 (91%)] Loss: -1504.807251\n",
      "Train Epoch: 276 [53248/54000 (99%)] Loss: -1508.229492\n",
      "    epoch          : 276\n",
      "    loss           : -1508.0817842167135\n",
      "    ess            : 3.771537954773383\n",
      "    log_marginal   : 1508.2212220684612\n",
      "    val_loss       : -1508.7104797363281\n",
      "    val_ess        : 3.7635823488235474\n",
      "    val_log_marginal: 1508.8515523274739\n",
      "Train Epoch: 277 [0/54000 (0%)] Loss: -1504.944824\n",
      "Train Epoch: 277 [4096/54000 (8%)] Loss: -1514.602417\n",
      "Train Epoch: 277 [8192/54000 (15%)] Loss: -1516.817871\n",
      "Train Epoch: 277 [12288/54000 (23%)] Loss: -1506.645142\n",
      "Train Epoch: 277 [16384/54000 (30%)] Loss: -1508.667236\n",
      "Train Epoch: 277 [20480/54000 (38%)] Loss: -1512.834473\n",
      "Train Epoch: 277 [24576/54000 (46%)] Loss: -1508.762939\n",
      "Train Epoch: 277 [28672/54000 (53%)] Loss: -1500.110596\n",
      "Train Epoch: 277 [32768/54000 (61%)] Loss: -1509.620972\n",
      "Train Epoch: 277 [36864/54000 (68%)] Loss: -1501.515625\n",
      "Train Epoch: 277 [40960/54000 (76%)] Loss: -1509.090820\n",
      "Train Epoch: 277 [45056/54000 (83%)] Loss: -1512.544800\n",
      "Train Epoch: 277 [49152/54000 (91%)] Loss: -1511.860840\n",
      "Train Epoch: 277 [53248/54000 (99%)] Loss: -1509.535645\n",
      "    epoch          : 277\n",
      "    loss           : -1508.5461495205125\n",
      "    ess            : 3.766064443859444\n",
      "    log_marginal   : 1508.6925031472156\n",
      "    val_loss       : -1508.4110056559246\n",
      "    val_ess        : 3.769705295562744\n",
      "    val_log_marginal: 1508.5586954752605\n",
      "Train Epoch: 278 [0/54000 (0%)] Loss: -1509.744873\n",
      "Train Epoch: 278 [4096/54000 (8%)] Loss: -1509.330566\n",
      "Train Epoch: 278 [8192/54000 (15%)] Loss: -1502.382568\n",
      "Train Epoch: 278 [12288/54000 (23%)] Loss: -1507.669312\n",
      "Train Epoch: 278 [16384/54000 (30%)] Loss: -1510.099854\n",
      "Train Epoch: 278 [20480/54000 (38%)] Loss: -1506.077881\n",
      "Train Epoch: 278 [24576/54000 (46%)] Loss: -1506.692383\n",
      "Train Epoch: 278 [28672/54000 (53%)] Loss: -1506.442627\n",
      "Train Epoch: 278 [32768/54000 (61%)] Loss: -1506.844116\n",
      "Train Epoch: 278 [36864/54000 (68%)] Loss: -1508.547363\n",
      "Train Epoch: 278 [40960/54000 (76%)] Loss: -1503.326660\n",
      "Train Epoch: 278 [45056/54000 (83%)] Loss: -1513.837891\n",
      "Train Epoch: 278 [49152/54000 (91%)] Loss: -1506.690186\n",
      "Train Epoch: 278 [53248/54000 (99%)] Loss: -1507.615723\n",
      "    epoch          : 278\n",
      "    loss           : -1508.7346035202534\n",
      "    ess            : 3.7700740127201895\n",
      "    log_marginal   : 1508.877116849637\n",
      "    val_loss       : -1509.466801961263\n",
      "    val_ess        : 3.771834045648575\n",
      "    val_log_marginal: 1509.600814819336\n",
      "Train Epoch: 279 [0/54000 (0%)] Loss: -1509.892334\n",
      "Train Epoch: 279 [4096/54000 (8%)] Loss: -1515.832031\n",
      "Train Epoch: 279 [8192/54000 (15%)] Loss: -1509.719360\n",
      "Train Epoch: 279 [12288/54000 (23%)] Loss: -1506.253784\n",
      "Train Epoch: 279 [16384/54000 (30%)] Loss: -1507.546631\n",
      "Train Epoch: 279 [20480/54000 (38%)] Loss: -1509.443115\n",
      "Train Epoch: 279 [24576/54000 (46%)] Loss: -1507.331543\n",
      "Train Epoch: 279 [28672/54000 (53%)] Loss: -1510.040039\n",
      "Train Epoch: 279 [32768/54000 (61%)] Loss: -1512.835815\n",
      "Train Epoch: 279 [36864/54000 (68%)] Loss: -1513.280762\n",
      "Train Epoch: 279 [40960/54000 (76%)] Loss: -1510.424683\n",
      "Train Epoch: 279 [45056/54000 (83%)] Loss: -1501.667969\n",
      "Train Epoch: 279 [49152/54000 (91%)] Loss: -1499.484375\n",
      "Train Epoch: 279 [53248/54000 (99%)] Loss: -1503.694092\n",
      "    epoch          : 279\n",
      "    loss           : -1509.0900045819758\n",
      "    ess            : 3.7689198566274054\n",
      "    log_marginal   : 1509.232284762848\n",
      "    val_loss       : -1508.3685353597004\n",
      "    val_ess        : 3.7738646268844604\n",
      "    val_log_marginal: 1508.512430826823\n",
      "Train Epoch: 280 [0/54000 (0%)] Loss: -1507.700684\n",
      "Train Epoch: 280 [4096/54000 (8%)] Loss: -1512.748291\n",
      "Train Epoch: 280 [8192/54000 (15%)] Loss: -1511.270264\n",
      "Train Epoch: 280 [12288/54000 (23%)] Loss: -1506.945312\n",
      "Train Epoch: 280 [16384/54000 (30%)] Loss: -1507.589355\n",
      "Train Epoch: 280 [20480/54000 (38%)] Loss: -1506.029663\n",
      "Train Epoch: 280 [24576/54000 (46%)] Loss: -1514.628906\n",
      "Train Epoch: 280 [28672/54000 (53%)] Loss: -1500.669434\n",
      "Train Epoch: 280 [32768/54000 (61%)] Loss: -1505.175659\n",
      "Train Epoch: 280 [36864/54000 (68%)] Loss: -1514.624756\n",
      "Train Epoch: 280 [40960/54000 (76%)] Loss: -1510.291504\n",
      "Train Epoch: 280 [45056/54000 (83%)] Loss: -1512.065430\n",
      "Train Epoch: 280 [49152/54000 (91%)] Loss: -1505.551270\n",
      "Train Epoch: 280 [53248/54000 (99%)] Loss: -1503.124268\n",
      "    epoch          : 280\n",
      "    loss           : -1509.0687128582272\n",
      "    ess            : 3.7685708513757064\n",
      "    log_marginal   : 1509.213096582494\n",
      "    val_loss       : -1509.5595448811848\n",
      "    val_ess        : 3.7593458791573844\n",
      "    val_log_marginal: 1509.7140604654949\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch280.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 281 [0/54000 (0%)] Loss: -1511.456665\n",
      "Train Epoch: 281 [4096/54000 (8%)] Loss: -1510.935425\n",
      "Train Epoch: 281 [8192/54000 (15%)] Loss: -1512.007324\n",
      "Train Epoch: 281 [12288/54000 (23%)] Loss: -1505.339111\n",
      "Train Epoch: 281 [16384/54000 (30%)] Loss: -1502.865479\n",
      "Train Epoch: 281 [20480/54000 (38%)] Loss: -1507.123047\n",
      "Train Epoch: 281 [24576/54000 (46%)] Loss: -1504.596436\n",
      "Train Epoch: 281 [28672/54000 (53%)] Loss: -1508.908691\n",
      "Train Epoch: 281 [32768/54000 (61%)] Loss: -1513.249023\n",
      "Train Epoch: 281 [36864/54000 (68%)] Loss: -1511.458008\n",
      "Train Epoch: 281 [40960/54000 (76%)] Loss: -1512.567383\n",
      "Train Epoch: 281 [45056/54000 (83%)] Loss: -1507.289673\n",
      "Train Epoch: 281 [49152/54000 (91%)] Loss: -1510.246704\n",
      "Train Epoch: 281 [53248/54000 (99%)] Loss: -1506.053467\n",
      "    epoch          : 281\n",
      "    loss           : -1509.4779099016957\n",
      "    ess            : 3.7697563928450455\n",
      "    log_marginal   : 1509.6199789182836\n",
      "    val_loss       : -1509.4501444498699\n",
      "    val_ess        : 3.766859163840612\n",
      "    val_log_marginal: 1509.5933430989583\n",
      "Train Epoch: 282 [0/54000 (0%)] Loss: -1515.873535\n",
      "Train Epoch: 282 [4096/54000 (8%)] Loss: -1510.169922\n",
      "Train Epoch: 282 [8192/54000 (15%)] Loss: -1509.020630\n",
      "Train Epoch: 282 [12288/54000 (23%)] Loss: -1510.351196\n",
      "Train Epoch: 282 [16384/54000 (30%)] Loss: -1502.252075\n",
      "Train Epoch: 282 [20480/54000 (38%)] Loss: -1517.303955\n",
      "Train Epoch: 282 [24576/54000 (46%)] Loss: -1506.904907\n",
      "Train Epoch: 282 [28672/54000 (53%)] Loss: -1513.163818\n",
      "Train Epoch: 282 [32768/54000 (61%)] Loss: -1507.778442\n",
      "Train Epoch: 282 [36864/54000 (68%)] Loss: -1508.775879\n",
      "Train Epoch: 282 [40960/54000 (76%)] Loss: -1509.903442\n",
      "Train Epoch: 282 [45056/54000 (83%)] Loss: -1513.230225\n",
      "Train Epoch: 282 [49152/54000 (91%)] Loss: -1499.280029\n",
      "Train Epoch: 282 [53248/54000 (99%)] Loss: -1506.563354\n",
      "    epoch          : 282\n",
      "    loss           : -1509.7959817461492\n",
      "    ess            : 3.767920774306166\n",
      "    log_marginal   : 1509.938865914729\n",
      "    val_loss       : -1509.5177510579426\n",
      "    val_ess        : 3.7529962162176767\n",
      "    val_log_marginal: 1509.6684672037761\n",
      "Train Epoch: 283 [0/54000 (0%)] Loss: -1506.592529\n",
      "Train Epoch: 283 [4096/54000 (8%)] Loss: -1507.416504\n",
      "Train Epoch: 283 [8192/54000 (15%)] Loss: -1508.653809\n",
      "Train Epoch: 283 [12288/54000 (23%)] Loss: -1512.499756\n",
      "Train Epoch: 283 [16384/54000 (30%)] Loss: -1508.381958\n",
      "Train Epoch: 283 [20480/54000 (38%)] Loss: -1510.588501\n",
      "Train Epoch: 283 [24576/54000 (46%)] Loss: -1520.488037\n",
      "Train Epoch: 283 [28672/54000 (53%)] Loss: -1512.419312\n",
      "Train Epoch: 283 [32768/54000 (61%)] Loss: -1515.549805\n",
      "Train Epoch: 283 [36864/54000 (68%)] Loss: -1514.116211\n",
      "Train Epoch: 283 [40960/54000 (76%)] Loss: -1508.151123\n",
      "Train Epoch: 283 [45056/54000 (83%)] Loss: -1502.866455\n",
      "Train Epoch: 283 [49152/54000 (91%)] Loss: -1507.599731\n",
      "Train Epoch: 283 [53248/54000 (99%)] Loss: -1509.252197\n",
      "    epoch          : 283\n",
      "    loss           : -1510.1124846110413\n",
      "    ess            : 3.7651435424931243\n",
      "    log_marginal   : 1510.2594937148253\n",
      "    val_loss       : -1510.3102010091145\n",
      "    val_ess        : 3.7657849490642548\n",
      "    val_log_marginal: 1510.459452311198\n",
      "Train Epoch: 284 [0/54000 (0%)] Loss: -1506.790527\n",
      "Train Epoch: 284 [4096/54000 (8%)] Loss: -1511.993774\n",
      "Train Epoch: 284 [8192/54000 (15%)] Loss: -1514.913574\n",
      "Train Epoch: 284 [12288/54000 (23%)] Loss: -1510.069580\n",
      "Train Epoch: 284 [16384/54000 (30%)] Loss: -1508.338379\n",
      "Train Epoch: 284 [20480/54000 (38%)] Loss: -1512.832886\n",
      "Train Epoch: 284 [24576/54000 (46%)] Loss: -1508.355225\n",
      "Train Epoch: 284 [28672/54000 (53%)] Loss: -1512.558228\n",
      "Train Epoch: 284 [32768/54000 (61%)] Loss: -1508.415039\n",
      "Train Epoch: 284 [36864/54000 (68%)] Loss: -1513.647705\n",
      "Train Epoch: 284 [40960/54000 (76%)] Loss: -1501.710449\n",
      "Train Epoch: 284 [45056/54000 (83%)] Loss: -1511.554688\n",
      "Train Epoch: 284 [49152/54000 (91%)] Loss: -1512.341797\n",
      "Train Epoch: 284 [53248/54000 (99%)] Loss: -1512.176147\n",
      "    epoch          : 284\n",
      "    loss           : -1510.7386781231487\n",
      "    ess            : 3.772683089378321\n",
      "    log_marginal   : 1510.8806649881517\n",
      "    val_loss       : -1510.6840718587239\n",
      "    val_ess        : 3.7700540026028952\n",
      "    val_log_marginal: 1510.8211059570312\n",
      "Train Epoch: 285 [0/54000 (0%)] Loss: -1511.564209\n",
      "Train Epoch: 285 [4096/54000 (8%)] Loss: -1510.185547\n",
      "Train Epoch: 285 [8192/54000 (15%)] Loss: -1512.416992\n",
      "Train Epoch: 285 [12288/54000 (23%)] Loss: -1507.262451\n",
      "Train Epoch: 285 [16384/54000 (30%)] Loss: -1519.150146\n",
      "Train Epoch: 285 [20480/54000 (38%)] Loss: -1513.907471\n",
      "Train Epoch: 285 [24576/54000 (46%)] Loss: -1506.674316\n",
      "Train Epoch: 285 [28672/54000 (53%)] Loss: -1509.666748\n",
      "Train Epoch: 285 [32768/54000 (61%)] Loss: -1512.329590\n",
      "Train Epoch: 285 [36864/54000 (68%)] Loss: -1510.459473\n",
      "Train Epoch: 285 [40960/54000 (76%)] Loss: -1501.778687\n",
      "Train Epoch: 285 [45056/54000 (83%)] Loss: -1515.655273\n",
      "Train Epoch: 285 [49152/54000 (91%)] Loss: -1508.756592\n",
      "Train Epoch: 285 [53248/54000 (99%)] Loss: -1510.903320\n",
      "    epoch          : 285\n",
      "    loss           : -1510.9703612124185\n",
      "    ess            : 3.767482183555856\n",
      "    log_marginal   : 1511.1147628711863\n",
      "    val_loss       : -1510.4746958414714\n",
      "    val_ess        : 3.77325106660525\n",
      "    val_log_marginal: 1510.6192576090496\n",
      "Train Epoch: 286 [0/54000 (0%)] Loss: -1507.955322\n",
      "Train Epoch: 286 [4096/54000 (8%)] Loss: -1507.261475\n",
      "Train Epoch: 286 [8192/54000 (15%)] Loss: -1502.710449\n",
      "Train Epoch: 286 [12288/54000 (23%)] Loss: -1515.906006\n",
      "Train Epoch: 286 [16384/54000 (30%)] Loss: -1518.816895\n",
      "Train Epoch: 286 [20480/54000 (38%)] Loss: -1514.789062\n",
      "Train Epoch: 286 [24576/54000 (46%)] Loss: -1512.994019\n",
      "Train Epoch: 286 [28672/54000 (53%)] Loss: -1509.119629\n",
      "Train Epoch: 286 [32768/54000 (61%)] Loss: -1512.797852\n",
      "Train Epoch: 286 [36864/54000 (68%)] Loss: -1516.060303\n",
      "Train Epoch: 286 [40960/54000 (76%)] Loss: -1515.289307\n",
      "Train Epoch: 286 [45056/54000 (83%)] Loss: -1508.388916\n",
      "Train Epoch: 286 [49152/54000 (91%)] Loss: -1508.194946\n",
      "Train Epoch: 286 [53248/54000 (99%)] Loss: -1513.761353\n",
      "    epoch          : 286\n",
      "    loss           : -1511.423297610893\n",
      "    ess            : 3.768260716262022\n",
      "    log_marginal   : 1511.5707377212307\n",
      "    val_loss       : -1511.2485605875652\n",
      "    val_ess        : 3.772376368443171\n",
      "    val_log_marginal: 1511.3909556070964\n",
      "Train Epoch: 287 [0/54000 (0%)] Loss: -1513.477295\n",
      "Train Epoch: 287 [4096/54000 (8%)] Loss: -1510.077881\n",
      "Train Epoch: 287 [8192/54000 (15%)] Loss: -1518.635254\n",
      "Train Epoch: 287 [12288/54000 (23%)] Loss: -1511.513550\n",
      "Train Epoch: 287 [16384/54000 (30%)] Loss: -1505.375610\n",
      "Train Epoch: 287 [20480/54000 (38%)] Loss: -1514.182495\n",
      "Train Epoch: 287 [24576/54000 (46%)] Loss: -1509.654297\n",
      "Train Epoch: 287 [28672/54000 (53%)] Loss: -1517.595703\n",
      "Train Epoch: 287 [32768/54000 (61%)] Loss: -1527.068359\n",
      "Train Epoch: 287 [36864/54000 (68%)] Loss: -1510.335449\n",
      "Train Epoch: 287 [40960/54000 (76%)] Loss: -1518.631226\n",
      "Train Epoch: 287 [45056/54000 (83%)] Loss: -1511.751343\n",
      "Train Epoch: 287 [49152/54000 (91%)] Loss: -1515.130615\n",
      "Train Epoch: 287 [53248/54000 (99%)] Loss: -1511.437500\n",
      "    epoch          : 287\n",
      "    loss           : -1511.6944684213936\n",
      "    ess            : 3.766238603546721\n",
      "    log_marginal   : 1511.8407607236745\n",
      "    val_loss       : -1511.1601155598958\n",
      "    val_ess        : 3.7639153202374778\n",
      "    val_log_marginal: 1511.309117635091\n",
      "Train Epoch: 288 [0/54000 (0%)] Loss: -1508.549683\n",
      "Train Epoch: 288 [4096/54000 (8%)] Loss: -1507.818726\n",
      "Train Epoch: 288 [8192/54000 (15%)] Loss: -1510.006470\n",
      "Train Epoch: 288 [12288/54000 (23%)] Loss: -1512.433594\n",
      "Train Epoch: 288 [16384/54000 (30%)] Loss: -1512.149902\n",
      "Train Epoch: 288 [20480/54000 (38%)] Loss: -1509.144775\n",
      "Train Epoch: 288 [24576/54000 (46%)] Loss: -1514.328125\n",
      "Train Epoch: 288 [28672/54000 (53%)] Loss: -1507.436768\n",
      "Train Epoch: 288 [32768/54000 (61%)] Loss: -1506.540405\n",
      "Train Epoch: 288 [36864/54000 (68%)] Loss: -1507.809448\n",
      "Train Epoch: 288 [40960/54000 (76%)] Loss: -1514.855225\n",
      "Train Epoch: 288 [45056/54000 (83%)] Loss: -1506.173828\n",
      "Train Epoch: 288 [49152/54000 (91%)] Loss: -1507.304688\n",
      "Train Epoch: 288 [53248/54000 (99%)] Loss: -1511.936035\n",
      "    epoch          : 288\n",
      "    loss           : -1511.8644082308945\n",
      "    ess            : 3.7668298680635424\n",
      "    log_marginal   : 1512.0108150825681\n",
      "    val_loss       : -1511.2058919270833\n",
      "    val_ess        : 3.7732782463232675\n",
      "    val_log_marginal: 1511.3442281087239\n",
      "Train Epoch: 289 [0/54000 (0%)] Loss: -1516.224243\n",
      "Train Epoch: 289 [4096/54000 (8%)] Loss: -1518.944702\n",
      "Train Epoch: 289 [8192/54000 (15%)] Loss: -1512.041992\n",
      "Train Epoch: 289 [12288/54000 (23%)] Loss: -1517.046387\n",
      "Train Epoch: 289 [16384/54000 (30%)] Loss: -1513.604736\n",
      "Train Epoch: 289 [20480/54000 (38%)] Loss: -1518.731201\n",
      "Train Epoch: 289 [24576/54000 (46%)] Loss: -1516.149536\n",
      "Train Epoch: 289 [28672/54000 (53%)] Loss: -1509.185303\n",
      "Train Epoch: 289 [32768/54000 (61%)] Loss: -1510.717529\n",
      "Train Epoch: 289 [36864/54000 (68%)] Loss: -1506.841553\n",
      "Train Epoch: 289 [40960/54000 (76%)] Loss: -1517.093750\n",
      "Train Epoch: 289 [45056/54000 (83%)] Loss: -1514.456909\n",
      "Train Epoch: 289 [49152/54000 (91%)] Loss: -1516.359253\n",
      "Train Epoch: 289 [53248/54000 (99%)] Loss: -1510.982422\n",
      "    epoch          : 289\n",
      "    loss           : -1512.146944308168\n",
      "    ess            : 3.7643157633559965\n",
      "    log_marginal   : 1512.293634640662\n",
      "    val_loss       : -1510.769810994466\n",
      "    val_ess        : 3.753339777390162\n",
      "    val_log_marginal: 1510.9195810953777\n",
      "Train Epoch: 290 [0/54000 (0%)] Loss: -1505.184204\n",
      "Train Epoch: 290 [4096/54000 (8%)] Loss: -1510.297363\n",
      "Train Epoch: 290 [8192/54000 (15%)] Loss: -1499.775635\n",
      "Train Epoch: 290 [12288/54000 (23%)] Loss: -1519.214844\n",
      "Train Epoch: 290 [16384/54000 (30%)] Loss: -1510.210205\n",
      "Train Epoch: 290 [20480/54000 (38%)] Loss: -1513.930908\n",
      "Train Epoch: 290 [24576/54000 (46%)] Loss: -1511.191772\n",
      "Train Epoch: 290 [28672/54000 (53%)] Loss: -1513.513916\n",
      "Train Epoch: 290 [32768/54000 (61%)] Loss: -1507.085205\n",
      "Train Epoch: 290 [36864/54000 (68%)] Loss: -1512.143677\n",
      "Train Epoch: 290 [40960/54000 (76%)] Loss: -1508.096436\n",
      "Train Epoch: 290 [45056/54000 (83%)] Loss: -1508.228271\n",
      "Train Epoch: 290 [49152/54000 (91%)] Loss: -1509.844238\n",
      "Train Epoch: 290 [53248/54000 (99%)] Loss: -1513.211426\n",
      "    epoch          : 290\n",
      "    loss           : -1512.3598974146548\n",
      "    ess            : 3.7705964883921834\n",
      "    log_marginal   : 1512.503573015403\n",
      "    val_loss       : -1512.7544555664062\n",
      "    val_ess        : 3.7729250888029733\n",
      "    val_log_marginal: 1512.8890533447266\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch290.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 291 [0/54000 (0%)] Loss: -1517.700317\n",
      "Train Epoch: 291 [4096/54000 (8%)] Loss: -1511.893555\n",
      "Train Epoch: 291 [8192/54000 (15%)] Loss: -1509.595337\n",
      "Train Epoch: 291 [12288/54000 (23%)] Loss: -1513.950073\n",
      "Train Epoch: 291 [16384/54000 (30%)] Loss: -1512.636597\n",
      "Train Epoch: 291 [20480/54000 (38%)] Loss: -1515.594238\n",
      "Train Epoch: 291 [24576/54000 (46%)] Loss: -1507.308105\n",
      "Train Epoch: 291 [28672/54000 (53%)] Loss: -1518.799805\n",
      "Train Epoch: 291 [32768/54000 (61%)] Loss: -1512.407959\n",
      "Train Epoch: 291 [36864/54000 (68%)] Loss: -1518.682007\n",
      "Train Epoch: 291 [40960/54000 (76%)] Loss: -1508.113037\n",
      "Train Epoch: 291 [45056/54000 (83%)] Loss: -1520.115845\n",
      "Train Epoch: 291 [49152/54000 (91%)] Loss: -1508.649292\n",
      "Train Epoch: 291 [53248/54000 (99%)] Loss: -1509.401367\n",
      "    epoch          : 291\n",
      "    loss           : -1512.7312410906027\n",
      "    ess            : 3.7701446953542987\n",
      "    log_marginal   : 1512.8754419986672\n",
      "    val_loss       : -1511.5278828938801\n",
      "    val_ess        : 3.7623190879821777\n",
      "    val_log_marginal: 1511.6703287760417\n",
      "Train Epoch: 292 [0/54000 (0%)] Loss: -1511.429932\n",
      "Train Epoch: 292 [4096/54000 (8%)] Loss: -1510.918335\n",
      "Train Epoch: 292 [8192/54000 (15%)] Loss: -1508.892944\n",
      "Train Epoch: 292 [12288/54000 (23%)] Loss: -1511.057251\n",
      "Train Epoch: 292 [16384/54000 (30%)] Loss: -1516.060669\n",
      "Train Epoch: 292 [20480/54000 (38%)] Loss: -1510.410156\n",
      "Train Epoch: 292 [24576/54000 (46%)] Loss: -1517.853760\n",
      "Train Epoch: 292 [28672/54000 (53%)] Loss: -1510.118286\n",
      "Train Epoch: 292 [32768/54000 (61%)] Loss: -1506.024658\n",
      "Train Epoch: 292 [36864/54000 (68%)] Loss: -1511.896729\n",
      "Train Epoch: 292 [40960/54000 (76%)] Loss: -1509.559204\n",
      "Train Epoch: 292 [45056/54000 (83%)] Loss: -1513.990112\n",
      "Train Epoch: 292 [49152/54000 (91%)] Loss: -1512.883423\n",
      "Train Epoch: 292 [53248/54000 (99%)] Loss: -1510.175293\n",
      "    epoch          : 292\n",
      "    loss           : -1512.8353022715492\n",
      "    ess            : 3.7634457570116666\n",
      "    log_marginal   : 1512.9824085687574\n",
      "    val_loss       : -1512.3519185384114\n",
      "    val_ess        : 3.770592470963796\n",
      "    val_log_marginal: 1512.5050354003906\n",
      "Train Epoch: 293 [0/54000 (0%)] Loss: -1514.939331\n",
      "Train Epoch: 293 [4096/54000 (8%)] Loss: -1511.433350\n",
      "Train Epoch: 293 [8192/54000 (15%)] Loss: -1507.782104\n",
      "Train Epoch: 293 [12288/54000 (23%)] Loss: -1513.695312\n",
      "Train Epoch: 293 [16384/54000 (30%)] Loss: -1500.554932\n",
      "Train Epoch: 293 [20480/54000 (38%)] Loss: -1512.467773\n",
      "Train Epoch: 293 [24576/54000 (46%)] Loss: -1515.744751\n",
      "Train Epoch: 293 [28672/54000 (53%)] Loss: -1510.559082\n",
      "Train Epoch: 293 [32768/54000 (61%)] Loss: -1513.248291\n",
      "Train Epoch: 293 [36864/54000 (68%)] Loss: -1512.007324\n",
      "Train Epoch: 293 [40960/54000 (76%)] Loss: -1514.170898\n",
      "Train Epoch: 293 [45056/54000 (83%)] Loss: -1517.066772\n",
      "Train Epoch: 293 [49152/54000 (91%)] Loss: -1513.928101\n",
      "Train Epoch: 293 [53248/54000 (99%)] Loss: -1523.625244\n",
      "    epoch          : 293\n",
      "    loss           : -1513.0438857236745\n",
      "    ess            : 3.770207815260684\n",
      "    log_marginal   : 1513.187615127925\n",
      "    val_loss       : -1513.1213684082031\n",
      "    val_ess        : 3.7637572983900704\n",
      "    val_log_marginal: 1513.270523071289\n",
      "Train Epoch: 294 [0/54000 (0%)] Loss: -1513.502441\n",
      "Train Epoch: 294 [4096/54000 (8%)] Loss: -1511.942383\n",
      "Train Epoch: 294 [8192/54000 (15%)] Loss: -1509.629150\n",
      "Train Epoch: 294 [12288/54000 (23%)] Loss: -1512.665771\n",
      "Train Epoch: 294 [16384/54000 (30%)] Loss: -1509.866943\n",
      "Train Epoch: 294 [20480/54000 (38%)] Loss: -1511.624756\n",
      "Train Epoch: 294 [24576/54000 (46%)] Loss: -1512.672241\n",
      "Train Epoch: 294 [28672/54000 (53%)] Loss: -1515.503784\n",
      "Train Epoch: 294 [32768/54000 (61%)] Loss: -1513.131714\n",
      "Train Epoch: 294 [36864/54000 (68%)] Loss: -1515.354980\n",
      "Train Epoch: 294 [40960/54000 (76%)] Loss: -1517.024170\n",
      "Train Epoch: 294 [45056/54000 (83%)] Loss: -1513.516846\n",
      "Train Epoch: 294 [49152/54000 (91%)] Loss: -1528.773438\n",
      "Train Epoch: 294 [53248/54000 (99%)] Loss: -1512.798584\n",
      "    epoch          : 294\n",
      "    loss           : -1513.3802524946311\n",
      "    ess            : 3.7700099696480267\n",
      "    log_marginal   : 1513.5231817887293\n",
      "    val_loss       : -1512.6562805175781\n",
      "    val_ess        : 3.773578683535258\n",
      "    val_log_marginal: 1512.7968495686848\n",
      "Train Epoch: 295 [0/54000 (0%)] Loss: -1512.907715\n",
      "Train Epoch: 295 [4096/54000 (8%)] Loss: -1512.437744\n",
      "Train Epoch: 295 [8192/54000 (15%)] Loss: -1515.775269\n",
      "Train Epoch: 295 [12288/54000 (23%)] Loss: -1513.774658\n",
      "Train Epoch: 295 [16384/54000 (30%)] Loss: -1515.198975\n",
      "Train Epoch: 295 [20480/54000 (38%)] Loss: -1519.938232\n",
      "Train Epoch: 295 [24576/54000 (46%)] Loss: -1509.103760\n",
      "Train Epoch: 295 [28672/54000 (53%)] Loss: -1515.913208\n",
      "Train Epoch: 295 [32768/54000 (61%)] Loss: -1509.903076\n",
      "Train Epoch: 295 [36864/54000 (68%)] Loss: -1515.847900\n",
      "Train Epoch: 295 [40960/54000 (76%)] Loss: -1523.279785\n",
      "Train Epoch: 295 [45056/54000 (83%)] Loss: -1511.611572\n",
      "Train Epoch: 295 [49152/54000 (91%)] Loss: -1507.653320\n",
      "Train Epoch: 295 [53248/54000 (99%)] Loss: -1518.810303\n",
      "    epoch          : 295\n",
      "    loss           : -1513.6270798235707\n",
      "    ess            : 3.771587096119379\n",
      "    log_marginal   : 1513.7683695571682\n",
      "    val_loss       : -1513.5699310302734\n",
      "    val_ess        : 3.775605320930481\n",
      "    val_log_marginal: 1513.6975962320964\n",
      "Train Epoch: 296 [0/54000 (0%)] Loss: -1514.390625\n",
      "Train Epoch: 296 [4096/54000 (8%)] Loss: -1516.705933\n",
      "Train Epoch: 296 [8192/54000 (15%)] Loss: -1513.751343\n",
      "Train Epoch: 296 [12288/54000 (23%)] Loss: -1521.948364\n",
      "Train Epoch: 296 [16384/54000 (30%)] Loss: -1522.372559\n",
      "Train Epoch: 296 [20480/54000 (38%)] Loss: -1517.729248\n",
      "Train Epoch: 296 [24576/54000 (46%)] Loss: -1509.652832\n",
      "Train Epoch: 296 [28672/54000 (53%)] Loss: -1516.664185\n",
      "Train Epoch: 296 [32768/54000 (61%)] Loss: -1521.294067\n",
      "Train Epoch: 296 [36864/54000 (68%)] Loss: -1512.627686\n",
      "Train Epoch: 296 [40960/54000 (76%)] Loss: -1514.979614\n",
      "Train Epoch: 296 [45056/54000 (83%)] Loss: -1519.095581\n",
      "Train Epoch: 296 [49152/54000 (91%)] Loss: -1515.654541\n",
      "Train Epoch: 296 [53248/54000 (99%)] Loss: -1515.676636\n",
      "    epoch          : 296\n",
      "    loss           : -1513.905247403547\n",
      "    ess            : 3.7687329669699285\n",
      "    log_marginal   : 1514.050664386478\n",
      "    val_loss       : -1514.3533884684246\n",
      "    val_ess        : 3.7674268782138824\n",
      "    val_log_marginal: 1514.5021107991536\n",
      "Train Epoch: 297 [0/54000 (0%)] Loss: -1512.411133\n",
      "Train Epoch: 297 [4096/54000 (8%)] Loss: -1518.279053\n",
      "Train Epoch: 297 [8192/54000 (15%)] Loss: -1518.827637\n",
      "Train Epoch: 297 [12288/54000 (23%)] Loss: -1515.331787\n",
      "Train Epoch: 297 [16384/54000 (30%)] Loss: -1517.185303\n",
      "Train Epoch: 297 [20480/54000 (38%)] Loss: -1511.621338\n",
      "Train Epoch: 297 [24576/54000 (46%)] Loss: -1509.417725\n",
      "Train Epoch: 297 [28672/54000 (53%)] Loss: -1511.881226\n",
      "Train Epoch: 297 [32768/54000 (61%)] Loss: -1513.580444\n",
      "Train Epoch: 297 [36864/54000 (68%)] Loss: -1515.587036\n",
      "Train Epoch: 297 [40960/54000 (76%)] Loss: -1509.054199\n",
      "Train Epoch: 297 [45056/54000 (83%)] Loss: -1513.674561\n",
      "Train Epoch: 297 [49152/54000 (91%)] Loss: -1518.274048\n",
      "Train Epoch: 297 [53248/54000 (99%)] Loss: -1506.322144\n",
      "    epoch          : 297\n",
      "    loss           : -1514.3106874583457\n",
      "    ess            : 3.7679117336092403\n",
      "    log_marginal   : 1514.4548750601673\n",
      "    val_loss       : -1514.6294860839844\n",
      "    val_ess        : 3.7792659203211465\n",
      "    val_log_marginal: 1514.7667592366536\n",
      "Train Epoch: 298 [0/54000 (0%)] Loss: -1515.523193\n",
      "Train Epoch: 298 [4096/54000 (8%)] Loss: -1517.318604\n",
      "Train Epoch: 298 [8192/54000 (15%)] Loss: -1512.731323\n",
      "Train Epoch: 298 [12288/54000 (23%)] Loss: -1511.850586\n",
      "Train Epoch: 298 [16384/54000 (30%)] Loss: -1512.301392\n",
      "Train Epoch: 298 [20480/54000 (38%)] Loss: -1514.599487\n",
      "Train Epoch: 298 [24576/54000 (46%)] Loss: -1514.652222\n",
      "Train Epoch: 298 [28672/54000 (53%)] Loss: -1512.454346\n",
      "Train Epoch: 298 [32768/54000 (61%)] Loss: -1508.377808\n",
      "Train Epoch: 298 [36864/54000 (68%)] Loss: -1514.922363\n",
      "Train Epoch: 298 [40960/54000 (76%)] Loss: -1511.402710\n",
      "Train Epoch: 298 [45056/54000 (83%)] Loss: -1520.790283\n",
      "Train Epoch: 298 [49152/54000 (91%)] Loss: -1516.358643\n",
      "Train Epoch: 298 [53248/54000 (99%)] Loss: -1518.818481\n",
      "    epoch          : 298\n",
      "    loss           : -1514.4861915913802\n",
      "    ess            : 3.7684856172986505\n",
      "    log_marginal   : 1514.634648761478\n",
      "    val_loss       : -1514.2736155192058\n",
      "    val_ess        : 3.77608789006869\n",
      "    val_log_marginal: 1514.419189453125\n",
      "Train Epoch: 299 [0/54000 (0%)] Loss: -1514.814941\n",
      "Train Epoch: 299 [4096/54000 (8%)] Loss: -1522.518066\n",
      "Train Epoch: 299 [8192/54000 (15%)] Loss: -1518.406494\n",
      "Train Epoch: 299 [12288/54000 (23%)] Loss: -1516.381226\n",
      "Train Epoch: 299 [16384/54000 (30%)] Loss: -1513.852295\n",
      "Train Epoch: 299 [20480/54000 (38%)] Loss: -1517.798218\n",
      "Train Epoch: 299 [24576/54000 (46%)] Loss: -1508.339844\n",
      "Train Epoch: 299 [28672/54000 (53%)] Loss: -1521.583496\n",
      "Train Epoch: 299 [32768/54000 (61%)] Loss: -1521.447876\n",
      "Train Epoch: 299 [36864/54000 (68%)] Loss: -1516.552124\n",
      "Train Epoch: 299 [40960/54000 (76%)] Loss: -1514.554932\n",
      "Train Epoch: 299 [45056/54000 (83%)] Loss: -1509.596680\n",
      "Train Epoch: 299 [49152/54000 (91%)] Loss: -1516.809082\n",
      "Train Epoch: 299 [53248/54000 (99%)] Loss: -1512.140259\n",
      "    epoch          : 299\n",
      "    loss           : -1514.9814221712086\n",
      "    ess            : 3.7670657352248638\n",
      "    log_marginal   : 1515.1280170458754\n",
      "    val_loss       : -1514.6780751546223\n",
      "    val_ess        : 3.765742947657903\n",
      "    val_log_marginal: 1514.8302663167317\n",
      "Train Epoch: 300 [0/54000 (0%)] Loss: -1510.964722\n",
      "Train Epoch: 300 [4096/54000 (8%)] Loss: -1518.582764\n",
      "Train Epoch: 300 [8192/54000 (15%)] Loss: -1516.395264\n",
      "Train Epoch: 300 [12288/54000 (23%)] Loss: -1515.524658\n",
      "Train Epoch: 300 [16384/54000 (30%)] Loss: -1516.081299\n",
      "Train Epoch: 300 [20480/54000 (38%)] Loss: -1516.856689\n",
      "Train Epoch: 300 [24576/54000 (46%)] Loss: -1517.136963\n",
      "Train Epoch: 300 [28672/54000 (53%)] Loss: -1518.954102\n",
      "Train Epoch: 300 [32768/54000 (61%)] Loss: -1519.616577\n",
      "Train Epoch: 300 [36864/54000 (68%)] Loss: -1515.267456\n",
      "Train Epoch: 300 [40960/54000 (76%)] Loss: -1518.879272\n",
      "Train Epoch: 300 [45056/54000 (83%)] Loss: -1507.539795\n",
      "Train Epoch: 300 [49152/54000 (91%)] Loss: -1519.094482\n",
      "Train Epoch: 300 [53248/54000 (99%)] Loss: -1517.512207\n",
      "    epoch          : 300\n",
      "    loss           : -1515.2638240289914\n",
      "    ess            : 3.7688895379197542\n",
      "    log_marginal   : 1515.4067637366707\n",
      "    val_loss       : -1514.8641662597656\n",
      "    val_ess        : 3.783518503109614\n",
      "    val_log_marginal: 1515.0010426839192\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch300.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 301 [0/54000 (0%)] Loss: -1518.028320\n",
      "Train Epoch: 301 [4096/54000 (8%)] Loss: -1514.895264\n",
      "Train Epoch: 301 [8192/54000 (15%)] Loss: -1518.558105\n",
      "Train Epoch: 301 [12288/54000 (23%)] Loss: -1518.312988\n",
      "Train Epoch: 301 [16384/54000 (30%)] Loss: -1517.994019\n",
      "Train Epoch: 301 [20480/54000 (38%)] Loss: -1512.388184\n",
      "Train Epoch: 301 [24576/54000 (46%)] Loss: -1512.376953\n",
      "Train Epoch: 301 [28672/54000 (53%)] Loss: -1514.482666\n",
      "Train Epoch: 301 [32768/54000 (61%)] Loss: -1516.581055\n",
      "Train Epoch: 301 [36864/54000 (68%)] Loss: -1509.860107\n",
      "Train Epoch: 301 [40960/54000 (76%)] Loss: -1511.333862\n",
      "Train Epoch: 301 [45056/54000 (83%)] Loss: -1509.488525\n",
      "Train Epoch: 301 [49152/54000 (91%)] Loss: -1516.299561\n",
      "Train Epoch: 301 [53248/54000 (99%)] Loss: -1516.164795\n",
      "    epoch          : 301\n",
      "    loss           : -1514.9874452708457\n",
      "    ess            : 3.7682415749789415\n",
      "    log_marginal   : 1515.1330439129147\n",
      "    val_loss       : -1515.375249226888\n",
      "    val_ess        : 3.777616639931997\n",
      "    val_log_marginal: 1515.514653523763\n",
      "Train Epoch: 302 [0/54000 (0%)] Loss: -1510.562256\n",
      "Train Epoch: 302 [4096/54000 (8%)] Loss: -1517.103760\n",
      "Train Epoch: 302 [8192/54000 (15%)] Loss: -1514.907959\n",
      "Train Epoch: 302 [12288/54000 (23%)] Loss: -1517.354492\n",
      "Train Epoch: 302 [16384/54000 (30%)] Loss: -1511.771729\n",
      "Train Epoch: 302 [20480/54000 (38%)] Loss: -1519.194336\n",
      "Train Epoch: 302 [24576/54000 (46%)] Loss: -1517.928223\n",
      "Train Epoch: 302 [28672/54000 (53%)] Loss: -1512.183228\n",
      "Train Epoch: 302 [32768/54000 (61%)] Loss: -1515.835083\n",
      "Train Epoch: 302 [36864/54000 (68%)] Loss: -1513.312012\n",
      "Train Epoch: 302 [40960/54000 (76%)] Loss: -1523.823120\n",
      "Train Epoch: 302 [45056/54000 (83%)] Loss: -1505.854736\n",
      "Train Epoch: 302 [49152/54000 (91%)] Loss: -1516.067627\n",
      "Train Epoch: 302 [53248/54000 (99%)] Loss: -1519.419312\n",
      "    epoch          : 302\n",
      "    loss           : -1515.213980579828\n",
      "    ess            : 3.7690123223580456\n",
      "    log_marginal   : 1515.3574224535323\n",
      "    val_loss       : -1515.7621459960938\n",
      "    val_ess        : 3.770206759373347\n",
      "    val_log_marginal: 1515.8975067138672\n",
      "Train Epoch: 303 [0/54000 (0%)] Loss: -1519.589111\n",
      "Train Epoch: 303 [4096/54000 (8%)] Loss: -1513.617188\n",
      "Train Epoch: 303 [8192/54000 (15%)] Loss: -1517.007080\n",
      "Train Epoch: 303 [12288/54000 (23%)] Loss: -1516.273926\n",
      "Train Epoch: 303 [16384/54000 (30%)] Loss: -1514.855225\n",
      "Train Epoch: 303 [20480/54000 (38%)] Loss: -1519.622803\n",
      "Train Epoch: 303 [24576/54000 (46%)] Loss: -1522.255859\n",
      "Train Epoch: 303 [28672/54000 (53%)] Loss: -1514.469238\n",
      "Train Epoch: 303 [32768/54000 (61%)] Loss: -1514.763062\n",
      "Train Epoch: 303 [36864/54000 (68%)] Loss: -1521.797607\n",
      "Train Epoch: 303 [40960/54000 (76%)] Loss: -1514.324707\n",
      "Train Epoch: 303 [45056/54000 (83%)] Loss: -1512.509766\n",
      "Train Epoch: 303 [49152/54000 (91%)] Loss: -1517.997070\n",
      "Train Epoch: 303 [53248/54000 (99%)] Loss: -1510.974976\n",
      "    epoch          : 303\n",
      "    loss           : -1515.588035836604\n",
      "    ess            : 3.7703211725605605\n",
      "    log_marginal   : 1515.7321227738078\n",
      "    val_loss       : -1515.3251037597656\n",
      "    val_ess        : 3.7807997862497964\n",
      "    val_log_marginal: 1515.4649149576824\n",
      "Train Epoch: 304 [0/54000 (0%)] Loss: -1515.863770\n",
      "Train Epoch: 304 [4096/54000 (8%)] Loss: -1511.125732\n",
      "Train Epoch: 304 [8192/54000 (15%)] Loss: -1518.992676\n",
      "Train Epoch: 304 [12288/54000 (23%)] Loss: -1509.764404\n",
      "Train Epoch: 304 [16384/54000 (30%)] Loss: -1514.182861\n",
      "Train Epoch: 304 [20480/54000 (38%)] Loss: -1514.994873\n",
      "Train Epoch: 304 [24576/54000 (46%)] Loss: -1510.499023\n",
      "Train Epoch: 304 [28672/54000 (53%)] Loss: -1519.064453\n",
      "Train Epoch: 304 [32768/54000 (61%)] Loss: -1519.853516\n",
      "Train Epoch: 304 [36864/54000 (68%)] Loss: -1514.220215\n",
      "Train Epoch: 304 [40960/54000 (76%)] Loss: -1512.840576\n",
      "Train Epoch: 304 [45056/54000 (83%)] Loss: -1523.703735\n",
      "Train Epoch: 304 [49152/54000 (91%)] Loss: -1516.419189\n",
      "Train Epoch: 304 [53248/54000 (99%)] Loss: -1512.819824\n",
      "    epoch          : 304\n",
      "    loss           : -1516.0517797967268\n",
      "    ess            : 3.763941596469608\n",
      "    log_marginal   : 1516.2011331133367\n",
      "    val_loss       : -1516.162862141927\n",
      "    val_ess        : 3.7649449606736503\n",
      "    val_log_marginal: 1516.3131408691406\n",
      "Train Epoch: 305 [0/54000 (0%)] Loss: -1510.735840\n",
      "Train Epoch: 305 [4096/54000 (8%)] Loss: -1514.765381\n",
      "Train Epoch: 305 [8192/54000 (15%)] Loss: -1511.745728\n",
      "Train Epoch: 305 [12288/54000 (23%)] Loss: -1509.692749\n",
      "Train Epoch: 305 [16384/54000 (30%)] Loss: -1513.185547\n",
      "Train Epoch: 305 [20480/54000 (38%)] Loss: -1516.531372\n",
      "Train Epoch: 305 [24576/54000 (46%)] Loss: -1518.032104\n",
      "Train Epoch: 305 [28672/54000 (53%)] Loss: -1521.147339\n",
      "Train Epoch: 305 [32768/54000 (61%)] Loss: -1516.846680\n",
      "Train Epoch: 305 [36864/54000 (68%)] Loss: -1512.081787\n",
      "Train Epoch: 305 [40960/54000 (76%)] Loss: -1510.471802\n",
      "Train Epoch: 305 [45056/54000 (83%)] Loss: -1517.640747\n",
      "Train Epoch: 305 [49152/54000 (91%)] Loss: -1513.723389\n",
      "Train Epoch: 305 [53248/54000 (99%)] Loss: -1512.263672\n",
      "    epoch          : 305\n",
      "    loss           : -1516.2459109337974\n",
      "    ess            : 3.7702649317646477\n",
      "    log_marginal   : 1516.3908980672393\n",
      "    val_loss       : -1516.518778483073\n",
      "    val_ess        : 3.761365999778112\n",
      "    val_log_marginal: 1516.6679992675781\n",
      "Train Epoch: 306 [0/54000 (0%)] Loss: -1523.837891\n",
      "Train Epoch: 306 [4096/54000 (8%)] Loss: -1516.762695\n",
      "Train Epoch: 306 [8192/54000 (15%)] Loss: -1515.156128\n",
      "Train Epoch: 306 [12288/54000 (23%)] Loss: -1513.751221\n",
      "Train Epoch: 306 [16384/54000 (30%)] Loss: -1522.374756\n",
      "Train Epoch: 306 [20480/54000 (38%)] Loss: -1516.387695\n",
      "Train Epoch: 306 [24576/54000 (46%)] Loss: -1514.318604\n",
      "Train Epoch: 306 [28672/54000 (53%)] Loss: -1508.935791\n",
      "Train Epoch: 306 [32768/54000 (61%)] Loss: -1508.134277\n",
      "Train Epoch: 306 [36864/54000 (68%)] Loss: -1517.213867\n",
      "Train Epoch: 306 [40960/54000 (76%)] Loss: -1522.765625\n",
      "Train Epoch: 306 [45056/54000 (83%)] Loss: -1512.717163\n",
      "Train Epoch: 306 [49152/54000 (91%)] Loss: -1506.782715\n",
      "Train Epoch: 306 [53248/54000 (99%)] Loss: -1518.363403\n",
      "    epoch          : 306\n",
      "    loss           : -1516.4190372991336\n",
      "    ess            : 3.764546211296913\n",
      "    log_marginal   : 1516.5659625157361\n",
      "    val_loss       : -1515.3218078613281\n",
      "    val_ess        : 3.7674361069997153\n",
      "    val_log_marginal: 1515.4662577311199\n",
      "Train Epoch: 307 [0/54000 (0%)] Loss: -1511.628418\n",
      "Train Epoch: 307 [4096/54000 (8%)] Loss: -1517.792969\n",
      "Train Epoch: 307 [8192/54000 (15%)] Loss: -1514.598999\n",
      "Train Epoch: 307 [12288/54000 (23%)] Loss: -1516.806152\n",
      "Train Epoch: 307 [16384/54000 (30%)] Loss: -1518.965820\n",
      "Train Epoch: 307 [20480/54000 (38%)] Loss: -1515.599243\n",
      "Train Epoch: 307 [24576/54000 (46%)] Loss: -1514.122314\n",
      "Train Epoch: 307 [28672/54000 (53%)] Loss: -1516.446777\n",
      "Train Epoch: 307 [32768/54000 (61%)] Loss: -1512.794189\n",
      "Train Epoch: 307 [36864/54000 (68%)] Loss: -1515.704834\n",
      "Train Epoch: 307 [40960/54000 (76%)] Loss: -1510.611450\n",
      "Train Epoch: 307 [45056/54000 (83%)] Loss: -1518.358887\n",
      "Train Epoch: 307 [49152/54000 (91%)] Loss: -1514.880615\n",
      "Train Epoch: 307 [53248/54000 (99%)] Loss: -1519.937256\n",
      "    epoch          : 307\n",
      "    loss           : -1516.7115195034805\n",
      "    ess            : 3.768287724228267\n",
      "    log_marginal   : 1516.8596660017402\n",
      "    val_loss       : -1516.4788513183594\n",
      "    val_ess        : 3.775787502527237\n",
      "    val_log_marginal: 1516.6154073079426\n",
      "Train Epoch: 308 [0/54000 (0%)] Loss: -1513.958496\n",
      "Train Epoch: 308 [4096/54000 (8%)] Loss: -1519.463257\n",
      "Train Epoch: 308 [8192/54000 (15%)] Loss: -1521.004639\n",
      "Train Epoch: 308 [12288/54000 (23%)] Loss: -1509.232666\n",
      "Train Epoch: 308 [16384/54000 (30%)] Loss: -1516.931641\n",
      "Train Epoch: 308 [20480/54000 (38%)] Loss: -1515.524902\n",
      "Train Epoch: 308 [24576/54000 (46%)] Loss: -1507.963379\n",
      "Train Epoch: 308 [28672/54000 (53%)] Loss: -1522.221191\n",
      "Train Epoch: 308 [32768/54000 (61%)] Loss: -1514.241211\n",
      "Train Epoch: 308 [36864/54000 (68%)] Loss: -1515.292725\n",
      "Train Epoch: 308 [40960/54000 (76%)] Loss: -1526.435303\n",
      "Train Epoch: 308 [45056/54000 (83%)] Loss: -1515.310181\n",
      "Train Epoch: 308 [49152/54000 (91%)] Loss: -1514.619873\n",
      "Train Epoch: 308 [53248/54000 (99%)] Loss: -1523.269531\n",
      "    epoch          : 308\n",
      "    loss           : -1517.0221508441944\n",
      "    ess            : 3.7684511889778607\n",
      "    log_marginal   : 1517.1651229496815\n",
      "    val_loss       : -1516.9230244954426\n",
      "    val_ess        : 3.773375481367111\n",
      "    val_log_marginal: 1517.0584716796875\n",
      "Train Epoch: 309 [0/54000 (0%)] Loss: -1514.558838\n",
      "Train Epoch: 309 [4096/54000 (8%)] Loss: -1515.240479\n",
      "Train Epoch: 309 [8192/54000 (15%)] Loss: -1516.452881\n",
      "Train Epoch: 309 [12288/54000 (23%)] Loss: -1522.473145\n",
      "Train Epoch: 309 [16384/54000 (30%)] Loss: -1520.625244\n",
      "Train Epoch: 309 [20480/54000 (38%)] Loss: -1518.629395\n",
      "Train Epoch: 309 [24576/54000 (46%)] Loss: -1523.980957\n",
      "Train Epoch: 309 [28672/54000 (53%)] Loss: -1512.918945\n",
      "Train Epoch: 309 [32768/54000 (61%)] Loss: -1509.622803\n",
      "Train Epoch: 309 [36864/54000 (68%)] Loss: -1521.809937\n",
      "Train Epoch: 309 [40960/54000 (76%)] Loss: -1517.387695\n",
      "Train Epoch: 309 [45056/54000 (83%)] Loss: -1517.948486\n",
      "Train Epoch: 309 [49152/54000 (91%)] Loss: -1515.425659\n",
      "Train Epoch: 309 [53248/54000 (99%)] Loss: -1518.532959\n",
      "    epoch          : 309\n",
      "    loss           : -1517.015806659138\n",
      "    ess            : 3.761946235222839\n",
      "    log_marginal   : 1517.1663482810648\n",
      "    val_loss       : -1517.508804321289\n",
      "    val_ess        : 3.7685127556324005\n",
      "    val_log_marginal: 1517.6517333984375\n",
      "Train Epoch: 310 [0/54000 (0%)] Loss: -1526.849609\n",
      "Train Epoch: 310 [4096/54000 (8%)] Loss: -1517.101318\n",
      "Train Epoch: 310 [8192/54000 (15%)] Loss: -1525.798096\n",
      "Train Epoch: 310 [12288/54000 (23%)] Loss: -1514.348633\n",
      "Train Epoch: 310 [16384/54000 (30%)] Loss: -1512.683350\n",
      "Train Epoch: 310 [20480/54000 (38%)] Loss: -1518.213623\n",
      "Train Epoch: 310 [24576/54000 (46%)] Loss: -1517.227051\n",
      "Train Epoch: 310 [28672/54000 (53%)] Loss: -1515.244141\n",
      "Train Epoch: 310 [32768/54000 (61%)] Loss: -1523.771118\n",
      "Train Epoch: 310 [36864/54000 (68%)] Loss: -1521.555786\n",
      "Train Epoch: 310 [40960/54000 (76%)] Loss: -1518.224609\n",
      "Train Epoch: 310 [45056/54000 (83%)] Loss: -1512.969727\n",
      "Train Epoch: 310 [49152/54000 (91%)] Loss: -1513.014160\n",
      "Train Epoch: 310 [53248/54000 (99%)] Loss: -1516.245728\n",
      "    epoch          : 310\n",
      "    loss           : -1517.3055622408176\n",
      "    ess            : 3.769287553443728\n",
      "    log_marginal   : 1517.4510822024956\n",
      "    val_loss       : -1517.1804707845051\n",
      "    val_ess        : 3.7744356095790863\n",
      "    val_log_marginal: 1517.3257395426433\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch310.pth ...\n",
      "Train Epoch: 311 [0/54000 (0%)] Loss: -1517.639160\n",
      "Train Epoch: 311 [4096/54000 (8%)] Loss: -1517.179932\n",
      "Train Epoch: 311 [8192/54000 (15%)] Loss: -1515.830322\n",
      "Train Epoch: 311 [12288/54000 (23%)] Loss: -1516.281982\n",
      "Train Epoch: 311 [16384/54000 (30%)] Loss: -1517.382080\n",
      "Train Epoch: 311 [20480/54000 (38%)] Loss: -1512.399414\n",
      "Train Epoch: 311 [24576/54000 (46%)] Loss: -1520.356201\n",
      "Train Epoch: 311 [28672/54000 (53%)] Loss: -1516.332153\n",
      "Train Epoch: 311 [32768/54000 (61%)] Loss: -1514.620728\n",
      "Train Epoch: 311 [36864/54000 (68%)] Loss: -1516.882324\n",
      "Train Epoch: 311 [40960/54000 (76%)] Loss: -1518.167236\n",
      "Train Epoch: 311 [45056/54000 (83%)] Loss: -1512.077881\n",
      "Train Epoch: 311 [49152/54000 (91%)] Loss: -1515.696655\n",
      "Train Epoch: 311 [53248/54000 (99%)] Loss: -1522.973022\n",
      "    epoch          : 311\n",
      "    loss           : -1517.6157747241557\n",
      "    ess            : 3.7672854803184763\n",
      "    log_marginal   : 1517.7599200931206\n",
      "    val_loss       : -1517.2758229573567\n",
      "    val_ess        : 3.743782560030619\n",
      "    val_log_marginal: 1517.439000447591\n",
      "Train Epoch: 312 [0/54000 (0%)] Loss: -1519.772827\n",
      "Train Epoch: 312 [4096/54000 (8%)] Loss: -1521.411255\n",
      "Train Epoch: 312 [8192/54000 (15%)] Loss: -1517.740601\n",
      "Train Epoch: 312 [12288/54000 (23%)] Loss: -1518.661987\n",
      "Train Epoch: 312 [16384/54000 (30%)] Loss: -1519.895020\n",
      "Train Epoch: 312 [20480/54000 (38%)] Loss: -1513.752808\n",
      "Train Epoch: 312 [24576/54000 (46%)] Loss: -1516.192139\n",
      "Train Epoch: 312 [28672/54000 (53%)] Loss: -1516.027222\n",
      "Train Epoch: 312 [32768/54000 (61%)] Loss: -1513.693359\n",
      "Train Epoch: 312 [36864/54000 (68%)] Loss: -1517.162109\n",
      "Train Epoch: 312 [40960/54000 (76%)] Loss: -1517.911133\n",
      "Train Epoch: 312 [45056/54000 (83%)] Loss: -1523.409912\n",
      "Train Epoch: 312 [49152/54000 (91%)] Loss: -1518.485596\n",
      "Train Epoch: 312 [53248/54000 (99%)] Loss: -1519.583984\n",
      "    epoch          : 312\n",
      "    loss           : -1517.7139377684389\n",
      "    ess            : 3.770211208488139\n",
      "    log_marginal   : 1517.8567623481931\n",
      "    val_loss       : -1517.3361002604167\n",
      "    val_ess        : 3.7696324785550437\n",
      "    val_log_marginal: 1517.4813791910808\n",
      "Train Epoch: 313 [0/54000 (0%)] Loss: -1519.662109\n",
      "Train Epoch: 313 [4096/54000 (8%)] Loss: -1522.827759\n",
      "Train Epoch: 313 [8192/54000 (15%)] Loss: -1526.691650\n",
      "Train Epoch: 313 [12288/54000 (23%)] Loss: -1512.572998\n",
      "Train Epoch: 313 [16384/54000 (30%)] Loss: -1519.227539\n",
      "Train Epoch: 313 [20480/54000 (38%)] Loss: -1517.282471\n",
      "Train Epoch: 313 [24576/54000 (46%)] Loss: -1513.479004\n",
      "Train Epoch: 313 [28672/54000 (53%)] Loss: -1516.002441\n",
      "Train Epoch: 313 [32768/54000 (61%)] Loss: -1520.168457\n",
      "Train Epoch: 313 [36864/54000 (68%)] Loss: -1516.041138\n",
      "Train Epoch: 313 [40960/54000 (76%)] Loss: -1514.812500\n",
      "Train Epoch: 313 [45056/54000 (83%)] Loss: -1516.747070\n",
      "Train Epoch: 313 [49152/54000 (91%)] Loss: -1509.875488\n",
      "Train Epoch: 313 [53248/54000 (99%)] Loss: -1516.787476\n",
      "    epoch          : 313\n",
      "    loss           : -1518.0738155129961\n",
      "    ess            : 3.7710652373978313\n",
      "    log_marginal   : 1518.216653977525\n",
      "    val_loss       : -1516.129130045573\n",
      "    val_ess        : 3.765977074702581\n",
      "    val_log_marginal: 1516.2820587158203\n",
      "Train Epoch: 314 [0/54000 (0%)] Loss: -1512.859375\n",
      "Train Epoch: 314 [4096/54000 (8%)] Loss: -1526.258789\n",
      "Train Epoch: 314 [8192/54000 (15%)] Loss: -1516.948242\n",
      "Train Epoch: 314 [12288/54000 (23%)] Loss: -1512.938843\n",
      "Train Epoch: 314 [16384/54000 (30%)] Loss: -1518.858154\n",
      "Train Epoch: 314 [20480/54000 (38%)] Loss: -1518.879639\n",
      "Train Epoch: 314 [24576/54000 (46%)] Loss: -1518.288574\n",
      "Train Epoch: 314 [28672/54000 (53%)] Loss: -1515.770264\n",
      "Train Epoch: 314 [32768/54000 (61%)] Loss: -1516.063232\n",
      "Train Epoch: 314 [36864/54000 (68%)] Loss: -1516.940430\n",
      "Train Epoch: 314 [40960/54000 (76%)] Loss: -1515.262085\n",
      "Train Epoch: 314 [45056/54000 (83%)] Loss: -1521.044678\n",
      "Train Epoch: 314 [49152/54000 (91%)] Loss: -1522.841797\n",
      "Train Epoch: 314 [53248/54000 (99%)] Loss: -1520.007690\n",
      "    epoch          : 314\n",
      "    loss           : -1518.0003233995483\n",
      "    ess            : 3.7707836006489974\n",
      "    log_marginal   : 1518.1441685102561\n",
      "    val_loss       : -1517.5519256591797\n",
      "    val_ess        : 3.777206927537918\n",
      "    val_log_marginal: 1517.6980082194011\n",
      "Train Epoch: 315 [0/54000 (0%)] Loss: -1515.614380\n",
      "Train Epoch: 315 [4096/54000 (8%)] Loss: -1514.164551\n",
      "Train Epoch: 315 [8192/54000 (15%)] Loss: -1516.362915\n",
      "Train Epoch: 315 [12288/54000 (23%)] Loss: -1517.958008\n",
      "Train Epoch: 315 [16384/54000 (30%)] Loss: -1515.468994\n",
      "Train Epoch: 315 [20480/54000 (38%)] Loss: -1527.142334\n",
      "Train Epoch: 315 [24576/54000 (46%)] Loss: -1521.951904\n",
      "Train Epoch: 315 [28672/54000 (53%)] Loss: -1519.980225\n",
      "Train Epoch: 315 [32768/54000 (61%)] Loss: -1520.882202\n",
      "Train Epoch: 315 [36864/54000 (68%)] Loss: -1519.784668\n",
      "Train Epoch: 315 [40960/54000 (76%)] Loss: -1514.200195\n",
      "Train Epoch: 315 [45056/54000 (83%)] Loss: -1526.901367\n",
      "Train Epoch: 315 [49152/54000 (91%)] Loss: -1517.174072\n",
      "Train Epoch: 315 [53248/54000 (99%)] Loss: -1518.179199\n",
      "    epoch          : 315\n",
      "    loss           : -1518.5461483634479\n",
      "    ess            : 3.7722712094184914\n",
      "    log_marginal   : 1518.6913738521919\n",
      "    val_loss       : -1518.106460571289\n",
      "    val_ess        : 3.7767521341641745\n",
      "    val_log_marginal: 1518.2415974934895\n",
      "Train Epoch: 316 [0/54000 (0%)] Loss: -1520.545532\n",
      "Train Epoch: 316 [4096/54000 (8%)] Loss: -1517.848145\n",
      "Train Epoch: 316 [8192/54000 (15%)] Loss: -1519.392700\n",
      "Train Epoch: 316 [12288/54000 (23%)] Loss: -1516.975952\n",
      "Train Epoch: 316 [16384/54000 (30%)] Loss: -1519.140869\n",
      "Train Epoch: 316 [20480/54000 (38%)] Loss: -1520.294922\n",
      "Train Epoch: 316 [24576/54000 (46%)] Loss: -1518.984619\n",
      "Train Epoch: 316 [28672/54000 (53%)] Loss: -1524.571533\n",
      "Train Epoch: 316 [32768/54000 (61%)] Loss: -1518.450806\n",
      "Train Epoch: 316 [36864/54000 (68%)] Loss: -1526.968506\n",
      "Train Epoch: 316 [40960/54000 (76%)] Loss: -1519.010254\n",
      "Train Epoch: 316 [45056/54000 (83%)] Loss: -1518.513306\n",
      "Train Epoch: 316 [49152/54000 (91%)] Loss: -1519.189697\n",
      "Train Epoch: 316 [53248/54000 (99%)] Loss: -1515.556152\n",
      "    epoch          : 316\n",
      "    loss           : -1518.8110062296357\n",
      "    ess            : 3.7666947423564316\n",
      "    log_marginal   : 1518.9557914553095\n",
      "    val_loss       : -1517.5594126383464\n",
      "    val_ess        : 3.772454390923182\n",
      "    val_log_marginal: 1517.697280883789\n",
      "Train Epoch: 317 [0/54000 (0%)] Loss: -1520.415527\n",
      "Train Epoch: 317 [4096/54000 (8%)] Loss: -1523.060547\n",
      "Train Epoch: 317 [8192/54000 (15%)] Loss: -1518.811035\n",
      "Train Epoch: 317 [12288/54000 (23%)] Loss: -1519.564087\n",
      "Train Epoch: 317 [16384/54000 (30%)] Loss: -1519.841675\n",
      "Train Epoch: 317 [20480/54000 (38%)] Loss: -1522.546875\n",
      "Train Epoch: 317 [24576/54000 (46%)] Loss: -1521.065674\n",
      "Train Epoch: 317 [28672/54000 (53%)] Loss: -1517.995850\n",
      "Train Epoch: 317 [32768/54000 (61%)] Loss: -1515.475220\n",
      "Train Epoch: 317 [36864/54000 (68%)] Loss: -1512.704346\n",
      "Train Epoch: 317 [40960/54000 (76%)] Loss: -1512.485229\n",
      "Train Epoch: 317 [45056/54000 (83%)] Loss: -1513.840088\n",
      "Train Epoch: 317 [49152/54000 (91%)] Loss: -1517.569580\n",
      "Train Epoch: 317 [53248/54000 (99%)] Loss: -1520.903687\n",
      "    epoch          : 317\n",
      "    loss           : -1519.1361060843083\n",
      "    ess            : 3.767801603434775\n",
      "    log_marginal   : 1519.2814796773177\n",
      "    val_loss       : -1518.1066131591797\n",
      "    val_ess        : 3.7626015345255532\n",
      "    val_log_marginal: 1518.25439453125\n",
      "Train Epoch: 318 [0/54000 (0%)] Loss: -1517.676147\n",
      "Train Epoch: 318 [4096/54000 (8%)] Loss: -1524.075439\n",
      "Train Epoch: 318 [8192/54000 (15%)] Loss: -1524.437012\n",
      "Train Epoch: 318 [12288/54000 (23%)] Loss: -1522.704346\n",
      "Train Epoch: 318 [16384/54000 (30%)] Loss: -1516.354492\n",
      "Train Epoch: 318 [20480/54000 (38%)] Loss: -1521.255859\n",
      "Train Epoch: 318 [24576/54000 (46%)] Loss: -1526.178955\n",
      "Train Epoch: 318 [28672/54000 (53%)] Loss: -1523.397095\n",
      "Train Epoch: 318 [32768/54000 (61%)] Loss: -1518.674072\n",
      "Train Epoch: 318 [36864/54000 (68%)] Loss: -1518.404297\n",
      "Train Epoch: 318 [40960/54000 (76%)] Loss: -1521.479980\n",
      "Train Epoch: 318 [45056/54000 (83%)] Loss: -1517.000854\n",
      "Train Epoch: 318 [49152/54000 (91%)] Loss: -1521.581299\n",
      "Train Epoch: 318 [53248/54000 (99%)] Loss: -1518.668701\n",
      "    epoch          : 318\n",
      "    loss           : -1519.0108908702978\n",
      "    ess            : 3.76592350684071\n",
      "    log_marginal   : 1519.159383330865\n",
      "    val_loss       : -1518.578618367513\n",
      "    val_ess        : 3.7542549073696136\n",
      "    val_log_marginal: 1518.738260904948\n",
      "Train Epoch: 319 [0/54000 (0%)] Loss: -1520.346436\n",
      "Train Epoch: 319 [4096/54000 (8%)] Loss: -1510.731812\n",
      "Train Epoch: 319 [8192/54000 (15%)] Loss: -1523.401245\n",
      "Train Epoch: 319 [12288/54000 (23%)] Loss: -1517.630859\n",
      "Train Epoch: 319 [16384/54000 (30%)] Loss: -1520.094971\n",
      "Train Epoch: 319 [20480/54000 (38%)] Loss: -1517.079224\n",
      "Train Epoch: 319 [24576/54000 (46%)] Loss: -1521.991577\n",
      "Train Epoch: 319 [28672/54000 (53%)] Loss: -1523.215332\n",
      "Train Epoch: 319 [32768/54000 (61%)] Loss: -1514.867432\n",
      "Train Epoch: 319 [36864/54000 (68%)] Loss: -1517.583496\n",
      "Train Epoch: 319 [40960/54000 (76%)] Loss: -1517.379639\n",
      "Train Epoch: 319 [45056/54000 (83%)] Loss: -1528.469971\n",
      "Train Epoch: 319 [49152/54000 (91%)] Loss: -1522.022949\n",
      "Train Epoch: 319 [53248/54000 (99%)] Loss: -1521.143799\n",
      "    epoch          : 319\n",
      "    loss           : -1519.178336048578\n",
      "    ess            : 3.766752658862073\n",
      "    log_marginal   : 1519.3262372491483\n",
      "    val_loss       : -1518.1658579508464\n",
      "    val_ess        : 3.7655164698759713\n",
      "    val_log_marginal: 1518.318079630534\n",
      "Train Epoch: 320 [0/54000 (0%)] Loss: -1515.395752\n",
      "Train Epoch: 320 [4096/54000 (8%)] Loss: -1513.101929\n",
      "Train Epoch: 320 [8192/54000 (15%)] Loss: -1522.189819\n",
      "Train Epoch: 320 [12288/54000 (23%)] Loss: -1514.559082\n",
      "Train Epoch: 320 [16384/54000 (30%)] Loss: -1518.025146\n",
      "Train Epoch: 320 [20480/54000 (38%)] Loss: -1522.515869\n",
      "Train Epoch: 320 [24576/54000 (46%)] Loss: -1523.913330\n",
      "Train Epoch: 320 [28672/54000 (53%)] Loss: -1519.845947\n",
      "Train Epoch: 320 [32768/54000 (61%)] Loss: -1522.885254\n",
      "Train Epoch: 320 [36864/54000 (68%)] Loss: -1518.032104\n",
      "Train Epoch: 320 [40960/54000 (76%)] Loss: -1522.399414\n",
      "Train Epoch: 320 [45056/54000 (83%)] Loss: -1516.303955\n",
      "Train Epoch: 320 [49152/54000 (91%)] Loss: -1518.971191\n",
      "Train Epoch: 320 [53248/54000 (99%)] Loss: -1520.762451\n",
      "    epoch          : 320\n",
      "    loss           : -1519.5543669931133\n",
      "    ess            : 3.771970556810569\n",
      "    log_marginal   : 1519.6978227515922\n",
      "    val_loss       : -1518.7667032877605\n",
      "    val_ess        : 3.763570487499237\n",
      "    val_log_marginal: 1518.924296061198\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch320.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 321 [0/54000 (0%)] Loss: -1518.695312\n",
      "Train Epoch: 321 [4096/54000 (8%)] Loss: -1521.849121\n",
      "Train Epoch: 321 [8192/54000 (15%)] Loss: -1520.075684\n",
      "Train Epoch: 321 [12288/54000 (23%)] Loss: -1520.025391\n",
      "Train Epoch: 321 [16384/54000 (30%)] Loss: -1518.489502\n",
      "Train Epoch: 321 [20480/54000 (38%)] Loss: -1517.060059\n",
      "Train Epoch: 321 [24576/54000 (46%)] Loss: -1516.452637\n",
      "Train Epoch: 321 [28672/54000 (53%)] Loss: -1519.228638\n",
      "Train Epoch: 321 [32768/54000 (61%)] Loss: -1520.201660\n",
      "Train Epoch: 321 [36864/54000 (68%)] Loss: -1513.799316\n",
      "Train Epoch: 321 [40960/54000 (76%)] Loss: -1521.085815\n",
      "Train Epoch: 321 [45056/54000 (83%)] Loss: -1514.003662\n",
      "Train Epoch: 321 [49152/54000 (91%)] Loss: -1521.407104\n",
      "Train Epoch: 321 [53248/54000 (99%)] Loss: -1514.103271\n",
      "    epoch          : 321\n",
      "    loss           : -1519.7032974026215\n",
      "    ess            : 3.7709219693007627\n",
      "    log_marginal   : 1519.8495440008517\n",
      "    val_loss       : -1518.7923024495442\n",
      "    val_ess        : 3.7588627636432648\n",
      "    val_log_marginal: 1518.9384256998699\n",
      "Train Epoch: 322 [0/54000 (0%)] Loss: -1516.412109\n",
      "Train Epoch: 322 [4096/54000 (8%)] Loss: -1515.404053\n",
      "Train Epoch: 322 [8192/54000 (15%)] Loss: -1516.807373\n",
      "Train Epoch: 322 [12288/54000 (23%)] Loss: -1521.952148\n",
      "Train Epoch: 322 [16384/54000 (30%)] Loss: -1518.816772\n",
      "Train Epoch: 322 [20480/54000 (38%)] Loss: -1523.099609\n",
      "Train Epoch: 322 [24576/54000 (46%)] Loss: -1518.960449\n",
      "Train Epoch: 322 [28672/54000 (53%)] Loss: -1520.036377\n",
      "Train Epoch: 322 [32768/54000 (61%)] Loss: -1519.687744\n",
      "Train Epoch: 322 [36864/54000 (68%)] Loss: -1523.509521\n",
      "Train Epoch: 322 [40960/54000 (76%)] Loss: -1516.260986\n",
      "Train Epoch: 322 [45056/54000 (83%)] Loss: -1516.893311\n",
      "Train Epoch: 322 [49152/54000 (91%)] Loss: -1519.311768\n",
      "Train Epoch: 322 [53248/54000 (99%)] Loss: -1525.614258\n",
      "    epoch          : 322\n",
      "    loss           : -1519.7893679650474\n",
      "    ess            : 3.771095518817269\n",
      "    log_marginal   : 1519.9310337446311\n",
      "    val_loss       : -1520.023401896159\n",
      "    val_ess        : 3.7872636119524636\n",
      "    val_log_marginal: 1520.1603546142578\n",
      "Train Epoch: 323 [0/54000 (0%)] Loss: -1515.219971\n",
      "Train Epoch: 323 [4096/54000 (8%)] Loss: -1523.446289\n",
      "Train Epoch: 323 [8192/54000 (15%)] Loss: -1517.820312\n",
      "Train Epoch: 323 [12288/54000 (23%)] Loss: -1519.734619\n",
      "Train Epoch: 323 [16384/54000 (30%)] Loss: -1521.978027\n",
      "Train Epoch: 323 [20480/54000 (38%)] Loss: -1515.805908\n",
      "Train Epoch: 323 [24576/54000 (46%)] Loss: -1518.196777\n",
      "Train Epoch: 323 [28672/54000 (53%)] Loss: -1513.880493\n",
      "Train Epoch: 323 [32768/54000 (61%)] Loss: -1515.828369\n",
      "Train Epoch: 323 [36864/54000 (68%)] Loss: -1512.192627\n",
      "Train Epoch: 323 [40960/54000 (76%)] Loss: -1524.874512\n",
      "Train Epoch: 323 [45056/54000 (83%)] Loss: -1520.195801\n",
      "Train Epoch: 323 [49152/54000 (91%)] Loss: -1521.821533\n",
      "Train Epoch: 323 [53248/54000 (99%)] Loss: -1519.467285\n",
      "    epoch          : 323\n",
      "    loss           : -1519.844749125259\n",
      "    ess            : 3.7695240499849003\n",
      "    log_marginal   : 1519.9906734810056\n",
      "    val_loss       : -1519.6227569580078\n",
      "    val_ess        : 3.7664613823095956\n",
      "    val_log_marginal: 1519.7791697184246\n",
      "Train Epoch: 324 [0/54000 (0%)] Loss: -1521.690430\n",
      "Train Epoch: 324 [4096/54000 (8%)] Loss: -1516.263062\n",
      "Train Epoch: 324 [8192/54000 (15%)] Loss: -1528.282715\n",
      "Train Epoch: 324 [12288/54000 (23%)] Loss: -1526.201660\n",
      "Train Epoch: 324 [16384/54000 (30%)] Loss: -1521.068359\n",
      "Train Epoch: 324 [20480/54000 (38%)] Loss: -1518.941528\n",
      "Train Epoch: 324 [24576/54000 (46%)] Loss: -1517.260498\n",
      "Train Epoch: 324 [28672/54000 (53%)] Loss: -1524.834839\n",
      "Train Epoch: 324 [32768/54000 (61%)] Loss: -1514.808105\n",
      "Train Epoch: 324 [36864/54000 (68%)] Loss: -1520.067383\n",
      "Train Epoch: 324 [40960/54000 (76%)] Loss: -1525.520752\n",
      "Train Epoch: 324 [45056/54000 (83%)] Loss: -1516.533691\n",
      "Train Epoch: 324 [49152/54000 (91%)] Loss: -1517.483032\n",
      "Train Epoch: 324 [53248/54000 (99%)] Loss: -1521.263672\n",
      "    epoch          : 324\n",
      "    loss           : -1520.0492464038432\n",
      "    ess            : 3.769707592742703\n",
      "    log_marginal   : 1520.1949023206087\n",
      "    val_loss       : -1520.9283854166667\n",
      "    val_ess        : 3.7703871726989746\n",
      "    val_log_marginal: 1521.0734049479167\n",
      "Train Epoch: 325 [0/54000 (0%)] Loss: -1520.898438\n",
      "Train Epoch: 325 [4096/54000 (8%)] Loss: -1519.704102\n",
      "Train Epoch: 325 [8192/54000 (15%)] Loss: -1516.992188\n",
      "Train Epoch: 325 [12288/54000 (23%)] Loss: -1520.194092\n",
      "Train Epoch: 325 [16384/54000 (30%)] Loss: -1522.401611\n",
      "Train Epoch: 325 [20480/54000 (38%)] Loss: -1522.009521\n",
      "Train Epoch: 325 [24576/54000 (46%)] Loss: -1519.576538\n",
      "Train Epoch: 325 [28672/54000 (53%)] Loss: -1521.946899\n",
      "Train Epoch: 325 [32768/54000 (61%)] Loss: -1517.067505\n",
      "Train Epoch: 325 [36864/54000 (68%)] Loss: -1520.027588\n",
      "Train Epoch: 325 [40960/54000 (76%)] Loss: -1520.871582\n",
      "Train Epoch: 325 [45056/54000 (83%)] Loss: -1524.613525\n",
      "Train Epoch: 325 [49152/54000 (91%)] Loss: -1521.153442\n",
      "Train Epoch: 325 [53248/54000 (99%)] Loss: -1518.708740\n",
      "    epoch          : 325\n",
      "    loss           : -1520.0895475414693\n",
      "    ess            : 3.7734521486182913\n",
      "    log_marginal   : 1520.2317600340639\n",
      "    val_loss       : -1519.5896606445312\n",
      "    val_ess        : 3.78559073805809\n",
      "    val_log_marginal: 1519.7237955729167\n",
      "Train Epoch: 326 [0/54000 (0%)] Loss: -1523.336426\n",
      "Train Epoch: 326 [4096/54000 (8%)] Loss: -1522.638672\n",
      "Train Epoch: 326 [8192/54000 (15%)] Loss: -1524.550537\n",
      "Train Epoch: 326 [12288/54000 (23%)] Loss: -1519.641357\n",
      "Train Epoch: 326 [16384/54000 (30%)] Loss: -1513.740601\n",
      "Train Epoch: 326 [20480/54000 (38%)] Loss: -1516.294678\n",
      "Train Epoch: 326 [24576/54000 (46%)] Loss: -1525.755005\n",
      "Train Epoch: 326 [28672/54000 (53%)] Loss: -1519.838623\n",
      "Train Epoch: 326 [32768/54000 (61%)] Loss: -1520.038086\n",
      "Train Epoch: 326 [36864/54000 (68%)] Loss: -1523.233154\n",
      "Train Epoch: 326 [40960/54000 (76%)] Loss: -1519.794067\n",
      "Train Epoch: 326 [45056/54000 (83%)] Loss: -1519.134155\n",
      "Train Epoch: 326 [49152/54000 (91%)] Loss: -1521.430664\n",
      "Train Epoch: 326 [53248/54000 (99%)] Loss: -1522.019287\n",
      "    epoch          : 326\n",
      "    loss           : -1520.3990079328348\n",
      "    ess            : 3.772255831985112\n",
      "    log_marginal   : 1520.5412539803021\n",
      "    val_loss       : -1520.5029398600261\n",
      "    val_ess        : 3.7759861449400582\n",
      "    val_log_marginal: 1520.635025024414\n",
      "Train Epoch: 327 [0/54000 (0%)] Loss: -1521.564575\n",
      "Train Epoch: 327 [4096/54000 (8%)] Loss: -1518.587646\n",
      "Train Epoch: 327 [8192/54000 (15%)] Loss: -1523.410034\n",
      "Train Epoch: 327 [12288/54000 (23%)] Loss: -1521.455566\n",
      "Train Epoch: 327 [16384/54000 (30%)] Loss: -1522.695557\n",
      "Train Epoch: 327 [20480/54000 (38%)] Loss: -1525.048706\n",
      "Train Epoch: 327 [24576/54000 (46%)] Loss: -1523.467529\n",
      "Train Epoch: 327 [28672/54000 (53%)] Loss: -1521.609375\n",
      "Train Epoch: 327 [32768/54000 (61%)] Loss: -1517.801270\n",
      "Train Epoch: 327 [36864/54000 (68%)] Loss: -1525.718506\n",
      "Train Epoch: 327 [40960/54000 (76%)] Loss: -1524.944580\n",
      "Train Epoch: 327 [45056/54000 (83%)] Loss: -1525.155273\n",
      "Train Epoch: 327 [49152/54000 (91%)] Loss: -1514.523071\n",
      "Train Epoch: 327 [53248/54000 (99%)] Loss: -1526.203857\n",
      "    epoch          : 327\n",
      "    loss           : -1520.620183718713\n",
      "    ess            : 3.768951567428372\n",
      "    log_marginal   : 1520.767820530028\n",
      "    val_loss       : -1520.545654296875\n",
      "    val_ess        : 3.779316544532776\n",
      "    val_log_marginal: 1520.6971638997395\n",
      "Train Epoch: 328 [0/54000 (0%)] Loss: -1527.510254\n",
      "Train Epoch: 328 [4096/54000 (8%)] Loss: -1525.370361\n",
      "Train Epoch: 328 [8192/54000 (15%)] Loss: -1524.989502\n",
      "Train Epoch: 328 [12288/54000 (23%)] Loss: -1518.656006\n",
      "Train Epoch: 328 [16384/54000 (30%)] Loss: -1525.830566\n",
      "Train Epoch: 328 [20480/54000 (38%)] Loss: -1526.300781\n",
      "Train Epoch: 328 [24576/54000 (46%)] Loss: -1527.193604\n",
      "Train Epoch: 328 [28672/54000 (53%)] Loss: -1518.170898\n",
      "Train Epoch: 328 [32768/54000 (61%)] Loss: -1521.431641\n",
      "Train Epoch: 328 [36864/54000 (68%)] Loss: -1515.926025\n",
      "Train Epoch: 328 [40960/54000 (76%)] Loss: -1527.158203\n",
      "Train Epoch: 328 [45056/54000 (83%)] Loss: -1516.997070\n",
      "Train Epoch: 328 [49152/54000 (91%)] Loss: -1519.222900\n",
      "Train Epoch: 328 [53248/54000 (99%)] Loss: -1515.628174\n",
      "    epoch          : 328\n",
      "    loss           : -1521.0301791367372\n",
      "    ess            : 3.77122374846472\n",
      "    log_marginal   : 1521.1743673170913\n",
      "    val_loss       : -1519.950424194336\n",
      "    val_ess        : 3.7634054521719613\n",
      "    val_log_marginal: 1520.0968678792317\n",
      "Train Epoch: 329 [0/54000 (0%)] Loss: -1530.593994\n",
      "Train Epoch: 329 [4096/54000 (8%)] Loss: -1522.897949\n",
      "Train Epoch: 329 [8192/54000 (15%)] Loss: -1514.984497\n",
      "Train Epoch: 329 [12288/54000 (23%)] Loss: -1529.380371\n",
      "Train Epoch: 329 [16384/54000 (30%)] Loss: -1513.979248\n",
      "Train Epoch: 329 [20480/54000 (38%)] Loss: -1511.899536\n",
      "Train Epoch: 329 [24576/54000 (46%)] Loss: -1517.309082\n",
      "Train Epoch: 329 [28672/54000 (53%)] Loss: -1518.313232\n",
      "Train Epoch: 329 [32768/54000 (61%)] Loss: -1523.286133\n",
      "Train Epoch: 329 [36864/54000 (68%)] Loss: -1513.406860\n",
      "Train Epoch: 329 [40960/54000 (76%)] Loss: -1515.694580\n",
      "Train Epoch: 329 [45056/54000 (83%)] Loss: -1519.427856\n",
      "Train Epoch: 329 [49152/54000 (91%)] Loss: -1518.138672\n",
      "Train Epoch: 329 [53248/54000 (99%)] Loss: -1523.590942\n",
      "    epoch          : 329\n",
      "    loss           : -1521.0630345638328\n",
      "    ess            : 3.769370240622787\n",
      "    log_marginal   : 1521.2058174892625\n",
      "    val_loss       : -1520.9189707438152\n",
      "    val_ess        : 3.7699130475521088\n",
      "    val_log_marginal: 1521.0687561035156\n",
      "Train Epoch: 330 [0/54000 (0%)] Loss: -1520.584473\n",
      "Train Epoch: 330 [4096/54000 (8%)] Loss: -1527.155029\n",
      "Train Epoch: 330 [8192/54000 (15%)] Loss: -1524.829590\n",
      "Train Epoch: 330 [12288/54000 (23%)] Loss: -1518.473633\n",
      "Train Epoch: 330 [16384/54000 (30%)] Loss: -1520.133789\n",
      "Train Epoch: 330 [20480/54000 (38%)] Loss: -1518.385132\n",
      "Train Epoch: 330 [24576/54000 (46%)] Loss: -1515.169434\n",
      "Train Epoch: 330 [28672/54000 (53%)] Loss: -1523.977417\n",
      "Train Epoch: 330 [32768/54000 (61%)] Loss: -1520.500000\n",
      "Train Epoch: 330 [36864/54000 (68%)] Loss: -1520.589478\n",
      "Train Epoch: 330 [40960/54000 (76%)] Loss: -1523.583740\n",
      "Train Epoch: 330 [45056/54000 (83%)] Loss: -1522.181885\n",
      "Train Epoch: 330 [49152/54000 (91%)] Loss: -1524.357910\n",
      "Train Epoch: 330 [53248/54000 (99%)] Loss: -1525.557129\n",
      "    epoch          : 330\n",
      "    loss           : -1521.2929762709198\n",
      "    ess            : 3.7721647696472456\n",
      "    log_marginal   : 1521.4371395743854\n",
      "    val_loss       : -1521.0362650553386\n",
      "    val_ess        : 3.7762789825598397\n",
      "    val_log_marginal: 1521.1670328776042\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch330.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 331 [0/54000 (0%)] Loss: -1519.562012\n",
      "Train Epoch: 331 [4096/54000 (8%)] Loss: -1528.320435\n",
      "Train Epoch: 331 [8192/54000 (15%)] Loss: -1516.747559\n",
      "Train Epoch: 331 [12288/54000 (23%)] Loss: -1522.645386\n",
      "Train Epoch: 331 [16384/54000 (30%)] Loss: -1524.795654\n",
      "Train Epoch: 331 [20480/54000 (38%)] Loss: -1521.529541\n",
      "Train Epoch: 331 [24576/54000 (46%)] Loss: -1515.870728\n",
      "Train Epoch: 331 [28672/54000 (53%)] Loss: -1523.527588\n",
      "Train Epoch: 331 [32768/54000 (61%)] Loss: -1523.554077\n",
      "Train Epoch: 331 [36864/54000 (68%)] Loss: -1513.578857\n",
      "Train Epoch: 331 [40960/54000 (76%)] Loss: -1522.484741\n",
      "Train Epoch: 331 [45056/54000 (83%)] Loss: -1521.345215\n",
      "Train Epoch: 331 [49152/54000 (91%)] Loss: -1527.948120\n",
      "Train Epoch: 331 [53248/54000 (99%)] Loss: -1524.015625\n",
      "    epoch          : 331\n",
      "    loss           : -1521.7417339306871\n",
      "    ess            : 3.7667527153593667\n",
      "    log_marginal   : 1521.8916698293099\n",
      "    val_loss       : -1520.7647247314453\n",
      "    val_ess        : 3.773246000210444\n",
      "    val_log_marginal: 1520.9090016682942\n",
      "Train Epoch: 332 [0/54000 (0%)] Loss: -1521.381470\n",
      "Train Epoch: 332 [4096/54000 (8%)] Loss: -1517.629395\n",
      "Train Epoch: 332 [8192/54000 (15%)] Loss: -1531.626709\n",
      "Train Epoch: 332 [12288/54000 (23%)] Loss: -1518.182983\n",
      "Train Epoch: 332 [16384/54000 (30%)] Loss: -1516.101562\n",
      "Train Epoch: 332 [20480/54000 (38%)] Loss: -1524.255127\n",
      "Train Epoch: 332 [24576/54000 (46%)] Loss: -1516.156738\n",
      "Train Epoch: 332 [28672/54000 (53%)] Loss: -1524.553223\n",
      "Train Epoch: 332 [32768/54000 (61%)] Loss: -1520.478882\n",
      "Train Epoch: 332 [36864/54000 (68%)] Loss: -1527.209717\n",
      "Train Epoch: 332 [40960/54000 (76%)] Loss: -1521.977173\n",
      "Train Epoch: 332 [45056/54000 (83%)] Loss: -1525.233154\n",
      "Train Epoch: 332 [49152/54000 (91%)] Loss: -1517.518677\n",
      "Train Epoch: 332 [53248/54000 (99%)] Loss: -1525.384766\n",
      "    epoch          : 332\n",
      "    loss           : -1521.8020754267254\n",
      "    ess            : 3.771263360977173\n",
      "    log_marginal   : 1521.944743802762\n",
      "    val_loss       : -1522.1057739257812\n",
      "    val_ess        : 3.7750125726064048\n",
      "    val_log_marginal: 1522.254623413086\n",
      "Train Epoch: 333 [0/54000 (0%)] Loss: -1520.265137\n",
      "Train Epoch: 333 [4096/54000 (8%)] Loss: -1519.916016\n",
      "Train Epoch: 333 [8192/54000 (15%)] Loss: -1525.451416\n",
      "Train Epoch: 333 [12288/54000 (23%)] Loss: -1520.718994\n",
      "Train Epoch: 333 [16384/54000 (30%)] Loss: -1518.848389\n",
      "Train Epoch: 333 [20480/54000 (38%)] Loss: -1524.898193\n",
      "Train Epoch: 333 [24576/54000 (46%)] Loss: -1528.787964\n",
      "Train Epoch: 333 [28672/54000 (53%)] Loss: -1523.361572\n",
      "Train Epoch: 333 [32768/54000 (61%)] Loss: -1523.052734\n",
      "Train Epoch: 333 [36864/54000 (68%)] Loss: -1523.950439\n",
      "Train Epoch: 333 [40960/54000 (76%)] Loss: -1520.546143\n",
      "Train Epoch: 333 [45056/54000 (83%)] Loss: -1518.719482\n",
      "Train Epoch: 333 [49152/54000 (91%)] Loss: -1524.553467\n",
      "Train Epoch: 333 [53248/54000 (99%)] Loss: -1523.750732\n",
      "    epoch          : 333\n",
      "    loss           : -1521.8399993751852\n",
      "    ess            : 3.7676825941456435\n",
      "    log_marginal   : 1521.9846457531103\n",
      "    val_loss       : -1521.680384318034\n",
      "    val_ess        : 3.781960348288218\n",
      "    val_log_marginal: 1521.820571899414\n",
      "Train Epoch: 334 [0/54000 (0%)] Loss: -1521.752197\n",
      "Train Epoch: 334 [4096/54000 (8%)] Loss: -1516.505127\n",
      "Train Epoch: 334 [8192/54000 (15%)] Loss: -1523.478027\n",
      "Train Epoch: 334 [12288/54000 (23%)] Loss: -1522.885254\n",
      "Train Epoch: 334 [16384/54000 (30%)] Loss: -1522.647461\n",
      "Train Epoch: 334 [20480/54000 (38%)] Loss: -1519.043213\n",
      "Train Epoch: 334 [24576/54000 (46%)] Loss: -1525.596680\n",
      "Train Epoch: 334 [28672/54000 (53%)] Loss: -1520.198730\n",
      "Train Epoch: 334 [32768/54000 (61%)] Loss: -1527.893066\n",
      "Train Epoch: 334 [36864/54000 (68%)] Loss: -1518.084839\n",
      "Train Epoch: 334 [40960/54000 (76%)] Loss: -1523.092896\n",
      "Train Epoch: 334 [45056/54000 (83%)] Loss: -1517.630859\n",
      "Train Epoch: 334 [49152/54000 (91%)] Loss: -1522.329834\n",
      "Train Epoch: 334 [53248/54000 (99%)] Loss: -1522.903320\n",
      "    epoch          : 334\n",
      "    loss           : -1521.990135445979\n",
      "    ess            : 3.7673228724872896\n",
      "    log_marginal   : 1522.1365845305095\n",
      "    val_loss       : -1521.6312611897786\n",
      "    val_ess        : 3.791803538799286\n",
      "    val_log_marginal: 1521.7630310058594\n",
      "Train Epoch: 335 [0/54000 (0%)] Loss: -1525.379639\n",
      "Train Epoch: 335 [4096/54000 (8%)] Loss: -1527.205566\n",
      "Train Epoch: 335 [8192/54000 (15%)] Loss: -1520.680908\n",
      "Train Epoch: 335 [12288/54000 (23%)] Loss: -1526.925171\n",
      "Train Epoch: 335 [16384/54000 (30%)] Loss: -1525.306641\n",
      "Train Epoch: 335 [20480/54000 (38%)] Loss: -1522.600708\n",
      "Train Epoch: 335 [24576/54000 (46%)] Loss: -1522.973633\n",
      "Train Epoch: 335 [28672/54000 (53%)] Loss: -1515.901123\n",
      "Train Epoch: 335 [32768/54000 (61%)] Loss: -1519.087402\n",
      "Train Epoch: 335 [36864/54000 (68%)] Loss: -1527.516846\n",
      "Train Epoch: 335 [40960/54000 (76%)] Loss: -1519.536987\n",
      "Train Epoch: 335 [45056/54000 (83%)] Loss: -1524.355103\n",
      "Train Epoch: 335 [49152/54000 (91%)] Loss: -1522.721924\n",
      "Train Epoch: 335 [53248/54000 (99%)] Loss: -1525.954346\n",
      "    epoch          : 335\n",
      "    loss           : -1522.461231972934\n",
      "    ess            : 3.7702213893004504\n",
      "    log_marginal   : 1522.6084539765995\n",
      "    val_loss       : -1522.3346150716145\n",
      "    val_ess        : 3.772857447465261\n",
      "    val_log_marginal: 1522.4800109863281\n",
      "Train Epoch: 336 [0/54000 (0%)] Loss: -1518.269287\n",
      "Train Epoch: 336 [4096/54000 (8%)] Loss: -1527.203857\n",
      "Train Epoch: 336 [8192/54000 (15%)] Loss: -1523.202881\n",
      "Train Epoch: 336 [12288/54000 (23%)] Loss: -1524.501587\n",
      "Train Epoch: 336 [16384/54000 (30%)] Loss: -1523.022339\n",
      "Train Epoch: 336 [20480/54000 (38%)] Loss: -1525.276123\n",
      "Train Epoch: 336 [24576/54000 (46%)] Loss: -1525.602905\n",
      "Train Epoch: 336 [28672/54000 (53%)] Loss: -1522.137573\n",
      "Train Epoch: 336 [32768/54000 (61%)] Loss: -1528.019775\n",
      "Train Epoch: 336 [36864/54000 (68%)] Loss: -1523.338867\n",
      "Train Epoch: 336 [40960/54000 (76%)] Loss: -1526.529785\n",
      "Train Epoch: 336 [45056/54000 (83%)] Loss: -1527.664551\n",
      "Train Epoch: 336 [49152/54000 (91%)] Loss: -1516.593628\n",
      "Train Epoch: 336 [53248/54000 (99%)] Loss: -1521.180664\n",
      "    epoch          : 336\n",
      "    loss           : -1522.3704388514514\n",
      "    ess            : 3.768914827238327\n",
      "    log_marginal   : 1522.5193542191203\n",
      "    val_loss       : -1522.0689544677734\n",
      "    val_ess        : 3.763213982184728\n",
      "    val_log_marginal: 1522.2200775146484\n",
      "Train Epoch: 337 [0/54000 (0%)] Loss: -1525.596680\n",
      "Train Epoch: 337 [4096/54000 (8%)] Loss: -1526.778931\n",
      "Train Epoch: 337 [8192/54000 (15%)] Loss: -1521.333496\n",
      "Train Epoch: 337 [12288/54000 (23%)] Loss: -1512.571411\n",
      "Train Epoch: 337 [16384/54000 (30%)] Loss: -1520.905396\n",
      "Train Epoch: 337 [20480/54000 (38%)] Loss: -1522.183350\n",
      "Train Epoch: 337 [24576/54000 (46%)] Loss: -1519.957031\n",
      "Train Epoch: 337 [28672/54000 (53%)] Loss: -1520.673706\n",
      "Train Epoch: 337 [32768/54000 (61%)] Loss: -1525.178223\n",
      "Train Epoch: 337 [36864/54000 (68%)] Loss: -1521.387451\n",
      "Train Epoch: 337 [40960/54000 (76%)] Loss: -1526.572388\n",
      "Train Epoch: 337 [45056/54000 (83%)] Loss: -1529.572021\n",
      "Train Epoch: 337 [49152/54000 (91%)] Loss: -1524.732666\n",
      "Train Epoch: 337 [53248/54000 (99%)] Loss: -1522.753174\n",
      "    epoch          : 337\n",
      "    loss           : -1522.7659923680021\n",
      "    ess            : 3.7691556537320827\n",
      "    log_marginal   : 1522.9093567183797\n",
      "    val_loss       : -1522.123026529948\n",
      "    val_ess        : 3.7670473953088126\n",
      "    val_log_marginal: 1522.2755737304688\n",
      "Train Epoch: 338 [0/54000 (0%)] Loss: -1524.609863\n",
      "Train Epoch: 338 [4096/54000 (8%)] Loss: -1525.097168\n",
      "Train Epoch: 338 [8192/54000 (15%)] Loss: -1523.718018\n",
      "Train Epoch: 338 [12288/54000 (23%)] Loss: -1519.606567\n",
      "Train Epoch: 338 [16384/54000 (30%)] Loss: -1526.468262\n",
      "Train Epoch: 338 [20480/54000 (38%)] Loss: -1524.051758\n",
      "Train Epoch: 338 [24576/54000 (46%)] Loss: -1526.832764\n",
      "Train Epoch: 338 [28672/54000 (53%)] Loss: -1519.106934\n",
      "Train Epoch: 338 [32768/54000 (61%)] Loss: -1522.868164\n",
      "Train Epoch: 338 [36864/54000 (68%)] Loss: -1523.712891\n",
      "Train Epoch: 338 [40960/54000 (76%)] Loss: -1524.000488\n",
      "Train Epoch: 338 [45056/54000 (83%)] Loss: -1518.971680\n",
      "Train Epoch: 338 [49152/54000 (91%)] Loss: -1524.653442\n",
      "Train Epoch: 338 [53248/54000 (99%)] Loss: -1529.216064\n",
      "    epoch          : 338\n",
      "    loss           : -1522.8480045264366\n",
      "    ess            : 3.7733584749755136\n",
      "    log_marginal   : 1522.990966796875\n",
      "    val_loss       : -1522.1482340494792\n",
      "    val_ess        : 3.76762518286705\n",
      "    val_log_marginal: 1522.2991994222004\n",
      "Train Epoch: 339 [0/54000 (0%)] Loss: -1518.646729\n",
      "Train Epoch: 339 [4096/54000 (8%)] Loss: -1520.693237\n",
      "Train Epoch: 339 [8192/54000 (15%)] Loss: -1525.803345\n",
      "Train Epoch: 339 [12288/54000 (23%)] Loss: -1521.463379\n",
      "Train Epoch: 339 [16384/54000 (30%)] Loss: -1522.230103\n",
      "Train Epoch: 339 [20480/54000 (38%)] Loss: -1519.191162\n",
      "Train Epoch: 339 [24576/54000 (46%)] Loss: -1522.443848\n",
      "Train Epoch: 339 [28672/54000 (53%)] Loss: -1532.331299\n",
      "Train Epoch: 339 [32768/54000 (61%)] Loss: -1517.916626\n",
      "Train Epoch: 339 [36864/54000 (68%)] Loss: -1528.055420\n",
      "Train Epoch: 339 [40960/54000 (76%)] Loss: -1524.861694\n",
      "Train Epoch: 339 [45056/54000 (83%)] Loss: -1521.260254\n",
      "Train Epoch: 339 [49152/54000 (91%)] Loss: -1513.792847\n",
      "Train Epoch: 339 [53248/54000 (99%)] Loss: -1526.700684\n",
      "    epoch          : 339\n",
      "    loss           : -1523.3282221934242\n",
      "    ess            : 3.7704578948811895\n",
      "    log_marginal   : 1523.4724369862633\n",
      "    val_loss       : -1522.4720967610676\n",
      "    val_ess        : 3.7728550930817923\n",
      "    val_log_marginal: 1522.615758260091\n",
      "Train Epoch: 340 [0/54000 (0%)] Loss: -1526.252686\n",
      "Train Epoch: 340 [4096/54000 (8%)] Loss: -1528.389526\n",
      "Train Epoch: 340 [8192/54000 (15%)] Loss: -1526.185059\n",
      "Train Epoch: 340 [12288/54000 (23%)] Loss: -1522.400879\n",
      "Train Epoch: 340 [16384/54000 (30%)] Loss: -1527.067261\n",
      "Train Epoch: 340 [20480/54000 (38%)] Loss: -1525.104614\n",
      "Train Epoch: 340 [24576/54000 (46%)] Loss: -1520.397705\n",
      "Train Epoch: 340 [28672/54000 (53%)] Loss: -1518.472778\n",
      "Train Epoch: 340 [32768/54000 (61%)] Loss: -1520.569336\n",
      "Train Epoch: 340 [36864/54000 (68%)] Loss: -1523.543945\n",
      "Train Epoch: 340 [40960/54000 (76%)] Loss: -1519.233154\n",
      "Train Epoch: 340 [45056/54000 (83%)] Loss: -1527.670532\n",
      "Train Epoch: 340 [49152/54000 (91%)] Loss: -1522.998413\n",
      "Train Epoch: 340 [53248/54000 (99%)] Loss: -1523.394775\n",
      "    epoch          : 340\n",
      "    loss           : -1523.2590870066276\n",
      "    ess            : 3.7726256011221646\n",
      "    log_marginal   : 1523.4041267865077\n",
      "    val_loss       : -1523.1700236002605\n",
      "    val_ess        : 3.777450382709503\n",
      "    val_log_marginal: 1523.3101145426433\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch340.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 341 [0/54000 (0%)] Loss: -1525.997070\n",
      "Train Epoch: 341 [4096/54000 (8%)] Loss: -1526.279663\n",
      "Train Epoch: 341 [8192/54000 (15%)] Loss: -1524.534668\n",
      "Train Epoch: 341 [12288/54000 (23%)] Loss: -1519.995605\n",
      "Train Epoch: 341 [16384/54000 (30%)] Loss: -1522.686035\n",
      "Train Epoch: 341 [20480/54000 (38%)] Loss: -1517.877197\n",
      "Train Epoch: 341 [24576/54000 (46%)] Loss: -1521.937012\n",
      "Train Epoch: 341 [28672/54000 (53%)] Loss: -1526.100098\n",
      "Train Epoch: 341 [32768/54000 (61%)] Loss: -1517.170044\n",
      "Train Epoch: 341 [36864/54000 (68%)] Loss: -1527.239502\n",
      "Train Epoch: 341 [40960/54000 (76%)] Loss: -1514.663452\n",
      "Train Epoch: 341 [45056/54000 (83%)] Loss: -1522.748169\n",
      "Train Epoch: 341 [49152/54000 (91%)] Loss: -1518.857666\n",
      "Train Epoch: 341 [53248/54000 (99%)] Loss: -1525.243896\n",
      "    epoch          : 341\n",
      "    loss           : -1523.370980357672\n",
      "    ess            : 3.7682973253783456\n",
      "    log_marginal   : 1523.5175289497556\n",
      "    val_loss       : -1522.5039367675781\n",
      "    val_ess        : 3.7760401368141174\n",
      "    val_log_marginal: 1522.6344350179036\n",
      "Train Epoch: 342 [0/54000 (0%)] Loss: -1520.887451\n",
      "Train Epoch: 342 [4096/54000 (8%)] Loss: -1525.179810\n",
      "Train Epoch: 342 [8192/54000 (15%)] Loss: -1524.204590\n",
      "Train Epoch: 342 [12288/54000 (23%)] Loss: -1522.751465\n",
      "Train Epoch: 342 [16384/54000 (30%)] Loss: -1521.407471\n",
      "Train Epoch: 342 [20480/54000 (38%)] Loss: -1518.964722\n",
      "Train Epoch: 342 [24576/54000 (46%)] Loss: -1528.939941\n",
      "Train Epoch: 342 [28672/54000 (53%)] Loss: -1528.831543\n",
      "Train Epoch: 342 [32768/54000 (61%)] Loss: -1525.628906\n",
      "Train Epoch: 342 [36864/54000 (68%)] Loss: -1526.816528\n",
      "Train Epoch: 342 [40960/54000 (76%)] Loss: -1530.874268\n",
      "Train Epoch: 342 [45056/54000 (83%)] Loss: -1516.670898\n",
      "Train Epoch: 342 [49152/54000 (91%)] Loss: -1528.181152\n",
      "Train Epoch: 342 [53248/54000 (99%)] Loss: -1516.561035\n",
      "    epoch          : 342\n",
      "    loss           : -1523.6986373250518\n",
      "    ess            : 3.7720024438830912\n",
      "    log_marginal   : 1523.8419791126703\n",
      "    val_loss       : -1522.6550038655598\n",
      "    val_ess        : 3.768546928962072\n",
      "    val_log_marginal: 1522.8025410970051\n",
      "Train Epoch: 343 [0/54000 (0%)] Loss: -1520.950317\n",
      "Train Epoch: 343 [4096/54000 (8%)] Loss: -1523.427734\n",
      "Train Epoch: 343 [8192/54000 (15%)] Loss: -1525.913330\n",
      "Train Epoch: 343 [12288/54000 (23%)] Loss: -1528.445190\n",
      "Train Epoch: 343 [16384/54000 (30%)] Loss: -1520.122559\n",
      "Train Epoch: 343 [20480/54000 (38%)] Loss: -1517.316162\n",
      "Train Epoch: 343 [24576/54000 (46%)] Loss: -1522.314453\n",
      "Train Epoch: 343 [28672/54000 (53%)] Loss: -1524.049561\n",
      "Train Epoch: 343 [32768/54000 (61%)] Loss: -1528.779541\n",
      "Train Epoch: 343 [36864/54000 (68%)] Loss: -1522.433594\n",
      "Train Epoch: 343 [40960/54000 (76%)] Loss: -1521.039673\n",
      "Train Epoch: 343 [45056/54000 (83%)] Loss: -1526.101929\n",
      "Train Epoch: 343 [49152/54000 (91%)] Loss: -1522.635010\n",
      "Train Epoch: 343 [53248/54000 (99%)] Loss: -1527.812256\n",
      "    epoch          : 343\n",
      "    loss           : -1523.793188592269\n",
      "    ess            : 3.7697611951150036\n",
      "    log_marginal   : 1523.941101363485\n",
      "    val_loss       : -1523.0487365722656\n",
      "    val_ess        : 3.7668388982613883\n",
      "    val_log_marginal: 1523.2008870442708\n",
      "Train Epoch: 344 [0/54000 (0%)] Loss: -1525.866211\n",
      "Train Epoch: 344 [4096/54000 (8%)] Loss: -1526.442383\n",
      "Train Epoch: 344 [8192/54000 (15%)] Loss: -1524.022461\n",
      "Train Epoch: 344 [12288/54000 (23%)] Loss: -1527.512939\n",
      "Train Epoch: 344 [16384/54000 (30%)] Loss: -1520.798950\n",
      "Train Epoch: 344 [20480/54000 (38%)] Loss: -1519.280273\n",
      "Train Epoch: 344 [24576/54000 (46%)] Loss: -1522.706055\n",
      "Train Epoch: 344 [28672/54000 (53%)] Loss: -1526.157837\n",
      "Train Epoch: 344 [32768/54000 (61%)] Loss: -1523.296631\n",
      "Train Epoch: 344 [36864/54000 (68%)] Loss: -1525.983398\n",
      "Train Epoch: 344 [40960/54000 (76%)] Loss: -1519.466675\n",
      "Train Epoch: 344 [45056/54000 (83%)] Loss: -1521.852051\n",
      "Train Epoch: 344 [49152/54000 (91%)] Loss: -1525.284302\n",
      "Train Epoch: 344 [53248/54000 (99%)] Loss: -1526.437012\n",
      "    epoch          : 344\n",
      "    loss           : -1523.7383385246965\n",
      "    ess            : 3.7675959826645693\n",
      "    log_marginal   : 1523.882953661878\n",
      "    val_loss       : -1523.8399709065754\n",
      "    val_ess        : 3.771322101354599\n",
      "    val_log_marginal: 1523.9847259521484\n",
      "Train Epoch: 345 [0/54000 (0%)] Loss: -1522.164795\n",
      "Train Epoch: 345 [4096/54000 (8%)] Loss: -1523.334839\n",
      "Train Epoch: 345 [8192/54000 (15%)] Loss: -1527.537476\n",
      "Train Epoch: 345 [12288/54000 (23%)] Loss: -1519.508179\n",
      "Train Epoch: 345 [16384/54000 (30%)] Loss: -1520.294678\n",
      "Train Epoch: 345 [20480/54000 (38%)] Loss: -1527.091309\n",
      "Train Epoch: 345 [24576/54000 (46%)] Loss: -1521.474609\n",
      "Train Epoch: 345 [28672/54000 (53%)] Loss: -1525.855713\n",
      "Train Epoch: 345 [32768/54000 (61%)] Loss: -1527.286865\n",
      "Train Epoch: 345 [36864/54000 (68%)] Loss: -1524.934814\n",
      "Train Epoch: 345 [40960/54000 (76%)] Loss: -1521.390625\n",
      "Train Epoch: 345 [45056/54000 (83%)] Loss: -1529.655273\n",
      "Train Epoch: 345 [49152/54000 (91%)] Loss: -1532.816162\n",
      "Train Epoch: 345 [53248/54000 (99%)] Loss: -1523.575317\n",
      "    epoch          : 345\n",
      "    loss           : -1523.8433994094341\n",
      "    ess            : 3.770874162420842\n",
      "    log_marginal   : 1523.985615951755\n",
      "    val_loss       : -1523.3514506022136\n",
      "    val_ess        : 3.767230192820231\n",
      "    val_log_marginal: 1523.4966888427734\n",
      "Train Epoch: 346 [0/54000 (0%)] Loss: -1523.900146\n",
      "Train Epoch: 346 [4096/54000 (8%)] Loss: -1522.910156\n",
      "Train Epoch: 346 [8192/54000 (15%)] Loss: -1521.237305\n",
      "Train Epoch: 346 [12288/54000 (23%)] Loss: -1518.646729\n",
      "Train Epoch: 346 [16384/54000 (30%)] Loss: -1526.750977\n",
      "Train Epoch: 346 [20480/54000 (38%)] Loss: -1524.216919\n",
      "Train Epoch: 346 [24576/54000 (46%)] Loss: -1514.442261\n",
      "Train Epoch: 346 [28672/54000 (53%)] Loss: -1515.567627\n",
      "Train Epoch: 346 [32768/54000 (61%)] Loss: -1521.600464\n",
      "Train Epoch: 346 [36864/54000 (68%)] Loss: -1523.571777\n",
      "Train Epoch: 346 [40960/54000 (76%)] Loss: -1519.119141\n",
      "Train Epoch: 346 [45056/54000 (83%)] Loss: -1526.679565\n",
      "Train Epoch: 346 [49152/54000 (91%)] Loss: -1525.542847\n",
      "Train Epoch: 346 [53248/54000 (99%)] Loss: -1518.478027\n",
      "    epoch          : 346\n",
      "    loss           : -1524.1809591139663\n",
      "    ess            : 3.7689750251046856\n",
      "    log_marginal   : 1524.3285172448905\n",
      "    val_loss       : -1523.2393646240234\n",
      "    val_ess        : 3.762668639421463\n",
      "    val_log_marginal: 1523.3887481689453\n",
      "Train Epoch: 347 [0/54000 (0%)] Loss: -1522.989502\n",
      "Train Epoch: 347 [4096/54000 (8%)] Loss: -1521.011475\n",
      "Train Epoch: 347 [8192/54000 (15%)] Loss: -1522.601929\n",
      "Train Epoch: 347 [12288/54000 (23%)] Loss: -1518.540161\n",
      "Train Epoch: 347 [16384/54000 (30%)] Loss: -1526.115723\n",
      "Train Epoch: 347 [20480/54000 (38%)] Loss: -1522.447388\n",
      "Train Epoch: 347 [24576/54000 (46%)] Loss: -1526.030762\n",
      "Train Epoch: 347 [28672/54000 (53%)] Loss: -1522.176270\n",
      "Train Epoch: 347 [32768/54000 (61%)] Loss: -1522.294556\n",
      "Train Epoch: 347 [36864/54000 (68%)] Loss: -1516.386230\n",
      "Train Epoch: 347 [40960/54000 (76%)] Loss: -1527.662354\n",
      "Train Epoch: 347 [45056/54000 (83%)] Loss: -1523.000000\n",
      "Train Epoch: 347 [49152/54000 (91%)] Loss: -1521.170166\n",
      "Train Epoch: 347 [53248/54000 (99%)] Loss: -1525.482788\n",
      "    epoch          : 347\n",
      "    loss           : -1524.138266323867\n",
      "    ess            : 3.7732398871561927\n",
      "    log_marginal   : 1524.282254910582\n",
      "    val_loss       : -1524.2331797281902\n",
      "    val_ess        : 3.765974462032318\n",
      "    val_log_marginal: 1524.375508626302\n",
      "Train Epoch: 348 [0/54000 (0%)] Loss: -1526.544434\n",
      "Train Epoch: 348 [4096/54000 (8%)] Loss: -1525.234497\n",
      "Train Epoch: 348 [8192/54000 (15%)] Loss: -1521.381470\n",
      "Train Epoch: 348 [12288/54000 (23%)] Loss: -1523.525391\n",
      "Train Epoch: 348 [16384/54000 (30%)] Loss: -1529.322388\n",
      "Train Epoch: 348 [20480/54000 (38%)] Loss: -1528.249512\n",
      "Train Epoch: 348 [24576/54000 (46%)] Loss: -1525.963135\n",
      "Train Epoch: 348 [28672/54000 (53%)] Loss: -1524.890259\n",
      "Train Epoch: 348 [32768/54000 (61%)] Loss: -1513.217285\n",
      "Train Epoch: 348 [36864/54000 (68%)] Loss: -1521.181885\n",
      "Train Epoch: 348 [40960/54000 (76%)] Loss: -1526.297607\n",
      "Train Epoch: 348 [45056/54000 (83%)] Loss: -1526.258179\n",
      "Train Epoch: 348 [49152/54000 (91%)] Loss: -1522.155762\n",
      "Train Epoch: 348 [53248/54000 (99%)] Loss: -1520.956787\n",
      "    epoch          : 348\n",
      "    loss           : -1524.213506183353\n",
      "    ess            : 3.7714244630099474\n",
      "    log_marginal   : 1524.3593778926615\n",
      "    val_loss       : -1525.1387329101562\n",
      "    val_ess        : 3.788789749145508\n",
      "    val_log_marginal: 1525.265848795573\n",
      "Train Epoch: 349 [0/54000 (0%)] Loss: -1525.873047\n",
      "Train Epoch: 349 [4096/54000 (8%)] Loss: -1524.058105\n",
      "Train Epoch: 349 [8192/54000 (15%)] Loss: -1525.610107\n",
      "Train Epoch: 349 [12288/54000 (23%)] Loss: -1530.418823\n",
      "Train Epoch: 349 [16384/54000 (30%)] Loss: -1530.987549\n",
      "Train Epoch: 349 [20480/54000 (38%)] Loss: -1529.018921\n",
      "Train Epoch: 349 [24576/54000 (46%)] Loss: -1530.623901\n",
      "Train Epoch: 349 [28672/54000 (53%)] Loss: -1518.949707\n",
      "Train Epoch: 349 [32768/54000 (61%)] Loss: -1526.229248\n",
      "Train Epoch: 349 [36864/54000 (68%)] Loss: -1524.284790\n",
      "Train Epoch: 349 [40960/54000 (76%)] Loss: -1528.374512\n",
      "Train Epoch: 349 [45056/54000 (83%)] Loss: -1529.394165\n",
      "Train Epoch: 349 [49152/54000 (91%)] Loss: -1517.397949\n",
      "Train Epoch: 349 [53248/54000 (99%)] Loss: -1528.970703\n",
      "    epoch          : 349\n",
      "    loss           : -1524.6679785850488\n",
      "    ess            : 3.7738055493594347\n",
      "    log_marginal   : 1524.8117305520586\n",
      "    val_loss       : -1524.7955322265625\n",
      "    val_ess        : 3.7682386934757233\n",
      "    val_log_marginal: 1524.9497375488281\n",
      "Train Epoch: 350 [0/54000 (0%)] Loss: -1528.617065\n",
      "Train Epoch: 350 [4096/54000 (8%)] Loss: -1521.368896\n",
      "Train Epoch: 350 [8192/54000 (15%)] Loss: -1528.551758\n",
      "Train Epoch: 350 [12288/54000 (23%)] Loss: -1523.996338\n",
      "Train Epoch: 350 [16384/54000 (30%)] Loss: -1524.482422\n",
      "Train Epoch: 350 [20480/54000 (38%)] Loss: -1526.663330\n",
      "Train Epoch: 350 [24576/54000 (46%)] Loss: -1526.604858\n",
      "Train Epoch: 350 [28672/54000 (53%)] Loss: -1526.474854\n",
      "Train Epoch: 350 [32768/54000 (61%)] Loss: -1520.160645\n",
      "Train Epoch: 350 [36864/54000 (68%)] Loss: -1528.369995\n",
      "Train Epoch: 350 [40960/54000 (76%)] Loss: -1518.078369\n",
      "Train Epoch: 350 [45056/54000 (83%)] Loss: -1528.918701\n",
      "Train Epoch: 350 [49152/54000 (91%)] Loss: -1519.489502\n",
      "Train Epoch: 350 [53248/54000 (99%)] Loss: -1527.832031\n",
      "    epoch          : 350\n",
      "    loss           : -1524.4443914765995\n",
      "    ess            : 3.769911731023924\n",
      "    log_marginal   : 1524.590862545357\n",
      "    val_loss       : -1525.1924947102864\n",
      "    val_ess        : 3.7686175306638083\n",
      "    val_log_marginal: 1525.3472493489583\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch350.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 351 [0/54000 (0%)] Loss: -1532.213013\n",
      "Train Epoch: 351 [4096/54000 (8%)] Loss: -1523.788086\n",
      "Train Epoch: 351 [8192/54000 (15%)] Loss: -1519.348633\n",
      "Train Epoch: 351 [12288/54000 (23%)] Loss: -1533.241699\n",
      "Train Epoch: 351 [16384/54000 (30%)] Loss: -1519.723877\n",
      "Train Epoch: 351 [20480/54000 (38%)] Loss: -1524.488525\n",
      "Train Epoch: 351 [24576/54000 (46%)] Loss: -1518.816650\n",
      "Train Epoch: 351 [28672/54000 (53%)] Loss: -1525.874268\n",
      "Train Epoch: 351 [32768/54000 (61%)] Loss: -1527.067627\n",
      "Train Epoch: 351 [36864/54000 (68%)] Loss: -1519.194092\n",
      "Train Epoch: 351 [40960/54000 (76%)] Loss: -1521.742676\n",
      "Train Epoch: 351 [45056/54000 (83%)] Loss: -1520.315552\n",
      "Train Epoch: 351 [49152/54000 (91%)] Loss: -1521.268677\n",
      "Train Epoch: 351 [53248/54000 (99%)] Loss: -1526.462280\n",
      "    epoch          : 351\n",
      "    loss           : -1524.7714566054503\n",
      "    ess            : 3.7737926374679494\n",
      "    log_marginal   : 1524.9130951940165\n",
      "    val_loss       : -1523.4605712890625\n",
      "    val_ess        : 3.78585617740949\n",
      "    val_log_marginal: 1523.5867309570312\n",
      "Train Epoch: 352 [0/54000 (0%)] Loss: -1524.237305\n",
      "Train Epoch: 352 [4096/54000 (8%)] Loss: -1523.382080\n",
      "Train Epoch: 352 [8192/54000 (15%)] Loss: -1534.498047\n",
      "Train Epoch: 352 [12288/54000 (23%)] Loss: -1526.251953\n",
      "Train Epoch: 352 [16384/54000 (30%)] Loss: -1522.035889\n",
      "Train Epoch: 352 [20480/54000 (38%)] Loss: -1525.439575\n",
      "Train Epoch: 352 [24576/54000 (46%)] Loss: -1519.996460\n",
      "Train Epoch: 352 [28672/54000 (53%)] Loss: -1527.834961\n",
      "Train Epoch: 352 [32768/54000 (61%)] Loss: -1521.659180\n",
      "Train Epoch: 352 [36864/54000 (68%)] Loss: -1524.255859\n",
      "Train Epoch: 352 [40960/54000 (76%)] Loss: -1524.340576\n",
      "Train Epoch: 352 [45056/54000 (83%)] Loss: -1524.734131\n",
      "Train Epoch: 352 [49152/54000 (91%)] Loss: -1522.284180\n",
      "Train Epoch: 352 [53248/54000 (99%)] Loss: -1525.548950\n",
      "    epoch          : 352\n",
      "    loss           : -1525.0511428326793\n",
      "    ess            : 3.7717454953216265\n",
      "    log_marginal   : 1525.1957568127962\n",
      "    val_loss       : -1524.0858001708984\n",
      "    val_ess        : 3.7882294754187265\n",
      "    val_log_marginal: 1524.2119394938152\n",
      "Train Epoch: 353 [0/54000 (0%)] Loss: -1525.988647\n",
      "Train Epoch: 353 [4096/54000 (8%)] Loss: -1527.814697\n",
      "Train Epoch: 353 [8192/54000 (15%)] Loss: -1523.209351\n",
      "Train Epoch: 353 [12288/54000 (23%)] Loss: -1526.802124\n",
      "Train Epoch: 353 [16384/54000 (30%)] Loss: -1516.336670\n",
      "Train Epoch: 353 [20480/54000 (38%)] Loss: -1527.398560\n",
      "Train Epoch: 353 [24576/54000 (46%)] Loss: -1522.874146\n",
      "Train Epoch: 353 [28672/54000 (53%)] Loss: -1533.205078\n",
      "Train Epoch: 353 [32768/54000 (61%)] Loss: -1531.593872\n",
      "Train Epoch: 353 [36864/54000 (68%)] Loss: -1529.109009\n",
      "Train Epoch: 353 [40960/54000 (76%)] Loss: -1515.036987\n",
      "Train Epoch: 353 [45056/54000 (83%)] Loss: -1531.687988\n",
      "Train Epoch: 353 [49152/54000 (91%)] Loss: -1530.469482\n",
      "Train Epoch: 353 [53248/54000 (99%)] Loss: -1527.048828\n",
      "    epoch          : 353\n",
      "    loss           : -1525.2992550818276\n",
      "    ess            : 3.7695291596001357\n",
      "    log_marginal   : 1525.445288201644\n",
      "    val_loss       : -1524.2239939371746\n",
      "    val_ess        : 3.7619011799494424\n",
      "    val_log_marginal: 1524.3749491373699\n",
      "Train Epoch: 354 [0/54000 (0%)] Loss: -1526.633057\n",
      "Train Epoch: 354 [4096/54000 (8%)] Loss: -1518.649048\n",
      "Train Epoch: 354 [8192/54000 (15%)] Loss: -1523.446045\n",
      "Train Epoch: 354 [12288/54000 (23%)] Loss: -1532.318359\n",
      "Train Epoch: 354 [16384/54000 (30%)] Loss: -1527.807861\n",
      "Train Epoch: 354 [20480/54000 (38%)] Loss: -1526.767090\n",
      "Train Epoch: 354 [24576/54000 (46%)] Loss: -1524.352783\n",
      "Train Epoch: 354 [28672/54000 (53%)] Loss: -1522.929199\n",
      "Train Epoch: 354 [32768/54000 (61%)] Loss: -1525.206543\n",
      "Train Epoch: 354 [36864/54000 (68%)] Loss: -1528.130005\n",
      "Train Epoch: 354 [40960/54000 (76%)] Loss: -1520.187866\n",
      "Train Epoch: 354 [45056/54000 (83%)] Loss: -1527.087524\n",
      "Train Epoch: 354 [49152/54000 (91%)] Loss: -1522.173828\n",
      "Train Epoch: 354 [53248/54000 (99%)] Loss: -1526.037842\n",
      "    epoch          : 354\n",
      "    loss           : -1525.3285166663582\n",
      "    ess            : 3.767664423486068\n",
      "    log_marginal   : 1525.4754563462677\n",
      "    val_loss       : -1524.7341969807942\n",
      "    val_ess        : 3.7751674751440683\n",
      "    val_log_marginal: 1524.869867960612\n",
      "Train Epoch: 355 [0/54000 (0%)] Loss: -1522.377319\n",
      "Train Epoch: 355 [4096/54000 (8%)] Loss: -1524.801270\n",
      "Train Epoch: 355 [8192/54000 (15%)] Loss: -1531.412842\n",
      "Train Epoch: 355 [12288/54000 (23%)] Loss: -1529.092285\n",
      "Train Epoch: 355 [16384/54000 (30%)] Loss: -1529.316895\n",
      "Train Epoch: 355 [20480/54000 (38%)] Loss: -1523.458984\n",
      "Train Epoch: 355 [24576/54000 (46%)] Loss: -1528.201782\n",
      "Train Epoch: 355 [28672/54000 (53%)] Loss: -1516.037354\n",
      "Train Epoch: 355 [32768/54000 (61%)] Loss: -1531.117676\n",
      "Train Epoch: 355 [36864/54000 (68%)] Loss: -1525.388794\n",
      "Train Epoch: 355 [40960/54000 (76%)] Loss: -1524.774048\n",
      "Train Epoch: 355 [45056/54000 (83%)] Loss: -1525.328857\n",
      "Train Epoch: 355 [49152/54000 (91%)] Loss: -1532.262207\n",
      "Train Epoch: 355 [53248/54000 (99%)] Loss: -1521.589355\n",
      "    epoch          : 355\n",
      "    loss           : -1525.3737341713565\n",
      "    ess            : 3.773030047168099\n",
      "    log_marginal   : 1525.5155839242077\n",
      "    val_loss       : -1525.8316345214844\n",
      "    val_ess        : 3.7789809703826904\n",
      "    val_log_marginal: 1525.9650268554688\n",
      "Train Epoch: 356 [0/54000 (0%)] Loss: -1531.643311\n",
      "Train Epoch: 356 [4096/54000 (8%)] Loss: -1526.673096\n",
      "Train Epoch: 356 [8192/54000 (15%)] Loss: -1521.134766\n",
      "Train Epoch: 356 [12288/54000 (23%)] Loss: -1533.209106\n",
      "Train Epoch: 356 [16384/54000 (30%)] Loss: -1529.993164\n",
      "Train Epoch: 356 [20480/54000 (38%)] Loss: -1529.539795\n",
      "Train Epoch: 356 [24576/54000 (46%)] Loss: -1526.987549\n",
      "Train Epoch: 356 [28672/54000 (53%)] Loss: -1526.217529\n",
      "Train Epoch: 356 [32768/54000 (61%)] Loss: -1528.651367\n",
      "Train Epoch: 356 [36864/54000 (68%)] Loss: -1526.433838\n",
      "Train Epoch: 356 [40960/54000 (76%)] Loss: -1528.176270\n",
      "Train Epoch: 356 [45056/54000 (83%)] Loss: -1527.513428\n",
      "Train Epoch: 356 [49152/54000 (91%)] Loss: -1521.527832\n",
      "Train Epoch: 356 [53248/54000 (99%)] Loss: -1524.213623\n",
      "    epoch          : 356\n",
      "    loss           : -1525.6333667339306\n",
      "    ess            : 3.7702703272561893\n",
      "    log_marginal   : 1525.7758476655065\n",
      "    val_loss       : -1526.477086385091\n",
      "    val_ess        : 3.7745029429594674\n",
      "    val_log_marginal: 1526.6225179036458\n",
      "Train Epoch: 357 [0/54000 (0%)] Loss: -1521.454956\n",
      "Train Epoch: 357 [4096/54000 (8%)] Loss: -1523.318115\n",
      "Train Epoch: 357 [8192/54000 (15%)] Loss: -1530.022949\n",
      "Train Epoch: 357 [12288/54000 (23%)] Loss: -1522.174316\n",
      "Train Epoch: 357 [16384/54000 (30%)] Loss: -1529.890991\n",
      "Train Epoch: 357 [20480/54000 (38%)] Loss: -1526.567749\n",
      "Train Epoch: 357 [24576/54000 (46%)] Loss: -1521.612793\n",
      "Train Epoch: 357 [28672/54000 (53%)] Loss: -1525.170166\n",
      "Train Epoch: 357 [32768/54000 (61%)] Loss: -1528.503906\n",
      "Train Epoch: 357 [36864/54000 (68%)] Loss: -1531.738525\n",
      "Train Epoch: 357 [40960/54000 (76%)] Loss: -1533.488159\n",
      "Train Epoch: 357 [45056/54000 (83%)] Loss: -1528.843750\n",
      "Train Epoch: 357 [49152/54000 (91%)] Loss: -1524.162231\n",
      "Train Epoch: 357 [53248/54000 (99%)] Loss: -1530.686401\n",
      "    epoch          : 357\n",
      "    loss           : -1525.8962344490521\n",
      "    ess            : 3.7674769055786856\n",
      "    log_marginal   : 1526.0407749555686\n",
      "    val_loss       : -1525.5521443684895\n",
      "    val_ess        : 3.7737698455651603\n",
      "    val_log_marginal: 1525.6966705322266\n",
      "Train Epoch: 358 [0/54000 (0%)] Loss: -1526.179565\n",
      "Train Epoch: 358 [4096/54000 (8%)] Loss: -1528.303833\n",
      "Train Epoch: 358 [8192/54000 (15%)] Loss: -1529.744141\n",
      "Train Epoch: 358 [12288/54000 (23%)] Loss: -1533.150879\n",
      "Train Epoch: 358 [16384/54000 (30%)] Loss: -1527.490356\n",
      "Train Epoch: 358 [20480/54000 (38%)] Loss: -1528.178955\n",
      "Train Epoch: 358 [24576/54000 (46%)] Loss: -1523.833252\n",
      "Train Epoch: 358 [28672/54000 (53%)] Loss: -1519.301758\n",
      "Train Epoch: 358 [32768/54000 (61%)] Loss: -1521.166870\n",
      "Train Epoch: 358 [36864/54000 (68%)] Loss: -1525.513916\n",
      "Train Epoch: 358 [40960/54000 (76%)] Loss: -1522.478027\n",
      "Train Epoch: 358 [45056/54000 (83%)] Loss: -1530.389893\n",
      "Train Epoch: 358 [49152/54000 (91%)] Loss: -1532.570801\n",
      "Train Epoch: 358 [53248/54000 (99%)] Loss: -1534.936768\n",
      "    epoch          : 358\n",
      "    loss           : -1525.7475429733784\n",
      "    ess            : 3.768892463349618\n",
      "    log_marginal   : 1525.8933498870706\n",
      "    val_loss       : -1525.3253072102864\n",
      "    val_ess        : 3.7774219314257302\n",
      "    val_log_marginal: 1525.4722188313801\n",
      "Train Epoch: 359 [0/54000 (0%)] Loss: -1528.991699\n",
      "Train Epoch: 359 [4096/54000 (8%)] Loss: -1523.716919\n",
      "Train Epoch: 359 [8192/54000 (15%)] Loss: -1528.594727\n",
      "Train Epoch: 359 [12288/54000 (23%)] Loss: -1520.827881\n",
      "Train Epoch: 359 [16384/54000 (30%)] Loss: -1524.105469\n",
      "Train Epoch: 359 [20480/54000 (38%)] Loss: -1524.422363\n",
      "Train Epoch: 359 [24576/54000 (46%)] Loss: -1527.453613\n",
      "Train Epoch: 359 [28672/54000 (53%)] Loss: -1521.965332\n",
      "Train Epoch: 359 [32768/54000 (61%)] Loss: -1523.887939\n",
      "Train Epoch: 359 [36864/54000 (68%)] Loss: -1531.332764\n",
      "Train Epoch: 359 [40960/54000 (76%)] Loss: -1522.193848\n",
      "Train Epoch: 359 [45056/54000 (83%)] Loss: -1533.324951\n",
      "Train Epoch: 359 [49152/54000 (91%)] Loss: -1524.273804\n",
      "Train Epoch: 359 [53248/54000 (99%)] Loss: -1524.006592\n",
      "    epoch          : 359\n",
      "    loss           : -1526.1441204920764\n",
      "    ess            : 3.7697143712879924\n",
      "    log_marginal   : 1526.286758205902\n",
      "    val_loss       : -1525.9828592936199\n",
      "    val_ess        : 3.7724352379639945\n",
      "    val_log_marginal: 1526.1251831054688\n",
      "Train Epoch: 360 [0/54000 (0%)] Loss: -1521.217773\n",
      "Train Epoch: 360 [4096/54000 (8%)] Loss: -1525.846680\n",
      "Train Epoch: 360 [8192/54000 (15%)] Loss: -1528.123657\n",
      "Train Epoch: 360 [12288/54000 (23%)] Loss: -1528.570801\n",
      "Train Epoch: 360 [16384/54000 (30%)] Loss: -1530.654419\n",
      "Train Epoch: 360 [20480/54000 (38%)] Loss: -1523.359375\n",
      "Train Epoch: 360 [24576/54000 (46%)] Loss: -1524.804932\n",
      "Train Epoch: 360 [28672/54000 (53%)] Loss: -1526.879150\n",
      "Train Epoch: 360 [32768/54000 (61%)] Loss: -1534.474365\n",
      "Train Epoch: 360 [36864/54000 (68%)] Loss: -1528.154419\n",
      "Train Epoch: 360 [40960/54000 (76%)] Loss: -1532.153320\n",
      "Train Epoch: 360 [45056/54000 (83%)] Loss: -1534.814453\n",
      "Train Epoch: 360 [49152/54000 (91%)] Loss: -1528.267822\n",
      "Train Epoch: 360 [53248/54000 (99%)] Loss: -1522.328857\n",
      "    epoch          : 360\n",
      "    loss           : -1526.229570867891\n",
      "    ess            : 3.774126586190897\n",
      "    log_marginal   : 1526.372003781287\n",
      "    val_loss       : -1525.2628122965496\n",
      "    val_ess        : 3.7624440093835196\n",
      "    val_log_marginal: 1525.4188181559246\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch360.pth ...\n",
      "Train Epoch: 361 [0/54000 (0%)] Loss: -1527.266602\n",
      "Train Epoch: 361 [4096/54000 (8%)] Loss: -1523.971191\n",
      "Train Epoch: 361 [8192/54000 (15%)] Loss: -1527.822510\n",
      "Train Epoch: 361 [12288/54000 (23%)] Loss: -1531.589844\n",
      "Train Epoch: 361 [16384/54000 (30%)] Loss: -1524.554443\n",
      "Train Epoch: 361 [20480/54000 (38%)] Loss: -1521.583008\n",
      "Train Epoch: 361 [24576/54000 (46%)] Loss: -1524.598877\n",
      "Train Epoch: 361 [28672/54000 (53%)] Loss: -1523.374023\n",
      "Train Epoch: 361 [32768/54000 (61%)] Loss: -1531.452637\n",
      "Train Epoch: 361 [36864/54000 (68%)] Loss: -1522.459717\n",
      "Train Epoch: 361 [40960/54000 (76%)] Loss: -1530.094238\n",
      "Train Epoch: 361 [45056/54000 (83%)] Loss: -1525.184082\n",
      "Train Epoch: 361 [49152/54000 (91%)] Loss: -1531.708496\n",
      "Train Epoch: 361 [53248/54000 (99%)] Loss: -1530.728271\n",
      "    epoch          : 361\n",
      "    loss           : -1526.5710078958086\n",
      "    ess            : 3.771803583579041\n",
      "    log_marginal   : 1526.7133696497335\n",
      "    val_loss       : -1526.2350006103516\n",
      "    val_ess        : 3.7597678899765015\n",
      "    val_log_marginal: 1526.389907836914\n",
      "Train Epoch: 362 [0/54000 (0%)] Loss: -1522.197754\n",
      "Train Epoch: 362 [4096/54000 (8%)] Loss: -1522.480591\n",
      "Train Epoch: 362 [8192/54000 (15%)] Loss: -1535.801392\n",
      "Train Epoch: 362 [12288/54000 (23%)] Loss: -1521.760010\n",
      "Train Epoch: 362 [16384/54000 (30%)] Loss: -1521.620605\n",
      "Train Epoch: 362 [20480/54000 (38%)] Loss: -1520.844116\n",
      "Train Epoch: 362 [24576/54000 (46%)] Loss: -1521.909668\n",
      "Train Epoch: 362 [28672/54000 (53%)] Loss: -1525.936279\n",
      "Train Epoch: 362 [32768/54000 (61%)] Loss: -1523.739502\n",
      "Train Epoch: 362 [36864/54000 (68%)] Loss: -1526.370361\n",
      "Train Epoch: 362 [40960/54000 (76%)] Loss: -1534.951660\n",
      "Train Epoch: 362 [45056/54000 (83%)] Loss: -1520.402100\n",
      "Train Epoch: 362 [49152/54000 (91%)] Loss: -1522.598633\n",
      "Train Epoch: 362 [53248/54000 (99%)] Loss: -1527.085205\n",
      "    epoch          : 362\n",
      "    loss           : -1526.294391360893\n",
      "    ess            : 3.768918176397893\n",
      "    log_marginal   : 1526.4405419227637\n",
      "    val_loss       : -1525.4561106363933\n",
      "    val_ess        : 3.7677434186140695\n",
      "    val_log_marginal: 1525.6090647379558\n",
      "Train Epoch: 363 [0/54000 (0%)] Loss: -1525.589600\n",
      "Train Epoch: 363 [4096/54000 (8%)] Loss: -1530.768799\n",
      "Train Epoch: 363 [8192/54000 (15%)] Loss: -1537.010010\n",
      "Train Epoch: 363 [12288/54000 (23%)] Loss: -1523.671143\n",
      "Train Epoch: 363 [16384/54000 (30%)] Loss: -1523.951172\n",
      "Train Epoch: 363 [20480/54000 (38%)] Loss: -1520.069824\n",
      "Train Epoch: 363 [24576/54000 (46%)] Loss: -1532.425781\n",
      "Train Epoch: 363 [28672/54000 (53%)] Loss: -1523.223877\n",
      "Train Epoch: 363 [32768/54000 (61%)] Loss: -1527.751465\n",
      "Train Epoch: 363 [36864/54000 (68%)] Loss: -1530.139648\n",
      "Train Epoch: 363 [40960/54000 (76%)] Loss: -1532.132080\n",
      "Train Epoch: 363 [45056/54000 (83%)] Loss: -1530.217163\n",
      "Train Epoch: 363 [49152/54000 (91%)] Loss: -1523.664307\n",
      "Train Epoch: 363 [53248/54000 (99%)] Loss: -1522.539062\n",
      "    epoch          : 363\n",
      "    loss           : -1526.6172424605672\n",
      "    ess            : 3.772130509688391\n",
      "    log_marginal   : 1526.7581787109375\n",
      "    val_loss       : -1526.0233306884766\n",
      "    val_ess        : 3.769572138786316\n",
      "    val_log_marginal: 1526.1687316894531\n",
      "Train Epoch: 364 [0/54000 (0%)] Loss: -1526.011230\n",
      "Train Epoch: 364 [4096/54000 (8%)] Loss: -1524.498535\n",
      "Train Epoch: 364 [8192/54000 (15%)] Loss: -1530.022949\n",
      "Train Epoch: 364 [12288/54000 (23%)] Loss: -1526.587158\n",
      "Train Epoch: 364 [16384/54000 (30%)] Loss: -1528.430908\n",
      "Train Epoch: 364 [20480/54000 (38%)] Loss: -1527.109985\n",
      "Train Epoch: 364 [24576/54000 (46%)] Loss: -1529.190674\n",
      "Train Epoch: 364 [28672/54000 (53%)] Loss: -1524.763672\n",
      "Train Epoch: 364 [32768/54000 (61%)] Loss: -1528.524902\n",
      "Train Epoch: 364 [36864/54000 (68%)] Loss: -1522.161255\n",
      "Train Epoch: 364 [40960/54000 (76%)] Loss: -1532.414307\n",
      "Train Epoch: 364 [45056/54000 (83%)] Loss: -1522.546753\n",
      "Train Epoch: 364 [49152/54000 (91%)] Loss: -1529.207764\n",
      "Train Epoch: 364 [53248/54000 (99%)] Loss: -1524.804810\n",
      "    epoch          : 364\n",
      "    loss           : -1526.7822242483708\n",
      "    ess            : 3.772914526021876\n",
      "    log_marginal   : 1526.9261231625815\n",
      "    val_loss       : -1525.9608357747395\n",
      "    val_ess        : 3.7824405829111734\n",
      "    val_log_marginal: 1526.1028086344402\n",
      "Train Epoch: 365 [0/54000 (0%)] Loss: -1524.375977\n",
      "Train Epoch: 365 [4096/54000 (8%)] Loss: -1529.686890\n",
      "Train Epoch: 365 [8192/54000 (15%)] Loss: -1529.112549\n",
      "Train Epoch: 365 [12288/54000 (23%)] Loss: -1529.368408\n",
      "Train Epoch: 365 [16384/54000 (30%)] Loss: -1522.619141\n",
      "Train Epoch: 365 [20480/54000 (38%)] Loss: -1524.034180\n",
      "Train Epoch: 365 [24576/54000 (46%)] Loss: -1524.034668\n",
      "Train Epoch: 365 [28672/54000 (53%)] Loss: -1530.759766\n",
      "Train Epoch: 365 [32768/54000 (61%)] Loss: -1521.130371\n",
      "Train Epoch: 365 [36864/54000 (68%)] Loss: -1531.645996\n",
      "Train Epoch: 365 [40960/54000 (76%)] Loss: -1524.106689\n",
      "Train Epoch: 365 [45056/54000 (83%)] Loss: -1526.594849\n",
      "Train Epoch: 365 [49152/54000 (91%)] Loss: -1534.482422\n",
      "Train Epoch: 365 [53248/54000 (99%)] Loss: -1528.676758\n",
      "    epoch          : 365\n",
      "    loss           : -1526.9393084919284\n",
      "    ess            : 3.7728520806931773\n",
      "    log_marginal   : 1527.082814004184\n",
      "    val_loss       : -1526.470230102539\n",
      "    val_ess        : 3.7815576791763306\n",
      "    val_log_marginal: 1526.6018575032551\n",
      "Train Epoch: 366 [0/54000 (0%)] Loss: -1527.197021\n",
      "Train Epoch: 366 [4096/54000 (8%)] Loss: -1527.605835\n",
      "Train Epoch: 366 [8192/54000 (15%)] Loss: -1525.381714\n",
      "Train Epoch: 366 [12288/54000 (23%)] Loss: -1523.532837\n",
      "Train Epoch: 366 [16384/54000 (30%)] Loss: -1528.299316\n",
      "Train Epoch: 366 [20480/54000 (38%)] Loss: -1520.090576\n",
      "Train Epoch: 366 [24576/54000 (46%)] Loss: -1524.285645\n",
      "Train Epoch: 366 [28672/54000 (53%)] Loss: -1529.872314\n",
      "Train Epoch: 366 [32768/54000 (61%)] Loss: -1527.255615\n",
      "Train Epoch: 366 [36864/54000 (68%)] Loss: -1523.065674\n",
      "Train Epoch: 366 [40960/54000 (76%)] Loss: -1521.818848\n",
      "Train Epoch: 366 [45056/54000 (83%)] Loss: -1531.628662\n",
      "Train Epoch: 366 [49152/54000 (91%)] Loss: -1522.078491\n",
      "Train Epoch: 366 [53248/54000 (99%)] Loss: -1523.471191\n",
      "    epoch          : 366\n",
      "    loss           : -1526.8815727053095\n",
      "    ess            : 3.772622778517375\n",
      "    log_marginal   : 1527.0245436537323\n",
      "    val_loss       : -1526.0360768636067\n",
      "    val_ess        : 3.7635370592276254\n",
      "    val_log_marginal: 1526.181645711263\n",
      "Train Epoch: 367 [0/54000 (0%)] Loss: -1525.366333\n",
      "Train Epoch: 367 [4096/54000 (8%)] Loss: -1523.603027\n",
      "Train Epoch: 367 [8192/54000 (15%)] Loss: -1530.560547\n",
      "Train Epoch: 367 [12288/54000 (23%)] Loss: -1525.358154\n",
      "Train Epoch: 367 [16384/54000 (30%)] Loss: -1530.974121\n",
      "Train Epoch: 367 [20480/54000 (38%)] Loss: -1526.450073\n",
      "Train Epoch: 367 [24576/54000 (46%)] Loss: -1522.088135\n",
      "Train Epoch: 367 [28672/54000 (53%)] Loss: -1529.367676\n",
      "Train Epoch: 367 [32768/54000 (61%)] Loss: -1527.818970\n",
      "Train Epoch: 367 [36864/54000 (68%)] Loss: -1524.606689\n",
      "Train Epoch: 367 [40960/54000 (76%)] Loss: -1531.209717\n",
      "Train Epoch: 367 [45056/54000 (83%)] Loss: -1530.380981\n",
      "Train Epoch: 367 [49152/54000 (91%)] Loss: -1529.325928\n",
      "Train Epoch: 367 [53248/54000 (99%)] Loss: -1524.947144\n",
      "    epoch          : 367\n",
      "    loss           : -1526.8151919107302\n",
      "    ess            : 3.7773684031590467\n",
      "    log_marginal   : 1526.952469522919\n",
      "    val_loss       : -1526.0717213948567\n",
      "    val_ess        : 3.790087103843689\n",
      "    val_log_marginal: 1526.1995239257812\n",
      "Train Epoch: 368 [0/54000 (0%)] Loss: -1520.793457\n",
      "Train Epoch: 368 [4096/54000 (8%)] Loss: -1529.669922\n",
      "Train Epoch: 368 [8192/54000 (15%)] Loss: -1524.630371\n",
      "Train Epoch: 368 [12288/54000 (23%)] Loss: -1525.233521\n",
      "Train Epoch: 368 [16384/54000 (30%)] Loss: -1530.107300\n",
      "Train Epoch: 368 [20480/54000 (38%)] Loss: -1521.934814\n",
      "Train Epoch: 368 [24576/54000 (46%)] Loss: -1526.274414\n",
      "Train Epoch: 368 [28672/54000 (53%)] Loss: -1520.530273\n",
      "Train Epoch: 368 [32768/54000 (61%)] Loss: -1522.035767\n",
      "Train Epoch: 368 [36864/54000 (68%)] Loss: -1529.356934\n",
      "Train Epoch: 368 [40960/54000 (76%)] Loss: -1525.193970\n",
      "Train Epoch: 368 [45056/54000 (83%)] Loss: -1529.117554\n",
      "Train Epoch: 368 [49152/54000 (91%)] Loss: -1528.894897\n",
      "Train Epoch: 368 [53248/54000 (99%)] Loss: -1527.177979\n",
      "    epoch          : 368\n",
      "    loss           : -1527.1291359273177\n",
      "    ess            : 3.773082317334216\n",
      "    log_marginal   : 1527.273112943387\n",
      "    val_loss       : -1526.3661041259766\n",
      "    val_ess        : 3.769518425067266\n",
      "    val_log_marginal: 1526.5118103027344\n",
      "Train Epoch: 369 [0/54000 (0%)] Loss: -1524.951904\n",
      "Train Epoch: 369 [4096/54000 (8%)] Loss: -1524.173340\n",
      "Train Epoch: 369 [8192/54000 (15%)] Loss: -1520.903564\n",
      "Train Epoch: 369 [12288/54000 (23%)] Loss: -1526.442627\n",
      "Train Epoch: 369 [16384/54000 (30%)] Loss: -1530.168701\n",
      "Train Epoch: 369 [20480/54000 (38%)] Loss: -1526.592407\n",
      "Train Epoch: 369 [24576/54000 (46%)] Loss: -1531.124878\n",
      "Train Epoch: 369 [28672/54000 (53%)] Loss: -1526.230835\n",
      "Train Epoch: 369 [32768/54000 (61%)] Loss: -1528.539795\n",
      "Train Epoch: 369 [36864/54000 (68%)] Loss: -1531.971191\n",
      "Train Epoch: 369 [40960/54000 (76%)] Loss: -1522.796265\n",
      "Train Epoch: 369 [45056/54000 (83%)] Loss: -1527.086670\n",
      "Train Epoch: 369 [49152/54000 (91%)] Loss: -1529.155151\n",
      "Train Epoch: 369 [53248/54000 (99%)] Loss: -1523.774536\n",
      "    epoch          : 369\n",
      "    loss           : -1527.4188654750444\n",
      "    ess            : 3.7736584914239097\n",
      "    log_marginal   : 1527.5628968731487\n",
      "    val_loss       : -1527.5363667805989\n",
      "    val_ess        : 3.783910870552063\n",
      "    val_log_marginal: 1527.6705373128254\n",
      "Train Epoch: 370 [0/54000 (0%)] Loss: -1523.260986\n",
      "Train Epoch: 370 [4096/54000 (8%)] Loss: -1524.709229\n",
      "Train Epoch: 370 [8192/54000 (15%)] Loss: -1530.284424\n",
      "Train Epoch: 370 [12288/54000 (23%)] Loss: -1530.648315\n",
      "Train Epoch: 370 [16384/54000 (30%)] Loss: -1518.204224\n",
      "Train Epoch: 370 [20480/54000 (38%)] Loss: -1528.676270\n",
      "Train Epoch: 370 [24576/54000 (46%)] Loss: -1526.976196\n",
      "Train Epoch: 370 [28672/54000 (53%)] Loss: -1525.395874\n",
      "Train Epoch: 370 [32768/54000 (61%)] Loss: -1525.773682\n",
      "Train Epoch: 370 [36864/54000 (68%)] Loss: -1526.167725\n",
      "Train Epoch: 370 [40960/54000 (76%)] Loss: -1524.754761\n",
      "Train Epoch: 370 [45056/54000 (83%)] Loss: -1527.595459\n",
      "Train Epoch: 370 [49152/54000 (91%)] Loss: -1525.555420\n",
      "Train Epoch: 370 [53248/54000 (99%)] Loss: -1522.587891\n",
      "    epoch          : 370\n",
      "    loss           : -1527.4245206281473\n",
      "    ess            : 3.770170424221816\n",
      "    log_marginal   : 1527.5677935704236\n",
      "    val_loss       : -1527.2785542805989\n",
      "    val_ess        : 3.7767202258110046\n",
      "    val_log_marginal: 1527.4109802246094\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch370.pth ...\n",
      "Train Epoch: 371 [0/54000 (0%)] Loss: -1526.783691\n",
      "Train Epoch: 371 [4096/54000 (8%)] Loss: -1529.444580\n",
      "Train Epoch: 371 [8192/54000 (15%)] Loss: -1520.743408\n",
      "Train Epoch: 371 [12288/54000 (23%)] Loss: -1531.371582\n",
      "Train Epoch: 371 [16384/54000 (30%)] Loss: -1526.978882\n",
      "Train Epoch: 371 [20480/54000 (38%)] Loss: -1525.843750\n",
      "Train Epoch: 371 [24576/54000 (46%)] Loss: -1533.531128\n",
      "Train Epoch: 371 [28672/54000 (53%)] Loss: -1523.174805\n",
      "Train Epoch: 371 [32768/54000 (61%)] Loss: -1530.711426\n",
      "Train Epoch: 371 [36864/54000 (68%)] Loss: -1531.436523\n",
      "Train Epoch: 371 [40960/54000 (76%)] Loss: -1523.032349\n",
      "Train Epoch: 371 [45056/54000 (83%)] Loss: -1529.159180\n",
      "Train Epoch: 371 [49152/54000 (91%)] Loss: -1535.007324\n",
      "Train Epoch: 371 [53248/54000 (99%)] Loss: -1526.160156\n",
      "    epoch          : 371\n",
      "    loss           : -1527.7176739299466\n",
      "    ess            : 3.7729896086652133\n",
      "    log_marginal   : 1527.86175566036\n",
      "    val_loss       : -1527.5372009277344\n",
      "    val_ess        : 3.758934219678243\n",
      "    val_log_marginal: 1527.695032755534\n",
      "Train Epoch: 372 [0/54000 (0%)] Loss: -1523.114746\n",
      "Train Epoch: 372 [4096/54000 (8%)] Loss: -1526.988525\n",
      "Train Epoch: 372 [8192/54000 (15%)] Loss: -1524.893433\n",
      "Train Epoch: 372 [12288/54000 (23%)] Loss: -1531.152100\n",
      "Train Epoch: 372 [16384/54000 (30%)] Loss: -1525.405762\n",
      "Train Epoch: 372 [20480/54000 (38%)] Loss: -1529.185913\n",
      "Train Epoch: 372 [24576/54000 (46%)] Loss: -1521.303467\n",
      "Train Epoch: 372 [28672/54000 (53%)] Loss: -1528.170288\n",
      "Train Epoch: 372 [32768/54000 (61%)] Loss: -1528.277588\n",
      "Train Epoch: 372 [36864/54000 (68%)] Loss: -1525.175903\n",
      "Train Epoch: 372 [40960/54000 (76%)] Loss: -1527.134277\n",
      "Train Epoch: 372 [45056/54000 (83%)] Loss: -1530.815918\n",
      "Train Epoch: 372 [49152/54000 (91%)] Loss: -1528.308228\n",
      "Train Epoch: 372 [53248/54000 (99%)] Loss: -1538.093262\n",
      "    epoch          : 372\n",
      "    loss           : -1527.869048059834\n",
      "    ess            : 3.771422844927458\n",
      "    log_marginal   : 1528.0134566609893\n",
      "    val_loss       : -1527.116714477539\n",
      "    val_ess        : 3.769561400016149\n",
      "    val_log_marginal: 1527.2606150309246\n",
      "Train Epoch: 373 [0/54000 (0%)] Loss: -1522.081665\n",
      "Train Epoch: 373 [4096/54000 (8%)] Loss: -1527.129395\n",
      "Train Epoch: 373 [8192/54000 (15%)] Loss: -1529.982056\n",
      "Train Epoch: 373 [12288/54000 (23%)] Loss: -1521.036499\n",
      "Train Epoch: 373 [16384/54000 (30%)] Loss: -1532.938477\n",
      "Train Epoch: 373 [20480/54000 (38%)] Loss: -1524.416504\n",
      "Train Epoch: 373 [24576/54000 (46%)] Loss: -1526.819214\n",
      "Train Epoch: 373 [28672/54000 (53%)] Loss: -1530.256348\n",
      "Train Epoch: 373 [32768/54000 (61%)] Loss: -1522.539062\n",
      "Train Epoch: 373 [36864/54000 (68%)] Loss: -1521.488037\n",
      "Train Epoch: 373 [40960/54000 (76%)] Loss: -1527.808350\n",
      "Train Epoch: 373 [45056/54000 (83%)] Loss: -1519.755371\n",
      "Train Epoch: 373 [49152/54000 (91%)] Loss: -1525.834473\n",
      "Train Epoch: 373 [53248/54000 (99%)] Loss: -1531.419556\n",
      "    epoch          : 373\n",
      "    loss           : -1528.026159494409\n",
      "    ess            : 3.7708966065357084\n",
      "    log_marginal   : 1528.1696956688759\n",
      "    val_loss       : -1529.2814534505208\n",
      "    val_ess        : 3.7835247814655304\n",
      "    val_log_marginal: 1529.4094136555989\n",
      "Train Epoch: 374 [0/54000 (0%)] Loss: -1527.757202\n",
      "Train Epoch: 374 [4096/54000 (8%)] Loss: -1532.596680\n",
      "Train Epoch: 374 [8192/54000 (15%)] Loss: -1531.700439\n",
      "Train Epoch: 374 [12288/54000 (23%)] Loss: -1526.457153\n",
      "Train Epoch: 374 [16384/54000 (30%)] Loss: -1532.678955\n",
      "Train Epoch: 374 [20480/54000 (38%)] Loss: -1527.142334\n",
      "Train Epoch: 374 [24576/54000 (46%)] Loss: -1521.062988\n",
      "Train Epoch: 374 [28672/54000 (53%)] Loss: -1528.918335\n",
      "Train Epoch: 374 [32768/54000 (61%)] Loss: -1525.771240\n",
      "Train Epoch: 374 [36864/54000 (68%)] Loss: -1527.876709\n",
      "Train Epoch: 374 [40960/54000 (76%)] Loss: -1529.776855\n",
      "Train Epoch: 374 [45056/54000 (83%)] Loss: -1523.242676\n",
      "Train Epoch: 374 [49152/54000 (91%)] Loss: -1526.746216\n",
      "Train Epoch: 374 [53248/54000 (99%)] Loss: -1529.519653\n",
      "    epoch          : 374\n",
      "    loss           : -1528.0356856070423\n",
      "    ess            : 3.7705114147674417\n",
      "    log_marginal   : 1528.1790262375962\n",
      "    val_loss       : -1528.1469167073567\n",
      "    val_ess        : 3.780323247114817\n",
      "    val_log_marginal: 1528.279561360677\n",
      "Train Epoch: 375 [0/54000 (0%)] Loss: -1529.188721\n",
      "Train Epoch: 375 [4096/54000 (8%)] Loss: -1522.082031\n",
      "Train Epoch: 375 [8192/54000 (15%)] Loss: -1538.122681\n",
      "Train Epoch: 375 [12288/54000 (23%)] Loss: -1530.567993\n",
      "Train Epoch: 375 [16384/54000 (30%)] Loss: -1529.162598\n",
      "Train Epoch: 375 [20480/54000 (38%)] Loss: -1531.116089\n",
      "Train Epoch: 375 [24576/54000 (46%)] Loss: -1526.190186\n",
      "Train Epoch: 375 [28672/54000 (53%)] Loss: -1531.479248\n",
      "Train Epoch: 375 [32768/54000 (61%)] Loss: -1532.691162\n",
      "Train Epoch: 375 [36864/54000 (68%)] Loss: -1528.973022\n",
      "Train Epoch: 375 [40960/54000 (76%)] Loss: -1525.015015\n",
      "Train Epoch: 375 [45056/54000 (83%)] Loss: -1526.408447\n",
      "Train Epoch: 375 [49152/54000 (91%)] Loss: -1523.809692\n",
      "Train Epoch: 375 [53248/54000 (99%)] Loss: -1530.627075\n",
      "    epoch          : 375\n",
      "    loss           : -1528.329793487115\n",
      "    ess            : 3.7771217834328024\n",
      "    log_marginal   : 1528.4688356227784\n",
      "    val_loss       : -1527.9167887369792\n",
      "    val_ess        : 3.791229615608851\n",
      "    val_log_marginal: 1528.0381724039714\n",
      "Train Epoch: 376 [0/54000 (0%)] Loss: -1521.769653\n",
      "Train Epoch: 376 [4096/54000 (8%)] Loss: -1528.458374\n",
      "Train Epoch: 376 [8192/54000 (15%)] Loss: -1528.337891\n",
      "Train Epoch: 376 [12288/54000 (23%)] Loss: -1525.941772\n",
      "Train Epoch: 376 [16384/54000 (30%)] Loss: -1531.253174\n",
      "Train Epoch: 376 [20480/54000 (38%)] Loss: -1531.162842\n",
      "Train Epoch: 376 [24576/54000 (46%)] Loss: -1525.734619\n",
      "Train Epoch: 376 [28672/54000 (53%)] Loss: -1525.457520\n",
      "Train Epoch: 376 [32768/54000 (61%)] Loss: -1522.686035\n",
      "Train Epoch: 376 [36864/54000 (68%)] Loss: -1526.258179\n",
      "Train Epoch: 376 [40960/54000 (76%)] Loss: -1529.531250\n",
      "Train Epoch: 376 [45056/54000 (83%)] Loss: -1537.004395\n",
      "Train Epoch: 376 [49152/54000 (91%)] Loss: -1530.922363\n",
      "Train Epoch: 376 [53248/54000 (99%)] Loss: -1531.619629\n",
      "    epoch          : 376\n",
      "    loss           : -1528.3200567887293\n",
      "    ess            : 3.7714795478712326\n",
      "    log_marginal   : 1528.462271016921\n",
      "    val_loss       : -1527.8027801513672\n",
      "    val_ess        : 3.7778307000796\n",
      "    val_log_marginal: 1527.936543782552\n",
      "Train Epoch: 377 [0/54000 (0%)] Loss: -1531.980469\n",
      "Train Epoch: 377 [4096/54000 (8%)] Loss: -1523.085449\n",
      "Train Epoch: 377 [8192/54000 (15%)] Loss: -1529.817993\n",
      "Train Epoch: 377 [12288/54000 (23%)] Loss: -1527.656738\n",
      "Train Epoch: 377 [16384/54000 (30%)] Loss: -1524.586792\n",
      "Train Epoch: 377 [20480/54000 (38%)] Loss: -1530.445557\n",
      "Train Epoch: 377 [24576/54000 (46%)] Loss: -1526.830078\n",
      "Train Epoch: 377 [28672/54000 (53%)] Loss: -1525.161743\n",
      "Train Epoch: 377 [32768/54000 (61%)] Loss: -1528.599854\n",
      "Train Epoch: 377 [36864/54000 (68%)] Loss: -1527.132080\n",
      "Train Epoch: 377 [40960/54000 (76%)] Loss: -1528.506836\n",
      "Train Epoch: 377 [45056/54000 (83%)] Loss: -1529.085693\n",
      "Train Epoch: 377 [49152/54000 (91%)] Loss: -1523.404541\n",
      "Train Epoch: 377 [53248/54000 (99%)] Loss: -1526.743652\n",
      "    epoch          : 377\n",
      "    loss           : -1528.339351419024\n",
      "    ess            : 3.775174624547009\n",
      "    log_marginal   : 1528.4824710502444\n",
      "    val_loss       : -1528.4578297932942\n",
      "    val_ess        : 3.7779533863067627\n",
      "    val_log_marginal: 1528.5927022298176\n",
      "Train Epoch: 378 [0/54000 (0%)] Loss: -1538.286133\n",
      "Train Epoch: 378 [4096/54000 (8%)] Loss: -1530.104980\n",
      "Train Epoch: 378 [8192/54000 (15%)] Loss: -1527.623901\n",
      "Train Epoch: 378 [12288/54000 (23%)] Loss: -1524.413940\n",
      "Train Epoch: 378 [16384/54000 (30%)] Loss: -1533.112061\n",
      "Train Epoch: 378 [20480/54000 (38%)] Loss: -1534.551270\n",
      "Train Epoch: 378 [24576/54000 (46%)] Loss: -1531.457275\n",
      "Train Epoch: 378 [28672/54000 (53%)] Loss: -1527.515259\n",
      "Train Epoch: 378 [32768/54000 (61%)] Loss: -1524.751221\n",
      "Train Epoch: 378 [36864/54000 (68%)] Loss: -1527.164551\n",
      "Train Epoch: 378 [40960/54000 (76%)] Loss: -1523.214722\n",
      "Train Epoch: 378 [45056/54000 (83%)] Loss: -1533.771484\n",
      "Train Epoch: 378 [49152/54000 (91%)] Loss: -1528.980957\n",
      "Train Epoch: 378 [53248/54000 (99%)] Loss: -1536.349854\n",
      "    epoch          : 378\n",
      "    loss           : -1528.504386431798\n",
      "    ess            : 3.7692033182388234\n",
      "    log_marginal   : 1528.6492549661211\n",
      "    val_loss       : -1528.4729614257812\n",
      "    val_ess        : 3.787833164135615\n",
      "    val_log_marginal: 1528.6008402506511\n",
      "Train Epoch: 379 [0/54000 (0%)] Loss: -1521.481079\n",
      "Train Epoch: 379 [4096/54000 (8%)] Loss: -1530.129150\n",
      "Train Epoch: 379 [8192/54000 (15%)] Loss: -1525.131592\n",
      "Train Epoch: 379 [12288/54000 (23%)] Loss: -1536.070801\n",
      "Train Epoch: 379 [16384/54000 (30%)] Loss: -1531.140747\n",
      "Train Epoch: 379 [20480/54000 (38%)] Loss: -1533.316040\n",
      "Train Epoch: 379 [24576/54000 (46%)] Loss: -1522.941284\n",
      "Train Epoch: 379 [28672/54000 (53%)] Loss: -1526.282593\n",
      "Train Epoch: 379 [32768/54000 (61%)] Loss: -1523.750977\n",
      "Train Epoch: 379 [36864/54000 (68%)] Loss: -1524.088501\n",
      "Train Epoch: 379 [40960/54000 (76%)] Loss: -1533.393677\n",
      "Train Epoch: 379 [45056/54000 (83%)] Loss: -1532.397339\n",
      "Train Epoch: 379 [49152/54000 (91%)] Loss: -1532.246216\n",
      "Train Epoch: 379 [53248/54000 (99%)] Loss: -1527.871338\n",
      "    epoch          : 379\n",
      "    loss           : -1528.5234994029547\n",
      "    ess            : 3.7729842515918315\n",
      "    log_marginal   : 1528.666231417543\n",
      "    val_loss       : -1528.5459493001301\n",
      "    val_ess        : 3.782565325498581\n",
      "    val_log_marginal: 1528.6868845621746\n",
      "Train Epoch: 380 [0/54000 (0%)] Loss: -1534.192627\n",
      "Train Epoch: 380 [4096/54000 (8%)] Loss: -1533.083496\n",
      "Train Epoch: 380 [8192/54000 (15%)] Loss: -1526.809448\n",
      "Train Epoch: 380 [12288/54000 (23%)] Loss: -1528.202393\n",
      "Train Epoch: 380 [16384/54000 (30%)] Loss: -1528.149536\n",
      "Train Epoch: 380 [20480/54000 (38%)] Loss: -1528.907715\n",
      "Train Epoch: 380 [24576/54000 (46%)] Loss: -1532.573242\n",
      "Train Epoch: 380 [28672/54000 (53%)] Loss: -1532.929199\n",
      "Train Epoch: 380 [32768/54000 (61%)] Loss: -1529.693604\n",
      "Train Epoch: 380 [36864/54000 (68%)] Loss: -1526.471924\n",
      "Train Epoch: 380 [40960/54000 (76%)] Loss: -1531.600220\n",
      "Train Epoch: 380 [45056/54000 (83%)] Loss: -1530.074951\n",
      "Train Epoch: 380 [49152/54000 (91%)] Loss: -1532.553345\n",
      "Train Epoch: 380 [53248/54000 (99%)] Loss: -1528.364990\n",
      "    epoch          : 380\n",
      "    loss           : -1528.9530156573978\n",
      "    ess            : 3.772156455505516\n",
      "    log_marginal   : 1529.095575847897\n",
      "    val_loss       : -1529.0523732503254\n",
      "    val_ess        : 3.77320804198583\n",
      "    val_log_marginal: 1529.1838684082031\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch380.pth ...\n",
      "Train Epoch: 381 [0/54000 (0%)] Loss: -1532.181763\n",
      "Train Epoch: 381 [4096/54000 (8%)] Loss: -1531.924316\n",
      "Train Epoch: 381 [8192/54000 (15%)] Loss: -1530.168701\n",
      "Train Epoch: 381 [12288/54000 (23%)] Loss: -1524.753662\n",
      "Train Epoch: 381 [16384/54000 (30%)] Loss: -1527.048096\n",
      "Train Epoch: 381 [20480/54000 (38%)] Loss: -1522.822021\n",
      "Train Epoch: 381 [24576/54000 (46%)] Loss: -1531.067871\n",
      "Train Epoch: 381 [28672/54000 (53%)] Loss: -1531.990234\n",
      "Train Epoch: 381 [32768/54000 (61%)] Loss: -1532.591919\n",
      "Train Epoch: 381 [36864/54000 (68%)] Loss: -1529.799072\n",
      "Train Epoch: 381 [40960/54000 (76%)] Loss: -1524.669678\n",
      "Train Epoch: 381 [45056/54000 (83%)] Loss: -1528.110596\n",
      "Train Epoch: 381 [49152/54000 (91%)] Loss: -1528.904541\n",
      "Train Epoch: 381 [53248/54000 (99%)] Loss: -1530.034424\n",
      "    epoch          : 381\n",
      "    loss           : -1529.0737819581236\n",
      "    ess            : 3.7713648018678785\n",
      "    log_marginal   : 1529.2201205429872\n",
      "    val_loss       : -1529.7940470377605\n",
      "    val_ess        : 3.7635692059993744\n",
      "    val_log_marginal: 1529.9403432210286\n",
      "Train Epoch: 382 [0/54000 (0%)] Loss: -1530.807373\n",
      "Train Epoch: 382 [4096/54000 (8%)] Loss: -1529.409668\n",
      "Train Epoch: 382 [8192/54000 (15%)] Loss: -1531.433838\n",
      "Train Epoch: 382 [12288/54000 (23%)] Loss: -1533.855957\n",
      "Train Epoch: 382 [16384/54000 (30%)] Loss: -1530.130127\n",
      "Train Epoch: 382 [20480/54000 (38%)] Loss: -1529.700562\n",
      "Train Epoch: 382 [24576/54000 (46%)] Loss: -1527.061768\n",
      "Train Epoch: 382 [28672/54000 (53%)] Loss: -1532.138428\n",
      "Train Epoch: 382 [32768/54000 (61%)] Loss: -1524.662598\n",
      "Train Epoch: 382 [36864/54000 (68%)] Loss: -1529.119385\n",
      "Train Epoch: 382 [40960/54000 (76%)] Loss: -1521.262451\n",
      "Train Epoch: 382 [45056/54000 (83%)] Loss: -1524.785034\n",
      "Train Epoch: 382 [49152/54000 (91%)] Loss: -1522.510742\n",
      "Train Epoch: 382 [53248/54000 (99%)] Loss: -1536.910645\n",
      "    epoch          : 382\n",
      "    loss           : -1529.2574260404324\n",
      "    ess            : 3.7738103098213953\n",
      "    log_marginal   : 1529.3979301271845\n",
      "    val_loss       : -1529.7290496826172\n",
      "    val_ess        : 3.7687727908293405\n",
      "    val_log_marginal: 1529.8795318603516\n",
      "Train Epoch: 383 [0/54000 (0%)] Loss: -1532.604370\n",
      "Train Epoch: 383 [4096/54000 (8%)] Loss: -1535.752319\n",
      "Train Epoch: 383 [8192/54000 (15%)] Loss: -1532.468872\n",
      "Train Epoch: 383 [12288/54000 (23%)] Loss: -1522.219482\n",
      "Train Epoch: 383 [16384/54000 (30%)] Loss: -1526.668823\n",
      "Train Epoch: 383 [20480/54000 (38%)] Loss: -1530.477051\n",
      "Train Epoch: 383 [24576/54000 (46%)] Loss: -1529.969971\n",
      "Train Epoch: 383 [28672/54000 (53%)] Loss: -1533.364258\n",
      "Train Epoch: 383 [32768/54000 (61%)] Loss: -1529.049683\n",
      "Train Epoch: 383 [36864/54000 (68%)] Loss: -1529.631592\n",
      "Train Epoch: 383 [40960/54000 (76%)] Loss: -1522.885742\n",
      "Train Epoch: 383 [45056/54000 (83%)] Loss: -1528.872314\n",
      "Train Epoch: 383 [49152/54000 (91%)] Loss: -1531.622803\n",
      "Train Epoch: 383 [53248/54000 (99%)] Loss: -1526.981323\n",
      "    epoch          : 383\n",
      "    loss           : -1529.4251587492595\n",
      "    ess            : 3.770684828690443\n",
      "    log_marginal   : 1529.5693989975193\n",
      "    val_loss       : -1528.2286631266277\n",
      "    val_ess        : 3.79219326376915\n",
      "    val_log_marginal: 1528.3603820800781\n",
      "Train Epoch: 384 [0/54000 (0%)] Loss: -1530.201294\n",
      "Train Epoch: 384 [4096/54000 (8%)] Loss: -1532.033447\n",
      "Train Epoch: 384 [8192/54000 (15%)] Loss: -1530.946899\n",
      "Train Epoch: 384 [12288/54000 (23%)] Loss: -1530.706543\n",
      "Train Epoch: 384 [16384/54000 (30%)] Loss: -1526.455078\n",
      "Train Epoch: 384 [20480/54000 (38%)] Loss: -1529.626709\n",
      "Train Epoch: 384 [24576/54000 (46%)] Loss: -1527.628418\n",
      "Train Epoch: 384 [28672/54000 (53%)] Loss: -1531.760254\n",
      "Train Epoch: 384 [32768/54000 (61%)] Loss: -1532.155640\n",
      "Train Epoch: 384 [36864/54000 (68%)] Loss: -1530.277710\n",
      "Train Epoch: 384 [40960/54000 (76%)] Loss: -1528.212646\n",
      "Train Epoch: 384 [45056/54000 (83%)] Loss: -1522.353271\n",
      "Train Epoch: 384 [49152/54000 (91%)] Loss: -1520.771484\n",
      "Train Epoch: 384 [53248/54000 (99%)] Loss: -1529.571411\n",
      "    epoch          : 384\n",
      "    loss           : -1529.5479510700534\n",
      "    ess            : 3.7747600869544873\n",
      "    log_marginal   : 1529.6931296976823\n",
      "    val_loss       : -1529.1494598388672\n",
      "    val_ess        : 3.773195823033651\n",
      "    val_log_marginal: 1529.2960611979167\n",
      "Train Epoch: 385 [0/54000 (0%)] Loss: -1524.800537\n",
      "Train Epoch: 385 [4096/54000 (8%)] Loss: -1529.193726\n",
      "Train Epoch: 385 [8192/54000 (15%)] Loss: -1532.419678\n",
      "Train Epoch: 385 [12288/54000 (23%)] Loss: -1532.119995\n",
      "Train Epoch: 385 [16384/54000 (30%)] Loss: -1527.708496\n",
      "Train Epoch: 385 [20480/54000 (38%)] Loss: -1527.659668\n",
      "Train Epoch: 385 [24576/54000 (46%)] Loss: -1532.580078\n",
      "Train Epoch: 385 [28672/54000 (53%)] Loss: -1532.509766\n",
      "Train Epoch: 385 [32768/54000 (61%)] Loss: -1530.468994\n",
      "Train Epoch: 385 [36864/54000 (68%)] Loss: -1525.356689\n",
      "Train Epoch: 385 [40960/54000 (76%)] Loss: -1539.559082\n",
      "Train Epoch: 385 [45056/54000 (83%)] Loss: -1525.868530\n",
      "Train Epoch: 385 [49152/54000 (91%)] Loss: -1528.880249\n",
      "Train Epoch: 385 [53248/54000 (99%)] Loss: -1527.384033\n",
      "    epoch          : 385\n",
      "    loss           : -1529.4770478885885\n",
      "    ess            : 3.769902094845523\n",
      "    log_marginal   : 1529.6213101210753\n",
      "    val_loss       : -1529.6579081217449\n",
      "    val_ess        : 3.785594234863917\n",
      "    val_log_marginal: 1529.7813161214192\n",
      "Train Epoch: 386 [0/54000 (0%)] Loss: -1528.065430\n",
      "Train Epoch: 386 [4096/54000 (8%)] Loss: -1524.610718\n",
      "Train Epoch: 386 [8192/54000 (15%)] Loss: -1526.627197\n",
      "Train Epoch: 386 [12288/54000 (23%)] Loss: -1527.087402\n",
      "Train Epoch: 386 [16384/54000 (30%)] Loss: -1534.597168\n",
      "Train Epoch: 386 [20480/54000 (38%)] Loss: -1530.464355\n",
      "Train Epoch: 386 [24576/54000 (46%)] Loss: -1529.855835\n",
      "Train Epoch: 386 [28672/54000 (53%)] Loss: -1525.124268\n",
      "Train Epoch: 386 [32768/54000 (61%)] Loss: -1529.062500\n",
      "Train Epoch: 386 [36864/54000 (68%)] Loss: -1534.548828\n",
      "Train Epoch: 386 [40960/54000 (76%)] Loss: -1527.840332\n",
      "Train Epoch: 386 [45056/54000 (83%)] Loss: -1530.071045\n",
      "Train Epoch: 386 [49152/54000 (91%)] Loss: -1529.819092\n",
      "Train Epoch: 386 [53248/54000 (99%)] Loss: -1528.185303\n",
      "    epoch          : 386\n",
      "    loss           : -1529.7620814897439\n",
      "    ess            : 3.7713232017806355\n",
      "    log_marginal   : 1529.9055760098859\n",
      "    val_loss       : -1530.5384826660156\n",
      "    val_ess        : 3.7691019475460052\n",
      "    val_log_marginal: 1530.676045735677\n",
      "Train Epoch: 387 [0/54000 (0%)] Loss: -1529.298096\n",
      "Train Epoch: 387 [4096/54000 (8%)] Loss: -1530.750122\n",
      "Train Epoch: 387 [8192/54000 (15%)] Loss: -1527.530518\n",
      "Train Epoch: 387 [12288/54000 (23%)] Loss: -1533.291138\n",
      "Train Epoch: 387 [16384/54000 (30%)] Loss: -1519.277100\n",
      "Train Epoch: 387 [20480/54000 (38%)] Loss: -1528.137573\n",
      "Train Epoch: 387 [24576/54000 (46%)] Loss: -1532.605469\n",
      "Train Epoch: 387 [28672/54000 (53%)] Loss: -1530.254150\n",
      "Train Epoch: 387 [32768/54000 (61%)] Loss: -1529.827026\n",
      "Train Epoch: 387 [36864/54000 (68%)] Loss: -1528.514648\n",
      "Train Epoch: 387 [40960/54000 (76%)] Loss: -1529.585938\n",
      "Train Epoch: 387 [45056/54000 (83%)] Loss: -1525.825439\n",
      "Train Epoch: 387 [49152/54000 (91%)] Loss: -1533.301758\n",
      "Train Epoch: 387 [53248/54000 (99%)] Loss: -1532.372559\n",
      "    epoch          : 387\n",
      "    loss           : -1529.8803763005405\n",
      "    ess            : 3.770416330952215\n",
      "    log_marginal   : 1530.0238216454384\n",
      "    val_loss       : -1529.6712748209636\n",
      "    val_ess        : 3.7672625283400216\n",
      "    val_log_marginal: 1529.816162109375\n",
      "Train Epoch: 388 [0/54000 (0%)] Loss: -1536.235107\n",
      "Train Epoch: 388 [4096/54000 (8%)] Loss: -1534.337891\n",
      "Train Epoch: 388 [8192/54000 (15%)] Loss: -1531.291260\n",
      "Train Epoch: 388 [12288/54000 (23%)] Loss: -1526.872070\n",
      "Train Epoch: 388 [16384/54000 (30%)] Loss: -1533.163574\n",
      "Train Epoch: 388 [20480/54000 (38%)] Loss: -1526.466797\n",
      "Train Epoch: 388 [24576/54000 (46%)] Loss: -1529.197510\n",
      "Train Epoch: 388 [28672/54000 (53%)] Loss: -1531.539551\n",
      "Train Epoch: 388 [32768/54000 (61%)] Loss: -1527.199707\n",
      "Train Epoch: 388 [36864/54000 (68%)] Loss: -1528.940918\n",
      "Train Epoch: 388 [40960/54000 (76%)] Loss: -1528.143066\n",
      "Train Epoch: 388 [45056/54000 (83%)] Loss: -1525.373901\n",
      "Train Epoch: 388 [49152/54000 (91%)] Loss: -1530.363037\n",
      "Train Epoch: 388 [53248/54000 (99%)] Loss: -1527.436890\n",
      "    epoch          : 388\n",
      "    loss           : -1529.9915088816276\n",
      "    ess            : 3.7753397446673063\n",
      "    log_marginal   : 1530.1317798198681\n",
      "    val_loss       : -1529.5713450113933\n",
      "    val_ess        : 3.77353506286939\n",
      "    val_log_marginal: 1529.7077128092449\n",
      "Train Epoch: 389 [0/54000 (0%)] Loss: -1522.134155\n",
      "Train Epoch: 389 [4096/54000 (8%)] Loss: -1533.741455\n",
      "Train Epoch: 389 [8192/54000 (15%)] Loss: -1538.805176\n",
      "Train Epoch: 389 [12288/54000 (23%)] Loss: -1532.357422\n",
      "Train Epoch: 389 [16384/54000 (30%)] Loss: -1530.118408\n",
      "Train Epoch: 389 [20480/54000 (38%)] Loss: -1524.899902\n",
      "Train Epoch: 389 [24576/54000 (46%)] Loss: -1529.034668\n",
      "Train Epoch: 389 [28672/54000 (53%)] Loss: -1524.072754\n",
      "Train Epoch: 389 [32768/54000 (61%)] Loss: -1529.892090\n",
      "Train Epoch: 389 [36864/54000 (68%)] Loss: -1530.277832\n",
      "Train Epoch: 389 [40960/54000 (76%)] Loss: -1530.400269\n",
      "Train Epoch: 389 [45056/54000 (83%)] Loss: -1528.330444\n",
      "Train Epoch: 389 [49152/54000 (91%)] Loss: -1529.754639\n",
      "Train Epoch: 389 [53248/54000 (99%)] Loss: -1533.837402\n",
      "    epoch          : 389\n",
      "    loss           : -1530.01420065351\n",
      "    ess            : 3.771723293015177\n",
      "    log_marginal   : 1530.15542269883\n",
      "    val_loss       : -1529.4885711669922\n",
      "    val_ess        : 3.77515576283137\n",
      "    val_log_marginal: 1529.631312052409\n",
      "Train Epoch: 390 [0/54000 (0%)] Loss: -1525.889648\n",
      "Train Epoch: 390 [4096/54000 (8%)] Loss: -1525.907349\n",
      "Train Epoch: 390 [8192/54000 (15%)] Loss: -1533.815674\n",
      "Train Epoch: 390 [12288/54000 (23%)] Loss: -1529.347168\n",
      "Train Epoch: 390 [16384/54000 (30%)] Loss: -1529.939453\n",
      "Train Epoch: 390 [20480/54000 (38%)] Loss: -1533.014526\n",
      "Train Epoch: 390 [24576/54000 (46%)] Loss: -1530.648193\n",
      "Train Epoch: 390 [28672/54000 (53%)] Loss: -1535.010986\n",
      "Train Epoch: 390 [32768/54000 (61%)] Loss: -1527.286621\n",
      "Train Epoch: 390 [36864/54000 (68%)] Loss: -1537.452148\n",
      "Train Epoch: 390 [40960/54000 (76%)] Loss: -1530.983032\n",
      "Train Epoch: 390 [45056/54000 (83%)] Loss: -1533.662354\n",
      "Train Epoch: 390 [49152/54000 (91%)] Loss: -1527.508789\n",
      "Train Epoch: 390 [53248/54000 (99%)] Loss: -1532.434082\n",
      "    epoch          : 390\n",
      "    loss           : -1530.159563254406\n",
      "    ess            : 3.7744029958101244\n",
      "    log_marginal   : 1530.3008547236004\n",
      "    val_loss       : -1530.7306365966797\n",
      "    val_ess        : 3.7714593609174094\n",
      "    val_log_marginal: 1530.8719533284504\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch390.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 391 [0/54000 (0%)] Loss: -1525.779175\n",
      "Train Epoch: 391 [4096/54000 (8%)] Loss: -1533.797119\n",
      "Train Epoch: 391 [8192/54000 (15%)] Loss: -1533.753174\n",
      "Train Epoch: 391 [12288/54000 (23%)] Loss: -1529.632080\n",
      "Train Epoch: 391 [16384/54000 (30%)] Loss: -1533.333740\n",
      "Train Epoch: 391 [20480/54000 (38%)] Loss: -1525.384277\n",
      "Train Epoch: 391 [24576/54000 (46%)] Loss: -1528.104980\n",
      "Train Epoch: 391 [28672/54000 (53%)] Loss: -1532.375732\n",
      "Train Epoch: 391 [32768/54000 (61%)] Loss: -1532.309204\n",
      "Train Epoch: 391 [36864/54000 (68%)] Loss: -1524.652832\n",
      "Train Epoch: 391 [40960/54000 (76%)] Loss: -1531.417236\n",
      "Train Epoch: 391 [45056/54000 (83%)] Loss: -1531.549805\n",
      "Train Epoch: 391 [49152/54000 (91%)] Loss: -1532.197998\n",
      "Train Epoch: 391 [53248/54000 (99%)] Loss: -1525.726196\n",
      "    epoch          : 391\n",
      "    loss           : -1530.127286359597\n",
      "    ess            : 3.7734362988675376\n",
      "    log_marginal   : 1530.2674375416543\n",
      "    val_loss       : -1529.4769592285156\n",
      "    val_ess        : 3.7702675064404807\n",
      "    val_log_marginal: 1529.620885213216\n",
      "Train Epoch: 392 [0/54000 (0%)] Loss: -1528.944336\n",
      "Train Epoch: 392 [4096/54000 (8%)] Loss: -1525.205200\n",
      "Train Epoch: 392 [8192/54000 (15%)] Loss: -1532.887817\n",
      "Train Epoch: 392 [12288/54000 (23%)] Loss: -1538.841797\n",
      "Train Epoch: 392 [16384/54000 (30%)] Loss: -1528.140625\n",
      "Train Epoch: 392 [20480/54000 (38%)] Loss: -1531.012573\n",
      "Train Epoch: 392 [24576/54000 (46%)] Loss: -1532.583984\n",
      "Train Epoch: 392 [28672/54000 (53%)] Loss: -1535.908447\n",
      "Train Epoch: 392 [32768/54000 (61%)] Loss: -1526.509521\n",
      "Train Epoch: 392 [36864/54000 (68%)] Loss: -1529.664185\n",
      "Train Epoch: 392 [40960/54000 (76%)] Loss: -1527.250977\n",
      "Train Epoch: 392 [45056/54000 (83%)] Loss: -1533.735840\n",
      "Train Epoch: 392 [49152/54000 (91%)] Loss: -1527.929932\n",
      "Train Epoch: 392 [53248/54000 (99%)] Loss: -1528.345215\n",
      "    epoch          : 392\n",
      "    loss           : -1530.3138653361966\n",
      "    ess            : 3.771050296123559\n",
      "    log_marginal   : 1530.4579921921284\n",
      "    val_loss       : -1529.9247029622395\n",
      "    val_ess        : 3.770771453777949\n",
      "    val_log_marginal: 1530.0690816243489\n",
      "Train Epoch: 393 [0/54000 (0%)] Loss: -1528.061646\n",
      "Train Epoch: 393 [4096/54000 (8%)] Loss: -1534.948486\n",
      "Train Epoch: 393 [8192/54000 (15%)] Loss: -1530.988159\n",
      "Train Epoch: 393 [12288/54000 (23%)] Loss: -1529.771851\n",
      "Train Epoch: 393 [16384/54000 (30%)] Loss: -1530.345459\n",
      "Train Epoch: 393 [20480/54000 (38%)] Loss: -1529.768311\n",
      "Train Epoch: 393 [24576/54000 (46%)] Loss: -1520.818848\n",
      "Train Epoch: 393 [28672/54000 (53%)] Loss: -1530.872314\n",
      "Train Epoch: 393 [32768/54000 (61%)] Loss: -1539.148560\n",
      "Train Epoch: 393 [36864/54000 (68%)] Loss: -1523.570312\n",
      "Train Epoch: 393 [40960/54000 (76%)] Loss: -1529.498169\n",
      "Train Epoch: 393 [45056/54000 (83%)] Loss: -1530.221069\n",
      "Train Epoch: 393 [49152/54000 (91%)] Loss: -1529.338623\n",
      "Train Epoch: 393 [53248/54000 (99%)] Loss: -1538.883545\n",
      "    epoch          : 393\n",
      "    loss           : -1530.5550247843232\n",
      "    ess            : 3.7704861265788145\n",
      "    log_marginal   : 1530.7014044449793\n",
      "    val_loss       : -1529.8346150716145\n",
      "    val_ess        : 3.764828165372213\n",
      "    val_log_marginal: 1529.981180826823\n",
      "Train Epoch: 394 [0/54000 (0%)] Loss: -1530.827637\n",
      "Train Epoch: 394 [4096/54000 (8%)] Loss: -1536.162964\n",
      "Train Epoch: 394 [8192/54000 (15%)] Loss: -1530.395386\n",
      "Train Epoch: 394 [12288/54000 (23%)] Loss: -1540.017090\n",
      "Train Epoch: 394 [16384/54000 (30%)] Loss: -1529.355347\n",
      "Train Epoch: 394 [20480/54000 (38%)] Loss: -1534.943848\n",
      "Train Epoch: 394 [24576/54000 (46%)] Loss: -1528.773193\n",
      "Train Epoch: 394 [28672/54000 (53%)] Loss: -1540.858154\n",
      "Train Epoch: 394 [32768/54000 (61%)] Loss: -1527.602051\n",
      "Train Epoch: 394 [36864/54000 (68%)] Loss: -1528.000000\n",
      "Train Epoch: 394 [40960/54000 (76%)] Loss: -1535.096680\n",
      "Train Epoch: 394 [45056/54000 (83%)] Loss: -1529.426270\n",
      "Train Epoch: 394 [49152/54000 (91%)] Loss: -1529.787964\n",
      "Train Epoch: 394 [53248/54000 (99%)] Loss: -1528.856934\n",
      "    epoch          : 394\n",
      "    loss           : -1530.2189530648327\n",
      "    ess            : 3.775732976000456\n",
      "    log_marginal   : 1530.3581537183427\n",
      "    val_loss       : -1530.1092580159504\n",
      "    val_ess        : 3.7871166467666626\n",
      "    val_log_marginal: 1530.2398579915364\n",
      "Train Epoch: 395 [0/54000 (0%)] Loss: -1525.642578\n",
      "Train Epoch: 395 [4096/54000 (8%)] Loss: -1531.260010\n",
      "Train Epoch: 395 [8192/54000 (15%)] Loss: -1529.517578\n",
      "Train Epoch: 395 [12288/54000 (23%)] Loss: -1535.739746\n",
      "Train Epoch: 395 [16384/54000 (30%)] Loss: -1538.268066\n",
      "Train Epoch: 395 [20480/54000 (38%)] Loss: -1522.164551\n",
      "Train Epoch: 395 [24576/54000 (46%)] Loss: -1533.515625\n",
      "Train Epoch: 395 [28672/54000 (53%)] Loss: -1526.704224\n",
      "Train Epoch: 395 [32768/54000 (61%)] Loss: -1531.162842\n",
      "Train Epoch: 395 [36864/54000 (68%)] Loss: -1528.515869\n",
      "Train Epoch: 395 [40960/54000 (76%)] Loss: -1521.554688\n",
      "Train Epoch: 395 [45056/54000 (83%)] Loss: -1534.276855\n",
      "Train Epoch: 395 [49152/54000 (91%)] Loss: -1533.044678\n",
      "Train Epoch: 395 [53248/54000 (99%)] Loss: -1531.842529\n",
      "    epoch          : 395\n",
      "    loss           : -1530.5471845147733\n",
      "    ess            : 3.7778316662774833\n",
      "    log_marginal   : 1530.6881849822275\n",
      "    val_loss       : -1530.1986694335938\n",
      "    val_ess        : 3.784265567859014\n",
      "    val_log_marginal: 1530.3357899983723\n",
      "Train Epoch: 396 [0/54000 (0%)] Loss: -1524.185059\n",
      "Train Epoch: 396 [4096/54000 (8%)] Loss: -1524.319824\n",
      "Train Epoch: 396 [8192/54000 (15%)] Loss: -1530.668945\n",
      "Train Epoch: 396 [12288/54000 (23%)] Loss: -1534.180054\n",
      "Train Epoch: 396 [16384/54000 (30%)] Loss: -1537.530029\n",
      "Train Epoch: 396 [20480/54000 (38%)] Loss: -1530.436523\n",
      "Train Epoch: 396 [24576/54000 (46%)] Loss: -1533.166748\n",
      "Train Epoch: 396 [28672/54000 (53%)] Loss: -1536.390991\n",
      "Train Epoch: 396 [32768/54000 (61%)] Loss: -1527.739502\n",
      "Train Epoch: 396 [36864/54000 (68%)] Loss: -1527.797974\n",
      "Train Epoch: 396 [40960/54000 (76%)] Loss: -1535.161133\n",
      "Train Epoch: 396 [45056/54000 (83%)] Loss: -1529.937378\n",
      "Train Epoch: 396 [49152/54000 (91%)] Loss: -1533.066162\n",
      "Train Epoch: 396 [53248/54000 (99%)] Loss: -1532.253296\n",
      "    epoch          : 396\n",
      "    loss           : -1530.8143206411064\n",
      "    ess            : 3.7739993542856514\n",
      "    log_marginal   : 1530.956430154954\n",
      "    val_loss       : -1530.6266225179036\n",
      "    val_ess        : 3.7653747498989105\n",
      "    val_log_marginal: 1530.7685852050781\n",
      "Train Epoch: 397 [0/54000 (0%)] Loss: -1527.381592\n",
      "Train Epoch: 397 [4096/54000 (8%)] Loss: -1525.283447\n",
      "Train Epoch: 397 [8192/54000 (15%)] Loss: -1527.355957\n",
      "Train Epoch: 397 [12288/54000 (23%)] Loss: -1535.272217\n",
      "Train Epoch: 397 [16384/54000 (30%)] Loss: -1530.248535\n",
      "Train Epoch: 397 [20480/54000 (38%)] Loss: -1531.955566\n",
      "Train Epoch: 397 [24576/54000 (46%)] Loss: -1530.699463\n",
      "Train Epoch: 397 [28672/54000 (53%)] Loss: -1529.576660\n",
      "Train Epoch: 397 [32768/54000 (61%)] Loss: -1535.135498\n",
      "Train Epoch: 397 [36864/54000 (68%)] Loss: -1531.511230\n",
      "Train Epoch: 397 [40960/54000 (76%)] Loss: -1525.719482\n",
      "Train Epoch: 397 [45056/54000 (83%)] Loss: -1530.305664\n",
      "Train Epoch: 397 [49152/54000 (91%)] Loss: -1531.365234\n",
      "Train Epoch: 397 [53248/54000 (99%)] Loss: -1533.055420\n",
      "    epoch          : 397\n",
      "    loss           : -1531.0048509932242\n",
      "    ess            : 3.773093695889152\n",
      "    log_marginal   : 1531.144162146401\n",
      "    val_loss       : -1530.7701822916667\n",
      "    val_ess        : 3.762854725122452\n",
      "    val_log_marginal: 1530.913569132487\n",
      "Train Epoch: 398 [0/54000 (0%)] Loss: -1527.665649\n",
      "Train Epoch: 398 [4096/54000 (8%)] Loss: -1530.602783\n",
      "Train Epoch: 398 [8192/54000 (15%)] Loss: -1533.232788\n",
      "Train Epoch: 398 [12288/54000 (23%)] Loss: -1528.294678\n",
      "Train Epoch: 398 [16384/54000 (30%)] Loss: -1531.684204\n",
      "Train Epoch: 398 [20480/54000 (38%)] Loss: -1523.578979\n",
      "Train Epoch: 398 [24576/54000 (46%)] Loss: -1535.169556\n",
      "Train Epoch: 398 [28672/54000 (53%)] Loss: -1528.652710\n",
      "Train Epoch: 398 [32768/54000 (61%)] Loss: -1534.805908\n",
      "Train Epoch: 398 [36864/54000 (68%)] Loss: -1529.057129\n",
      "Train Epoch: 398 [40960/54000 (76%)] Loss: -1533.259644\n",
      "Train Epoch: 398 [45056/54000 (83%)] Loss: -1527.410400\n",
      "Train Epoch: 398 [49152/54000 (91%)] Loss: -1536.543091\n",
      "Train Epoch: 398 [53248/54000 (99%)] Loss: -1525.107910\n",
      "    epoch          : 398\n",
      "    loss           : -1531.0462322506294\n",
      "    ess            : 3.774294578633602\n",
      "    log_marginal   : 1531.1877209993336\n",
      "    val_loss       : -1530.425745646159\n",
      "    val_ess        : 3.7654032111167908\n",
      "    val_log_marginal: 1530.5738321940105\n",
      "Train Epoch: 399 [0/54000 (0%)] Loss: -1529.794189\n",
      "Train Epoch: 399 [4096/54000 (8%)] Loss: -1537.707886\n",
      "Train Epoch: 399 [8192/54000 (15%)] Loss: -1533.109619\n",
      "Train Epoch: 399 [12288/54000 (23%)] Loss: -1519.508789\n",
      "Train Epoch: 399 [16384/54000 (30%)] Loss: -1528.961670\n",
      "Train Epoch: 399 [20480/54000 (38%)] Loss: -1531.646484\n",
      "Train Epoch: 399 [24576/54000 (46%)] Loss: -1535.680176\n",
      "Train Epoch: 399 [28672/54000 (53%)] Loss: -1529.625366\n",
      "Train Epoch: 399 [32768/54000 (61%)] Loss: -1533.200439\n",
      "Train Epoch: 399 [36864/54000 (68%)] Loss: -1535.499756\n",
      "Train Epoch: 399 [40960/54000 (76%)] Loss: -1526.664307\n",
      "Train Epoch: 399 [45056/54000 (83%)] Loss: -1532.976562\n",
      "Train Epoch: 399 [49152/54000 (91%)] Loss: -1529.594360\n",
      "Train Epoch: 399 [53248/54000 (99%)] Loss: -1532.652222\n",
      "    epoch          : 399\n",
      "    loss           : -1531.1174970147733\n",
      "    ess            : 3.772604086952752\n",
      "    log_marginal   : 1531.263469967232\n",
      "    val_loss       : -1530.58447265625\n",
      "    val_ess        : 3.768749952316284\n",
      "    val_log_marginal: 1530.7365824381511\n",
      "Train Epoch: 400 [0/54000 (0%)] Loss: -1531.967651\n",
      "Train Epoch: 400 [4096/54000 (8%)] Loss: -1528.430420\n",
      "Train Epoch: 400 [8192/54000 (15%)] Loss: -1534.900635\n",
      "Train Epoch: 400 [12288/54000 (23%)] Loss: -1523.686035\n",
      "Train Epoch: 400 [16384/54000 (30%)] Loss: -1530.869873\n",
      "Train Epoch: 400 [20480/54000 (38%)] Loss: -1532.738525\n",
      "Train Epoch: 400 [24576/54000 (46%)] Loss: -1527.940430\n",
      "Train Epoch: 400 [28672/54000 (53%)] Loss: -1530.315918\n",
      "Train Epoch: 400 [32768/54000 (61%)] Loss: -1528.341309\n",
      "Train Epoch: 400 [36864/54000 (68%)] Loss: -1527.178467\n",
      "Train Epoch: 400 [40960/54000 (76%)] Loss: -1530.384766\n",
      "Train Epoch: 400 [45056/54000 (83%)] Loss: -1530.161133\n",
      "Train Epoch: 400 [49152/54000 (91%)] Loss: -1527.882568\n",
      "Train Epoch: 400 [53248/54000 (99%)] Loss: -1535.512085\n",
      "    epoch          : 400\n",
      "    loss           : -1531.2895340038137\n",
      "    ess            : 3.775458984465396\n",
      "    log_marginal   : 1531.431123995668\n",
      "    val_loss       : -1530.5391693115234\n",
      "    val_ess        : 3.7813203434149423\n",
      "    val_log_marginal: 1530.6799062093098\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [0/54000 (0%)] Loss: -1533.294189\n",
      "Train Epoch: 401 [4096/54000 (8%)] Loss: -1531.001221\n",
      "Train Epoch: 401 [8192/54000 (15%)] Loss: -1534.051147\n",
      "Train Epoch: 401 [12288/54000 (23%)] Loss: -1527.575928\n",
      "Train Epoch: 401 [16384/54000 (30%)] Loss: -1528.305420\n",
      "Train Epoch: 401 [20480/54000 (38%)] Loss: -1535.973877\n",
      "Train Epoch: 401 [24576/54000 (46%)] Loss: -1534.122803\n",
      "Train Epoch: 401 [28672/54000 (53%)] Loss: -1530.983643\n",
      "Train Epoch: 401 [32768/54000 (61%)] Loss: -1532.941162\n",
      "Train Epoch: 401 [36864/54000 (68%)] Loss: -1536.150391\n",
      "Train Epoch: 401 [40960/54000 (76%)] Loss: -1534.238037\n",
      "Train Epoch: 401 [45056/54000 (83%)] Loss: -1532.412354\n",
      "Train Epoch: 401 [49152/54000 (91%)] Loss: -1526.773682\n",
      "Train Epoch: 401 [53248/54000 (99%)] Loss: -1531.973877\n",
      "    epoch          : 401\n",
      "    loss           : -1531.2012401418099\n",
      "    ess            : 3.77378167586304\n",
      "    log_marginal   : 1531.3455712196387\n",
      "    val_loss       : -1530.591079711914\n",
      "    val_ess        : 3.7749238312244415\n",
      "    val_log_marginal: 1530.7364095052083\n",
      "Train Epoch: 402 [0/54000 (0%)] Loss: -1527.631104\n",
      "Train Epoch: 402 [4096/54000 (8%)] Loss: -1528.110107\n",
      "Train Epoch: 402 [8192/54000 (15%)] Loss: -1523.013550\n",
      "Train Epoch: 402 [12288/54000 (23%)] Loss: -1534.166382\n",
      "Train Epoch: 402 [16384/54000 (30%)] Loss: -1532.526611\n",
      "Train Epoch: 402 [20480/54000 (38%)] Loss: -1530.197632\n",
      "Train Epoch: 402 [24576/54000 (46%)] Loss: -1535.143066\n",
      "Train Epoch: 402 [28672/54000 (53%)] Loss: -1532.369385\n",
      "Train Epoch: 402 [32768/54000 (61%)] Loss: -1538.120483\n",
      "Train Epoch: 402 [36864/54000 (68%)] Loss: -1525.766846\n",
      "Train Epoch: 402 [40960/54000 (76%)] Loss: -1533.141479\n",
      "Train Epoch: 402 [45056/54000 (83%)] Loss: -1529.581543\n",
      "Train Epoch: 402 [49152/54000 (91%)] Loss: -1525.859009\n",
      "Train Epoch: 402 [53248/54000 (99%)] Loss: -1532.238525\n",
      "    epoch          : 402\n",
      "    loss           : -1531.2892349026215\n",
      "    ess            : 3.77473914340774\n",
      "    log_marginal   : 1531.4313692933574\n",
      "    val_loss       : -1530.4920552571614\n",
      "    val_ess        : 3.774740735689799\n",
      "    val_log_marginal: 1530.637954711914\n",
      "Train Epoch: 403 [0/54000 (0%)] Loss: -1534.343750\n",
      "Train Epoch: 403 [4096/54000 (8%)] Loss: -1537.079712\n",
      "Train Epoch: 403 [8192/54000 (15%)] Loss: -1537.171631\n",
      "Train Epoch: 403 [12288/54000 (23%)] Loss: -1524.351807\n",
      "Train Epoch: 403 [16384/54000 (30%)] Loss: -1535.881104\n",
      "Train Epoch: 403 [20480/54000 (38%)] Loss: -1533.013062\n",
      "Train Epoch: 403 [24576/54000 (46%)] Loss: -1534.131104\n",
      "Train Epoch: 403 [28672/54000 (53%)] Loss: -1522.618286\n",
      "Train Epoch: 403 [32768/54000 (61%)] Loss: -1535.303467\n",
      "Train Epoch: 403 [36864/54000 (68%)] Loss: -1532.045898\n",
      "Train Epoch: 403 [40960/54000 (76%)] Loss: -1524.806641\n",
      "Train Epoch: 403 [45056/54000 (83%)] Loss: -1526.469727\n",
      "Train Epoch: 403 [49152/54000 (91%)] Loss: -1527.570190\n",
      "Train Epoch: 403 [53248/54000 (99%)] Loss: -1528.111938\n",
      "    epoch          : 403\n",
      "    loss           : -1531.1577929456087\n",
      "    ess            : 3.7722806885344156\n",
      "    log_marginal   : 1531.3036247361892\n",
      "    val_loss       : -1530.0683034261067\n",
      "    val_ess        : 3.765373796224594\n",
      "    val_log_marginal: 1530.2066497802734\n",
      "Train Epoch: 404 [0/54000 (0%)] Loss: -1521.641846\n",
      "Train Epoch: 404 [4096/54000 (8%)] Loss: -1536.728149\n",
      "Train Epoch: 404 [8192/54000 (15%)] Loss: -1532.400879\n",
      "Train Epoch: 404 [12288/54000 (23%)] Loss: -1531.914795\n",
      "Train Epoch: 404 [16384/54000 (30%)] Loss: -1532.624756\n",
      "Train Epoch: 404 [20480/54000 (38%)] Loss: -1531.224121\n",
      "Train Epoch: 404 [24576/54000 (46%)] Loss: -1531.045044\n",
      "Train Epoch: 404 [28672/54000 (53%)] Loss: -1528.388184\n",
      "Train Epoch: 404 [32768/54000 (61%)] Loss: -1529.283203\n",
      "Train Epoch: 404 [36864/54000 (68%)] Loss: -1534.627930\n",
      "Train Epoch: 404 [40960/54000 (76%)] Loss: -1530.362305\n",
      "Train Epoch: 404 [45056/54000 (83%)] Loss: -1526.579956\n",
      "Train Epoch: 404 [49152/54000 (91%)] Loss: -1529.818604\n",
      "Train Epoch: 404 [53248/54000 (99%)] Loss: -1532.253662\n",
      "    epoch          : 404\n",
      "    loss           : -1531.2105909591603\n",
      "    ess            : 3.7756814470788314\n",
      "    log_marginal   : 1531.3513646419578\n",
      "    val_loss       : -1531.566426595052\n",
      "    val_ess        : 3.7698028683662415\n",
      "    val_log_marginal: 1531.708719889323\n",
      "Train Epoch: 405 [0/54000 (0%)] Loss: -1537.695923\n",
      "Train Epoch: 405 [4096/54000 (8%)] Loss: -1535.197876\n",
      "Train Epoch: 405 [8192/54000 (15%)] Loss: -1538.337280\n",
      "Train Epoch: 405 [12288/54000 (23%)] Loss: -1528.543701\n",
      "Train Epoch: 405 [16384/54000 (30%)] Loss: -1530.835205\n",
      "Train Epoch: 405 [20480/54000 (38%)] Loss: -1530.350342\n",
      "Train Epoch: 405 [24576/54000 (46%)] Loss: -1541.621826\n",
      "Train Epoch: 405 [28672/54000 (53%)] Loss: -1524.864990\n",
      "Train Epoch: 405 [32768/54000 (61%)] Loss: -1524.833740\n",
      "Train Epoch: 405 [36864/54000 (68%)] Loss: -1528.239258\n",
      "Train Epoch: 405 [40960/54000 (76%)] Loss: -1536.090942\n",
      "Train Epoch: 405 [45056/54000 (83%)] Loss: -1529.777954\n",
      "Train Epoch: 405 [49152/54000 (91%)] Loss: -1535.314453\n",
      "Train Epoch: 405 [53248/54000 (99%)] Loss: -1525.554932\n",
      "    epoch          : 405\n",
      "    loss           : -1531.6245695719788\n",
      "    ess            : 3.7774719321897243\n",
      "    log_marginal   : 1531.7652368048357\n",
      "    val_loss       : -1531.637466430664\n",
      "    val_ess        : 3.765676607688268\n",
      "    val_log_marginal: 1531.788106282552\n",
      "Train Epoch: 406 [0/54000 (0%)] Loss: -1534.510742\n",
      "Train Epoch: 406 [4096/54000 (8%)] Loss: -1532.665771\n",
      "Train Epoch: 406 [8192/54000 (15%)] Loss: -1527.595093\n",
      "Train Epoch: 406 [12288/54000 (23%)] Loss: -1530.586060\n",
      "Train Epoch: 406 [16384/54000 (30%)] Loss: -1534.537598\n",
      "Train Epoch: 406 [20480/54000 (38%)] Loss: -1534.974609\n",
      "Train Epoch: 406 [24576/54000 (46%)] Loss: -1535.830322\n",
      "Train Epoch: 406 [28672/54000 (53%)] Loss: -1534.614990\n",
      "Train Epoch: 406 [32768/54000 (61%)] Loss: -1529.863037\n",
      "Train Epoch: 406 [36864/54000 (68%)] Loss: -1527.784424\n",
      "Train Epoch: 406 [40960/54000 (76%)] Loss: -1528.963257\n",
      "Train Epoch: 406 [45056/54000 (83%)] Loss: -1535.815918\n",
      "Train Epoch: 406 [49152/54000 (91%)] Loss: -1532.775879\n",
      "Train Epoch: 406 [53248/54000 (99%)] Loss: -1539.158203\n",
      "    epoch          : 406\n",
      "    loss           : -1531.6367366845009\n",
      "    ess            : 3.7746903952829083\n",
      "    log_marginal   : 1531.7780767504073\n",
      "    val_loss       : -1532.213602701823\n",
      "    val_ess        : 3.7851092517375946\n",
      "    val_log_marginal: 1532.3430786132812\n",
      "Train Epoch: 407 [0/54000 (0%)] Loss: -1534.580322\n",
      "Train Epoch: 407 [4096/54000 (8%)] Loss: -1531.284546\n",
      "Train Epoch: 407 [8192/54000 (15%)] Loss: -1535.648682\n",
      "Train Epoch: 407 [12288/54000 (23%)] Loss: -1528.657959\n",
      "Train Epoch: 407 [16384/54000 (30%)] Loss: -1534.855713\n",
      "Train Epoch: 407 [20480/54000 (38%)] Loss: -1527.247314\n",
      "Train Epoch: 407 [24576/54000 (46%)] Loss: -1536.685059\n",
      "Train Epoch: 407 [28672/54000 (53%)] Loss: -1533.247925\n",
      "Train Epoch: 407 [32768/54000 (61%)] Loss: -1529.324707\n",
      "Train Epoch: 407 [36864/54000 (68%)] Loss: -1533.952515\n",
      "Train Epoch: 407 [40960/54000 (76%)] Loss: -1534.414795\n",
      "Train Epoch: 407 [45056/54000 (83%)] Loss: -1532.265625\n",
      "Train Epoch: 407 [49152/54000 (91%)] Loss: -1533.140259\n",
      "Train Epoch: 407 [53248/54000 (99%)] Loss: -1535.081055\n",
      "    epoch          : 407\n",
      "    loss           : -1531.9590404926319\n",
      "    ess            : 3.780514732921293\n",
      "    log_marginal   : 1532.0985292552207\n",
      "    val_loss       : -1530.997817993164\n",
      "    val_ess        : 3.7782556116580963\n",
      "    val_log_marginal: 1531.1367492675781\n",
      "Train Epoch: 408 [0/54000 (0%)] Loss: -1530.227173\n",
      "Train Epoch: 408 [4096/54000 (8%)] Loss: -1528.301270\n",
      "Train Epoch: 408 [8192/54000 (15%)] Loss: -1529.666992\n",
      "Train Epoch: 408 [12288/54000 (23%)] Loss: -1536.097168\n",
      "Train Epoch: 408 [16384/54000 (30%)] Loss: -1528.410889\n",
      "Train Epoch: 408 [20480/54000 (38%)] Loss: -1531.874756\n",
      "Train Epoch: 408 [24576/54000 (46%)] Loss: -1532.945801\n",
      "Train Epoch: 408 [28672/54000 (53%)] Loss: -1533.772339\n",
      "Train Epoch: 408 [32768/54000 (61%)] Loss: -1532.469727\n",
      "Train Epoch: 408 [36864/54000 (68%)] Loss: -1530.630981\n",
      "Train Epoch: 408 [40960/54000 (76%)] Loss: -1526.463867\n",
      "Train Epoch: 408 [45056/54000 (83%)] Loss: -1525.581055\n",
      "Train Epoch: 408 [49152/54000 (91%)] Loss: -1527.750000\n",
      "Train Epoch: 408 [53248/54000 (99%)] Loss: -1533.822388\n",
      "    epoch          : 408\n",
      "    loss           : -1531.689400478562\n",
      "    ess            : 3.7775980318892057\n",
      "    log_marginal   : 1531.8311611374409\n",
      "    val_loss       : -1530.4637807210286\n",
      "    val_ess        : 3.7694010635217032\n",
      "    val_log_marginal: 1530.6082509358723\n",
      "Train Epoch: 409 [0/54000 (0%)] Loss: -1534.719727\n",
      "Train Epoch: 409 [4096/54000 (8%)] Loss: -1530.901855\n",
      "Train Epoch: 409 [8192/54000 (15%)] Loss: -1531.039795\n",
      "Train Epoch: 409 [12288/54000 (23%)] Loss: -1531.578003\n",
      "Train Epoch: 409 [16384/54000 (30%)] Loss: -1536.105469\n",
      "Train Epoch: 409 [20480/54000 (38%)] Loss: -1526.799072\n",
      "Train Epoch: 409 [24576/54000 (46%)] Loss: -1541.066772\n",
      "Train Epoch: 409 [28672/54000 (53%)] Loss: -1534.203735\n",
      "Train Epoch: 409 [32768/54000 (61%)] Loss: -1533.230347\n",
      "Train Epoch: 409 [36864/54000 (68%)] Loss: -1532.322388\n",
      "Train Epoch: 409 [40960/54000 (76%)] Loss: -1530.058594\n",
      "Train Epoch: 409 [45056/54000 (83%)] Loss: -1530.282959\n",
      "Train Epoch: 409 [49152/54000 (91%)] Loss: -1529.622314\n",
      "Train Epoch: 409 [53248/54000 (99%)] Loss: -1525.965698\n",
      "    epoch          : 409\n",
      "    loss           : -1531.79553916895\n",
      "    ess            : 3.7753594000757587\n",
      "    log_marginal   : 1531.9353987707345\n",
      "    val_loss       : -1530.0193379720051\n",
      "    val_ess        : 3.7858060797055564\n",
      "    val_log_marginal: 1530.1586659749348\n",
      "Train Epoch: 410 [0/54000 (0%)] Loss: -1529.994385\n",
      "Train Epoch: 410 [4096/54000 (8%)] Loss: -1529.979736\n",
      "Train Epoch: 410 [8192/54000 (15%)] Loss: -1536.853760\n",
      "Train Epoch: 410 [12288/54000 (23%)] Loss: -1535.283936\n",
      "Train Epoch: 410 [16384/54000 (30%)] Loss: -1534.519043\n",
      "Train Epoch: 410 [20480/54000 (38%)] Loss: -1531.937134\n",
      "Train Epoch: 410 [24576/54000 (46%)] Loss: -1527.185791\n",
      "Train Epoch: 410 [28672/54000 (53%)] Loss: -1530.551147\n",
      "Train Epoch: 410 [32768/54000 (61%)] Loss: -1527.388916\n",
      "Train Epoch: 410 [36864/54000 (68%)] Loss: -1535.844727\n",
      "Train Epoch: 410 [40960/54000 (76%)] Loss: -1526.894165\n",
      "Train Epoch: 410 [45056/54000 (83%)] Loss: -1526.000244\n",
      "Train Epoch: 410 [49152/54000 (91%)] Loss: -1538.711914\n",
      "Train Epoch: 410 [53248/54000 (99%)] Loss: -1536.693848\n",
      "    epoch          : 410\n",
      "    loss           : -1532.0425255942685\n",
      "    ess            : 3.7775639922697963\n",
      "    log_marginal   : 1532.184953879406\n",
      "    val_loss       : -1530.1340789794922\n",
      "    val_ess        : 3.7640580932299295\n",
      "    val_log_marginal: 1530.2916819254558\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch410.pth ...\n",
      "Train Epoch: 411 [0/54000 (0%)] Loss: -1533.697021\n",
      "Train Epoch: 411 [4096/54000 (8%)] Loss: -1533.728271\n",
      "Train Epoch: 411 [8192/54000 (15%)] Loss: -1533.344238\n",
      "Train Epoch: 411 [12288/54000 (23%)] Loss: -1539.813721\n",
      "Train Epoch: 411 [16384/54000 (30%)] Loss: -1529.941406\n",
      "Train Epoch: 411 [20480/54000 (38%)] Loss: -1533.824341\n",
      "Train Epoch: 411 [24576/54000 (46%)] Loss: -1534.488159\n",
      "Train Epoch: 411 [28672/54000 (53%)] Loss: -1533.504883\n",
      "Train Epoch: 411 [32768/54000 (61%)] Loss: -1533.985352\n",
      "Train Epoch: 411 [36864/54000 (68%)] Loss: -1526.125488\n",
      "Train Epoch: 411 [40960/54000 (76%)] Loss: -1531.120361\n",
      "Train Epoch: 411 [45056/54000 (83%)] Loss: -1534.564453\n",
      "Train Epoch: 411 [49152/54000 (91%)] Loss: -1534.027832\n",
      "Train Epoch: 411 [53248/54000 (99%)] Loss: -1530.557983\n",
      "    epoch          : 411\n",
      "    loss           : -1532.1495384469417\n",
      "    ess            : 3.7721308509320446\n",
      "    log_marginal   : 1532.2974315480599\n",
      "    val_loss       : -1532.2638295491536\n",
      "    val_ess        : 3.7716270983219147\n",
      "    val_log_marginal: 1532.4052124023438\n",
      "Train Epoch: 412 [0/54000 (0%)] Loss: -1532.455811\n",
      "Train Epoch: 412 [4096/54000 (8%)] Loss: -1538.605225\n",
      "Train Epoch: 412 [8192/54000 (15%)] Loss: -1525.596558\n",
      "Train Epoch: 412 [12288/54000 (23%)] Loss: -1534.253174\n",
      "Train Epoch: 412 [16384/54000 (30%)] Loss: -1527.698242\n",
      "Train Epoch: 412 [20480/54000 (38%)] Loss: -1537.412476\n",
      "Train Epoch: 412 [24576/54000 (46%)] Loss: -1535.992065\n",
      "Train Epoch: 412 [28672/54000 (53%)] Loss: -1535.986450\n",
      "Train Epoch: 412 [32768/54000 (61%)] Loss: -1523.057373\n",
      "Train Epoch: 412 [36864/54000 (68%)] Loss: -1532.886230\n",
      "Train Epoch: 412 [40960/54000 (76%)] Loss: -1537.053833\n",
      "Train Epoch: 412 [45056/54000 (83%)] Loss: -1534.291504\n",
      "Train Epoch: 412 [49152/54000 (91%)] Loss: -1528.199219\n",
      "Train Epoch: 412 [53248/54000 (99%)] Loss: -1528.570312\n",
      "    epoch          : 412\n",
      "    loss           : -1532.2431432353376\n",
      "    ess            : 3.776645960965993\n",
      "    log_marginal   : 1532.3854506072275\n",
      "    val_loss       : -1532.6728210449219\n",
      "    val_ess        : 3.785010874271393\n",
      "    val_log_marginal: 1532.8062235514324\n",
      "Train Epoch: 413 [0/54000 (0%)] Loss: -1533.057617\n",
      "Train Epoch: 413 [4096/54000 (8%)] Loss: -1528.955811\n",
      "Train Epoch: 413 [8192/54000 (15%)] Loss: -1538.593262\n",
      "Train Epoch: 413 [12288/54000 (23%)] Loss: -1535.390869\n",
      "Train Epoch: 413 [16384/54000 (30%)] Loss: -1535.856445\n",
      "Train Epoch: 413 [20480/54000 (38%)] Loss: -1530.854736\n",
      "Train Epoch: 413 [24576/54000 (46%)] Loss: -1527.060303\n",
      "Train Epoch: 413 [28672/54000 (53%)] Loss: -1533.310913\n",
      "Train Epoch: 413 [32768/54000 (61%)] Loss: -1525.649170\n",
      "Train Epoch: 413 [36864/54000 (68%)] Loss: -1534.356201\n",
      "Train Epoch: 413 [40960/54000 (76%)] Loss: -1533.706909\n",
      "Train Epoch: 413 [45056/54000 (83%)] Loss: -1534.873169\n",
      "Train Epoch: 413 [49152/54000 (91%)] Loss: -1530.951416\n",
      "Train Epoch: 413 [53248/54000 (99%)] Loss: -1535.081299\n",
      "    epoch          : 413\n",
      "    loss           : -1532.3690370677207\n",
      "    ess            : 3.775317976260072\n",
      "    log_marginal   : 1532.5127172967268\n",
      "    val_loss       : -1532.901331583659\n",
      "    val_ess        : 3.775852143764496\n",
      "    val_log_marginal: 1533.0442860921223\n",
      "Train Epoch: 414 [0/54000 (0%)] Loss: -1532.602783\n",
      "Train Epoch: 414 [4096/54000 (8%)] Loss: -1530.865967\n",
      "Train Epoch: 414 [8192/54000 (15%)] Loss: -1540.224121\n",
      "Train Epoch: 414 [12288/54000 (23%)] Loss: -1530.986572\n",
      "Train Epoch: 414 [16384/54000 (30%)] Loss: -1534.187378\n",
      "Train Epoch: 414 [20480/54000 (38%)] Loss: -1532.568359\n",
      "Train Epoch: 414 [24576/54000 (46%)] Loss: -1534.320923\n",
      "Train Epoch: 414 [28672/54000 (53%)] Loss: -1534.868896\n",
      "Train Epoch: 414 [32768/54000 (61%)] Loss: -1530.015747\n",
      "Train Epoch: 414 [36864/54000 (68%)] Loss: -1526.423706\n",
      "Train Epoch: 414 [40960/54000 (76%)] Loss: -1532.166992\n",
      "Train Epoch: 414 [45056/54000 (83%)] Loss: -1526.204102\n",
      "Train Epoch: 414 [49152/54000 (91%)] Loss: -1530.076050\n",
      "Train Epoch: 414 [53248/54000 (99%)] Loss: -1531.453003\n",
      "    epoch          : 414\n",
      "    loss           : -1532.5413841500667\n",
      "    ess            : 3.7755970909697183\n",
      "    log_marginal   : 1532.6838893799986\n",
      "    val_loss       : -1532.1231384277344\n",
      "    val_ess        : 3.773206889629364\n",
      "    val_log_marginal: 1532.2652333577473\n",
      "Train Epoch: 415 [0/54000 (0%)] Loss: -1534.999634\n",
      "Train Epoch: 415 [4096/54000 (8%)] Loss: -1533.403564\n",
      "Train Epoch: 415 [8192/54000 (15%)] Loss: -1526.866943\n",
      "Train Epoch: 415 [12288/54000 (23%)] Loss: -1529.000000\n",
      "Train Epoch: 415 [16384/54000 (30%)] Loss: -1530.932861\n",
      "Train Epoch: 415 [20480/54000 (38%)] Loss: -1530.413086\n",
      "Train Epoch: 415 [24576/54000 (46%)] Loss: -1532.932495\n",
      "Train Epoch: 415 [28672/54000 (53%)] Loss: -1531.055786\n",
      "Train Epoch: 415 [32768/54000 (61%)] Loss: -1538.440674\n",
      "Train Epoch: 415 [36864/54000 (68%)] Loss: -1531.643799\n",
      "Train Epoch: 415 [40960/54000 (76%)] Loss: -1527.001831\n",
      "Train Epoch: 415 [45056/54000 (83%)] Loss: -1538.345459\n",
      "Train Epoch: 415 [49152/54000 (91%)] Loss: -1528.536133\n",
      "Train Epoch: 415 [53248/54000 (99%)] Loss: -1527.280762\n",
      "    epoch          : 415\n",
      "    loss           : -1532.5757426040432\n",
      "    ess            : 3.775126955520485\n",
      "    log_marginal   : 1532.7188766985707\n",
      "    val_loss       : -1532.7507883707683\n",
      "    val_ess        : 3.766736388206482\n",
      "    val_log_marginal: 1532.8934580485027\n",
      "Train Epoch: 416 [0/54000 (0%)] Loss: -1532.608643\n",
      "Train Epoch: 416 [4096/54000 (8%)] Loss: -1535.577393\n",
      "Train Epoch: 416 [8192/54000 (15%)] Loss: -1534.855469\n",
      "Train Epoch: 416 [12288/54000 (23%)] Loss: -1536.263428\n",
      "Train Epoch: 416 [16384/54000 (30%)] Loss: -1530.666992\n",
      "Train Epoch: 416 [20480/54000 (38%)] Loss: -1538.473633\n",
      "Train Epoch: 416 [24576/54000 (46%)] Loss: -1535.919922\n",
      "Train Epoch: 416 [28672/54000 (53%)] Loss: -1532.849365\n",
      "Train Epoch: 416 [32768/54000 (61%)] Loss: -1533.270020\n",
      "Train Epoch: 416 [36864/54000 (68%)] Loss: -1528.259399\n",
      "Train Epoch: 416 [40960/54000 (76%)] Loss: -1528.714966\n",
      "Train Epoch: 416 [45056/54000 (83%)] Loss: -1528.775391\n",
      "Train Epoch: 416 [49152/54000 (91%)] Loss: -1524.504150\n",
      "Train Epoch: 416 [53248/54000 (99%)] Loss: -1531.312256\n",
      "    epoch          : 416\n",
      "    loss           : -1532.552861652103\n",
      "    ess            : 3.770072349439865\n",
      "    log_marginal   : 1532.6999372871\n",
      "    val_loss       : -1533.1397552490234\n",
      "    val_ess        : 3.7706619997819266\n",
      "    val_log_marginal: 1533.2869822184246\n",
      "Train Epoch: 417 [0/54000 (0%)] Loss: -1539.695435\n",
      "Train Epoch: 417 [4096/54000 (8%)] Loss: -1528.703857\n",
      "Train Epoch: 417 [8192/54000 (15%)] Loss: -1537.334717\n",
      "Train Epoch: 417 [12288/54000 (23%)] Loss: -1533.336670\n",
      "Train Epoch: 417 [16384/54000 (30%)] Loss: -1527.888916\n",
      "Train Epoch: 417 [20480/54000 (38%)] Loss: -1531.547241\n",
      "Train Epoch: 417 [24576/54000 (46%)] Loss: -1538.657715\n",
      "Train Epoch: 417 [28672/54000 (53%)] Loss: -1532.251221\n",
      "Train Epoch: 417 [32768/54000 (61%)] Loss: -1540.654541\n",
      "Train Epoch: 417 [36864/54000 (68%)] Loss: -1527.674927\n",
      "Train Epoch: 417 [40960/54000 (76%)] Loss: -1539.042480\n",
      "Train Epoch: 417 [45056/54000 (83%)] Loss: -1532.587769\n",
      "Train Epoch: 417 [49152/54000 (91%)] Loss: -1537.674316\n",
      "Train Epoch: 417 [53248/54000 (99%)] Loss: -1527.535278\n",
      "    epoch          : 417\n",
      "    loss           : -1532.8011306835012\n",
      "    ess            : 3.776357758101694\n",
      "    log_marginal   : 1532.9394745306945\n",
      "    val_loss       : -1532.6524353027344\n",
      "    val_ess        : 3.773537000020345\n",
      "    val_log_marginal: 1532.7890319824219\n",
      "Train Epoch: 418 [0/54000 (0%)] Loss: -1529.645142\n",
      "Train Epoch: 418 [4096/54000 (8%)] Loss: -1541.382324\n",
      "Train Epoch: 418 [8192/54000 (15%)] Loss: -1531.203613\n",
      "Train Epoch: 418 [12288/54000 (23%)] Loss: -1536.149414\n",
      "Train Epoch: 418 [16384/54000 (30%)] Loss: -1534.774902\n",
      "Train Epoch: 418 [20480/54000 (38%)] Loss: -1536.731934\n",
      "Train Epoch: 418 [24576/54000 (46%)] Loss: -1542.824829\n",
      "Train Epoch: 418 [28672/54000 (53%)] Loss: -1530.196289\n",
      "Train Epoch: 418 [32768/54000 (61%)] Loss: -1539.051758\n",
      "Train Epoch: 418 [36864/54000 (68%)] Loss: -1529.775879\n",
      "Train Epoch: 418 [40960/54000 (76%)] Loss: -1533.011108\n",
      "Train Epoch: 418 [45056/54000 (83%)] Loss: -1531.371338\n",
      "Train Epoch: 418 [49152/54000 (91%)] Loss: -1533.447754\n",
      "Train Epoch: 418 [53248/54000 (99%)] Loss: -1531.734375\n",
      "    epoch          : 418\n",
      "    loss           : -1533.1603546865742\n",
      "    ess            : 3.7791798363364704\n",
      "    log_marginal   : 1533.299011519735\n",
      "    val_loss       : -1532.5259043375652\n",
      "    val_ess        : 3.7767615417639413\n",
      "    val_log_marginal: 1532.6679229736328\n",
      "Train Epoch: 419 [0/54000 (0%)] Loss: -1531.016846\n",
      "Train Epoch: 419 [4096/54000 (8%)] Loss: -1528.544922\n",
      "Train Epoch: 419 [8192/54000 (15%)] Loss: -1534.916870\n",
      "Train Epoch: 419 [12288/54000 (23%)] Loss: -1533.153687\n",
      "Train Epoch: 419 [16384/54000 (30%)] Loss: -1532.163818\n",
      "Train Epoch: 419 [20480/54000 (38%)] Loss: -1532.541260\n",
      "Train Epoch: 419 [24576/54000 (46%)] Loss: -1538.026611\n",
      "Train Epoch: 419 [28672/54000 (53%)] Loss: -1528.592407\n",
      "Train Epoch: 419 [32768/54000 (61%)] Loss: -1533.137207\n",
      "Train Epoch: 419 [36864/54000 (68%)] Loss: -1528.483521\n",
      "Train Epoch: 419 [40960/54000 (76%)] Loss: -1537.694702\n",
      "Train Epoch: 419 [45056/54000 (83%)] Loss: -1529.046509\n",
      "Train Epoch: 419 [49152/54000 (91%)] Loss: -1526.056641\n",
      "Train Epoch: 419 [53248/54000 (99%)] Loss: -1535.377686\n",
      "    epoch          : 419\n",
      "    loss           : -1532.851344393328\n",
      "    ess            : 3.7786560533171016\n",
      "    log_marginal   : 1532.989891305354\n",
      "    val_loss       : -1532.4232177734375\n",
      "    val_ess        : 3.7700275778770447\n",
      "    val_log_marginal: 1532.5643310546875\n",
      "Train Epoch: 420 [0/54000 (0%)] Loss: -1530.546021\n",
      "Train Epoch: 420 [4096/54000 (8%)] Loss: -1529.316406\n",
      "Train Epoch: 420 [8192/54000 (15%)] Loss: -1534.681885\n",
      "Train Epoch: 420 [12288/54000 (23%)] Loss: -1534.731323\n",
      "Train Epoch: 420 [16384/54000 (30%)] Loss: -1535.117188\n",
      "Train Epoch: 420 [20480/54000 (38%)] Loss: -1530.900635\n",
      "Train Epoch: 420 [24576/54000 (46%)] Loss: -1529.057861\n",
      "Train Epoch: 420 [28672/54000 (53%)] Loss: -1532.021729\n",
      "Train Epoch: 420 [32768/54000 (61%)] Loss: -1529.714111\n",
      "Train Epoch: 420 [36864/54000 (68%)] Loss: -1527.012939\n",
      "Train Epoch: 420 [40960/54000 (76%)] Loss: -1531.641113\n",
      "Train Epoch: 420 [45056/54000 (83%)] Loss: -1533.467041\n",
      "Train Epoch: 420 [49152/54000 (91%)] Loss: -1525.840698\n",
      "Train Epoch: 420 [53248/54000 (99%)] Loss: -1529.492920\n",
      "    epoch          : 420\n",
      "    loss           : -1532.953149298356\n",
      "    ess            : 3.7744439439185986\n",
      "    log_marginal   : 1533.0946768087233\n",
      "    val_loss       : -1532.5731201171875\n",
      "    val_ess        : 3.7760222951571145\n",
      "    val_log_marginal: 1532.7057240804036\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch420.pth ...\n",
      "Train Epoch: 421 [0/54000 (0%)] Loss: -1534.383423\n",
      "Train Epoch: 421 [4096/54000 (8%)] Loss: -1528.968994\n",
      "Train Epoch: 421 [8192/54000 (15%)] Loss: -1531.609619\n",
      "Train Epoch: 421 [12288/54000 (23%)] Loss: -1532.579834\n",
      "Train Epoch: 421 [16384/54000 (30%)] Loss: -1534.490967\n",
      "Train Epoch: 421 [20480/54000 (38%)] Loss: -1535.736816\n",
      "Train Epoch: 421 [24576/54000 (46%)] Loss: -1532.659180\n",
      "Train Epoch: 421 [28672/54000 (53%)] Loss: -1530.689697\n",
      "Train Epoch: 421 [32768/54000 (61%)] Loss: -1531.680908\n",
      "Train Epoch: 421 [36864/54000 (68%)] Loss: -1528.164307\n",
      "Train Epoch: 421 [40960/54000 (76%)] Loss: -1541.114258\n",
      "Train Epoch: 421 [45056/54000 (83%)] Loss: -1534.956055\n",
      "Train Epoch: 421 [49152/54000 (91%)] Loss: -1540.934204\n",
      "Train Epoch: 421 [53248/54000 (99%)] Loss: -1531.184082\n",
      "    epoch          : 421\n",
      "    loss           : -1533.0220791061909\n",
      "    ess            : 3.775054132768893\n",
      "    log_marginal   : 1533.1646531814647\n",
      "    val_loss       : -1532.3743947347004\n",
      "    val_ess        : 3.7721080680688224\n",
      "    val_log_marginal: 1532.5201822916667\n",
      "Train Epoch: 422 [0/54000 (0%)] Loss: -1527.750488\n",
      "Train Epoch: 422 [4096/54000 (8%)] Loss: -1536.309692\n",
      "Train Epoch: 422 [8192/54000 (15%)] Loss: -1532.930542\n",
      "Train Epoch: 422 [12288/54000 (23%)] Loss: -1535.086914\n",
      "Train Epoch: 422 [16384/54000 (30%)] Loss: -1539.408325\n",
      "Train Epoch: 422 [20480/54000 (38%)] Loss: -1536.612305\n",
      "Train Epoch: 422 [24576/54000 (46%)] Loss: -1534.139160\n",
      "Train Epoch: 422 [28672/54000 (53%)] Loss: -1533.235352\n",
      "Train Epoch: 422 [32768/54000 (61%)] Loss: -1532.929321\n",
      "Train Epoch: 422 [36864/54000 (68%)] Loss: -1533.242798\n",
      "Train Epoch: 422 [40960/54000 (76%)] Loss: -1532.191650\n",
      "Train Epoch: 422 [45056/54000 (83%)] Loss: -1532.845703\n",
      "Train Epoch: 422 [49152/54000 (91%)] Loss: -1532.296875\n",
      "Train Epoch: 422 [53248/54000 (99%)] Loss: -1526.836304\n",
      "    epoch          : 422\n",
      "    loss           : -1533.147366058205\n",
      "    ess            : 3.7732015108045243\n",
      "    log_marginal   : 1533.2889965473194\n",
      "    val_loss       : -1532.8788045247395\n",
      "    val_ess        : 3.770854959885279\n",
      "    val_log_marginal: 1533.0301513671875\n",
      "Train Epoch: 423 [0/54000 (0%)] Loss: -1531.314575\n",
      "Train Epoch: 423 [4096/54000 (8%)] Loss: -1534.404541\n",
      "Train Epoch: 423 [8192/54000 (15%)] Loss: -1531.140625\n",
      "Train Epoch: 423 [12288/54000 (23%)] Loss: -1530.869141\n",
      "Train Epoch: 423 [16384/54000 (30%)] Loss: -1530.665161\n",
      "Train Epoch: 423 [20480/54000 (38%)] Loss: -1531.959473\n",
      "Train Epoch: 423 [24576/54000 (46%)] Loss: -1533.538574\n",
      "Train Epoch: 423 [28672/54000 (53%)] Loss: -1533.816772\n",
      "Train Epoch: 423 [32768/54000 (61%)] Loss: -1532.602295\n",
      "Train Epoch: 423 [36864/54000 (68%)] Loss: -1532.080078\n",
      "Train Epoch: 423 [40960/54000 (76%)] Loss: -1533.840942\n",
      "Train Epoch: 423 [45056/54000 (83%)] Loss: -1535.940674\n",
      "Train Epoch: 423 [49152/54000 (91%)] Loss: -1534.176025\n",
      "Train Epoch: 423 [53248/54000 (99%)] Loss: -1539.026855\n",
      "    epoch          : 423\n",
      "    loss           : -1533.39697265625\n",
      "    ess            : 3.777348420066291\n",
      "    log_marginal   : 1533.5365863818129\n",
      "    val_loss       : -1534.4588521321614\n",
      "    val_ess        : 3.7808514138062796\n",
      "    val_log_marginal: 1534.5914510091145\n",
      "Train Epoch: 424 [0/54000 (0%)] Loss: -1538.046143\n",
      "Train Epoch: 424 [4096/54000 (8%)] Loss: -1535.961426\n",
      "Train Epoch: 424 [8192/54000 (15%)] Loss: -1532.985596\n",
      "Train Epoch: 424 [12288/54000 (23%)] Loss: -1535.087646\n",
      "Train Epoch: 424 [16384/54000 (30%)] Loss: -1530.422363\n",
      "Train Epoch: 424 [20480/54000 (38%)] Loss: -1530.421265\n",
      "Train Epoch: 424 [24576/54000 (46%)] Loss: -1528.146729\n",
      "Train Epoch: 424 [28672/54000 (53%)] Loss: -1528.195312\n",
      "Train Epoch: 424 [32768/54000 (61%)] Loss: -1538.794434\n",
      "Train Epoch: 424 [36864/54000 (68%)] Loss: -1534.339844\n",
      "Train Epoch: 424 [40960/54000 (76%)] Loss: -1530.889648\n",
      "Train Epoch: 424 [45056/54000 (83%)] Loss: -1537.444824\n",
      "Train Epoch: 424 [49152/54000 (91%)] Loss: -1533.455688\n",
      "Train Epoch: 424 [53248/54000 (99%)] Loss: -1535.241455\n",
      "    epoch          : 424\n",
      "    loss           : -1533.4369220462456\n",
      "    ess            : 3.774617321683332\n",
      "    log_marginal   : 1533.5810338603376\n",
      "    val_loss       : -1533.743413289388\n",
      "    val_ess        : 3.7863905330499015\n",
      "    val_log_marginal: 1533.8771464029949\n",
      "Train Epoch: 425 [0/54000 (0%)] Loss: -1532.231445\n",
      "Train Epoch: 425 [4096/54000 (8%)] Loss: -1530.376465\n",
      "Train Epoch: 425 [8192/54000 (15%)] Loss: -1526.893677\n",
      "Train Epoch: 425 [12288/54000 (23%)] Loss: -1537.365112\n",
      "Train Epoch: 425 [16384/54000 (30%)] Loss: -1531.605347\n",
      "Train Epoch: 425 [20480/54000 (38%)] Loss: -1531.135254\n",
      "Train Epoch: 425 [24576/54000 (46%)] Loss: -1531.712769\n",
      "Train Epoch: 425 [28672/54000 (53%)] Loss: -1530.820801\n",
      "Train Epoch: 425 [32768/54000 (61%)] Loss: -1525.208008\n",
      "Train Epoch: 425 [36864/54000 (68%)] Loss: -1538.383545\n",
      "Train Epoch: 425 [40960/54000 (76%)] Loss: -1534.422363\n",
      "Train Epoch: 425 [45056/54000 (83%)] Loss: -1538.416992\n",
      "Train Epoch: 425 [49152/54000 (91%)] Loss: -1532.131226\n",
      "Train Epoch: 425 [53248/54000 (99%)] Loss: -1532.527100\n",
      "    epoch          : 425\n",
      "    loss           : -1533.2982438073905\n",
      "    ess            : 3.773823851092732\n",
      "    log_marginal   : 1533.4416978302725\n",
      "    val_loss       : -1533.4181671142578\n",
      "    val_ess        : 3.787190188964208\n",
      "    val_log_marginal: 1533.5544331868489\n",
      "Train Epoch: 426 [0/54000 (0%)] Loss: -1541.950195\n",
      "Train Epoch: 426 [4096/54000 (8%)] Loss: -1531.593140\n",
      "Train Epoch: 426 [8192/54000 (15%)] Loss: -1530.744995\n",
      "Train Epoch: 426 [12288/54000 (23%)] Loss: -1532.892944\n",
      "Train Epoch: 426 [16384/54000 (30%)] Loss: -1532.178955\n",
      "Train Epoch: 426 [20480/54000 (38%)] Loss: -1535.932129\n",
      "Train Epoch: 426 [24576/54000 (46%)] Loss: -1529.729858\n",
      "Train Epoch: 426 [28672/54000 (53%)] Loss: -1524.310059\n",
      "Train Epoch: 426 [32768/54000 (61%)] Loss: -1534.391968\n",
      "Train Epoch: 426 [36864/54000 (68%)] Loss: -1533.340332\n",
      "Train Epoch: 426 [40960/54000 (76%)] Loss: -1534.481567\n",
      "Train Epoch: 426 [45056/54000 (83%)] Loss: -1534.116455\n",
      "Train Epoch: 426 [49152/54000 (91%)] Loss: -1537.412598\n",
      "Train Epoch: 426 [53248/54000 (99%)] Loss: -1535.320557\n",
      "    epoch          : 426\n",
      "    loss           : -1533.5076464612337\n",
      "    ess            : 3.775669546488902\n",
      "    log_marginal   : 1533.649898294024\n",
      "    val_loss       : -1532.1962890625\n",
      "    val_ess        : 3.7551926573117576\n",
      "    val_log_marginal: 1532.3585408528645\n",
      "Train Epoch: 427 [0/54000 (0%)] Loss: -1534.558716\n",
      "Train Epoch: 427 [4096/54000 (8%)] Loss: -1534.550415\n",
      "Train Epoch: 427 [8192/54000 (15%)] Loss: -1536.647217\n",
      "Train Epoch: 427 [12288/54000 (23%)] Loss: -1533.315918\n",
      "Train Epoch: 427 [16384/54000 (30%)] Loss: -1532.702759\n",
      "Train Epoch: 427 [20480/54000 (38%)] Loss: -1538.148438\n",
      "Train Epoch: 427 [24576/54000 (46%)] Loss: -1531.549072\n",
      "Train Epoch: 427 [28672/54000 (53%)] Loss: -1540.136230\n",
      "Train Epoch: 427 [32768/54000 (61%)] Loss: -1535.098267\n",
      "Train Epoch: 427 [36864/54000 (68%)] Loss: -1542.126953\n",
      "Train Epoch: 427 [40960/54000 (76%)] Loss: -1534.309326\n",
      "Train Epoch: 427 [45056/54000 (83%)] Loss: -1544.541260\n",
      "Train Epoch: 427 [49152/54000 (91%)] Loss: -1539.949463\n",
      "Train Epoch: 427 [53248/54000 (99%)] Loss: -1534.726074\n",
      "    epoch          : 427\n",
      "    loss           : -1533.8312629591233\n",
      "    ess            : 3.7692899252001144\n",
      "    log_marginal   : 1533.9779862679577\n",
      "    val_loss       : -1533.1988016764324\n",
      "    val_ess        : 3.776412387688955\n",
      "    val_log_marginal: 1533.3464050292969\n",
      "Train Epoch: 428 [0/54000 (0%)] Loss: -1533.231934\n",
      "Train Epoch: 428 [4096/54000 (8%)] Loss: -1538.725708\n",
      "Train Epoch: 428 [8192/54000 (15%)] Loss: -1533.109375\n",
      "Train Epoch: 428 [12288/54000 (23%)] Loss: -1535.106934\n",
      "Train Epoch: 428 [16384/54000 (30%)] Loss: -1532.840210\n",
      "Train Epoch: 428 [20480/54000 (38%)] Loss: -1539.335693\n",
      "Train Epoch: 428 [24576/54000 (46%)] Loss: -1527.718262\n",
      "Train Epoch: 428 [28672/54000 (53%)] Loss: -1533.039795\n",
      "Train Epoch: 428 [32768/54000 (61%)] Loss: -1532.723022\n",
      "Train Epoch: 428 [36864/54000 (68%)] Loss: -1528.224365\n",
      "Train Epoch: 428 [40960/54000 (76%)] Loss: -1534.419800\n",
      "Train Epoch: 428 [45056/54000 (83%)] Loss: -1533.669189\n",
      "Train Epoch: 428 [49152/54000 (91%)] Loss: -1533.683838\n",
      "Train Epoch: 428 [53248/54000 (99%)] Loss: -1531.214233\n",
      "    epoch          : 428\n",
      "    loss           : -1533.6788578847008\n",
      "    ess            : 3.778465430318462\n",
      "    log_marginal   : 1533.819951495853\n",
      "    val_loss       : -1533.452356974284\n",
      "    val_ess        : 3.783273458480835\n",
      "    val_log_marginal: 1533.5895436604817\n",
      "Train Epoch: 429 [0/54000 (0%)] Loss: -1533.135742\n",
      "Train Epoch: 429 [4096/54000 (8%)] Loss: -1535.176758\n",
      "Train Epoch: 429 [8192/54000 (15%)] Loss: -1530.624756\n",
      "Train Epoch: 429 [12288/54000 (23%)] Loss: -1534.409180\n",
      "Train Epoch: 429 [16384/54000 (30%)] Loss: -1531.715820\n",
      "Train Epoch: 429 [20480/54000 (38%)] Loss: -1536.151611\n",
      "Train Epoch: 429 [24576/54000 (46%)] Loss: -1534.829102\n",
      "Train Epoch: 429 [28672/54000 (53%)] Loss: -1537.392456\n",
      "Train Epoch: 429 [32768/54000 (61%)] Loss: -1539.578979\n",
      "Train Epoch: 429 [36864/54000 (68%)] Loss: -1532.612549\n",
      "Train Epoch: 429 [40960/54000 (76%)] Loss: -1533.440674\n",
      "Train Epoch: 429 [45056/54000 (83%)] Loss: -1522.487305\n",
      "Train Epoch: 429 [49152/54000 (91%)] Loss: -1537.789429\n",
      "Train Epoch: 429 [53248/54000 (99%)] Loss: -1532.903198\n",
      "    epoch          : 429\n",
      "    loss           : -1533.8089761598414\n",
      "    ess            : 3.7749913202077856\n",
      "    log_marginal   : 1533.9508883941794\n",
      "    val_loss       : -1533.6584014892578\n",
      "    val_ess        : 3.7754351695378623\n",
      "    val_log_marginal: 1533.7903493245442\n",
      "Train Epoch: 430 [0/54000 (0%)] Loss: -1531.940552\n",
      "Train Epoch: 430 [4096/54000 (8%)] Loss: -1535.858521\n",
      "Train Epoch: 430 [8192/54000 (15%)] Loss: -1527.002686\n",
      "Train Epoch: 430 [12288/54000 (23%)] Loss: -1531.501953\n",
      "Train Epoch: 430 [16384/54000 (30%)] Loss: -1536.529053\n",
      "Train Epoch: 430 [20480/54000 (38%)] Loss: -1535.090088\n",
      "Train Epoch: 430 [24576/54000 (46%)] Loss: -1541.187256\n",
      "Train Epoch: 430 [28672/54000 (53%)] Loss: -1535.932861\n",
      "Train Epoch: 430 [32768/54000 (61%)] Loss: -1535.462646\n",
      "Train Epoch: 430 [36864/54000 (68%)] Loss: -1532.705811\n",
      "Train Epoch: 430 [40960/54000 (76%)] Loss: -1538.665039\n",
      "Train Epoch: 430 [45056/54000 (83%)] Loss: -1531.752197\n",
      "Train Epoch: 430 [49152/54000 (91%)] Loss: -1531.599609\n",
      "Train Epoch: 430 [53248/54000 (99%)] Loss: -1536.324463\n",
      "    epoch          : 430\n",
      "    loss           : -1533.93569613633\n",
      "    ess            : 3.776369396544181\n",
      "    log_marginal   : 1534.0747602562203\n",
      "    val_loss       : -1533.1546478271484\n",
      "    val_ess        : 3.7842509746551514\n",
      "    val_log_marginal: 1533.2833048502605\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch430.pth ...\n",
      "Train Epoch: 431 [0/54000 (0%)] Loss: -1539.452393\n",
      "Train Epoch: 431 [4096/54000 (8%)] Loss: -1535.202148\n",
      "Train Epoch: 431 [8192/54000 (15%)] Loss: -1532.083984\n",
      "Train Epoch: 431 [12288/54000 (23%)] Loss: -1532.038696\n",
      "Train Epoch: 431 [16384/54000 (30%)] Loss: -1532.365479\n",
      "Train Epoch: 431 [20480/54000 (38%)] Loss: -1535.363281\n",
      "Train Epoch: 431 [24576/54000 (46%)] Loss: -1533.429932\n",
      "Train Epoch: 431 [28672/54000 (53%)] Loss: -1530.863281\n",
      "Train Epoch: 431 [32768/54000 (61%)] Loss: -1541.861816\n",
      "Train Epoch: 431 [36864/54000 (68%)] Loss: -1526.016602\n",
      "Train Epoch: 431 [40960/54000 (76%)] Loss: -1533.976807\n",
      "Train Epoch: 431 [45056/54000 (83%)] Loss: -1539.037109\n",
      "Train Epoch: 431 [49152/54000 (91%)] Loss: -1536.735352\n",
      "Train Epoch: 431 [53248/54000 (99%)] Loss: -1536.926025\n",
      "    epoch          : 431\n",
      "    loss           : -1534.1534290765699\n",
      "    ess            : 3.7723865237846192\n",
      "    log_marginal   : 1534.294984356487\n",
      "    val_loss       : -1534.4298807779949\n",
      "    val_ess        : 3.766418933868408\n",
      "    val_log_marginal: 1534.5775705973308\n",
      "Train Epoch: 432 [0/54000 (0%)] Loss: -1532.643311\n",
      "Train Epoch: 432 [4096/54000 (8%)] Loss: -1530.008301\n",
      "Train Epoch: 432 [8192/54000 (15%)] Loss: -1534.643799\n",
      "Train Epoch: 432 [12288/54000 (23%)] Loss: -1528.748779\n",
      "Train Epoch: 432 [16384/54000 (30%)] Loss: -1533.567383\n",
      "Train Epoch: 432 [20480/54000 (38%)] Loss: -1532.511475\n",
      "Train Epoch: 432 [24576/54000 (46%)] Loss: -1531.825439\n",
      "Train Epoch: 432 [28672/54000 (53%)] Loss: -1529.541260\n",
      "Train Epoch: 432 [32768/54000 (61%)] Loss: -1533.658081\n",
      "Train Epoch: 432 [36864/54000 (68%)] Loss: -1534.268799\n",
      "Train Epoch: 432 [40960/54000 (76%)] Loss: -1538.852783\n",
      "Train Epoch: 432 [45056/54000 (83%)] Loss: -1538.124512\n",
      "Train Epoch: 432 [49152/54000 (91%)] Loss: -1532.262451\n",
      "Train Epoch: 432 [53248/54000 (99%)] Loss: -1535.708740\n",
      "    epoch          : 432\n",
      "    loss           : -1534.13557267754\n",
      "    ess            : 3.777579565183811\n",
      "    log_marginal   : 1534.2723544875591\n",
      "    val_loss       : -1534.349624633789\n",
      "    val_ess        : 3.764419118563334\n",
      "    val_log_marginal: 1534.4905446370442\n",
      "Train Epoch: 433 [0/54000 (0%)] Loss: -1529.953369\n",
      "Train Epoch: 433 [4096/54000 (8%)] Loss: -1534.741943\n",
      "Train Epoch: 433 [8192/54000 (15%)] Loss: -1534.172852\n",
      "Train Epoch: 433 [12288/54000 (23%)] Loss: -1533.897949\n",
      "Train Epoch: 433 [16384/54000 (30%)] Loss: -1540.391357\n",
      "Train Epoch: 433 [20480/54000 (38%)] Loss: -1535.369385\n",
      "Train Epoch: 433 [24576/54000 (46%)] Loss: -1535.913818\n",
      "Train Epoch: 433 [28672/54000 (53%)] Loss: -1535.978516\n",
      "Train Epoch: 433 [32768/54000 (61%)] Loss: -1531.655884\n",
      "Train Epoch: 433 [36864/54000 (68%)] Loss: -1533.581299\n",
      "Train Epoch: 433 [40960/54000 (76%)] Loss: -1532.547485\n",
      "Train Epoch: 433 [45056/54000 (83%)] Loss: -1533.255981\n",
      "Train Epoch: 433 [49152/54000 (91%)] Loss: -1535.718506\n",
      "Train Epoch: 433 [53248/54000 (99%)] Loss: -1529.061523\n",
      "    epoch          : 433\n",
      "    loss           : -1534.0614823617077\n",
      "    ess            : 3.7706432003545536\n",
      "    log_marginal   : 1534.2069450486892\n",
      "    val_loss       : -1534.4418385823567\n",
      "    val_ess        : 3.7934395372867584\n",
      "    val_log_marginal: 1534.5699971516926\n",
      "Train Epoch: 434 [0/54000 (0%)] Loss: -1529.772827\n",
      "Train Epoch: 434 [4096/54000 (8%)] Loss: -1531.324951\n",
      "Train Epoch: 434 [8192/54000 (15%)] Loss: -1526.830078\n",
      "Train Epoch: 434 [12288/54000 (23%)] Loss: -1526.994385\n",
      "Train Epoch: 434 [16384/54000 (30%)] Loss: -1538.480225\n",
      "Train Epoch: 434 [20480/54000 (38%)] Loss: -1542.342773\n",
      "Train Epoch: 434 [24576/54000 (46%)] Loss: -1534.894287\n",
      "Train Epoch: 434 [28672/54000 (53%)] Loss: -1541.172852\n",
      "Train Epoch: 434 [32768/54000 (61%)] Loss: -1532.958008\n",
      "Train Epoch: 434 [36864/54000 (68%)] Loss: -1540.589355\n",
      "Train Epoch: 434 [40960/54000 (76%)] Loss: -1532.235352\n",
      "Train Epoch: 434 [45056/54000 (83%)] Loss: -1532.629639\n",
      "Train Epoch: 434 [49152/54000 (91%)] Loss: -1533.375977\n",
      "Train Epoch: 434 [53248/54000 (99%)] Loss: -1529.597778\n",
      "    epoch          : 434\n",
      "    loss           : -1534.2465461622483\n",
      "    ess            : 3.775373382025985\n",
      "    log_marginal   : 1534.3882402899142\n",
      "    val_loss       : -1533.8890380859375\n",
      "    val_ess        : 3.7687215407689414\n",
      "    val_log_marginal: 1534.036885579427\n",
      "Train Epoch: 435 [0/54000 (0%)] Loss: -1537.571045\n",
      "Train Epoch: 435 [4096/54000 (8%)] Loss: -1534.289551\n",
      "Train Epoch: 435 [8192/54000 (15%)] Loss: -1530.606689\n",
      "Train Epoch: 435 [12288/54000 (23%)] Loss: -1536.744873\n",
      "Train Epoch: 435 [16384/54000 (30%)] Loss: -1536.905884\n",
      "Train Epoch: 435 [20480/54000 (38%)] Loss: -1529.743164\n",
      "Train Epoch: 435 [24576/54000 (46%)] Loss: -1542.746582\n",
      "Train Epoch: 435 [28672/54000 (53%)] Loss: -1531.823486\n",
      "Train Epoch: 435 [32768/54000 (61%)] Loss: -1533.870483\n",
      "Train Epoch: 435 [36864/54000 (68%)] Loss: -1532.830688\n",
      "Train Epoch: 435 [40960/54000 (76%)] Loss: -1530.448242\n",
      "Train Epoch: 435 [45056/54000 (83%)] Loss: -1531.174072\n",
      "Train Epoch: 435 [49152/54000 (91%)] Loss: -1531.352539\n",
      "Train Epoch: 435 [53248/54000 (99%)] Loss: -1528.919189\n",
      "    epoch          : 435\n",
      "    loss           : -1534.2062936213345\n",
      "    ess            : 3.778644527869202\n",
      "    log_marginal   : 1534.3462608301245\n",
      "    val_loss       : -1534.0974375406902\n",
      "    val_ess        : 3.759910970926285\n",
      "    val_log_marginal: 1534.2630411783855\n",
      "Train Epoch: 436 [0/54000 (0%)] Loss: -1540.773926\n",
      "Train Epoch: 436 [4096/54000 (8%)] Loss: -1534.440674\n",
      "Train Epoch: 436 [8192/54000 (15%)] Loss: -1537.955933\n",
      "Train Epoch: 436 [12288/54000 (23%)] Loss: -1528.363525\n",
      "Train Epoch: 436 [16384/54000 (30%)] Loss: -1536.008789\n",
      "Train Epoch: 436 [20480/54000 (38%)] Loss: -1532.399170\n",
      "Train Epoch: 436 [24576/54000 (46%)] Loss: -1529.788574\n",
      "Train Epoch: 436 [28672/54000 (53%)] Loss: -1538.837158\n",
      "Train Epoch: 436 [32768/54000 (61%)] Loss: -1525.816650\n",
      "Train Epoch: 436 [36864/54000 (68%)] Loss: -1529.527832\n",
      "Train Epoch: 436 [40960/54000 (76%)] Loss: -1541.277222\n",
      "Train Epoch: 436 [45056/54000 (83%)] Loss: -1533.912109\n",
      "Train Epoch: 436 [49152/54000 (91%)] Loss: -1531.928101\n",
      "Train Epoch: 436 [53248/54000 (99%)] Loss: -1538.716187\n",
      "    epoch          : 436\n",
      "    loss           : -1534.2970427743633\n",
      "    ess            : 3.777721087514507\n",
      "    log_marginal   : 1534.4335017633664\n",
      "    val_loss       : -1534.4354705810547\n",
      "    val_ess        : 3.77241188287735\n",
      "    val_log_marginal: 1534.5870412190754\n",
      "Train Epoch: 437 [0/54000 (0%)] Loss: -1532.281738\n",
      "Train Epoch: 437 [4096/54000 (8%)] Loss: -1536.499634\n",
      "Train Epoch: 437 [8192/54000 (15%)] Loss: -1532.905273\n",
      "Train Epoch: 437 [12288/54000 (23%)] Loss: -1533.876221\n",
      "Train Epoch: 437 [16384/54000 (30%)] Loss: -1530.821533\n",
      "Train Epoch: 437 [20480/54000 (38%)] Loss: -1531.861328\n",
      "Train Epoch: 437 [24576/54000 (46%)] Loss: -1536.446533\n",
      "Train Epoch: 437 [28672/54000 (53%)] Loss: -1536.549927\n",
      "Train Epoch: 437 [32768/54000 (61%)] Loss: -1530.247070\n",
      "Train Epoch: 437 [36864/54000 (68%)] Loss: -1538.997803\n",
      "Train Epoch: 437 [40960/54000 (76%)] Loss: -1541.404785\n",
      "Train Epoch: 437 [45056/54000 (83%)] Loss: -1540.027588\n",
      "Train Epoch: 437 [49152/54000 (91%)] Loss: -1534.316528\n",
      "Train Epoch: 437 [53248/54000 (99%)] Loss: -1531.267822\n",
      "    epoch          : 437\n",
      "    loss           : -1534.2989426743927\n",
      "    ess            : 3.777039682695651\n",
      "    log_marginal   : 1534.4398089223564\n",
      "    val_loss       : -1533.084467569987\n",
      "    val_ess        : 3.7771516541639962\n",
      "    val_log_marginal: 1533.2298024495442\n",
      "Train Epoch: 438 [0/54000 (0%)] Loss: -1527.307373\n",
      "Train Epoch: 438 [4096/54000 (8%)] Loss: -1537.400879\n",
      "Train Epoch: 438 [8192/54000 (15%)] Loss: -1531.853760\n",
      "Train Epoch: 438 [12288/54000 (23%)] Loss: -1534.654053\n",
      "Train Epoch: 438 [16384/54000 (30%)] Loss: -1535.953125\n",
      "Train Epoch: 438 [20480/54000 (38%)] Loss: -1537.661377\n",
      "Train Epoch: 438 [24576/54000 (46%)] Loss: -1534.908447\n",
      "Train Epoch: 438 [28672/54000 (53%)] Loss: -1533.257568\n",
      "Train Epoch: 438 [32768/54000 (61%)] Loss: -1532.953613\n",
      "Train Epoch: 438 [36864/54000 (68%)] Loss: -1525.957520\n",
      "Train Epoch: 438 [40960/54000 (76%)] Loss: -1535.257324\n",
      "Train Epoch: 438 [45056/54000 (83%)] Loss: -1532.306885\n",
      "Train Epoch: 438 [49152/54000 (91%)] Loss: -1535.637695\n",
      "Train Epoch: 438 [53248/54000 (99%)] Loss: -1534.813599\n",
      "    epoch          : 438\n",
      "    loss           : -1534.3576503952534\n",
      "    ess            : 3.7783084819667145\n",
      "    log_marginal   : 1534.5001504183945\n",
      "    val_loss       : -1534.9227294921875\n",
      "    val_ess        : 3.7733624974886575\n",
      "    val_log_marginal: 1535.078872680664\n",
      "Train Epoch: 439 [0/54000 (0%)] Loss: -1538.883179\n",
      "Train Epoch: 439 [4096/54000 (8%)] Loss: -1537.774414\n",
      "Train Epoch: 439 [8192/54000 (15%)] Loss: -1530.741211\n",
      "Train Epoch: 439 [12288/54000 (23%)] Loss: -1541.901123\n",
      "Train Epoch: 439 [16384/54000 (30%)] Loss: -1530.775879\n",
      "Train Epoch: 439 [20480/54000 (38%)] Loss: -1543.143188\n",
      "Train Epoch: 439 [24576/54000 (46%)] Loss: -1535.566284\n",
      "Train Epoch: 439 [28672/54000 (53%)] Loss: -1533.138184\n",
      "Train Epoch: 439 [32768/54000 (61%)] Loss: -1536.303101\n",
      "Train Epoch: 439 [36864/54000 (68%)] Loss: -1537.859131\n",
      "Train Epoch: 439 [40960/54000 (76%)] Loss: -1541.441284\n",
      "Train Epoch: 439 [45056/54000 (83%)] Loss: -1532.335205\n",
      "Train Epoch: 439 [49152/54000 (91%)] Loss: -1535.283936\n",
      "Train Epoch: 439 [53248/54000 (99%)] Loss: -1531.314697\n",
      "    epoch          : 439\n",
      "    loss           : -1534.563872278584\n",
      "    ess            : 3.774663867543659\n",
      "    log_marginal   : 1534.7075895336568\n",
      "    val_loss       : -1533.966272989909\n",
      "    val_ess        : 3.7649953961372375\n",
      "    val_log_marginal: 1534.117696126302\n",
      "Train Epoch: 440 [0/54000 (0%)] Loss: -1531.062744\n",
      "Train Epoch: 440 [4096/54000 (8%)] Loss: -1540.277588\n",
      "Train Epoch: 440 [8192/54000 (15%)] Loss: -1530.757568\n",
      "Train Epoch: 440 [12288/54000 (23%)] Loss: -1536.744995\n",
      "Train Epoch: 440 [16384/54000 (30%)] Loss: -1531.582764\n",
      "Train Epoch: 440 [20480/54000 (38%)] Loss: -1530.611206\n",
      "Train Epoch: 440 [24576/54000 (46%)] Loss: -1535.209961\n",
      "Train Epoch: 440 [28672/54000 (53%)] Loss: -1533.357422\n",
      "Train Epoch: 440 [32768/54000 (61%)] Loss: -1535.627930\n",
      "Train Epoch: 440 [36864/54000 (68%)] Loss: -1537.842773\n",
      "Train Epoch: 440 [40960/54000 (76%)] Loss: -1532.756958\n",
      "Train Epoch: 440 [45056/54000 (83%)] Loss: -1534.306885\n",
      "Train Epoch: 440 [49152/54000 (91%)] Loss: -1531.156006\n",
      "Train Epoch: 440 [53248/54000 (99%)] Loss: -1528.788086\n",
      "    epoch          : 440\n",
      "    loss           : -1534.6377774640848\n",
      "    ess            : 3.777696101021428\n",
      "    log_marginal   : 1534.7745783656694\n",
      "    val_loss       : -1535.4277903238933\n",
      "    val_ess        : 3.782705227533976\n",
      "    val_log_marginal: 1535.5662485758464\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch440.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 441 [0/54000 (0%)] Loss: -1531.847656\n",
      "Train Epoch: 441 [4096/54000 (8%)] Loss: -1542.026367\n",
      "Train Epoch: 441 [8192/54000 (15%)] Loss: -1534.495728\n",
      "Train Epoch: 441 [12288/54000 (23%)] Loss: -1533.066162\n",
      "Train Epoch: 441 [16384/54000 (30%)] Loss: -1529.626221\n",
      "Train Epoch: 441 [20480/54000 (38%)] Loss: -1530.318115\n",
      "Train Epoch: 441 [24576/54000 (46%)] Loss: -1541.127075\n",
      "Train Epoch: 441 [28672/54000 (53%)] Loss: -1544.729736\n",
      "Train Epoch: 441 [32768/54000 (61%)] Loss: -1534.909180\n",
      "Train Epoch: 441 [36864/54000 (68%)] Loss: -1538.335327\n",
      "Train Epoch: 441 [40960/54000 (76%)] Loss: -1532.856812\n",
      "Train Epoch: 441 [45056/54000 (83%)] Loss: -1540.544678\n",
      "Train Epoch: 441 [49152/54000 (91%)] Loss: -1541.570801\n",
      "Train Epoch: 441 [53248/54000 (99%)] Loss: -1535.755615\n",
      "    epoch          : 441\n",
      "    loss           : -1534.8514039821534\n",
      "    ess            : 3.7788163191899304\n",
      "    log_marginal   : 1534.9887515967491\n",
      "    val_loss       : -1534.5086059570312\n",
      "    val_ess        : 3.778886208931605\n",
      "    val_log_marginal: 1534.649134318034\n",
      "Train Epoch: 442 [0/54000 (0%)] Loss: -1541.032227\n",
      "Train Epoch: 442 [4096/54000 (8%)] Loss: -1538.296631\n",
      "Train Epoch: 442 [8192/54000 (15%)] Loss: -1541.863281\n",
      "Train Epoch: 442 [12288/54000 (23%)] Loss: -1530.616455\n",
      "Train Epoch: 442 [16384/54000 (30%)] Loss: -1534.123047\n",
      "Train Epoch: 442 [20480/54000 (38%)] Loss: -1526.509766\n",
      "Train Epoch: 442 [24576/54000 (46%)] Loss: -1533.761841\n",
      "Train Epoch: 442 [28672/54000 (53%)] Loss: -1534.313477\n",
      "Train Epoch: 442 [32768/54000 (61%)] Loss: -1538.150757\n",
      "Train Epoch: 442 [36864/54000 (68%)] Loss: -1537.924316\n",
      "Train Epoch: 442 [40960/54000 (76%)] Loss: -1536.894775\n",
      "Train Epoch: 442 [45056/54000 (83%)] Loss: -1535.842773\n",
      "Train Epoch: 442 [49152/54000 (91%)] Loss: -1529.017334\n",
      "Train Epoch: 442 [53248/54000 (99%)] Loss: -1539.248901\n",
      "    epoch          : 442\n",
      "    loss           : -1534.8083519235042\n",
      "    ess            : 3.7799393418840888\n",
      "    log_marginal   : 1534.9468571812056\n",
      "    val_loss       : -1534.4436696370442\n",
      "    val_ess        : 3.7766604125499725\n",
      "    val_log_marginal: 1534.5847727457683\n",
      "Train Epoch: 443 [0/54000 (0%)] Loss: -1533.698242\n",
      "Train Epoch: 443 [4096/54000 (8%)] Loss: -1538.334595\n",
      "Train Epoch: 443 [8192/54000 (15%)] Loss: -1540.237305\n",
      "Train Epoch: 443 [12288/54000 (23%)] Loss: -1537.710449\n",
      "Train Epoch: 443 [16384/54000 (30%)] Loss: -1538.228760\n",
      "Train Epoch: 443 [20480/54000 (38%)] Loss: -1538.547119\n",
      "Train Epoch: 443 [24576/54000 (46%)] Loss: -1535.051758\n",
      "Train Epoch: 443 [28672/54000 (53%)] Loss: -1537.356934\n",
      "Train Epoch: 443 [32768/54000 (61%)] Loss: -1536.233521\n",
      "Train Epoch: 443 [36864/54000 (68%)] Loss: -1538.855103\n",
      "Train Epoch: 443 [40960/54000 (76%)] Loss: -1539.911133\n",
      "Train Epoch: 443 [45056/54000 (83%)] Loss: -1536.581909\n",
      "Train Epoch: 443 [49152/54000 (91%)] Loss: -1533.551392\n",
      "Train Epoch: 443 [53248/54000 (99%)] Loss: -1525.219238\n",
      "    epoch          : 443\n",
      "    loss           : -1534.8404055048504\n",
      "    ess            : 3.7816379736950045\n",
      "    log_marginal   : 1534.974714089344\n",
      "    val_loss       : -1534.8566233317058\n",
      "    val_ess        : 3.776788224776586\n",
      "    val_log_marginal: 1534.989293416341\n",
      "Train Epoch: 444 [0/54000 (0%)] Loss: -1536.645508\n",
      "Train Epoch: 444 [4096/54000 (8%)] Loss: -1535.537598\n",
      "Train Epoch: 444 [8192/54000 (15%)] Loss: -1532.662964\n",
      "Train Epoch: 444 [12288/54000 (23%)] Loss: -1536.982056\n",
      "Train Epoch: 444 [16384/54000 (30%)] Loss: -1540.100342\n",
      "Train Epoch: 444 [20480/54000 (38%)] Loss: -1534.341187\n",
      "Train Epoch: 444 [24576/54000 (46%)] Loss: -1536.246582\n",
      "Train Epoch: 444 [28672/54000 (53%)] Loss: -1533.155396\n",
      "Train Epoch: 444 [32768/54000 (61%)] Loss: -1527.477539\n",
      "Train Epoch: 444 [36864/54000 (68%)] Loss: -1535.302979\n",
      "Train Epoch: 444 [40960/54000 (76%)] Loss: -1533.184570\n",
      "Train Epoch: 444 [45056/54000 (83%)] Loss: -1535.421631\n",
      "Train Epoch: 444 [49152/54000 (91%)] Loss: -1534.171875\n",
      "Train Epoch: 444 [53248/54000 (99%)] Loss: -1539.816406\n",
      "    epoch          : 444\n",
      "    loss           : -1534.7466583975117\n",
      "    ess            : 3.772748059006099\n",
      "    log_marginal   : 1534.8925787035323\n",
      "    val_loss       : -1534.7998758951824\n",
      "    val_ess        : 3.777318924665451\n",
      "    val_log_marginal: 1534.9346008300781\n",
      "Train Epoch: 445 [0/54000 (0%)] Loss: -1538.090454\n",
      "Train Epoch: 445 [4096/54000 (8%)] Loss: -1532.753540\n",
      "Train Epoch: 445 [8192/54000 (15%)] Loss: -1529.460449\n",
      "Train Epoch: 445 [12288/54000 (23%)] Loss: -1531.170776\n",
      "Train Epoch: 445 [16384/54000 (30%)] Loss: -1530.597656\n",
      "Train Epoch: 445 [20480/54000 (38%)] Loss: -1541.284546\n",
      "Train Epoch: 445 [24576/54000 (46%)] Loss: -1539.882324\n",
      "Train Epoch: 445 [28672/54000 (53%)] Loss: -1530.301025\n",
      "Train Epoch: 445 [32768/54000 (61%)] Loss: -1535.425293\n",
      "Train Epoch: 445 [36864/54000 (68%)] Loss: -1535.080566\n",
      "Train Epoch: 445 [40960/54000 (76%)] Loss: -1532.204834\n",
      "Train Epoch: 445 [45056/54000 (83%)] Loss: -1528.402832\n",
      "Train Epoch: 445 [49152/54000 (91%)] Loss: -1529.973633\n",
      "Train Epoch: 445 [53248/54000 (99%)] Loss: -1536.274170\n",
      "    epoch          : 445\n",
      "    loss           : -1535.25261091621\n",
      "    ess            : 3.7770799200681715\n",
      "    log_marginal   : 1535.3933967481858\n",
      "    val_loss       : -1535.2298177083333\n",
      "    val_ess        : 3.7699636816978455\n",
      "    val_log_marginal: 1535.3702494303386\n",
      "Train Epoch: 446 [0/54000 (0%)] Loss: -1535.062012\n",
      "Train Epoch: 446 [4096/54000 (8%)] Loss: -1534.338745\n",
      "Train Epoch: 446 [8192/54000 (15%)] Loss: -1531.598633\n",
      "Train Epoch: 446 [12288/54000 (23%)] Loss: -1538.705078\n",
      "Train Epoch: 446 [16384/54000 (30%)] Loss: -1535.000244\n",
      "Train Epoch: 446 [20480/54000 (38%)] Loss: -1526.908325\n",
      "Train Epoch: 446 [24576/54000 (46%)] Loss: -1534.992432\n",
      "Train Epoch: 446 [28672/54000 (53%)] Loss: -1537.935547\n",
      "Train Epoch: 446 [32768/54000 (61%)] Loss: -1537.512207\n",
      "Train Epoch: 446 [36864/54000 (68%)] Loss: -1530.241211\n",
      "Train Epoch: 446 [40960/54000 (76%)] Loss: -1534.426270\n",
      "Train Epoch: 446 [45056/54000 (83%)] Loss: -1533.819214\n",
      "Train Epoch: 446 [49152/54000 (91%)] Loss: -1537.126221\n",
      "Train Epoch: 446 [53248/54000 (99%)] Loss: -1534.677002\n",
      "    epoch          : 446\n",
      "    loss           : -1535.172230218824\n",
      "    ess            : 3.7796962871370723\n",
      "    log_marginal   : 1535.3124566100785\n",
      "    val_loss       : -1534.5849507649739\n",
      "    val_ess        : 3.7745942572752633\n",
      "    val_log_marginal: 1534.731709798177\n",
      "Train Epoch: 447 [0/54000 (0%)] Loss: -1532.729492\n",
      "Train Epoch: 447 [4096/54000 (8%)] Loss: -1532.882812\n",
      "Train Epoch: 447 [8192/54000 (15%)] Loss: -1536.186157\n",
      "Train Epoch: 447 [12288/54000 (23%)] Loss: -1534.898926\n",
      "Train Epoch: 447 [16384/54000 (30%)] Loss: -1537.781250\n",
      "Train Epoch: 447 [20480/54000 (38%)] Loss: -1528.649902\n",
      "Train Epoch: 447 [24576/54000 (46%)] Loss: -1528.920898\n",
      "Train Epoch: 447 [28672/54000 (53%)] Loss: -1531.863037\n",
      "Train Epoch: 447 [32768/54000 (61%)] Loss: -1534.651367\n",
      "Train Epoch: 447 [36864/54000 (68%)] Loss: -1540.769287\n",
      "Train Epoch: 447 [40960/54000 (76%)] Loss: -1533.370850\n",
      "Train Epoch: 447 [45056/54000 (83%)] Loss: -1536.918457\n",
      "Train Epoch: 447 [49152/54000 (91%)] Loss: -1537.408447\n",
      "Train Epoch: 447 [53248/54000 (99%)] Loss: -1533.400635\n",
      "    epoch          : 447\n",
      "    loss           : -1535.1013108384552\n",
      "    ess            : 3.7703467748741404\n",
      "    log_marginal   : 1535.2480214195793\n",
      "    val_loss       : -1534.3385264078777\n",
      "    val_ess        : 3.765510926644007\n",
      "    val_log_marginal: 1534.4906565348308\n",
      "Train Epoch: 448 [0/54000 (0%)] Loss: -1536.050781\n",
      "Train Epoch: 448 [4096/54000 (8%)] Loss: -1533.620361\n",
      "Train Epoch: 448 [8192/54000 (15%)] Loss: -1531.838013\n",
      "Train Epoch: 448 [12288/54000 (23%)] Loss: -1532.078613\n",
      "Train Epoch: 448 [16384/54000 (30%)] Loss: -1535.451294\n",
      "Train Epoch: 448 [20480/54000 (38%)] Loss: -1531.757935\n",
      "Train Epoch: 448 [24576/54000 (46%)] Loss: -1533.759521\n",
      "Train Epoch: 448 [28672/54000 (53%)] Loss: -1526.873047\n",
      "Train Epoch: 448 [32768/54000 (61%)] Loss: -1535.593628\n",
      "Train Epoch: 448 [36864/54000 (68%)] Loss: -1537.177490\n",
      "Train Epoch: 448 [40960/54000 (76%)] Loss: -1539.819824\n",
      "Train Epoch: 448 [45056/54000 (83%)] Loss: -1537.840576\n",
      "Train Epoch: 448 [49152/54000 (91%)] Loss: -1536.237549\n",
      "Train Epoch: 448 [53248/54000 (99%)] Loss: -1532.817383\n",
      "    epoch          : 448\n",
      "    loss           : -1535.2236958725193\n",
      "    ess            : 3.7761299361549847\n",
      "    log_marginal   : 1535.3653275186982\n",
      "    val_loss       : -1535.0154978434246\n",
      "    val_ess        : 3.7877889573574066\n",
      "    val_log_marginal: 1535.143290201823\n",
      "Train Epoch: 449 [0/54000 (0%)] Loss: -1541.123657\n",
      "Train Epoch: 449 [4096/54000 (8%)] Loss: -1531.318726\n",
      "Train Epoch: 449 [8192/54000 (15%)] Loss: -1537.998413\n",
      "Train Epoch: 449 [12288/54000 (23%)] Loss: -1539.453979\n",
      "Train Epoch: 449 [16384/54000 (30%)] Loss: -1532.143555\n",
      "Train Epoch: 449 [20480/54000 (38%)] Loss: -1536.297119\n",
      "Train Epoch: 449 [24576/54000 (46%)] Loss: -1540.027466\n",
      "Train Epoch: 449 [28672/54000 (53%)] Loss: -1543.777344\n",
      "Train Epoch: 449 [32768/54000 (61%)] Loss: -1540.982788\n",
      "Train Epoch: 449 [36864/54000 (68%)] Loss: -1533.403687\n",
      "Train Epoch: 449 [40960/54000 (76%)] Loss: -1533.102905\n",
      "Train Epoch: 449 [45056/54000 (83%)] Loss: -1541.385376\n",
      "Train Epoch: 449 [49152/54000 (91%)] Loss: -1539.365845\n",
      "Train Epoch: 449 [53248/54000 (99%)] Loss: -1527.768555\n",
      "    epoch          : 449\n",
      "    loss           : -1535.2332023150548\n",
      "    ess            : 3.7757774902181036\n",
      "    log_marginal   : 1535.3768773372703\n",
      "    val_loss       : -1536.081049601237\n",
      "    val_ess        : 3.7909510831038156\n",
      "    val_log_marginal: 1536.2012837727864\n",
      "Train Epoch: 450 [0/54000 (0%)] Loss: -1530.067505\n",
      "Train Epoch: 450 [4096/54000 (8%)] Loss: -1530.843750\n",
      "Train Epoch: 450 [8192/54000 (15%)] Loss: -1534.746460\n",
      "Train Epoch: 450 [12288/54000 (23%)] Loss: -1538.022949\n",
      "Train Epoch: 450 [16384/54000 (30%)] Loss: -1533.404297\n",
      "Train Epoch: 450 [20480/54000 (38%)] Loss: -1533.127441\n",
      "Train Epoch: 450 [24576/54000 (46%)] Loss: -1538.857910\n",
      "Train Epoch: 450 [28672/54000 (53%)] Loss: -1533.863525\n",
      "Train Epoch: 450 [32768/54000 (61%)] Loss: -1537.264648\n",
      "Train Epoch: 450 [36864/54000 (68%)] Loss: -1535.541016\n",
      "Train Epoch: 450 [40960/54000 (76%)] Loss: -1537.507202\n",
      "Train Epoch: 450 [45056/54000 (83%)] Loss: -1538.024170\n",
      "Train Epoch: 450 [49152/54000 (91%)] Loss: -1531.271240\n",
      "Train Epoch: 450 [53248/54000 (99%)] Loss: -1537.628174\n",
      "    epoch          : 450\n",
      "    loss           : -1535.4533303789617\n",
      "    ess            : 3.780576163558598\n",
      "    log_marginal   : 1535.5931431196311\n",
      "    val_loss       : -1535.4251708984375\n",
      "    val_ess        : 3.7657573521137238\n",
      "    val_log_marginal: 1535.5607299804688\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [0/54000 (0%)] Loss: -1533.233154\n",
      "Train Epoch: 451 [4096/54000 (8%)] Loss: -1541.217407\n",
      "Train Epoch: 451 [8192/54000 (15%)] Loss: -1532.411377\n",
      "Train Epoch: 451 [12288/54000 (23%)] Loss: -1533.310059\n",
      "Train Epoch: 451 [16384/54000 (30%)] Loss: -1532.149170\n",
      "Train Epoch: 451 [20480/54000 (38%)] Loss: -1531.287598\n",
      "Train Epoch: 451 [24576/54000 (46%)] Loss: -1537.833984\n",
      "Train Epoch: 451 [28672/54000 (53%)] Loss: -1536.170654\n",
      "Train Epoch: 451 [32768/54000 (61%)] Loss: -1535.054443\n",
      "Train Epoch: 451 [36864/54000 (68%)] Loss: -1543.979736\n",
      "Train Epoch: 451 [40960/54000 (76%)] Loss: -1529.474731\n",
      "Train Epoch: 451 [45056/54000 (83%)] Loss: -1534.960938\n",
      "Train Epoch: 451 [49152/54000 (91%)] Loss: -1533.938232\n",
      "Train Epoch: 451 [53248/54000 (99%)] Loss: -1540.398926\n",
      "    epoch          : 451\n",
      "    loss           : -1535.2144347276733\n",
      "    ess            : 3.7818769934053105\n",
      "    log_marginal   : 1535.3467612605525\n",
      "    val_loss       : -1536.5809478759766\n",
      "    val_ess        : 3.785728911558787\n",
      "    val_log_marginal: 1536.7156066894531\n",
      "Train Epoch: 452 [0/54000 (0%)] Loss: -1538.648682\n",
      "Train Epoch: 452 [4096/54000 (8%)] Loss: -1539.260498\n",
      "Train Epoch: 452 [8192/54000 (15%)] Loss: -1537.974731\n",
      "Train Epoch: 452 [12288/54000 (23%)] Loss: -1535.767700\n",
      "Train Epoch: 452 [16384/54000 (30%)] Loss: -1534.950684\n",
      "Train Epoch: 452 [20480/54000 (38%)] Loss: -1540.686768\n",
      "Train Epoch: 452 [24576/54000 (46%)] Loss: -1534.696045\n",
      "Train Epoch: 452 [28672/54000 (53%)] Loss: -1535.427490\n",
      "Train Epoch: 452 [32768/54000 (61%)] Loss: -1533.524658\n",
      "Train Epoch: 452 [36864/54000 (68%)] Loss: -1537.286621\n",
      "Train Epoch: 452 [40960/54000 (76%)] Loss: -1531.566528\n",
      "Train Epoch: 452 [45056/54000 (83%)] Loss: -1532.075806\n",
      "Train Epoch: 452 [49152/54000 (91%)] Loss: -1532.072632\n",
      "Train Epoch: 452 [53248/54000 (99%)] Loss: -1532.855713\n",
      "    epoch          : 452\n",
      "    loss           : -1535.4151246852784\n",
      "    ess            : 3.778050157131177\n",
      "    log_marginal   : 1535.554522039766\n",
      "    val_loss       : -1535.5435689290364\n",
      "    val_ess        : 3.766337603330612\n",
      "    val_log_marginal: 1535.6937917073567\n",
      "Train Epoch: 453 [0/54000 (0%)] Loss: -1533.462036\n",
      "Train Epoch: 453 [4096/54000 (8%)] Loss: -1539.847412\n",
      "Train Epoch: 453 [8192/54000 (15%)] Loss: -1536.304810\n",
      "Train Epoch: 453 [12288/54000 (23%)] Loss: -1537.839844\n",
      "Train Epoch: 453 [16384/54000 (30%)] Loss: -1534.982300\n",
      "Train Epoch: 453 [20480/54000 (38%)] Loss: -1536.526611\n",
      "Train Epoch: 453 [24576/54000 (46%)] Loss: -1530.325439\n",
      "Train Epoch: 453 [28672/54000 (53%)] Loss: -1538.301147\n",
      "Train Epoch: 453 [32768/54000 (61%)] Loss: -1535.710083\n",
      "Train Epoch: 453 [36864/54000 (68%)] Loss: -1536.312256\n",
      "Train Epoch: 453 [40960/54000 (76%)] Loss: -1535.113525\n",
      "Train Epoch: 453 [45056/54000 (83%)] Loss: -1528.419922\n",
      "Train Epoch: 453 [49152/54000 (91%)] Loss: -1542.431763\n",
      "Train Epoch: 453 [53248/54000 (99%)] Loss: -1542.798828\n",
      "    epoch          : 453\n",
      "    loss           : -1535.4977535591306\n",
      "    ess            : 3.779775679393967\n",
      "    log_marginal   : 1535.6357757423727\n",
      "    val_loss       : -1534.3763682047527\n",
      "    val_ess        : 3.774249404668808\n",
      "    val_log_marginal: 1534.519271850586\n",
      "Train Epoch: 454 [0/54000 (0%)] Loss: -1537.613525\n",
      "Train Epoch: 454 [4096/54000 (8%)] Loss: -1539.322998\n",
      "Train Epoch: 454 [8192/54000 (15%)] Loss: -1535.200439\n",
      "Train Epoch: 454 [12288/54000 (23%)] Loss: -1529.878174\n",
      "Train Epoch: 454 [16384/54000 (30%)] Loss: -1537.469116\n",
      "Train Epoch: 454 [20480/54000 (38%)] Loss: -1536.543945\n",
      "Train Epoch: 454 [24576/54000 (46%)] Loss: -1541.773804\n",
      "Train Epoch: 454 [28672/54000 (53%)] Loss: -1536.965698\n",
      "Train Epoch: 454 [32768/54000 (61%)] Loss: -1530.917480\n",
      "Train Epoch: 454 [36864/54000 (68%)] Loss: -1536.365356\n",
      "Train Epoch: 454 [40960/54000 (76%)] Loss: -1533.009277\n",
      "Train Epoch: 454 [45056/54000 (83%)] Loss: -1539.873779\n",
      "Train Epoch: 454 [49152/54000 (91%)] Loss: -1540.169434\n",
      "Train Epoch: 454 [53248/54000 (99%)] Loss: -1532.779541\n",
      "    epoch          : 454\n",
      "    loss           : -1535.6785477913952\n",
      "    ess            : 3.775102246994091\n",
      "    log_marginal   : 1535.8224686898327\n",
      "    val_loss       : -1535.6095581054688\n",
      "    val_ess        : 3.7767774959405265\n",
      "    val_log_marginal: 1535.7488403320312\n",
      "Train Epoch: 455 [0/54000 (0%)] Loss: -1536.821289\n",
      "Train Epoch: 455 [4096/54000 (8%)] Loss: -1527.716064\n",
      "Train Epoch: 455 [8192/54000 (15%)] Loss: -1533.356934\n",
      "Train Epoch: 455 [12288/54000 (23%)] Loss: -1540.371338\n",
      "Train Epoch: 455 [16384/54000 (30%)] Loss: -1534.485596\n",
      "Train Epoch: 455 [20480/54000 (38%)] Loss: -1537.712524\n",
      "Train Epoch: 455 [24576/54000 (46%)] Loss: -1532.858643\n",
      "Train Epoch: 455 [28672/54000 (53%)] Loss: -1532.829834\n",
      "Train Epoch: 455 [32768/54000 (61%)] Loss: -1538.560547\n",
      "Train Epoch: 455 [36864/54000 (68%)] Loss: -1540.471680\n",
      "Train Epoch: 455 [40960/54000 (76%)] Loss: -1530.725342\n",
      "Train Epoch: 455 [45056/54000 (83%)] Loss: -1530.453735\n",
      "Train Epoch: 455 [49152/54000 (91%)] Loss: -1530.087158\n",
      "Train Epoch: 455 [53248/54000 (99%)] Loss: -1541.367676\n",
      "    epoch          : 455\n",
      "    loss           : -1535.7182906453643\n",
      "    ess            : 3.7750389564658793\n",
      "    log_marginal   : 1535.8595231042655\n",
      "    val_loss       : -1535.1598612467449\n",
      "    val_ess        : 3.7883464197317758\n",
      "    val_log_marginal: 1535.300084431966\n",
      "Train Epoch: 456 [0/54000 (0%)] Loss: -1534.274048\n",
      "Train Epoch: 456 [4096/54000 (8%)] Loss: -1531.493774\n",
      "Train Epoch: 456 [8192/54000 (15%)] Loss: -1536.966919\n",
      "Train Epoch: 456 [12288/54000 (23%)] Loss: -1535.458374\n",
      "Train Epoch: 456 [16384/54000 (30%)] Loss: -1532.737671\n",
      "Train Epoch: 456 [20480/54000 (38%)] Loss: -1537.170044\n",
      "Train Epoch: 456 [24576/54000 (46%)] Loss: -1532.703003\n",
      "Train Epoch: 456 [28672/54000 (53%)] Loss: -1533.709595\n",
      "Train Epoch: 456 [32768/54000 (61%)] Loss: -1531.366455\n",
      "Train Epoch: 456 [36864/54000 (68%)] Loss: -1532.481079\n",
      "Train Epoch: 456 [40960/54000 (76%)] Loss: -1533.573486\n",
      "Train Epoch: 456 [45056/54000 (83%)] Loss: -1535.479492\n",
      "Train Epoch: 456 [49152/54000 (91%)] Loss: -1535.106567\n",
      "Train Epoch: 456 [53248/54000 (99%)] Loss: -1535.812500\n",
      "    epoch          : 456\n",
      "    loss           : -1535.6162676336642\n",
      "    ess            : 3.7774423185682973\n",
      "    log_marginal   : 1535.7576372047172\n",
      "    val_loss       : -1535.2763214111328\n",
      "    val_ess        : 3.777180184920629\n",
      "    val_log_marginal: 1535.4195709228516\n",
      "Train Epoch: 457 [0/54000 (0%)] Loss: -1540.620850\n",
      "Train Epoch: 457 [4096/54000 (8%)] Loss: -1538.376343\n",
      "Train Epoch: 457 [8192/54000 (15%)] Loss: -1537.242432\n",
      "Train Epoch: 457 [12288/54000 (23%)] Loss: -1539.642334\n",
      "Train Epoch: 457 [16384/54000 (30%)] Loss: -1544.050537\n",
      "Train Epoch: 457 [20480/54000 (38%)] Loss: -1538.907715\n",
      "Train Epoch: 457 [24576/54000 (46%)] Loss: -1531.734009\n",
      "Train Epoch: 457 [28672/54000 (53%)] Loss: -1537.286499\n",
      "Train Epoch: 457 [32768/54000 (61%)] Loss: -1539.265137\n",
      "Train Epoch: 457 [36864/54000 (68%)] Loss: -1533.918335\n",
      "Train Epoch: 457 [40960/54000 (76%)] Loss: -1540.342529\n",
      "Train Epoch: 457 [45056/54000 (83%)] Loss: -1537.372192\n",
      "Train Epoch: 457 [49152/54000 (91%)] Loss: -1539.809814\n",
      "Train Epoch: 457 [53248/54000 (99%)] Loss: -1534.844604\n",
      "    epoch          : 457\n",
      "    loss           : -1535.532317392069\n",
      "    ess            : 3.781749682403854\n",
      "    log_marginal   : 1535.6677194025845\n",
      "    val_loss       : -1535.3692525227864\n",
      "    val_ess        : 3.776839325825373\n",
      "    val_log_marginal: 1535.5053456624348\n",
      "Train Epoch: 458 [0/54000 (0%)] Loss: -1535.116943\n",
      "Train Epoch: 458 [4096/54000 (8%)] Loss: -1536.267090\n",
      "Train Epoch: 458 [8192/54000 (15%)] Loss: -1536.845581\n",
      "Train Epoch: 458 [12288/54000 (23%)] Loss: -1537.775879\n",
      "Train Epoch: 458 [16384/54000 (30%)] Loss: -1537.930664\n",
      "Train Epoch: 458 [20480/54000 (38%)] Loss: -1538.093506\n",
      "Train Epoch: 458 [24576/54000 (46%)] Loss: -1533.663452\n",
      "Train Epoch: 458 [28672/54000 (53%)] Loss: -1532.177979\n",
      "Train Epoch: 458 [32768/54000 (61%)] Loss: -1533.412109\n",
      "Train Epoch: 458 [36864/54000 (68%)] Loss: -1539.988647\n",
      "Train Epoch: 458 [40960/54000 (76%)] Loss: -1535.063843\n",
      "Train Epoch: 458 [45056/54000 (83%)] Loss: -1535.581177\n",
      "Train Epoch: 458 [49152/54000 (91%)] Loss: -1534.288574\n",
      "Train Epoch: 458 [53248/54000 (99%)] Loss: -1530.733154\n",
      "    epoch          : 458\n",
      "    loss           : -1535.8570116956087\n",
      "    ess            : 3.7797062758585853\n",
      "    log_marginal   : 1535.993547629406\n",
      "    val_loss       : -1535.1141306559246\n",
      "    val_ess        : 3.782924383878708\n",
      "    val_log_marginal: 1535.2437845865886\n",
      "Train Epoch: 459 [0/54000 (0%)] Loss: -1539.249268\n",
      "Train Epoch: 459 [4096/54000 (8%)] Loss: -1544.143311\n",
      "Train Epoch: 459 [8192/54000 (15%)] Loss: -1537.021851\n",
      "Train Epoch: 459 [12288/54000 (23%)] Loss: -1538.172852\n",
      "Train Epoch: 459 [16384/54000 (30%)] Loss: -1537.274292\n",
      "Train Epoch: 459 [20480/54000 (38%)] Loss: -1534.888916\n",
      "Train Epoch: 459 [24576/54000 (46%)] Loss: -1535.857178\n",
      "Train Epoch: 459 [28672/54000 (53%)] Loss: -1537.190918\n",
      "Train Epoch: 459 [32768/54000 (61%)] Loss: -1535.413086\n",
      "Train Epoch: 459 [36864/54000 (68%)] Loss: -1535.878662\n",
      "Train Epoch: 459 [40960/54000 (76%)] Loss: -1537.154297\n",
      "Train Epoch: 459 [45056/54000 (83%)] Loss: -1534.135742\n",
      "Train Epoch: 459 [49152/54000 (91%)] Loss: -1532.045898\n",
      "Train Epoch: 459 [53248/54000 (99%)] Loss: -1531.622925\n",
      "    epoch          : 459\n",
      "    loss           : -1536.059528079643\n",
      "    ess            : 3.7760193144540652\n",
      "    log_marginal   : 1536.2022768716677\n",
      "    val_loss       : -1534.9806264241536\n",
      "    val_ess        : 3.7808863123257956\n",
      "    val_log_marginal: 1535.1168670654297\n",
      "Train Epoch: 460 [0/54000 (0%)] Loss: -1539.549072\n",
      "Train Epoch: 460 [4096/54000 (8%)] Loss: -1535.160889\n",
      "Train Epoch: 460 [8192/54000 (15%)] Loss: -1539.619873\n",
      "Train Epoch: 460 [12288/54000 (23%)] Loss: -1537.683472\n",
      "Train Epoch: 460 [16384/54000 (30%)] Loss: -1530.376587\n",
      "Train Epoch: 460 [20480/54000 (38%)] Loss: -1538.337524\n",
      "Train Epoch: 460 [24576/54000 (46%)] Loss: -1532.883179\n",
      "Train Epoch: 460 [28672/54000 (53%)] Loss: -1532.900757\n",
      "Train Epoch: 460 [32768/54000 (61%)] Loss: -1533.859619\n",
      "Train Epoch: 460 [36864/54000 (68%)] Loss: -1538.317139\n",
      "Train Epoch: 460 [40960/54000 (76%)] Loss: -1541.114868\n",
      "Train Epoch: 460 [45056/54000 (83%)] Loss: -1531.205322\n",
      "Train Epoch: 460 [49152/54000 (91%)] Loss: -1536.234619\n",
      "Train Epoch: 460 [53248/54000 (99%)] Loss: -1536.500366\n",
      "    epoch          : 460\n",
      "    loss           : -1535.9002621908323\n",
      "    ess            : 3.7796444734690877\n",
      "    log_marginal   : 1536.0394744149883\n",
      "    val_loss       : -1535.5951131184895\n",
      "    val_ess        : 3.779223620891571\n",
      "    val_log_marginal: 1535.7360229492188\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch460.pth ...\n",
      "Train Epoch: 461 [0/54000 (0%)] Loss: -1533.047607\n",
      "Train Epoch: 461 [4096/54000 (8%)] Loss: -1536.680176\n",
      "Train Epoch: 461 [8192/54000 (15%)] Loss: -1537.193970\n",
      "Train Epoch: 461 [12288/54000 (23%)] Loss: -1537.652100\n",
      "Train Epoch: 461 [16384/54000 (30%)] Loss: -1532.622192\n",
      "Train Epoch: 461 [20480/54000 (38%)] Loss: -1529.239990\n",
      "Train Epoch: 461 [24576/54000 (46%)] Loss: -1532.195068\n",
      "Train Epoch: 461 [28672/54000 (53%)] Loss: -1537.513794\n",
      "Train Epoch: 461 [32768/54000 (61%)] Loss: -1530.006348\n",
      "Train Epoch: 461 [36864/54000 (68%)] Loss: -1537.314819\n",
      "Train Epoch: 461 [40960/54000 (76%)] Loss: -1535.958374\n",
      "Train Epoch: 461 [45056/54000 (83%)] Loss: -1530.343262\n",
      "Train Epoch: 461 [49152/54000 (91%)] Loss: -1534.784424\n",
      "Train Epoch: 461 [53248/54000 (99%)] Loss: -1532.448730\n",
      "    epoch          : 461\n",
      "    loss           : -1535.7794843194608\n",
      "    ess            : 3.7786798624065816\n",
      "    log_marginal   : 1535.9170818600044\n",
      "    val_loss       : -1535.6658528645833\n",
      "    val_ess        : 3.772549440463384\n",
      "    val_log_marginal: 1535.8116607666016\n",
      "Train Epoch: 462 [0/54000 (0%)] Loss: -1537.796875\n",
      "Train Epoch: 462 [4096/54000 (8%)] Loss: -1540.245361\n",
      "Train Epoch: 462 [8192/54000 (15%)] Loss: -1538.879639\n",
      "Train Epoch: 462 [12288/54000 (23%)] Loss: -1533.212646\n",
      "Train Epoch: 462 [16384/54000 (30%)] Loss: -1536.197388\n",
      "Train Epoch: 462 [20480/54000 (38%)] Loss: -1537.470459\n",
      "Train Epoch: 462 [24576/54000 (46%)] Loss: -1539.835938\n",
      "Train Epoch: 462 [28672/54000 (53%)] Loss: -1536.033447\n",
      "Train Epoch: 462 [32768/54000 (61%)] Loss: -1530.888428\n",
      "Train Epoch: 462 [36864/54000 (68%)] Loss: -1541.065674\n",
      "Train Epoch: 462 [40960/54000 (76%)] Loss: -1536.986938\n",
      "Train Epoch: 462 [45056/54000 (83%)] Loss: -1532.482788\n",
      "Train Epoch: 462 [49152/54000 (91%)] Loss: -1543.542969\n",
      "Train Epoch: 462 [53248/54000 (99%)] Loss: -1528.762573\n",
      "    epoch          : 462\n",
      "    loss           : -1536.1826264440165\n",
      "    ess            : 3.7839497322154836\n",
      "    log_marginal   : 1536.3201568748148\n",
      "    val_loss       : -1535.433110555013\n",
      "    val_ess        : 3.782575100660324\n",
      "    val_log_marginal: 1535.571533203125\n",
      "Train Epoch: 463 [0/54000 (0%)] Loss: -1533.118408\n",
      "Train Epoch: 463 [4096/54000 (8%)] Loss: -1538.305298\n",
      "Train Epoch: 463 [8192/54000 (15%)] Loss: -1545.109741\n",
      "Train Epoch: 463 [12288/54000 (23%)] Loss: -1537.490479\n",
      "Train Epoch: 463 [16384/54000 (30%)] Loss: -1536.715332\n",
      "Train Epoch: 463 [20480/54000 (38%)] Loss: -1534.551025\n",
      "Train Epoch: 463 [24576/54000 (46%)] Loss: -1541.885010\n",
      "Train Epoch: 463 [28672/54000 (53%)] Loss: -1534.453857\n",
      "Train Epoch: 463 [32768/54000 (61%)] Loss: -1532.678955\n",
      "Train Epoch: 463 [36864/54000 (68%)] Loss: -1544.322266\n",
      "Train Epoch: 463 [40960/54000 (76%)] Loss: -1536.568848\n",
      "Train Epoch: 463 [45056/54000 (83%)] Loss: -1544.072754\n",
      "Train Epoch: 463 [49152/54000 (91%)] Loss: -1542.911255\n",
      "Train Epoch: 463 [53248/54000 (99%)] Loss: -1541.753174\n",
      "    epoch          : 463\n",
      "    loss           : -1537.4718162211198\n",
      "    ess            : 3.7851267019154338\n",
      "    log_marginal   : 1537.603382562574\n",
      "    val_loss       : -1537.543940226237\n",
      "    val_ess        : 3.7828511695067086\n",
      "    val_log_marginal: 1537.679423014323\n",
      "Train Epoch: 464 [0/54000 (0%)] Loss: -1539.755127\n",
      "Train Epoch: 464 [4096/54000 (8%)] Loss: -1531.217529\n",
      "Train Epoch: 464 [8192/54000 (15%)] Loss: -1540.208984\n",
      "Train Epoch: 464 [12288/54000 (23%)] Loss: -1542.628662\n",
      "Train Epoch: 464 [16384/54000 (30%)] Loss: -1537.312378\n",
      "Train Epoch: 464 [20480/54000 (38%)] Loss: -1534.074463\n",
      "Train Epoch: 464 [24576/54000 (46%)] Loss: -1534.864136\n",
      "Train Epoch: 464 [28672/54000 (53%)] Loss: -1542.350708\n",
      "Train Epoch: 464 [32768/54000 (61%)] Loss: -1536.493408\n",
      "Train Epoch: 464 [36864/54000 (68%)] Loss: -1539.063599\n",
      "Train Epoch: 464 [40960/54000 (76%)] Loss: -1537.741211\n",
      "Train Epoch: 464 [45056/54000 (83%)] Loss: -1532.002686\n",
      "Train Epoch: 464 [49152/54000 (91%)] Loss: -1537.877441\n",
      "Train Epoch: 464 [53248/54000 (99%)] Loss: -1544.687378\n",
      "    epoch          : 464\n",
      "    loss           : -1538.4898646928689\n",
      "    ess            : 3.7845018893056572\n",
      "    log_marginal   : 1538.6214402908397\n",
      "    val_loss       : -1538.1376088460286\n",
      "    val_ess        : 3.7677332858244577\n",
      "    val_log_marginal: 1538.2877248128254\n",
      "Train Epoch: 465 [0/54000 (0%)] Loss: -1535.597534\n",
      "Train Epoch: 465 [4096/54000 (8%)] Loss: -1542.114014\n",
      "Train Epoch: 465 [8192/54000 (15%)] Loss: -1538.089478\n",
      "Train Epoch: 465 [12288/54000 (23%)] Loss: -1539.336548\n",
      "Train Epoch: 465 [16384/54000 (30%)] Loss: -1540.189819\n",
      "Train Epoch: 465 [20480/54000 (38%)] Loss: -1536.457764\n",
      "Train Epoch: 465 [24576/54000 (46%)] Loss: -1535.995361\n",
      "Train Epoch: 465 [28672/54000 (53%)] Loss: -1539.207275\n",
      "Train Epoch: 465 [32768/54000 (61%)] Loss: -1532.419434\n",
      "Train Epoch: 465 [36864/54000 (68%)] Loss: -1542.079102\n",
      "Train Epoch: 465 [40960/54000 (76%)] Loss: -1541.649536\n",
      "Train Epoch: 465 [45056/54000 (83%)] Loss: -1543.542603\n",
      "Train Epoch: 465 [49152/54000 (91%)] Loss: -1537.806885\n",
      "Train Epoch: 465 [53248/54000 (99%)] Loss: -1540.220215\n",
      "    epoch          : 465\n",
      "    loss           : -1539.2251988994\n",
      "    ess            : 3.783064982337409\n",
      "    log_marginal   : 1539.3598002212307\n",
      "    val_loss       : -1538.6496988932292\n",
      "    val_ess        : 3.7803105413913727\n",
      "    val_log_marginal: 1538.7824096679688\n",
      "Train Epoch: 466 [0/54000 (0%)] Loss: -1535.359985\n",
      "Train Epoch: 466 [4096/54000 (8%)] Loss: -1540.205933\n",
      "Train Epoch: 466 [8192/54000 (15%)] Loss: -1544.490234\n",
      "Train Epoch: 466 [12288/54000 (23%)] Loss: -1536.656738\n",
      "Train Epoch: 466 [16384/54000 (30%)] Loss: -1541.826782\n",
      "Train Epoch: 466 [20480/54000 (38%)] Loss: -1533.713623\n",
      "Train Epoch: 466 [24576/54000 (46%)] Loss: -1538.364990\n",
      "Train Epoch: 466 [28672/54000 (53%)] Loss: -1529.644287\n",
      "Train Epoch: 466 [32768/54000 (61%)] Loss: -1543.931274\n",
      "Train Epoch: 466 [36864/54000 (68%)] Loss: -1540.293457\n",
      "Train Epoch: 466 [40960/54000 (76%)] Loss: -1530.692749\n",
      "Train Epoch: 466 [45056/54000 (83%)] Loss: -1542.465820\n",
      "Train Epoch: 466 [49152/54000 (91%)] Loss: -1541.424194\n",
      "Train Epoch: 466 [53248/54000 (99%)] Loss: -1536.200195\n",
      "    epoch          : 466\n",
      "    loss           : -1539.5823459715639\n",
      "    ess            : 3.780790819376001\n",
      "    log_marginal   : 1539.7177103774807\n",
      "    val_loss       : -1539.0262807210286\n",
      "    val_ess        : 3.775197426478068\n",
      "    val_log_marginal: 1539.1657409667969\n",
      "Train Epoch: 467 [0/54000 (0%)] Loss: -1535.871826\n",
      "Train Epoch: 467 [4096/54000 (8%)] Loss: -1540.761597\n",
      "Train Epoch: 467 [8192/54000 (15%)] Loss: -1532.731445\n",
      "Train Epoch: 467 [12288/54000 (23%)] Loss: -1542.464233\n",
      "Train Epoch: 467 [16384/54000 (30%)] Loss: -1539.854126\n",
      "Train Epoch: 467 [20480/54000 (38%)] Loss: -1538.775879\n",
      "Train Epoch: 467 [24576/54000 (46%)] Loss: -1535.622803\n",
      "Train Epoch: 467 [28672/54000 (53%)] Loss: -1545.963135\n",
      "Train Epoch: 467 [32768/54000 (61%)] Loss: -1534.586426\n",
      "Train Epoch: 467 [36864/54000 (68%)] Loss: -1540.953979\n",
      "Train Epoch: 467 [40960/54000 (76%)] Loss: -1540.475830\n",
      "Train Epoch: 467 [45056/54000 (83%)] Loss: -1541.177979\n",
      "Train Epoch: 467 [49152/54000 (91%)] Loss: -1544.055176\n",
      "Train Epoch: 467 [53248/54000 (99%)] Loss: -1541.435303\n",
      "    epoch          : 467\n",
      "    loss           : -1539.859155157731\n",
      "    ess            : 3.7844955909873637\n",
      "    log_marginal   : 1539.9958316748741\n",
      "    val_loss       : -1540.314712524414\n",
      "    val_ess        : 3.7995248436927795\n",
      "    val_log_marginal: 1540.4455312093098\n",
      "Train Epoch: 468 [0/54000 (0%)] Loss: -1534.280640\n",
      "Train Epoch: 468 [4096/54000 (8%)] Loss: -1543.667725\n",
      "Train Epoch: 468 [8192/54000 (15%)] Loss: -1544.582642\n",
      "Train Epoch: 468 [12288/54000 (23%)] Loss: -1537.232544\n",
      "Train Epoch: 468 [16384/54000 (30%)] Loss: -1542.429932\n",
      "Train Epoch: 468 [20480/54000 (38%)] Loss: -1537.073364\n",
      "Train Epoch: 468 [24576/54000 (46%)] Loss: -1543.318237\n",
      "Train Epoch: 468 [28672/54000 (53%)] Loss: -1538.396973\n",
      "Train Epoch: 468 [32768/54000 (61%)] Loss: -1538.393066\n",
      "Train Epoch: 468 [36864/54000 (68%)] Loss: -1539.907227\n",
      "Train Epoch: 468 [40960/54000 (76%)] Loss: -1548.293091\n",
      "Train Epoch: 468 [45056/54000 (83%)] Loss: -1545.335815\n",
      "Train Epoch: 468 [49152/54000 (91%)] Loss: -1542.292969\n",
      "Train Epoch: 468 [53248/54000 (99%)] Loss: -1540.698975\n",
      "    epoch          : 468\n",
      "    loss           : -1540.0825675494298\n",
      "    ess            : 3.778521428176012\n",
      "    log_marginal   : 1540.2193499379814\n",
      "    val_loss       : -1538.847132364909\n",
      "    val_ess        : 3.79154043396314\n",
      "    val_log_marginal: 1538.9811096191406\n",
      "Train Epoch: 469 [0/54000 (0%)] Loss: -1542.581177\n",
      "Train Epoch: 469 [4096/54000 (8%)] Loss: -1542.795898\n",
      "Train Epoch: 469 [8192/54000 (15%)] Loss: -1536.829468\n",
      "Train Epoch: 469 [12288/54000 (23%)] Loss: -1544.633667\n",
      "Train Epoch: 469 [16384/54000 (30%)] Loss: -1542.947144\n",
      "Train Epoch: 469 [20480/54000 (38%)] Loss: -1534.715088\n",
      "Train Epoch: 469 [24576/54000 (46%)] Loss: -1538.159546\n",
      "Train Epoch: 469 [28672/54000 (53%)] Loss: -1542.963135\n",
      "Train Epoch: 469 [32768/54000 (61%)] Loss: -1542.921875\n",
      "Train Epoch: 469 [36864/54000 (68%)] Loss: -1546.630127\n",
      "Train Epoch: 469 [40960/54000 (76%)] Loss: -1539.791992\n",
      "Train Epoch: 469 [45056/54000 (83%)] Loss: -1534.579102\n",
      "Train Epoch: 469 [49152/54000 (91%)] Loss: -1536.206421\n",
      "Train Epoch: 469 [53248/54000 (99%)] Loss: -1536.312256\n",
      "    epoch          : 469\n",
      "    loss           : -1540.048553900696\n",
      "    ess            : 3.7819279234556227\n",
      "    log_marginal   : 1540.1832501018216\n",
      "    val_loss       : -1540.0076293945312\n",
      "    val_ess        : 3.7706835170586905\n",
      "    val_log_marginal: 1540.1519673665364\n",
      "Train Epoch: 470 [0/54000 (0%)] Loss: -1543.994629\n",
      "Train Epoch: 470 [4096/54000 (8%)] Loss: -1542.710327\n",
      "Train Epoch: 470 [8192/54000 (15%)] Loss: -1540.809082\n",
      "Train Epoch: 470 [12288/54000 (23%)] Loss: -1536.083008\n",
      "Train Epoch: 470 [16384/54000 (30%)] Loss: -1540.170410\n",
      "Train Epoch: 470 [20480/54000 (38%)] Loss: -1542.827759\n",
      "Train Epoch: 470 [24576/54000 (46%)] Loss: -1537.152344\n",
      "Train Epoch: 470 [28672/54000 (53%)] Loss: -1537.100220\n",
      "Train Epoch: 470 [32768/54000 (61%)] Loss: -1543.712158\n",
      "Train Epoch: 470 [36864/54000 (68%)] Loss: -1544.811279\n",
      "Train Epoch: 470 [40960/54000 (76%)] Loss: -1540.952148\n",
      "Train Epoch: 470 [45056/54000 (83%)] Loss: -1542.941528\n",
      "Train Epoch: 470 [49152/54000 (91%)] Loss: -1538.428833\n",
      "Train Epoch: 470 [53248/54000 (99%)] Loss: -1538.763062\n",
      "    epoch          : 470\n",
      "    loss           : -1540.2879615530583\n",
      "    ess            : 3.787042435876566\n",
      "    log_marginal   : 1540.4228666043396\n",
      "    val_loss       : -1539.532964070638\n",
      "    val_ess        : 3.7754868964354196\n",
      "    val_log_marginal: 1539.6661326090496\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch470.pth ...\n",
      "Train Epoch: 471 [0/54000 (0%)] Loss: -1538.015015\n",
      "Train Epoch: 471 [4096/54000 (8%)] Loss: -1532.101562\n",
      "Train Epoch: 471 [8192/54000 (15%)] Loss: -1540.640869\n",
      "Train Epoch: 471 [12288/54000 (23%)] Loss: -1541.546875\n",
      "Train Epoch: 471 [16384/54000 (30%)] Loss: -1541.210571\n",
      "Train Epoch: 471 [20480/54000 (38%)] Loss: -1537.022339\n",
      "Train Epoch: 471 [24576/54000 (46%)] Loss: -1542.964600\n",
      "Train Epoch: 471 [28672/54000 (53%)] Loss: -1543.823730\n",
      "Train Epoch: 471 [32768/54000 (61%)] Loss: -1535.382568\n",
      "Train Epoch: 471 [36864/54000 (68%)] Loss: -1537.089844\n",
      "Train Epoch: 471 [40960/54000 (76%)] Loss: -1538.546387\n",
      "Train Epoch: 471 [45056/54000 (83%)] Loss: -1533.300781\n",
      "Train Epoch: 471 [49152/54000 (91%)] Loss: -1543.387939\n",
      "Train Epoch: 471 [53248/54000 (99%)] Loss: -1543.241455\n",
      "    epoch          : 471\n",
      "    loss           : -1540.7358496787988\n",
      "    ess            : 3.7834228531444243\n",
      "    log_marginal   : 1540.8693379045098\n",
      "    val_loss       : -1540.548100789388\n",
      "    val_ess        : 3.791216343641281\n",
      "    val_log_marginal: 1540.6852569580078\n",
      "Train Epoch: 472 [0/54000 (0%)] Loss: -1535.983765\n",
      "Train Epoch: 472 [4096/54000 (8%)] Loss: -1539.694092\n",
      "Train Epoch: 472 [8192/54000 (15%)] Loss: -1549.358643\n",
      "Train Epoch: 472 [12288/54000 (23%)] Loss: -1549.892456\n",
      "Train Epoch: 472 [16384/54000 (30%)] Loss: -1539.575562\n",
      "Train Epoch: 472 [20480/54000 (38%)] Loss: -1538.361572\n",
      "Train Epoch: 472 [24576/54000 (46%)] Loss: -1542.212158\n",
      "Train Epoch: 472 [28672/54000 (53%)] Loss: -1546.931641\n",
      "Train Epoch: 472 [32768/54000 (61%)] Loss: -1535.384033\n",
      "Train Epoch: 472 [36864/54000 (68%)] Loss: -1541.664917\n",
      "Train Epoch: 472 [40960/54000 (76%)] Loss: -1539.925293\n",
      "Train Epoch: 472 [45056/54000 (83%)] Loss: -1544.115234\n",
      "Train Epoch: 472 [49152/54000 (91%)] Loss: -1536.644775\n",
      "Train Epoch: 472 [53248/54000 (99%)] Loss: -1540.817139\n",
      "    epoch          : 472\n",
      "    loss           : -1540.8759840834198\n",
      "    ess            : 3.7810628933929156\n",
      "    log_marginal   : 1541.0136585687574\n",
      "    val_loss       : -1540.8112335205078\n",
      "    val_ess        : 3.7793416480223336\n",
      "    val_log_marginal: 1540.9567159016926\n",
      "Train Epoch: 473 [0/54000 (0%)] Loss: -1542.638794\n",
      "Train Epoch: 473 [4096/54000 (8%)] Loss: -1537.376709\n",
      "Train Epoch: 473 [8192/54000 (15%)] Loss: -1537.042114\n",
      "Train Epoch: 473 [12288/54000 (23%)] Loss: -1542.770142\n",
      "Train Epoch: 473 [16384/54000 (30%)] Loss: -1538.629883\n",
      "Train Epoch: 473 [20480/54000 (38%)] Loss: -1539.944336\n",
      "Train Epoch: 473 [24576/54000 (46%)] Loss: -1545.821411\n",
      "Train Epoch: 473 [28672/54000 (53%)] Loss: -1541.412842\n",
      "Train Epoch: 473 [32768/54000 (61%)] Loss: -1538.393066\n",
      "Train Epoch: 473 [36864/54000 (68%)] Loss: -1539.096069\n",
      "Train Epoch: 473 [40960/54000 (76%)] Loss: -1543.622559\n",
      "Train Epoch: 473 [45056/54000 (83%)] Loss: -1545.531738\n",
      "Train Epoch: 473 [49152/54000 (91%)] Loss: -1545.340820\n",
      "Train Epoch: 473 [53248/54000 (99%)] Loss: -1542.735596\n",
      "    epoch          : 473\n",
      "    loss           : -1541.3644238512663\n",
      "    ess            : 3.7816789941200146\n",
      "    log_marginal   : 1541.5015354246889\n",
      "    val_loss       : -1541.3103586832683\n",
      "    val_ess        : 3.78471577167511\n",
      "    val_log_marginal: 1541.445307413737\n",
      "Train Epoch: 474 [0/54000 (0%)] Loss: -1543.255859\n",
      "Train Epoch: 474 [4096/54000 (8%)] Loss: -1537.033447\n",
      "Train Epoch: 474 [8192/54000 (15%)] Loss: -1545.896973\n",
      "Train Epoch: 474 [12288/54000 (23%)] Loss: -1537.612305\n",
      "Train Epoch: 474 [16384/54000 (30%)] Loss: -1536.439453\n",
      "Train Epoch: 474 [20480/54000 (38%)] Loss: -1540.611816\n",
      "Train Epoch: 474 [24576/54000 (46%)] Loss: -1543.813232\n",
      "Train Epoch: 474 [28672/54000 (53%)] Loss: -1537.348267\n",
      "Train Epoch: 474 [32768/54000 (61%)] Loss: -1540.080200\n",
      "Train Epoch: 474 [36864/54000 (68%)] Loss: -1537.852783\n",
      "Train Epoch: 474 [40960/54000 (76%)] Loss: -1539.223755\n",
      "Train Epoch: 474 [45056/54000 (83%)] Loss: -1542.039551\n",
      "Train Epoch: 474 [49152/54000 (91%)] Loss: -1536.789551\n",
      "Train Epoch: 474 [53248/54000 (99%)] Loss: -1551.522949\n",
      "    epoch          : 474\n",
      "    loss           : -1541.4411632664396\n",
      "    ess            : 3.7833801174615798\n",
      "    log_marginal   : 1541.575594499778\n",
      "    val_loss       : -1541.649693806966\n",
      "    val_ess        : 3.7794034679730735\n",
      "    val_log_marginal: 1541.7920786539714\n",
      "Train Epoch: 475 [0/54000 (0%)] Loss: -1539.667480\n",
      "Train Epoch: 475 [4096/54000 (8%)] Loss: -1534.768555\n",
      "Train Epoch: 475 [8192/54000 (15%)] Loss: -1540.063965\n",
      "Train Epoch: 475 [12288/54000 (23%)] Loss: -1539.885742\n",
      "Train Epoch: 475 [16384/54000 (30%)] Loss: -1547.451294\n",
      "Train Epoch: 475 [20480/54000 (38%)] Loss: -1539.504517\n",
      "Train Epoch: 475 [24576/54000 (46%)] Loss: -1545.817627\n",
      "Train Epoch: 475 [28672/54000 (53%)] Loss: -1546.978271\n",
      "Train Epoch: 475 [32768/54000 (61%)] Loss: -1540.132568\n",
      "Train Epoch: 475 [36864/54000 (68%)] Loss: -1540.944580\n",
      "Train Epoch: 475 [40960/54000 (76%)] Loss: -1540.467285\n",
      "Train Epoch: 475 [45056/54000 (83%)] Loss: -1548.024902\n",
      "Train Epoch: 475 [49152/54000 (91%)] Loss: -1541.677246\n",
      "Train Epoch: 475 [53248/54000 (99%)] Loss: -1545.391724\n",
      "    epoch          : 475\n",
      "    loss           : -1541.717389870594\n",
      "    ess            : 3.7807787741529997\n",
      "    log_marginal   : 1541.8594953347156\n",
      "    val_loss       : -1540.9329986572266\n",
      "    val_ess        : 3.7698339323202767\n",
      "    val_log_marginal: 1541.078842163086\n",
      "Train Epoch: 476 [0/54000 (0%)] Loss: -1545.341797\n",
      "Train Epoch: 476 [4096/54000 (8%)] Loss: -1548.194458\n",
      "Train Epoch: 476 [8192/54000 (15%)] Loss: -1541.279297\n",
      "Train Epoch: 476 [12288/54000 (23%)] Loss: -1539.204834\n",
      "Train Epoch: 476 [16384/54000 (30%)] Loss: -1541.814697\n",
      "Train Epoch: 476 [20480/54000 (38%)] Loss: -1545.950684\n",
      "Train Epoch: 476 [24576/54000 (46%)] Loss: -1537.827881\n",
      "Train Epoch: 476 [28672/54000 (53%)] Loss: -1538.626953\n",
      "Train Epoch: 476 [32768/54000 (61%)] Loss: -1542.561035\n",
      "Train Epoch: 476 [36864/54000 (68%)] Loss: -1542.468262\n",
      "Train Epoch: 476 [40960/54000 (76%)] Loss: -1537.909058\n",
      "Train Epoch: 476 [45056/54000 (83%)] Loss: -1539.981689\n",
      "Train Epoch: 476 [49152/54000 (91%)] Loss: -1541.238892\n",
      "Train Epoch: 476 [53248/54000 (99%)] Loss: -1544.822388\n",
      "    epoch          : 476\n",
      "    loss           : -1541.5353974979635\n",
      "    ess            : 3.7799347791626556\n",
      "    log_marginal   : 1541.6769903824793\n",
      "    val_loss       : -1541.0469614664714\n",
      "    val_ess        : 3.7798474729061127\n",
      "    val_log_marginal: 1541.196756998698\n",
      "Train Epoch: 477 [0/54000 (0%)] Loss: -1541.108398\n",
      "Train Epoch: 477 [4096/54000 (8%)] Loss: -1545.129639\n",
      "Train Epoch: 477 [8192/54000 (15%)] Loss: -1543.999756\n",
      "Train Epoch: 477 [12288/54000 (23%)] Loss: -1541.464722\n",
      "Train Epoch: 477 [16384/54000 (30%)] Loss: -1544.076904\n",
      "Train Epoch: 477 [20480/54000 (38%)] Loss: -1532.501709\n",
      "Train Epoch: 477 [24576/54000 (46%)] Loss: -1537.748535\n",
      "Train Epoch: 477 [28672/54000 (53%)] Loss: -1544.463501\n",
      "Train Epoch: 477 [32768/54000 (61%)] Loss: -1540.155151\n",
      "Train Epoch: 477 [36864/54000 (68%)] Loss: -1536.181152\n",
      "Train Epoch: 477 [40960/54000 (76%)] Loss: -1542.542969\n",
      "Train Epoch: 477 [45056/54000 (83%)] Loss: -1537.922363\n",
      "Train Epoch: 477 [49152/54000 (91%)] Loss: -1537.983765\n",
      "Train Epoch: 477 [53248/54000 (99%)] Loss: -1541.080811\n",
      "    epoch          : 477\n",
      "    loss           : -1541.5112663377517\n",
      "    ess            : 3.7824562398178316\n",
      "    log_marginal   : 1541.6455714510516\n",
      "    val_loss       : -1542.1490681966145\n",
      "    val_ess        : 3.7755719125270844\n",
      "    val_log_marginal: 1542.290542602539\n",
      "Train Epoch: 478 [0/54000 (0%)] Loss: -1546.326904\n",
      "Train Epoch: 478 [4096/54000 (8%)] Loss: -1541.060913\n",
      "Train Epoch: 478 [8192/54000 (15%)] Loss: -1545.208496\n",
      "Train Epoch: 478 [12288/54000 (23%)] Loss: -1547.609375\n",
      "Train Epoch: 478 [16384/54000 (30%)] Loss: -1538.886475\n",
      "Train Epoch: 478 [20480/54000 (38%)] Loss: -1540.890869\n",
      "Train Epoch: 478 [24576/54000 (46%)] Loss: -1540.586182\n",
      "Train Epoch: 478 [28672/54000 (53%)] Loss: -1537.177979\n",
      "Train Epoch: 478 [32768/54000 (61%)] Loss: -1536.385498\n",
      "Train Epoch: 478 [36864/54000 (68%)] Loss: -1544.984131\n",
      "Train Epoch: 478 [40960/54000 (76%)] Loss: -1541.055664\n",
      "Train Epoch: 478 [45056/54000 (83%)] Loss: -1542.459229\n",
      "Train Epoch: 478 [49152/54000 (91%)] Loss: -1542.615234\n",
      "Train Epoch: 478 [53248/54000 (99%)] Loss: -1541.449829\n",
      "    epoch          : 478\n",
      "    loss           : -1541.9391031129664\n",
      "    ess            : 3.7760404229729096\n",
      "    log_marginal   : 1542.0783298004294\n",
      "    val_loss       : -1541.818344116211\n",
      "    val_ess        : 3.7882661521434784\n",
      "    val_log_marginal: 1541.948465983073\n",
      "Train Epoch: 479 [0/54000 (0%)] Loss: -1543.371460\n",
      "Train Epoch: 479 [4096/54000 (8%)] Loss: -1536.438110\n",
      "Train Epoch: 479 [8192/54000 (15%)] Loss: -1543.573486\n",
      "Train Epoch: 479 [12288/54000 (23%)] Loss: -1541.190063\n",
      "Train Epoch: 479 [16384/54000 (30%)] Loss: -1544.826782\n",
      "Train Epoch: 479 [20480/54000 (38%)] Loss: -1537.903564\n",
      "Train Epoch: 479 [24576/54000 (46%)] Loss: -1539.800537\n",
      "Train Epoch: 479 [28672/54000 (53%)] Loss: -1539.067749\n",
      "Train Epoch: 479 [32768/54000 (61%)] Loss: -1542.060669\n",
      "Train Epoch: 479 [36864/54000 (68%)] Loss: -1541.206665\n",
      "Train Epoch: 479 [40960/54000 (76%)] Loss: -1539.252319\n",
      "Train Epoch: 479 [45056/54000 (83%)] Loss: -1539.410034\n",
      "Train Epoch: 479 [49152/54000 (91%)] Loss: -1545.717773\n",
      "Train Epoch: 479 [53248/54000 (99%)] Loss: -1541.541748\n",
      "    epoch          : 479\n",
      "    loss           : -1541.9002054946682\n",
      "    ess            : 3.7834707820584987\n",
      "    log_marginal   : 1542.0362537257479\n",
      "    val_loss       : -1541.8084004720051\n",
      "    val_ess        : 3.790732463200887\n",
      "    val_log_marginal: 1541.938700358073\n",
      "Train Epoch: 480 [0/54000 (0%)] Loss: -1541.375610\n",
      "Train Epoch: 480 [4096/54000 (8%)] Loss: -1550.191162\n",
      "Train Epoch: 480 [8192/54000 (15%)] Loss: -1535.095581\n",
      "Train Epoch: 480 [12288/54000 (23%)] Loss: -1547.476929\n",
      "Train Epoch: 480 [16384/54000 (30%)] Loss: -1542.144531\n",
      "Train Epoch: 480 [20480/54000 (38%)] Loss: -1540.720703\n",
      "Train Epoch: 480 [24576/54000 (46%)] Loss: -1541.300049\n",
      "Train Epoch: 480 [28672/54000 (53%)] Loss: -1540.231323\n",
      "Train Epoch: 480 [32768/54000 (61%)] Loss: -1543.953125\n",
      "Train Epoch: 480 [36864/54000 (68%)] Loss: -1543.858276\n",
      "Train Epoch: 480 [40960/54000 (76%)] Loss: -1537.954712\n",
      "Train Epoch: 480 [45056/54000 (83%)] Loss: -1544.487549\n",
      "Train Epoch: 480 [49152/54000 (91%)] Loss: -1537.958618\n",
      "Train Epoch: 480 [53248/54000 (99%)] Loss: -1542.942383\n",
      "    epoch          : 480\n",
      "    loss           : -1542.1116584669358\n",
      "    ess            : 3.7784510076893447\n",
      "    log_marginal   : 1542.2485264782656\n",
      "    val_loss       : -1541.085184733073\n",
      "    val_ess        : 3.7986817955970764\n",
      "    val_log_marginal: 1541.219935099284\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch480.pth ...\n",
      "Train Epoch: 481 [0/54000 (0%)] Loss: -1539.007080\n",
      "Train Epoch: 481 [4096/54000 (8%)] Loss: -1546.964844\n",
      "Train Epoch: 481 [8192/54000 (15%)] Loss: -1542.260254\n",
      "Train Epoch: 481 [12288/54000 (23%)] Loss: -1546.994385\n",
      "Train Epoch: 481 [16384/54000 (30%)] Loss: -1540.228271\n",
      "Train Epoch: 481 [20480/54000 (38%)] Loss: -1537.877686\n",
      "Train Epoch: 481 [24576/54000 (46%)] Loss: -1546.545044\n",
      "Train Epoch: 481 [28672/54000 (53%)] Loss: -1548.563232\n",
      "Train Epoch: 481 [32768/54000 (61%)] Loss: -1545.294312\n",
      "Train Epoch: 481 [36864/54000 (68%)] Loss: -1544.042480\n",
      "Train Epoch: 481 [40960/54000 (76%)] Loss: -1540.000488\n",
      "Train Epoch: 481 [45056/54000 (83%)] Loss: -1539.842041\n",
      "Train Epoch: 481 [49152/54000 (91%)] Loss: -1542.044189\n",
      "Train Epoch: 481 [53248/54000 (99%)] Loss: -1550.210083\n",
      "    epoch          : 481\n",
      "    loss           : -1541.9405835770883\n",
      "    ess            : 3.783506786653781\n",
      "    log_marginal   : 1542.0743448700384\n",
      "    val_loss       : -1541.2014973958333\n",
      "    val_ess        : 3.7903175254662833\n",
      "    val_log_marginal: 1541.3326568603516\n",
      "Train Epoch: 482 [0/54000 (0%)] Loss: -1542.266357\n",
      "Train Epoch: 482 [4096/54000 (8%)] Loss: -1543.005127\n",
      "Train Epoch: 482 [8192/54000 (15%)] Loss: -1544.491211\n",
      "Train Epoch: 482 [12288/54000 (23%)] Loss: -1541.250854\n",
      "Train Epoch: 482 [16384/54000 (30%)] Loss: -1541.537598\n",
      "Train Epoch: 482 [20480/54000 (38%)] Loss: -1549.686401\n",
      "Train Epoch: 482 [24576/54000 (46%)] Loss: -1547.106934\n",
      "Train Epoch: 482 [28672/54000 (53%)] Loss: -1542.462036\n",
      "Train Epoch: 482 [32768/54000 (61%)] Loss: -1545.367920\n",
      "Train Epoch: 482 [36864/54000 (68%)] Loss: -1538.562012\n",
      "Train Epoch: 482 [40960/54000 (76%)] Loss: -1534.849365\n",
      "Train Epoch: 482 [45056/54000 (83%)] Loss: -1540.689209\n",
      "Train Epoch: 482 [49152/54000 (91%)] Loss: -1544.067505\n",
      "Train Epoch: 482 [53248/54000 (99%)] Loss: -1540.815552\n",
      "    epoch          : 482\n",
      "    loss           : -1542.2097966343306\n",
      "    ess            : 3.7843854834118162\n",
      "    log_marginal   : 1542.3440456299986\n",
      "    val_loss       : -1542.4061330159504\n",
      "    val_ess        : 3.7849924763043723\n",
      "    val_log_marginal: 1542.5414326985676\n",
      "Train Epoch: 483 [0/54000 (0%)] Loss: -1539.510986\n",
      "Train Epoch: 483 [4096/54000 (8%)] Loss: -1540.348145\n",
      "Train Epoch: 483 [8192/54000 (15%)] Loss: -1540.256104\n",
      "Train Epoch: 483 [12288/54000 (23%)] Loss: -1540.923340\n",
      "Train Epoch: 483 [16384/54000 (30%)] Loss: -1538.237183\n",
      "Train Epoch: 483 [20480/54000 (38%)] Loss: -1537.192383\n",
      "Train Epoch: 483 [24576/54000 (46%)] Loss: -1541.651245\n",
      "Train Epoch: 483 [28672/54000 (53%)] Loss: -1540.713379\n",
      "Train Epoch: 483 [32768/54000 (61%)] Loss: -1551.737305\n",
      "Train Epoch: 483 [36864/54000 (68%)] Loss: -1553.423340\n",
      "Train Epoch: 483 [40960/54000 (76%)] Loss: -1541.325195\n",
      "Train Epoch: 483 [45056/54000 (83%)] Loss: -1545.762939\n",
      "Train Epoch: 483 [49152/54000 (91%)] Loss: -1543.060425\n",
      "Train Epoch: 483 [53248/54000 (99%)] Loss: -1540.800171\n",
      "    epoch          : 483\n",
      "    loss           : -1542.6112598581901\n",
      "    ess            : 3.7794953172240775\n",
      "    log_marginal   : 1542.7482557251556\n",
      "    val_loss       : -1542.6803487141926\n",
      "    val_ess        : 3.7836094001928964\n",
      "    val_log_marginal: 1542.8113606770833\n",
      "Train Epoch: 484 [0/54000 (0%)] Loss: -1536.141846\n",
      "Train Epoch: 484 [4096/54000 (8%)] Loss: -1543.938477\n",
      "Train Epoch: 484 [8192/54000 (15%)] Loss: -1550.306152\n",
      "Train Epoch: 484 [12288/54000 (23%)] Loss: -1541.243530\n",
      "Train Epoch: 484 [16384/54000 (30%)] Loss: -1544.423584\n",
      "Train Epoch: 484 [20480/54000 (38%)] Loss: -1545.787109\n",
      "Train Epoch: 484 [24576/54000 (46%)] Loss: -1541.636597\n",
      "Train Epoch: 484 [28672/54000 (53%)] Loss: -1543.476929\n",
      "Train Epoch: 484 [32768/54000 (61%)] Loss: -1543.417236\n",
      "Train Epoch: 484 [36864/54000 (68%)] Loss: -1543.958496\n",
      "Train Epoch: 484 [40960/54000 (76%)] Loss: -1538.760498\n",
      "Train Epoch: 484 [45056/54000 (83%)] Loss: -1537.735718\n",
      "Train Epoch: 484 [49152/54000 (91%)] Loss: -1544.442749\n",
      "Train Epoch: 484 [53248/54000 (99%)] Loss: -1543.391846\n",
      "    epoch          : 484\n",
      "    loss           : -1542.8445738299763\n",
      "    ess            : 3.782864250842994\n",
      "    log_marginal   : 1542.9793620177354\n",
      "    val_loss       : -1542.0848541259766\n",
      "    val_ess        : 3.7877526581287384\n",
      "    val_log_marginal: 1542.2208862304688\n",
      "Train Epoch: 485 [0/54000 (0%)] Loss: -1546.197266\n",
      "Train Epoch: 485 [4096/54000 (8%)] Loss: -1542.131348\n",
      "Train Epoch: 485 [8192/54000 (15%)] Loss: -1541.682007\n",
      "Train Epoch: 485 [12288/54000 (23%)] Loss: -1541.307129\n",
      "Train Epoch: 485 [16384/54000 (30%)] Loss: -1553.070190\n",
      "Train Epoch: 485 [20480/54000 (38%)] Loss: -1541.829346\n",
      "Train Epoch: 485 [24576/54000 (46%)] Loss: -1548.228149\n",
      "Train Epoch: 485 [28672/54000 (53%)] Loss: -1540.895996\n",
      "Train Epoch: 485 [32768/54000 (61%)] Loss: -1535.394531\n",
      "Train Epoch: 485 [36864/54000 (68%)] Loss: -1545.552002\n",
      "Train Epoch: 485 [40960/54000 (76%)] Loss: -1542.704224\n",
      "Train Epoch: 485 [45056/54000 (83%)] Loss: -1537.349854\n",
      "Train Epoch: 485 [49152/54000 (91%)] Loss: -1535.016479\n",
      "Train Epoch: 485 [53248/54000 (99%)] Loss: -1539.609131\n",
      "    epoch          : 485\n",
      "    loss           : -1542.8005238031324\n",
      "    ess            : 3.7862011584060453\n",
      "    log_marginal   : 1542.9346484143587\n",
      "    val_loss       : -1541.1513366699219\n",
      "    val_ess        : 3.7866871654987335\n",
      "    val_log_marginal: 1541.2747243245442\n",
      "Train Epoch: 486 [0/54000 (0%)] Loss: -1542.429321\n",
      "Train Epoch: 486 [4096/54000 (8%)] Loss: -1540.183594\n",
      "Train Epoch: 486 [8192/54000 (15%)] Loss: -1549.508911\n",
      "Train Epoch: 486 [12288/54000 (23%)] Loss: -1546.513184\n",
      "Train Epoch: 486 [16384/54000 (30%)] Loss: -1543.194092\n",
      "Train Epoch: 486 [20480/54000 (38%)] Loss: -1546.845215\n",
      "Train Epoch: 486 [24576/54000 (46%)] Loss: -1548.330566\n",
      "Train Epoch: 486 [28672/54000 (53%)] Loss: -1540.887939\n",
      "Train Epoch: 486 [32768/54000 (61%)] Loss: -1538.743530\n",
      "Train Epoch: 486 [36864/54000 (68%)] Loss: -1534.508057\n",
      "Train Epoch: 486 [40960/54000 (76%)] Loss: -1542.286865\n",
      "Train Epoch: 486 [45056/54000 (83%)] Loss: -1543.679077\n",
      "Train Epoch: 486 [49152/54000 (91%)] Loss: -1545.633179\n",
      "Train Epoch: 486 [53248/54000 (99%)] Loss: -1548.383545\n",
      "    epoch          : 486\n",
      "    loss           : -1542.7833032110857\n",
      "    ess            : 3.7855065761584243\n",
      "    log_marginal   : 1542.9171813675578\n",
      "    val_loss       : -1543.3252207438152\n",
      "    val_ess        : 3.7842691838741302\n",
      "    val_log_marginal: 1543.4641672770183\n",
      "Train Epoch: 487 [0/54000 (0%)] Loss: -1542.953369\n",
      "Train Epoch: 487 [4096/54000 (8%)] Loss: -1547.064941\n",
      "Train Epoch: 487 [8192/54000 (15%)] Loss: -1544.481567\n",
      "Train Epoch: 487 [12288/54000 (23%)] Loss: -1540.432861\n",
      "Train Epoch: 487 [16384/54000 (30%)] Loss: -1545.926025\n",
      "Train Epoch: 487 [20480/54000 (38%)] Loss: -1538.456543\n",
      "Train Epoch: 487 [24576/54000 (46%)] Loss: -1542.473755\n",
      "Train Epoch: 487 [28672/54000 (53%)] Loss: -1544.167480\n",
      "Train Epoch: 487 [32768/54000 (61%)] Loss: -1543.328125\n",
      "Train Epoch: 487 [36864/54000 (68%)] Loss: -1542.644775\n",
      "Train Epoch: 487 [40960/54000 (76%)] Loss: -1545.081055\n",
      "Train Epoch: 487 [45056/54000 (83%)] Loss: -1540.225098\n",
      "Train Epoch: 487 [49152/54000 (91%)] Loss: -1542.678467\n",
      "Train Epoch: 487 [53248/54000 (99%)] Loss: -1547.664062\n",
      "    epoch          : 487\n",
      "    loss           : -1543.0057639171728\n",
      "    ess            : 3.7858852187604137\n",
      "    log_marginal   : 1543.1382923578199\n",
      "    val_loss       : -1541.3800404866536\n",
      "    val_ess        : 3.779344310363134\n",
      "    val_log_marginal: 1541.5224304199219\n",
      "Train Epoch: 488 [0/54000 (0%)] Loss: -1539.120728\n",
      "Train Epoch: 488 [4096/54000 (8%)] Loss: -1548.748291\n",
      "Train Epoch: 488 [8192/54000 (15%)] Loss: -1554.409058\n",
      "Train Epoch: 488 [12288/54000 (23%)] Loss: -1541.249512\n",
      "Train Epoch: 488 [16384/54000 (30%)] Loss: -1541.576660\n",
      "Train Epoch: 488 [20480/54000 (38%)] Loss: -1543.510254\n",
      "Train Epoch: 488 [24576/54000 (46%)] Loss: -1542.736206\n",
      "Train Epoch: 488 [28672/54000 (53%)] Loss: -1541.633301\n",
      "Train Epoch: 488 [32768/54000 (61%)] Loss: -1543.156494\n",
      "Train Epoch: 488 [36864/54000 (68%)] Loss: -1547.734863\n",
      "Train Epoch: 488 [40960/54000 (76%)] Loss: -1548.354492\n",
      "Train Epoch: 488 [45056/54000 (83%)] Loss: -1536.545410\n",
      "Train Epoch: 488 [49152/54000 (91%)] Loss: -1549.440063\n",
      "Train Epoch: 488 [53248/54000 (99%)] Loss: -1542.933838\n",
      "    epoch          : 488\n",
      "    loss           : -1543.1785755609449\n",
      "    ess            : 3.7799899984875\n",
      "    log_marginal   : 1543.3182361476229\n",
      "    val_loss       : -1542.6627756754558\n",
      "    val_ess        : 3.7918596069018045\n",
      "    val_log_marginal: 1542.7972005208333\n",
      "Train Epoch: 489 [0/54000 (0%)] Loss: -1538.604248\n",
      "Train Epoch: 489 [4096/54000 (8%)] Loss: -1547.421265\n",
      "Train Epoch: 489 [8192/54000 (15%)] Loss: -1543.710083\n",
      "Train Epoch: 489 [12288/54000 (23%)] Loss: -1542.302124\n",
      "Train Epoch: 489 [16384/54000 (30%)] Loss: -1543.466309\n",
      "Train Epoch: 489 [20480/54000 (38%)] Loss: -1545.299561\n",
      "Train Epoch: 489 [24576/54000 (46%)] Loss: -1542.986206\n",
      "Train Epoch: 489 [28672/54000 (53%)] Loss: -1551.342773\n",
      "Train Epoch: 489 [32768/54000 (61%)] Loss: -1539.056030\n",
      "Train Epoch: 489 [36864/54000 (68%)] Loss: -1544.072754\n",
      "Train Epoch: 489 [40960/54000 (76%)] Loss: -1534.999512\n",
      "Train Epoch: 489 [45056/54000 (83%)] Loss: -1544.364014\n",
      "Train Epoch: 489 [49152/54000 (91%)] Loss: -1542.008057\n",
      "Train Epoch: 489 [53248/54000 (99%)] Loss: -1547.133545\n",
      "    epoch          : 489\n",
      "    loss           : -1543.4922875860857\n",
      "    ess            : 3.7836484909057617\n",
      "    log_marginal   : 1543.6264139329087\n",
      "    val_loss       : -1543.048334757487\n",
      "    val_ess        : 3.7706440587838492\n",
      "    val_log_marginal: 1543.205602010091\n",
      "Train Epoch: 490 [0/54000 (0%)] Loss: -1545.141846\n",
      "Train Epoch: 490 [4096/54000 (8%)] Loss: -1541.935547\n",
      "Train Epoch: 490 [8192/54000 (15%)] Loss: -1546.600830\n",
      "Train Epoch: 490 [12288/54000 (23%)] Loss: -1541.348755\n",
      "Train Epoch: 490 [16384/54000 (30%)] Loss: -1534.128296\n",
      "Train Epoch: 490 [20480/54000 (38%)] Loss: -1541.240845\n",
      "Train Epoch: 490 [24576/54000 (46%)] Loss: -1543.026001\n",
      "Train Epoch: 490 [28672/54000 (53%)] Loss: -1545.471924\n",
      "Train Epoch: 490 [32768/54000 (61%)] Loss: -1548.052979\n",
      "Train Epoch: 490 [36864/54000 (68%)] Loss: -1552.855103\n",
      "Train Epoch: 490 [40960/54000 (76%)] Loss: -1543.425049\n",
      "Train Epoch: 490 [45056/54000 (83%)] Loss: -1539.072021\n",
      "Train Epoch: 490 [49152/54000 (91%)] Loss: -1540.017822\n",
      "Train Epoch: 490 [53248/54000 (99%)] Loss: -1546.214111\n",
      "    epoch          : 490\n",
      "    loss           : -1543.5033207753258\n",
      "    ess            : 3.786013543323318\n",
      "    log_marginal   : 1543.636807843972\n",
      "    val_loss       : -1543.2061818440754\n",
      "    val_ess        : 3.7947258949279785\n",
      "    val_log_marginal: 1543.3243357340496\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch490.pth ...\n",
      "Train Epoch: 491 [0/54000 (0%)] Loss: -1546.126221\n",
      "Train Epoch: 491 [4096/54000 (8%)] Loss: -1537.027344\n",
      "Train Epoch: 491 [8192/54000 (15%)] Loss: -1543.933838\n",
      "Train Epoch: 491 [12288/54000 (23%)] Loss: -1545.224365\n",
      "Train Epoch: 491 [16384/54000 (30%)] Loss: -1541.281372\n",
      "Train Epoch: 491 [20480/54000 (38%)] Loss: -1544.448853\n",
      "Train Epoch: 491 [24576/54000 (46%)] Loss: -1539.715820\n",
      "Train Epoch: 491 [28672/54000 (53%)] Loss: -1541.928223\n",
      "Train Epoch: 491 [32768/54000 (61%)] Loss: -1548.890625\n",
      "Train Epoch: 491 [36864/54000 (68%)] Loss: -1545.906250\n",
      "Train Epoch: 491 [40960/54000 (76%)] Loss: -1545.051758\n",
      "Train Epoch: 491 [45056/54000 (83%)] Loss: -1542.713257\n",
      "Train Epoch: 491 [49152/54000 (91%)] Loss: -1546.201904\n",
      "Train Epoch: 491 [53248/54000 (99%)] Loss: -1553.855713\n",
      "    epoch          : 491\n",
      "    loss           : -1543.339743085382\n",
      "    ess            : 3.784012954946943\n",
      "    log_marginal   : 1543.4743068026141\n",
      "    val_loss       : -1542.7523701985676\n",
      "    val_ess        : 3.7821250359217324\n",
      "    val_log_marginal: 1542.8862915039062\n",
      "Train Epoch: 492 [0/54000 (0%)] Loss: -1539.385742\n",
      "Train Epoch: 492 [4096/54000 (8%)] Loss: -1544.488770\n",
      "Train Epoch: 492 [8192/54000 (15%)] Loss: -1544.572998\n",
      "Train Epoch: 492 [12288/54000 (23%)] Loss: -1543.263428\n",
      "Train Epoch: 492 [16384/54000 (30%)] Loss: -1541.229614\n",
      "Train Epoch: 492 [20480/54000 (38%)] Loss: -1539.058960\n",
      "Train Epoch: 492 [24576/54000 (46%)] Loss: -1548.853516\n",
      "Train Epoch: 492 [28672/54000 (53%)] Loss: -1544.512207\n",
      "Train Epoch: 492 [32768/54000 (61%)] Loss: -1542.808105\n",
      "Train Epoch: 492 [36864/54000 (68%)] Loss: -1551.420654\n",
      "Train Epoch: 492 [40960/54000 (76%)] Loss: -1543.015869\n",
      "Train Epoch: 492 [45056/54000 (83%)] Loss: -1551.061523\n",
      "Train Epoch: 492 [49152/54000 (91%)] Loss: -1543.573486\n",
      "Train Epoch: 492 [53248/54000 (99%)] Loss: -1547.636353\n",
      "    epoch          : 492\n",
      "    loss           : -1543.5392424235413\n",
      "    ess            : 3.780988398321432\n",
      "    log_marginal   : 1543.675779514403\n",
      "    val_loss       : -1543.2774251302083\n",
      "    val_ess        : 3.786383271217346\n",
      "    val_log_marginal: 1543.4170786539714\n",
      "Train Epoch: 493 [0/54000 (0%)] Loss: -1541.474854\n",
      "Train Epoch: 493 [4096/54000 (8%)] Loss: -1540.263428\n",
      "Train Epoch: 493 [8192/54000 (15%)] Loss: -1546.155518\n",
      "Train Epoch: 493 [12288/54000 (23%)] Loss: -1538.207764\n",
      "Train Epoch: 493 [16384/54000 (30%)] Loss: -1545.929688\n",
      "Train Epoch: 493 [20480/54000 (38%)] Loss: -1535.587646\n",
      "Train Epoch: 493 [24576/54000 (46%)] Loss: -1536.652100\n",
      "Train Epoch: 493 [28672/54000 (53%)] Loss: -1545.122925\n",
      "Train Epoch: 493 [32768/54000 (61%)] Loss: -1549.848755\n",
      "Train Epoch: 493 [36864/54000 (68%)] Loss: -1545.539307\n",
      "Train Epoch: 493 [40960/54000 (76%)] Loss: -1542.704468\n",
      "Train Epoch: 493 [45056/54000 (83%)] Loss: -1548.612305\n",
      "Train Epoch: 493 [49152/54000 (91%)] Loss: -1539.513672\n",
      "Train Epoch: 493 [53248/54000 (99%)] Loss: -1547.849609\n",
      "    epoch          : 493\n",
      "    loss           : -1543.6848260237707\n",
      "    ess            : 3.7818690950836618\n",
      "    log_marginal   : 1543.8221198348638\n",
      "    val_loss       : -1543.4999135335286\n",
      "    val_ess        : 3.774855633576711\n",
      "    val_log_marginal: 1543.6519266764324\n",
      "Train Epoch: 494 [0/54000 (0%)] Loss: -1545.236084\n",
      "Train Epoch: 494 [4096/54000 (8%)] Loss: -1535.996704\n",
      "Train Epoch: 494 [8192/54000 (15%)] Loss: -1541.920166\n",
      "Train Epoch: 494 [12288/54000 (23%)] Loss: -1543.425293\n",
      "Train Epoch: 494 [16384/54000 (30%)] Loss: -1552.352295\n",
      "Train Epoch: 494 [20480/54000 (38%)] Loss: -1540.748169\n",
      "Train Epoch: 494 [24576/54000 (46%)] Loss: -1539.906738\n",
      "Train Epoch: 494 [28672/54000 (53%)] Loss: -1542.971313\n",
      "Train Epoch: 494 [32768/54000 (61%)] Loss: -1542.461548\n",
      "Train Epoch: 494 [36864/54000 (68%)] Loss: -1542.770874\n",
      "Train Epoch: 494 [40960/54000 (76%)] Loss: -1537.975708\n",
      "Train Epoch: 494 [45056/54000 (83%)] Loss: -1544.122192\n",
      "Train Epoch: 494 [49152/54000 (91%)] Loss: -1539.515015\n",
      "Train Epoch: 494 [53248/54000 (99%)] Loss: -1546.286133\n",
      "    epoch          : 494\n",
      "    loss           : -1543.4663959521254\n",
      "    ess            : 3.781296827216849\n",
      "    log_marginal   : 1543.6066576338492\n",
      "    val_loss       : -1544.1012725830078\n",
      "    val_ess        : 3.779592494169871\n",
      "    val_log_marginal: 1544.2297261555989\n",
      "Train Epoch: 495 [0/54000 (0%)] Loss: -1537.730225\n",
      "Train Epoch: 495 [4096/54000 (8%)] Loss: -1543.682983\n",
      "Train Epoch: 495 [8192/54000 (15%)] Loss: -1544.874023\n",
      "Train Epoch: 495 [12288/54000 (23%)] Loss: -1543.500732\n",
      "Train Epoch: 495 [16384/54000 (30%)] Loss: -1540.269165\n",
      "Train Epoch: 495 [20480/54000 (38%)] Loss: -1541.758057\n",
      "Train Epoch: 495 [24576/54000 (46%)] Loss: -1546.235962\n",
      "Train Epoch: 495 [28672/54000 (53%)] Loss: -1543.341553\n",
      "Train Epoch: 495 [32768/54000 (61%)] Loss: -1544.239258\n",
      "Train Epoch: 495 [36864/54000 (68%)] Loss: -1537.996948\n",
      "Train Epoch: 495 [40960/54000 (76%)] Loss: -1541.019653\n",
      "Train Epoch: 495 [45056/54000 (83%)] Loss: -1537.813477\n",
      "Train Epoch: 495 [49152/54000 (91%)] Loss: -1546.435303\n",
      "Train Epoch: 495 [53248/54000 (99%)] Loss: -1544.617310\n",
      "    epoch          : 495\n",
      "    loss           : -1543.5989243927725\n",
      "    ess            : 3.7823637673075163\n",
      "    log_marginal   : 1543.7356871112263\n",
      "    val_loss       : -1543.1826680501301\n",
      "    val_ess        : 3.7625662684440613\n",
      "    val_log_marginal: 1543.339090983073\n",
      "Train Epoch: 496 [0/54000 (0%)] Loss: -1543.321411\n",
      "Train Epoch: 496 [4096/54000 (8%)] Loss: -1541.690918\n",
      "Train Epoch: 496 [8192/54000 (15%)] Loss: -1545.492920\n",
      "Train Epoch: 496 [12288/54000 (23%)] Loss: -1543.010620\n",
      "Train Epoch: 496 [16384/54000 (30%)] Loss: -1547.153442\n",
      "Train Epoch: 496 [20480/54000 (38%)] Loss: -1542.795166\n",
      "Train Epoch: 496 [24576/54000 (46%)] Loss: -1549.896729\n",
      "Train Epoch: 496 [28672/54000 (53%)] Loss: -1549.092407\n",
      "Train Epoch: 496 [32768/54000 (61%)] Loss: -1542.542969\n",
      "Train Epoch: 496 [36864/54000 (68%)] Loss: -1546.201416\n",
      "Train Epoch: 496 [40960/54000 (76%)] Loss: -1548.132080\n",
      "Train Epoch: 496 [45056/54000 (83%)] Loss: -1542.812012\n",
      "Train Epoch: 496 [49152/54000 (91%)] Loss: -1541.300537\n",
      "Train Epoch: 496 [53248/54000 (99%)] Loss: -1538.903931\n",
      "    epoch          : 496\n",
      "    loss           : -1543.8512223230155\n",
      "    ess            : 3.781448897592264\n",
      "    log_marginal   : 1543.9866040849008\n",
      "    val_loss       : -1543.2300415039062\n",
      "    val_ess        : 3.7793881793816886\n",
      "    val_log_marginal: 1543.3670959472656\n",
      "Train Epoch: 497 [0/54000 (0%)] Loss: -1537.271118\n",
      "Train Epoch: 497 [4096/54000 (8%)] Loss: -1548.046265\n",
      "Train Epoch: 497 [8192/54000 (15%)] Loss: -1543.078857\n",
      "Train Epoch: 497 [12288/54000 (23%)] Loss: -1540.427734\n",
      "Train Epoch: 497 [16384/54000 (30%)] Loss: -1543.321533\n",
      "Train Epoch: 497 [20480/54000 (38%)] Loss: -1546.773926\n",
      "Train Epoch: 497 [24576/54000 (46%)] Loss: -1535.762695\n",
      "Train Epoch: 497 [28672/54000 (53%)] Loss: -1548.671387\n",
      "Train Epoch: 497 [32768/54000 (61%)] Loss: -1545.380127\n",
      "Train Epoch: 497 [36864/54000 (68%)] Loss: -1548.527344\n",
      "Train Epoch: 497 [40960/54000 (76%)] Loss: -1548.241089\n",
      "Train Epoch: 497 [45056/54000 (83%)] Loss: -1540.427490\n",
      "Train Epoch: 497 [49152/54000 (91%)] Loss: -1543.751587\n",
      "Train Epoch: 497 [53248/54000 (99%)] Loss: -1545.329712\n",
      "    epoch          : 497\n",
      "    loss           : -1544.061809810982\n",
      "    ess            : 3.780723076861052\n",
      "    log_marginal   : 1544.1997278584124\n",
      "    val_loss       : -1542.5053151448567\n",
      "    val_ess        : 3.7826769053936005\n",
      "    val_log_marginal: 1542.6413167317708\n",
      "Train Epoch: 498 [0/54000 (0%)] Loss: -1547.955811\n",
      "Train Epoch: 498 [4096/54000 (8%)] Loss: -1539.609863\n",
      "Train Epoch: 498 [8192/54000 (15%)] Loss: -1550.025879\n",
      "Train Epoch: 498 [12288/54000 (23%)] Loss: -1539.538940\n",
      "Train Epoch: 498 [16384/54000 (30%)] Loss: -1552.036865\n",
      "Train Epoch: 498 [20480/54000 (38%)] Loss: -1549.882690\n",
      "Train Epoch: 498 [24576/54000 (46%)] Loss: -1545.220825\n",
      "Train Epoch: 498 [28672/54000 (53%)] Loss: -1542.733887\n",
      "Train Epoch: 498 [32768/54000 (61%)] Loss: -1543.983765\n",
      "Train Epoch: 498 [36864/54000 (68%)] Loss: -1546.981812\n",
      "Train Epoch: 498 [40960/54000 (76%)] Loss: -1542.039307\n",
      "Train Epoch: 498 [45056/54000 (83%)] Loss: -1536.299072\n",
      "Train Epoch: 498 [49152/54000 (91%)] Loss: -1548.940918\n",
      "Train Epoch: 498 [53248/54000 (99%)] Loss: -1546.367432\n",
      "    epoch          : 498\n",
      "    loss           : -1543.9443816415508\n",
      "    ess            : 3.786871937213916\n",
      "    log_marginal   : 1544.073435995816\n",
      "    val_loss       : -1543.9092203776042\n",
      "    val_ess        : 3.774656265974045\n",
      "    val_log_marginal: 1544.046666463216\n",
      "Train Epoch: 499 [0/54000 (0%)] Loss: -1542.050537\n",
      "Train Epoch: 499 [4096/54000 (8%)] Loss: -1543.638428\n",
      "Train Epoch: 499 [8192/54000 (15%)] Loss: -1545.547607\n",
      "Train Epoch: 499 [12288/54000 (23%)] Loss: -1540.655151\n",
      "Train Epoch: 499 [16384/54000 (30%)] Loss: -1546.728516\n",
      "Train Epoch: 499 [20480/54000 (38%)] Loss: -1547.273926\n",
      "Train Epoch: 499 [24576/54000 (46%)] Loss: -1545.037354\n",
      "Train Epoch: 499 [28672/54000 (53%)] Loss: -1542.481201\n",
      "Train Epoch: 499 [32768/54000 (61%)] Loss: -1543.939697\n",
      "Train Epoch: 499 [36864/54000 (68%)] Loss: -1545.955078\n",
      "Train Epoch: 499 [40960/54000 (76%)] Loss: -1542.136719\n",
      "Train Epoch: 499 [45056/54000 (83%)] Loss: -1541.566162\n",
      "Train Epoch: 499 [49152/54000 (91%)] Loss: -1540.516235\n",
      "Train Epoch: 499 [53248/54000 (99%)] Loss: -1546.005615\n",
      "    epoch          : 499\n",
      "    loss           : -1544.0708470638328\n",
      "    ess            : 3.781119208765256\n",
      "    log_marginal   : 1544.2108298929948\n",
      "    val_loss       : -1543.5396169026692\n",
      "    val_ess        : 3.784749060869217\n",
      "    val_log_marginal: 1543.6700948079426\n",
      "Train Epoch: 500 [0/54000 (0%)] Loss: -1550.052002\n",
      "Train Epoch: 500 [4096/54000 (8%)] Loss: -1544.107666\n",
      "Train Epoch: 500 [8192/54000 (15%)] Loss: -1541.620850\n",
      "Train Epoch: 500 [12288/54000 (23%)] Loss: -1538.966064\n",
      "Train Epoch: 500 [16384/54000 (30%)] Loss: -1546.178101\n",
      "Train Epoch: 500 [20480/54000 (38%)] Loss: -1547.477783\n",
      "Train Epoch: 500 [24576/54000 (46%)] Loss: -1547.436401\n",
      "Train Epoch: 500 [28672/54000 (53%)] Loss: -1544.266113\n",
      "Train Epoch: 500 [32768/54000 (61%)] Loss: -1546.878784\n",
      "Train Epoch: 500 [36864/54000 (68%)] Loss: -1544.793823\n",
      "Train Epoch: 500 [40960/54000 (76%)] Loss: -1540.127686\n",
      "Train Epoch: 500 [45056/54000 (83%)] Loss: -1544.787842\n",
      "Train Epoch: 500 [49152/54000 (91%)] Loss: -1541.965576\n",
      "Train Epoch: 500 [53248/54000 (99%)] Loss: -1544.471680\n",
      "    epoch          : 500\n",
      "    loss           : -1544.134186514181\n",
      "    ess            : 3.7853129667128433\n",
      "    log_marginal   : 1544.2708329476452\n",
      "    val_loss       : -1544.3850962320964\n",
      "    val_ess        : 3.7880427141984305\n",
      "    val_log_marginal: 1544.5165608723958\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch500.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 501 [0/54000 (0%)] Loss: -1546.956787\n",
      "Train Epoch: 501 [4096/54000 (8%)] Loss: -1536.273438\n",
      "Train Epoch: 501 [8192/54000 (15%)] Loss: -1545.885986\n",
      "Train Epoch: 501 [12288/54000 (23%)] Loss: -1548.272949\n",
      "Train Epoch: 501 [16384/54000 (30%)] Loss: -1546.504395\n",
      "Train Epoch: 501 [20480/54000 (38%)] Loss: -1543.362915\n",
      "Train Epoch: 501 [24576/54000 (46%)] Loss: -1555.270020\n",
      "Train Epoch: 501 [28672/54000 (53%)] Loss: -1550.514282\n",
      "Train Epoch: 501 [32768/54000 (61%)] Loss: -1550.255859\n",
      "Train Epoch: 501 [36864/54000 (68%)] Loss: -1542.308594\n",
      "Train Epoch: 501 [40960/54000 (76%)] Loss: -1547.616943\n",
      "Train Epoch: 501 [45056/54000 (83%)] Loss: -1538.978516\n",
      "Train Epoch: 501 [49152/54000 (91%)] Loss: -1545.454834\n",
      "Train Epoch: 501 [53248/54000 (99%)] Loss: -1543.356445\n",
      "    epoch          : 501\n",
      "    loss           : -1544.4740759682315\n",
      "    ess            : 3.7812919096924116\n",
      "    log_marginal   : 1544.611071835197\n",
      "    val_loss       : -1544.5184529622395\n",
      "    val_ess        : 3.7745045522848764\n",
      "    val_log_marginal: 1544.6585998535156\n",
      "Train Epoch: 502 [0/54000 (0%)] Loss: -1548.338257\n",
      "Train Epoch: 502 [4096/54000 (8%)] Loss: -1547.178833\n",
      "Train Epoch: 502 [8192/54000 (15%)] Loss: -1549.197754\n",
      "Train Epoch: 502 [12288/54000 (23%)] Loss: -1542.574951\n",
      "Train Epoch: 502 [16384/54000 (30%)] Loss: -1540.418579\n",
      "Train Epoch: 502 [20480/54000 (38%)] Loss: -1551.665894\n",
      "Train Epoch: 502 [24576/54000 (46%)] Loss: -1544.802979\n",
      "Train Epoch: 502 [28672/54000 (53%)] Loss: -1549.892944\n",
      "Train Epoch: 502 [32768/54000 (61%)] Loss: -1540.627197\n",
      "Train Epoch: 502 [36864/54000 (68%)] Loss: -1539.093140\n",
      "Train Epoch: 502 [40960/54000 (76%)] Loss: -1534.166504\n",
      "Train Epoch: 502 [45056/54000 (83%)] Loss: -1538.553833\n",
      "Train Epoch: 502 [49152/54000 (91%)] Loss: -1543.877930\n",
      "Train Epoch: 502 [53248/54000 (99%)] Loss: -1537.622070\n",
      "    epoch          : 502\n",
      "    loss           : -1544.730608176281\n",
      "    ess            : 3.78609607908963\n",
      "    log_marginal   : 1544.8623243575978\n",
      "    val_loss       : -1543.9180857340496\n",
      "    val_ess        : 3.7802219788233438\n",
      "    val_log_marginal: 1544.0475260416667\n",
      "Train Epoch: 503 [0/54000 (0%)] Loss: -1534.666382\n",
      "Train Epoch: 503 [4096/54000 (8%)] Loss: -1546.045898\n",
      "Train Epoch: 503 [8192/54000 (15%)] Loss: -1544.094360\n",
      "Train Epoch: 503 [12288/54000 (23%)] Loss: -1539.710449\n",
      "Train Epoch: 503 [16384/54000 (30%)] Loss: -1540.573730\n",
      "Train Epoch: 503 [20480/54000 (38%)] Loss: -1544.211548\n",
      "Train Epoch: 503 [24576/54000 (46%)] Loss: -1547.847778\n",
      "Train Epoch: 503 [28672/54000 (53%)] Loss: -1548.415771\n",
      "Train Epoch: 503 [32768/54000 (61%)] Loss: -1547.073486\n",
      "Train Epoch: 503 [36864/54000 (68%)] Loss: -1535.966797\n",
      "Train Epoch: 503 [40960/54000 (76%)] Loss: -1537.095703\n",
      "Train Epoch: 503 [45056/54000 (83%)] Loss: -1547.558594\n",
      "Train Epoch: 503 [49152/54000 (91%)] Loss: -1548.295044\n",
      "Train Epoch: 503 [53248/54000 (99%)] Loss: -1547.239380\n",
      "    epoch          : 503\n",
      "    loss           : -1544.3696468407509\n",
      "    ess            : 3.785991700339656\n",
      "    log_marginal   : 1544.5033711076348\n",
      "    val_loss       : -1543.7648417154949\n",
      "    val_ess        : 3.770723263422648\n",
      "    val_log_marginal: 1543.9035542805989\n",
      "Train Epoch: 504 [0/54000 (0%)] Loss: -1547.734131\n",
      "Train Epoch: 504 [4096/54000 (8%)] Loss: -1542.239746\n",
      "Train Epoch: 504 [8192/54000 (15%)] Loss: -1543.711548\n",
      "Train Epoch: 504 [12288/54000 (23%)] Loss: -1536.420898\n",
      "Train Epoch: 504 [16384/54000 (30%)] Loss: -1541.548340\n",
      "Train Epoch: 504 [20480/54000 (38%)] Loss: -1545.537842\n",
      "Train Epoch: 504 [24576/54000 (46%)] Loss: -1544.759766\n",
      "Train Epoch: 504 [28672/54000 (53%)] Loss: -1542.039307\n",
      "Train Epoch: 504 [32768/54000 (61%)] Loss: -1546.484985\n",
      "Train Epoch: 504 [36864/54000 (68%)] Loss: -1545.987549\n",
      "Train Epoch: 504 [40960/54000 (76%)] Loss: -1551.718140\n",
      "Train Epoch: 504 [45056/54000 (83%)] Loss: -1548.828735\n",
      "Train Epoch: 504 [49152/54000 (91%)] Loss: -1539.711548\n",
      "Train Epoch: 504 [53248/54000 (99%)] Loss: -1544.383057\n",
      "    epoch          : 504\n",
      "    loss           : -1544.5630519198016\n",
      "    ess            : 3.7811363839425183\n",
      "    log_marginal   : 1544.6980998685574\n",
      "    val_loss       : -1544.9114023844402\n",
      "    val_ess        : 3.7793373465538025\n",
      "    val_log_marginal: 1545.0440165201824\n",
      "Train Epoch: 505 [0/54000 (0%)] Loss: -1541.228760\n",
      "Train Epoch: 505 [4096/54000 (8%)] Loss: -1549.025635\n",
      "Train Epoch: 505 [8192/54000 (15%)] Loss: -1545.665283\n",
      "Train Epoch: 505 [12288/54000 (23%)] Loss: -1547.822388\n",
      "Train Epoch: 505 [16384/54000 (30%)] Loss: -1545.680420\n",
      "Train Epoch: 505 [20480/54000 (38%)] Loss: -1540.892578\n",
      "Train Epoch: 505 [24576/54000 (46%)] Loss: -1539.553833\n",
      "Train Epoch: 505 [28672/54000 (53%)] Loss: -1541.781006\n",
      "Train Epoch: 505 [32768/54000 (61%)] Loss: -1543.799316\n",
      "Train Epoch: 505 [36864/54000 (68%)] Loss: -1539.770996\n",
      "Train Epoch: 505 [40960/54000 (76%)] Loss: -1549.315552\n",
      "Train Epoch: 505 [45056/54000 (83%)] Loss: -1538.726440\n",
      "Train Epoch: 505 [49152/54000 (91%)] Loss: -1548.613281\n",
      "Train Epoch: 505 [53248/54000 (99%)] Loss: -1542.998535\n",
      "    epoch          : 505\n",
      "    loss           : -1544.6254067081975\n",
      "    ess            : 3.7838432800148336\n",
      "    log_marginal   : 1544.759959433316\n",
      "    val_loss       : -1544.1905059814453\n",
      "    val_ess        : 3.7816185553868613\n",
      "    val_log_marginal: 1544.3164469401042\n",
      "Train Epoch: 506 [0/54000 (0%)] Loss: -1536.507202\n",
      "Train Epoch: 506 [4096/54000 (8%)] Loss: -1551.842285\n",
      "Train Epoch: 506 [8192/54000 (15%)] Loss: -1547.199707\n",
      "Train Epoch: 506 [12288/54000 (23%)] Loss: -1541.328369\n",
      "Train Epoch: 506 [16384/54000 (30%)] Loss: -1545.352295\n",
      "Train Epoch: 506 [20480/54000 (38%)] Loss: -1549.874023\n",
      "Train Epoch: 506 [24576/54000 (46%)] Loss: -1541.576660\n",
      "Train Epoch: 506 [28672/54000 (53%)] Loss: -1546.342041\n",
      "Train Epoch: 506 [32768/54000 (61%)] Loss: -1546.082031\n",
      "Train Epoch: 506 [36864/54000 (68%)] Loss: -1537.787720\n",
      "Train Epoch: 506 [40960/54000 (76%)] Loss: -1548.613281\n",
      "Train Epoch: 506 [45056/54000 (83%)] Loss: -1542.684204\n",
      "Train Epoch: 506 [49152/54000 (91%)] Loss: -1546.066406\n",
      "Train Epoch: 506 [53248/54000 (99%)] Loss: -1549.143311\n",
      "    epoch          : 506\n",
      "    loss           : -1544.8088569821905\n",
      "    ess            : 3.7821665883629243\n",
      "    log_marginal   : 1544.948231773919\n",
      "    val_loss       : -1544.7696787516277\n",
      "    val_ess        : 3.7887423038482666\n",
      "    val_log_marginal: 1544.8988800048828\n",
      "Train Epoch: 507 [0/54000 (0%)] Loss: -1548.440308\n",
      "Train Epoch: 507 [4096/54000 (8%)] Loss: -1550.662720\n",
      "Train Epoch: 507 [8192/54000 (15%)] Loss: -1543.706543\n",
      "Train Epoch: 507 [12288/54000 (23%)] Loss: -1548.855103\n",
      "Train Epoch: 507 [16384/54000 (30%)] Loss: -1541.547119\n",
      "Train Epoch: 507 [20480/54000 (38%)] Loss: -1542.077881\n",
      "Train Epoch: 507 [24576/54000 (46%)] Loss: -1543.960693\n",
      "Train Epoch: 507 [28672/54000 (53%)] Loss: -1543.532593\n",
      "Train Epoch: 507 [32768/54000 (61%)] Loss: -1547.707153\n",
      "Train Epoch: 507 [36864/54000 (68%)] Loss: -1544.647949\n",
      "Train Epoch: 507 [40960/54000 (76%)] Loss: -1542.901489\n",
      "Train Epoch: 507 [45056/54000 (83%)] Loss: -1540.661743\n",
      "Train Epoch: 507 [49152/54000 (91%)] Loss: -1548.332275\n",
      "Train Epoch: 507 [53248/54000 (99%)] Loss: -1549.714844\n",
      "    epoch          : 507\n",
      "    loss           : -1544.9645857246\n",
      "    ess            : 3.783300430288812\n",
      "    log_marginal   : 1545.0973097091603\n",
      "    val_loss       : -1543.1561787923176\n",
      "    val_ess        : 3.7909595469633737\n",
      "    val_log_marginal: 1543.2879892985027\n",
      "Train Epoch: 508 [0/54000 (0%)] Loss: -1546.044434\n",
      "Train Epoch: 508 [4096/54000 (8%)] Loss: -1549.177246\n",
      "Train Epoch: 508 [8192/54000 (15%)] Loss: -1551.819336\n",
      "Train Epoch: 508 [12288/54000 (23%)] Loss: -1543.280273\n",
      "Train Epoch: 508 [16384/54000 (30%)] Loss: -1550.106445\n",
      "Train Epoch: 508 [20480/54000 (38%)] Loss: -1544.814453\n",
      "Train Epoch: 508 [24576/54000 (46%)] Loss: -1541.229736\n",
      "Train Epoch: 508 [28672/54000 (53%)] Loss: -1540.541870\n",
      "Train Epoch: 508 [32768/54000 (61%)] Loss: -1543.014648\n",
      "Train Epoch: 508 [36864/54000 (68%)] Loss: -1540.757568\n",
      "Train Epoch: 508 [40960/54000 (76%)] Loss: -1548.030518\n",
      "Train Epoch: 508 [45056/54000 (83%)] Loss: -1541.656738\n",
      "Train Epoch: 508 [49152/54000 (91%)] Loss: -1546.277588\n",
      "Train Epoch: 508 [53248/54000 (99%)] Loss: -1540.537231\n",
      "    epoch          : 508\n",
      "    loss           : -1545.0838565193646\n",
      "    ess            : 3.7810809860862262\n",
      "    log_marginal   : 1545.22040460234\n",
      "    val_loss       : -1544.2628835042317\n",
      "    val_ess        : 3.7855022251605988\n",
      "    val_log_marginal: 1544.4022776285808\n",
      "Train Epoch: 509 [0/54000 (0%)] Loss: -1542.497681\n",
      "Train Epoch: 509 [4096/54000 (8%)] Loss: -1546.115479\n",
      "Train Epoch: 509 [8192/54000 (15%)] Loss: -1545.754150\n",
      "Train Epoch: 509 [12288/54000 (23%)] Loss: -1549.711426\n",
      "Train Epoch: 509 [16384/54000 (30%)] Loss: -1545.388428\n",
      "Train Epoch: 509 [20480/54000 (38%)] Loss: -1545.831055\n",
      "Train Epoch: 509 [24576/54000 (46%)] Loss: -1549.161865\n",
      "Train Epoch: 509 [28672/54000 (53%)] Loss: -1545.064819\n",
      "Train Epoch: 509 [32768/54000 (61%)] Loss: -1548.475830\n",
      "Train Epoch: 509 [36864/54000 (68%)] Loss: -1554.120239\n",
      "Train Epoch: 509 [40960/54000 (76%)] Loss: -1544.190430\n",
      "Train Epoch: 509 [45056/54000 (83%)] Loss: -1548.048706\n",
      "Train Epoch: 509 [49152/54000 (91%)] Loss: -1545.821167\n",
      "Train Epoch: 509 [53248/54000 (99%)] Loss: -1543.259766\n",
      "    epoch          : 509\n",
      "    loss           : -1545.0459100081457\n",
      "    ess            : 3.785055537924382\n",
      "    log_marginal   : 1545.1811349877814\n",
      "    val_loss       : -1543.8202819824219\n",
      "    val_ess        : 3.7854753732681274\n",
      "    val_log_marginal: 1543.9623311360676\n",
      "Train Epoch: 510 [0/54000 (0%)] Loss: -1536.547241\n",
      "Train Epoch: 510 [4096/54000 (8%)] Loss: -1544.892212\n",
      "Train Epoch: 510 [8192/54000 (15%)] Loss: -1546.821289\n",
      "Train Epoch: 510 [12288/54000 (23%)] Loss: -1538.712769\n",
      "Train Epoch: 510 [16384/54000 (30%)] Loss: -1544.406616\n",
      "Train Epoch: 510 [20480/54000 (38%)] Loss: -1545.130371\n",
      "Train Epoch: 510 [24576/54000 (46%)] Loss: -1544.656494\n",
      "Train Epoch: 510 [28672/54000 (53%)] Loss: -1550.996826\n",
      "Train Epoch: 510 [32768/54000 (61%)] Loss: -1538.654297\n",
      "Train Epoch: 510 [36864/54000 (68%)] Loss: -1547.958740\n",
      "Train Epoch: 510 [40960/54000 (76%)] Loss: -1544.794678\n",
      "Train Epoch: 510 [45056/54000 (83%)] Loss: -1542.268188\n",
      "Train Epoch: 510 [49152/54000 (91%)] Loss: -1550.230591\n",
      "Train Epoch: 510 [53248/54000 (99%)] Loss: -1547.226440\n",
      "    epoch          : 510\n",
      "    loss           : -1545.312996380702\n",
      "    ess            : 3.7821401295503736\n",
      "    log_marginal   : 1545.450603177762\n",
      "    val_loss       : -1545.8750864664714\n",
      "    val_ess        : 3.800467441479365\n",
      "    val_log_marginal: 1545.998779296875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch510.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 511 [0/54000 (0%)] Loss: -1550.119385\n",
      "Train Epoch: 511 [4096/54000 (8%)] Loss: -1540.383301\n",
      "Train Epoch: 511 [8192/54000 (15%)] Loss: -1545.642212\n",
      "Train Epoch: 511 [12288/54000 (23%)] Loss: -1550.760132\n",
      "Train Epoch: 511 [16384/54000 (30%)] Loss: -1542.234497\n",
      "Train Epoch: 511 [20480/54000 (38%)] Loss: -1548.232544\n",
      "Train Epoch: 511 [24576/54000 (46%)] Loss: -1540.368408\n",
      "Train Epoch: 511 [28672/54000 (53%)] Loss: -1535.403442\n",
      "Train Epoch: 511 [32768/54000 (61%)] Loss: -1546.614502\n",
      "Train Epoch: 511 [36864/54000 (68%)] Loss: -1541.843994\n",
      "Train Epoch: 511 [40960/54000 (76%)] Loss: -1545.620605\n",
      "Train Epoch: 511 [45056/54000 (83%)] Loss: -1545.504639\n",
      "Train Epoch: 511 [49152/54000 (91%)] Loss: -1546.893066\n",
      "Train Epoch: 511 [53248/54000 (99%)] Loss: -1544.983398\n",
      "    epoch          : 511\n",
      "    loss           : -1545.244576259812\n",
      "    ess            : 3.7805310290006666\n",
      "    log_marginal   : 1545.3807147419284\n",
      "    val_loss       : -1544.8394673665364\n",
      "    val_ess        : 3.7996215224266052\n",
      "    val_log_marginal: 1544.9622344970703\n",
      "Train Epoch: 512 [0/54000 (0%)] Loss: -1541.100464\n",
      "Train Epoch: 512 [4096/54000 (8%)] Loss: -1546.617188\n",
      "Train Epoch: 512 [8192/54000 (15%)] Loss: -1546.253174\n",
      "Train Epoch: 512 [12288/54000 (23%)] Loss: -1545.214844\n",
      "Train Epoch: 512 [16384/54000 (30%)] Loss: -1548.165283\n",
      "Train Epoch: 512 [20480/54000 (38%)] Loss: -1548.457031\n",
      "Train Epoch: 512 [24576/54000 (46%)] Loss: -1546.137207\n",
      "Train Epoch: 512 [28672/54000 (53%)] Loss: -1552.593506\n",
      "Train Epoch: 512 [32768/54000 (61%)] Loss: -1540.050781\n",
      "Train Epoch: 512 [36864/54000 (68%)] Loss: -1541.763550\n",
      "Train Epoch: 512 [40960/54000 (76%)] Loss: -1544.450928\n",
      "Train Epoch: 512 [45056/54000 (83%)] Loss: -1547.476440\n",
      "Train Epoch: 512 [49152/54000 (91%)] Loss: -1541.161255\n",
      "Train Epoch: 512 [53248/54000 (99%)] Loss: -1547.406982\n",
      "    epoch          : 512\n",
      "    loss           : -1545.505524404806\n",
      "    ess            : 3.780685375087069\n",
      "    log_marginal   : 1545.6452347452607\n",
      "    val_loss       : -1545.1085561116536\n",
      "    val_ess        : 3.782813330491384\n",
      "    val_log_marginal: 1545.2446950276692\n",
      "Train Epoch: 513 [0/54000 (0%)] Loss: -1549.089478\n",
      "Train Epoch: 513 [4096/54000 (8%)] Loss: -1544.151367\n",
      "Train Epoch: 513 [8192/54000 (15%)] Loss: -1551.969849\n",
      "Train Epoch: 513 [12288/54000 (23%)] Loss: -1544.839844\n",
      "Train Epoch: 513 [16384/54000 (30%)] Loss: -1547.666260\n",
      "Train Epoch: 513 [20480/54000 (38%)] Loss: -1541.569580\n",
      "Train Epoch: 513 [24576/54000 (46%)] Loss: -1542.403809\n",
      "Train Epoch: 513 [28672/54000 (53%)] Loss: -1542.952881\n",
      "Train Epoch: 513 [32768/54000 (61%)] Loss: -1542.322021\n",
      "Train Epoch: 513 [36864/54000 (68%)] Loss: -1542.031494\n",
      "Train Epoch: 513 [40960/54000 (76%)] Loss: -1546.844238\n",
      "Train Epoch: 513 [45056/54000 (83%)] Loss: -1547.376221\n",
      "Train Epoch: 513 [49152/54000 (91%)] Loss: -1544.481689\n",
      "Train Epoch: 513 [53248/54000 (99%)] Loss: -1548.024780\n",
      "    epoch          : 513\n",
      "    loss           : -1545.2812262801763\n",
      "    ess            : 3.786744512087926\n",
      "    log_marginal   : 1545.4160937268587\n",
      "    val_loss       : -1545.094970703125\n",
      "    val_ess        : 3.7781018813451133\n",
      "    val_log_marginal: 1545.2394104003906\n",
      "Train Epoch: 514 [0/54000 (0%)] Loss: -1549.338379\n",
      "Train Epoch: 514 [4096/54000 (8%)] Loss: -1547.040283\n",
      "Train Epoch: 514 [8192/54000 (15%)] Loss: -1543.331543\n",
      "Train Epoch: 514 [12288/54000 (23%)] Loss: -1549.315674\n",
      "Train Epoch: 514 [16384/54000 (30%)] Loss: -1550.908203\n",
      "Train Epoch: 514 [20480/54000 (38%)] Loss: -1547.275635\n",
      "Train Epoch: 514 [24576/54000 (46%)] Loss: -1546.600342\n",
      "Train Epoch: 514 [28672/54000 (53%)] Loss: -1544.911865\n",
      "Train Epoch: 514 [32768/54000 (61%)] Loss: -1542.062012\n",
      "Train Epoch: 514 [36864/54000 (68%)] Loss: -1546.578613\n",
      "Train Epoch: 514 [40960/54000 (76%)] Loss: -1548.795166\n",
      "Train Epoch: 514 [45056/54000 (83%)] Loss: -1545.681519\n",
      "Train Epoch: 514 [49152/54000 (91%)] Loss: -1543.376465\n",
      "Train Epoch: 514 [53248/54000 (99%)] Loss: -1546.085693\n",
      "    epoch          : 514\n",
      "    loss           : -1545.3778272872853\n",
      "    ess            : 3.7809073179254034\n",
      "    log_marginal   : 1545.5170782731043\n",
      "    val_loss       : -1545.1924285888672\n",
      "    val_ess        : 3.7924658556779227\n",
      "    val_log_marginal: 1545.319091796875\n",
      "Train Epoch: 515 [0/54000 (0%)] Loss: -1543.423218\n",
      "Train Epoch: 515 [4096/54000 (8%)] Loss: -1543.176758\n",
      "Train Epoch: 515 [8192/54000 (15%)] Loss: -1540.809570\n",
      "Train Epoch: 515 [12288/54000 (23%)] Loss: -1542.722656\n",
      "Train Epoch: 515 [16384/54000 (30%)] Loss: -1543.194580\n",
      "Train Epoch: 515 [20480/54000 (38%)] Loss: -1547.787109\n",
      "Train Epoch: 515 [24576/54000 (46%)] Loss: -1542.719116\n",
      "Train Epoch: 515 [28672/54000 (53%)] Loss: -1550.517334\n",
      "Train Epoch: 515 [32768/54000 (61%)] Loss: -1539.757812\n",
      "Train Epoch: 515 [36864/54000 (68%)] Loss: -1544.152832\n",
      "Train Epoch: 515 [40960/54000 (76%)] Loss: -1549.962891\n",
      "Train Epoch: 515 [45056/54000 (83%)] Loss: -1541.283447\n",
      "Train Epoch: 515 [49152/54000 (91%)] Loss: -1547.403931\n",
      "Train Epoch: 515 [53248/54000 (99%)] Loss: -1545.044678\n",
      "    epoch          : 515\n",
      "    loss           : -1545.3777613346047\n",
      "    ess            : 3.7805177306676927\n",
      "    log_marginal   : 1545.5162116317388\n",
      "    val_loss       : -1544.1197306315105\n",
      "    val_ess        : 3.775306314229965\n",
      "    val_log_marginal: 1544.26171875\n",
      "Train Epoch: 516 [0/54000 (0%)] Loss: -1548.498901\n",
      "Train Epoch: 516 [4096/54000 (8%)] Loss: -1544.314331\n",
      "Train Epoch: 516 [8192/54000 (15%)] Loss: -1547.389160\n",
      "Train Epoch: 516 [12288/54000 (23%)] Loss: -1541.573364\n",
      "Train Epoch: 516 [16384/54000 (30%)] Loss: -1551.881348\n",
      "Train Epoch: 516 [20480/54000 (38%)] Loss: -1540.588379\n",
      "Train Epoch: 516 [24576/54000 (46%)] Loss: -1541.105225\n",
      "Train Epoch: 516 [28672/54000 (53%)] Loss: -1546.390625\n",
      "Train Epoch: 516 [32768/54000 (61%)] Loss: -1548.500977\n",
      "Train Epoch: 516 [36864/54000 (68%)] Loss: -1544.893311\n",
      "Train Epoch: 516 [40960/54000 (76%)] Loss: -1546.451904\n",
      "Train Epoch: 516 [45056/54000 (83%)] Loss: -1547.898560\n",
      "Train Epoch: 516 [49152/54000 (91%)] Loss: -1552.115479\n",
      "Train Epoch: 516 [53248/54000 (99%)] Loss: -1540.404053\n",
      "    epoch          : 516\n",
      "    loss           : -1545.5807920338418\n",
      "    ess            : 3.783681877416457\n",
      "    log_marginal   : 1545.7160297411879\n",
      "    val_loss       : -1545.2960459391277\n",
      "    val_ess        : 3.7645762165387473\n",
      "    val_log_marginal: 1545.450892130534\n",
      "Train Epoch: 517 [0/54000 (0%)] Loss: -1543.305420\n",
      "Train Epoch: 517 [4096/54000 (8%)] Loss: -1542.396362\n",
      "Train Epoch: 517 [8192/54000 (15%)] Loss: -1541.217285\n",
      "Train Epoch: 517 [12288/54000 (23%)] Loss: -1545.224121\n",
      "Train Epoch: 517 [16384/54000 (30%)] Loss: -1539.543945\n",
      "Train Epoch: 517 [20480/54000 (38%)] Loss: -1549.348389\n",
      "Train Epoch: 517 [24576/54000 (46%)] Loss: -1541.484863\n",
      "Train Epoch: 517 [28672/54000 (53%)] Loss: -1547.726929\n",
      "Train Epoch: 517 [32768/54000 (61%)] Loss: -1541.567383\n",
      "Train Epoch: 517 [36864/54000 (68%)] Loss: -1549.554688\n",
      "Train Epoch: 517 [40960/54000 (76%)] Loss: -1544.803589\n",
      "Train Epoch: 517 [45056/54000 (83%)] Loss: -1545.312256\n",
      "Train Epoch: 517 [49152/54000 (91%)] Loss: -1545.887451\n",
      "Train Epoch: 517 [53248/54000 (99%)] Loss: -1546.399658\n",
      "    epoch          : 517\n",
      "    loss           : -1545.8266347008293\n",
      "    ess            : 3.781058662875569\n",
      "    log_marginal   : 1545.964224141921\n",
      "    val_loss       : -1545.7327219645183\n",
      "    val_ess        : 3.800573170185089\n",
      "    val_log_marginal: 1545.8594818115234\n",
      "Train Epoch: 518 [0/54000 (0%)] Loss: -1546.657227\n",
      "Train Epoch: 518 [4096/54000 (8%)] Loss: -1549.312500\n",
      "Train Epoch: 518 [8192/54000 (15%)] Loss: -1541.389893\n",
      "Train Epoch: 518 [12288/54000 (23%)] Loss: -1548.399414\n",
      "Train Epoch: 518 [16384/54000 (30%)] Loss: -1553.765869\n",
      "Train Epoch: 518 [20480/54000 (38%)] Loss: -1552.293213\n",
      "Train Epoch: 518 [24576/54000 (46%)] Loss: -1543.061890\n",
      "Train Epoch: 518 [28672/54000 (53%)] Loss: -1540.716675\n",
      "Train Epoch: 518 [32768/54000 (61%)] Loss: -1541.478760\n",
      "Train Epoch: 518 [36864/54000 (68%)] Loss: -1537.447510\n",
      "Train Epoch: 518 [40960/54000 (76%)] Loss: -1548.381104\n",
      "Train Epoch: 518 [45056/54000 (83%)] Loss: -1547.878418\n",
      "Train Epoch: 518 [49152/54000 (91%)] Loss: -1545.000977\n",
      "Train Epoch: 518 [53248/54000 (99%)] Loss: -1547.774292\n",
      "    epoch          : 518\n",
      "    loss           : -1545.5349878971047\n",
      "    ess            : 3.780619990769156\n",
      "    log_marginal   : 1545.6684049633443\n",
      "    val_loss       : -1544.7046915690105\n",
      "    val_ess        : 3.7855440179506936\n",
      "    val_log_marginal: 1544.8391927083333\n",
      "Train Epoch: 519 [0/54000 (0%)] Loss: -1547.644897\n",
      "Train Epoch: 519 [4096/54000 (8%)] Loss: -1543.425415\n",
      "Train Epoch: 519 [8192/54000 (15%)] Loss: -1544.186157\n",
      "Train Epoch: 519 [12288/54000 (23%)] Loss: -1543.204712\n",
      "Train Epoch: 519 [16384/54000 (30%)] Loss: -1551.767456\n",
      "Train Epoch: 519 [20480/54000 (38%)] Loss: -1546.107178\n",
      "Train Epoch: 519 [24576/54000 (46%)] Loss: -1540.677490\n",
      "Train Epoch: 519 [28672/54000 (53%)] Loss: -1542.488281\n",
      "Train Epoch: 519 [32768/54000 (61%)] Loss: -1545.995361\n",
      "Train Epoch: 519 [36864/54000 (68%)] Loss: -1545.875488\n",
      "Train Epoch: 519 [40960/54000 (76%)] Loss: -1548.339111\n",
      "Train Epoch: 519 [45056/54000 (83%)] Loss: -1545.780884\n",
      "Train Epoch: 519 [49152/54000 (91%)] Loss: -1548.414307\n",
      "Train Epoch: 519 [53248/54000 (99%)] Loss: -1547.651245\n",
      "    epoch          : 519\n",
      "    loss           : -1545.5404232079384\n",
      "    ess            : 3.7862663020454876\n",
      "    log_marginal   : 1545.674211691906\n",
      "    val_loss       : -1547.032958984375\n",
      "    val_ess        : 3.781354526678721\n",
      "    val_log_marginal: 1547.1751251220703\n",
      "Train Epoch: 520 [0/54000 (0%)] Loss: -1539.607422\n",
      "Train Epoch: 520 [4096/54000 (8%)] Loss: -1550.865234\n",
      "Train Epoch: 520 [8192/54000 (15%)] Loss: -1545.358643\n",
      "Train Epoch: 520 [12288/54000 (23%)] Loss: -1553.195312\n",
      "Train Epoch: 520 [16384/54000 (30%)] Loss: -1539.366943\n",
      "Train Epoch: 520 [20480/54000 (38%)] Loss: -1544.700439\n",
      "Train Epoch: 520 [24576/54000 (46%)] Loss: -1542.974854\n",
      "Train Epoch: 520 [28672/54000 (53%)] Loss: -1547.251221\n",
      "Train Epoch: 520 [32768/54000 (61%)] Loss: -1547.146973\n",
      "Train Epoch: 520 [36864/54000 (68%)] Loss: -1541.085083\n",
      "Train Epoch: 520 [40960/54000 (76%)] Loss: -1548.277832\n",
      "Train Epoch: 520 [45056/54000 (83%)] Loss: -1544.925049\n",
      "Train Epoch: 520 [49152/54000 (91%)] Loss: -1547.481079\n",
      "Train Epoch: 520 [53248/54000 (99%)] Loss: -1541.823486\n",
      "    epoch          : 520\n",
      "    loss           : -1545.7070578624853\n",
      "    ess            : 3.781650488975489\n",
      "    log_marginal   : 1545.8433849461271\n",
      "    val_loss       : -1545.5208079020183\n",
      "    val_ess        : 3.769109696149826\n",
      "    val_log_marginal: 1545.663553873698\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch520.pth ...\n",
      "Train Epoch: 521 [0/54000 (0%)] Loss: -1543.875000\n",
      "Train Epoch: 521 [4096/54000 (8%)] Loss: -1542.965820\n",
      "Train Epoch: 521 [8192/54000 (15%)] Loss: -1545.804443\n",
      "Train Epoch: 521 [12288/54000 (23%)] Loss: -1543.497070\n",
      "Train Epoch: 521 [16384/54000 (30%)] Loss: -1546.711426\n",
      "Train Epoch: 521 [20480/54000 (38%)] Loss: -1545.166992\n",
      "Train Epoch: 521 [24576/54000 (46%)] Loss: -1548.998535\n",
      "Train Epoch: 521 [28672/54000 (53%)] Loss: -1550.990845\n",
      "Train Epoch: 521 [32768/54000 (61%)] Loss: -1546.194214\n",
      "Train Epoch: 521 [36864/54000 (68%)] Loss: -1545.951660\n",
      "Train Epoch: 521 [40960/54000 (76%)] Loss: -1550.622925\n",
      "Train Epoch: 521 [45056/54000 (83%)] Loss: -1548.474121\n",
      "Train Epoch: 521 [49152/54000 (91%)] Loss: -1549.667725\n",
      "Train Epoch: 521 [53248/54000 (99%)] Loss: -1545.498779\n",
      "    epoch          : 521\n",
      "    loss           : -1545.935290585197\n",
      "    ess            : 3.7838406754895972\n",
      "    log_marginal   : 1546.0687747611819\n",
      "    val_loss       : -1545.9283142089844\n",
      "    val_ess        : 3.769050935904185\n",
      "    val_log_marginal: 1546.0759684244792\n",
      "Train Epoch: 522 [0/54000 (0%)] Loss: -1548.003052\n",
      "Train Epoch: 522 [4096/54000 (8%)] Loss: -1544.781006\n",
      "Train Epoch: 522 [8192/54000 (15%)] Loss: -1550.595947\n",
      "Train Epoch: 522 [12288/54000 (23%)] Loss: -1545.474487\n",
      "Train Epoch: 522 [16384/54000 (30%)] Loss: -1547.211670\n",
      "Train Epoch: 522 [20480/54000 (38%)] Loss: -1544.658936\n",
      "Train Epoch: 522 [24576/54000 (46%)] Loss: -1541.746582\n",
      "Train Epoch: 522 [28672/54000 (53%)] Loss: -1541.564453\n",
      "Train Epoch: 522 [32768/54000 (61%)] Loss: -1550.289551\n",
      "Train Epoch: 522 [36864/54000 (68%)] Loss: -1548.786133\n",
      "Train Epoch: 522 [40960/54000 (76%)] Loss: -1544.295532\n",
      "Train Epoch: 522 [45056/54000 (83%)] Loss: -1551.223999\n",
      "Train Epoch: 522 [49152/54000 (91%)] Loss: -1545.150879\n",
      "Train Epoch: 522 [53248/54000 (99%)] Loss: -1541.057129\n",
      "    epoch          : 522\n",
      "    loss           : -1546.0520800549837\n",
      "    ess            : 3.7820292988094675\n",
      "    log_marginal   : 1546.18926336641\n",
      "    val_loss       : -1545.2103780110676\n",
      "    val_ess        : 3.79317315419515\n",
      "    val_log_marginal: 1545.325647989909\n",
      "Train Epoch: 523 [0/54000 (0%)] Loss: -1545.110107\n",
      "Train Epoch: 523 [4096/54000 (8%)] Loss: -1552.899170\n",
      "Train Epoch: 523 [8192/54000 (15%)] Loss: -1547.486816\n",
      "Train Epoch: 523 [12288/54000 (23%)] Loss: -1540.845459\n",
      "Train Epoch: 523 [16384/54000 (30%)] Loss: -1537.955811\n",
      "Train Epoch: 523 [20480/54000 (38%)] Loss: -1546.068115\n",
      "Train Epoch: 523 [24576/54000 (46%)] Loss: -1541.844238\n",
      "Train Epoch: 523 [28672/54000 (53%)] Loss: -1550.379395\n",
      "Train Epoch: 523 [32768/54000 (61%)] Loss: -1554.321777\n",
      "Train Epoch: 523 [36864/54000 (68%)] Loss: -1545.112793\n",
      "Train Epoch: 523 [40960/54000 (76%)] Loss: -1549.080566\n",
      "Train Epoch: 523 [45056/54000 (83%)] Loss: -1544.316650\n",
      "Train Epoch: 523 [49152/54000 (91%)] Loss: -1552.814941\n",
      "Train Epoch: 523 [53248/54000 (99%)] Loss: -1545.439575\n",
      "    epoch          : 523\n",
      "    loss           : -1546.2531888699646\n",
      "    ess            : 3.778507318541902\n",
      "    log_marginal   : 1546.3917404102488\n",
      "    val_loss       : -1546.221176147461\n",
      "    val_ess        : 3.7933426102002463\n",
      "    val_log_marginal: 1546.3461151123047\n",
      "Train Epoch: 524 [0/54000 (0%)] Loss: -1538.232666\n",
      "Train Epoch: 524 [4096/54000 (8%)] Loss: -1540.900269\n",
      "Train Epoch: 524 [8192/54000 (15%)] Loss: -1548.718262\n",
      "Train Epoch: 524 [12288/54000 (23%)] Loss: -1548.292358\n",
      "Train Epoch: 524 [16384/54000 (30%)] Loss: -1547.056396\n",
      "Train Epoch: 524 [20480/54000 (38%)] Loss: -1537.629883\n",
      "Train Epoch: 524 [24576/54000 (46%)] Loss: -1546.473999\n",
      "Train Epoch: 524 [28672/54000 (53%)] Loss: -1550.188843\n",
      "Train Epoch: 524 [32768/54000 (61%)] Loss: -1541.083618\n",
      "Train Epoch: 524 [36864/54000 (68%)] Loss: -1546.384888\n",
      "Train Epoch: 524 [40960/54000 (76%)] Loss: -1548.250488\n",
      "Train Epoch: 524 [45056/54000 (83%)] Loss: -1546.680176\n",
      "Train Epoch: 524 [49152/54000 (91%)] Loss: -1547.076294\n",
      "Train Epoch: 524 [53248/54000 (99%)] Loss: -1548.951416\n",
      "    epoch          : 524\n",
      "    loss           : -1546.2824805381738\n",
      "    ess            : 3.7858891283731326\n",
      "    log_marginal   : 1546.4133578476747\n",
      "    val_loss       : -1544.9826253255208\n",
      "    val_ess        : 3.7941165765126548\n",
      "    val_log_marginal: 1545.117955525716\n",
      "Train Epoch: 525 [0/54000 (0%)] Loss: -1542.525757\n",
      "Train Epoch: 525 [4096/54000 (8%)] Loss: -1555.694824\n",
      "Train Epoch: 525 [8192/54000 (15%)] Loss: -1547.962891\n",
      "Train Epoch: 525 [12288/54000 (23%)] Loss: -1543.957520\n",
      "Train Epoch: 525 [16384/54000 (30%)] Loss: -1545.023682\n",
      "Train Epoch: 525 [20480/54000 (38%)] Loss: -1548.098267\n",
      "Train Epoch: 525 [24576/54000 (46%)] Loss: -1540.383057\n",
      "Train Epoch: 525 [28672/54000 (53%)] Loss: -1542.557861\n",
      "Train Epoch: 525 [32768/54000 (61%)] Loss: -1538.144775\n",
      "Train Epoch: 525 [36864/54000 (68%)] Loss: -1545.256348\n",
      "Train Epoch: 525 [40960/54000 (76%)] Loss: -1548.676514\n",
      "Train Epoch: 525 [45056/54000 (83%)] Loss: -1546.150635\n",
      "Train Epoch: 525 [49152/54000 (91%)] Loss: -1554.365356\n",
      "Train Epoch: 525 [53248/54000 (99%)] Loss: -1546.957642\n",
      "    epoch          : 525\n",
      "    loss           : -1546.1134958854784\n",
      "    ess            : 3.783919514073015\n",
      "    log_marginal   : 1546.2532131683206\n",
      "    val_loss       : -1545.6086324055989\n",
      "    val_ess        : 3.7834678888320923\n",
      "    val_log_marginal: 1545.74609375\n",
      "Train Epoch: 526 [0/54000 (0%)] Loss: -1544.085938\n",
      "Train Epoch: 526 [4096/54000 (8%)] Loss: -1544.058594\n",
      "Train Epoch: 526 [8192/54000 (15%)] Loss: -1549.316650\n",
      "Train Epoch: 526 [12288/54000 (23%)] Loss: -1546.563721\n",
      "Train Epoch: 526 [16384/54000 (30%)] Loss: -1543.774658\n",
      "Train Epoch: 526 [20480/54000 (38%)] Loss: -1546.026245\n",
      "Train Epoch: 526 [24576/54000 (46%)] Loss: -1552.864990\n",
      "Train Epoch: 526 [28672/54000 (53%)] Loss: -1547.498657\n",
      "Train Epoch: 526 [32768/54000 (61%)] Loss: -1543.907959\n",
      "Train Epoch: 526 [36864/54000 (68%)] Loss: -1544.121704\n",
      "Train Epoch: 526 [40960/54000 (76%)] Loss: -1550.058594\n",
      "Train Epoch: 526 [45056/54000 (83%)] Loss: -1544.757324\n",
      "Train Epoch: 526 [49152/54000 (91%)] Loss: -1546.020142\n",
      "Train Epoch: 526 [53248/54000 (99%)] Loss: -1547.794067\n",
      "    epoch          : 526\n",
      "    loss           : -1546.198779065462\n",
      "    ess            : 3.7873279890177938\n",
      "    log_marginal   : 1546.3291183399363\n",
      "    val_loss       : -1545.4945576985676\n",
      "    val_ess        : 3.7812692721684775\n",
      "    val_log_marginal: 1545.6244049072266\n",
      "Train Epoch: 527 [0/54000 (0%)] Loss: -1541.318848\n",
      "Train Epoch: 527 [4096/54000 (8%)] Loss: -1543.387207\n",
      "Train Epoch: 527 [8192/54000 (15%)] Loss: -1543.646729\n",
      "Train Epoch: 527 [12288/54000 (23%)] Loss: -1550.629761\n",
      "Train Epoch: 527 [16384/54000 (30%)] Loss: -1548.698730\n",
      "Train Epoch: 527 [20480/54000 (38%)] Loss: -1543.424805\n",
      "Train Epoch: 527 [24576/54000 (46%)] Loss: -1547.431030\n",
      "Train Epoch: 527 [28672/54000 (53%)] Loss: -1543.614014\n",
      "Train Epoch: 527 [32768/54000 (61%)] Loss: -1544.545654\n",
      "Train Epoch: 527 [36864/54000 (68%)] Loss: -1555.391235\n",
      "Train Epoch: 527 [40960/54000 (76%)] Loss: -1537.797852\n",
      "Train Epoch: 527 [45056/54000 (83%)] Loss: -1542.486084\n",
      "Train Epoch: 527 [49152/54000 (91%)] Loss: -1555.450806\n",
      "Train Epoch: 527 [53248/54000 (99%)] Loss: -1544.823364\n",
      "    epoch          : 527\n",
      "    loss           : -1546.2949872491483\n",
      "    ess            : 3.78040807620044\n",
      "    log_marginal   : 1546.4328566998668\n",
      "    val_loss       : -1545.3970336914062\n",
      "    val_ess        : 3.7806268334388733\n",
      "    val_log_marginal: 1545.5384419759114\n",
      "Train Epoch: 528 [0/54000 (0%)] Loss: -1548.133423\n",
      "Train Epoch: 528 [4096/54000 (8%)] Loss: -1549.206055\n",
      "Train Epoch: 528 [8192/54000 (15%)] Loss: -1545.972900\n",
      "Train Epoch: 528 [12288/54000 (23%)] Loss: -1544.234009\n",
      "Train Epoch: 528 [16384/54000 (30%)] Loss: -1545.097046\n",
      "Train Epoch: 528 [20480/54000 (38%)] Loss: -1544.391846\n",
      "Train Epoch: 528 [24576/54000 (46%)] Loss: -1546.666382\n",
      "Train Epoch: 528 [28672/54000 (53%)] Loss: -1548.023315\n",
      "Train Epoch: 528 [32768/54000 (61%)] Loss: -1544.807007\n",
      "Train Epoch: 528 [36864/54000 (68%)] Loss: -1552.831909\n",
      "Train Epoch: 528 [40960/54000 (76%)] Loss: -1546.051758\n",
      "Train Epoch: 528 [45056/54000 (83%)] Loss: -1540.915039\n",
      "Train Epoch: 528 [49152/54000 (91%)] Loss: -1541.656250\n",
      "Train Epoch: 528 [53248/54000 (99%)] Loss: -1543.897705\n",
      "    epoch          : 528\n",
      "    loss           : -1546.3571968259405\n",
      "    ess            : 3.7838722382676546\n",
      "    log_marginal   : 1546.4903240475044\n",
      "    val_loss       : -1546.207290649414\n",
      "    val_ess        : 3.7892929514249167\n",
      "    val_log_marginal: 1546.344009399414\n",
      "Train Epoch: 529 [0/54000 (0%)] Loss: -1543.534912\n",
      "Train Epoch: 529 [4096/54000 (8%)] Loss: -1540.942749\n",
      "Train Epoch: 529 [8192/54000 (15%)] Loss: -1543.821045\n",
      "Train Epoch: 529 [12288/54000 (23%)] Loss: -1548.295288\n",
      "Train Epoch: 529 [16384/54000 (30%)] Loss: -1548.008057\n",
      "Train Epoch: 529 [20480/54000 (38%)] Loss: -1546.324707\n",
      "Train Epoch: 529 [24576/54000 (46%)] Loss: -1542.620605\n",
      "Train Epoch: 529 [28672/54000 (53%)] Loss: -1538.081177\n",
      "Train Epoch: 529 [32768/54000 (61%)] Loss: -1555.452148\n",
      "Train Epoch: 529 [36864/54000 (68%)] Loss: -1547.069336\n",
      "Train Epoch: 529 [40960/54000 (76%)] Loss: -1546.599365\n",
      "Train Epoch: 529 [45056/54000 (83%)] Loss: -1548.295166\n",
      "Train Epoch: 529 [49152/54000 (91%)] Loss: -1546.627075\n",
      "Train Epoch: 529 [53248/54000 (99%)] Loss: -1543.569580\n",
      "    epoch          : 529\n",
      "    loss           : -1546.5776517605896\n",
      "    ess            : 3.7850315412638875\n",
      "    log_marginal   : 1546.7139314045837\n",
      "    val_loss       : -1546.0731150309246\n",
      "    val_ess        : 3.782110780477524\n",
      "    val_log_marginal: 1546.214604695638\n",
      "Train Epoch: 530 [0/54000 (0%)] Loss: -1550.253662\n",
      "Train Epoch: 530 [4096/54000 (8%)] Loss: -1546.734253\n",
      "Train Epoch: 530 [8192/54000 (15%)] Loss: -1545.894775\n",
      "Train Epoch: 530 [12288/54000 (23%)] Loss: -1538.718628\n",
      "Train Epoch: 530 [16384/54000 (30%)] Loss: -1550.567871\n",
      "Train Epoch: 530 [20480/54000 (38%)] Loss: -1544.876465\n",
      "Train Epoch: 530 [24576/54000 (46%)] Loss: -1549.942383\n",
      "Train Epoch: 530 [28672/54000 (53%)] Loss: -1541.911255\n",
      "Train Epoch: 530 [32768/54000 (61%)] Loss: -1547.236816\n",
      "Train Epoch: 530 [36864/54000 (68%)] Loss: -1545.441162\n",
      "Train Epoch: 530 [40960/54000 (76%)] Loss: -1549.151367\n",
      "Train Epoch: 530 [45056/54000 (83%)] Loss: -1544.154297\n",
      "Train Epoch: 530 [49152/54000 (91%)] Loss: -1547.097168\n",
      "Train Epoch: 530 [53248/54000 (99%)] Loss: -1545.911377\n",
      "    epoch          : 530\n",
      "    loss           : -1546.264568021512\n",
      "    ess            : 3.782310110697814\n",
      "    log_marginal   : 1546.4031484884108\n",
      "    val_loss       : -1545.7883758544922\n",
      "    val_ess        : 3.790696640809377\n",
      "    val_log_marginal: 1545.9156595865886\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch530.pth ...\n",
      "Train Epoch: 531 [0/54000 (0%)] Loss: -1550.570312\n",
      "Train Epoch: 531 [4096/54000 (8%)] Loss: -1540.589233\n",
      "Train Epoch: 531 [8192/54000 (15%)] Loss: -1554.247803\n",
      "Train Epoch: 531 [12288/54000 (23%)] Loss: -1548.114502\n",
      "Train Epoch: 531 [16384/54000 (30%)] Loss: -1543.342773\n",
      "Train Epoch: 531 [20480/54000 (38%)] Loss: -1547.771973\n",
      "Train Epoch: 531 [24576/54000 (46%)] Loss: -1550.609131\n",
      "Train Epoch: 531 [28672/54000 (53%)] Loss: -1549.108154\n",
      "Train Epoch: 531 [32768/54000 (61%)] Loss: -1547.856934\n",
      "Train Epoch: 531 [36864/54000 (68%)] Loss: -1545.416260\n",
      "Train Epoch: 531 [40960/54000 (76%)] Loss: -1551.372803\n",
      "Train Epoch: 531 [45056/54000 (83%)] Loss: -1545.902344\n",
      "Train Epoch: 531 [49152/54000 (91%)] Loss: -1544.601440\n",
      "Train Epoch: 531 [53248/54000 (99%)] Loss: -1550.063599\n",
      "    epoch          : 531\n",
      "    loss           : -1547.9917449228008\n",
      "    ess            : 3.79014964578276\n",
      "    log_marginal   : 1548.1193992289323\n",
      "    val_loss       : -1547.6153259277344\n",
      "    val_ess        : 3.7805236180623374\n",
      "    val_log_marginal: 1547.7535349527996\n",
      "Train Epoch: 532 [0/54000 (0%)] Loss: -1542.080811\n",
      "Train Epoch: 532 [4096/54000 (8%)] Loss: -1551.626099\n",
      "Train Epoch: 532 [8192/54000 (15%)] Loss: -1553.678955\n",
      "Train Epoch: 532 [12288/54000 (23%)] Loss: -1546.970581\n",
      "Train Epoch: 532 [16384/54000 (30%)] Loss: -1550.767578\n",
      "Train Epoch: 532 [20480/54000 (38%)] Loss: -1551.501953\n",
      "Train Epoch: 532 [24576/54000 (46%)] Loss: -1550.346191\n",
      "Train Epoch: 532 [28672/54000 (53%)] Loss: -1550.973389\n",
      "Train Epoch: 532 [32768/54000 (61%)] Loss: -1543.996826\n",
      "Train Epoch: 532 [36864/54000 (68%)] Loss: -1550.692139\n",
      "Train Epoch: 532 [40960/54000 (76%)] Loss: -1550.747437\n",
      "Train Epoch: 532 [45056/54000 (83%)] Loss: -1550.196899\n",
      "Train Epoch: 532 [49152/54000 (91%)] Loss: -1547.323120\n",
      "Train Epoch: 532 [53248/54000 (99%)] Loss: -1549.048218\n",
      "    epoch          : 532\n",
      "    loss           : -1548.9572562990595\n",
      "    ess            : 3.7860526801285586\n",
      "    log_marginal   : 1549.0907352682539\n",
      "    val_loss       : -1548.528055826823\n",
      "    val_ess        : 3.7891533573468528\n",
      "    val_log_marginal: 1548.6617126464844\n",
      "Train Epoch: 533 [0/54000 (0%)] Loss: -1548.166870\n",
      "Train Epoch: 533 [4096/54000 (8%)] Loss: -1548.324829\n",
      "Train Epoch: 533 [8192/54000 (15%)] Loss: -1551.115234\n",
      "Train Epoch: 533 [12288/54000 (23%)] Loss: -1550.213379\n",
      "Train Epoch: 533 [16384/54000 (30%)] Loss: -1550.007446\n",
      "Train Epoch: 533 [20480/54000 (38%)] Loss: -1556.253906\n",
      "Train Epoch: 533 [24576/54000 (46%)] Loss: -1545.734863\n",
      "Train Epoch: 533 [28672/54000 (53%)] Loss: -1548.900513\n",
      "Train Epoch: 533 [32768/54000 (61%)] Loss: -1545.680542\n",
      "Train Epoch: 533 [36864/54000 (68%)] Loss: -1550.942383\n",
      "Train Epoch: 533 [40960/54000 (76%)] Loss: -1551.222412\n",
      "Train Epoch: 533 [45056/54000 (83%)] Loss: -1552.592407\n",
      "Train Epoch: 533 [49152/54000 (91%)] Loss: -1547.446777\n",
      "Train Epoch: 533 [53248/54000 (99%)] Loss: -1548.653931\n",
      "    epoch          : 533\n",
      "    loss           : -1549.5522709706383\n",
      "    ess            : 3.787825106444517\n",
      "    log_marginal   : 1549.6830476155212\n",
      "    val_loss       : -1548.4066365559895\n",
      "    val_ess        : 3.788690427939097\n",
      "    val_log_marginal: 1548.5350697835286\n",
      "Train Epoch: 534 [0/54000 (0%)] Loss: -1543.281128\n",
      "Train Epoch: 534 [4096/54000 (8%)] Loss: -1548.122314\n",
      "Train Epoch: 534 [8192/54000 (15%)] Loss: -1550.531250\n",
      "Train Epoch: 534 [12288/54000 (23%)] Loss: -1551.255737\n",
      "Train Epoch: 534 [16384/54000 (30%)] Loss: -1542.632324\n",
      "Train Epoch: 534 [20480/54000 (38%)] Loss: -1551.413330\n",
      "Train Epoch: 534 [24576/54000 (46%)] Loss: -1543.255737\n",
      "Train Epoch: 534 [28672/54000 (53%)] Loss: -1547.509277\n",
      "Train Epoch: 534 [32768/54000 (61%)] Loss: -1551.798584\n",
      "Train Epoch: 534 [36864/54000 (68%)] Loss: -1541.831055\n",
      "Train Epoch: 534 [40960/54000 (76%)] Loss: -1551.157471\n",
      "Train Epoch: 534 [45056/54000 (83%)] Loss: -1553.888672\n",
      "Train Epoch: 534 [49152/54000 (91%)] Loss: -1547.151978\n",
      "Train Epoch: 534 [53248/54000 (99%)] Loss: -1550.192139\n",
      "    epoch          : 534\n",
      "    loss           : -1549.867556603599\n",
      "    ess            : 3.7868916287806362\n",
      "    log_marginal   : 1549.9997523881814\n",
      "    val_loss       : -1549.382848103841\n",
      "    val_ess        : 3.7954146564006805\n",
      "    val_log_marginal: 1549.5013834635417\n",
      "Train Epoch: 535 [0/54000 (0%)] Loss: -1546.740112\n",
      "Train Epoch: 535 [4096/54000 (8%)] Loss: -1547.874756\n",
      "Train Epoch: 535 [8192/54000 (15%)] Loss: -1550.540283\n",
      "Train Epoch: 535 [12288/54000 (23%)] Loss: -1555.511230\n",
      "Train Epoch: 535 [16384/54000 (30%)] Loss: -1552.192383\n",
      "Train Epoch: 535 [20480/54000 (38%)] Loss: -1556.803223\n",
      "Train Epoch: 535 [24576/54000 (46%)] Loss: -1548.088623\n",
      "Train Epoch: 535 [28672/54000 (53%)] Loss: -1551.300903\n",
      "Train Epoch: 535 [32768/54000 (61%)] Loss: -1551.357178\n",
      "Train Epoch: 535 [36864/54000 (68%)] Loss: -1552.190552\n",
      "Train Epoch: 535 [40960/54000 (76%)] Loss: -1549.700317\n",
      "Train Epoch: 535 [45056/54000 (83%)] Loss: -1546.422852\n",
      "Train Epoch: 535 [49152/54000 (91%)] Loss: -1553.514404\n",
      "Train Epoch: 535 [53248/54000 (99%)] Loss: -1546.557495\n",
      "    epoch          : 535\n",
      "    loss           : -1550.2753507062723\n",
      "    ess            : 3.7910474352362034\n",
      "    log_marginal   : 1550.3991502517772\n",
      "    val_loss       : -1550.0876566569011\n",
      "    val_ess        : 3.7981682817141214\n",
      "    val_log_marginal: 1550.2166290283203\n",
      "Train Epoch: 536 [0/54000 (0%)] Loss: -1553.409912\n",
      "Train Epoch: 536 [4096/54000 (8%)] Loss: -1556.302002\n",
      "Train Epoch: 536 [8192/54000 (15%)] Loss: -1557.411987\n",
      "Train Epoch: 536 [12288/54000 (23%)] Loss: -1546.448730\n",
      "Train Epoch: 536 [16384/54000 (30%)] Loss: -1559.148926\n",
      "Train Epoch: 536 [20480/54000 (38%)] Loss: -1553.911865\n",
      "Train Epoch: 536 [24576/54000 (46%)] Loss: -1549.233887\n",
      "Train Epoch: 536 [28672/54000 (53%)] Loss: -1553.033813\n",
      "Train Epoch: 536 [32768/54000 (61%)] Loss: -1547.889526\n",
      "Train Epoch: 536 [36864/54000 (68%)] Loss: -1546.263184\n",
      "Train Epoch: 536 [40960/54000 (76%)] Loss: -1542.969727\n",
      "Train Epoch: 536 [45056/54000 (83%)] Loss: -1556.748657\n",
      "Train Epoch: 536 [49152/54000 (91%)] Loss: -1547.131836\n",
      "Train Epoch: 536 [53248/54000 (99%)] Loss: -1549.225708\n",
      "    epoch          : 536\n",
      "    loss           : -1550.6193298050578\n",
      "    ess            : 3.7868891101312863\n",
      "    log_marginal   : 1550.7548712418543\n",
      "    val_loss       : -1550.1093495686848\n",
      "    val_ess        : 3.78291247288386\n",
      "    val_log_marginal: 1550.2520395914714\n",
      "Train Epoch: 537 [0/54000 (0%)] Loss: -1546.218262\n",
      "Train Epoch: 537 [4096/54000 (8%)] Loss: -1552.563721\n",
      "Train Epoch: 537 [8192/54000 (15%)] Loss: -1544.609375\n",
      "Train Epoch: 537 [12288/54000 (23%)] Loss: -1545.549561\n",
      "Train Epoch: 537 [16384/54000 (30%)] Loss: -1552.619263\n",
      "Train Epoch: 537 [20480/54000 (38%)] Loss: -1545.742676\n",
      "Train Epoch: 537 [24576/54000 (46%)] Loss: -1558.637207\n",
      "Train Epoch: 537 [28672/54000 (53%)] Loss: -1553.924194\n",
      "Train Epoch: 537 [32768/54000 (61%)] Loss: -1547.556763\n",
      "Train Epoch: 537 [36864/54000 (68%)] Loss: -1553.049683\n",
      "Train Epoch: 537 [40960/54000 (76%)] Loss: -1543.420410\n",
      "Train Epoch: 537 [45056/54000 (83%)] Loss: -1547.029419\n",
      "Train Epoch: 537 [49152/54000 (91%)] Loss: -1554.733765\n",
      "Train Epoch: 537 [53248/54000 (99%)] Loss: -1550.061279\n",
      "    epoch          : 537\n",
      "    loss           : -1550.6743279768957\n",
      "    ess            : 3.785674040916407\n",
      "    log_marginal   : 1550.8056652195646\n",
      "    val_loss       : -1551.0480651855469\n",
      "    val_ess        : 3.76597007115682\n",
      "    val_log_marginal: 1551.1859181722004\n",
      "Train Epoch: 538 [0/54000 (0%)] Loss: -1546.528076\n",
      "Train Epoch: 538 [4096/54000 (8%)] Loss: -1550.840454\n",
      "Train Epoch: 538 [8192/54000 (15%)] Loss: -1549.089722\n",
      "Train Epoch: 538 [12288/54000 (23%)] Loss: -1556.385742\n",
      "Train Epoch: 538 [16384/54000 (30%)] Loss: -1551.993652\n",
      "Train Epoch: 538 [20480/54000 (38%)] Loss: -1544.510986\n",
      "Train Epoch: 538 [24576/54000 (46%)] Loss: -1550.684326\n",
      "Train Epoch: 538 [28672/54000 (53%)] Loss: -1548.793457\n",
      "Train Epoch: 538 [32768/54000 (61%)] Loss: -1549.352051\n",
      "Train Epoch: 538 [36864/54000 (68%)] Loss: -1554.110596\n",
      "Train Epoch: 538 [40960/54000 (76%)] Loss: -1547.614014\n",
      "Train Epoch: 538 [45056/54000 (83%)] Loss: -1551.122803\n",
      "Train Epoch: 538 [49152/54000 (91%)] Loss: -1548.833252\n",
      "Train Epoch: 538 [53248/54000 (99%)] Loss: -1548.220337\n",
      "    epoch          : 538\n",
      "    loss           : -1550.88506414766\n",
      "    ess            : 3.78619404200694\n",
      "    log_marginal   : 1551.0181364086568\n",
      "    val_loss       : -1550.9366658528645\n",
      "    val_ess        : 3.8073766926924386\n",
      "    val_log_marginal: 1551.0447031656902\n",
      "Train Epoch: 539 [0/54000 (0%)] Loss: -1558.719849\n",
      "Train Epoch: 539 [4096/54000 (8%)] Loss: -1549.346802\n",
      "Train Epoch: 539 [8192/54000 (15%)] Loss: -1550.481445\n",
      "Train Epoch: 539 [12288/54000 (23%)] Loss: -1553.200439\n",
      "Train Epoch: 539 [16384/54000 (30%)] Loss: -1550.333252\n",
      "Train Epoch: 539 [20480/54000 (38%)] Loss: -1552.386108\n",
      "Train Epoch: 539 [24576/54000 (46%)] Loss: -1550.435059\n",
      "Train Epoch: 539 [28672/54000 (53%)] Loss: -1557.491699\n",
      "Train Epoch: 539 [32768/54000 (61%)] Loss: -1545.274170\n",
      "Train Epoch: 539 [36864/54000 (68%)] Loss: -1546.614258\n",
      "Train Epoch: 539 [40960/54000 (76%)] Loss: -1549.307983\n",
      "Train Epoch: 539 [45056/54000 (83%)] Loss: -1557.125610\n",
      "Train Epoch: 539 [49152/54000 (91%)] Loss: -1554.487793\n",
      "Train Epoch: 539 [53248/54000 (99%)] Loss: -1544.641602\n",
      "    epoch          : 539\n",
      "    loss           : -1551.061549471453\n",
      "    ess            : 3.786111503980736\n",
      "    log_marginal   : 1551.1968710659805\n",
      "    val_loss       : -1550.1602376302083\n",
      "    val_ess        : 3.7898566921552024\n",
      "    val_log_marginal: 1550.2846272786458\n",
      "Train Epoch: 540 [0/54000 (0%)] Loss: -1553.370361\n",
      "Train Epoch: 540 [4096/54000 (8%)] Loss: -1554.311279\n",
      "Train Epoch: 540 [8192/54000 (15%)] Loss: -1550.214111\n",
      "Train Epoch: 540 [12288/54000 (23%)] Loss: -1555.010986\n",
      "Train Epoch: 540 [16384/54000 (30%)] Loss: -1550.132812\n",
      "Train Epoch: 540 [20480/54000 (38%)] Loss: -1546.282715\n",
      "Train Epoch: 540 [24576/54000 (46%)] Loss: -1550.538330\n",
      "Train Epoch: 540 [28672/54000 (53%)] Loss: -1554.838257\n",
      "Train Epoch: 540 [32768/54000 (61%)] Loss: -1555.421753\n",
      "Train Epoch: 540 [36864/54000 (68%)] Loss: -1551.973022\n",
      "Train Epoch: 540 [40960/54000 (76%)] Loss: -1550.366089\n",
      "Train Epoch: 540 [45056/54000 (83%)] Loss: -1548.067261\n",
      "Train Epoch: 540 [49152/54000 (91%)] Loss: -1544.792480\n",
      "Train Epoch: 540 [53248/54000 (99%)] Loss: -1552.509399\n",
      "    epoch          : 540\n",
      "    loss           : -1551.0031541580272\n",
      "    ess            : 3.7901647825376683\n",
      "    log_marginal   : 1551.1353736624333\n",
      "    val_loss       : -1551.0972849527996\n",
      "    val_ess        : 3.7979839742183685\n",
      "    val_log_marginal: 1551.2293039957683\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch540.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 541 [0/54000 (0%)] Loss: -1555.726318\n",
      "Train Epoch: 541 [4096/54000 (8%)] Loss: -1557.417603\n",
      "Train Epoch: 541 [8192/54000 (15%)] Loss: -1550.722168\n",
      "Train Epoch: 541 [12288/54000 (23%)] Loss: -1551.426147\n",
      "Train Epoch: 541 [16384/54000 (30%)] Loss: -1554.188232\n",
      "Train Epoch: 541 [20480/54000 (38%)] Loss: -1551.280518\n",
      "Train Epoch: 541 [24576/54000 (46%)] Loss: -1549.901489\n",
      "Train Epoch: 541 [28672/54000 (53%)] Loss: -1556.292847\n",
      "Train Epoch: 541 [32768/54000 (61%)] Loss: -1550.366943\n",
      "Train Epoch: 541 [36864/54000 (68%)] Loss: -1546.975586\n",
      "Train Epoch: 541 [40960/54000 (76%)] Loss: -1559.244141\n",
      "Train Epoch: 541 [45056/54000 (83%)] Loss: -1549.597900\n",
      "Train Epoch: 541 [49152/54000 (91%)] Loss: -1541.670044\n",
      "Train Epoch: 541 [53248/54000 (99%)] Loss: -1549.099487\n",
      "    epoch          : 541\n",
      "    loss           : -1551.517626721712\n",
      "    ess            : 3.7890973147622784\n",
      "    log_marginal   : 1551.6483397280435\n",
      "    val_loss       : -1550.6207427978516\n",
      "    val_ess        : 3.7832585275173187\n",
      "    val_log_marginal: 1550.7496083577473\n",
      "Train Epoch: 542 [0/54000 (0%)] Loss: -1549.251953\n",
      "Train Epoch: 542 [4096/54000 (8%)] Loss: -1551.788086\n",
      "Train Epoch: 542 [8192/54000 (15%)] Loss: -1547.198730\n",
      "Train Epoch: 542 [12288/54000 (23%)] Loss: -1549.675781\n",
      "Train Epoch: 542 [16384/54000 (30%)] Loss: -1552.543701\n",
      "Train Epoch: 542 [20480/54000 (38%)] Loss: -1548.940918\n",
      "Train Epoch: 542 [24576/54000 (46%)] Loss: -1551.256592\n",
      "Train Epoch: 542 [28672/54000 (53%)] Loss: -1558.837646\n",
      "Train Epoch: 542 [32768/54000 (61%)] Loss: -1545.135254\n",
      "Train Epoch: 542 [36864/54000 (68%)] Loss: -1546.995117\n",
      "Train Epoch: 542 [40960/54000 (76%)] Loss: -1544.689087\n",
      "Train Epoch: 542 [45056/54000 (83%)] Loss: -1544.783447\n",
      "Train Epoch: 542 [49152/54000 (91%)] Loss: -1550.317139\n",
      "Train Epoch: 542 [53248/54000 (99%)] Loss: -1558.762939\n",
      "    epoch          : 542\n",
      "    loss           : -1551.3772950375815\n",
      "    ess            : 3.7831090400569245\n",
      "    log_marginal   : 1551.5130192905806\n",
      "    val_loss       : -1551.0200449625652\n",
      "    val_ess        : 3.788274109363556\n",
      "    val_log_marginal: 1551.1509806315105\n",
      "Train Epoch: 543 [0/54000 (0%)] Loss: -1557.525146\n",
      "Train Epoch: 543 [4096/54000 (8%)] Loss: -1551.088623\n",
      "Train Epoch: 543 [8192/54000 (15%)] Loss: -1550.137207\n",
      "Train Epoch: 543 [12288/54000 (23%)] Loss: -1551.714600\n",
      "Train Epoch: 543 [16384/54000 (30%)] Loss: -1551.267822\n",
      "Train Epoch: 543 [20480/54000 (38%)] Loss: -1553.073608\n",
      "Train Epoch: 543 [24576/54000 (46%)] Loss: -1559.725220\n",
      "Train Epoch: 543 [28672/54000 (53%)] Loss: -1555.165771\n",
      "Train Epoch: 543 [32768/54000 (61%)] Loss: -1553.287109\n",
      "Train Epoch: 543 [36864/54000 (68%)] Loss: -1542.604980\n",
      "Train Epoch: 543 [40960/54000 (76%)] Loss: -1551.256226\n",
      "Train Epoch: 543 [45056/54000 (83%)] Loss: -1554.943359\n",
      "Train Epoch: 543 [49152/54000 (91%)] Loss: -1551.610962\n",
      "Train Epoch: 543 [53248/54000 (99%)] Loss: -1548.649658\n",
      "    epoch          : 543\n",
      "    loss           : -1551.6634839677133\n",
      "    ess            : 3.790300346663778\n",
      "    log_marginal   : 1551.7921264069905\n",
      "    val_loss       : -1552.3425191243489\n",
      "    val_ess        : 3.7961325645446777\n",
      "    val_log_marginal: 1552.464579264323\n",
      "Train Epoch: 544 [0/54000 (0%)] Loss: -1551.549438\n",
      "Train Epoch: 544 [4096/54000 (8%)] Loss: -1560.137695\n",
      "Train Epoch: 544 [8192/54000 (15%)] Loss: -1553.635986\n",
      "Train Epoch: 544 [12288/54000 (23%)] Loss: -1554.668457\n",
      "Train Epoch: 544 [16384/54000 (30%)] Loss: -1553.879883\n",
      "Train Epoch: 544 [20480/54000 (38%)] Loss: -1557.109131\n",
      "Train Epoch: 544 [24576/54000 (46%)] Loss: -1549.443115\n",
      "Train Epoch: 544 [28672/54000 (53%)] Loss: -1550.187744\n",
      "Train Epoch: 544 [32768/54000 (61%)] Loss: -1550.448242\n",
      "Train Epoch: 544 [36864/54000 (68%)] Loss: -1552.948486\n",
      "Train Epoch: 544 [40960/54000 (76%)] Loss: -1552.632080\n",
      "Train Epoch: 544 [45056/54000 (83%)] Loss: -1551.725098\n",
      "Train Epoch: 544 [49152/54000 (91%)] Loss: -1550.123413\n",
      "Train Epoch: 544 [53248/54000 (99%)] Loss: -1548.133789\n",
      "    epoch          : 544\n",
      "    loss           : -1552.0722945516143\n",
      "    ess            : 3.790298783948636\n",
      "    log_marginal   : 1552.201302623297\n",
      "    val_loss       : -1551.6230977376301\n",
      "    val_ess        : 3.7771943310896554\n",
      "    val_log_marginal: 1551.762690226237\n",
      "Train Epoch: 545 [0/54000 (0%)] Loss: -1556.002197\n",
      "Train Epoch: 545 [4096/54000 (8%)] Loss: -1544.757080\n",
      "Train Epoch: 545 [8192/54000 (15%)] Loss: -1553.023315\n",
      "Train Epoch: 545 [12288/54000 (23%)] Loss: -1553.676514\n",
      "Train Epoch: 545 [16384/54000 (30%)] Loss: -1553.139648\n",
      "Train Epoch: 545 [20480/54000 (38%)] Loss: -1560.589600\n",
      "Train Epoch: 545 [24576/54000 (46%)] Loss: -1553.708252\n",
      "Train Epoch: 545 [28672/54000 (53%)] Loss: -1556.866821\n",
      "Train Epoch: 545 [32768/54000 (61%)] Loss: -1548.031494\n",
      "Train Epoch: 545 [36864/54000 (68%)] Loss: -1555.426514\n",
      "Train Epoch: 545 [40960/54000 (76%)] Loss: -1554.446655\n",
      "Train Epoch: 545 [45056/54000 (83%)] Loss: -1553.518799\n",
      "Train Epoch: 545 [49152/54000 (91%)] Loss: -1555.251465\n",
      "Train Epoch: 545 [53248/54000 (99%)] Loss: -1554.415039\n",
      "    epoch          : 545\n",
      "    loss           : -1552.1343583382702\n",
      "    ess            : 3.7850149389691827\n",
      "    log_marginal   : 1552.2665957771771\n",
      "    val_loss       : -1551.38037109375\n",
      "    val_ess        : 3.7905020117759705\n",
      "    val_log_marginal: 1551.502197265625\n",
      "Train Epoch: 546 [0/54000 (0%)] Loss: -1550.906738\n",
      "Train Epoch: 546 [4096/54000 (8%)] Loss: -1550.145020\n",
      "Train Epoch: 546 [8192/54000 (15%)] Loss: -1556.639771\n",
      "Train Epoch: 546 [12288/54000 (23%)] Loss: -1552.478271\n",
      "Train Epoch: 546 [16384/54000 (30%)] Loss: -1558.001221\n",
      "Train Epoch: 546 [20480/54000 (38%)] Loss: -1555.878418\n",
      "Train Epoch: 546 [24576/54000 (46%)] Loss: -1558.703369\n",
      "Train Epoch: 546 [28672/54000 (53%)] Loss: -1550.141479\n",
      "Train Epoch: 546 [32768/54000 (61%)] Loss: -1552.278442\n",
      "Train Epoch: 546 [36864/54000 (68%)] Loss: -1556.843750\n",
      "Train Epoch: 546 [40960/54000 (76%)] Loss: -1544.374878\n",
      "Train Epoch: 546 [45056/54000 (83%)] Loss: -1555.456543\n",
      "Train Epoch: 546 [49152/54000 (91%)] Loss: -1556.317749\n",
      "Train Epoch: 546 [53248/54000 (99%)] Loss: -1551.490112\n",
      "    epoch          : 546\n",
      "    loss           : -1552.1027421273327\n",
      "    ess            : 3.78384403933846\n",
      "    log_marginal   : 1552.2377420579087\n",
      "    val_loss       : -1550.301045735677\n",
      "    val_ess        : 3.7803598443667092\n",
      "    val_log_marginal: 1550.4415842692058\n",
      "Train Epoch: 547 [0/54000 (0%)] Loss: -1554.101562\n",
      "Train Epoch: 547 [4096/54000 (8%)] Loss: -1554.690918\n",
      "Train Epoch: 547 [8192/54000 (15%)] Loss: -1556.961304\n",
      "Train Epoch: 547 [12288/54000 (23%)] Loss: -1549.362671\n",
      "Train Epoch: 547 [16384/54000 (30%)] Loss: -1552.671753\n",
      "Train Epoch: 547 [20480/54000 (38%)] Loss: -1552.953857\n",
      "Train Epoch: 547 [24576/54000 (46%)] Loss: -1557.653076\n",
      "Train Epoch: 547 [28672/54000 (53%)] Loss: -1548.499268\n",
      "Train Epoch: 547 [32768/54000 (61%)] Loss: -1554.847534\n",
      "Train Epoch: 547 [36864/54000 (68%)] Loss: -1553.411987\n",
      "Train Epoch: 547 [40960/54000 (76%)] Loss: -1553.751587\n",
      "Train Epoch: 547 [45056/54000 (83%)] Loss: -1551.735718\n",
      "Train Epoch: 547 [49152/54000 (91%)] Loss: -1550.406982\n",
      "Train Epoch: 547 [53248/54000 (99%)] Loss: -1556.726685\n",
      "    epoch          : 547\n",
      "    loss           : -1552.1939801401436\n",
      "    ess            : 3.7872635018769034\n",
      "    log_marginal   : 1552.3241070932686\n",
      "    val_loss       : -1550.6741282145183\n",
      "    val_ess        : 3.797420471906662\n",
      "    val_log_marginal: 1550.7941487630208\n",
      "Train Epoch: 548 [0/54000 (0%)] Loss: -1548.752441\n",
      "Train Epoch: 548 [4096/54000 (8%)] Loss: -1552.406006\n",
      "Train Epoch: 548 [8192/54000 (15%)] Loss: -1551.421387\n",
      "Train Epoch: 548 [12288/54000 (23%)] Loss: -1552.141479\n",
      "Train Epoch: 548 [16384/54000 (30%)] Loss: -1553.814209\n",
      "Train Epoch: 548 [20480/54000 (38%)] Loss: -1555.770020\n",
      "Train Epoch: 548 [24576/54000 (46%)] Loss: -1549.170654\n",
      "Train Epoch: 548 [28672/54000 (53%)] Loss: -1548.165771\n",
      "Train Epoch: 548 [32768/54000 (61%)] Loss: -1555.528076\n",
      "Train Epoch: 548 [36864/54000 (68%)] Loss: -1547.972656\n",
      "Train Epoch: 548 [40960/54000 (76%)] Loss: -1555.323242\n",
      "Train Epoch: 548 [45056/54000 (83%)] Loss: -1554.411499\n",
      "Train Epoch: 548 [49152/54000 (91%)] Loss: -1549.582520\n",
      "Train Epoch: 548 [53248/54000 (99%)] Loss: -1552.176025\n",
      "    epoch          : 548\n",
      "    loss           : -1552.4119508571534\n",
      "    ess            : 3.786469478742771\n",
      "    log_marginal   : 1552.543709271327\n",
      "    val_loss       : -1551.3858083089192\n",
      "    val_ess        : 3.7917517026265464\n",
      "    val_log_marginal: 1551.5087076822917\n",
      "Train Epoch: 549 [0/54000 (0%)] Loss: -1553.742188\n",
      "Train Epoch: 549 [4096/54000 (8%)] Loss: -1550.279541\n",
      "Train Epoch: 549 [8192/54000 (15%)] Loss: -1553.878174\n",
      "Train Epoch: 549 [12288/54000 (23%)] Loss: -1550.513428\n",
      "Train Epoch: 549 [16384/54000 (30%)] Loss: -1553.999878\n",
      "Train Epoch: 549 [20480/54000 (38%)] Loss: -1557.421021\n",
      "Train Epoch: 549 [24576/54000 (46%)] Loss: -1554.351440\n",
      "Train Epoch: 549 [28672/54000 (53%)] Loss: -1549.333496\n",
      "Train Epoch: 549 [32768/54000 (61%)] Loss: -1556.522217\n",
      "Train Epoch: 549 [36864/54000 (68%)] Loss: -1557.922974\n",
      "Train Epoch: 549 [40960/54000 (76%)] Loss: -1553.563477\n",
      "Train Epoch: 549 [45056/54000 (83%)] Loss: -1559.797485\n",
      "Train Epoch: 549 [49152/54000 (91%)] Loss: -1544.229248\n",
      "Train Epoch: 549 [53248/54000 (99%)] Loss: -1552.080322\n",
      "    epoch          : 549\n",
      "    loss           : -1552.6809406009331\n",
      "    ess            : 3.788728941108378\n",
      "    log_marginal   : 1552.8091913738522\n",
      "    val_loss       : -1552.2597096761067\n",
      "    val_ess        : 3.79035014907519\n",
      "    val_log_marginal: 1552.38916015625\n",
      "Train Epoch: 550 [0/54000 (0%)] Loss: -1549.685547\n",
      "Train Epoch: 550 [4096/54000 (8%)] Loss: -1551.846069\n",
      "Train Epoch: 550 [8192/54000 (15%)] Loss: -1547.958252\n",
      "Train Epoch: 550 [12288/54000 (23%)] Loss: -1554.693115\n",
      "Train Epoch: 550 [16384/54000 (30%)] Loss: -1552.128296\n",
      "Train Epoch: 550 [20480/54000 (38%)] Loss: -1554.894409\n",
      "Train Epoch: 550 [24576/54000 (46%)] Loss: -1560.745972\n",
      "Train Epoch: 550 [28672/54000 (53%)] Loss: -1550.828735\n",
      "Train Epoch: 550 [32768/54000 (61%)] Loss: -1559.031250\n",
      "Train Epoch: 550 [36864/54000 (68%)] Loss: -1551.237793\n",
      "Train Epoch: 550 [40960/54000 (76%)] Loss: -1550.283203\n",
      "Train Epoch: 550 [45056/54000 (83%)] Loss: -1549.592529\n",
      "Train Epoch: 550 [49152/54000 (91%)] Loss: -1553.331665\n",
      "Train Epoch: 550 [53248/54000 (99%)] Loss: -1545.869873\n",
      "    epoch          : 550\n",
      "    loss           : -1552.8800043042802\n",
      "    ess            : 3.7883378634520617\n",
      "    log_marginal   : 1553.0109973202384\n",
      "    val_loss       : -1553.2705688476562\n",
      "    val_ess        : 3.7789551615715027\n",
      "    val_log_marginal: 1553.4071095784504\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch550.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 551 [0/54000 (0%)] Loss: -1552.770752\n",
      "Train Epoch: 551 [4096/54000 (8%)] Loss: -1549.676392\n",
      "Train Epoch: 551 [8192/54000 (15%)] Loss: -1557.020752\n",
      "Train Epoch: 551 [12288/54000 (23%)] Loss: -1549.568848\n",
      "Train Epoch: 551 [16384/54000 (30%)] Loss: -1555.537354\n",
      "Train Epoch: 551 [20480/54000 (38%)] Loss: -1551.996460\n",
      "Train Epoch: 551 [24576/54000 (46%)] Loss: -1551.110596\n",
      "Train Epoch: 551 [28672/54000 (53%)] Loss: -1552.600586\n",
      "Train Epoch: 551 [32768/54000 (61%)] Loss: -1553.163940\n",
      "Train Epoch: 551 [36864/54000 (68%)] Loss: -1553.853760\n",
      "Train Epoch: 551 [40960/54000 (76%)] Loss: -1549.512451\n",
      "Train Epoch: 551 [45056/54000 (83%)] Loss: -1547.655518\n",
      "Train Epoch: 551 [49152/54000 (91%)] Loss: -1558.495605\n",
      "Train Epoch: 551 [53248/54000 (99%)] Loss: -1555.600342\n",
      "    epoch          : 551\n",
      "    loss           : -1552.752297930243\n",
      "    ess            : 3.785613491636882\n",
      "    log_marginal   : 1552.8859857495927\n",
      "    val_loss       : -1553.1092020670574\n",
      "    val_ess        : 3.7965941627820334\n",
      "    val_log_marginal: 1553.2411855061848\n",
      "Train Epoch: 552 [0/54000 (0%)] Loss: -1559.521729\n",
      "Train Epoch: 552 [4096/54000 (8%)] Loss: -1554.028320\n",
      "Train Epoch: 552 [8192/54000 (15%)] Loss: -1558.822632\n",
      "Train Epoch: 552 [12288/54000 (23%)] Loss: -1551.308838\n",
      "Train Epoch: 552 [16384/54000 (30%)] Loss: -1557.185547\n",
      "Train Epoch: 552 [20480/54000 (38%)] Loss: -1551.170898\n",
      "Train Epoch: 552 [24576/54000 (46%)] Loss: -1556.241943\n",
      "Train Epoch: 552 [28672/54000 (53%)] Loss: -1552.623413\n",
      "Train Epoch: 552 [32768/54000 (61%)] Loss: -1559.154785\n",
      "Train Epoch: 552 [36864/54000 (68%)] Loss: -1555.811401\n",
      "Train Epoch: 552 [40960/54000 (76%)] Loss: -1540.927490\n",
      "Train Epoch: 552 [45056/54000 (83%)] Loss: -1547.916138\n",
      "Train Epoch: 552 [49152/54000 (91%)] Loss: -1551.064087\n",
      "Train Epoch: 552 [53248/54000 (99%)] Loss: -1542.959229\n",
      "    epoch          : 552\n",
      "    loss           : -1553.1907530870483\n",
      "    ess            : 3.786239894080501\n",
      "    log_marginal   : 1553.3212057538508\n",
      "    val_loss       : -1552.1053365071614\n",
      "    val_ess        : 3.778828044732412\n",
      "    val_log_marginal: 1552.2475891113281\n",
      "Train Epoch: 553 [0/54000 (0%)] Loss: -1549.442871\n",
      "Train Epoch: 553 [4096/54000 (8%)] Loss: -1554.533936\n",
      "Train Epoch: 553 [8192/54000 (15%)] Loss: -1555.181641\n",
      "Train Epoch: 553 [12288/54000 (23%)] Loss: -1551.805054\n",
      "Train Epoch: 553 [16384/54000 (30%)] Loss: -1552.291748\n",
      "Train Epoch: 553 [20480/54000 (38%)] Loss: -1555.578125\n",
      "Train Epoch: 553 [24576/54000 (46%)] Loss: -1554.848877\n",
      "Train Epoch: 553 [28672/54000 (53%)] Loss: -1552.512695\n",
      "Train Epoch: 553 [32768/54000 (61%)] Loss: -1556.687988\n",
      "Train Epoch: 553 [36864/54000 (68%)] Loss: -1553.182373\n",
      "Train Epoch: 553 [40960/54000 (76%)] Loss: -1556.620850\n",
      "Train Epoch: 553 [45056/54000 (83%)] Loss: -1555.528442\n",
      "Train Epoch: 553 [49152/54000 (91%)] Loss: -1550.582886\n",
      "Train Epoch: 553 [53248/54000 (99%)] Loss: -1544.218872\n",
      "    epoch          : 553\n",
      "    loss           : -1553.2274829448681\n",
      "    ess            : 3.790952824868297\n",
      "    log_marginal   : 1553.355819919098\n",
      "    val_loss       : -1552.7997487386067\n",
      "    val_ess        : 3.801101883252462\n",
      "    val_log_marginal: 1552.9293721516926\n",
      "Train Epoch: 554 [0/54000 (0%)] Loss: -1554.414551\n",
      "Train Epoch: 554 [4096/54000 (8%)] Loss: -1542.628662\n",
      "Train Epoch: 554 [8192/54000 (15%)] Loss: -1552.334717\n",
      "Train Epoch: 554 [12288/54000 (23%)] Loss: -1555.522461\n",
      "Train Epoch: 554 [16384/54000 (30%)] Loss: -1556.612793\n",
      "Train Epoch: 554 [20480/54000 (38%)] Loss: -1557.077026\n",
      "Train Epoch: 554 [24576/54000 (46%)] Loss: -1561.293457\n",
      "Train Epoch: 554 [28672/54000 (53%)] Loss: -1558.084473\n",
      "Train Epoch: 554 [32768/54000 (61%)] Loss: -1557.418457\n",
      "Train Epoch: 554 [36864/54000 (68%)] Loss: -1556.137695\n",
      "Train Epoch: 554 [40960/54000 (76%)] Loss: -1554.843750\n",
      "Train Epoch: 554 [45056/54000 (83%)] Loss: -1548.726318\n",
      "Train Epoch: 554 [49152/54000 (91%)] Loss: -1555.881226\n",
      "Train Epoch: 554 [53248/54000 (99%)] Loss: -1553.606689\n",
      "    epoch          : 554\n",
      "    loss           : -1553.1716036683574\n",
      "    ess            : 3.7854526393221453\n",
      "    log_marginal   : 1553.3026637940611\n",
      "    val_loss       : -1552.709955851237\n",
      "    val_ess        : 3.797423501809438\n",
      "    val_log_marginal: 1552.8402404785156\n",
      "Train Epoch: 555 [0/54000 (0%)] Loss: -1550.511475\n",
      "Train Epoch: 555 [4096/54000 (8%)] Loss: -1551.495361\n",
      "Train Epoch: 555 [8192/54000 (15%)] Loss: -1548.707031\n",
      "Train Epoch: 555 [12288/54000 (23%)] Loss: -1555.689697\n",
      "Train Epoch: 555 [16384/54000 (30%)] Loss: -1550.916748\n",
      "Train Epoch: 555 [20480/54000 (38%)] Loss: -1554.608398\n",
      "Train Epoch: 555 [24576/54000 (46%)] Loss: -1550.433350\n",
      "Train Epoch: 555 [28672/54000 (53%)] Loss: -1552.744995\n",
      "Train Epoch: 555 [32768/54000 (61%)] Loss: -1557.967285\n",
      "Train Epoch: 555 [36864/54000 (68%)] Loss: -1553.590088\n",
      "Train Epoch: 555 [40960/54000 (76%)] Loss: -1560.532227\n",
      "Train Epoch: 555 [45056/54000 (83%)] Loss: -1548.187256\n",
      "Train Epoch: 555 [49152/54000 (91%)] Loss: -1552.654541\n",
      "Train Epoch: 555 [53248/54000 (99%)] Loss: -1548.901611\n",
      "    epoch          : 555\n",
      "    loss           : -1553.2607086326273\n",
      "    ess            : 3.7872541741737256\n",
      "    log_marginal   : 1553.3920586030065\n",
      "    val_loss       : -1552.9690958658855\n",
      "    val_ess        : 3.787182112534841\n",
      "    val_log_marginal: 1553.094975789388\n",
      "Train Epoch: 556 [0/54000 (0%)] Loss: -1553.869263\n",
      "Train Epoch: 556 [4096/54000 (8%)] Loss: -1555.171265\n",
      "Train Epoch: 556 [8192/54000 (15%)] Loss: -1547.846191\n",
      "Train Epoch: 556 [12288/54000 (23%)] Loss: -1552.804443\n",
      "Train Epoch: 556 [16384/54000 (30%)] Loss: -1555.346313\n",
      "Train Epoch: 556 [20480/54000 (38%)] Loss: -1552.210449\n",
      "Train Epoch: 556 [24576/54000 (46%)] Loss: -1548.510132\n",
      "Train Epoch: 556 [28672/54000 (53%)] Loss: -1558.461182\n",
      "Train Epoch: 556 [32768/54000 (61%)] Loss: -1555.764648\n",
      "Train Epoch: 556 [36864/54000 (68%)] Loss: -1547.340820\n",
      "Train Epoch: 556 [40960/54000 (76%)] Loss: -1551.045410\n",
      "Train Epoch: 556 [45056/54000 (83%)] Loss: -1558.694702\n",
      "Train Epoch: 556 [49152/54000 (91%)] Loss: -1547.496582\n",
      "Train Epoch: 556 [53248/54000 (99%)] Loss: -1548.921265\n",
      "    epoch          : 556\n",
      "    loss           : -1553.2893436666914\n",
      "    ess            : 3.781313665670241\n",
      "    log_marginal   : 1553.4270997250815\n",
      "    val_loss       : -1552.166971842448\n",
      "    val_ess        : 3.805163731177648\n",
      "    val_log_marginal: 1552.2999776204426\n",
      "Train Epoch: 557 [0/54000 (0%)] Loss: -1555.022339\n",
      "Train Epoch: 557 [4096/54000 (8%)] Loss: -1556.482666\n",
      "Train Epoch: 557 [8192/54000 (15%)] Loss: -1551.081909\n",
      "Train Epoch: 557 [12288/54000 (23%)] Loss: -1552.014160\n",
      "Train Epoch: 557 [16384/54000 (30%)] Loss: -1549.184326\n",
      "Train Epoch: 557 [20480/54000 (38%)] Loss: -1555.771973\n",
      "Train Epoch: 557 [24576/54000 (46%)] Loss: -1549.540161\n",
      "Train Epoch: 557 [28672/54000 (53%)] Loss: -1551.470703\n",
      "Train Epoch: 557 [32768/54000 (61%)] Loss: -1552.589600\n",
      "Train Epoch: 557 [36864/54000 (68%)] Loss: -1553.314575\n",
      "Train Epoch: 557 [40960/54000 (76%)] Loss: -1550.738403\n",
      "Train Epoch: 557 [45056/54000 (83%)] Loss: -1547.706543\n",
      "Train Epoch: 557 [49152/54000 (91%)] Loss: -1554.016846\n",
      "Train Epoch: 557 [53248/54000 (99%)] Loss: -1556.725586\n",
      "    epoch          : 557\n",
      "    loss           : -1553.565587048282\n",
      "    ess            : 3.7874966775071566\n",
      "    log_marginal   : 1553.6982329309835\n",
      "    val_loss       : -1553.531010945638\n",
      "    val_ess        : 3.7748025556405387\n",
      "    val_log_marginal: 1553.6671803792317\n",
      "Train Epoch: 558 [0/54000 (0%)] Loss: -1555.343506\n",
      "Train Epoch: 558 [4096/54000 (8%)] Loss: -1553.005371\n",
      "Train Epoch: 558 [8192/54000 (15%)] Loss: -1559.243164\n",
      "Train Epoch: 558 [12288/54000 (23%)] Loss: -1556.690674\n",
      "Train Epoch: 558 [16384/54000 (30%)] Loss: -1552.582764\n",
      "Train Epoch: 558 [20480/54000 (38%)] Loss: -1555.285645\n",
      "Train Epoch: 558 [24576/54000 (46%)] Loss: -1558.815918\n",
      "Train Epoch: 558 [28672/54000 (53%)] Loss: -1564.384521\n",
      "Train Epoch: 558 [32768/54000 (61%)] Loss: -1551.378662\n",
      "Train Epoch: 558 [36864/54000 (68%)] Loss: -1558.046997\n",
      "Train Epoch: 558 [40960/54000 (76%)] Loss: -1551.415771\n",
      "Train Epoch: 558 [45056/54000 (83%)] Loss: -1556.926025\n",
      "Train Epoch: 558 [49152/54000 (91%)] Loss: -1548.848633\n",
      "Train Epoch: 558 [53248/54000 (99%)] Loss: -1556.657715\n",
      "    epoch          : 558\n",
      "    loss           : -1553.700040265847\n",
      "    ess            : 3.7913614347647715\n",
      "    log_marginal   : 1553.8279884663802\n",
      "    val_loss       : -1553.5948791503906\n",
      "    val_ess        : 3.7922368745009103\n",
      "    val_log_marginal: 1553.7264404296875\n",
      "Train Epoch: 559 [0/54000 (0%)] Loss: -1554.795532\n",
      "Train Epoch: 559 [4096/54000 (8%)] Loss: -1553.838013\n",
      "Train Epoch: 559 [8192/54000 (15%)] Loss: -1546.592163\n",
      "Train Epoch: 559 [12288/54000 (23%)] Loss: -1556.861328\n",
      "Train Epoch: 559 [16384/54000 (30%)] Loss: -1557.571533\n",
      "Train Epoch: 559 [20480/54000 (38%)] Loss: -1551.993286\n",
      "Train Epoch: 559 [24576/54000 (46%)] Loss: -1552.124756\n",
      "Train Epoch: 559 [28672/54000 (53%)] Loss: -1557.953613\n",
      "Train Epoch: 559 [32768/54000 (61%)] Loss: -1553.828979\n",
      "Train Epoch: 559 [36864/54000 (68%)] Loss: -1552.578125\n",
      "Train Epoch: 559 [40960/54000 (76%)] Loss: -1555.497925\n",
      "Train Epoch: 559 [45056/54000 (83%)] Loss: -1551.217529\n",
      "Train Epoch: 559 [49152/54000 (91%)] Loss: -1556.241455\n",
      "Train Epoch: 559 [53248/54000 (99%)] Loss: -1553.311279\n",
      "    epoch          : 559\n",
      "    loss           : -1553.5912675179577\n",
      "    ess            : 3.7853470153718196\n",
      "    log_marginal   : 1553.7268523446758\n",
      "    val_loss       : -1553.3425547281902\n",
      "    val_ess        : 3.7832280496756234\n",
      "    val_log_marginal: 1553.4699452718098\n",
      "Train Epoch: 560 [0/54000 (0%)] Loss: -1547.101807\n",
      "Train Epoch: 560 [4096/54000 (8%)] Loss: -1547.460693\n",
      "Train Epoch: 560 [8192/54000 (15%)] Loss: -1554.071899\n",
      "Train Epoch: 560 [12288/54000 (23%)] Loss: -1547.484985\n",
      "Train Epoch: 560 [16384/54000 (30%)] Loss: -1551.814453\n",
      "Train Epoch: 560 [20480/54000 (38%)] Loss: -1552.323975\n",
      "Train Epoch: 560 [24576/54000 (46%)] Loss: -1553.925049\n",
      "Train Epoch: 560 [28672/54000 (53%)] Loss: -1556.309570\n",
      "Train Epoch: 560 [32768/54000 (61%)] Loss: -1546.974854\n",
      "Train Epoch: 560 [36864/54000 (68%)] Loss: -1553.064697\n",
      "Train Epoch: 560 [40960/54000 (76%)] Loss: -1555.352539\n",
      "Train Epoch: 560 [45056/54000 (83%)] Loss: -1555.162354\n",
      "Train Epoch: 560 [49152/54000 (91%)] Loss: -1547.548096\n",
      "Train Epoch: 560 [53248/54000 (99%)] Loss: -1561.254883\n",
      "    epoch          : 560\n",
      "    loss           : -1553.8857728497112\n",
      "    ess            : 3.7870172154846915\n",
      "    log_marginal   : 1554.0183944340565\n",
      "    val_loss       : -1553.4711354573567\n",
      "    val_ess        : 3.793459633986155\n",
      "    val_log_marginal: 1553.597412109375\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch560.pth ...\n",
      "Train Epoch: 561 [0/54000 (0%)] Loss: -1551.717896\n",
      "Train Epoch: 561 [4096/54000 (8%)] Loss: -1556.137939\n",
      "Train Epoch: 561 [8192/54000 (15%)] Loss: -1551.394287\n",
      "Train Epoch: 561 [12288/54000 (23%)] Loss: -1547.083008\n",
      "Train Epoch: 561 [16384/54000 (30%)] Loss: -1551.935547\n",
      "Train Epoch: 561 [20480/54000 (38%)] Loss: -1555.268555\n",
      "Train Epoch: 561 [24576/54000 (46%)] Loss: -1554.094482\n",
      "Train Epoch: 561 [28672/54000 (53%)] Loss: -1559.467773\n",
      "Train Epoch: 561 [32768/54000 (61%)] Loss: -1554.637939\n",
      "Train Epoch: 561 [36864/54000 (68%)] Loss: -1555.801025\n",
      "Train Epoch: 561 [40960/54000 (76%)] Loss: -1555.907715\n",
      "Train Epoch: 561 [45056/54000 (83%)] Loss: -1557.635132\n",
      "Train Epoch: 561 [49152/54000 (91%)] Loss: -1557.366089\n",
      "Train Epoch: 561 [53248/54000 (99%)] Loss: -1556.205933\n",
      "    epoch          : 561\n",
      "    loss           : -1553.7373920458754\n",
      "    ess            : 3.790337916234093\n",
      "    log_marginal   : 1553.8660136579902\n",
      "    val_loss       : -1553.4083455403645\n",
      "    val_ess        : 3.7944710552692413\n",
      "    val_log_marginal: 1553.530532836914\n",
      "Train Epoch: 562 [0/54000 (0%)] Loss: -1558.649902\n",
      "Train Epoch: 562 [4096/54000 (8%)] Loss: -1551.718872\n",
      "Train Epoch: 562 [8192/54000 (15%)] Loss: -1558.245850\n",
      "Train Epoch: 562 [12288/54000 (23%)] Loss: -1554.654785\n",
      "Train Epoch: 562 [16384/54000 (30%)] Loss: -1551.880859\n",
      "Train Epoch: 562 [20480/54000 (38%)] Loss: -1556.882446\n",
      "Train Epoch: 562 [24576/54000 (46%)] Loss: -1556.215088\n",
      "Train Epoch: 562 [28672/54000 (53%)] Loss: -1556.416382\n",
      "Train Epoch: 562 [32768/54000 (61%)] Loss: -1550.819214\n",
      "Train Epoch: 562 [36864/54000 (68%)] Loss: -1554.367676\n",
      "Train Epoch: 562 [40960/54000 (76%)] Loss: -1551.503418\n",
      "Train Epoch: 562 [45056/54000 (83%)] Loss: -1562.510254\n",
      "Train Epoch: 562 [49152/54000 (91%)] Loss: -1556.838257\n",
      "Train Epoch: 562 [53248/54000 (99%)] Loss: -1554.576904\n",
      "    epoch          : 562\n",
      "    loss           : -1553.873692517032\n",
      "    ess            : 3.7861545967264765\n",
      "    log_marginal   : 1554.0074243048357\n",
      "    val_loss       : -1553.1158803304036\n",
      "    val_ess        : 3.7885109881560006\n",
      "    val_log_marginal: 1553.2450408935547\n",
      "Train Epoch: 563 [0/54000 (0%)] Loss: -1549.102783\n",
      "Train Epoch: 563 [4096/54000 (8%)] Loss: -1549.782349\n",
      "Train Epoch: 563 [8192/54000 (15%)] Loss: -1557.867798\n",
      "Train Epoch: 563 [12288/54000 (23%)] Loss: -1549.413086\n",
      "Train Epoch: 563 [16384/54000 (30%)] Loss: -1555.594604\n",
      "Train Epoch: 563 [20480/54000 (38%)] Loss: -1554.217163\n",
      "Train Epoch: 563 [24576/54000 (46%)] Loss: -1555.763916\n",
      "Train Epoch: 563 [28672/54000 (53%)] Loss: -1547.713379\n",
      "Train Epoch: 563 [32768/54000 (61%)] Loss: -1551.444824\n",
      "Train Epoch: 563 [36864/54000 (68%)] Loss: -1554.648438\n",
      "Train Epoch: 563 [40960/54000 (76%)] Loss: -1556.517334\n",
      "Train Epoch: 563 [45056/54000 (83%)] Loss: -1555.491089\n",
      "Train Epoch: 563 [49152/54000 (91%)] Loss: -1558.356689\n",
      "Train Epoch: 563 [53248/54000 (99%)] Loss: -1549.347290\n",
      "    epoch          : 563\n",
      "    loss           : -1553.9484423596712\n",
      "    ess            : 3.7877167333358837\n",
      "    log_marginal   : 1554.0784645984522\n",
      "    val_loss       : -1553.7425944010417\n",
      "    val_ess        : 3.7881182034810386\n",
      "    val_log_marginal: 1553.8753204345703\n",
      "Train Epoch: 564 [0/54000 (0%)] Loss: -1559.887573\n",
      "Train Epoch: 564 [4096/54000 (8%)] Loss: -1555.335571\n",
      "Train Epoch: 564 [8192/54000 (15%)] Loss: -1561.683594\n",
      "Train Epoch: 564 [12288/54000 (23%)] Loss: -1549.444580\n",
      "Train Epoch: 564 [16384/54000 (30%)] Loss: -1552.360352\n",
      "Train Epoch: 564 [20480/54000 (38%)] Loss: -1556.424316\n",
      "Train Epoch: 564 [24576/54000 (46%)] Loss: -1552.412354\n",
      "Train Epoch: 564 [28672/54000 (53%)] Loss: -1554.472412\n",
      "Train Epoch: 564 [32768/54000 (61%)] Loss: -1545.391602\n",
      "Train Epoch: 564 [36864/54000 (68%)] Loss: -1556.505859\n",
      "Train Epoch: 564 [40960/54000 (76%)] Loss: -1552.990479\n",
      "Train Epoch: 564 [45056/54000 (83%)] Loss: -1553.386597\n",
      "Train Epoch: 564 [49152/54000 (91%)] Loss: -1555.638428\n",
      "Train Epoch: 564 [53248/54000 (99%)] Loss: -1557.642822\n",
      "    epoch          : 564\n",
      "    loss           : -1554.111511519735\n",
      "    ess            : 3.7902709488620125\n",
      "    log_marginal   : 1554.2391993807391\n",
      "    val_loss       : -1554.0636647542317\n",
      "    val_ess        : 3.7973403135935464\n",
      "    val_log_marginal: 1554.186050415039\n",
      "Train Epoch: 565 [0/54000 (0%)] Loss: -1556.105713\n",
      "Train Epoch: 565 [4096/54000 (8%)] Loss: -1546.686523\n",
      "Train Epoch: 565 [8192/54000 (15%)] Loss: -1553.378906\n",
      "Train Epoch: 565 [12288/54000 (23%)] Loss: -1561.220215\n",
      "Train Epoch: 565 [16384/54000 (30%)] Loss: -1550.937500\n",
      "Train Epoch: 565 [20480/54000 (38%)] Loss: -1554.266479\n",
      "Train Epoch: 565 [24576/54000 (46%)] Loss: -1550.172485\n",
      "Train Epoch: 565 [28672/54000 (53%)] Loss: -1559.982910\n",
      "Train Epoch: 565 [32768/54000 (61%)] Loss: -1551.668213\n",
      "Train Epoch: 565 [36864/54000 (68%)] Loss: -1555.625000\n",
      "Train Epoch: 565 [40960/54000 (76%)] Loss: -1554.869629\n",
      "Train Epoch: 565 [45056/54000 (83%)] Loss: -1554.898926\n",
      "Train Epoch: 565 [49152/54000 (91%)] Loss: -1556.612549\n",
      "Train Epoch: 565 [53248/54000 (99%)] Loss: -1555.452515\n",
      "    epoch          : 565\n",
      "    loss           : -1553.9631417080125\n",
      "    ess            : 3.7821276730270745\n",
      "    log_marginal   : 1554.095884784138\n",
      "    val_loss       : -1553.3236796061199\n",
      "    val_ess        : 3.7813097834587097\n",
      "    val_log_marginal: 1553.4556528727214\n",
      "Train Epoch: 566 [0/54000 (0%)] Loss: -1555.391357\n",
      "Train Epoch: 566 [4096/54000 (8%)] Loss: -1554.928589\n",
      "Train Epoch: 566 [8192/54000 (15%)] Loss: -1554.294556\n",
      "Train Epoch: 566 [12288/54000 (23%)] Loss: -1549.732666\n",
      "Train Epoch: 566 [16384/54000 (30%)] Loss: -1559.878418\n",
      "Train Epoch: 566 [20480/54000 (38%)] Loss: -1553.766846\n",
      "Train Epoch: 566 [24576/54000 (46%)] Loss: -1554.300537\n",
      "Train Epoch: 566 [28672/54000 (53%)] Loss: -1553.762817\n",
      "Train Epoch: 566 [32768/54000 (61%)] Loss: -1548.318237\n",
      "Train Epoch: 566 [36864/54000 (68%)] Loss: -1553.589355\n",
      "Train Epoch: 566 [40960/54000 (76%)] Loss: -1563.042236\n",
      "Train Epoch: 566 [45056/54000 (83%)] Loss: -1547.017334\n",
      "Train Epoch: 566 [49152/54000 (91%)] Loss: -1551.578857\n",
      "Train Epoch: 566 [53248/54000 (99%)] Loss: -1550.960205\n",
      "    epoch          : 566\n",
      "    loss           : -1553.9717658888108\n",
      "    ess            : 3.786186028430812\n",
      "    log_marginal   : 1554.1035086826125\n",
      "    val_loss       : -1553.9685465494792\n",
      "    val_ess        : 3.788383662700653\n",
      "    val_log_marginal: 1554.100092569987\n",
      "Train Epoch: 567 [0/54000 (0%)] Loss: -1553.514160\n",
      "Train Epoch: 567 [4096/54000 (8%)] Loss: -1551.736450\n",
      "Train Epoch: 567 [8192/54000 (15%)] Loss: -1547.231201\n",
      "Train Epoch: 567 [12288/54000 (23%)] Loss: -1550.159424\n",
      "Train Epoch: 567 [16384/54000 (30%)] Loss: -1552.185181\n",
      "Train Epoch: 567 [20480/54000 (38%)] Loss: -1555.320557\n",
      "Train Epoch: 567 [24576/54000 (46%)] Loss: -1556.319336\n",
      "Train Epoch: 567 [28672/54000 (53%)] Loss: -1548.719238\n",
      "Train Epoch: 567 [32768/54000 (61%)] Loss: -1560.061157\n",
      "Train Epoch: 567 [36864/54000 (68%)] Loss: -1558.684937\n",
      "Train Epoch: 567 [40960/54000 (76%)] Loss: -1554.739868\n",
      "Train Epoch: 567 [45056/54000 (83%)] Loss: -1557.160645\n",
      "Train Epoch: 567 [49152/54000 (91%)] Loss: -1547.533203\n",
      "Train Epoch: 567 [53248/54000 (99%)] Loss: -1557.373047\n",
      "    epoch          : 567\n",
      "    loss           : -1554.0891986865004\n",
      "    ess            : 3.785341671857789\n",
      "    log_marginal   : 1554.2233637949867\n",
      "    val_loss       : -1554.9676208496094\n",
      "    val_ess        : 3.787219097216924\n",
      "    val_log_marginal: 1555.0930430094402\n",
      "Train Epoch: 568 [0/54000 (0%)] Loss: -1560.999023\n",
      "Train Epoch: 568 [4096/54000 (8%)] Loss: -1556.070312\n",
      "Train Epoch: 568 [8192/54000 (15%)] Loss: -1556.828125\n",
      "Train Epoch: 568 [12288/54000 (23%)] Loss: -1557.402832\n",
      "Train Epoch: 568 [16384/54000 (30%)] Loss: -1558.578369\n",
      "Train Epoch: 568 [20480/54000 (38%)] Loss: -1551.321289\n",
      "Train Epoch: 568 [24576/54000 (46%)] Loss: -1553.601929\n",
      "Train Epoch: 568 [28672/54000 (53%)] Loss: -1553.545410\n",
      "Train Epoch: 568 [32768/54000 (61%)] Loss: -1552.023193\n",
      "Train Epoch: 568 [36864/54000 (68%)] Loss: -1552.574951\n",
      "Train Epoch: 568 [40960/54000 (76%)] Loss: -1555.060547\n",
      "Train Epoch: 568 [45056/54000 (83%)] Loss: -1554.224365\n",
      "Train Epoch: 568 [49152/54000 (91%)] Loss: -1557.912476\n",
      "Train Epoch: 568 [53248/54000 (99%)] Loss: -1555.583252\n",
      "    epoch          : 568\n",
      "    loss           : -1554.3317333058724\n",
      "    ess            : 3.7814380738407514\n",
      "    log_marginal   : 1554.4661668533397\n",
      "    val_loss       : -1553.5235646565754\n",
      "    val_ess        : 3.786946872870127\n",
      "    val_log_marginal: 1553.6387786865234\n",
      "Train Epoch: 569 [0/54000 (0%)] Loss: -1551.663574\n",
      "Train Epoch: 569 [4096/54000 (8%)] Loss: -1556.932983\n",
      "Train Epoch: 569 [8192/54000 (15%)] Loss: -1553.692505\n",
      "Train Epoch: 569 [12288/54000 (23%)] Loss: -1557.120850\n",
      "Train Epoch: 569 [16384/54000 (30%)] Loss: -1557.905396\n",
      "Train Epoch: 569 [20480/54000 (38%)] Loss: -1546.970215\n",
      "Train Epoch: 569 [24576/54000 (46%)] Loss: -1553.041626\n",
      "Train Epoch: 569 [28672/54000 (53%)] Loss: -1552.854248\n",
      "Train Epoch: 569 [32768/54000 (61%)] Loss: -1551.336670\n",
      "Train Epoch: 569 [36864/54000 (68%)] Loss: -1551.421143\n",
      "Train Epoch: 569 [40960/54000 (76%)] Loss: -1551.981323\n",
      "Train Epoch: 569 [45056/54000 (83%)] Loss: -1554.018555\n",
      "Train Epoch: 569 [49152/54000 (91%)] Loss: -1558.416748\n",
      "Train Epoch: 569 [53248/54000 (99%)] Loss: -1551.203491\n",
      "    epoch          : 569\n",
      "    loss           : -1554.2479502601082\n",
      "    ess            : 3.785098466827971\n",
      "    log_marginal   : 1554.384194613633\n",
      "    val_loss       : -1554.6321512858074\n",
      "    val_ess        : 3.7916095654169717\n",
      "    val_log_marginal: 1554.7510986328125\n",
      "Train Epoch: 570 [0/54000 (0%)] Loss: -1556.422485\n",
      "Train Epoch: 570 [4096/54000 (8%)] Loss: -1553.843262\n",
      "Train Epoch: 570 [8192/54000 (15%)] Loss: -1555.740234\n",
      "Train Epoch: 570 [12288/54000 (23%)] Loss: -1551.783691\n",
      "Train Epoch: 570 [16384/54000 (30%)] Loss: -1557.840942\n",
      "Train Epoch: 570 [20480/54000 (38%)] Loss: -1551.110352\n",
      "Train Epoch: 570 [24576/54000 (46%)] Loss: -1553.596191\n",
      "Train Epoch: 570 [28672/54000 (53%)] Loss: -1550.645752\n",
      "Train Epoch: 570 [32768/54000 (61%)] Loss: -1558.492432\n",
      "Train Epoch: 570 [36864/54000 (68%)] Loss: -1560.174561\n",
      "Train Epoch: 570 [40960/54000 (76%)] Loss: -1555.739746\n",
      "Train Epoch: 570 [45056/54000 (83%)] Loss: -1552.954834\n",
      "Train Epoch: 570 [49152/54000 (91%)] Loss: -1555.176514\n",
      "Train Epoch: 570 [53248/54000 (99%)] Loss: -1555.784912\n",
      "    epoch          : 570\n",
      "    loss           : -1554.2667461955716\n",
      "    ess            : 3.783437108541552\n",
      "    log_marginal   : 1554.3996877082716\n",
      "    val_loss       : -1553.7116597493489\n",
      "    val_ess        : 3.7874162197113037\n",
      "    val_log_marginal: 1553.8419901529949\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch570.pth ...\n",
      "Train Epoch: 571 [0/54000 (0%)] Loss: -1549.256348\n",
      "Train Epoch: 571 [4096/54000 (8%)] Loss: -1555.721436\n",
      "Train Epoch: 571 [8192/54000 (15%)] Loss: -1550.592041\n",
      "Train Epoch: 571 [12288/54000 (23%)] Loss: -1554.752075\n",
      "Train Epoch: 571 [16384/54000 (30%)] Loss: -1555.705566\n",
      "Train Epoch: 571 [20480/54000 (38%)] Loss: -1544.007568\n",
      "Train Epoch: 571 [24576/54000 (46%)] Loss: -1552.563599\n",
      "Train Epoch: 571 [28672/54000 (53%)] Loss: -1557.706665\n",
      "Train Epoch: 571 [32768/54000 (61%)] Loss: -1553.966431\n",
      "Train Epoch: 571 [36864/54000 (68%)] Loss: -1556.440796\n",
      "Train Epoch: 571 [40960/54000 (76%)] Loss: -1549.158691\n",
      "Train Epoch: 571 [45056/54000 (83%)] Loss: -1555.223389\n",
      "Train Epoch: 571 [49152/54000 (91%)] Loss: -1553.470703\n",
      "Train Epoch: 571 [53248/54000 (99%)] Loss: -1557.814209\n",
      "    epoch          : 571\n",
      "    loss           : -1554.660876522697\n",
      "    ess            : 3.7846850365824043\n",
      "    log_marginal   : 1554.7949224535323\n",
      "    val_loss       : -1554.792231241862\n",
      "    val_ess        : 3.771896243095398\n",
      "    val_log_marginal: 1554.936528523763\n",
      "Train Epoch: 572 [0/54000 (0%)] Loss: -1553.869873\n",
      "Train Epoch: 572 [4096/54000 (8%)] Loss: -1556.925293\n",
      "Train Epoch: 572 [8192/54000 (15%)] Loss: -1557.716919\n",
      "Train Epoch: 572 [12288/54000 (23%)] Loss: -1555.926025\n",
      "Train Epoch: 572 [16384/54000 (30%)] Loss: -1559.679443\n",
      "Train Epoch: 572 [20480/54000 (38%)] Loss: -1552.430664\n",
      "Train Epoch: 572 [24576/54000 (46%)] Loss: -1550.633057\n",
      "Train Epoch: 572 [28672/54000 (53%)] Loss: -1553.492432\n",
      "Train Epoch: 572 [32768/54000 (61%)] Loss: -1548.518066\n",
      "Train Epoch: 572 [36864/54000 (68%)] Loss: -1558.885498\n",
      "Train Epoch: 572 [40960/54000 (76%)] Loss: -1555.349609\n",
      "Train Epoch: 572 [45056/54000 (83%)] Loss: -1552.854614\n",
      "Train Epoch: 572 [49152/54000 (91%)] Loss: -1553.438477\n",
      "Train Epoch: 572 [53248/54000 (99%)] Loss: -1553.435059\n",
      "    epoch          : 572\n",
      "    loss           : -1554.4500888625591\n",
      "    ess            : 3.787940564313771\n",
      "    log_marginal   : 1554.5832594740448\n",
      "    val_loss       : -1555.3287404378254\n",
      "    val_ess        : 3.782972037792206\n",
      "    val_log_marginal: 1555.4696299235027\n",
      "Train Epoch: 573 [0/54000 (0%)] Loss: -1565.762817\n",
      "Train Epoch: 573 [4096/54000 (8%)] Loss: -1554.951172\n",
      "Train Epoch: 573 [8192/54000 (15%)] Loss: -1552.915527\n",
      "Train Epoch: 573 [12288/54000 (23%)] Loss: -1558.569824\n",
      "Train Epoch: 573 [16384/54000 (30%)] Loss: -1555.913818\n",
      "Train Epoch: 573 [20480/54000 (38%)] Loss: -1549.272095\n",
      "Train Epoch: 573 [24576/54000 (46%)] Loss: -1557.218018\n",
      "Train Epoch: 573 [28672/54000 (53%)] Loss: -1554.456787\n",
      "Train Epoch: 573 [32768/54000 (61%)] Loss: -1553.408691\n",
      "Train Epoch: 573 [36864/54000 (68%)] Loss: -1554.994385\n",
      "Train Epoch: 573 [40960/54000 (76%)] Loss: -1553.559814\n",
      "Train Epoch: 573 [45056/54000 (83%)] Loss: -1556.146118\n",
      "Train Epoch: 573 [49152/54000 (91%)] Loss: -1563.210693\n",
      "Train Epoch: 573 [53248/54000 (99%)] Loss: -1556.591919\n",
      "    epoch          : 573\n",
      "    loss           : -1554.4847550957124\n",
      "    ess            : 3.785530074512789\n",
      "    log_marginal   : 1554.6205256312944\n",
      "    val_loss       : -1555.1712849934895\n",
      "    val_ess        : 3.785498797893524\n",
      "    val_log_marginal: 1555.2966206868489\n",
      "Train Epoch: 574 [0/54000 (0%)] Loss: -1553.602051\n",
      "Train Epoch: 574 [4096/54000 (8%)] Loss: -1551.680176\n",
      "Train Epoch: 574 [8192/54000 (15%)] Loss: -1546.539307\n",
      "Train Epoch: 574 [12288/54000 (23%)] Loss: -1554.319092\n",
      "Train Epoch: 574 [16384/54000 (30%)] Loss: -1554.222412\n",
      "Train Epoch: 574 [20480/54000 (38%)] Loss: -1551.713989\n",
      "Train Epoch: 574 [24576/54000 (46%)] Loss: -1550.916748\n",
      "Train Epoch: 574 [28672/54000 (53%)] Loss: -1549.585205\n",
      "Train Epoch: 574 [32768/54000 (61%)] Loss: -1557.437988\n",
      "Train Epoch: 574 [36864/54000 (68%)] Loss: -1559.121338\n",
      "Train Epoch: 574 [40960/54000 (76%)] Loss: -1555.018188\n",
      "Train Epoch: 574 [45056/54000 (83%)] Loss: -1549.696289\n",
      "Train Epoch: 574 [49152/54000 (91%)] Loss: -1559.385742\n",
      "Train Epoch: 574 [53248/54000 (99%)] Loss: -1557.792969\n",
      "    epoch          : 574\n",
      "    loss           : -1554.4584550179577\n",
      "    ess            : 3.7865497896456604\n",
      "    log_marginal   : 1554.588316424763\n",
      "    val_loss       : -1554.2317199707031\n",
      "    val_ess        : 3.786710242430369\n",
      "    val_log_marginal: 1554.3624013264973\n",
      "Train Epoch: 575 [0/54000 (0%)] Loss: -1556.350952\n",
      "Train Epoch: 575 [4096/54000 (8%)] Loss: -1548.071777\n",
      "Train Epoch: 575 [8192/54000 (15%)] Loss: -1557.378296\n",
      "Train Epoch: 575 [12288/54000 (23%)] Loss: -1554.396362\n",
      "Train Epoch: 575 [16384/54000 (30%)] Loss: -1556.236084\n",
      "Train Epoch: 575 [20480/54000 (38%)] Loss: -1554.514893\n",
      "Train Epoch: 575 [24576/54000 (46%)] Loss: -1548.048706\n",
      "Train Epoch: 575 [28672/54000 (53%)] Loss: -1550.199585\n",
      "Train Epoch: 575 [32768/54000 (61%)] Loss: -1547.002197\n",
      "Train Epoch: 575 [36864/54000 (68%)] Loss: -1551.271240\n",
      "Train Epoch: 575 [40960/54000 (76%)] Loss: -1555.078857\n",
      "Train Epoch: 575 [45056/54000 (83%)] Loss: -1552.304688\n",
      "Train Epoch: 575 [49152/54000 (91%)] Loss: -1557.445557\n",
      "Train Epoch: 575 [53248/54000 (99%)] Loss: -1550.411499\n",
      "    epoch          : 575\n",
      "    loss           : -1554.7065111494742\n",
      "    ess            : 3.790138644629745\n",
      "    log_marginal   : 1554.8368926568055\n",
      "    val_loss       : -1554.4071553548176\n",
      "    val_ess        : 3.781066983938217\n",
      "    val_log_marginal: 1554.5438639322917\n",
      "Train Epoch: 576 [0/54000 (0%)] Loss: -1558.611084\n",
      "Train Epoch: 576 [4096/54000 (8%)] Loss: -1555.840820\n",
      "Train Epoch: 576 [8192/54000 (15%)] Loss: -1555.092285\n",
      "Train Epoch: 576 [12288/54000 (23%)] Loss: -1549.775635\n",
      "Train Epoch: 576 [16384/54000 (30%)] Loss: -1558.206787\n",
      "Train Epoch: 576 [20480/54000 (38%)] Loss: -1551.073242\n",
      "Train Epoch: 576 [24576/54000 (46%)] Loss: -1553.441406\n",
      "Train Epoch: 576 [28672/54000 (53%)] Loss: -1555.543945\n",
      "Train Epoch: 576 [32768/54000 (61%)] Loss: -1559.596436\n",
      "Train Epoch: 576 [36864/54000 (68%)] Loss: -1552.968994\n",
      "Train Epoch: 576 [40960/54000 (76%)] Loss: -1550.724854\n",
      "Train Epoch: 576 [45056/54000 (83%)] Loss: -1555.503662\n",
      "Train Epoch: 576 [49152/54000 (91%)] Loss: -1552.012695\n",
      "Train Epoch: 576 [53248/54000 (99%)] Loss: -1550.755371\n",
      "    epoch          : 576\n",
      "    loss           : -1554.9008719638625\n",
      "    ess            : 3.7872493922427934\n",
      "    log_marginal   : 1555.0324654963345\n",
      "    val_loss       : -1555.1245524088542\n",
      "    val_ess        : 3.7759139935175576\n",
      "    val_log_marginal: 1555.2685953776042\n",
      "Train Epoch: 577 [0/54000 (0%)] Loss: -1562.290283\n",
      "Train Epoch: 577 [4096/54000 (8%)] Loss: -1547.659424\n",
      "Train Epoch: 577 [8192/54000 (15%)] Loss: -1558.134766\n",
      "Train Epoch: 577 [12288/54000 (23%)] Loss: -1552.396240\n",
      "Train Epoch: 577 [16384/54000 (30%)] Loss: -1553.588013\n",
      "Train Epoch: 577 [20480/54000 (38%)] Loss: -1554.983276\n",
      "Train Epoch: 577 [24576/54000 (46%)] Loss: -1559.460693\n",
      "Train Epoch: 577 [28672/54000 (53%)] Loss: -1553.835938\n",
      "Train Epoch: 577 [32768/54000 (61%)] Loss: -1553.129150\n",
      "Train Epoch: 577 [36864/54000 (68%)] Loss: -1554.639648\n",
      "Train Epoch: 577 [40960/54000 (76%)] Loss: -1552.765747\n",
      "Train Epoch: 577 [45056/54000 (83%)] Loss: -1557.787354\n",
      "Train Epoch: 577 [49152/54000 (91%)] Loss: -1558.831177\n",
      "Train Epoch: 577 [53248/54000 (99%)] Loss: -1555.778076\n",
      "    epoch          : 577\n",
      "    loss           : -1554.7645709141736\n",
      "    ess            : 3.788302949254547\n",
      "    log_marginal   : 1554.8945827393736\n",
      "    val_loss       : -1554.58935546875\n",
      "    val_ess        : 3.792564113934835\n",
      "    val_log_marginal: 1554.7166697184246\n",
      "Train Epoch: 578 [0/54000 (0%)] Loss: -1556.062744\n",
      "Train Epoch: 578 [4096/54000 (8%)] Loss: -1549.519531\n",
      "Train Epoch: 578 [8192/54000 (15%)] Loss: -1557.607178\n",
      "Train Epoch: 578 [12288/54000 (23%)] Loss: -1551.901611\n",
      "Train Epoch: 578 [16384/54000 (30%)] Loss: -1559.279053\n",
      "Train Epoch: 578 [20480/54000 (38%)] Loss: -1552.820312\n",
      "Train Epoch: 578 [24576/54000 (46%)] Loss: -1557.002197\n",
      "Train Epoch: 578 [28672/54000 (53%)] Loss: -1547.160645\n",
      "Train Epoch: 578 [32768/54000 (61%)] Loss: -1560.612915\n",
      "Train Epoch: 578 [36864/54000 (68%)] Loss: -1554.650635\n",
      "Train Epoch: 578 [40960/54000 (76%)] Loss: -1549.853027\n",
      "Train Epoch: 578 [45056/54000 (83%)] Loss: -1561.335938\n",
      "Train Epoch: 578 [49152/54000 (91%)] Loss: -1554.081055\n",
      "Train Epoch: 578 [53248/54000 (99%)] Loss: -1554.642822\n",
      "    epoch          : 578\n",
      "    loss           : -1554.7338300225858\n",
      "    ess            : 3.783193471872411\n",
      "    log_marginal   : 1554.8691429391292\n",
      "    val_loss       : -1554.446283976237\n",
      "    val_ess        : 3.7862954239050546\n",
      "    val_log_marginal: 1554.5763193766277\n",
      "Train Epoch: 579 [0/54000 (0%)] Loss: -1551.449707\n",
      "Train Epoch: 579 [4096/54000 (8%)] Loss: -1554.111816\n",
      "Train Epoch: 579 [8192/54000 (15%)] Loss: -1553.338379\n",
      "Train Epoch: 579 [12288/54000 (23%)] Loss: -1547.508423\n",
      "Train Epoch: 579 [16384/54000 (30%)] Loss: -1551.392578\n",
      "Train Epoch: 579 [20480/54000 (38%)] Loss: -1552.958862\n",
      "Train Epoch: 579 [24576/54000 (46%)] Loss: -1545.001709\n",
      "Train Epoch: 579 [28672/54000 (53%)] Loss: -1554.127197\n",
      "Train Epoch: 579 [32768/54000 (61%)] Loss: -1559.756592\n",
      "Train Epoch: 579 [36864/54000 (68%)] Loss: -1555.720215\n",
      "Train Epoch: 579 [40960/54000 (76%)] Loss: -1553.816650\n",
      "Train Epoch: 579 [45056/54000 (83%)] Loss: -1563.963379\n",
      "Train Epoch: 579 [49152/54000 (91%)] Loss: -1556.497925\n",
      "Train Epoch: 579 [53248/54000 (99%)] Loss: -1551.226562\n",
      "    epoch          : 579\n",
      "    loss           : -1555.0072692581828\n",
      "    ess            : 3.7878043787174316\n",
      "    log_marginal   : 1555.1374777843603\n",
      "    val_loss       : -1554.9914245605469\n",
      "    val_ess        : 3.7722124556700387\n",
      "    val_log_marginal: 1555.1405995686848\n",
      "Train Epoch: 580 [0/54000 (0%)] Loss: -1553.752441\n",
      "Train Epoch: 580 [4096/54000 (8%)] Loss: -1555.557007\n",
      "Train Epoch: 580 [8192/54000 (15%)] Loss: -1550.679688\n",
      "Train Epoch: 580 [12288/54000 (23%)] Loss: -1554.208374\n",
      "Train Epoch: 580 [16384/54000 (30%)] Loss: -1552.968994\n",
      "Train Epoch: 580 [20480/54000 (38%)] Loss: -1554.166992\n",
      "Train Epoch: 580 [24576/54000 (46%)] Loss: -1552.097534\n",
      "Train Epoch: 580 [28672/54000 (53%)] Loss: -1555.106445\n",
      "Train Epoch: 580 [32768/54000 (61%)] Loss: -1551.814575\n",
      "Train Epoch: 580 [36864/54000 (68%)] Loss: -1550.297119\n",
      "Train Epoch: 580 [40960/54000 (76%)] Loss: -1550.593750\n",
      "Train Epoch: 580 [45056/54000 (83%)] Loss: -1560.793213\n",
      "Train Epoch: 580 [49152/54000 (91%)] Loss: -1551.066284\n",
      "Train Epoch: 580 [53248/54000 (99%)] Loss: -1559.648438\n",
      "    epoch          : 580\n",
      "    loss           : -1554.94452569609\n",
      "    ess            : 3.781577493342178\n",
      "    log_marginal   : 1555.0772138116483\n",
      "    val_loss       : -1554.8225962320964\n",
      "    val_ess        : 3.784362326065699\n",
      "    val_log_marginal: 1554.9536997477214\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch580.pth ...\n",
      "Train Epoch: 581 [0/54000 (0%)] Loss: -1554.835693\n",
      "Train Epoch: 581 [4096/54000 (8%)] Loss: -1553.394043\n",
      "Train Epoch: 581 [8192/54000 (15%)] Loss: -1557.667480\n",
      "Train Epoch: 581 [12288/54000 (23%)] Loss: -1552.834595\n",
      "Train Epoch: 581 [16384/54000 (30%)] Loss: -1555.307373\n",
      "Train Epoch: 581 [20480/54000 (38%)] Loss: -1553.980957\n",
      "Train Epoch: 581 [24576/54000 (46%)] Loss: -1551.682373\n",
      "Train Epoch: 581 [28672/54000 (53%)] Loss: -1556.079956\n",
      "Train Epoch: 581 [32768/54000 (61%)] Loss: -1549.940430\n",
      "Train Epoch: 581 [36864/54000 (68%)] Loss: -1554.993042\n",
      "Train Epoch: 581 [40960/54000 (76%)] Loss: -1557.018311\n",
      "Train Epoch: 581 [45056/54000 (83%)] Loss: -1552.847900\n",
      "Train Epoch: 581 [49152/54000 (91%)] Loss: -1556.632568\n",
      "Train Epoch: 581 [53248/54000 (99%)] Loss: -1554.608154\n",
      "    epoch          : 581\n",
      "    loss           : -1555.2501978580422\n",
      "    ess            : 3.786403181428593\n",
      "    log_marginal   : 1555.384983731672\n",
      "    val_loss       : -1555.0306955973308\n",
      "    val_ess        : 3.7814019918441772\n",
      "    val_log_marginal: 1555.1725260416667\n",
      "Train Epoch: 582 [0/54000 (0%)] Loss: -1554.024170\n",
      "Train Epoch: 582 [4096/54000 (8%)] Loss: -1554.308594\n",
      "Train Epoch: 582 [8192/54000 (15%)] Loss: -1558.130493\n",
      "Train Epoch: 582 [12288/54000 (23%)] Loss: -1551.544434\n",
      "Train Epoch: 582 [16384/54000 (30%)] Loss: -1560.114014\n",
      "Train Epoch: 582 [20480/54000 (38%)] Loss: -1556.023926\n",
      "Train Epoch: 582 [24576/54000 (46%)] Loss: -1563.224121\n",
      "Train Epoch: 582 [28672/54000 (53%)] Loss: -1555.296387\n",
      "Train Epoch: 582 [32768/54000 (61%)] Loss: -1552.337402\n",
      "Train Epoch: 582 [36864/54000 (68%)] Loss: -1557.806274\n",
      "Train Epoch: 582 [40960/54000 (76%)] Loss: -1549.343262\n",
      "Train Epoch: 582 [45056/54000 (83%)] Loss: -1557.580688\n",
      "Train Epoch: 582 [49152/54000 (91%)] Loss: -1547.303711\n",
      "Train Epoch: 582 [53248/54000 (99%)] Loss: -1557.790283\n",
      "    epoch          : 582\n",
      "    loss           : -1555.4876026316276\n",
      "    ess            : 3.7875687477147975\n",
      "    log_marginal   : 1555.6208646512146\n",
      "    val_loss       : -1555.7014973958333\n",
      "    val_ess        : 3.7935321033000946\n",
      "    val_log_marginal: 1555.8283386230469\n",
      "Train Epoch: 583 [0/54000 (0%)] Loss: -1554.162598\n",
      "Train Epoch: 583 [4096/54000 (8%)] Loss: -1556.207031\n",
      "Train Epoch: 583 [8192/54000 (15%)] Loss: -1550.879150\n",
      "Train Epoch: 583 [12288/54000 (23%)] Loss: -1554.972656\n",
      "Train Epoch: 583 [16384/54000 (30%)] Loss: -1555.593140\n",
      "Train Epoch: 583 [20480/54000 (38%)] Loss: -1558.789673\n",
      "Train Epoch: 583 [24576/54000 (46%)] Loss: -1557.041748\n",
      "Train Epoch: 583 [28672/54000 (53%)] Loss: -1552.777832\n",
      "Train Epoch: 583 [32768/54000 (61%)] Loss: -1553.483643\n",
      "Train Epoch: 583 [36864/54000 (68%)] Loss: -1555.918457\n",
      "Train Epoch: 583 [40960/54000 (76%)] Loss: -1560.934448\n",
      "Train Epoch: 583 [45056/54000 (83%)] Loss: -1553.523193\n",
      "Train Epoch: 583 [49152/54000 (91%)] Loss: -1554.167725\n",
      "Train Epoch: 583 [53248/54000 (99%)] Loss: -1565.418701\n",
      "    epoch          : 583\n",
      "    loss           : -1555.3496342518883\n",
      "    ess            : 3.7846402918557986\n",
      "    log_marginal   : 1555.4793747454457\n",
      "    val_loss       : -1555.4293467203777\n",
      "    val_ess        : 3.7870238522688546\n",
      "    val_log_marginal: 1555.559331258138\n",
      "Train Epoch: 584 [0/54000 (0%)] Loss: -1556.187744\n",
      "Train Epoch: 584 [4096/54000 (8%)] Loss: -1555.533447\n",
      "Train Epoch: 584 [8192/54000 (15%)] Loss: -1547.967041\n",
      "Train Epoch: 584 [12288/54000 (23%)] Loss: -1552.883301\n",
      "Train Epoch: 584 [16384/54000 (30%)] Loss: -1551.693237\n",
      "Train Epoch: 584 [20480/54000 (38%)] Loss: -1554.305176\n",
      "Train Epoch: 584 [24576/54000 (46%)] Loss: -1551.804688\n",
      "Train Epoch: 584 [28672/54000 (53%)] Loss: -1555.646851\n",
      "Train Epoch: 584 [32768/54000 (61%)] Loss: -1556.520508\n",
      "Train Epoch: 584 [36864/54000 (68%)] Loss: -1557.151367\n",
      "Train Epoch: 584 [40960/54000 (76%)] Loss: -1555.522339\n",
      "Train Epoch: 584 [45056/54000 (83%)] Loss: -1564.520874\n",
      "Train Epoch: 584 [49152/54000 (91%)] Loss: -1558.570312\n",
      "Train Epoch: 584 [53248/54000 (99%)] Loss: -1551.723633\n",
      "    epoch          : 584\n",
      "    loss           : -1555.5137424559389\n",
      "    ess            : 3.7872525447917775\n",
      "    log_marginal   : 1555.6441766097082\n",
      "    val_loss       : -1554.837646484375\n",
      "    val_ess        : 3.791638861099879\n",
      "    val_log_marginal: 1554.9588928222656\n",
      "Train Epoch: 585 [0/54000 (0%)] Loss: -1558.629150\n",
      "Train Epoch: 585 [4096/54000 (8%)] Loss: -1554.293457\n",
      "Train Epoch: 585 [8192/54000 (15%)] Loss: -1555.260498\n",
      "Train Epoch: 585 [12288/54000 (23%)] Loss: -1554.593994\n",
      "Train Epoch: 585 [16384/54000 (30%)] Loss: -1553.988770\n",
      "Train Epoch: 585 [20480/54000 (38%)] Loss: -1561.807617\n",
      "Train Epoch: 585 [24576/54000 (46%)] Loss: -1558.935913\n",
      "Train Epoch: 585 [28672/54000 (53%)] Loss: -1555.849121\n",
      "Train Epoch: 585 [32768/54000 (61%)] Loss: -1554.520874\n",
      "Train Epoch: 585 [36864/54000 (68%)] Loss: -1552.364380\n",
      "Train Epoch: 585 [40960/54000 (76%)] Loss: -1552.960693\n",
      "Train Epoch: 585 [45056/54000 (83%)] Loss: -1555.053467\n",
      "Train Epoch: 585 [49152/54000 (91%)] Loss: -1551.468140\n",
      "Train Epoch: 585 [53248/54000 (99%)] Loss: -1551.063477\n",
      "    epoch          : 585\n",
      "    loss           : -1555.2507596128926\n",
      "    ess            : 3.7875604448725264\n",
      "    log_marginal   : 1555.3817676706901\n",
      "    val_loss       : -1554.6160736083984\n",
      "    val_ess        : 3.794091443220774\n",
      "    val_log_marginal: 1554.7457478841145\n",
      "Train Epoch: 586 [0/54000 (0%)] Loss: -1554.943848\n",
      "Train Epoch: 586 [4096/54000 (8%)] Loss: -1550.064941\n",
      "Train Epoch: 586 [8192/54000 (15%)] Loss: -1557.708008\n",
      "Train Epoch: 586 [12288/54000 (23%)] Loss: -1547.954102\n",
      "Train Epoch: 586 [16384/54000 (30%)] Loss: -1554.869385\n",
      "Train Epoch: 586 [20480/54000 (38%)] Loss: -1551.241699\n",
      "Train Epoch: 586 [24576/54000 (46%)] Loss: -1551.445557\n",
      "Train Epoch: 586 [28672/54000 (53%)] Loss: -1548.119873\n",
      "Train Epoch: 586 [32768/54000 (61%)] Loss: -1549.767578\n",
      "Train Epoch: 586 [36864/54000 (68%)] Loss: -1552.886963\n",
      "Train Epoch: 586 [40960/54000 (76%)] Loss: -1559.685181\n",
      "Train Epoch: 586 [45056/54000 (83%)] Loss: -1547.604736\n",
      "Train Epoch: 586 [49152/54000 (91%)] Loss: -1563.309326\n",
      "Train Epoch: 586 [53248/54000 (99%)] Loss: -1559.419556\n",
      "    epoch          : 586\n",
      "    loss           : -1555.3150773613374\n",
      "    ess            : 3.7878676059686742\n",
      "    log_marginal   : 1555.447406786878\n",
      "    val_loss       : -1554.6636606852214\n",
      "    val_ess        : 3.77920467654864\n",
      "    val_log_marginal: 1554.7957051595051\n",
      "Train Epoch: 587 [0/54000 (0%)] Loss: -1552.857422\n",
      "Train Epoch: 587 [4096/54000 (8%)] Loss: -1555.278809\n",
      "Train Epoch: 587 [8192/54000 (15%)] Loss: -1554.784668\n",
      "Train Epoch: 587 [12288/54000 (23%)] Loss: -1558.232666\n",
      "Train Epoch: 587 [16384/54000 (30%)] Loss: -1553.973145\n",
      "Train Epoch: 587 [20480/54000 (38%)] Loss: -1550.977783\n",
      "Train Epoch: 587 [24576/54000 (46%)] Loss: -1548.580566\n",
      "Train Epoch: 587 [28672/54000 (53%)] Loss: -1558.730225\n",
      "Train Epoch: 587 [32768/54000 (61%)] Loss: -1556.697388\n",
      "Train Epoch: 587 [36864/54000 (68%)] Loss: -1558.827148\n",
      "Train Epoch: 587 [40960/54000 (76%)] Loss: -1561.138428\n",
      "Train Epoch: 587 [45056/54000 (83%)] Loss: -1559.282715\n",
      "Train Epoch: 587 [49152/54000 (91%)] Loss: -1556.362305\n",
      "Train Epoch: 587 [53248/54000 (99%)] Loss: -1556.703125\n",
      "    epoch          : 587\n",
      "    loss           : -1555.6894403972897\n",
      "    ess            : 3.7885085361263764\n",
      "    log_marginal   : 1555.819949181724\n",
      "    val_loss       : -1554.6595255533855\n",
      "    val_ess        : 3.7939454118410745\n",
      "    val_log_marginal: 1554.7782948811848\n",
      "Train Epoch: 588 [0/54000 (0%)] Loss: -1559.789185\n",
      "Train Epoch: 588 [4096/54000 (8%)] Loss: -1545.604980\n",
      "Train Epoch: 588 [8192/54000 (15%)] Loss: -1544.138306\n",
      "Train Epoch: 588 [12288/54000 (23%)] Loss: -1559.859619\n",
      "Train Epoch: 588 [16384/54000 (30%)] Loss: -1550.107910\n",
      "Train Epoch: 588 [20480/54000 (38%)] Loss: -1555.156738\n",
      "Train Epoch: 588 [24576/54000 (46%)] Loss: -1556.036377\n",
      "Train Epoch: 588 [28672/54000 (53%)] Loss: -1559.125732\n",
      "Train Epoch: 588 [32768/54000 (61%)] Loss: -1550.299316\n",
      "Train Epoch: 588 [36864/54000 (68%)] Loss: -1556.344971\n",
      "Train Epoch: 588 [40960/54000 (76%)] Loss: -1551.782959\n",
      "Train Epoch: 588 [45056/54000 (83%)] Loss: -1557.627930\n",
      "Train Epoch: 588 [49152/54000 (91%)] Loss: -1555.904053\n",
      "Train Epoch: 588 [53248/54000 (99%)] Loss: -1550.358887\n",
      "    epoch          : 588\n",
      "    loss           : -1555.8306398798504\n",
      "    ess            : 3.7845047876168203\n",
      "    log_marginal   : 1555.9667638986596\n",
      "    val_loss       : -1556.231938680013\n",
      "    val_ess        : 3.7849119206269584\n",
      "    val_log_marginal: 1556.3627471923828\n",
      "Train Epoch: 589 [0/54000 (0%)] Loss: -1551.915771\n",
      "Train Epoch: 589 [4096/54000 (8%)] Loss: -1556.893677\n",
      "Train Epoch: 589 [8192/54000 (15%)] Loss: -1560.973633\n",
      "Train Epoch: 589 [12288/54000 (23%)] Loss: -1557.862183\n",
      "Train Epoch: 589 [16384/54000 (30%)] Loss: -1559.425537\n",
      "Train Epoch: 589 [20480/54000 (38%)] Loss: -1558.789551\n",
      "Train Epoch: 589 [24576/54000 (46%)] Loss: -1551.936768\n",
      "Train Epoch: 589 [28672/54000 (53%)] Loss: -1561.523071\n",
      "Train Epoch: 589 [32768/54000 (61%)] Loss: -1556.779297\n",
      "Train Epoch: 589 [36864/54000 (68%)] Loss: -1558.054688\n",
      "Train Epoch: 589 [40960/54000 (76%)] Loss: -1561.369507\n",
      "Train Epoch: 589 [45056/54000 (83%)] Loss: -1556.735474\n",
      "Train Epoch: 589 [49152/54000 (91%)] Loss: -1559.203735\n",
      "Train Epoch: 589 [53248/54000 (99%)] Loss: -1560.780640\n",
      "    epoch          : 589\n",
      "    loss           : -1555.884729177466\n",
      "    ess            : 3.7840132973205423\n",
      "    log_marginal   : 1556.0187253545246\n",
      "    val_loss       : -1555.5106099446614\n",
      "    val_ess        : 3.7865533431371055\n",
      "    val_log_marginal: 1555.6409352620442\n",
      "Train Epoch: 590 [0/54000 (0%)] Loss: -1555.030273\n",
      "Train Epoch: 590 [4096/54000 (8%)] Loss: -1555.226074\n",
      "Train Epoch: 590 [8192/54000 (15%)] Loss: -1555.902710\n",
      "Train Epoch: 590 [12288/54000 (23%)] Loss: -1559.377197\n",
      "Train Epoch: 590 [16384/54000 (30%)] Loss: -1555.362061\n",
      "Train Epoch: 590 [20480/54000 (38%)] Loss: -1555.263550\n",
      "Train Epoch: 590 [24576/54000 (46%)] Loss: -1560.932007\n",
      "Train Epoch: 590 [28672/54000 (53%)] Loss: -1567.465576\n",
      "Train Epoch: 590 [32768/54000 (61%)] Loss: -1559.835815\n",
      "Train Epoch: 590 [36864/54000 (68%)] Loss: -1552.775146\n",
      "Train Epoch: 590 [40960/54000 (76%)] Loss: -1551.405273\n",
      "Train Epoch: 590 [45056/54000 (83%)] Loss: -1547.779297\n",
      "Train Epoch: 590 [49152/54000 (91%)] Loss: -1552.802979\n",
      "Train Epoch: 590 [53248/54000 (99%)] Loss: -1552.751587\n",
      "    epoch          : 590\n",
      "    loss           : -1555.7976010580198\n",
      "    ess            : 3.7834679831825726\n",
      "    log_marginal   : 1555.9353438101673\n",
      "    val_loss       : -1555.6141001383464\n",
      "    val_ess        : 3.77669624487559\n",
      "    val_log_marginal: 1555.7543182373047\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch590.pth ...\n",
      "Train Epoch: 591 [0/54000 (0%)] Loss: -1548.774902\n",
      "Train Epoch: 591 [4096/54000 (8%)] Loss: -1555.210938\n",
      "Train Epoch: 591 [8192/54000 (15%)] Loss: -1561.941406\n",
      "Train Epoch: 591 [12288/54000 (23%)] Loss: -1560.172607\n",
      "Train Epoch: 591 [16384/54000 (30%)] Loss: -1552.645264\n",
      "Train Epoch: 591 [20480/54000 (38%)] Loss: -1547.912598\n",
      "Train Epoch: 591 [24576/54000 (46%)] Loss: -1561.813477\n",
      "Train Epoch: 591 [28672/54000 (53%)] Loss: -1559.029297\n",
      "Train Epoch: 591 [32768/54000 (61%)] Loss: -1558.795410\n",
      "Train Epoch: 591 [36864/54000 (68%)] Loss: -1558.288330\n",
      "Train Epoch: 591 [40960/54000 (76%)] Loss: -1554.649292\n",
      "Train Epoch: 591 [45056/54000 (83%)] Loss: -1553.088135\n",
      "Train Epoch: 591 [49152/54000 (91%)] Loss: -1552.669434\n",
      "Train Epoch: 591 [53248/54000 (99%)] Loss: -1557.183350\n",
      "    epoch          : 591\n",
      "    loss           : -1555.7828253434168\n",
      "    ess            : 3.792118335787154\n",
      "    log_marginal   : 1555.9141463871815\n",
      "    val_loss       : -1554.7411499023438\n",
      "    val_ess        : 3.779913584391276\n",
      "    val_log_marginal: 1554.8849589029949\n",
      "Train Epoch: 592 [0/54000 (0%)] Loss: -1555.707886\n",
      "Train Epoch: 592 [4096/54000 (8%)] Loss: -1553.883057\n",
      "Train Epoch: 592 [8192/54000 (15%)] Loss: -1547.973145\n",
      "Train Epoch: 592 [12288/54000 (23%)] Loss: -1557.178711\n",
      "Train Epoch: 592 [16384/54000 (30%)] Loss: -1556.610107\n",
      "Train Epoch: 592 [20480/54000 (38%)] Loss: -1550.980591\n",
      "Train Epoch: 592 [24576/54000 (46%)] Loss: -1560.787109\n",
      "Train Epoch: 592 [28672/54000 (53%)] Loss: -1553.362427\n",
      "Train Epoch: 592 [32768/54000 (61%)] Loss: -1553.386963\n",
      "Train Epoch: 592 [36864/54000 (68%)] Loss: -1564.810181\n",
      "Train Epoch: 592 [40960/54000 (76%)] Loss: -1551.903076\n",
      "Train Epoch: 592 [45056/54000 (83%)] Loss: -1552.768311\n",
      "Train Epoch: 592 [49152/54000 (91%)] Loss: -1559.698975\n",
      "Train Epoch: 592 [53248/54000 (99%)] Loss: -1562.880371\n",
      "    epoch          : 592\n",
      "    loss           : -1556.019353640588\n",
      "    ess            : 3.784684943926843\n",
      "    log_marginal   : 1556.1538577689944\n",
      "    val_loss       : -1556.047139485677\n",
      "    val_ess        : 3.765946328639984\n",
      "    val_log_marginal: 1556.1945495605469\n",
      "Train Epoch: 593 [0/54000 (0%)] Loss: -1553.825317\n",
      "Train Epoch: 593 [4096/54000 (8%)] Loss: -1555.619385\n",
      "Train Epoch: 593 [8192/54000 (15%)] Loss: -1548.687012\n",
      "Train Epoch: 593 [12288/54000 (23%)] Loss: -1549.862061\n",
      "Train Epoch: 593 [16384/54000 (30%)] Loss: -1550.027100\n",
      "Train Epoch: 593 [20480/54000 (38%)] Loss: -1560.677002\n",
      "Train Epoch: 593 [24576/54000 (46%)] Loss: -1561.264771\n",
      "Train Epoch: 593 [28672/54000 (53%)] Loss: -1558.951904\n",
      "Train Epoch: 593 [32768/54000 (61%)] Loss: -1559.796509\n",
      "Train Epoch: 593 [36864/54000 (68%)] Loss: -1556.855225\n",
      "Train Epoch: 593 [40960/54000 (76%)] Loss: -1552.655273\n",
      "Train Epoch: 593 [45056/54000 (83%)] Loss: -1554.353394\n",
      "Train Epoch: 593 [49152/54000 (91%)] Loss: -1555.954712\n",
      "Train Epoch: 593 [53248/54000 (99%)] Loss: -1554.806885\n",
      "    epoch          : 593\n",
      "    loss           : -1555.9458684695276\n",
      "    ess            : 3.791502114155846\n",
      "    log_marginal   : 1556.0727018383443\n",
      "    val_loss       : -1554.6507008870442\n",
      "    val_ess        : 3.7955846786499023\n",
      "    val_log_marginal: 1554.7827809651692\n",
      "Train Epoch: 594 [0/54000 (0%)] Loss: -1550.640747\n",
      "Train Epoch: 594 [4096/54000 (8%)] Loss: -1556.978271\n",
      "Train Epoch: 594 [8192/54000 (15%)] Loss: -1557.717285\n",
      "Train Epoch: 594 [12288/54000 (23%)] Loss: -1558.142334\n",
      "Train Epoch: 594 [16384/54000 (30%)] Loss: -1557.744141\n",
      "Train Epoch: 594 [20480/54000 (38%)] Loss: -1560.334961\n",
      "Train Epoch: 594 [24576/54000 (46%)] Loss: -1562.136475\n",
      "Train Epoch: 594 [28672/54000 (53%)] Loss: -1560.038940\n",
      "Train Epoch: 594 [32768/54000 (61%)] Loss: -1552.423584\n",
      "Train Epoch: 594 [36864/54000 (68%)] Loss: -1554.861572\n",
      "Train Epoch: 594 [40960/54000 (76%)] Loss: -1552.853027\n",
      "Train Epoch: 594 [45056/54000 (83%)] Loss: -1555.406738\n",
      "Train Epoch: 594 [49152/54000 (91%)] Loss: -1554.626221\n",
      "Train Epoch: 594 [53248/54000 (99%)] Loss: -1562.365967\n",
      "    epoch          : 594\n",
      "    loss           : -1556.1069463214603\n",
      "    ess            : 3.785649603577022\n",
      "    log_marginal   : 1556.2414192091233\n",
      "    val_loss       : -1556.3454030354817\n",
      "    val_ess        : 3.7818810840447745\n",
      "    val_log_marginal: 1556.4857381184895\n",
      "Train Epoch: 595 [0/54000 (0%)] Loss: -1558.948120\n",
      "Train Epoch: 595 [4096/54000 (8%)] Loss: -1557.377441\n",
      "Train Epoch: 595 [8192/54000 (15%)] Loss: -1561.329224\n",
      "Train Epoch: 595 [12288/54000 (23%)] Loss: -1560.486572\n",
      "Train Epoch: 595 [16384/54000 (30%)] Loss: -1559.660156\n",
      "Train Epoch: 595 [20480/54000 (38%)] Loss: -1555.780762\n",
      "Train Epoch: 595 [24576/54000 (46%)] Loss: -1556.507690\n",
      "Train Epoch: 595 [28672/54000 (53%)] Loss: -1556.656494\n",
      "Train Epoch: 595 [32768/54000 (61%)] Loss: -1559.721191\n",
      "Train Epoch: 595 [36864/54000 (68%)] Loss: -1555.004272\n",
      "Train Epoch: 595 [40960/54000 (76%)] Loss: -1557.214600\n",
      "Train Epoch: 595 [45056/54000 (83%)] Loss: -1557.698242\n",
      "Train Epoch: 595 [49152/54000 (91%)] Loss: -1550.717529\n",
      "Train Epoch: 595 [53248/54000 (99%)] Loss: -1550.187500\n",
      "    epoch          : 595\n",
      "    loss           : -1555.9453298559686\n",
      "    ess            : 3.785017554793878\n",
      "    log_marginal   : 1556.0769696710233\n",
      "    val_loss       : -1555.073969523112\n",
      "    val_ess        : 3.8049958447615304\n",
      "    val_log_marginal: 1555.1949920654297\n",
      "Train Epoch: 596 [0/54000 (0%)] Loss: -1562.324951\n",
      "Train Epoch: 596 [4096/54000 (8%)] Loss: -1555.044312\n",
      "Train Epoch: 596 [8192/54000 (15%)] Loss: -1553.651123\n",
      "Train Epoch: 596 [12288/54000 (23%)] Loss: -1562.968750\n",
      "Train Epoch: 596 [16384/54000 (30%)] Loss: -1557.160156\n",
      "Train Epoch: 596 [20480/54000 (38%)] Loss: -1553.416748\n",
      "Train Epoch: 596 [24576/54000 (46%)] Loss: -1557.027344\n",
      "Train Epoch: 596 [28672/54000 (53%)] Loss: -1559.322266\n",
      "Train Epoch: 596 [32768/54000 (61%)] Loss: -1553.913818\n",
      "Train Epoch: 596 [36864/54000 (68%)] Loss: -1560.646240\n",
      "Train Epoch: 596 [40960/54000 (76%)] Loss: -1552.017212\n",
      "Train Epoch: 596 [45056/54000 (83%)] Loss: -1560.598511\n",
      "Train Epoch: 596 [49152/54000 (91%)] Loss: -1553.438232\n",
      "Train Epoch: 596 [53248/54000 (99%)] Loss: -1563.918579\n",
      "    epoch          : 596\n",
      "    loss           : -1556.2193840713862\n",
      "    ess            : 3.7848568335528623\n",
      "    log_marginal   : 1556.3532199950014\n",
      "    val_loss       : -1555.712875366211\n",
      "    val_ess        : 3.7818139096101127\n",
      "    val_log_marginal: 1555.8485717773438\n",
      "Train Epoch: 597 [0/54000 (0%)] Loss: -1554.633423\n",
      "Train Epoch: 597 [4096/54000 (8%)] Loss: -1553.572998\n",
      "Train Epoch: 597 [8192/54000 (15%)] Loss: -1548.227661\n",
      "Train Epoch: 597 [12288/54000 (23%)] Loss: -1554.348877\n",
      "Train Epoch: 597 [16384/54000 (30%)] Loss: -1554.660156\n",
      "Train Epoch: 597 [20480/54000 (38%)] Loss: -1556.517334\n",
      "Train Epoch: 597 [24576/54000 (46%)] Loss: -1562.595947\n",
      "Train Epoch: 597 [28672/54000 (53%)] Loss: -1553.882202\n",
      "Train Epoch: 597 [32768/54000 (61%)] Loss: -1554.137451\n",
      "Train Epoch: 597 [36864/54000 (68%)] Loss: -1557.227783\n",
      "Train Epoch: 597 [40960/54000 (76%)] Loss: -1561.014404\n",
      "Train Epoch: 597 [45056/54000 (83%)] Loss: -1559.061768\n",
      "Train Epoch: 597 [49152/54000 (91%)] Loss: -1547.449463\n",
      "Train Epoch: 597 [53248/54000 (99%)] Loss: -1560.695068\n",
      "    epoch          : 597\n",
      "    loss           : -1556.0892328199052\n",
      "    ess            : 3.7837170085635794\n",
      "    log_marginal   : 1556.224724502925\n",
      "    val_loss       : -1556.339828491211\n",
      "    val_ess        : 3.786603252092997\n",
      "    val_log_marginal: 1556.4745839436848\n",
      "Train Epoch: 598 [0/54000 (0%)] Loss: -1556.546387\n",
      "Train Epoch: 598 [4096/54000 (8%)] Loss: -1559.613403\n",
      "Train Epoch: 598 [8192/54000 (15%)] Loss: -1551.812866\n",
      "Train Epoch: 598 [12288/54000 (23%)] Loss: -1555.443115\n",
      "Train Epoch: 598 [16384/54000 (30%)] Loss: -1561.229248\n",
      "Train Epoch: 598 [20480/54000 (38%)] Loss: -1560.922485\n",
      "Train Epoch: 598 [24576/54000 (46%)] Loss: -1557.615112\n",
      "Train Epoch: 598 [28672/54000 (53%)] Loss: -1558.384521\n",
      "Train Epoch: 598 [32768/54000 (61%)] Loss: -1552.127197\n",
      "Train Epoch: 598 [36864/54000 (68%)] Loss: -1563.250000\n",
      "Train Epoch: 598 [40960/54000 (76%)] Loss: -1559.515625\n",
      "Train Epoch: 598 [45056/54000 (83%)] Loss: -1552.518311\n",
      "Train Epoch: 598 [49152/54000 (91%)] Loss: -1556.119507\n",
      "Train Epoch: 598 [53248/54000 (99%)] Loss: -1560.303955\n",
      "    epoch          : 598\n",
      "    loss           : -1556.5789627147512\n",
      "    ess            : 3.7842541520629447\n",
      "    log_marginal   : 1556.712121755591\n",
      "    val_loss       : -1557.0014088948567\n",
      "    val_ess        : 3.7846055924892426\n",
      "    val_log_marginal: 1557.1315358479817\n",
      "Train Epoch: 599 [0/54000 (0%)] Loss: -1562.904175\n",
      "Train Epoch: 599 [4096/54000 (8%)] Loss: -1558.220581\n",
      "Train Epoch: 599 [8192/54000 (15%)] Loss: -1551.765381\n",
      "Train Epoch: 599 [12288/54000 (23%)] Loss: -1564.679688\n",
      "Train Epoch: 599 [16384/54000 (30%)] Loss: -1556.170166\n",
      "Train Epoch: 599 [20480/54000 (38%)] Loss: -1557.054077\n",
      "Train Epoch: 599 [24576/54000 (46%)] Loss: -1554.759521\n",
      "Train Epoch: 599 [28672/54000 (53%)] Loss: -1557.138184\n",
      "Train Epoch: 599 [32768/54000 (61%)] Loss: -1558.366211\n",
      "Train Epoch: 599 [36864/54000 (68%)] Loss: -1556.817871\n",
      "Train Epoch: 599 [40960/54000 (76%)] Loss: -1556.526001\n",
      "Train Epoch: 599 [45056/54000 (83%)] Loss: -1546.633301\n",
      "Train Epoch: 599 [49152/54000 (91%)] Loss: -1557.238403\n",
      "Train Epoch: 599 [53248/54000 (99%)] Loss: -1548.391968\n",
      "    epoch          : 599\n",
      "    loss           : -1556.3969911692832\n",
      "    ess            : 3.7868348297914625\n",
      "    log_marginal   : 1556.5285413118336\n",
      "    val_loss       : -1556.4622344970703\n",
      "    val_ess        : 3.7814809481302896\n",
      "    val_log_marginal: 1556.5935160319011\n",
      "Train Epoch: 600 [0/54000 (0%)] Loss: -1559.791138\n",
      "Train Epoch: 600 [4096/54000 (8%)] Loss: -1552.000488\n",
      "Train Epoch: 600 [8192/54000 (15%)] Loss: -1558.350830\n",
      "Train Epoch: 600 [12288/54000 (23%)] Loss: -1556.203857\n",
      "Train Epoch: 600 [16384/54000 (30%)] Loss: -1559.309814\n",
      "Train Epoch: 600 [20480/54000 (38%)] Loss: -1557.676758\n",
      "Train Epoch: 600 [24576/54000 (46%)] Loss: -1558.819458\n",
      "Train Epoch: 600 [28672/54000 (53%)] Loss: -1549.913574\n",
      "Train Epoch: 600 [32768/54000 (61%)] Loss: -1558.439209\n",
      "Train Epoch: 600 [36864/54000 (68%)] Loss: -1556.923584\n",
      "Train Epoch: 600 [40960/54000 (76%)] Loss: -1559.522827\n",
      "Train Epoch: 600 [45056/54000 (83%)] Loss: -1551.913330\n",
      "Train Epoch: 600 [49152/54000 (91%)] Loss: -1551.358887\n",
      "Train Epoch: 600 [53248/54000 (99%)] Loss: -1557.530640\n",
      "    epoch          : 600\n",
      "    loss           : -1555.9936436657656\n",
      "    ess            : 3.7808377482879783\n",
      "    log_marginal   : 1556.1297289229117\n",
      "    val_loss       : -1556.3366394042969\n",
      "    val_ess        : 3.77902020017306\n",
      "    val_log_marginal: 1556.4814860026042\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [0/54000 (0%)] Loss: -1563.893066\n",
      "Train Epoch: 601 [4096/54000 (8%)] Loss: -1554.340454\n",
      "Train Epoch: 601 [8192/54000 (15%)] Loss: -1553.699951\n",
      "Train Epoch: 601 [12288/54000 (23%)] Loss: -1560.591431\n",
      "Train Epoch: 601 [16384/54000 (30%)] Loss: -1557.114136\n",
      "Train Epoch: 601 [20480/54000 (38%)] Loss: -1555.459839\n",
      "Train Epoch: 601 [24576/54000 (46%)] Loss: -1548.850830\n",
      "Train Epoch: 601 [28672/54000 (53%)] Loss: -1558.870605\n",
      "Train Epoch: 601 [32768/54000 (61%)] Loss: -1550.930054\n",
      "Train Epoch: 601 [36864/54000 (68%)] Loss: -1555.321777\n",
      "Train Epoch: 601 [40960/54000 (76%)] Loss: -1553.802368\n",
      "Train Epoch: 601 [45056/54000 (83%)] Loss: -1554.929565\n",
      "Train Epoch: 601 [49152/54000 (91%)] Loss: -1552.425781\n",
      "Train Epoch: 601 [53248/54000 (99%)] Loss: -1558.545654\n",
      "    epoch          : 601\n",
      "    loss           : -1556.2629058982523\n",
      "    ess            : 3.7848505295848396\n",
      "    log_marginal   : 1556.3970663784805\n",
      "    val_loss       : -1556.6643320719402\n",
      "    val_ess        : 3.7977941036224365\n",
      "    val_log_marginal: 1556.7877909342449\n",
      "Train Epoch: 602 [0/54000 (0%)] Loss: -1556.376831\n",
      "Train Epoch: 602 [4096/54000 (8%)] Loss: -1554.211182\n",
      "Train Epoch: 602 [8192/54000 (15%)] Loss: -1557.839844\n",
      "Train Epoch: 602 [12288/54000 (23%)] Loss: -1556.173462\n",
      "Train Epoch: 602 [16384/54000 (30%)] Loss: -1551.610474\n",
      "Train Epoch: 602 [20480/54000 (38%)] Loss: -1551.396362\n",
      "Train Epoch: 602 [24576/54000 (46%)] Loss: -1558.430420\n",
      "Train Epoch: 602 [28672/54000 (53%)] Loss: -1558.359741\n",
      "Train Epoch: 602 [32768/54000 (61%)] Loss: -1556.506592\n",
      "Train Epoch: 602 [36864/54000 (68%)] Loss: -1556.024902\n",
      "Train Epoch: 602 [40960/54000 (76%)] Loss: -1556.210083\n",
      "Train Epoch: 602 [45056/54000 (83%)] Loss: -1557.104248\n",
      "Train Epoch: 602 [49152/54000 (91%)] Loss: -1548.117554\n",
      "Train Epoch: 602 [53248/54000 (99%)] Loss: -1560.340088\n",
      "    epoch          : 602\n",
      "    loss           : -1556.2032164081013\n",
      "    ess            : 3.784918152325526\n",
      "    log_marginal   : 1556.3373560611672\n",
      "    val_loss       : -1555.581059773763\n",
      "    val_ess        : 3.776313771804174\n",
      "    val_log_marginal: 1555.723648071289\n",
      "Train Epoch: 603 [0/54000 (0%)] Loss: -1554.862549\n",
      "Train Epoch: 603 [4096/54000 (8%)] Loss: -1559.194336\n",
      "Train Epoch: 603 [8192/54000 (15%)] Loss: -1555.963623\n",
      "Train Epoch: 603 [12288/54000 (23%)] Loss: -1555.277344\n",
      "Train Epoch: 603 [16384/54000 (30%)] Loss: -1548.837158\n",
      "Train Epoch: 603 [20480/54000 (38%)] Loss: -1559.973877\n",
      "Train Epoch: 603 [24576/54000 (46%)] Loss: -1552.276855\n",
      "Train Epoch: 603 [28672/54000 (53%)] Loss: -1555.934570\n",
      "Train Epoch: 603 [32768/54000 (61%)] Loss: -1552.373413\n",
      "Train Epoch: 603 [36864/54000 (68%)] Loss: -1550.313232\n",
      "Train Epoch: 603 [40960/54000 (76%)] Loss: -1563.417725\n",
      "Train Epoch: 603 [45056/54000 (83%)] Loss: -1555.801270\n",
      "Train Epoch: 603 [49152/54000 (91%)] Loss: -1559.507812\n",
      "Train Epoch: 603 [53248/54000 (99%)] Loss: -1564.808960\n",
      "    epoch          : 603\n",
      "    loss           : -1556.3308140180686\n",
      "    ess            : 3.7848431645976426\n",
      "    log_marginal   : 1556.4654332744\n",
      "    val_loss       : -1556.5625864664714\n",
      "    val_ess        : 3.7875411013762155\n",
      "    val_log_marginal: 1556.6997680664062\n",
      "Train Epoch: 604 [0/54000 (0%)] Loss: -1560.411377\n",
      "Train Epoch: 604 [4096/54000 (8%)] Loss: -1556.527100\n",
      "Train Epoch: 604 [8192/54000 (15%)] Loss: -1558.875854\n",
      "Train Epoch: 604 [12288/54000 (23%)] Loss: -1556.683472\n",
      "Train Epoch: 604 [16384/54000 (30%)] Loss: -1557.786255\n",
      "Train Epoch: 604 [20480/54000 (38%)] Loss: -1559.849365\n",
      "Train Epoch: 604 [24576/54000 (46%)] Loss: -1560.361328\n",
      "Train Epoch: 604 [28672/54000 (53%)] Loss: -1559.796143\n",
      "Train Epoch: 604 [32768/54000 (61%)] Loss: -1553.698730\n",
      "Train Epoch: 604 [36864/54000 (68%)] Loss: -1557.825439\n",
      "Train Epoch: 604 [40960/54000 (76%)] Loss: -1553.993408\n",
      "Train Epoch: 604 [45056/54000 (83%)] Loss: -1558.517090\n",
      "Train Epoch: 604 [49152/54000 (91%)] Loss: -1555.671631\n",
      "Train Epoch: 604 [53248/54000 (99%)] Loss: -1563.455811\n",
      "    epoch          : 604\n",
      "    loss           : -1556.6500099507552\n",
      "    ess            : 3.7891894211701307\n",
      "    log_marginal   : 1556.7811273511552\n",
      "    val_loss       : -1555.8298848470051\n",
      "    val_ess        : 3.7918639381726584\n",
      "    val_log_marginal: 1555.9586283365886\n",
      "Train Epoch: 605 [0/54000 (0%)] Loss: -1558.725586\n",
      "Train Epoch: 605 [4096/54000 (8%)] Loss: -1558.533691\n",
      "Train Epoch: 605 [8192/54000 (15%)] Loss: -1557.196167\n",
      "Train Epoch: 605 [12288/54000 (23%)] Loss: -1555.632690\n",
      "Train Epoch: 605 [16384/54000 (30%)] Loss: -1556.889648\n",
      "Train Epoch: 605 [20480/54000 (38%)] Loss: -1554.760742\n",
      "Train Epoch: 605 [24576/54000 (46%)] Loss: -1554.920898\n",
      "Train Epoch: 605 [28672/54000 (53%)] Loss: -1562.808105\n",
      "Train Epoch: 605 [32768/54000 (61%)] Loss: -1560.763062\n",
      "Train Epoch: 605 [36864/54000 (68%)] Loss: -1562.397705\n",
      "Train Epoch: 605 [40960/54000 (76%)] Loss: -1556.214600\n",
      "Train Epoch: 605 [45056/54000 (83%)] Loss: -1555.916260\n",
      "Train Epoch: 605 [49152/54000 (91%)] Loss: -1555.945190\n",
      "Train Epoch: 605 [53248/54000 (99%)] Loss: -1553.335327\n",
      "    epoch          : 605\n",
      "    loss           : -1556.2914182834716\n",
      "    ess            : 3.7890119823799315\n",
      "    log_marginal   : 1556.4236563009108\n",
      "    val_loss       : -1555.6651051839192\n",
      "    val_ess        : 3.7884946167469025\n",
      "    val_log_marginal: 1555.8002268473308\n",
      "Train Epoch: 606 [0/54000 (0%)] Loss: -1554.093262\n",
      "Train Epoch: 606 [4096/54000 (8%)] Loss: -1556.115845\n",
      "Train Epoch: 606 [8192/54000 (15%)] Loss: -1557.661621\n",
      "Train Epoch: 606 [12288/54000 (23%)] Loss: -1561.126465\n",
      "Train Epoch: 606 [16384/54000 (30%)] Loss: -1555.798340\n",
      "Train Epoch: 606 [20480/54000 (38%)] Loss: -1558.258301\n",
      "Train Epoch: 606 [24576/54000 (46%)] Loss: -1553.867676\n",
      "Train Epoch: 606 [28672/54000 (53%)] Loss: -1554.294434\n",
      "Train Epoch: 606 [32768/54000 (61%)] Loss: -1559.531494\n",
      "Train Epoch: 606 [36864/54000 (68%)] Loss: -1560.681152\n",
      "Train Epoch: 606 [40960/54000 (76%)] Loss: -1565.936401\n",
      "Train Epoch: 606 [45056/54000 (83%)] Loss: -1554.075195\n",
      "Train Epoch: 606 [49152/54000 (91%)] Loss: -1566.682373\n",
      "Train Epoch: 606 [53248/54000 (99%)] Loss: -1553.396729\n",
      "    epoch          : 606\n",
      "    loss           : -1556.5606747306354\n",
      "    ess            : 3.7853842188396727\n",
      "    log_marginal   : 1556.6961004609745\n",
      "    val_loss       : -1557.0418090820312\n",
      "    val_ess        : 3.783750573794047\n",
      "    val_log_marginal: 1557.1773986816406\n",
      "Train Epoch: 607 [0/54000 (0%)] Loss: -1558.165527\n",
      "Train Epoch: 607 [4096/54000 (8%)] Loss: -1560.429199\n",
      "Train Epoch: 607 [8192/54000 (15%)] Loss: -1552.780029\n",
      "Train Epoch: 607 [12288/54000 (23%)] Loss: -1556.988770\n",
      "Train Epoch: 607 [16384/54000 (30%)] Loss: -1553.905762\n",
      "Train Epoch: 607 [20480/54000 (38%)] Loss: -1558.234253\n",
      "Train Epoch: 607 [24576/54000 (46%)] Loss: -1560.613647\n",
      "Train Epoch: 607 [28672/54000 (53%)] Loss: -1554.941162\n",
      "Train Epoch: 607 [32768/54000 (61%)] Loss: -1549.234863\n",
      "Train Epoch: 607 [36864/54000 (68%)] Loss: -1557.211670\n",
      "Train Epoch: 607 [40960/54000 (76%)] Loss: -1559.120239\n",
      "Train Epoch: 607 [45056/54000 (83%)] Loss: -1556.423706\n",
      "Train Epoch: 607 [49152/54000 (91%)] Loss: -1555.035400\n",
      "Train Epoch: 607 [53248/54000 (99%)] Loss: -1553.531250\n",
      "    epoch          : 607\n",
      "    loss           : -1556.7099134978525\n",
      "    ess            : 3.7835225923366456\n",
      "    log_marginal   : 1556.847260533916\n",
      "    val_loss       : -1556.0183664957683\n",
      "    val_ess        : 3.779657413562139\n",
      "    val_log_marginal: 1556.1536204020183\n",
      "Train Epoch: 608 [0/54000 (0%)] Loss: -1555.436279\n",
      "Train Epoch: 608 [4096/54000 (8%)] Loss: -1568.162354\n",
      "Train Epoch: 608 [8192/54000 (15%)] Loss: -1554.147339\n",
      "Train Epoch: 608 [12288/54000 (23%)] Loss: -1557.744629\n",
      "Train Epoch: 608 [16384/54000 (30%)] Loss: -1553.485229\n",
      "Train Epoch: 608 [20480/54000 (38%)] Loss: -1565.548096\n",
      "Train Epoch: 608 [24576/54000 (46%)] Loss: -1552.123779\n",
      "Train Epoch: 608 [28672/54000 (53%)] Loss: -1554.082764\n",
      "Train Epoch: 608 [32768/54000 (61%)] Loss: -1555.229126\n",
      "Train Epoch: 608 [36864/54000 (68%)] Loss: -1550.367432\n",
      "Train Epoch: 608 [40960/54000 (76%)] Loss: -1552.203369\n",
      "Train Epoch: 608 [45056/54000 (83%)] Loss: -1558.125366\n",
      "Train Epoch: 608 [49152/54000 (91%)] Loss: -1558.115845\n",
      "Train Epoch: 608 [53248/54000 (99%)] Loss: -1554.045166\n",
      "    epoch          : 608\n",
      "    loss           : -1556.6853941424763\n",
      "    ess            : 3.7841782117906906\n",
      "    log_marginal   : 1556.8198716583975\n",
      "    val_loss       : -1556.208002726237\n",
      "    val_ess        : 3.788643399874369\n",
      "    val_log_marginal: 1556.3512217203777\n",
      "Train Epoch: 609 [0/54000 (0%)] Loss: -1556.909668\n",
      "Train Epoch: 609 [4096/54000 (8%)] Loss: -1559.809814\n",
      "Train Epoch: 609 [8192/54000 (15%)] Loss: -1552.177490\n",
      "Train Epoch: 609 [12288/54000 (23%)] Loss: -1556.728882\n",
      "Train Epoch: 609 [16384/54000 (30%)] Loss: -1552.079102\n",
      "Train Epoch: 609 [20480/54000 (38%)] Loss: -1560.574707\n",
      "Train Epoch: 609 [24576/54000 (46%)] Loss: -1561.212891\n",
      "Train Epoch: 609 [28672/54000 (53%)] Loss: -1554.144775\n",
      "Train Epoch: 609 [32768/54000 (61%)] Loss: -1557.981323\n",
      "Train Epoch: 609 [36864/54000 (68%)] Loss: -1553.473511\n",
      "Train Epoch: 609 [40960/54000 (76%)] Loss: -1557.313477\n",
      "Train Epoch: 609 [45056/54000 (83%)] Loss: -1555.493286\n",
      "Train Epoch: 609 [49152/54000 (91%)] Loss: -1546.012207\n",
      "Train Epoch: 609 [53248/54000 (99%)] Loss: -1555.854248\n",
      "    epoch          : 609\n",
      "    loss           : -1557.0089713001703\n",
      "    ess            : 3.7899737493686767\n",
      "    log_marginal   : 1557.140203249963\n",
      "    val_loss       : -1557.7849731445312\n",
      "    val_ess        : 3.796511193116506\n",
      "    val_log_marginal: 1557.9147135416667\n",
      "Train Epoch: 610 [0/54000 (0%)] Loss: -1556.348267\n",
      "Train Epoch: 610 [4096/54000 (8%)] Loss: -1561.207642\n",
      "Train Epoch: 610 [8192/54000 (15%)] Loss: -1553.781982\n",
      "Train Epoch: 610 [12288/54000 (23%)] Loss: -1556.757446\n",
      "Train Epoch: 610 [16384/54000 (30%)] Loss: -1557.182739\n",
      "Train Epoch: 610 [20480/54000 (38%)] Loss: -1551.558105\n",
      "Train Epoch: 610 [24576/54000 (46%)] Loss: -1553.310425\n",
      "Train Epoch: 610 [28672/54000 (53%)] Loss: -1551.530396\n",
      "Train Epoch: 610 [32768/54000 (61%)] Loss: -1550.654297\n",
      "Train Epoch: 610 [36864/54000 (68%)] Loss: -1556.259399\n",
      "Train Epoch: 610 [40960/54000 (76%)] Loss: -1563.101196\n",
      "Train Epoch: 610 [45056/54000 (83%)] Loss: -1559.989502\n",
      "Train Epoch: 610 [49152/54000 (91%)] Loss: -1553.638428\n",
      "Train Epoch: 610 [53248/54000 (99%)] Loss: -1552.764526\n",
      "    epoch          : 610\n",
      "    loss           : -1557.0968700246224\n",
      "    ess            : 3.790896310625483\n",
      "    log_marginal   : 1557.2279220508738\n",
      "    val_loss       : -1556.510981241862\n",
      "    val_ess        : 3.771863728761673\n",
      "    val_log_marginal: 1556.6427764892578\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch610.pth ...\n",
      "Train Epoch: 611 [0/54000 (0%)] Loss: -1556.846924\n",
      "Train Epoch: 611 [4096/54000 (8%)] Loss: -1562.156738\n",
      "Train Epoch: 611 [8192/54000 (15%)] Loss: -1555.357422\n",
      "Train Epoch: 611 [12288/54000 (23%)] Loss: -1556.093018\n",
      "Train Epoch: 611 [16384/54000 (30%)] Loss: -1557.204346\n",
      "Train Epoch: 611 [20480/54000 (38%)] Loss: -1556.541138\n",
      "Train Epoch: 611 [24576/54000 (46%)] Loss: -1561.996948\n",
      "Train Epoch: 611 [28672/54000 (53%)] Loss: -1553.879150\n",
      "Train Epoch: 611 [32768/54000 (61%)] Loss: -1561.795776\n",
      "Train Epoch: 611 [36864/54000 (68%)] Loss: -1557.246094\n",
      "Train Epoch: 611 [40960/54000 (76%)] Loss: -1552.077393\n",
      "Train Epoch: 611 [45056/54000 (83%)] Loss: -1556.751465\n",
      "Train Epoch: 611 [49152/54000 (91%)] Loss: -1558.212891\n",
      "Train Epoch: 611 [53248/54000 (99%)] Loss: -1557.740723\n",
      "    epoch          : 611\n",
      "    loss           : -1556.876813698719\n",
      "    ess            : 3.7844123806433654\n",
      "    log_marginal   : 1557.0097245492077\n",
      "    val_loss       : -1556.4276275634766\n",
      "    val_ess        : 3.787322441736857\n",
      "    val_log_marginal: 1556.5680592854817\n",
      "Train Epoch: 612 [0/54000 (0%)] Loss: -1554.860352\n",
      "Train Epoch: 612 [4096/54000 (8%)] Loss: -1559.224609\n",
      "Train Epoch: 612 [8192/54000 (15%)] Loss: -1561.687256\n",
      "Train Epoch: 612 [12288/54000 (23%)] Loss: -1553.529053\n",
      "Train Epoch: 612 [16384/54000 (30%)] Loss: -1556.131348\n",
      "Train Epoch: 612 [20480/54000 (38%)] Loss: -1556.148193\n",
      "Train Epoch: 612 [24576/54000 (46%)] Loss: -1563.213379\n",
      "Train Epoch: 612 [28672/54000 (53%)] Loss: -1555.036377\n",
      "Train Epoch: 612 [32768/54000 (61%)] Loss: -1559.096191\n",
      "Train Epoch: 612 [36864/54000 (68%)] Loss: -1566.441895\n",
      "Train Epoch: 612 [40960/54000 (76%)] Loss: -1557.037354\n",
      "Train Epoch: 612 [45056/54000 (83%)] Loss: -1560.617188\n",
      "Train Epoch: 612 [49152/54000 (91%)] Loss: -1561.207642\n",
      "Train Epoch: 612 [53248/54000 (99%)] Loss: -1561.589355\n",
      "    epoch          : 612\n",
      "    loss           : -1557.1889324459419\n",
      "    ess            : 3.7850686893643926\n",
      "    log_marginal   : 1557.3246607486672\n",
      "    val_loss       : -1555.1399993896484\n",
      "    val_ess        : 3.8000259896119437\n",
      "    val_log_marginal: 1555.2591705322266\n",
      "Train Epoch: 613 [0/54000 (0%)] Loss: -1556.665405\n",
      "Train Epoch: 613 [4096/54000 (8%)] Loss: -1554.279053\n",
      "Train Epoch: 613 [8192/54000 (15%)] Loss: -1560.885010\n",
      "Train Epoch: 613 [12288/54000 (23%)] Loss: -1555.369873\n",
      "Train Epoch: 613 [16384/54000 (30%)] Loss: -1558.696533\n",
      "Train Epoch: 613 [20480/54000 (38%)] Loss: -1554.606689\n",
      "Train Epoch: 613 [24576/54000 (46%)] Loss: -1559.379639\n",
      "Train Epoch: 613 [28672/54000 (53%)] Loss: -1565.481445\n",
      "Train Epoch: 613 [32768/54000 (61%)] Loss: -1560.672852\n",
      "Train Epoch: 613 [36864/54000 (68%)] Loss: -1553.328369\n",
      "Train Epoch: 613 [40960/54000 (76%)] Loss: -1555.925659\n",
      "Train Epoch: 613 [45056/54000 (83%)] Loss: -1556.315308\n",
      "Train Epoch: 613 [49152/54000 (91%)] Loss: -1550.392334\n",
      "Train Epoch: 613 [53248/54000 (99%)] Loss: -1558.550537\n",
      "    epoch          : 613\n",
      "    loss           : -1556.950950297134\n",
      "    ess            : 3.786684744730945\n",
      "    log_marginal   : 1557.082194974637\n",
      "    val_loss       : -1555.4301503499348\n",
      "    val_ess        : 3.7946054339408875\n",
      "    val_log_marginal: 1555.549280802409\n",
      "Train Epoch: 614 [0/54000 (0%)] Loss: -1556.067993\n",
      "Train Epoch: 614 [4096/54000 (8%)] Loss: -1557.620239\n",
      "Train Epoch: 614 [8192/54000 (15%)] Loss: -1563.733643\n",
      "Train Epoch: 614 [12288/54000 (23%)] Loss: -1552.504517\n",
      "Train Epoch: 614 [16384/54000 (30%)] Loss: -1557.407227\n",
      "Train Epoch: 614 [20480/54000 (38%)] Loss: -1559.830078\n",
      "Train Epoch: 614 [24576/54000 (46%)] Loss: -1555.333984\n",
      "Train Epoch: 614 [28672/54000 (53%)] Loss: -1555.765381\n",
      "Train Epoch: 614 [32768/54000 (61%)] Loss: -1561.146851\n",
      "Train Epoch: 614 [36864/54000 (68%)] Loss: -1556.141602\n",
      "Train Epoch: 614 [40960/54000 (76%)] Loss: -1553.637085\n",
      "Train Epoch: 614 [45056/54000 (83%)] Loss: -1557.895752\n",
      "Train Epoch: 614 [49152/54000 (91%)] Loss: -1556.425781\n",
      "Train Epoch: 614 [53248/54000 (99%)] Loss: -1560.470703\n",
      "    epoch          : 614\n",
      "    loss           : -1557.075233495631\n",
      "    ess            : 3.787659187452488\n",
      "    log_marginal   : 1557.2071400140699\n",
      "    val_loss       : -1555.647710164388\n",
      "    val_ess        : 3.7789633373419442\n",
      "    val_log_marginal: 1555.7862752278645\n",
      "Train Epoch: 615 [0/54000 (0%)] Loss: -1554.034668\n",
      "Train Epoch: 615 [4096/54000 (8%)] Loss: -1555.574219\n",
      "Train Epoch: 615 [8192/54000 (15%)] Loss: -1557.025513\n",
      "Train Epoch: 615 [12288/54000 (23%)] Loss: -1556.250244\n",
      "Train Epoch: 615 [16384/54000 (30%)] Loss: -1553.176270\n",
      "Train Epoch: 615 [20480/54000 (38%)] Loss: -1551.569458\n",
      "Train Epoch: 615 [24576/54000 (46%)] Loss: -1560.297974\n",
      "Train Epoch: 615 [28672/54000 (53%)] Loss: -1555.864502\n",
      "Train Epoch: 615 [32768/54000 (61%)] Loss: -1559.573242\n",
      "Train Epoch: 615 [36864/54000 (68%)] Loss: -1561.614014\n",
      "Train Epoch: 615 [40960/54000 (76%)] Loss: -1557.538452\n",
      "Train Epoch: 615 [45056/54000 (83%)] Loss: -1562.035278\n",
      "Train Epoch: 615 [49152/54000 (91%)] Loss: -1551.061768\n",
      "Train Epoch: 615 [53248/54000 (99%)] Loss: -1561.604614\n",
      "    epoch          : 615\n",
      "    loss           : -1557.1070672347082\n",
      "    ess            : 3.7864478594883924\n",
      "    log_marginal   : 1557.240875967306\n",
      "    val_loss       : -1556.606424967448\n",
      "    val_ess        : 3.7734784483909607\n",
      "    val_log_marginal: 1556.7520395914714\n",
      "Train Epoch: 616 [0/54000 (0%)] Loss: -1555.089600\n",
      "Train Epoch: 616 [4096/54000 (8%)] Loss: -1551.717529\n",
      "Train Epoch: 616 [8192/54000 (15%)] Loss: -1556.177246\n",
      "Train Epoch: 616 [12288/54000 (23%)] Loss: -1553.854248\n",
      "Train Epoch: 616 [16384/54000 (30%)] Loss: -1560.069824\n",
      "Train Epoch: 616 [20480/54000 (38%)] Loss: -1551.586304\n",
      "Train Epoch: 616 [24576/54000 (46%)] Loss: -1561.517334\n",
      "Train Epoch: 616 [28672/54000 (53%)] Loss: -1559.714355\n",
      "Train Epoch: 616 [32768/54000 (61%)] Loss: -1560.962891\n",
      "Train Epoch: 616 [36864/54000 (68%)] Loss: -1556.633057\n",
      "Train Epoch: 616 [40960/54000 (76%)] Loss: -1559.072510\n",
      "Train Epoch: 616 [45056/54000 (83%)] Loss: -1555.510986\n",
      "Train Epoch: 616 [49152/54000 (91%)] Loss: -1556.874268\n",
      "Train Epoch: 616 [53248/54000 (99%)] Loss: -1561.037598\n",
      "    epoch          : 616\n",
      "    loss           : -1557.2507740761996\n",
      "    ess            : 3.78703154997803\n",
      "    log_marginal   : 1557.385691855191\n",
      "    val_loss       : -1557.237813313802\n",
      "    val_ess        : 3.7844585180282593\n",
      "    val_log_marginal: 1557.3809865315754\n",
      "Train Epoch: 617 [0/54000 (0%)] Loss: -1554.756714\n",
      "Train Epoch: 617 [4096/54000 (8%)] Loss: -1560.080078\n",
      "Train Epoch: 617 [8192/54000 (15%)] Loss: -1558.484863\n",
      "Train Epoch: 617 [12288/54000 (23%)] Loss: -1559.775879\n",
      "Train Epoch: 617 [16384/54000 (30%)] Loss: -1556.351440\n",
      "Train Epoch: 617 [20480/54000 (38%)] Loss: -1549.087158\n",
      "Train Epoch: 617 [24576/54000 (46%)] Loss: -1549.323120\n",
      "Train Epoch: 617 [28672/54000 (53%)] Loss: -1555.621826\n",
      "Train Epoch: 617 [32768/54000 (61%)] Loss: -1553.505615\n",
      "Train Epoch: 617 [36864/54000 (68%)] Loss: -1561.495117\n",
      "Train Epoch: 617 [40960/54000 (76%)] Loss: -1557.820801\n",
      "Train Epoch: 617 [45056/54000 (83%)] Loss: -1559.728760\n",
      "Train Epoch: 617 [49152/54000 (91%)] Loss: -1559.225464\n",
      "Train Epoch: 617 [53248/54000 (99%)] Loss: -1562.212158\n",
      "    epoch          : 617\n",
      "    loss           : -1557.2355893392698\n",
      "    ess            : 3.787590714992505\n",
      "    log_marginal   : 1557.3694703884034\n",
      "    val_loss       : -1557.204849243164\n",
      "    val_ess        : 3.7805898686250052\n",
      "    val_log_marginal: 1557.3451690673828\n",
      "Train Epoch: 618 [0/54000 (0%)] Loss: -1558.808594\n",
      "Train Epoch: 618 [4096/54000 (8%)] Loss: -1554.740967\n",
      "Train Epoch: 618 [8192/54000 (15%)] Loss: -1560.110107\n",
      "Train Epoch: 618 [12288/54000 (23%)] Loss: -1556.271484\n",
      "Train Epoch: 618 [16384/54000 (30%)] Loss: -1561.393188\n",
      "Train Epoch: 618 [20480/54000 (38%)] Loss: -1558.213867\n",
      "Train Epoch: 618 [24576/54000 (46%)] Loss: -1554.559082\n",
      "Train Epoch: 618 [28672/54000 (53%)] Loss: -1559.056885\n",
      "Train Epoch: 618 [32768/54000 (61%)] Loss: -1551.063843\n",
      "Train Epoch: 618 [36864/54000 (68%)] Loss: -1566.424561\n",
      "Train Epoch: 618 [40960/54000 (76%)] Loss: -1557.237305\n",
      "Train Epoch: 618 [45056/54000 (83%)] Loss: -1550.402100\n",
      "Train Epoch: 618 [49152/54000 (91%)] Loss: -1557.700195\n",
      "Train Epoch: 618 [53248/54000 (99%)] Loss: -1560.712891\n",
      "    epoch          : 618\n",
      "    loss           : -1557.6156532323755\n",
      "    ess            : 3.78498941688176\n",
      "    log_marginal   : 1557.7491096388108\n",
      "    val_loss       : -1556.4089253743489\n",
      "    val_ess        : 3.7867934703826904\n",
      "    val_log_marginal: 1556.5447743733723\n",
      "Train Epoch: 619 [0/54000 (0%)] Loss: -1556.276733\n",
      "Train Epoch: 619 [4096/54000 (8%)] Loss: -1556.435547\n",
      "Train Epoch: 619 [8192/54000 (15%)] Loss: -1551.175171\n",
      "Train Epoch: 619 [12288/54000 (23%)] Loss: -1555.282959\n",
      "Train Epoch: 619 [16384/54000 (30%)] Loss: -1557.335815\n",
      "Train Epoch: 619 [20480/54000 (38%)] Loss: -1554.571899\n",
      "Train Epoch: 619 [24576/54000 (46%)] Loss: -1559.989990\n",
      "Train Epoch: 619 [28672/54000 (53%)] Loss: -1560.416260\n",
      "Train Epoch: 619 [32768/54000 (61%)] Loss: -1552.980225\n",
      "Train Epoch: 619 [36864/54000 (68%)] Loss: -1562.224121\n",
      "Train Epoch: 619 [40960/54000 (76%)] Loss: -1555.210571\n",
      "Train Epoch: 619 [45056/54000 (83%)] Loss: -1552.439575\n",
      "Train Epoch: 619 [49152/54000 (91%)] Loss: -1557.051147\n",
      "Train Epoch: 619 [53248/54000 (99%)] Loss: -1560.864380\n",
      "    epoch          : 619\n",
      "    loss           : -1557.20823806835\n",
      "    ess            : 3.7872531640021156\n",
      "    log_marginal   : 1557.3418651418099\n",
      "    val_loss       : -1556.4735056559246\n",
      "    val_ess        : 3.8011770447095237\n",
      "    val_log_marginal: 1556.5957590738933\n",
      "Train Epoch: 620 [0/54000 (0%)] Loss: -1562.784546\n",
      "Train Epoch: 620 [4096/54000 (8%)] Loss: -1560.645020\n",
      "Train Epoch: 620 [8192/54000 (15%)] Loss: -1553.421021\n",
      "Train Epoch: 620 [12288/54000 (23%)] Loss: -1562.281982\n",
      "Train Epoch: 620 [16384/54000 (30%)] Loss: -1559.449097\n",
      "Train Epoch: 620 [20480/54000 (38%)] Loss: -1557.293701\n",
      "Train Epoch: 620 [24576/54000 (46%)] Loss: -1555.468750\n",
      "Train Epoch: 620 [28672/54000 (53%)] Loss: -1560.702148\n",
      "Train Epoch: 620 [32768/54000 (61%)] Loss: -1558.122437\n",
      "Train Epoch: 620 [36864/54000 (68%)] Loss: -1560.985596\n",
      "Train Epoch: 620 [40960/54000 (76%)] Loss: -1555.624023\n",
      "Train Epoch: 620 [45056/54000 (83%)] Loss: -1557.882080\n",
      "Train Epoch: 620 [49152/54000 (91%)] Loss: -1558.449951\n",
      "Train Epoch: 620 [53248/54000 (99%)] Loss: -1554.437744\n",
      "    epoch          : 620\n",
      "    loss           : -1557.3011173772586\n",
      "    ess            : 3.7907355453165787\n",
      "    log_marginal   : 1557.430460419135\n",
      "    val_loss       : -1556.1188507080078\n",
      "    val_ess        : 3.7905665040016174\n",
      "    val_log_marginal: 1556.2508443196614\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch620.pth ...\n",
      "Train Epoch: 621 [0/54000 (0%)] Loss: -1562.437500\n",
      "Train Epoch: 621 [4096/54000 (8%)] Loss: -1563.545898\n",
      "Train Epoch: 621 [8192/54000 (15%)] Loss: -1560.399414\n",
      "Train Epoch: 621 [12288/54000 (23%)] Loss: -1564.180176\n",
      "Train Epoch: 621 [16384/54000 (30%)] Loss: -1553.566895\n",
      "Train Epoch: 621 [20480/54000 (38%)] Loss: -1554.502075\n",
      "Train Epoch: 621 [24576/54000 (46%)] Loss: -1557.750244\n",
      "Train Epoch: 621 [28672/54000 (53%)] Loss: -1561.639771\n",
      "Train Epoch: 621 [32768/54000 (61%)] Loss: -1560.276611\n",
      "Train Epoch: 621 [36864/54000 (68%)] Loss: -1562.135498\n",
      "Train Epoch: 621 [40960/54000 (76%)] Loss: -1551.884033\n",
      "Train Epoch: 621 [45056/54000 (83%)] Loss: -1558.287598\n",
      "Train Epoch: 621 [49152/54000 (91%)] Loss: -1565.514404\n",
      "Train Epoch: 621 [53248/54000 (99%)] Loss: -1557.435913\n",
      "    epoch          : 621\n",
      "    loss           : -1558.4366293089086\n",
      "    ess            : 3.7935289048470593\n",
      "    log_marginal   : 1558.5657253174986\n",
      "    val_loss       : -1558.1227467854817\n",
      "    val_ess        : 3.804667075475057\n",
      "    val_log_marginal: 1558.2467549641926\n",
      "Train Epoch: 622 [0/54000 (0%)] Loss: -1562.196777\n",
      "Train Epoch: 622 [4096/54000 (8%)] Loss: -1562.745728\n",
      "Train Epoch: 622 [8192/54000 (15%)] Loss: -1561.441895\n",
      "Train Epoch: 622 [12288/54000 (23%)] Loss: -1558.096191\n",
      "Train Epoch: 622 [16384/54000 (30%)] Loss: -1562.212646\n",
      "Train Epoch: 622 [20480/54000 (38%)] Loss: -1553.078369\n",
      "Train Epoch: 622 [24576/54000 (46%)] Loss: -1559.081299\n",
      "Train Epoch: 622 [28672/54000 (53%)] Loss: -1563.428467\n",
      "Train Epoch: 622 [32768/54000 (61%)] Loss: -1561.471191\n",
      "Train Epoch: 622 [36864/54000 (68%)] Loss: -1554.650513\n",
      "Train Epoch: 622 [40960/54000 (76%)] Loss: -1557.414551\n",
      "Train Epoch: 622 [45056/54000 (83%)] Loss: -1557.538940\n",
      "Train Epoch: 622 [49152/54000 (91%)] Loss: -1552.035400\n",
      "Train Epoch: 622 [53248/54000 (99%)] Loss: -1554.864014\n",
      "    epoch          : 622\n",
      "    loss           : -1559.3887702254888\n",
      "    ess            : 3.7925346383551286\n",
      "    log_marginal   : 1559.5177366428466\n",
      "    val_loss       : -1560.1754760742188\n",
      "    val_ess        : 3.791905572017034\n",
      "    val_log_marginal: 1560.3041737874348\n",
      "Train Epoch: 623 [0/54000 (0%)] Loss: -1558.386475\n",
      "Train Epoch: 623 [4096/54000 (8%)] Loss: -1558.861816\n",
      "Train Epoch: 623 [8192/54000 (15%)] Loss: -1558.132812\n",
      "Train Epoch: 623 [12288/54000 (23%)] Loss: -1567.725220\n",
      "Train Epoch: 623 [16384/54000 (30%)] Loss: -1558.354980\n",
      "Train Epoch: 623 [20480/54000 (38%)] Loss: -1564.360596\n",
      "Train Epoch: 623 [24576/54000 (46%)] Loss: -1548.750977\n",
      "Train Epoch: 623 [28672/54000 (53%)] Loss: -1561.619385\n",
      "Train Epoch: 623 [32768/54000 (61%)] Loss: -1563.346313\n",
      "Train Epoch: 623 [36864/54000 (68%)] Loss: -1564.211060\n",
      "Train Epoch: 623 [40960/54000 (76%)] Loss: -1555.738281\n",
      "Train Epoch: 623 [45056/54000 (83%)] Loss: -1556.908447\n",
      "Train Epoch: 623 [49152/54000 (91%)] Loss: -1552.960693\n",
      "Train Epoch: 623 [53248/54000 (99%)] Loss: -1557.363770\n",
      "    epoch          : 623\n",
      "    loss           : -1560.0701962150104\n",
      "    ess            : 3.7959929122744014\n",
      "    log_marginal   : 1560.1949630664988\n",
      "    val_loss       : -1559.613037109375\n",
      "    val_ess        : 3.792890022198359\n",
      "    val_log_marginal: 1559.7393544514973\n",
      "Train Epoch: 624 [0/54000 (0%)] Loss: -1556.254395\n",
      "Train Epoch: 624 [4096/54000 (8%)] Loss: -1557.856201\n",
      "Train Epoch: 624 [8192/54000 (15%)] Loss: -1567.375732\n",
      "Train Epoch: 624 [12288/54000 (23%)] Loss: -1559.041260\n",
      "Train Epoch: 624 [16384/54000 (30%)] Loss: -1560.552734\n",
      "Train Epoch: 624 [20480/54000 (38%)] Loss: -1569.518066\n",
      "Train Epoch: 624 [24576/54000 (46%)] Loss: -1559.238037\n",
      "Train Epoch: 624 [28672/54000 (53%)] Loss: -1553.421997\n",
      "Train Epoch: 624 [32768/54000 (61%)] Loss: -1568.542969\n",
      "Train Epoch: 624 [36864/54000 (68%)] Loss: -1571.326172\n",
      "Train Epoch: 624 [40960/54000 (76%)] Loss: -1558.519653\n",
      "Train Epoch: 624 [45056/54000 (83%)] Loss: -1555.823608\n",
      "Train Epoch: 624 [49152/54000 (91%)] Loss: -1558.770264\n",
      "Train Epoch: 624 [53248/54000 (99%)] Loss: -1561.594849\n",
      "    epoch          : 624\n",
      "    loss           : -1560.410925119409\n",
      "    ess            : 3.796114824394479\n",
      "    log_marginal   : 1560.535483120742\n",
      "    val_loss       : -1560.3284962972004\n",
      "    val_ess        : 3.794304440418879\n",
      "    val_log_marginal: 1560.449966430664\n",
      "Train Epoch: 625 [0/54000 (0%)] Loss: -1554.126221\n",
      "Train Epoch: 625 [4096/54000 (8%)] Loss: -1552.855103\n",
      "Train Epoch: 625 [8192/54000 (15%)] Loss: -1564.793701\n",
      "Train Epoch: 625 [12288/54000 (23%)] Loss: -1567.801392\n",
      "Train Epoch: 625 [16384/54000 (30%)] Loss: -1560.032349\n",
      "Train Epoch: 625 [20480/54000 (38%)] Loss: -1566.410645\n",
      "Train Epoch: 625 [24576/54000 (46%)] Loss: -1565.280396\n",
      "Train Epoch: 625 [28672/54000 (53%)] Loss: -1562.327881\n",
      "Train Epoch: 625 [32768/54000 (61%)] Loss: -1563.887573\n",
      "Train Epoch: 625 [36864/54000 (68%)] Loss: -1561.921631\n",
      "Train Epoch: 625 [40960/54000 (76%)] Loss: -1563.316162\n",
      "Train Epoch: 625 [45056/54000 (83%)] Loss: -1564.161377\n",
      "Train Epoch: 625 [49152/54000 (91%)] Loss: -1560.260742\n",
      "Train Epoch: 625 [53248/54000 (99%)] Loss: -1559.367065\n",
      "    epoch          : 625\n",
      "    loss           : -1560.5930916302577\n",
      "    ess            : 3.7891683815779844\n",
      "    log_marginal   : 1560.7227823700384\n",
      "    val_loss       : -1560.1967671712239\n",
      "    val_ess        : 3.7889317671457925\n",
      "    val_log_marginal: 1560.3260294596355\n",
      "Train Epoch: 626 [0/54000 (0%)] Loss: -1563.067627\n",
      "Train Epoch: 626 [4096/54000 (8%)] Loss: -1561.601562\n",
      "Train Epoch: 626 [8192/54000 (15%)] Loss: -1556.783203\n",
      "Train Epoch: 626 [12288/54000 (23%)] Loss: -1556.721802\n",
      "Train Epoch: 626 [16384/54000 (30%)] Loss: -1555.340332\n",
      "Train Epoch: 626 [20480/54000 (38%)] Loss: -1565.226074\n",
      "Train Epoch: 626 [24576/54000 (46%)] Loss: -1555.979370\n",
      "Train Epoch: 626 [28672/54000 (53%)] Loss: -1561.442139\n",
      "Train Epoch: 626 [32768/54000 (61%)] Loss: -1568.653687\n",
      "Train Epoch: 626 [36864/54000 (68%)] Loss: -1555.588989\n",
      "Train Epoch: 626 [40960/54000 (76%)] Loss: -1555.826416\n",
      "Train Epoch: 626 [45056/54000 (83%)] Loss: -1554.750244\n",
      "Train Epoch: 626 [49152/54000 (91%)] Loss: -1565.116455\n",
      "Train Epoch: 626 [53248/54000 (99%)] Loss: -1563.934326\n",
      "    epoch          : 626\n",
      "    loss           : -1560.5926756655435\n",
      "    ess            : 3.7950065011661764\n",
      "    log_marginal   : 1560.7181060935648\n",
      "    val_loss       : -1560.1860860188801\n",
      "    val_ess        : 3.7927255233128867\n",
      "    val_log_marginal: 1560.3097178141277\n",
      "Train Epoch: 627 [0/54000 (0%)] Loss: -1563.535400\n",
      "Train Epoch: 627 [4096/54000 (8%)] Loss: -1559.518066\n",
      "Train Epoch: 627 [8192/54000 (15%)] Loss: -1564.882812\n",
      "Train Epoch: 627 [12288/54000 (23%)] Loss: -1569.354980\n",
      "Train Epoch: 627 [16384/54000 (30%)] Loss: -1565.339966\n",
      "Train Epoch: 627 [20480/54000 (38%)] Loss: -1570.331787\n",
      "Train Epoch: 627 [24576/54000 (46%)] Loss: -1569.045410\n",
      "Train Epoch: 627 [28672/54000 (53%)] Loss: -1561.135742\n",
      "Train Epoch: 627 [32768/54000 (61%)] Loss: -1554.949463\n",
      "Train Epoch: 627 [36864/54000 (68%)] Loss: -1561.922119\n",
      "Train Epoch: 627 [40960/54000 (76%)] Loss: -1560.070557\n",
      "Train Epoch: 627 [45056/54000 (83%)] Loss: -1562.625854\n",
      "Train Epoch: 627 [49152/54000 (91%)] Loss: -1566.881714\n",
      "Train Epoch: 627 [53248/54000 (99%)] Loss: -1558.946899\n",
      "    epoch          : 627\n",
      "    loss           : -1560.842991544172\n",
      "    ess            : 3.790240170266391\n",
      "    log_marginal   : 1560.9709374305762\n",
      "    val_loss       : -1560.787806193034\n",
      "    val_ess        : 3.801786998907725\n",
      "    val_log_marginal: 1560.9190826416016\n",
      "Train Epoch: 628 [0/54000 (0%)] Loss: -1564.648682\n",
      "Train Epoch: 628 [4096/54000 (8%)] Loss: -1554.992310\n",
      "Train Epoch: 628 [8192/54000 (15%)] Loss: -1556.532959\n",
      "Train Epoch: 628 [12288/54000 (23%)] Loss: -1564.994385\n",
      "Train Epoch: 628 [16384/54000 (30%)] Loss: -1554.841431\n",
      "Train Epoch: 628 [20480/54000 (38%)] Loss: -1568.334961\n",
      "Train Epoch: 628 [24576/54000 (46%)] Loss: -1565.769287\n",
      "Train Epoch: 628 [28672/54000 (53%)] Loss: -1561.425903\n",
      "Train Epoch: 628 [32768/54000 (61%)] Loss: -1565.158691\n",
      "Train Epoch: 628 [36864/54000 (68%)] Loss: -1569.542969\n",
      "Train Epoch: 628 [40960/54000 (76%)] Loss: -1554.889771\n",
      "Train Epoch: 628 [45056/54000 (83%)] Loss: -1555.867554\n",
      "Train Epoch: 628 [49152/54000 (91%)] Loss: -1560.591309\n",
      "Train Epoch: 628 [53248/54000 (99%)] Loss: -1560.409912\n",
      "    epoch          : 628\n",
      "    loss           : -1561.4281503397142\n",
      "    ess            : 3.7881941026985926\n",
      "    log_marginal   : 1561.560647539618\n",
      "    val_loss       : -1560.8171641031902\n",
      "    val_ess        : 3.7868451674779258\n",
      "    val_log_marginal: 1560.9547068277996\n",
      "Train Epoch: 629 [0/54000 (0%)] Loss: -1566.854126\n",
      "Train Epoch: 629 [4096/54000 (8%)] Loss: -1561.272949\n",
      "Train Epoch: 629 [8192/54000 (15%)] Loss: -1561.035889\n",
      "Train Epoch: 629 [12288/54000 (23%)] Loss: -1564.692139\n",
      "Train Epoch: 629 [16384/54000 (30%)] Loss: -1563.902954\n",
      "Train Epoch: 629 [20480/54000 (38%)] Loss: -1562.912109\n",
      "Train Epoch: 629 [24576/54000 (46%)] Loss: -1552.678345\n",
      "Train Epoch: 629 [28672/54000 (53%)] Loss: -1567.368896\n",
      "Train Epoch: 629 [32768/54000 (61%)] Loss: -1562.257446\n",
      "Train Epoch: 629 [36864/54000 (68%)] Loss: -1554.845459\n",
      "Train Epoch: 629 [40960/54000 (76%)] Loss: -1565.852051\n",
      "Train Epoch: 629 [45056/54000 (83%)] Loss: -1560.331543\n",
      "Train Epoch: 629 [49152/54000 (91%)] Loss: -1555.466553\n",
      "Train Epoch: 629 [53248/54000 (99%)] Loss: -1562.662354\n",
      "    epoch          : 629\n",
      "    loss           : -1561.4480981329607\n",
      "    ess            : 3.7927399687292453\n",
      "    log_marginal   : 1561.5759664960383\n",
      "    val_loss       : -1560.8550567626953\n",
      "    val_ess        : 3.784599095582962\n",
      "    val_log_marginal: 1560.982650756836\n",
      "Train Epoch: 630 [0/54000 (0%)] Loss: -1554.063477\n",
      "Train Epoch: 630 [4096/54000 (8%)] Loss: -1566.338867\n",
      "Train Epoch: 630 [8192/54000 (15%)] Loss: -1563.370117\n",
      "Train Epoch: 630 [12288/54000 (23%)] Loss: -1559.607910\n",
      "Train Epoch: 630 [16384/54000 (30%)] Loss: -1558.323364\n",
      "Train Epoch: 630 [20480/54000 (38%)] Loss: -1571.916260\n",
      "Train Epoch: 630 [24576/54000 (46%)] Loss: -1559.862793\n",
      "Train Epoch: 630 [28672/54000 (53%)] Loss: -1555.069092\n",
      "Train Epoch: 630 [32768/54000 (61%)] Loss: -1562.070557\n",
      "Train Epoch: 630 [36864/54000 (68%)] Loss: -1561.604004\n",
      "Train Epoch: 630 [40960/54000 (76%)] Loss: -1555.679932\n",
      "Train Epoch: 630 [45056/54000 (83%)] Loss: -1558.721191\n",
      "Train Epoch: 630 [49152/54000 (91%)] Loss: -1561.758423\n",
      "Train Epoch: 630 [53248/54000 (99%)] Loss: -1556.902954\n",
      "    epoch          : 630\n",
      "    loss           : -1561.6579155944535\n",
      "    ess            : 3.790596811692297\n",
      "    log_marginal   : 1561.7894495381\n",
      "    val_loss       : -1561.5046997070312\n",
      "    val_ess        : 3.7918503681818643\n",
      "    val_log_marginal: 1561.6281483968098\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch630.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 631 [0/54000 (0%)] Loss: -1564.263550\n",
      "Train Epoch: 631 [4096/54000 (8%)] Loss: -1562.309204\n",
      "Train Epoch: 631 [8192/54000 (15%)] Loss: -1565.817627\n",
      "Train Epoch: 631 [12288/54000 (23%)] Loss: -1561.773193\n",
      "Train Epoch: 631 [16384/54000 (30%)] Loss: -1561.233643\n",
      "Train Epoch: 631 [20480/54000 (38%)] Loss: -1559.510742\n",
      "Train Epoch: 631 [24576/54000 (46%)] Loss: -1560.479858\n",
      "Train Epoch: 631 [28672/54000 (53%)] Loss: -1562.472900\n",
      "Train Epoch: 631 [32768/54000 (61%)] Loss: -1564.837646\n",
      "Train Epoch: 631 [36864/54000 (68%)] Loss: -1563.308105\n",
      "Train Epoch: 631 [40960/54000 (76%)] Loss: -1557.455811\n",
      "Train Epoch: 631 [45056/54000 (83%)] Loss: -1558.119385\n",
      "Train Epoch: 631 [49152/54000 (91%)] Loss: -1559.536133\n",
      "Train Epoch: 631 [53248/54000 (99%)] Loss: -1565.317627\n",
      "    epoch          : 631\n",
      "    loss           : -1561.7607537581457\n",
      "    ess            : 3.790260183867685\n",
      "    log_marginal   : 1561.8925301068202\n",
      "    val_loss       : -1561.9091796875\n",
      "    val_ess        : 3.781027138233185\n",
      "    val_log_marginal: 1562.038589477539\n",
      "Train Epoch: 632 [0/54000 (0%)] Loss: -1569.009033\n",
      "Train Epoch: 632 [4096/54000 (8%)] Loss: -1567.266479\n",
      "Train Epoch: 632 [8192/54000 (15%)] Loss: -1566.799805\n",
      "Train Epoch: 632 [12288/54000 (23%)] Loss: -1569.707031\n",
      "Train Epoch: 632 [16384/54000 (30%)] Loss: -1561.682739\n",
      "Train Epoch: 632 [20480/54000 (38%)] Loss: -1569.394653\n",
      "Train Epoch: 632 [24576/54000 (46%)] Loss: -1563.777832\n",
      "Train Epoch: 632 [28672/54000 (53%)] Loss: -1562.481079\n",
      "Train Epoch: 632 [32768/54000 (61%)] Loss: -1560.908813\n",
      "Train Epoch: 632 [36864/54000 (68%)] Loss: -1560.225342\n",
      "Train Epoch: 632 [40960/54000 (76%)] Loss: -1565.091064\n",
      "Train Epoch: 632 [45056/54000 (83%)] Loss: -1559.675537\n",
      "Train Epoch: 632 [49152/54000 (91%)] Loss: -1562.226196\n",
      "Train Epoch: 632 [53248/54000 (99%)] Loss: -1561.070801\n",
      "    epoch          : 632\n",
      "    loss           : -1561.9953034748962\n",
      "    ess            : 3.7882041818157757\n",
      "    log_marginal   : 1562.129804132109\n",
      "    val_loss       : -1561.9820607503254\n",
      "    val_ess        : 3.796519249677658\n",
      "    val_log_marginal: 1562.1092122395833\n",
      "Train Epoch: 633 [0/54000 (0%)] Loss: -1556.999390\n",
      "Train Epoch: 633 [4096/54000 (8%)] Loss: -1559.801514\n",
      "Train Epoch: 633 [8192/54000 (15%)] Loss: -1559.753174\n",
      "Train Epoch: 633 [12288/54000 (23%)] Loss: -1563.601196\n",
      "Train Epoch: 633 [16384/54000 (30%)] Loss: -1560.795776\n",
      "Train Epoch: 633 [20480/54000 (38%)] Loss: -1563.534424\n",
      "Train Epoch: 633 [24576/54000 (46%)] Loss: -1562.804688\n",
      "Train Epoch: 633 [28672/54000 (53%)] Loss: -1563.310547\n",
      "Train Epoch: 633 [32768/54000 (61%)] Loss: -1566.518799\n",
      "Train Epoch: 633 [36864/54000 (68%)] Loss: -1562.263916\n",
      "Train Epoch: 633 [40960/54000 (76%)] Loss: -1563.661133\n",
      "Train Epoch: 633 [45056/54000 (83%)] Loss: -1563.184082\n",
      "Train Epoch: 633 [49152/54000 (91%)] Loss: -1561.215576\n",
      "Train Epoch: 633 [53248/54000 (99%)] Loss: -1565.877930\n",
      "    epoch          : 633\n",
      "    loss           : -1561.981691188722\n",
      "    ess            : 3.7903225907782243\n",
      "    log_marginal   : 1562.1101762672172\n",
      "    val_loss       : -1561.119613647461\n",
      "    val_ess        : 3.793599377075831\n",
      "    val_log_marginal: 1561.2537536621094\n",
      "Train Epoch: 634 [0/54000 (0%)] Loss: -1562.781616\n",
      "Train Epoch: 634 [4096/54000 (8%)] Loss: -1557.705566\n",
      "Train Epoch: 634 [8192/54000 (15%)] Loss: -1559.781494\n",
      "Train Epoch: 634 [12288/54000 (23%)] Loss: -1568.432007\n",
      "Train Epoch: 634 [16384/54000 (30%)] Loss: -1562.140015\n",
      "Train Epoch: 634 [20480/54000 (38%)] Loss: -1557.166260\n",
      "Train Epoch: 634 [24576/54000 (46%)] Loss: -1567.233887\n",
      "Train Epoch: 634 [28672/54000 (53%)] Loss: -1559.951660\n",
      "Train Epoch: 634 [32768/54000 (61%)] Loss: -1564.715332\n",
      "Train Epoch: 634 [36864/54000 (68%)] Loss: -1567.492310\n",
      "Train Epoch: 634 [40960/54000 (76%)] Loss: -1558.591064\n",
      "Train Epoch: 634 [45056/54000 (83%)] Loss: -1563.696655\n",
      "Train Epoch: 634 [49152/54000 (91%)] Loss: -1562.635498\n",
      "Train Epoch: 634 [53248/54000 (99%)] Loss: -1567.966919\n",
      "    epoch          : 634\n",
      "    loss           : -1561.988363980117\n",
      "    ess            : 3.785399016610819\n",
      "    log_marginal   : 1562.122550494298\n",
      "    val_loss       : -1561.1051127115886\n",
      "    val_ess        : 3.7766853272914886\n",
      "    val_log_marginal: 1561.2367045084636\n",
      "Train Epoch: 635 [0/54000 (0%)] Loss: -1564.203369\n",
      "Train Epoch: 635 [4096/54000 (8%)] Loss: -1565.279053\n",
      "Train Epoch: 635 [8192/54000 (15%)] Loss: -1566.536499\n",
      "Train Epoch: 635 [12288/54000 (23%)] Loss: -1570.565308\n",
      "Train Epoch: 635 [16384/54000 (30%)] Loss: -1555.132690\n",
      "Train Epoch: 635 [20480/54000 (38%)] Loss: -1561.977417\n",
      "Train Epoch: 635 [24576/54000 (46%)] Loss: -1557.011230\n",
      "Train Epoch: 635 [28672/54000 (53%)] Loss: -1566.154053\n",
      "Train Epoch: 635 [32768/54000 (61%)] Loss: -1565.953369\n",
      "Train Epoch: 635 [36864/54000 (68%)] Loss: -1564.395508\n",
      "Train Epoch: 635 [40960/54000 (76%)] Loss: -1563.638916\n",
      "Train Epoch: 635 [45056/54000 (83%)] Loss: -1561.818115\n",
      "Train Epoch: 635 [49152/54000 (91%)] Loss: -1560.807373\n",
      "Train Epoch: 635 [53248/54000 (99%)] Loss: -1557.507446\n",
      "    epoch          : 635\n",
      "    loss           : -1562.2856474239115\n",
      "    ess            : 3.793705142504796\n",
      "    log_marginal   : 1562.4098415284361\n",
      "    val_loss       : -1560.9011789957683\n",
      "    val_ess        : 3.793929874897003\n",
      "    val_log_marginal: 1561.0214385986328\n",
      "Train Epoch: 636 [0/54000 (0%)] Loss: -1562.583252\n",
      "Train Epoch: 636 [4096/54000 (8%)] Loss: -1564.467163\n",
      "Train Epoch: 636 [8192/54000 (15%)] Loss: -1567.771362\n",
      "Train Epoch: 636 [12288/54000 (23%)] Loss: -1558.633789\n",
      "Train Epoch: 636 [16384/54000 (30%)] Loss: -1562.872925\n",
      "Train Epoch: 636 [20480/54000 (38%)] Loss: -1556.326538\n",
      "Train Epoch: 636 [24576/54000 (46%)] Loss: -1563.640869\n",
      "Train Epoch: 636 [28672/54000 (53%)] Loss: -1561.645996\n",
      "Train Epoch: 636 [32768/54000 (61%)] Loss: -1552.280029\n",
      "Train Epoch: 636 [36864/54000 (68%)] Loss: -1558.203369\n",
      "Train Epoch: 636 [40960/54000 (76%)] Loss: -1561.696533\n",
      "Train Epoch: 636 [45056/54000 (83%)] Loss: -1558.856934\n",
      "Train Epoch: 636 [49152/54000 (91%)] Loss: -1562.443237\n",
      "Train Epoch: 636 [53248/54000 (99%)] Loss: -1559.521729\n",
      "    epoch          : 636\n",
      "    loss           : -1562.3498066545098\n",
      "    ess            : 3.7885869238613905\n",
      "    log_marginal   : 1562.4826220471712\n",
      "    val_loss       : -1561.7911122639973\n",
      "    val_ess        : 3.792058984438578\n",
      "    val_log_marginal: 1561.9238535563152\n",
      "Train Epoch: 637 [0/54000 (0%)] Loss: -1564.569580\n",
      "Train Epoch: 637 [4096/54000 (8%)] Loss: -1567.217407\n",
      "Train Epoch: 637 [8192/54000 (15%)] Loss: -1563.942993\n",
      "Train Epoch: 637 [12288/54000 (23%)] Loss: -1566.406494\n",
      "Train Epoch: 637 [16384/54000 (30%)] Loss: -1564.466919\n",
      "Train Epoch: 637 [20480/54000 (38%)] Loss: -1553.410767\n",
      "Train Epoch: 637 [24576/54000 (46%)] Loss: -1565.736572\n",
      "Train Epoch: 637 [28672/54000 (53%)] Loss: -1566.221436\n",
      "Train Epoch: 637 [32768/54000 (61%)] Loss: -1565.620361\n",
      "Train Epoch: 637 [36864/54000 (68%)] Loss: -1563.687500\n",
      "Train Epoch: 637 [40960/54000 (76%)] Loss: -1559.472900\n",
      "Train Epoch: 637 [45056/54000 (83%)] Loss: -1568.823242\n",
      "Train Epoch: 637 [49152/54000 (91%)] Loss: -1564.677490\n",
      "Train Epoch: 637 [53248/54000 (99%)] Loss: -1556.954346\n",
      "    epoch          : 637\n",
      "    loss           : -1562.3906070654991\n",
      "    ess            : 3.788755871108358\n",
      "    log_marginal   : 1562.5227912794358\n",
      "    val_loss       : -1561.0909525553386\n",
      "    val_ess        : 3.792223165432612\n",
      "    val_log_marginal: 1561.2174733479817\n",
      "Train Epoch: 638 [0/54000 (0%)] Loss: -1557.403320\n",
      "Train Epoch: 638 [4096/54000 (8%)] Loss: -1567.596313\n",
      "Train Epoch: 638 [8192/54000 (15%)] Loss: -1559.625854\n",
      "Train Epoch: 638 [12288/54000 (23%)] Loss: -1563.102417\n",
      "Train Epoch: 638 [16384/54000 (30%)] Loss: -1562.260254\n",
      "Train Epoch: 638 [20480/54000 (38%)] Loss: -1559.263184\n",
      "Train Epoch: 638 [24576/54000 (46%)] Loss: -1566.599365\n",
      "Train Epoch: 638 [28672/54000 (53%)] Loss: -1560.176758\n",
      "Train Epoch: 638 [32768/54000 (61%)] Loss: -1555.507690\n",
      "Train Epoch: 638 [36864/54000 (68%)] Loss: -1564.824585\n",
      "Train Epoch: 638 [40960/54000 (76%)] Loss: -1564.904541\n",
      "Train Epoch: 638 [45056/54000 (83%)] Loss: -1561.261963\n",
      "Train Epoch: 638 [49152/54000 (91%)] Loss: -1564.367065\n",
      "Train Epoch: 638 [53248/54000 (99%)] Loss: -1564.906738\n",
      "    epoch          : 638\n",
      "    loss           : -1562.4478418431577\n",
      "    ess            : 3.790176850359587\n",
      "    log_marginal   : 1562.5804258229043\n",
      "    val_loss       : -1562.4588165283203\n",
      "    val_ess        : 3.776336838801702\n",
      "    val_log_marginal: 1562.6012624104817\n",
      "Train Epoch: 639 [0/54000 (0%)] Loss: -1568.252075\n",
      "Train Epoch: 639 [4096/54000 (8%)] Loss: -1565.542725\n",
      "Train Epoch: 639 [8192/54000 (15%)] Loss: -1564.749756\n",
      "Train Epoch: 639 [12288/54000 (23%)] Loss: -1560.793213\n",
      "Train Epoch: 639 [16384/54000 (30%)] Loss: -1559.214722\n",
      "Train Epoch: 639 [20480/54000 (38%)] Loss: -1567.964844\n",
      "Train Epoch: 639 [24576/54000 (46%)] Loss: -1560.675049\n",
      "Train Epoch: 639 [28672/54000 (53%)] Loss: -1565.393921\n",
      "Train Epoch: 639 [32768/54000 (61%)] Loss: -1560.684937\n",
      "Train Epoch: 639 [36864/54000 (68%)] Loss: -1560.741333\n",
      "Train Epoch: 639 [40960/54000 (76%)] Loss: -1561.566650\n",
      "Train Epoch: 639 [45056/54000 (83%)] Loss: -1560.579590\n",
      "Train Epoch: 639 [49152/54000 (91%)] Loss: -1554.198242\n",
      "Train Epoch: 639 [53248/54000 (99%)] Loss: -1564.526367\n",
      "    epoch          : 639\n",
      "    loss           : -1562.5598294949646\n",
      "    ess            : 3.7879635734015733\n",
      "    log_marginal   : 1562.6920102377073\n",
      "    val_loss       : -1562.6910654703777\n",
      "    val_ess        : 3.7976867953936257\n",
      "    val_log_marginal: 1562.816630045573\n",
      "Train Epoch: 640 [0/54000 (0%)] Loss: -1565.181519\n",
      "Train Epoch: 640 [4096/54000 (8%)] Loss: -1563.338989\n",
      "Train Epoch: 640 [8192/54000 (15%)] Loss: -1564.996094\n",
      "Train Epoch: 640 [12288/54000 (23%)] Loss: -1564.000732\n",
      "Train Epoch: 640 [16384/54000 (30%)] Loss: -1566.245605\n",
      "Train Epoch: 640 [20480/54000 (38%)] Loss: -1555.632935\n",
      "Train Epoch: 640 [24576/54000 (46%)] Loss: -1560.500488\n",
      "Train Epoch: 640 [28672/54000 (53%)] Loss: -1560.082275\n",
      "Train Epoch: 640 [32768/54000 (61%)] Loss: -1564.318359\n",
      "Train Epoch: 640 [36864/54000 (68%)] Loss: -1560.097046\n",
      "Train Epoch: 640 [40960/54000 (76%)] Loss: -1560.473877\n",
      "Train Epoch: 640 [45056/54000 (83%)] Loss: -1561.912231\n",
      "Train Epoch: 640 [49152/54000 (91%)] Loss: -1560.513672\n",
      "Train Epoch: 640 [53248/54000 (99%)] Loss: -1566.539795\n",
      "    epoch          : 640\n",
      "    loss           : -1562.6516171134479\n",
      "    ess            : 3.790374171677359\n",
      "    log_marginal   : 1562.7825169857078\n",
      "    val_loss       : -1563.1665496826172\n",
      "    val_ess        : 3.7914775013923645\n",
      "    val_log_marginal: 1563.2993418375652\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch640.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 641 [0/54000 (0%)] Loss: -1566.266479\n",
      "Train Epoch: 641 [4096/54000 (8%)] Loss: -1568.380127\n",
      "Train Epoch: 641 [8192/54000 (15%)] Loss: -1559.783447\n",
      "Train Epoch: 641 [12288/54000 (23%)] Loss: -1559.609131\n",
      "Train Epoch: 641 [16384/54000 (30%)] Loss: -1564.567017\n",
      "Train Epoch: 641 [20480/54000 (38%)] Loss: -1557.408203\n",
      "Train Epoch: 641 [24576/54000 (46%)] Loss: -1558.812988\n",
      "Train Epoch: 641 [28672/54000 (53%)] Loss: -1556.359985\n",
      "Train Epoch: 641 [32768/54000 (61%)] Loss: -1567.140503\n",
      "Train Epoch: 641 [36864/54000 (68%)] Loss: -1569.473633\n",
      "Train Epoch: 641 [40960/54000 (76%)] Loss: -1566.766968\n",
      "Train Epoch: 641 [45056/54000 (83%)] Loss: -1565.373413\n",
      "Train Epoch: 641 [49152/54000 (91%)] Loss: -1567.099365\n",
      "Train Epoch: 641 [53248/54000 (99%)] Loss: -1571.085449\n",
      "    epoch          : 641\n",
      "    loss           : -1562.8735993733337\n",
      "    ess            : 3.793383975729558\n",
      "    log_marginal   : 1563.0035805363225\n",
      "    val_loss       : -1563.5255381266277\n",
      "    val_ess        : 3.785320738951365\n",
      "    val_log_marginal: 1563.6621754964192\n",
      "Train Epoch: 642 [0/54000 (0%)] Loss: -1568.390015\n",
      "Train Epoch: 642 [4096/54000 (8%)] Loss: -1557.907471\n",
      "Train Epoch: 642 [8192/54000 (15%)] Loss: -1556.522705\n",
      "Train Epoch: 642 [12288/54000 (23%)] Loss: -1563.124268\n",
      "Train Epoch: 642 [16384/54000 (30%)] Loss: -1567.747559\n",
      "Train Epoch: 642 [20480/54000 (38%)] Loss: -1560.997925\n",
      "Train Epoch: 642 [24576/54000 (46%)] Loss: -1556.830322\n",
      "Train Epoch: 642 [28672/54000 (53%)] Loss: -1563.864868\n",
      "Train Epoch: 642 [32768/54000 (61%)] Loss: -1572.988525\n",
      "Train Epoch: 642 [36864/54000 (68%)] Loss: -1567.933350\n",
      "Train Epoch: 642 [40960/54000 (76%)] Loss: -1562.681519\n",
      "Train Epoch: 642 [45056/54000 (83%)] Loss: -1562.198975\n",
      "Train Epoch: 642 [49152/54000 (91%)] Loss: -1559.741699\n",
      "Train Epoch: 642 [53248/54000 (99%)] Loss: -1559.690918\n",
      "    epoch          : 642\n",
      "    loss           : -1562.9705289867818\n",
      "    ess            : 3.792435405378658\n",
      "    log_marginal   : 1563.1040218407509\n",
      "    val_loss       : -1563.123519897461\n",
      "    val_ess        : 3.785934786001841\n",
      "    val_log_marginal: 1563.250747680664\n",
      "Train Epoch: 643 [0/54000 (0%)] Loss: -1569.244263\n",
      "Train Epoch: 643 [4096/54000 (8%)] Loss: -1564.891846\n",
      "Train Epoch: 643 [8192/54000 (15%)] Loss: -1572.314453\n",
      "Train Epoch: 643 [12288/54000 (23%)] Loss: -1566.516968\n",
      "Train Epoch: 643 [16384/54000 (30%)] Loss: -1570.884521\n",
      "Train Epoch: 643 [20480/54000 (38%)] Loss: -1564.244995\n",
      "Train Epoch: 643 [24576/54000 (46%)] Loss: -1566.725464\n",
      "Train Epoch: 643 [28672/54000 (53%)] Loss: -1562.767578\n",
      "Train Epoch: 643 [32768/54000 (61%)] Loss: -1563.279785\n",
      "Train Epoch: 643 [36864/54000 (68%)] Loss: -1562.971924\n",
      "Train Epoch: 643 [40960/54000 (76%)] Loss: -1563.222168\n",
      "Train Epoch: 643 [45056/54000 (83%)] Loss: -1562.238281\n",
      "Train Epoch: 643 [49152/54000 (91%)] Loss: -1561.246338\n",
      "Train Epoch: 643 [53248/54000 (99%)] Loss: -1564.155396\n",
      "    epoch          : 643\n",
      "    loss           : -1563.0358944571979\n",
      "    ess            : 3.789178973690593\n",
      "    log_marginal   : 1563.1642146539914\n",
      "    val_loss       : -1563.6703592936199\n",
      "    val_ess        : 3.7961795926094055\n",
      "    val_log_marginal: 1563.7990976969402\n",
      "Train Epoch: 644 [0/54000 (0%)] Loss: -1567.586182\n",
      "Train Epoch: 644 [4096/54000 (8%)] Loss: -1566.870605\n",
      "Train Epoch: 644 [8192/54000 (15%)] Loss: -1563.793701\n",
      "Train Epoch: 644 [12288/54000 (23%)] Loss: -1563.209229\n",
      "Train Epoch: 644 [16384/54000 (30%)] Loss: -1563.372559\n",
      "Train Epoch: 644 [20480/54000 (38%)] Loss: -1561.974487\n",
      "Train Epoch: 644 [24576/54000 (46%)] Loss: -1558.812622\n",
      "Train Epoch: 644 [28672/54000 (53%)] Loss: -1564.535278\n",
      "Train Epoch: 644 [32768/54000 (61%)] Loss: -1565.979004\n",
      "Train Epoch: 644 [36864/54000 (68%)] Loss: -1564.044678\n",
      "Train Epoch: 644 [40960/54000 (76%)] Loss: -1562.740479\n",
      "Train Epoch: 644 [45056/54000 (83%)] Loss: -1556.659790\n",
      "Train Epoch: 644 [49152/54000 (91%)] Loss: -1555.943848\n",
      "Train Epoch: 644 [53248/54000 (99%)] Loss: -1568.717041\n",
      "    epoch          : 644\n",
      "    loss           : -1563.284807395031\n",
      "    ess            : 3.795616138602885\n",
      "    log_marginal   : 1563.4098652482598\n",
      "    val_loss       : -1563.1590474446614\n",
      "    val_ess        : 3.795416643222173\n",
      "    val_log_marginal: 1563.2927754720051\n",
      "Train Epoch: 645 [0/54000 (0%)] Loss: -1556.982300\n",
      "Train Epoch: 645 [4096/54000 (8%)] Loss: -1566.590332\n",
      "Train Epoch: 645 [8192/54000 (15%)] Loss: -1563.121582\n",
      "Train Epoch: 645 [12288/54000 (23%)] Loss: -1561.933716\n",
      "Train Epoch: 645 [16384/54000 (30%)] Loss: -1556.443481\n",
      "Train Epoch: 645 [20480/54000 (38%)] Loss: -1566.224609\n",
      "Train Epoch: 645 [24576/54000 (46%)] Loss: -1553.958008\n",
      "Train Epoch: 645 [28672/54000 (53%)] Loss: -1559.628906\n",
      "Train Epoch: 645 [32768/54000 (61%)] Loss: -1561.229980\n",
      "Train Epoch: 645 [36864/54000 (68%)] Loss: -1566.304932\n",
      "Train Epoch: 645 [40960/54000 (76%)] Loss: -1565.022949\n",
      "Train Epoch: 645 [45056/54000 (83%)] Loss: -1558.406372\n",
      "Train Epoch: 645 [49152/54000 (91%)] Loss: -1562.233276\n",
      "Train Epoch: 645 [53248/54000 (99%)] Loss: -1559.183105\n",
      "    epoch          : 645\n",
      "    loss           : -1563.1337641856117\n",
      "    ess            : 3.7868758852447946\n",
      "    log_marginal   : 1563.2655804530139\n",
      "    val_loss       : -1562.2825164794922\n",
      "    val_ess        : 3.8029282093048096\n",
      "    val_log_marginal: 1562.4048309326172\n",
      "Train Epoch: 646 [0/54000 (0%)] Loss: -1568.830933\n",
      "Train Epoch: 646 [4096/54000 (8%)] Loss: -1559.696777\n",
      "Train Epoch: 646 [8192/54000 (15%)] Loss: -1557.574707\n",
      "Train Epoch: 646 [12288/54000 (23%)] Loss: -1564.219360\n",
      "Train Epoch: 646 [16384/54000 (30%)] Loss: -1557.461670\n",
      "Train Epoch: 646 [20480/54000 (38%)] Loss: -1569.509155\n",
      "Train Epoch: 646 [24576/54000 (46%)] Loss: -1564.514771\n",
      "Train Epoch: 646 [28672/54000 (53%)] Loss: -1564.609009\n",
      "Train Epoch: 646 [32768/54000 (61%)] Loss: -1562.837891\n",
      "Train Epoch: 646 [36864/54000 (68%)] Loss: -1557.872070\n",
      "Train Epoch: 646 [40960/54000 (76%)] Loss: -1567.344727\n",
      "Train Epoch: 646 [45056/54000 (83%)] Loss: -1560.142578\n",
      "Train Epoch: 646 [49152/54000 (91%)] Loss: -1572.619385\n",
      "Train Epoch: 646 [53248/54000 (99%)] Loss: -1565.818848\n",
      "    epoch          : 646\n",
      "    loss           : -1563.219763010034\n",
      "    ess            : 3.791876683302965\n",
      "    log_marginal   : 1563.349686319794\n",
      "    val_loss       : -1563.147496541341\n",
      "    val_ess        : 3.78825373450915\n",
      "    val_log_marginal: 1563.274658203125\n",
      "Train Epoch: 647 [0/54000 (0%)] Loss: -1563.010132\n",
      "Train Epoch: 647 [4096/54000 (8%)] Loss: -1559.235474\n",
      "Train Epoch: 647 [8192/54000 (15%)] Loss: -1563.265015\n",
      "Train Epoch: 647 [12288/54000 (23%)] Loss: -1558.516602\n",
      "Train Epoch: 647 [16384/54000 (30%)] Loss: -1560.220337\n",
      "Train Epoch: 647 [20480/54000 (38%)] Loss: -1570.203735\n",
      "Train Epoch: 647 [24576/54000 (46%)] Loss: -1561.405029\n",
      "Train Epoch: 647 [28672/54000 (53%)] Loss: -1561.694824\n",
      "Train Epoch: 647 [32768/54000 (61%)] Loss: -1565.060669\n",
      "Train Epoch: 647 [36864/54000 (68%)] Loss: -1568.003662\n",
      "Train Epoch: 647 [40960/54000 (76%)] Loss: -1564.563965\n",
      "Train Epoch: 647 [45056/54000 (83%)] Loss: -1559.603516\n",
      "Train Epoch: 647 [49152/54000 (91%)] Loss: -1569.736084\n",
      "Train Epoch: 647 [53248/54000 (99%)] Loss: -1567.934570\n",
      "    epoch          : 647\n",
      "    loss           : -1563.1836822654398\n",
      "    ess            : 3.792169877138183\n",
      "    log_marginal   : 1563.3127765384331\n",
      "    val_loss       : -1562.2722422281902\n",
      "    val_ess        : 3.7968953251838684\n",
      "    val_log_marginal: 1562.3944142659504\n",
      "Train Epoch: 648 [0/54000 (0%)] Loss: -1561.640869\n",
      "Train Epoch: 648 [4096/54000 (8%)] Loss: -1562.224854\n",
      "Train Epoch: 648 [8192/54000 (15%)] Loss: -1565.880127\n",
      "Train Epoch: 648 [12288/54000 (23%)] Loss: -1558.879761\n",
      "Train Epoch: 648 [16384/54000 (30%)] Loss: -1568.606934\n",
      "Train Epoch: 648 [20480/54000 (38%)] Loss: -1564.853760\n",
      "Train Epoch: 648 [24576/54000 (46%)] Loss: -1560.034424\n",
      "Train Epoch: 648 [28672/54000 (53%)] Loss: -1571.462646\n",
      "Train Epoch: 648 [32768/54000 (61%)] Loss: -1568.057861\n",
      "Train Epoch: 648 [36864/54000 (68%)] Loss: -1565.749756\n",
      "Train Epoch: 648 [40960/54000 (76%)] Loss: -1567.036377\n",
      "Train Epoch: 648 [45056/54000 (83%)] Loss: -1559.328003\n",
      "Train Epoch: 648 [49152/54000 (91%)] Loss: -1565.228760\n",
      "Train Epoch: 648 [53248/54000 (99%)] Loss: -1561.071289\n",
      "    epoch          : 648\n",
      "    loss           : -1563.379386431798\n",
      "    ess            : 3.7847398717256517\n",
      "    log_marginal   : 1563.5116967657732\n",
      "    val_loss       : -1562.5538940429688\n",
      "    val_ess        : 3.8166824082533517\n",
      "    val_log_marginal: 1562.6724650065105\n",
      "Train Epoch: 649 [0/54000 (0%)] Loss: -1561.975830\n",
      "Train Epoch: 649 [4096/54000 (8%)] Loss: -1564.517334\n",
      "Train Epoch: 649 [8192/54000 (15%)] Loss: -1562.736084\n",
      "Train Epoch: 649 [12288/54000 (23%)] Loss: -1561.514038\n",
      "Train Epoch: 649 [16384/54000 (30%)] Loss: -1564.181152\n",
      "Train Epoch: 649 [20480/54000 (38%)] Loss: -1558.227417\n",
      "Train Epoch: 649 [24576/54000 (46%)] Loss: -1565.612061\n",
      "Train Epoch: 649 [28672/54000 (53%)] Loss: -1563.458130\n",
      "Train Epoch: 649 [32768/54000 (61%)] Loss: -1562.522583\n",
      "Train Epoch: 649 [36864/54000 (68%)] Loss: -1568.734131\n",
      "Train Epoch: 649 [40960/54000 (76%)] Loss: -1565.927490\n",
      "Train Epoch: 649 [45056/54000 (83%)] Loss: -1560.270264\n",
      "Train Epoch: 649 [49152/54000 (91%)] Loss: -1564.122803\n",
      "Train Epoch: 649 [53248/54000 (99%)] Loss: -1564.158691\n",
      "    epoch          : 649\n",
      "    loss           : -1563.5564560732005\n",
      "    ess            : 3.7905177674587303\n",
      "    log_marginal   : 1563.687013454347\n",
      "    val_loss       : -1563.7223510742188\n",
      "    val_ess        : 3.7916914522647858\n",
      "    val_log_marginal: 1563.8600362141926\n",
      "Train Epoch: 650 [0/54000 (0%)] Loss: -1561.563721\n",
      "Train Epoch: 650 [4096/54000 (8%)] Loss: -1566.248535\n",
      "Train Epoch: 650 [8192/54000 (15%)] Loss: -1565.227295\n",
      "Train Epoch: 650 [12288/54000 (23%)] Loss: -1563.564453\n",
      "Train Epoch: 650 [16384/54000 (30%)] Loss: -1557.159790\n",
      "Train Epoch: 650 [20480/54000 (38%)] Loss: -1566.535522\n",
      "Train Epoch: 650 [24576/54000 (46%)] Loss: -1564.156128\n",
      "Train Epoch: 650 [28672/54000 (53%)] Loss: -1571.253906\n",
      "Train Epoch: 650 [32768/54000 (61%)] Loss: -1560.184082\n",
      "Train Epoch: 650 [36864/54000 (68%)] Loss: -1562.533691\n",
      "Train Epoch: 650 [40960/54000 (76%)] Loss: -1567.091309\n",
      "Train Epoch: 650 [45056/54000 (83%)] Loss: -1561.884521\n",
      "Train Epoch: 650 [49152/54000 (91%)] Loss: -1563.744263\n",
      "Train Epoch: 650 [53248/54000 (99%)] Loss: -1563.603760\n",
      "    epoch          : 650\n",
      "    loss           : -1563.639131808168\n",
      "    ess            : 3.7880676459362155\n",
      "    log_marginal   : 1563.771078823867\n",
      "    val_loss       : -1563.5742645263672\n",
      "    val_ess        : 3.8005969524383545\n",
      "    val_log_marginal: 1563.6976521809895\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [0/54000 (0%)] Loss: -1568.092163\n",
      "Train Epoch: 651 [4096/54000 (8%)] Loss: -1557.961792\n",
      "Train Epoch: 651 [8192/54000 (15%)] Loss: -1565.807251\n",
      "Train Epoch: 651 [12288/54000 (23%)] Loss: -1568.220703\n",
      "Train Epoch: 651 [16384/54000 (30%)] Loss: -1557.886719\n",
      "Train Epoch: 651 [20480/54000 (38%)] Loss: -1554.793701\n",
      "Train Epoch: 651 [24576/54000 (46%)] Loss: -1558.842773\n",
      "Train Epoch: 651 [28672/54000 (53%)] Loss: -1561.403687\n",
      "Train Epoch: 651 [32768/54000 (61%)] Loss: -1560.818848\n",
      "Train Epoch: 651 [36864/54000 (68%)] Loss: -1565.110840\n",
      "Train Epoch: 651 [40960/54000 (76%)] Loss: -1566.165405\n",
      "Train Epoch: 651 [45056/54000 (83%)] Loss: -1558.470215\n",
      "Train Epoch: 651 [49152/54000 (91%)] Loss: -1572.144287\n",
      "Train Epoch: 651 [53248/54000 (99%)] Loss: -1563.030762\n",
      "    epoch          : 651\n",
      "    loss           : -1563.5960496658397\n",
      "    ess            : 3.7966733995772084\n",
      "    log_marginal   : 1563.7211133043913\n",
      "    val_loss       : -1563.5531311035156\n",
      "    val_ess        : 3.79146409034729\n",
      "    val_log_marginal: 1563.6873982747395\n",
      "Train Epoch: 652 [0/54000 (0%)] Loss: -1562.746094\n",
      "Train Epoch: 652 [4096/54000 (8%)] Loss: -1559.225098\n",
      "Train Epoch: 652 [8192/54000 (15%)] Loss: -1563.888672\n",
      "Train Epoch: 652 [12288/54000 (23%)] Loss: -1558.592041\n",
      "Train Epoch: 652 [16384/54000 (30%)] Loss: -1570.151123\n",
      "Train Epoch: 652 [20480/54000 (38%)] Loss: -1564.660156\n",
      "Train Epoch: 652 [24576/54000 (46%)] Loss: -1565.252686\n",
      "Train Epoch: 652 [28672/54000 (53%)] Loss: -1567.455688\n",
      "Train Epoch: 652 [32768/54000 (61%)] Loss: -1563.315674\n",
      "Train Epoch: 652 [36864/54000 (68%)] Loss: -1557.880737\n",
      "Train Epoch: 652 [40960/54000 (76%)] Loss: -1562.237305\n",
      "Train Epoch: 652 [45056/54000 (83%)] Loss: -1567.761475\n",
      "Train Epoch: 652 [49152/54000 (91%)] Loss: -1560.594482\n",
      "Train Epoch: 652 [53248/54000 (99%)] Loss: -1558.857178\n",
      "    epoch          : 652\n",
      "    loss           : -1563.7868941609893\n",
      "    ess            : 3.789250373840332\n",
      "    log_marginal   : 1563.9145542524436\n",
      "    val_loss       : -1563.4305674235027\n",
      "    val_ess        : 3.7861848572889962\n",
      "    val_log_marginal: 1563.571009318034\n",
      "Train Epoch: 653 [0/54000 (0%)] Loss: -1567.257935\n",
      "Train Epoch: 653 [4096/54000 (8%)] Loss: -1569.473633\n",
      "Train Epoch: 653 [8192/54000 (15%)] Loss: -1563.673828\n",
      "Train Epoch: 653 [12288/54000 (23%)] Loss: -1570.368408\n",
      "Train Epoch: 653 [16384/54000 (30%)] Loss: -1564.092529\n",
      "Train Epoch: 653 [20480/54000 (38%)] Loss: -1566.085327\n",
      "Train Epoch: 653 [24576/54000 (46%)] Loss: -1569.427002\n",
      "Train Epoch: 653 [28672/54000 (53%)] Loss: -1564.634277\n",
      "Train Epoch: 653 [32768/54000 (61%)] Loss: -1569.254150\n",
      "Train Epoch: 653 [36864/54000 (68%)] Loss: -1566.714844\n",
      "Train Epoch: 653 [40960/54000 (76%)] Loss: -1565.342285\n",
      "Train Epoch: 653 [45056/54000 (83%)] Loss: -1568.862671\n",
      "Train Epoch: 653 [49152/54000 (91%)] Loss: -1567.725830\n",
      "Train Epoch: 653 [53248/54000 (99%)] Loss: -1560.134888\n",
      "    epoch          : 653\n",
      "    loss           : -1563.7408302632552\n",
      "    ess            : 3.784849043706017\n",
      "    log_marginal   : 1563.872566693202\n",
      "    val_loss       : -1563.707260131836\n",
      "    val_ess        : 3.8049828708171844\n",
      "    val_log_marginal: 1563.8303629557292\n",
      "Train Epoch: 654 [0/54000 (0%)] Loss: -1561.866577\n",
      "Train Epoch: 654 [4096/54000 (8%)] Loss: -1568.333008\n",
      "Train Epoch: 654 [8192/54000 (15%)] Loss: -1561.714600\n",
      "Train Epoch: 654 [12288/54000 (23%)] Loss: -1568.116943\n",
      "Train Epoch: 654 [16384/54000 (30%)] Loss: -1568.137085\n",
      "Train Epoch: 654 [20480/54000 (38%)] Loss: -1566.494629\n",
      "Train Epoch: 654 [24576/54000 (46%)] Loss: -1564.040771\n",
      "Train Epoch: 654 [28672/54000 (53%)] Loss: -1570.656982\n",
      "Train Epoch: 654 [32768/54000 (61%)] Loss: -1569.409912\n",
      "Train Epoch: 654 [36864/54000 (68%)] Loss: -1567.590576\n",
      "Train Epoch: 654 [40960/54000 (76%)] Loss: -1553.848389\n",
      "Train Epoch: 654 [45056/54000 (83%)] Loss: -1564.996216\n",
      "Train Epoch: 654 [49152/54000 (91%)] Loss: -1568.343628\n",
      "Train Epoch: 654 [53248/54000 (99%)] Loss: -1560.044189\n",
      "    epoch          : 654\n",
      "    loss           : -1563.9740973739263\n",
      "    ess            : 3.7931919244793355\n",
      "    log_marginal   : 1564.098437268587\n",
      "    val_loss       : -1563.4324900309246\n",
      "    val_ess        : 3.790687362353007\n",
      "    val_log_marginal: 1563.5665028889973\n",
      "Train Epoch: 655 [0/54000 (0%)] Loss: -1571.854492\n",
      "Train Epoch: 655 [4096/54000 (8%)] Loss: -1564.979126\n",
      "Train Epoch: 655 [8192/54000 (15%)] Loss: -1558.558105\n",
      "Train Epoch: 655 [12288/54000 (23%)] Loss: -1556.022095\n",
      "Train Epoch: 655 [16384/54000 (30%)] Loss: -1566.544678\n",
      "Train Epoch: 655 [20480/54000 (38%)] Loss: -1565.848145\n",
      "Train Epoch: 655 [24576/54000 (46%)] Loss: -1570.982300\n",
      "Train Epoch: 655 [28672/54000 (53%)] Loss: -1567.259766\n",
      "Train Epoch: 655 [32768/54000 (61%)] Loss: -1560.175049\n",
      "Train Epoch: 655 [36864/54000 (68%)] Loss: -1563.437988\n",
      "Train Epoch: 655 [40960/54000 (76%)] Loss: -1568.753418\n",
      "Train Epoch: 655 [45056/54000 (83%)] Loss: -1562.470459\n",
      "Train Epoch: 655 [49152/54000 (91%)] Loss: -1566.692871\n",
      "Train Epoch: 655 [53248/54000 (99%)] Loss: -1565.416748\n",
      "    epoch          : 655\n",
      "    loss           : -1563.8116570784582\n",
      "    ess            : 3.7897475681033743\n",
      "    log_marginal   : 1563.9420443711122\n",
      "    val_loss       : -1562.688985188802\n",
      "    val_ess        : 3.785762071609497\n",
      "    val_log_marginal: 1562.815434773763\n",
      "Train Epoch: 656 [0/54000 (0%)] Loss: -1564.215576\n",
      "Train Epoch: 656 [4096/54000 (8%)] Loss: -1565.213013\n",
      "Train Epoch: 656 [8192/54000 (15%)] Loss: -1559.489258\n",
      "Train Epoch: 656 [12288/54000 (23%)] Loss: -1564.248901\n",
      "Train Epoch: 656 [16384/54000 (30%)] Loss: -1563.587646\n",
      "Train Epoch: 656 [20480/54000 (38%)] Loss: -1564.515869\n",
      "Train Epoch: 656 [24576/54000 (46%)] Loss: -1561.067017\n",
      "Train Epoch: 656 [28672/54000 (53%)] Loss: -1568.024170\n",
      "Train Epoch: 656 [32768/54000 (61%)] Loss: -1569.719727\n",
      "Train Epoch: 656 [36864/54000 (68%)] Loss: -1565.652832\n",
      "Train Epoch: 656 [40960/54000 (76%)] Loss: -1562.273926\n",
      "Train Epoch: 656 [45056/54000 (83%)] Loss: -1562.356201\n",
      "Train Epoch: 656 [49152/54000 (91%)] Loss: -1565.287354\n",
      "Train Epoch: 656 [53248/54000 (99%)] Loss: -1563.343506\n",
      "    epoch          : 656\n",
      "    loss           : -1563.9616386811315\n",
      "    ess            : 3.791075861284518\n",
      "    log_marginal   : 1564.092286891847\n",
      "    val_loss       : -1563.5165710449219\n",
      "    val_ess        : 3.7950806319713593\n",
      "    val_log_marginal: 1563.6400909423828\n",
      "Train Epoch: 657 [0/54000 (0%)] Loss: -1561.204468\n",
      "Train Epoch: 657 [4096/54000 (8%)] Loss: -1560.992798\n",
      "Train Epoch: 657 [8192/54000 (15%)] Loss: -1563.702515\n",
      "Train Epoch: 657 [12288/54000 (23%)] Loss: -1563.341797\n",
      "Train Epoch: 657 [16384/54000 (30%)] Loss: -1569.319824\n",
      "Train Epoch: 657 [20480/54000 (38%)] Loss: -1565.231689\n",
      "Train Epoch: 657 [24576/54000 (46%)] Loss: -1563.017334\n",
      "Train Epoch: 657 [28672/54000 (53%)] Loss: -1564.841064\n",
      "Train Epoch: 657 [32768/54000 (61%)] Loss: -1564.598511\n",
      "Train Epoch: 657 [36864/54000 (68%)] Loss: -1570.860229\n",
      "Train Epoch: 657 [40960/54000 (76%)] Loss: -1568.980225\n",
      "Train Epoch: 657 [45056/54000 (83%)] Loss: -1565.011597\n",
      "Train Epoch: 657 [49152/54000 (91%)] Loss: -1561.362793\n",
      "Train Epoch: 657 [53248/54000 (99%)] Loss: -1558.389282\n",
      "    epoch          : 657\n",
      "    loss           : -1563.9393686592862\n",
      "    ess            : 3.7881590461278978\n",
      "    log_marginal   : 1564.0697038840344\n",
      "    val_loss       : -1562.9046122233074\n",
      "    val_ess        : 3.7877343893051147\n",
      "    val_log_marginal: 1563.0377756754558\n",
      "Train Epoch: 658 [0/54000 (0%)] Loss: -1559.401001\n",
      "Train Epoch: 658 [4096/54000 (8%)] Loss: -1561.358032\n",
      "Train Epoch: 658 [8192/54000 (15%)] Loss: -1571.716187\n",
      "Train Epoch: 658 [12288/54000 (23%)] Loss: -1567.364380\n",
      "Train Epoch: 658 [16384/54000 (30%)] Loss: -1565.967285\n",
      "Train Epoch: 658 [20480/54000 (38%)] Loss: -1565.965576\n",
      "Train Epoch: 658 [24576/54000 (46%)] Loss: -1562.729248\n",
      "Train Epoch: 658 [28672/54000 (53%)] Loss: -1561.121582\n",
      "Train Epoch: 658 [32768/54000 (61%)] Loss: -1563.030151\n",
      "Train Epoch: 658 [36864/54000 (68%)] Loss: -1566.956177\n",
      "Train Epoch: 658 [40960/54000 (76%)] Loss: -1569.646362\n",
      "Train Epoch: 658 [45056/54000 (83%)] Loss: -1559.230225\n",
      "Train Epoch: 658 [49152/54000 (91%)] Loss: -1561.603027\n",
      "Train Epoch: 658 [53248/54000 (99%)] Loss: -1566.250732\n",
      "    epoch          : 658\n",
      "    loss           : -1563.9861186963121\n",
      "    ess            : 3.7941414349452014\n",
      "    log_marginal   : 1564.1148687425948\n",
      "    val_loss       : -1565.1068522135417\n",
      "    val_ess        : 3.7852562069892883\n",
      "    val_log_marginal: 1565.2364705403645\n",
      "Train Epoch: 659 [0/54000 (0%)] Loss: -1563.037109\n",
      "Train Epoch: 659 [4096/54000 (8%)] Loss: -1562.076050\n",
      "Train Epoch: 659 [8192/54000 (15%)] Loss: -1562.237061\n",
      "Train Epoch: 659 [12288/54000 (23%)] Loss: -1561.711914\n",
      "Train Epoch: 659 [16384/54000 (30%)] Loss: -1569.704102\n",
      "Train Epoch: 659 [20480/54000 (38%)] Loss: -1563.424072\n",
      "Train Epoch: 659 [24576/54000 (46%)] Loss: -1562.409180\n",
      "Train Epoch: 659 [28672/54000 (53%)] Loss: -1564.692139\n",
      "Train Epoch: 659 [32768/54000 (61%)] Loss: -1567.437012\n",
      "Train Epoch: 659 [36864/54000 (68%)] Loss: -1564.011353\n",
      "Train Epoch: 659 [40960/54000 (76%)] Loss: -1570.404785\n",
      "Train Epoch: 659 [45056/54000 (83%)] Loss: -1563.022217\n",
      "Train Epoch: 659 [49152/54000 (91%)] Loss: -1571.643066\n",
      "Train Epoch: 659 [53248/54000 (99%)] Loss: -1557.803467\n",
      "    epoch          : 659\n",
      "    loss           : -1563.9512198931798\n",
      "    ess            : 3.7923586571951047\n",
      "    log_marginal   : 1564.0779404482005\n",
      "    val_loss       : -1563.7244110107422\n",
      "    val_ess        : 3.802569627761841\n",
      "    val_log_marginal: 1563.8445485432942\n",
      "Train Epoch: 660 [0/54000 (0%)] Loss: -1567.093750\n",
      "Train Epoch: 660 [4096/54000 (8%)] Loss: -1559.805908\n",
      "Train Epoch: 660 [8192/54000 (15%)] Loss: -1568.364380\n",
      "Train Epoch: 660 [12288/54000 (23%)] Loss: -1572.316650\n",
      "Train Epoch: 660 [16384/54000 (30%)] Loss: -1557.911377\n",
      "Train Epoch: 660 [20480/54000 (38%)] Loss: -1562.494385\n",
      "Train Epoch: 660 [24576/54000 (46%)] Loss: -1569.358887\n",
      "Train Epoch: 660 [28672/54000 (53%)] Loss: -1567.288818\n",
      "Train Epoch: 660 [32768/54000 (61%)] Loss: -1561.299927\n",
      "Train Epoch: 660 [36864/54000 (68%)] Loss: -1566.341309\n",
      "Train Epoch: 660 [40960/54000 (76%)] Loss: -1568.625000\n",
      "Train Epoch: 660 [45056/54000 (83%)] Loss: -1563.878174\n",
      "Train Epoch: 660 [49152/54000 (91%)] Loss: -1565.307007\n",
      "Train Epoch: 660 [53248/54000 (99%)] Loss: -1563.638428\n",
      "    epoch          : 660\n",
      "    loss           : -1563.797633455828\n",
      "    ess            : 3.7888912973810713\n",
      "    log_marginal   : 1563.9279952930613\n",
      "    val_loss       : -1564.2686208089192\n",
      "    val_ess        : 3.7974149187405906\n",
      "    val_log_marginal: 1564.3902537027996\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch660.pth ...\n",
      "Train Epoch: 661 [0/54000 (0%)] Loss: -1569.138672\n",
      "Train Epoch: 661 [4096/54000 (8%)] Loss: -1564.772949\n",
      "Train Epoch: 661 [8192/54000 (15%)] Loss: -1564.813232\n",
      "Train Epoch: 661 [12288/54000 (23%)] Loss: -1565.541504\n",
      "Train Epoch: 661 [16384/54000 (30%)] Loss: -1560.173462\n",
      "Train Epoch: 661 [20480/54000 (38%)] Loss: -1569.191528\n",
      "Train Epoch: 661 [24576/54000 (46%)] Loss: -1559.979492\n",
      "Train Epoch: 661 [28672/54000 (53%)] Loss: -1560.306641\n",
      "Train Epoch: 661 [32768/54000 (61%)] Loss: -1568.957031\n",
      "Train Epoch: 661 [36864/54000 (68%)] Loss: -1561.903442\n",
      "Train Epoch: 661 [40960/54000 (76%)] Loss: -1564.722412\n",
      "Train Epoch: 661 [45056/54000 (83%)] Loss: -1566.812500\n",
      "Train Epoch: 661 [49152/54000 (91%)] Loss: -1566.112427\n",
      "Train Epoch: 661 [53248/54000 (99%)] Loss: -1559.515869\n",
      "    epoch          : 661\n",
      "    loss           : -1564.1953032434835\n",
      "    ess            : 3.7913592731783177\n",
      "    log_marginal   : 1564.322947714566\n",
      "    val_loss       : -1564.495885213216\n",
      "    val_ess        : 3.795090446869532\n",
      "    val_log_marginal: 1564.6264038085938\n",
      "Train Epoch: 662 [0/54000 (0%)] Loss: -1568.283447\n",
      "Train Epoch: 662 [4096/54000 (8%)] Loss: -1562.605469\n",
      "Train Epoch: 662 [8192/54000 (15%)] Loss: -1563.813965\n",
      "Train Epoch: 662 [12288/54000 (23%)] Loss: -1570.119873\n",
      "Train Epoch: 662 [16384/54000 (30%)] Loss: -1562.925293\n",
      "Train Epoch: 662 [20480/54000 (38%)] Loss: -1562.411621\n",
      "Train Epoch: 662 [24576/54000 (46%)] Loss: -1568.933716\n",
      "Train Epoch: 662 [28672/54000 (53%)] Loss: -1566.007324\n",
      "Train Epoch: 662 [32768/54000 (61%)] Loss: -1563.472656\n",
      "Train Epoch: 662 [36864/54000 (68%)] Loss: -1567.795288\n",
      "Train Epoch: 662 [40960/54000 (76%)] Loss: -1569.561157\n",
      "Train Epoch: 662 [45056/54000 (83%)] Loss: -1567.612793\n",
      "Train Epoch: 662 [49152/54000 (91%)] Loss: -1568.932739\n",
      "Train Epoch: 662 [53248/54000 (99%)] Loss: -1561.744385\n",
      "    epoch          : 662\n",
      "    loss           : -1564.3891578421208\n",
      "    ess            : 3.7936898181788727\n",
      "    log_marginal   : 1564.5137279926319\n",
      "    val_loss       : -1563.8123067220051\n",
      "    val_ess        : 3.7923848927021027\n",
      "    val_log_marginal: 1563.9395243326824\n",
      "Train Epoch: 663 [0/54000 (0%)] Loss: -1561.003784\n",
      "Train Epoch: 663 [4096/54000 (8%)] Loss: -1567.848877\n",
      "Train Epoch: 663 [8192/54000 (15%)] Loss: -1571.769653\n",
      "Train Epoch: 663 [12288/54000 (23%)] Loss: -1568.773804\n",
      "Train Epoch: 663 [16384/54000 (30%)] Loss: -1563.043701\n",
      "Train Epoch: 663 [20480/54000 (38%)] Loss: -1560.788330\n",
      "Train Epoch: 663 [24576/54000 (46%)] Loss: -1568.521118\n",
      "Train Epoch: 663 [28672/54000 (53%)] Loss: -1566.481079\n",
      "Train Epoch: 663 [32768/54000 (61%)] Loss: -1562.808716\n",
      "Train Epoch: 663 [36864/54000 (68%)] Loss: -1564.064941\n",
      "Train Epoch: 663 [40960/54000 (76%)] Loss: -1568.026367\n",
      "Train Epoch: 663 [45056/54000 (83%)] Loss: -1565.410645\n",
      "Train Epoch: 663 [49152/54000 (91%)] Loss: -1566.474976\n",
      "Train Epoch: 663 [53248/54000 (99%)] Loss: -1565.889404\n",
      "    epoch          : 663\n",
      "    loss           : -1564.5079750675725\n",
      "    ess            : 3.7918353996005667\n",
      "    log_marginal   : 1564.6328061361448\n",
      "    val_loss       : -1564.1629384358723\n",
      "    val_ess        : 3.7983952860037484\n",
      "    val_log_marginal: 1564.2807718912761\n",
      "Train Epoch: 664 [0/54000 (0%)] Loss: -1563.104004\n",
      "Train Epoch: 664 [4096/54000 (8%)] Loss: -1565.658569\n",
      "Train Epoch: 664 [8192/54000 (15%)] Loss: -1560.352295\n",
      "Train Epoch: 664 [12288/54000 (23%)] Loss: -1565.151123\n",
      "Train Epoch: 664 [16384/54000 (30%)] Loss: -1570.595947\n",
      "Train Epoch: 664 [20480/54000 (38%)] Loss: -1558.698120\n",
      "Train Epoch: 664 [24576/54000 (46%)] Loss: -1565.263916\n",
      "Train Epoch: 664 [28672/54000 (53%)] Loss: -1562.312012\n",
      "Train Epoch: 664 [32768/54000 (61%)] Loss: -1562.242676\n",
      "Train Epoch: 664 [36864/54000 (68%)] Loss: -1563.395752\n",
      "Train Epoch: 664 [40960/54000 (76%)] Loss: -1566.955688\n",
      "Train Epoch: 664 [45056/54000 (83%)] Loss: -1559.094727\n",
      "Train Epoch: 664 [49152/54000 (91%)] Loss: -1565.725586\n",
      "Train Epoch: 664 [53248/54000 (99%)] Loss: -1565.084473\n",
      "    epoch          : 664\n",
      "    loss           : -1564.5769904981858\n",
      "    ess            : 3.791260250371779\n",
      "    log_marginal   : 1564.7059088973638\n",
      "    val_loss       : -1564.275899251302\n",
      "    val_ess        : 3.8027498622735343\n",
      "    val_log_marginal: 1564.4086100260417\n",
      "Train Epoch: 665 [0/54000 (0%)] Loss: -1557.500000\n",
      "Train Epoch: 665 [4096/54000 (8%)] Loss: -1564.967041\n",
      "Train Epoch: 665 [8192/54000 (15%)] Loss: -1559.287598\n",
      "Train Epoch: 665 [12288/54000 (23%)] Loss: -1565.460693\n",
      "Train Epoch: 665 [16384/54000 (30%)] Loss: -1559.271118\n",
      "Train Epoch: 665 [20480/54000 (38%)] Loss: -1569.595947\n",
      "Train Epoch: 665 [24576/54000 (46%)] Loss: -1567.400146\n",
      "Train Epoch: 665 [28672/54000 (53%)] Loss: -1562.790161\n",
      "Train Epoch: 665 [32768/54000 (61%)] Loss: -1569.894165\n",
      "Train Epoch: 665 [36864/54000 (68%)] Loss: -1563.490601\n",
      "Train Epoch: 665 [40960/54000 (76%)] Loss: -1562.432007\n",
      "Train Epoch: 665 [45056/54000 (83%)] Loss: -1560.419922\n",
      "Train Epoch: 665 [49152/54000 (91%)] Loss: -1557.574097\n",
      "Train Epoch: 665 [53248/54000 (99%)] Loss: -1564.057617\n",
      "    epoch          : 665\n",
      "    loss           : -1564.36343051133\n",
      "    ess            : 3.7878780534482117\n",
      "    log_marginal   : 1564.4925618103896\n",
      "    val_loss       : -1563.7161254882812\n",
      "    val_ess        : 3.7862583299477897\n",
      "    val_log_marginal: 1563.846644083659\n",
      "Train Epoch: 666 [0/54000 (0%)] Loss: -1562.760620\n",
      "Train Epoch: 666 [4096/54000 (8%)] Loss: -1564.450195\n",
      "Train Epoch: 666 [8192/54000 (15%)] Loss: -1565.826050\n",
      "Train Epoch: 666 [12288/54000 (23%)] Loss: -1564.049683\n",
      "Train Epoch: 666 [16384/54000 (30%)] Loss: -1568.034912\n",
      "Train Epoch: 666 [20480/54000 (38%)] Loss: -1562.047241\n",
      "Train Epoch: 666 [24576/54000 (46%)] Loss: -1566.399902\n",
      "Train Epoch: 666 [28672/54000 (53%)] Loss: -1565.776367\n",
      "Train Epoch: 666 [32768/54000 (61%)] Loss: -1560.535767\n",
      "Train Epoch: 666 [36864/54000 (68%)] Loss: -1558.893066\n",
      "Train Epoch: 666 [40960/54000 (76%)] Loss: -1566.088135\n",
      "Train Epoch: 666 [45056/54000 (83%)] Loss: -1564.237183\n",
      "Train Epoch: 666 [49152/54000 (91%)] Loss: -1565.683838\n",
      "Train Epoch: 666 [53248/54000 (99%)] Loss: -1558.001099\n",
      "    epoch          : 666\n",
      "    loss           : -1564.4197622000888\n",
      "    ess            : 3.792252611774969\n",
      "    log_marginal   : 1564.550181890551\n",
      "    val_loss       : -1564.4168752034504\n",
      "    val_ess        : 3.798191944758097\n",
      "    val_log_marginal: 1564.5421549479167\n",
      "Train Epoch: 667 [0/54000 (0%)] Loss: -1567.236084\n",
      "Train Epoch: 667 [4096/54000 (8%)] Loss: -1568.043579\n",
      "Train Epoch: 667 [8192/54000 (15%)] Loss: -1570.954224\n",
      "Train Epoch: 667 [12288/54000 (23%)] Loss: -1563.402954\n",
      "Train Epoch: 667 [16384/54000 (30%)] Loss: -1571.699463\n",
      "Train Epoch: 667 [20480/54000 (38%)] Loss: -1561.455078\n",
      "Train Epoch: 667 [24576/54000 (46%)] Loss: -1563.520020\n",
      "Train Epoch: 667 [28672/54000 (53%)] Loss: -1563.471558\n",
      "Train Epoch: 667 [32768/54000 (61%)] Loss: -1563.540161\n",
      "Train Epoch: 667 [36864/54000 (68%)] Loss: -1564.005737\n",
      "Train Epoch: 667 [40960/54000 (76%)] Loss: -1567.593262\n",
      "Train Epoch: 667 [45056/54000 (83%)] Loss: -1562.253418\n",
      "Train Epoch: 667 [49152/54000 (91%)] Loss: -1561.969727\n",
      "Train Epoch: 667 [53248/54000 (99%)] Loss: -1565.780762\n",
      "    epoch          : 667\n",
      "    loss           : -1564.8019944322052\n",
      "    ess            : 3.7907474809348303\n",
      "    log_marginal   : 1564.9292501295913\n",
      "    val_loss       : -1564.3787180582683\n",
      "    val_ess        : 3.77755140264829\n",
      "    val_log_marginal: 1564.5083974202473\n",
      "Train Epoch: 668 [0/54000 (0%)] Loss: -1559.759888\n",
      "Train Epoch: 668 [4096/54000 (8%)] Loss: -1564.484009\n",
      "Train Epoch: 668 [8192/54000 (15%)] Loss: -1559.673218\n",
      "Train Epoch: 668 [12288/54000 (23%)] Loss: -1564.768433\n",
      "Train Epoch: 668 [16384/54000 (30%)] Loss: -1572.397217\n",
      "Train Epoch: 668 [20480/54000 (38%)] Loss: -1562.537354\n",
      "Train Epoch: 668 [24576/54000 (46%)] Loss: -1563.242432\n",
      "Train Epoch: 668 [28672/54000 (53%)] Loss: -1566.034912\n",
      "Train Epoch: 668 [32768/54000 (61%)] Loss: -1564.611816\n",
      "Train Epoch: 668 [36864/54000 (68%)] Loss: -1557.437744\n",
      "Train Epoch: 668 [40960/54000 (76%)] Loss: -1566.695801\n",
      "Train Epoch: 668 [45056/54000 (83%)] Loss: -1566.847656\n",
      "Train Epoch: 668 [49152/54000 (91%)] Loss: -1565.296875\n",
      "Train Epoch: 668 [53248/54000 (99%)] Loss: -1564.049805\n",
      "    epoch          : 668\n",
      "    loss           : -1564.7266602719565\n",
      "    ess            : 3.7905257414867526\n",
      "    log_marginal   : 1564.85336636367\n",
      "    val_loss       : -1564.2716674804688\n",
      "    val_ess        : 3.792816619078318\n",
      "    val_log_marginal: 1564.3955637613933\n",
      "Train Epoch: 669 [0/54000 (0%)] Loss: -1569.566406\n",
      "Train Epoch: 669 [4096/54000 (8%)] Loss: -1564.998779\n",
      "Train Epoch: 669 [8192/54000 (15%)] Loss: -1562.431030\n",
      "Train Epoch: 669 [12288/54000 (23%)] Loss: -1567.534424\n",
      "Train Epoch: 669 [16384/54000 (30%)] Loss: -1565.239624\n",
      "Train Epoch: 669 [20480/54000 (38%)] Loss: -1563.454590\n",
      "Train Epoch: 669 [24576/54000 (46%)] Loss: -1558.907959\n",
      "Train Epoch: 669 [28672/54000 (53%)] Loss: -1565.843750\n",
      "Train Epoch: 669 [32768/54000 (61%)] Loss: -1564.232422\n",
      "Train Epoch: 669 [36864/54000 (68%)] Loss: -1568.783081\n",
      "Train Epoch: 669 [40960/54000 (76%)] Loss: -1572.404297\n",
      "Train Epoch: 669 [45056/54000 (83%)] Loss: -1566.528320\n",
      "Train Epoch: 669 [49152/54000 (91%)] Loss: -1559.580444\n",
      "Train Epoch: 669 [53248/54000 (99%)] Loss: -1574.671021\n",
      "    epoch          : 669\n",
      "    loss           : -1564.8030618242742\n",
      "    ess            : 3.790257711546116\n",
      "    log_marginal   : 1564.9333843213121\n",
      "    val_loss       : -1563.9664967854817\n",
      "    val_ess        : 3.8027509649594626\n",
      "    val_log_marginal: 1564.0862528483074\n",
      "Train Epoch: 670 [0/54000 (0%)] Loss: -1567.542725\n",
      "Train Epoch: 670 [4096/54000 (8%)] Loss: -1564.822021\n",
      "Train Epoch: 670 [8192/54000 (15%)] Loss: -1569.365234\n",
      "Train Epoch: 670 [12288/54000 (23%)] Loss: -1563.571289\n",
      "Train Epoch: 670 [16384/54000 (30%)] Loss: -1562.658203\n",
      "Train Epoch: 670 [20480/54000 (38%)] Loss: -1563.183350\n",
      "Train Epoch: 670 [24576/54000 (46%)] Loss: -1565.012207\n",
      "Train Epoch: 670 [28672/54000 (53%)] Loss: -1566.544189\n",
      "Train Epoch: 670 [32768/54000 (61%)] Loss: -1568.088623\n",
      "Train Epoch: 670 [36864/54000 (68%)] Loss: -1565.691406\n",
      "Train Epoch: 670 [40960/54000 (76%)] Loss: -1562.948730\n",
      "Train Epoch: 670 [45056/54000 (83%)] Loss: -1568.122925\n",
      "Train Epoch: 670 [49152/54000 (91%)] Loss: -1572.341187\n",
      "Train Epoch: 670 [53248/54000 (99%)] Loss: -1564.731689\n",
      "    epoch          : 670\n",
      "    loss           : -1565.8471887959124\n",
      "    ess            : 3.795884361764266\n",
      "    log_marginal   : 1565.970061532694\n",
      "    val_loss       : -1565.9383239746094\n",
      "    val_ess        : 3.7968552112579346\n",
      "    val_log_marginal: 1566.0639394124348\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch670.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 671 [0/54000 (0%)] Loss: -1574.242065\n",
      "Train Epoch: 671 [4096/54000 (8%)] Loss: -1568.380859\n",
      "Train Epoch: 671 [8192/54000 (15%)] Loss: -1571.273682\n",
      "Train Epoch: 671 [12288/54000 (23%)] Loss: -1564.820190\n",
      "Train Epoch: 671 [16384/54000 (30%)] Loss: -1565.801270\n",
      "Train Epoch: 671 [20480/54000 (38%)] Loss: -1563.220947\n",
      "Train Epoch: 671 [24576/54000 (46%)] Loss: -1572.563721\n",
      "Train Epoch: 671 [28672/54000 (53%)] Loss: -1558.501221\n",
      "Train Epoch: 671 [32768/54000 (61%)] Loss: -1569.110352\n",
      "Train Epoch: 671 [36864/54000 (68%)] Loss: -1567.495728\n",
      "Train Epoch: 671 [40960/54000 (76%)] Loss: -1569.757324\n",
      "Train Epoch: 671 [45056/54000 (83%)] Loss: -1567.311523\n",
      "Train Epoch: 671 [49152/54000 (91%)] Loss: -1566.505127\n",
      "Train Epoch: 671 [53248/54000 (99%)] Loss: -1564.011230\n",
      "    epoch          : 671\n",
      "    loss           : -1566.9652383090195\n",
      "    ess            : 3.7923068875950094\n",
      "    log_marginal   : 1567.0904315388034\n",
      "    val_loss       : -1566.8468424479167\n",
      "    val_ess        : 3.797270973523458\n",
      "    val_log_marginal: 1566.9650268554688\n",
      "Train Epoch: 672 [0/54000 (0%)] Loss: -1570.875122\n",
      "Train Epoch: 672 [4096/54000 (8%)] Loss: -1569.331787\n",
      "Train Epoch: 672 [8192/54000 (15%)] Loss: -1573.880859\n",
      "Train Epoch: 672 [12288/54000 (23%)] Loss: -1568.337646\n",
      "Train Epoch: 672 [16384/54000 (30%)] Loss: -1569.236572\n",
      "Train Epoch: 672 [20480/54000 (38%)] Loss: -1567.549316\n",
      "Train Epoch: 672 [24576/54000 (46%)] Loss: -1568.126953\n",
      "Train Epoch: 672 [28672/54000 (53%)] Loss: -1570.253052\n",
      "Train Epoch: 672 [32768/54000 (61%)] Loss: -1567.674316\n",
      "Train Epoch: 672 [36864/54000 (68%)] Loss: -1572.106201\n",
      "Train Epoch: 672 [40960/54000 (76%)] Loss: -1568.948242\n",
      "Train Epoch: 672 [45056/54000 (83%)] Loss: -1560.639282\n",
      "Train Epoch: 672 [49152/54000 (91%)] Loss: -1566.736938\n",
      "Train Epoch: 672 [53248/54000 (99%)] Loss: -1575.396606\n",
      "    epoch          : 672\n",
      "    loss           : -1567.3656781092639\n",
      "    ess            : 3.795326163983458\n",
      "    log_marginal   : 1567.4927064434612\n",
      "    val_loss       : -1566.969935099284\n",
      "    val_ess        : 3.8041618267695108\n",
      "    val_log_marginal: 1567.0941111246746\n",
      "Train Epoch: 673 [0/54000 (0%)] Loss: -1566.607178\n",
      "Train Epoch: 673 [4096/54000 (8%)] Loss: -1567.946045\n",
      "Train Epoch: 673 [8192/54000 (15%)] Loss: -1560.611084\n",
      "Train Epoch: 673 [12288/54000 (23%)] Loss: -1567.640381\n",
      "Train Epoch: 673 [16384/54000 (30%)] Loss: -1572.397461\n",
      "Train Epoch: 673 [20480/54000 (38%)] Loss: -1564.148438\n",
      "Train Epoch: 673 [24576/54000 (46%)] Loss: -1559.764404\n",
      "Train Epoch: 673 [28672/54000 (53%)] Loss: -1569.212158\n",
      "Train Epoch: 673 [32768/54000 (61%)] Loss: -1559.496338\n",
      "Train Epoch: 673 [36864/54000 (68%)] Loss: -1565.058716\n",
      "Train Epoch: 673 [40960/54000 (76%)] Loss: -1565.239014\n",
      "Train Epoch: 673 [45056/54000 (83%)] Loss: -1568.576660\n",
      "Train Epoch: 673 [49152/54000 (91%)] Loss: -1564.604248\n",
      "Train Epoch: 673 [53248/54000 (99%)] Loss: -1563.643433\n",
      "    epoch          : 673\n",
      "    loss           : -1567.7639270077384\n",
      "    ess            : 3.7951093194609005\n",
      "    log_marginal   : 1567.8881650807168\n",
      "    val_loss       : -1567.5531717936199\n",
      "    val_ess        : 3.7890424728393555\n",
      "    val_log_marginal: 1567.6831715901692\n",
      "Train Epoch: 674 [0/54000 (0%)] Loss: -1574.103760\n",
      "Train Epoch: 674 [4096/54000 (8%)] Loss: -1566.645508\n",
      "Train Epoch: 674 [8192/54000 (15%)] Loss: -1564.691895\n",
      "Train Epoch: 674 [12288/54000 (23%)] Loss: -1562.692627\n",
      "Train Epoch: 674 [16384/54000 (30%)] Loss: -1567.127686\n",
      "Train Epoch: 674 [20480/54000 (38%)] Loss: -1565.334717\n",
      "Train Epoch: 674 [24576/54000 (46%)] Loss: -1575.616699\n",
      "Train Epoch: 674 [28672/54000 (53%)] Loss: -1564.222412\n",
      "Train Epoch: 674 [32768/54000 (61%)] Loss: -1566.239990\n",
      "Train Epoch: 674 [36864/54000 (68%)] Loss: -1567.067139\n",
      "Train Epoch: 674 [40960/54000 (76%)] Loss: -1565.422119\n",
      "Train Epoch: 674 [45056/54000 (83%)] Loss: -1571.671631\n",
      "Train Epoch: 674 [49152/54000 (91%)] Loss: -1578.259644\n",
      "Train Epoch: 674 [53248/54000 (99%)] Loss: -1568.093506\n",
      "    epoch          : 674\n",
      "    loss           : -1567.9949025520216\n",
      "    ess            : 3.792084673569666\n",
      "    log_marginal   : 1568.122966459012\n",
      "    val_loss       : -1567.4926147460938\n",
      "    val_ess        : 3.795124500989914\n",
      "    val_log_marginal: 1567.6239115397136\n",
      "Train Epoch: 675 [0/54000 (0%)] Loss: -1560.945801\n",
      "Train Epoch: 675 [4096/54000 (8%)] Loss: -1567.373047\n",
      "Train Epoch: 675 [8192/54000 (15%)] Loss: -1575.138428\n",
      "Train Epoch: 675 [12288/54000 (23%)] Loss: -1572.160889\n",
      "Train Epoch: 675 [16384/54000 (30%)] Loss: -1568.336182\n",
      "Train Epoch: 675 [20480/54000 (38%)] Loss: -1565.276611\n",
      "Train Epoch: 675 [24576/54000 (46%)] Loss: -1567.825562\n",
      "Train Epoch: 675 [28672/54000 (53%)] Loss: -1568.063354\n",
      "Train Epoch: 675 [32768/54000 (61%)] Loss: -1563.686035\n",
      "Train Epoch: 675 [36864/54000 (68%)] Loss: -1567.388672\n",
      "Train Epoch: 675 [40960/54000 (76%)] Loss: -1574.894409\n",
      "Train Epoch: 675 [45056/54000 (83%)] Loss: -1566.360352\n",
      "Train Epoch: 675 [49152/54000 (91%)] Loss: -1562.813110\n",
      "Train Epoch: 675 [53248/54000 (99%)] Loss: -1569.379761\n",
      "    epoch          : 675\n",
      "    loss           : -1568.2507833327163\n",
      "    ess            : 3.793475866317749\n",
      "    log_marginal   : 1568.375756720231\n",
      "    val_loss       : -1568.4834696451824\n",
      "    val_ess        : 3.7998841404914856\n",
      "    val_log_marginal: 1568.6016540527344\n",
      "Train Epoch: 676 [0/54000 (0%)] Loss: -1571.649536\n",
      "Train Epoch: 676 [4096/54000 (8%)] Loss: -1570.727295\n",
      "Train Epoch: 676 [8192/54000 (15%)] Loss: -1574.179688\n",
      "Train Epoch: 676 [12288/54000 (23%)] Loss: -1561.844482\n",
      "Train Epoch: 676 [16384/54000 (30%)] Loss: -1575.682495\n",
      "Train Epoch: 676 [20480/54000 (38%)] Loss: -1568.770508\n",
      "Train Epoch: 676 [24576/54000 (46%)] Loss: -1563.593506\n",
      "Train Epoch: 676 [28672/54000 (53%)] Loss: -1565.612793\n",
      "Train Epoch: 676 [32768/54000 (61%)] Loss: -1562.352051\n",
      "Train Epoch: 676 [36864/54000 (68%)] Loss: -1571.799438\n",
      "Train Epoch: 676 [40960/54000 (76%)] Loss: -1573.252930\n",
      "Train Epoch: 676 [45056/54000 (83%)] Loss: -1564.669312\n",
      "Train Epoch: 676 [49152/54000 (91%)] Loss: -1571.090576\n",
      "Train Epoch: 676 [53248/54000 (99%)] Loss: -1567.678345\n",
      "    epoch          : 676\n",
      "    loss           : -1568.2434469647883\n",
      "    ess            : 3.7880280887911106\n",
      "    log_marginal   : 1568.372909762848\n",
      "    val_loss       : -1567.7308756510417\n",
      "    val_ess        : 3.7937385936578116\n",
      "    val_log_marginal: 1567.8619486490886\n",
      "Train Epoch: 677 [0/54000 (0%)] Loss: -1569.021973\n",
      "Train Epoch: 677 [4096/54000 (8%)] Loss: -1570.063843\n",
      "Train Epoch: 677 [8192/54000 (15%)] Loss: -1570.040771\n",
      "Train Epoch: 677 [12288/54000 (23%)] Loss: -1571.889893\n",
      "Train Epoch: 677 [16384/54000 (30%)] Loss: -1562.894287\n",
      "Train Epoch: 677 [20480/54000 (38%)] Loss: -1564.074341\n",
      "Train Epoch: 677 [24576/54000 (46%)] Loss: -1573.979614\n",
      "Train Epoch: 677 [28672/54000 (53%)] Loss: -1571.487549\n",
      "Train Epoch: 677 [32768/54000 (61%)] Loss: -1570.251709\n",
      "Train Epoch: 677 [36864/54000 (68%)] Loss: -1564.960449\n",
      "Train Epoch: 677 [40960/54000 (76%)] Loss: -1573.369873\n",
      "Train Epoch: 677 [45056/54000 (83%)] Loss: -1561.704102\n",
      "Train Epoch: 677 [49152/54000 (91%)] Loss: -1571.402954\n",
      "Train Epoch: 677 [53248/54000 (99%)] Loss: -1572.662354\n",
      "    epoch          : 677\n",
      "    loss           : -1568.408112295431\n",
      "    ess            : 3.7920937334756717\n",
      "    log_marginal   : 1568.5349549207642\n",
      "    val_loss       : -1568.0646260579426\n",
      "    val_ess        : 3.795789976914724\n",
      "    val_log_marginal: 1568.191441853841\n",
      "Train Epoch: 678 [0/54000 (0%)] Loss: -1570.350220\n",
      "Train Epoch: 678 [4096/54000 (8%)] Loss: -1572.257690\n",
      "Train Epoch: 678 [8192/54000 (15%)] Loss: -1564.099609\n",
      "Train Epoch: 678 [12288/54000 (23%)] Loss: -1566.513916\n",
      "Train Epoch: 678 [16384/54000 (30%)] Loss: -1567.450439\n",
      "Train Epoch: 678 [20480/54000 (38%)] Loss: -1568.822754\n",
      "Train Epoch: 678 [24576/54000 (46%)] Loss: -1566.738892\n",
      "Train Epoch: 678 [28672/54000 (53%)] Loss: -1571.728516\n",
      "Train Epoch: 678 [32768/54000 (61%)] Loss: -1567.493652\n",
      "Train Epoch: 678 [36864/54000 (68%)] Loss: -1573.907349\n",
      "Train Epoch: 678 [40960/54000 (76%)] Loss: -1575.269653\n",
      "Train Epoch: 678 [45056/54000 (83%)] Loss: -1569.382080\n",
      "Train Epoch: 678 [49152/54000 (91%)] Loss: -1574.016113\n",
      "Train Epoch: 678 [53248/54000 (99%)] Loss: -1566.149536\n",
      "    epoch          : 678\n",
      "    loss           : -1568.6510194895957\n",
      "    ess            : 3.7974109367171733\n",
      "    log_marginal   : 1568.775945437463\n",
      "    val_loss       : -1568.388936360677\n",
      "    val_ess        : 3.7731322149435678\n",
      "    val_log_marginal: 1568.5346069335938\n",
      "Train Epoch: 679 [0/54000 (0%)] Loss: -1567.782104\n",
      "Train Epoch: 679 [4096/54000 (8%)] Loss: -1568.013916\n",
      "Train Epoch: 679 [8192/54000 (15%)] Loss: -1573.017700\n",
      "Train Epoch: 679 [12288/54000 (23%)] Loss: -1565.646729\n",
      "Train Epoch: 679 [16384/54000 (30%)] Loss: -1567.641602\n",
      "Train Epoch: 679 [20480/54000 (38%)] Loss: -1572.620117\n",
      "Train Epoch: 679 [24576/54000 (46%)] Loss: -1571.202148\n",
      "Train Epoch: 679 [28672/54000 (53%)] Loss: -1559.324951\n",
      "Train Epoch: 679 [32768/54000 (61%)] Loss: -1574.044800\n",
      "Train Epoch: 679 [36864/54000 (68%)] Loss: -1570.755371\n",
      "Train Epoch: 679 [40960/54000 (76%)] Loss: -1569.980713\n",
      "Train Epoch: 679 [45056/54000 (83%)] Loss: -1572.174194\n",
      "Train Epoch: 679 [49152/54000 (91%)] Loss: -1565.750732\n",
      "Train Epoch: 679 [53248/54000 (99%)] Loss: -1565.698608\n",
      "    epoch          : 679\n",
      "    loss           : -1568.671939795616\n",
      "    ess            : 3.791654808261383\n",
      "    log_marginal   : 1568.7996548476378\n",
      "    val_loss       : -1568.1154378255208\n",
      "    val_ess        : 3.787739505370458\n",
      "    val_log_marginal: 1568.2535044352214\n",
      "Train Epoch: 680 [0/54000 (0%)] Loss: -1566.889038\n",
      "Train Epoch: 680 [4096/54000 (8%)] Loss: -1566.540405\n",
      "Train Epoch: 680 [8192/54000 (15%)] Loss: -1571.527588\n",
      "Train Epoch: 680 [12288/54000 (23%)] Loss: -1569.045776\n",
      "Train Epoch: 680 [16384/54000 (30%)] Loss: -1568.843994\n",
      "Train Epoch: 680 [20480/54000 (38%)] Loss: -1565.420410\n",
      "Train Epoch: 680 [24576/54000 (46%)] Loss: -1571.003418\n",
      "Train Epoch: 680 [28672/54000 (53%)] Loss: -1567.784180\n",
      "Train Epoch: 680 [32768/54000 (61%)] Loss: -1570.937744\n",
      "Train Epoch: 680 [36864/54000 (68%)] Loss: -1571.440430\n",
      "Train Epoch: 680 [40960/54000 (76%)] Loss: -1566.656494\n",
      "Train Epoch: 680 [45056/54000 (83%)] Loss: -1575.077637\n",
      "Train Epoch: 680 [49152/54000 (91%)] Loss: -1574.019531\n",
      "Train Epoch: 680 [53248/54000 (99%)] Loss: -1568.855225\n",
      "    epoch          : 680\n",
      "    loss           : -1568.9226988299763\n",
      "    ess            : 3.7916320149932425\n",
      "    log_marginal   : 1569.052022201755\n",
      "    val_loss       : -1568.2795664469402\n",
      "    val_ess        : 3.799259066581726\n",
      "    val_log_marginal: 1568.4058787027996\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch680.pth ...\n",
      "Train Epoch: 681 [0/54000 (0%)] Loss: -1568.683472\n",
      "Train Epoch: 681 [4096/54000 (8%)] Loss: -1563.744019\n",
      "Train Epoch: 681 [8192/54000 (15%)] Loss: -1567.683838\n",
      "Train Epoch: 681 [12288/54000 (23%)] Loss: -1567.258545\n",
      "Train Epoch: 681 [16384/54000 (30%)] Loss: -1569.167358\n",
      "Train Epoch: 681 [20480/54000 (38%)] Loss: -1569.356445\n",
      "Train Epoch: 681 [24576/54000 (46%)] Loss: -1566.979980\n",
      "Train Epoch: 681 [28672/54000 (53%)] Loss: -1567.965088\n",
      "Train Epoch: 681 [32768/54000 (61%)] Loss: -1570.150879\n",
      "Train Epoch: 681 [36864/54000 (68%)] Loss: -1566.934814\n",
      "Train Epoch: 681 [40960/54000 (76%)] Loss: -1571.143921\n",
      "Train Epoch: 681 [45056/54000 (83%)] Loss: -1570.564575\n",
      "Train Epoch: 681 [49152/54000 (91%)] Loss: -1574.666504\n",
      "Train Epoch: 681 [53248/54000 (99%)] Loss: -1565.509766\n",
      "    epoch          : 681\n",
      "    loss           : -1569.1402078782212\n",
      "    ess            : 3.7967711489347487\n",
      "    log_marginal   : 1569.2648711724305\n",
      "    val_loss       : -1568.0364939371746\n",
      "    val_ess        : 3.7924383083979287\n",
      "    val_log_marginal: 1568.1616617838542\n",
      "Train Epoch: 682 [0/54000 (0%)] Loss: -1564.788452\n",
      "Train Epoch: 682 [4096/54000 (8%)] Loss: -1566.767700\n",
      "Train Epoch: 682 [8192/54000 (15%)] Loss: -1571.960449\n",
      "Train Epoch: 682 [12288/54000 (23%)] Loss: -1569.318848\n",
      "Train Epoch: 682 [16384/54000 (30%)] Loss: -1568.308960\n",
      "Train Epoch: 682 [20480/54000 (38%)] Loss: -1562.613525\n",
      "Train Epoch: 682 [24576/54000 (46%)] Loss: -1571.286377\n",
      "Train Epoch: 682 [28672/54000 (53%)] Loss: -1570.348877\n",
      "Train Epoch: 682 [32768/54000 (61%)] Loss: -1564.337402\n",
      "Train Epoch: 682 [36864/54000 (68%)] Loss: -1568.083740\n",
      "Train Epoch: 682 [40960/54000 (76%)] Loss: -1570.842163\n",
      "Train Epoch: 682 [45056/54000 (83%)] Loss: -1569.598389\n",
      "Train Epoch: 682 [49152/54000 (91%)] Loss: -1560.460205\n",
      "Train Epoch: 682 [53248/54000 (99%)] Loss: -1565.633423\n",
      "    epoch          : 682\n",
      "    loss           : -1569.1701683297542\n",
      "    ess            : 3.7887019670405095\n",
      "    log_marginal   : 1569.3040470647586\n",
      "    val_loss       : -1568.6620534261067\n",
      "    val_ess        : 3.7812423706054688\n",
      "    val_log_marginal: 1568.7962493896484\n",
      "Train Epoch: 683 [0/54000 (0%)] Loss: -1572.838867\n",
      "Train Epoch: 683 [4096/54000 (8%)] Loss: -1567.629395\n",
      "Train Epoch: 683 [8192/54000 (15%)] Loss: -1568.029053\n",
      "Train Epoch: 683 [12288/54000 (23%)] Loss: -1564.598267\n",
      "Train Epoch: 683 [16384/54000 (30%)] Loss: -1570.855957\n",
      "Train Epoch: 683 [20480/54000 (38%)] Loss: -1571.211182\n",
      "Train Epoch: 683 [24576/54000 (46%)] Loss: -1571.979736\n",
      "Train Epoch: 683 [28672/54000 (53%)] Loss: -1569.473145\n",
      "Train Epoch: 683 [32768/54000 (61%)] Loss: -1568.875000\n",
      "Train Epoch: 683 [36864/54000 (68%)] Loss: -1569.698242\n",
      "Train Epoch: 683 [40960/54000 (76%)] Loss: -1570.249512\n",
      "Train Epoch: 683 [45056/54000 (83%)] Loss: -1569.687988\n",
      "Train Epoch: 683 [49152/54000 (91%)] Loss: -1570.025879\n",
      "Train Epoch: 683 [53248/54000 (99%)] Loss: -1568.685181\n",
      "    epoch          : 683\n",
      "    loss           : -1569.1272169357228\n",
      "    ess            : 3.79597340714875\n",
      "    log_marginal   : 1569.2505160507997\n",
      "    val_loss       : -1568.8150126139324\n",
      "    val_ess        : 3.7855318784713745\n",
      "    val_log_marginal: 1568.9440002441406\n",
      "Train Epoch: 684 [0/54000 (0%)] Loss: -1569.692139\n",
      "Train Epoch: 684 [4096/54000 (8%)] Loss: -1573.556396\n",
      "Train Epoch: 684 [8192/54000 (15%)] Loss: -1568.285645\n",
      "Train Epoch: 684 [12288/54000 (23%)] Loss: -1571.491455\n",
      "Train Epoch: 684 [16384/54000 (30%)] Loss: -1571.867676\n",
      "Train Epoch: 684 [20480/54000 (38%)] Loss: -1573.733032\n",
      "Train Epoch: 684 [24576/54000 (46%)] Loss: -1572.058838\n",
      "Train Epoch: 684 [28672/54000 (53%)] Loss: -1569.814697\n",
      "Train Epoch: 684 [32768/54000 (61%)] Loss: -1570.705933\n",
      "Train Epoch: 684 [36864/54000 (68%)] Loss: -1575.639038\n",
      "Train Epoch: 684 [40960/54000 (76%)] Loss: -1563.252441\n",
      "Train Epoch: 684 [45056/54000 (83%)] Loss: -1560.926758\n",
      "Train Epoch: 684 [49152/54000 (91%)] Loss: -1567.202393\n",
      "Train Epoch: 684 [53248/54000 (99%)] Loss: -1567.948486\n",
      "    epoch          : 684\n",
      "    loss           : -1569.4205993363078\n",
      "    ess            : 3.789375652069164\n",
      "    log_marginal   : 1569.5512845730896\n",
      "    val_loss       : -1569.2307383219402\n",
      "    val_ess        : 3.806193540493647\n",
      "    val_log_marginal: 1569.3469950358074\n",
      "Train Epoch: 685 [0/54000 (0%)] Loss: -1558.702148\n",
      "Train Epoch: 685 [4096/54000 (8%)] Loss: -1569.540039\n",
      "Train Epoch: 685 [8192/54000 (15%)] Loss: -1571.473511\n",
      "Train Epoch: 685 [12288/54000 (23%)] Loss: -1568.042236\n",
      "Train Epoch: 685 [16384/54000 (30%)] Loss: -1568.681519\n",
      "Train Epoch: 685 [20480/54000 (38%)] Loss: -1572.184570\n",
      "Train Epoch: 685 [24576/54000 (46%)] Loss: -1571.828125\n",
      "Train Epoch: 685 [28672/54000 (53%)] Loss: -1567.797119\n",
      "Train Epoch: 685 [32768/54000 (61%)] Loss: -1565.277222\n",
      "Train Epoch: 685 [36864/54000 (68%)] Loss: -1569.380981\n",
      "Train Epoch: 685 [40960/54000 (76%)] Loss: -1573.584106\n",
      "Train Epoch: 685 [45056/54000 (83%)] Loss: -1569.828369\n",
      "Train Epoch: 685 [49152/54000 (91%)] Loss: -1564.318481\n",
      "Train Epoch: 685 [53248/54000 (99%)] Loss: -1566.834351\n",
      "    epoch          : 685\n",
      "    loss           : -1569.3641872315611\n",
      "    ess            : 3.794461131660859\n",
      "    log_marginal   : 1569.4899815563906\n",
      "    val_loss       : -1569.36181640625\n",
      "    val_ess        : 3.792626053094864\n",
      "    val_log_marginal: 1569.491475423177\n",
      "Train Epoch: 686 [0/54000 (0%)] Loss: -1571.511108\n",
      "Train Epoch: 686 [4096/54000 (8%)] Loss: -1570.454346\n",
      "Train Epoch: 686 [8192/54000 (15%)] Loss: -1578.264038\n",
      "Train Epoch: 686 [12288/54000 (23%)] Loss: -1572.506104\n",
      "Train Epoch: 686 [16384/54000 (30%)] Loss: -1572.641968\n",
      "Train Epoch: 686 [20480/54000 (38%)] Loss: -1569.417969\n",
      "Train Epoch: 686 [24576/54000 (46%)] Loss: -1569.181152\n",
      "Train Epoch: 686 [28672/54000 (53%)] Loss: -1572.233765\n",
      "Train Epoch: 686 [32768/54000 (61%)] Loss: -1572.909668\n",
      "Train Epoch: 686 [36864/54000 (68%)] Loss: -1567.676025\n",
      "Train Epoch: 686 [40960/54000 (76%)] Loss: -1566.434814\n",
      "Train Epoch: 686 [45056/54000 (83%)] Loss: -1566.325562\n",
      "Train Epoch: 686 [49152/54000 (91%)] Loss: -1566.993408\n",
      "Train Epoch: 686 [53248/54000 (99%)] Loss: -1568.300781\n",
      "    epoch          : 686\n",
      "    loss           : -1569.7148263940314\n",
      "    ess            : 3.79838981899605\n",
      "    log_marginal   : 1569.8382551003406\n",
      "    val_loss       : -1569.0962575276692\n",
      "    val_ess        : 3.809483806292216\n",
      "    val_log_marginal: 1569.2144673665364\n",
      "Train Epoch: 687 [0/54000 (0%)] Loss: -1566.678711\n",
      "Train Epoch: 687 [4096/54000 (8%)] Loss: -1564.149414\n",
      "Train Epoch: 687 [8192/54000 (15%)] Loss: -1568.365479\n",
      "Train Epoch: 687 [12288/54000 (23%)] Loss: -1567.544189\n",
      "Train Epoch: 687 [16384/54000 (30%)] Loss: -1571.603027\n",
      "Train Epoch: 687 [20480/54000 (38%)] Loss: -1570.411255\n",
      "Train Epoch: 687 [24576/54000 (46%)] Loss: -1571.173096\n",
      "Train Epoch: 687 [28672/54000 (53%)] Loss: -1571.164795\n",
      "Train Epoch: 687 [32768/54000 (61%)] Loss: -1566.481445\n",
      "Train Epoch: 687 [36864/54000 (68%)] Loss: -1567.263916\n",
      "Train Epoch: 687 [40960/54000 (76%)] Loss: -1568.661499\n",
      "Train Epoch: 687 [45056/54000 (83%)] Loss: -1570.376465\n",
      "Train Epoch: 687 [49152/54000 (91%)] Loss: -1575.690430\n",
      "Train Epoch: 687 [53248/54000 (99%)] Loss: -1574.199951\n",
      "    epoch          : 687\n",
      "    loss           : -1569.5827989623444\n",
      "    ess            : 3.7943712252576205\n",
      "    log_marginal   : 1569.711090811056\n",
      "    val_loss       : -1569.6579284667969\n",
      "    val_ess        : 3.780962566534678\n",
      "    val_log_marginal: 1569.7971445719402\n",
      "Train Epoch: 688 [0/54000 (0%)] Loss: -1572.145142\n",
      "Train Epoch: 688 [4096/54000 (8%)] Loss: -1575.755371\n",
      "Train Epoch: 688 [8192/54000 (15%)] Loss: -1570.918213\n",
      "Train Epoch: 688 [12288/54000 (23%)] Loss: -1568.172119\n",
      "Train Epoch: 688 [16384/54000 (30%)] Loss: -1572.909302\n",
      "Train Epoch: 688 [20480/54000 (38%)] Loss: -1568.885742\n",
      "Train Epoch: 688 [24576/54000 (46%)] Loss: -1573.140381\n",
      "Train Epoch: 688 [28672/54000 (53%)] Loss: -1578.507812\n",
      "Train Epoch: 688 [32768/54000 (61%)] Loss: -1567.354004\n",
      "Train Epoch: 688 [36864/54000 (68%)] Loss: -1569.187866\n",
      "Train Epoch: 688 [40960/54000 (76%)] Loss: -1565.087891\n",
      "Train Epoch: 688 [45056/54000 (83%)] Loss: -1572.793701\n",
      "Train Epoch: 688 [49152/54000 (91%)] Loss: -1575.768311\n",
      "Train Epoch: 688 [53248/54000 (99%)] Loss: -1564.255859\n",
      "    epoch          : 688\n",
      "    loss           : -1569.6657159452755\n",
      "    ess            : 3.798454621391839\n",
      "    log_marginal   : 1569.786966477525\n",
      "    val_loss       : -1569.037073771159\n",
      "    val_ess        : 3.7876550356547036\n",
      "    val_log_marginal: 1569.1693674723308\n",
      "Train Epoch: 689 [0/54000 (0%)] Loss: -1572.693359\n",
      "Train Epoch: 689 [4096/54000 (8%)] Loss: -1568.119141\n",
      "Train Epoch: 689 [8192/54000 (15%)] Loss: -1561.792480\n",
      "Train Epoch: 689 [12288/54000 (23%)] Loss: -1569.455688\n",
      "Train Epoch: 689 [16384/54000 (30%)] Loss: -1572.970703\n",
      "Train Epoch: 689 [20480/54000 (38%)] Loss: -1567.557251\n",
      "Train Epoch: 689 [24576/54000 (46%)] Loss: -1578.421143\n",
      "Train Epoch: 689 [28672/54000 (53%)] Loss: -1569.195312\n",
      "Train Epoch: 689 [32768/54000 (61%)] Loss: -1573.068359\n",
      "Train Epoch: 689 [36864/54000 (68%)] Loss: -1571.153564\n",
      "Train Epoch: 689 [40960/54000 (76%)] Loss: -1573.989014\n",
      "Train Epoch: 689 [45056/54000 (83%)] Loss: -1573.629150\n",
      "Train Epoch: 689 [49152/54000 (91%)] Loss: -1573.351318\n",
      "Train Epoch: 689 [53248/54000 (99%)] Loss: -1564.991089\n",
      "    epoch          : 689\n",
      "    loss           : -1570.0263139625297\n",
      "    ess            : 3.789128896749415\n",
      "    log_marginal   : 1570.1560029667135\n",
      "    val_loss       : -1569.4235382080078\n",
      "    val_ess        : 3.7930715183417\n",
      "    val_log_marginal: 1569.5531514485676\n",
      "Train Epoch: 690 [0/54000 (0%)] Loss: -1568.210693\n",
      "Train Epoch: 690 [4096/54000 (8%)] Loss: -1567.284668\n",
      "Train Epoch: 690 [8192/54000 (15%)] Loss: -1566.122803\n",
      "Train Epoch: 690 [12288/54000 (23%)] Loss: -1560.180176\n",
      "Train Epoch: 690 [16384/54000 (30%)] Loss: -1568.436279\n",
      "Train Epoch: 690 [20480/54000 (38%)] Loss: -1563.777832\n",
      "Train Epoch: 690 [24576/54000 (46%)] Loss: -1564.781250\n",
      "Train Epoch: 690 [28672/54000 (53%)] Loss: -1569.769897\n",
      "Train Epoch: 690 [32768/54000 (61%)] Loss: -1574.947998\n",
      "Train Epoch: 690 [36864/54000 (68%)] Loss: -1573.862549\n",
      "Train Epoch: 690 [40960/54000 (76%)] Loss: -1573.597168\n",
      "Train Epoch: 690 [45056/54000 (83%)] Loss: -1574.601196\n",
      "Train Epoch: 690 [49152/54000 (91%)] Loss: -1572.324829\n",
      "Train Epoch: 690 [53248/54000 (99%)] Loss: -1575.963135\n",
      "    epoch          : 690\n",
      "    loss           : -1570.0341241484005\n",
      "    ess            : 3.795035340774681\n",
      "    log_marginal   : 1570.1607469314647\n",
      "    val_loss       : -1569.9444020589192\n",
      "    val_ess        : 3.801031539837519\n",
      "    val_log_marginal: 1570.066670735677\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch690.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 691 [0/54000 (0%)] Loss: -1570.950928\n",
      "Train Epoch: 691 [4096/54000 (8%)] Loss: -1570.868286\n",
      "Train Epoch: 691 [8192/54000 (15%)] Loss: -1574.132324\n",
      "Train Epoch: 691 [12288/54000 (23%)] Loss: -1574.467407\n",
      "Train Epoch: 691 [16384/54000 (30%)] Loss: -1571.118408\n",
      "Train Epoch: 691 [20480/54000 (38%)] Loss: -1572.406494\n",
      "Train Epoch: 691 [24576/54000 (46%)] Loss: -1576.123291\n",
      "Train Epoch: 691 [28672/54000 (53%)] Loss: -1565.434570\n",
      "Train Epoch: 691 [32768/54000 (61%)] Loss: -1566.667969\n",
      "Train Epoch: 691 [36864/54000 (68%)] Loss: -1569.377441\n",
      "Train Epoch: 691 [40960/54000 (76%)] Loss: -1572.789551\n",
      "Train Epoch: 691 [45056/54000 (83%)] Loss: -1573.412598\n",
      "Train Epoch: 691 [49152/54000 (91%)] Loss: -1570.723145\n",
      "Train Epoch: 691 [53248/54000 (99%)] Loss: -1567.920288\n",
      "    epoch          : 691\n",
      "    loss           : -1570.1019182973564\n",
      "    ess            : 3.7927903552755926\n",
      "    log_marginal   : 1570.228428845157\n",
      "    val_loss       : -1569.066167195638\n",
      "    val_ess        : 3.7955753803253174\n",
      "    val_log_marginal: 1569.1867167154949\n",
      "Train Epoch: 692 [0/54000 (0%)] Loss: -1572.579102\n",
      "Train Epoch: 692 [4096/54000 (8%)] Loss: -1575.077148\n",
      "Train Epoch: 692 [8192/54000 (15%)] Loss: -1569.467529\n",
      "Train Epoch: 692 [12288/54000 (23%)] Loss: -1564.108398\n",
      "Train Epoch: 692 [16384/54000 (30%)] Loss: -1572.312988\n",
      "Train Epoch: 692 [20480/54000 (38%)] Loss: -1567.142090\n",
      "Train Epoch: 692 [24576/54000 (46%)] Loss: -1567.253906\n",
      "Train Epoch: 692 [28672/54000 (53%)] Loss: -1569.763428\n",
      "Train Epoch: 692 [32768/54000 (61%)] Loss: -1567.077393\n",
      "Train Epoch: 692 [36864/54000 (68%)] Loss: -1569.149536\n",
      "Train Epoch: 692 [40960/54000 (76%)] Loss: -1572.145996\n",
      "Train Epoch: 692 [45056/54000 (83%)] Loss: -1565.075195\n",
      "Train Epoch: 692 [49152/54000 (91%)] Loss: -1572.175781\n",
      "Train Epoch: 692 [53248/54000 (99%)] Loss: -1572.567871\n",
      "    epoch          : 692\n",
      "    loss           : -1569.985482310797\n",
      "    ess            : 3.7907991104216374\n",
      "    log_marginal   : 1570.116893027066\n",
      "    val_loss       : -1570.586898803711\n",
      "    val_ess        : 3.7952937285105386\n",
      "    val_log_marginal: 1570.7077077229817\n",
      "Train Epoch: 693 [0/54000 (0%)] Loss: -1570.118164\n",
      "Train Epoch: 693 [4096/54000 (8%)] Loss: -1569.511475\n",
      "Train Epoch: 693 [8192/54000 (15%)] Loss: -1570.917236\n",
      "Train Epoch: 693 [12288/54000 (23%)] Loss: -1574.476685\n",
      "Train Epoch: 693 [16384/54000 (30%)] Loss: -1570.821167\n",
      "Train Epoch: 693 [20480/54000 (38%)] Loss: -1571.395996\n",
      "Train Epoch: 693 [24576/54000 (46%)] Loss: -1568.858643\n",
      "Train Epoch: 693 [28672/54000 (53%)] Loss: -1570.785645\n",
      "Train Epoch: 693 [32768/54000 (61%)] Loss: -1568.828735\n",
      "Train Epoch: 693 [36864/54000 (68%)] Loss: -1573.171631\n",
      "Train Epoch: 693 [40960/54000 (76%)] Loss: -1569.179810\n",
      "Train Epoch: 693 [45056/54000 (83%)] Loss: -1568.636841\n",
      "Train Epoch: 693 [49152/54000 (91%)] Loss: -1576.483765\n",
      "Train Epoch: 693 [53248/54000 (99%)] Loss: -1574.969116\n",
      "    epoch          : 693\n",
      "    loss           : -1570.2151029324646\n",
      "    ess            : 3.7885439282909954\n",
      "    log_marginal   : 1570.348608514144\n",
      "    val_loss       : -1569.8699188232422\n",
      "    val_ess        : 3.793516476949056\n",
      "    val_log_marginal: 1570.0066528320312\n",
      "Train Epoch: 694 [0/54000 (0%)] Loss: -1569.089478\n",
      "Train Epoch: 694 [4096/54000 (8%)] Loss: -1569.124268\n",
      "Train Epoch: 694 [8192/54000 (15%)] Loss: -1566.696289\n",
      "Train Epoch: 694 [12288/54000 (23%)] Loss: -1574.107422\n",
      "Train Epoch: 694 [16384/54000 (30%)] Loss: -1569.995850\n",
      "Train Epoch: 694 [20480/54000 (38%)] Loss: -1570.374512\n",
      "Train Epoch: 694 [24576/54000 (46%)] Loss: -1571.753662\n",
      "Train Epoch: 694 [28672/54000 (53%)] Loss: -1574.118286\n",
      "Train Epoch: 694 [32768/54000 (61%)] Loss: -1570.990112\n",
      "Train Epoch: 694 [36864/54000 (68%)] Loss: -1567.037354\n",
      "Train Epoch: 694 [40960/54000 (76%)] Loss: -1569.869019\n",
      "Train Epoch: 694 [45056/54000 (83%)] Loss: -1568.684326\n",
      "Train Epoch: 694 [49152/54000 (91%)] Loss: -1571.466431\n",
      "Train Epoch: 694 [53248/54000 (99%)] Loss: -1571.637695\n",
      "    epoch          : 694\n",
      "    loss           : -1570.528903473045\n",
      "    ess            : 3.7933019337495923\n",
      "    log_marginal   : 1570.6551831864633\n",
      "    val_loss       : -1569.7254638671875\n",
      "    val_ess        : 3.8006795148054757\n",
      "    val_log_marginal: 1569.844762166341\n",
      "Train Epoch: 695 [0/54000 (0%)] Loss: -1568.626953\n",
      "Train Epoch: 695 [4096/54000 (8%)] Loss: -1573.978638\n",
      "Train Epoch: 695 [8192/54000 (15%)] Loss: -1568.961182\n",
      "Train Epoch: 695 [12288/54000 (23%)] Loss: -1577.562378\n",
      "Train Epoch: 695 [16384/54000 (30%)] Loss: -1572.534912\n",
      "Train Epoch: 695 [20480/54000 (38%)] Loss: -1569.725220\n",
      "Train Epoch: 695 [24576/54000 (46%)] Loss: -1567.600342\n",
      "Train Epoch: 695 [28672/54000 (53%)] Loss: -1575.192139\n",
      "Train Epoch: 695 [32768/54000 (61%)] Loss: -1566.803223\n",
      "Train Epoch: 695 [36864/54000 (68%)] Loss: -1572.638550\n",
      "Train Epoch: 695 [40960/54000 (76%)] Loss: -1565.932373\n",
      "Train Epoch: 695 [45056/54000 (83%)] Loss: -1571.208252\n",
      "Train Epoch: 695 [49152/54000 (91%)] Loss: -1569.503052\n",
      "Train Epoch: 695 [53248/54000 (99%)] Loss: -1569.909180\n",
      "    epoch          : 695\n",
      "    loss           : -1570.8494254017328\n",
      "    ess            : 3.79425867925888\n",
      "    log_marginal   : 1570.9746481366633\n",
      "    val_loss       : -1570.4288075764973\n",
      "    val_ess        : 3.778169184923172\n",
      "    val_log_marginal: 1570.5611470540364\n",
      "Train Epoch: 696 [0/54000 (0%)] Loss: -1567.612427\n",
      "Train Epoch: 696 [4096/54000 (8%)] Loss: -1570.992432\n",
      "Train Epoch: 696 [8192/54000 (15%)] Loss: -1573.440918\n",
      "Train Epoch: 696 [12288/54000 (23%)] Loss: -1575.578369\n",
      "Train Epoch: 696 [16384/54000 (30%)] Loss: -1573.195068\n",
      "Train Epoch: 696 [20480/54000 (38%)] Loss: -1575.174805\n",
      "Train Epoch: 696 [24576/54000 (46%)] Loss: -1566.647949\n",
      "Train Epoch: 696 [28672/54000 (53%)] Loss: -1571.176880\n",
      "Train Epoch: 696 [32768/54000 (61%)] Loss: -1571.887085\n",
      "Train Epoch: 696 [36864/54000 (68%)] Loss: -1566.663208\n",
      "Train Epoch: 696 [40960/54000 (76%)] Loss: -1567.846191\n",
      "Train Epoch: 696 [45056/54000 (83%)] Loss: -1569.552490\n",
      "Train Epoch: 696 [49152/54000 (91%)] Loss: -1566.437500\n",
      "Train Epoch: 696 [53248/54000 (99%)] Loss: -1575.632812\n",
      "    epoch          : 696\n",
      "    loss           : -1571.0147097619224\n",
      "    ess            : 3.792149117772613\n",
      "    log_marginal   : 1571.143976437537\n",
      "    val_loss       : -1571.2322184244792\n",
      "    val_ess        : 3.7968028485774994\n",
      "    val_log_marginal: 1571.3454132080078\n",
      "Train Epoch: 697 [0/54000 (0%)] Loss: -1569.802002\n",
      "Train Epoch: 697 [4096/54000 (8%)] Loss: -1571.925781\n",
      "Train Epoch: 697 [8192/54000 (15%)] Loss: -1567.001709\n",
      "Train Epoch: 697 [12288/54000 (23%)] Loss: -1572.948242\n",
      "Train Epoch: 697 [16384/54000 (30%)] Loss: -1570.093140\n",
      "Train Epoch: 697 [20480/54000 (38%)] Loss: -1567.777710\n",
      "Train Epoch: 697 [24576/54000 (46%)] Loss: -1572.185181\n",
      "Train Epoch: 697 [28672/54000 (53%)] Loss: -1576.813110\n",
      "Train Epoch: 697 [32768/54000 (61%)] Loss: -1567.762451\n",
      "Train Epoch: 697 [36864/54000 (68%)] Loss: -1572.079956\n",
      "Train Epoch: 697 [40960/54000 (76%)] Loss: -1570.953125\n",
      "Train Epoch: 697 [45056/54000 (83%)] Loss: -1565.701904\n",
      "Train Epoch: 697 [49152/54000 (91%)] Loss: -1568.190063\n",
      "Train Epoch: 697 [53248/54000 (99%)] Loss: -1570.147217\n",
      "    epoch          : 697\n",
      "    loss           : -1570.6841537692535\n",
      "    ess            : 3.7954382150659063\n",
      "    log_marginal   : 1570.81162468065\n",
      "    val_loss       : -1570.9832712809246\n",
      "    val_ess        : 3.7940777242183685\n",
      "    val_log_marginal: 1571.104268391927\n",
      "Train Epoch: 698 [0/54000 (0%)] Loss: -1574.869629\n",
      "Train Epoch: 698 [4096/54000 (8%)] Loss: -1571.968628\n",
      "Train Epoch: 698 [8192/54000 (15%)] Loss: -1565.352661\n",
      "Train Epoch: 698 [12288/54000 (23%)] Loss: -1571.520264\n",
      "Train Epoch: 698 [16384/54000 (30%)] Loss: -1566.575684\n",
      "Train Epoch: 698 [20480/54000 (38%)] Loss: -1572.124146\n",
      "Train Epoch: 698 [24576/54000 (46%)] Loss: -1573.870117\n",
      "Train Epoch: 698 [28672/54000 (53%)] Loss: -1572.326904\n",
      "Train Epoch: 698 [32768/54000 (61%)] Loss: -1571.524658\n",
      "Train Epoch: 698 [36864/54000 (68%)] Loss: -1566.784180\n",
      "Train Epoch: 698 [40960/54000 (76%)] Loss: -1570.475098\n",
      "Train Epoch: 698 [45056/54000 (83%)] Loss: -1570.037109\n",
      "Train Epoch: 698 [49152/54000 (91%)] Loss: -1573.661621\n",
      "Train Epoch: 698 [53248/54000 (99%)] Loss: -1573.902100\n",
      "    epoch          : 698\n",
      "    loss           : -1570.7289229117298\n",
      "    ess            : 3.7988869341628813\n",
      "    log_marginal   : 1570.8508399131738\n",
      "    val_loss       : -1569.9496968587239\n",
      "    val_ess        : 3.7738081415494285\n",
      "    val_log_marginal: 1570.1012725830078\n",
      "Train Epoch: 699 [0/54000 (0%)] Loss: -1570.612549\n",
      "Train Epoch: 699 [4096/54000 (8%)] Loss: -1567.411621\n",
      "Train Epoch: 699 [8192/54000 (15%)] Loss: -1575.882935\n",
      "Train Epoch: 699 [12288/54000 (23%)] Loss: -1568.609375\n",
      "Train Epoch: 699 [16384/54000 (30%)] Loss: -1576.211914\n",
      "Train Epoch: 699 [20480/54000 (38%)] Loss: -1563.519287\n",
      "Train Epoch: 699 [24576/54000 (46%)] Loss: -1565.200317\n",
      "Train Epoch: 699 [28672/54000 (53%)] Loss: -1569.917114\n",
      "Train Epoch: 699 [32768/54000 (61%)] Loss: -1570.720581\n",
      "Train Epoch: 699 [36864/54000 (68%)] Loss: -1569.218506\n",
      "Train Epoch: 699 [40960/54000 (76%)] Loss: -1573.231079\n",
      "Train Epoch: 699 [45056/54000 (83%)] Loss: -1569.868652\n",
      "Train Epoch: 699 [49152/54000 (91%)] Loss: -1570.950317\n",
      "Train Epoch: 699 [53248/54000 (99%)] Loss: -1568.592529\n",
      "    epoch          : 699\n",
      "    loss           : -1571.038331813722\n",
      "    ess            : 3.7950382616847613\n",
      "    log_marginal   : 1571.1658345443943\n",
      "    val_loss       : -1570.3001658121746\n",
      "    val_ess        : 3.801143834988276\n",
      "    val_log_marginal: 1570.4156341552734\n",
      "Train Epoch: 700 [0/54000 (0%)] Loss: -1576.430908\n",
      "Train Epoch: 700 [4096/54000 (8%)] Loss: -1570.612061\n",
      "Train Epoch: 700 [8192/54000 (15%)] Loss: -1565.412598\n",
      "Train Epoch: 700 [12288/54000 (23%)] Loss: -1563.388672\n",
      "Train Epoch: 700 [16384/54000 (30%)] Loss: -1570.811768\n",
      "Train Epoch: 700 [20480/54000 (38%)] Loss: -1573.499756\n",
      "Train Epoch: 700 [24576/54000 (46%)] Loss: -1571.378052\n",
      "Train Epoch: 700 [28672/54000 (53%)] Loss: -1571.135254\n",
      "Train Epoch: 700 [32768/54000 (61%)] Loss: -1568.200928\n",
      "Train Epoch: 700 [36864/54000 (68%)] Loss: -1572.283447\n",
      "Train Epoch: 700 [40960/54000 (76%)] Loss: -1567.516602\n",
      "Train Epoch: 700 [45056/54000 (83%)] Loss: -1570.932983\n",
      "Train Epoch: 700 [49152/54000 (91%)] Loss: -1573.177734\n",
      "Train Epoch: 700 [53248/54000 (99%)] Loss: -1568.286865\n",
      "    epoch          : 700\n",
      "    loss           : -1570.5324359911879\n",
      "    ess            : 3.7907025881853147\n",
      "    log_marginal   : 1570.6646751656917\n",
      "    val_loss       : -1569.9120178222656\n",
      "    val_ess        : 3.7880039314428964\n",
      "    val_log_marginal: 1570.0386199951172\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [0/54000 (0%)] Loss: -1569.104492\n",
      "Train Epoch: 701 [4096/54000 (8%)] Loss: -1570.686279\n",
      "Train Epoch: 701 [8192/54000 (15%)] Loss: -1570.350464\n",
      "Train Epoch: 701 [12288/54000 (23%)] Loss: -1572.669189\n",
      "Train Epoch: 701 [16384/54000 (30%)] Loss: -1564.039062\n",
      "Train Epoch: 701 [20480/54000 (38%)] Loss: -1566.236572\n",
      "Train Epoch: 701 [24576/54000 (46%)] Loss: -1573.809692\n",
      "Train Epoch: 701 [28672/54000 (53%)] Loss: -1570.617554\n",
      "Train Epoch: 701 [32768/54000 (61%)] Loss: -1576.727417\n",
      "Train Epoch: 701 [36864/54000 (68%)] Loss: -1573.648193\n",
      "Train Epoch: 701 [40960/54000 (76%)] Loss: -1569.372803\n",
      "Train Epoch: 701 [45056/54000 (83%)] Loss: -1565.682373\n",
      "Train Epoch: 701 [49152/54000 (91%)] Loss: -1572.974976\n",
      "Train Epoch: 701 [53248/54000 (99%)] Loss: -1566.343750\n",
      "    epoch          : 701\n",
      "    loss           : -1570.804431210197\n",
      "    ess            : 3.793597040583172\n",
      "    log_marginal   : 1570.9327328939573\n",
      "    val_loss       : -1570.189702351888\n",
      "    val_ess        : 3.797415256500244\n",
      "    val_log_marginal: 1570.3138580322266\n",
      "Train Epoch: 702 [0/54000 (0%)] Loss: -1570.635620\n",
      "Train Epoch: 702 [4096/54000 (8%)] Loss: -1577.771240\n",
      "Train Epoch: 702 [8192/54000 (15%)] Loss: -1573.538696\n",
      "Train Epoch: 702 [12288/54000 (23%)] Loss: -1575.262451\n",
      "Train Epoch: 702 [16384/54000 (30%)] Loss: -1565.778320\n",
      "Train Epoch: 702 [20480/54000 (38%)] Loss: -1572.907471\n",
      "Train Epoch: 702 [24576/54000 (46%)] Loss: -1571.442627\n",
      "Train Epoch: 702 [28672/54000 (53%)] Loss: -1573.831055\n",
      "Train Epoch: 702 [32768/54000 (61%)] Loss: -1573.049194\n",
      "Train Epoch: 702 [36864/54000 (68%)] Loss: -1569.048584\n",
      "Train Epoch: 702 [40960/54000 (76%)] Loss: -1569.668701\n",
      "Train Epoch: 702 [45056/54000 (83%)] Loss: -1566.900146\n",
      "Train Epoch: 702 [49152/54000 (91%)] Loss: -1573.717285\n",
      "Train Epoch: 702 [53248/54000 (99%)] Loss: -1577.685913\n",
      "    epoch          : 702\n",
      "    loss           : -1570.991491525659\n",
      "    ess            : 3.797964752567888\n",
      "    log_marginal   : 1571.115531162063\n",
      "    val_loss       : -1571.0147908528645\n",
      "    val_ess        : 3.776549647251765\n",
      "    val_log_marginal: 1571.1548970540364\n",
      "Train Epoch: 703 [0/54000 (0%)] Loss: -1572.942139\n",
      "Train Epoch: 703 [4096/54000 (8%)] Loss: -1567.455811\n",
      "Train Epoch: 703 [8192/54000 (15%)] Loss: -1568.584351\n",
      "Train Epoch: 703 [12288/54000 (23%)] Loss: -1569.324707\n",
      "Train Epoch: 703 [16384/54000 (30%)] Loss: -1563.302734\n",
      "Train Epoch: 703 [20480/54000 (38%)] Loss: -1568.772095\n",
      "Train Epoch: 703 [24576/54000 (46%)] Loss: -1570.580444\n",
      "Train Epoch: 703 [28672/54000 (53%)] Loss: -1565.899780\n",
      "Train Epoch: 703 [32768/54000 (61%)] Loss: -1568.840088\n",
      "Train Epoch: 703 [36864/54000 (68%)] Loss: -1570.732910\n",
      "Train Epoch: 703 [40960/54000 (76%)] Loss: -1569.209473\n",
      "Train Epoch: 703 [45056/54000 (83%)] Loss: -1575.149902\n",
      "Train Epoch: 703 [49152/54000 (91%)] Loss: -1574.496338\n",
      "Train Epoch: 703 [53248/54000 (99%)] Loss: -1566.783936\n",
      "    epoch          : 703\n",
      "    loss           : -1571.1810042394845\n",
      "    ess            : 3.7910128023952105\n",
      "    log_marginal   : 1571.3100296671357\n",
      "    val_loss       : -1570.0564524332683\n",
      "    val_ess        : 3.804670830567678\n",
      "    val_log_marginal: 1570.1765696207683\n",
      "Train Epoch: 704 [0/54000 (0%)] Loss: -1572.363892\n",
      "Train Epoch: 704 [4096/54000 (8%)] Loss: -1570.277954\n",
      "Train Epoch: 704 [8192/54000 (15%)] Loss: -1572.198975\n",
      "Train Epoch: 704 [12288/54000 (23%)] Loss: -1573.863770\n",
      "Train Epoch: 704 [16384/54000 (30%)] Loss: -1572.278564\n",
      "Train Epoch: 704 [20480/54000 (38%)] Loss: -1575.818115\n",
      "Train Epoch: 704 [24576/54000 (46%)] Loss: -1567.666016\n",
      "Train Epoch: 704 [28672/54000 (53%)] Loss: -1576.430176\n",
      "Train Epoch: 704 [32768/54000 (61%)] Loss: -1571.548096\n",
      "Train Epoch: 704 [36864/54000 (68%)] Loss: -1565.641357\n",
      "Train Epoch: 704 [40960/54000 (76%)] Loss: -1568.579956\n",
      "Train Epoch: 704 [45056/54000 (83%)] Loss: -1573.572266\n",
      "Train Epoch: 704 [49152/54000 (91%)] Loss: -1566.355469\n",
      "Train Epoch: 704 [53248/54000 (99%)] Loss: -1570.040283\n",
      "    epoch          : 704\n",
      "    loss           : -1571.143068141847\n",
      "    ess            : 3.795649662966977\n",
      "    log_marginal   : 1571.2661693988819\n",
      "    val_loss       : -1570.968297322591\n",
      "    val_ess        : 3.805726021528244\n",
      "    val_log_marginal: 1571.0815887451172\n",
      "Train Epoch: 705 [0/54000 (0%)] Loss: -1569.701660\n",
      "Train Epoch: 705 [4096/54000 (8%)] Loss: -1570.017334\n",
      "Train Epoch: 705 [8192/54000 (15%)] Loss: -1570.463623\n",
      "Train Epoch: 705 [12288/54000 (23%)] Loss: -1563.265259\n",
      "Train Epoch: 705 [16384/54000 (30%)] Loss: -1566.354736\n",
      "Train Epoch: 705 [20480/54000 (38%)] Loss: -1569.403198\n",
      "Train Epoch: 705 [24576/54000 (46%)] Loss: -1571.444580\n",
      "Train Epoch: 705 [28672/54000 (53%)] Loss: -1569.437256\n",
      "Train Epoch: 705 [32768/54000 (61%)] Loss: -1567.112793\n",
      "Train Epoch: 705 [36864/54000 (68%)] Loss: -1573.107422\n",
      "Train Epoch: 705 [40960/54000 (76%)] Loss: -1567.789307\n",
      "Train Epoch: 705 [45056/54000 (83%)] Loss: -1566.147217\n",
      "Train Epoch: 705 [49152/54000 (91%)] Loss: -1565.494385\n",
      "Train Epoch: 705 [53248/54000 (99%)] Loss: -1571.647583\n",
      "    epoch          : 705\n",
      "    loss           : -1571.1565554650474\n",
      "    ess            : 3.7927590309161148\n",
      "    log_marginal   : 1571.2856248611522\n",
      "    val_loss       : -1570.6072845458984\n",
      "    val_ess        : 3.7950317362944284\n",
      "    val_log_marginal: 1570.7324625651042\n",
      "Train Epoch: 706 [0/54000 (0%)] Loss: -1564.402954\n",
      "Train Epoch: 706 [4096/54000 (8%)] Loss: -1568.041016\n",
      "Train Epoch: 706 [8192/54000 (15%)] Loss: -1571.500732\n",
      "Train Epoch: 706 [12288/54000 (23%)] Loss: -1567.370850\n",
      "Train Epoch: 706 [16384/54000 (30%)] Loss: -1578.109741\n",
      "Train Epoch: 706 [20480/54000 (38%)] Loss: -1571.630371\n",
      "Train Epoch: 706 [24576/54000 (46%)] Loss: -1572.240601\n",
      "Train Epoch: 706 [28672/54000 (53%)] Loss: -1573.148438\n",
      "Train Epoch: 706 [32768/54000 (61%)] Loss: -1570.491211\n",
      "Train Epoch: 706 [36864/54000 (68%)] Loss: -1569.683838\n",
      "Train Epoch: 706 [40960/54000 (76%)] Loss: -1576.057861\n",
      "Train Epoch: 706 [45056/54000 (83%)] Loss: -1567.453735\n",
      "Train Epoch: 706 [49152/54000 (91%)] Loss: -1572.276123\n",
      "Train Epoch: 706 [53248/54000 (99%)] Loss: -1567.349365\n",
      "    epoch          : 706\n",
      "    loss           : -1571.2746934935944\n",
      "    ess            : 3.7923049892859435\n",
      "    log_marginal   : 1571.4019729108043\n",
      "    val_loss       : -1570.7666880289714\n",
      "    val_ess        : 3.7924391428629556\n",
      "    val_log_marginal: 1570.9066975911458\n",
      "Train Epoch: 707 [0/54000 (0%)] Loss: -1571.194702\n",
      "Train Epoch: 707 [4096/54000 (8%)] Loss: -1570.394043\n",
      "Train Epoch: 707 [8192/54000 (15%)] Loss: -1569.140015\n",
      "Train Epoch: 707 [12288/54000 (23%)] Loss: -1569.719116\n",
      "Train Epoch: 707 [16384/54000 (30%)] Loss: -1571.709229\n",
      "Train Epoch: 707 [20480/54000 (38%)] Loss: -1571.001221\n",
      "Train Epoch: 707 [24576/54000 (46%)] Loss: -1577.388062\n",
      "Train Epoch: 707 [28672/54000 (53%)] Loss: -1570.717529\n",
      "Train Epoch: 707 [32768/54000 (61%)] Loss: -1577.486084\n",
      "Train Epoch: 707 [36864/54000 (68%)] Loss: -1572.925781\n",
      "Train Epoch: 707 [40960/54000 (76%)] Loss: -1570.097656\n",
      "Train Epoch: 707 [45056/54000 (83%)] Loss: -1568.470459\n",
      "Train Epoch: 707 [49152/54000 (91%)] Loss: -1576.344727\n",
      "Train Epoch: 707 [53248/54000 (99%)] Loss: -1577.677246\n",
      "    epoch          : 707\n",
      "    loss           : -1571.3023548578199\n",
      "    ess            : 3.7916860919428097\n",
      "    log_marginal   : 1571.432927859338\n",
      "    val_loss       : -1570.5460459391277\n",
      "    val_ess        : 3.805679827928543\n",
      "    val_log_marginal: 1570.6616872151692\n",
      "Train Epoch: 708 [0/54000 (0%)] Loss: -1575.220581\n",
      "Train Epoch: 708 [4096/54000 (8%)] Loss: -1570.065552\n",
      "Train Epoch: 708 [8192/54000 (15%)] Loss: -1577.110352\n",
      "Train Epoch: 708 [12288/54000 (23%)] Loss: -1571.588135\n",
      "Train Epoch: 708 [16384/54000 (30%)] Loss: -1571.040894\n",
      "Train Epoch: 708 [20480/54000 (38%)] Loss: -1571.014771\n",
      "Train Epoch: 708 [24576/54000 (46%)] Loss: -1571.223877\n",
      "Train Epoch: 708 [28672/54000 (53%)] Loss: -1566.546387\n",
      "Train Epoch: 708 [32768/54000 (61%)] Loss: -1573.349731\n",
      "Train Epoch: 708 [36864/54000 (68%)] Loss: -1575.380859\n",
      "Train Epoch: 708 [40960/54000 (76%)] Loss: -1568.537109\n",
      "Train Epoch: 708 [45056/54000 (83%)] Loss: -1564.737793\n",
      "Train Epoch: 708 [49152/54000 (91%)] Loss: -1567.862061\n",
      "Train Epoch: 708 [53248/54000 (99%)] Loss: -1569.061279\n",
      "    epoch          : 708\n",
      "    loss           : -1572.2235309908176\n",
      "    ess            : 3.8007302363336932\n",
      "    log_marginal   : 1572.3476649279844\n",
      "    val_loss       : -1571.928955078125\n",
      "    val_ess        : 3.8188287019729614\n",
      "    val_log_marginal: 1572.0367075602214\n",
      "Train Epoch: 709 [0/54000 (0%)] Loss: -1577.006592\n",
      "Train Epoch: 709 [4096/54000 (8%)] Loss: -1574.101562\n",
      "Train Epoch: 709 [8192/54000 (15%)] Loss: -1578.715210\n",
      "Train Epoch: 709 [12288/54000 (23%)] Loss: -1572.214844\n",
      "Train Epoch: 709 [16384/54000 (30%)] Loss: -1569.356079\n",
      "Train Epoch: 709 [20480/54000 (38%)] Loss: -1574.053955\n",
      "Train Epoch: 709 [24576/54000 (46%)] Loss: -1574.590454\n",
      "Train Epoch: 709 [28672/54000 (53%)] Loss: -1579.411133\n",
      "Train Epoch: 709 [32768/54000 (61%)] Loss: -1572.643921\n",
      "Train Epoch: 709 [36864/54000 (68%)] Loss: -1567.583252\n",
      "Train Epoch: 709 [40960/54000 (76%)] Loss: -1578.350342\n",
      "Train Epoch: 709 [45056/54000 (83%)] Loss: -1570.033203\n",
      "Train Epoch: 709 [49152/54000 (91%)] Loss: -1576.660889\n",
      "Train Epoch: 709 [53248/54000 (99%)] Loss: -1578.248169\n",
      "    epoch          : 709\n",
      "    loss           : -1573.198333017069\n",
      "    ess            : 3.7972954799778655\n",
      "    log_marginal   : 1573.3254504452384\n",
      "    val_loss       : -1573.375996907552\n",
      "    val_ess        : 3.794592668612798\n",
      "    val_log_marginal: 1573.5006408691406\n",
      "Train Epoch: 710 [0/54000 (0%)] Loss: -1568.773682\n",
      "Train Epoch: 710 [4096/54000 (8%)] Loss: -1571.063477\n",
      "Train Epoch: 710 [8192/54000 (15%)] Loss: -1574.771973\n",
      "Train Epoch: 710 [12288/54000 (23%)] Loss: -1571.466919\n",
      "Train Epoch: 710 [16384/54000 (30%)] Loss: -1573.359863\n",
      "Train Epoch: 710 [20480/54000 (38%)] Loss: -1575.430664\n",
      "Train Epoch: 710 [24576/54000 (46%)] Loss: -1572.105591\n",
      "Train Epoch: 710 [28672/54000 (53%)] Loss: -1568.005371\n",
      "Train Epoch: 710 [32768/54000 (61%)] Loss: -1580.480835\n",
      "Train Epoch: 710 [36864/54000 (68%)] Loss: -1577.333008\n",
      "Train Epoch: 710 [40960/54000 (76%)] Loss: -1575.250488\n",
      "Train Epoch: 710 [45056/54000 (83%)] Loss: -1580.027222\n",
      "Train Epoch: 710 [49152/54000 (91%)] Loss: -1576.036987\n",
      "Train Epoch: 710 [53248/54000 (99%)] Loss: -1579.575806\n",
      "    epoch          : 710\n",
      "    loss           : -1573.9070923430095\n",
      "    ess            : 3.7979310643616446\n",
      "    log_marginal   : 1574.0322479681945\n",
      "    val_loss       : -1573.3712819417317\n",
      "    val_ess        : 3.8009286721547446\n",
      "    val_log_marginal: 1573.4867757161458\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch710.pth ...\n",
      "Train Epoch: 711 [0/54000 (0%)] Loss: -1581.866455\n",
      "Train Epoch: 711 [4096/54000 (8%)] Loss: -1573.867920\n",
      "Train Epoch: 711 [8192/54000 (15%)] Loss: -1567.379150\n",
      "Train Epoch: 711 [12288/54000 (23%)] Loss: -1575.836792\n",
      "Train Epoch: 711 [16384/54000 (30%)] Loss: -1570.718750\n",
      "Train Epoch: 711 [20480/54000 (38%)] Loss: -1577.354980\n",
      "Train Epoch: 711 [24576/54000 (46%)] Loss: -1576.652222\n",
      "Train Epoch: 711 [28672/54000 (53%)] Loss: -1568.799194\n",
      "Train Epoch: 711 [32768/54000 (61%)] Loss: -1570.549316\n",
      "Train Epoch: 711 [36864/54000 (68%)] Loss: -1573.323730\n",
      "Train Epoch: 711 [40960/54000 (76%)] Loss: -1573.975830\n",
      "Train Epoch: 711 [45056/54000 (83%)] Loss: -1570.452393\n",
      "Train Epoch: 711 [49152/54000 (91%)] Loss: -1575.988037\n",
      "Train Epoch: 711 [53248/54000 (99%)] Loss: -1570.662109\n",
      "    epoch          : 711\n",
      "    loss           : -1573.946880322497\n",
      "    ess            : 3.794402634363039\n",
      "    log_marginal   : 1574.071131701718\n",
      "    val_loss       : -1574.4535878499348\n",
      "    val_ess        : 3.797433525323868\n",
      "    val_log_marginal: 1574.5674133300781\n",
      "Train Epoch: 712 [0/54000 (0%)] Loss: -1574.351807\n",
      "Train Epoch: 712 [4096/54000 (8%)] Loss: -1574.507568\n",
      "Train Epoch: 712 [8192/54000 (15%)] Loss: -1575.175781\n",
      "Train Epoch: 712 [12288/54000 (23%)] Loss: -1574.596436\n",
      "Train Epoch: 712 [16384/54000 (30%)] Loss: -1574.929688\n",
      "Train Epoch: 712 [20480/54000 (38%)] Loss: -1577.801025\n",
      "Train Epoch: 712 [24576/54000 (46%)] Loss: -1566.206055\n",
      "Train Epoch: 712 [28672/54000 (53%)] Loss: -1576.510864\n",
      "Train Epoch: 712 [32768/54000 (61%)] Loss: -1575.099976\n",
      "Train Epoch: 712 [36864/54000 (68%)] Loss: -1573.206055\n",
      "Train Epoch: 712 [40960/54000 (76%)] Loss: -1574.224609\n",
      "Train Epoch: 712 [45056/54000 (83%)] Loss: -1570.967529\n",
      "Train Epoch: 712 [49152/54000 (91%)] Loss: -1568.973511\n",
      "Train Epoch: 712 [53248/54000 (99%)] Loss: -1579.434814\n",
      "    epoch          : 712\n",
      "    loss           : -1574.3920910008146\n",
      "    ess            : 3.7928120683154787\n",
      "    log_marginal   : 1574.5226697876556\n",
      "    val_loss       : -1575.0187225341797\n",
      "    val_ess        : 3.779023677110672\n",
      "    val_log_marginal: 1575.1556752522786\n",
      "Train Epoch: 713 [0/54000 (0%)] Loss: -1577.398438\n",
      "Train Epoch: 713 [4096/54000 (8%)] Loss: -1570.162476\n",
      "Train Epoch: 713 [8192/54000 (15%)] Loss: -1572.099854\n",
      "Train Epoch: 713 [12288/54000 (23%)] Loss: -1571.820312\n",
      "Train Epoch: 713 [16384/54000 (30%)] Loss: -1579.527344\n",
      "Train Epoch: 713 [20480/54000 (38%)] Loss: -1572.842285\n",
      "Train Epoch: 713 [24576/54000 (46%)] Loss: -1574.324219\n",
      "Train Epoch: 713 [28672/54000 (53%)] Loss: -1573.212158\n",
      "Train Epoch: 713 [32768/54000 (61%)] Loss: -1572.545898\n",
      "Train Epoch: 713 [36864/54000 (68%)] Loss: -1571.705078\n",
      "Train Epoch: 713 [40960/54000 (76%)] Loss: -1573.418213\n",
      "Train Epoch: 713 [45056/54000 (83%)] Loss: -1576.590088\n",
      "Train Epoch: 713 [49152/54000 (91%)] Loss: -1577.262207\n",
      "Train Epoch: 713 [53248/54000 (99%)] Loss: -1579.543701\n",
      "    epoch          : 713\n",
      "    loss           : -1574.424274173393\n",
      "    ess            : 3.792052771807847\n",
      "    log_marginal   : 1574.5501546995336\n",
      "    val_loss       : -1575.4248758951824\n",
      "    val_ess        : 3.8005490005016327\n",
      "    val_log_marginal: 1575.5544993082683\n",
      "Train Epoch: 714 [0/54000 (0%)] Loss: -1571.795410\n",
      "Train Epoch: 714 [4096/54000 (8%)] Loss: -1575.017212\n",
      "Train Epoch: 714 [8192/54000 (15%)] Loss: -1574.361450\n",
      "Train Epoch: 714 [12288/54000 (23%)] Loss: -1575.169922\n",
      "Train Epoch: 714 [16384/54000 (30%)] Loss: -1572.905273\n",
      "Train Epoch: 714 [20480/54000 (38%)] Loss: -1572.884033\n",
      "Train Epoch: 714 [24576/54000 (46%)] Loss: -1575.057739\n",
      "Train Epoch: 714 [28672/54000 (53%)] Loss: -1567.834229\n",
      "Train Epoch: 714 [32768/54000 (61%)] Loss: -1573.770996\n",
      "Train Epoch: 714 [36864/54000 (68%)] Loss: -1576.455200\n",
      "Train Epoch: 714 [40960/54000 (76%)] Loss: -1573.712036\n",
      "Train Epoch: 714 [45056/54000 (83%)] Loss: -1576.528564\n",
      "Train Epoch: 714 [49152/54000 (91%)] Loss: -1569.576660\n",
      "Train Epoch: 714 [53248/54000 (99%)] Loss: -1577.063843\n",
      "    epoch          : 714\n",
      "    loss           : -1574.7707704661582\n",
      "    ess            : 3.793177402414982\n",
      "    log_marginal   : 1574.8992144688611\n",
      "    val_loss       : -1575.0032806396484\n",
      "    val_ess        : 3.7968326012293496\n",
      "    val_log_marginal: 1575.124791463216\n",
      "Train Epoch: 715 [0/54000 (0%)] Loss: -1574.024414\n",
      "Train Epoch: 715 [4096/54000 (8%)] Loss: -1568.991699\n",
      "Train Epoch: 715 [8192/54000 (15%)] Loss: -1581.802979\n",
      "Train Epoch: 715 [12288/54000 (23%)] Loss: -1577.628540\n",
      "Train Epoch: 715 [16384/54000 (30%)] Loss: -1579.008789\n",
      "Train Epoch: 715 [20480/54000 (38%)] Loss: -1575.793213\n",
      "Train Epoch: 715 [24576/54000 (46%)] Loss: -1578.324219\n",
      "Train Epoch: 715 [28672/54000 (53%)] Loss: -1572.715332\n",
      "Train Epoch: 715 [32768/54000 (61%)] Loss: -1580.648682\n",
      "Train Epoch: 715 [36864/54000 (68%)] Loss: -1572.444702\n",
      "Train Epoch: 715 [40960/54000 (76%)] Loss: -1573.547363\n",
      "Train Epoch: 715 [45056/54000 (83%)] Loss: -1568.853027\n",
      "Train Epoch: 715 [49152/54000 (91%)] Loss: -1580.119385\n",
      "Train Epoch: 715 [53248/54000 (99%)] Loss: -1579.697510\n",
      "    epoch          : 715\n",
      "    loss           : -1575.2978440415802\n",
      "    ess            : 3.7944722842266208\n",
      "    log_marginal   : 1575.4230870251406\n",
      "    val_loss       : -1575.5322774251301\n",
      "    val_ess        : 3.8110453685124717\n",
      "    val_log_marginal: 1575.6491190592449\n",
      "Train Epoch: 716 [0/54000 (0%)] Loss: -1571.886475\n",
      "Train Epoch: 716 [4096/54000 (8%)] Loss: -1578.810547\n",
      "Train Epoch: 716 [8192/54000 (15%)] Loss: -1573.254150\n",
      "Train Epoch: 716 [12288/54000 (23%)] Loss: -1576.291748\n",
      "Train Epoch: 716 [16384/54000 (30%)] Loss: -1573.432251\n",
      "Train Epoch: 716 [20480/54000 (38%)] Loss: -1576.985840\n",
      "Train Epoch: 716 [24576/54000 (46%)] Loss: -1572.220703\n",
      "Train Epoch: 716 [28672/54000 (53%)] Loss: -1571.632690\n",
      "Train Epoch: 716 [32768/54000 (61%)] Loss: -1578.759033\n",
      "Train Epoch: 716 [36864/54000 (68%)] Loss: -1576.778809\n",
      "Train Epoch: 716 [40960/54000 (76%)] Loss: -1573.426514\n",
      "Train Epoch: 716 [45056/54000 (83%)] Loss: -1574.753906\n",
      "Train Epoch: 716 [49152/54000 (91%)] Loss: -1583.293213\n",
      "Train Epoch: 716 [53248/54000 (99%)] Loss: -1576.675415\n",
      "    epoch          : 716\n",
      "    loss           : -1574.9858334798948\n",
      "    ess            : 3.79551311804785\n",
      "    log_marginal   : 1575.1125031240742\n",
      "    val_loss       : -1575.0091908772786\n",
      "    val_ess        : 3.787524571021398\n",
      "    val_log_marginal: 1575.1404571533203\n",
      "Train Epoch: 717 [0/54000 (0%)] Loss: -1571.188354\n",
      "Train Epoch: 717 [4096/54000 (8%)] Loss: -1575.070557\n",
      "Train Epoch: 717 [8192/54000 (15%)] Loss: -1578.944946\n",
      "Train Epoch: 717 [12288/54000 (23%)] Loss: -1577.920898\n",
      "Train Epoch: 717 [16384/54000 (30%)] Loss: -1574.747070\n",
      "Train Epoch: 717 [20480/54000 (38%)] Loss: -1573.734619\n",
      "Train Epoch: 717 [24576/54000 (46%)] Loss: -1577.724854\n",
      "Train Epoch: 717 [28672/54000 (53%)] Loss: -1579.657959\n",
      "Train Epoch: 717 [32768/54000 (61%)] Loss: -1568.139404\n",
      "Train Epoch: 717 [36864/54000 (68%)] Loss: -1575.804565\n",
      "Train Epoch: 717 [40960/54000 (76%)] Loss: -1575.983643\n",
      "Train Epoch: 717 [45056/54000 (83%)] Loss: -1570.219849\n",
      "Train Epoch: 717 [49152/54000 (91%)] Loss: -1567.836060\n",
      "Train Epoch: 717 [53248/54000 (99%)] Loss: -1575.722290\n",
      "    epoch          : 717\n",
      "    loss           : -1575.17854142754\n",
      "    ess            : 3.7933228061097495\n",
      "    log_marginal   : 1575.3061425087012\n",
      "    val_loss       : -1574.3036549886067\n",
      "    val_ess        : 3.8068596025307975\n",
      "    val_log_marginal: 1574.4201405843098\n",
      "Train Epoch: 718 [0/54000 (0%)] Loss: -1568.936768\n",
      "Train Epoch: 718 [4096/54000 (8%)] Loss: -1575.147705\n",
      "Train Epoch: 718 [8192/54000 (15%)] Loss: -1574.861938\n",
      "Train Epoch: 718 [12288/54000 (23%)] Loss: -1576.012939\n",
      "Train Epoch: 718 [16384/54000 (30%)] Loss: -1576.669434\n",
      "Train Epoch: 718 [20480/54000 (38%)] Loss: -1577.515137\n",
      "Train Epoch: 718 [24576/54000 (46%)] Loss: -1582.429565\n",
      "Train Epoch: 718 [28672/54000 (53%)] Loss: -1571.753174\n",
      "Train Epoch: 718 [32768/54000 (61%)] Loss: -1573.940918\n",
      "Train Epoch: 718 [36864/54000 (68%)] Loss: -1577.699219\n",
      "Train Epoch: 718 [40960/54000 (76%)] Loss: -1578.531738\n",
      "Train Epoch: 718 [45056/54000 (83%)] Loss: -1578.961182\n",
      "Train Epoch: 718 [49152/54000 (91%)] Loss: -1574.534912\n",
      "Train Epoch: 718 [53248/54000 (99%)] Loss: -1574.109131\n",
      "    epoch          : 718\n",
      "    loss           : -1575.155906930354\n",
      "    ess            : 3.792450707105664\n",
      "    log_marginal   : 1575.2846124296505\n",
      "    val_loss       : -1575.6201070149739\n",
      "    val_ess        : 3.801651487747828\n",
      "    val_log_marginal: 1575.740249633789\n",
      "Train Epoch: 719 [0/54000 (0%)] Loss: -1577.824097\n",
      "Train Epoch: 719 [4096/54000 (8%)] Loss: -1577.784424\n",
      "Train Epoch: 719 [8192/54000 (15%)] Loss: -1578.345337\n",
      "Train Epoch: 719 [12288/54000 (23%)] Loss: -1571.739746\n",
      "Train Epoch: 719 [16384/54000 (30%)] Loss: -1581.871216\n",
      "Train Epoch: 719 [20480/54000 (38%)] Loss: -1573.853027\n",
      "Train Epoch: 719 [24576/54000 (46%)] Loss: -1567.535156\n",
      "Train Epoch: 719 [28672/54000 (53%)] Loss: -1575.483398\n",
      "Train Epoch: 719 [32768/54000 (61%)] Loss: -1576.481812\n",
      "Train Epoch: 719 [36864/54000 (68%)] Loss: -1568.536987\n",
      "Train Epoch: 719 [40960/54000 (76%)] Loss: -1573.611816\n",
      "Train Epoch: 719 [45056/54000 (83%)] Loss: -1573.832886\n",
      "Train Epoch: 719 [49152/54000 (91%)] Loss: -1579.455322\n",
      "Train Epoch: 719 [53248/54000 (99%)] Loss: -1566.676514\n",
      "    epoch          : 719\n",
      "    loss           : -1575.4240572237854\n",
      "    ess            : 3.796869531061977\n",
      "    log_marginal   : 1575.5514361485486\n",
      "    val_loss       : -1575.2220458984375\n",
      "    val_ess        : 3.792810082435608\n",
      "    val_log_marginal: 1575.3509928385417\n",
      "Train Epoch: 720 [0/54000 (0%)] Loss: -1581.987305\n",
      "Train Epoch: 720 [4096/54000 (8%)] Loss: -1575.959961\n",
      "Train Epoch: 720 [8192/54000 (15%)] Loss: -1580.446655\n",
      "Train Epoch: 720 [12288/54000 (23%)] Loss: -1568.747314\n",
      "Train Epoch: 720 [16384/54000 (30%)] Loss: -1576.977051\n",
      "Train Epoch: 720 [20480/54000 (38%)] Loss: -1574.885742\n",
      "Train Epoch: 720 [24576/54000 (46%)] Loss: -1579.967285\n",
      "Train Epoch: 720 [28672/54000 (53%)] Loss: -1574.219727\n",
      "Train Epoch: 720 [32768/54000 (61%)] Loss: -1575.661377\n",
      "Train Epoch: 720 [36864/54000 (68%)] Loss: -1572.427734\n",
      "Train Epoch: 720 [40960/54000 (76%)] Loss: -1578.240967\n",
      "Train Epoch: 720 [45056/54000 (83%)] Loss: -1577.095947\n",
      "Train Epoch: 720 [49152/54000 (91%)] Loss: -1570.968750\n",
      "Train Epoch: 720 [53248/54000 (99%)] Loss: -1574.542969\n",
      "    epoch          : 720\n",
      "    loss           : -1575.468272132331\n",
      "    ess            : 3.794030817764065\n",
      "    log_marginal   : 1575.5967277056798\n",
      "    val_loss       : -1574.9770812988281\n",
      "    val_ess        : 3.8121952017148337\n",
      "    val_log_marginal: 1575.0916341145833\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch720.pth ...\n",
      "Train Epoch: 721 [0/54000 (0%)] Loss: -1577.173096\n",
      "Train Epoch: 721 [4096/54000 (8%)] Loss: -1575.042114\n",
      "Train Epoch: 721 [8192/54000 (15%)] Loss: -1571.766602\n",
      "Train Epoch: 721 [12288/54000 (23%)] Loss: -1573.878784\n",
      "Train Epoch: 721 [16384/54000 (30%)] Loss: -1584.310425\n",
      "Train Epoch: 721 [20480/54000 (38%)] Loss: -1567.886230\n",
      "Train Epoch: 721 [24576/54000 (46%)] Loss: -1568.894531\n",
      "Train Epoch: 721 [28672/54000 (53%)] Loss: -1571.854248\n",
      "Train Epoch: 721 [32768/54000 (61%)] Loss: -1570.302612\n",
      "Train Epoch: 721 [36864/54000 (68%)] Loss: -1577.102783\n",
      "Train Epoch: 721 [40960/54000 (76%)] Loss: -1577.341797\n",
      "Train Epoch: 721 [45056/54000 (83%)] Loss: -1570.870361\n",
      "Train Epoch: 721 [49152/54000 (91%)] Loss: -1575.146484\n",
      "Train Epoch: 721 [53248/54000 (99%)] Loss: -1576.469482\n",
      "    epoch          : 721\n",
      "    loss           : -1575.6202728126852\n",
      "    ess            : 3.797053123537398\n",
      "    log_marginal   : 1575.7456401806871\n",
      "    val_loss       : -1575.2421417236328\n",
      "    val_ess        : 3.790236324071884\n",
      "    val_log_marginal: 1575.3684997558594\n",
      "Train Epoch: 722 [0/54000 (0%)] Loss: -1573.330811\n",
      "Train Epoch: 722 [4096/54000 (8%)] Loss: -1578.397705\n",
      "Train Epoch: 722 [8192/54000 (15%)] Loss: -1575.045410\n",
      "Train Epoch: 722 [12288/54000 (23%)] Loss: -1580.280029\n",
      "Train Epoch: 722 [16384/54000 (30%)] Loss: -1572.741943\n",
      "Train Epoch: 722 [20480/54000 (38%)] Loss: -1569.768555\n",
      "Train Epoch: 722 [24576/54000 (46%)] Loss: -1586.978271\n",
      "Train Epoch: 722 [28672/54000 (53%)] Loss: -1571.448975\n",
      "Train Epoch: 722 [32768/54000 (61%)] Loss: -1578.498169\n",
      "Train Epoch: 722 [36864/54000 (68%)] Loss: -1579.847168\n",
      "Train Epoch: 722 [40960/54000 (76%)] Loss: -1578.267090\n",
      "Train Epoch: 722 [45056/54000 (83%)] Loss: -1577.447876\n",
      "Train Epoch: 722 [49152/54000 (91%)] Loss: -1584.571533\n",
      "Train Epoch: 722 [53248/54000 (99%)] Loss: -1578.500000\n",
      "    epoch          : 722\n",
      "    loss           : -1575.7485785461715\n",
      "    ess            : 3.7951676608261904\n",
      "    log_marginal   : 1575.8732887014958\n",
      "    val_loss       : -1575.8659159342449\n",
      "    val_ess        : 3.8029772341251373\n",
      "    val_log_marginal: 1575.9977773030598\n",
      "Train Epoch: 723 [0/54000 (0%)] Loss: -1583.004883\n",
      "Train Epoch: 723 [4096/54000 (8%)] Loss: -1576.934204\n",
      "Train Epoch: 723 [8192/54000 (15%)] Loss: -1574.165405\n",
      "Train Epoch: 723 [12288/54000 (23%)] Loss: -1577.249512\n",
      "Train Epoch: 723 [16384/54000 (30%)] Loss: -1575.088257\n",
      "Train Epoch: 723 [20480/54000 (38%)] Loss: -1577.069702\n",
      "Train Epoch: 723 [24576/54000 (46%)] Loss: -1579.181763\n",
      "Train Epoch: 723 [28672/54000 (53%)] Loss: -1578.896118\n",
      "Train Epoch: 723 [32768/54000 (61%)] Loss: -1573.154053\n",
      "Train Epoch: 723 [36864/54000 (68%)] Loss: -1572.604980\n",
      "Train Epoch: 723 [40960/54000 (76%)] Loss: -1577.083252\n",
      "Train Epoch: 723 [45056/54000 (83%)] Loss: -1575.671509\n",
      "Train Epoch: 723 [49152/54000 (91%)] Loss: -1568.779663\n",
      "Train Epoch: 723 [53248/54000 (99%)] Loss: -1573.582153\n",
      "    epoch          : 723\n",
      "    loss           : -1575.84351974415\n",
      "    ess            : 3.798966795347313\n",
      "    log_marginal   : 1575.9638671875\n",
      "    val_loss       : -1576.3233133951824\n",
      "    val_ess        : 3.799506147702535\n",
      "    val_log_marginal: 1576.4488881429036\n",
      "Train Epoch: 724 [0/54000 (0%)] Loss: -1579.735596\n",
      "Train Epoch: 724 [4096/54000 (8%)] Loss: -1575.474609\n",
      "Train Epoch: 724 [8192/54000 (15%)] Loss: -1573.286255\n",
      "Train Epoch: 724 [12288/54000 (23%)] Loss: -1569.800537\n",
      "Train Epoch: 724 [16384/54000 (30%)] Loss: -1572.875488\n",
      "Train Epoch: 724 [20480/54000 (38%)] Loss: -1575.093384\n",
      "Train Epoch: 724 [24576/54000 (46%)] Loss: -1577.364014\n",
      "Train Epoch: 724 [28672/54000 (53%)] Loss: -1572.415283\n",
      "Train Epoch: 724 [32768/54000 (61%)] Loss: -1577.541016\n",
      "Train Epoch: 724 [36864/54000 (68%)] Loss: -1572.094482\n",
      "Train Epoch: 724 [40960/54000 (76%)] Loss: -1576.416504\n",
      "Train Epoch: 724 [45056/54000 (83%)] Loss: -1575.169922\n",
      "Train Epoch: 724 [49152/54000 (91%)] Loss: -1576.604492\n",
      "Train Epoch: 724 [53248/54000 (99%)] Loss: -1576.788086\n",
      "    epoch          : 724\n",
      "    loss           : -1576.0245135700534\n",
      "    ess            : 3.7960615169380514\n",
      "    log_marginal   : 1576.149744982968\n",
      "    val_loss       : -1575.8013254801433\n",
      "    val_ess        : 3.7898492415746055\n",
      "    val_log_marginal: 1575.9277903238933\n",
      "Train Epoch: 725 [0/54000 (0%)] Loss: -1573.607788\n",
      "Train Epoch: 725 [4096/54000 (8%)] Loss: -1573.432129\n",
      "Train Epoch: 725 [8192/54000 (15%)] Loss: -1570.675049\n",
      "Train Epoch: 725 [12288/54000 (23%)] Loss: -1577.505493\n",
      "Train Epoch: 725 [16384/54000 (30%)] Loss: -1571.401733\n",
      "Train Epoch: 725 [20480/54000 (38%)] Loss: -1571.180908\n",
      "Train Epoch: 725 [24576/54000 (46%)] Loss: -1576.253662\n",
      "Train Epoch: 725 [28672/54000 (53%)] Loss: -1580.141724\n",
      "Train Epoch: 725 [32768/54000 (61%)] Loss: -1574.549194\n",
      "Train Epoch: 725 [36864/54000 (68%)] Loss: -1574.517578\n",
      "Train Epoch: 725 [40960/54000 (76%)] Loss: -1572.950195\n",
      "Train Epoch: 725 [45056/54000 (83%)] Loss: -1574.322266\n",
      "Train Epoch: 725 [49152/54000 (91%)] Loss: -1582.389893\n",
      "Train Epoch: 725 [53248/54000 (99%)] Loss: -1575.784912\n",
      "    epoch          : 725\n",
      "    loss           : -1575.9553957392254\n",
      "    ess            : 3.792380266279971\n",
      "    log_marginal   : 1576.0862371797245\n",
      "    val_loss       : -1575.6793823242188\n",
      "    val_ess        : 3.8017471631368003\n",
      "    val_log_marginal: 1575.789545694987\n",
      "Train Epoch: 726 [0/54000 (0%)] Loss: -1576.545654\n",
      "Train Epoch: 726 [4096/54000 (8%)] Loss: -1575.420288\n",
      "Train Epoch: 726 [8192/54000 (15%)] Loss: -1574.243530\n",
      "Train Epoch: 726 [12288/54000 (23%)] Loss: -1575.316162\n",
      "Train Epoch: 726 [16384/54000 (30%)] Loss: -1576.608398\n",
      "Train Epoch: 726 [20480/54000 (38%)] Loss: -1573.653931\n",
      "Train Epoch: 726 [24576/54000 (46%)] Loss: -1580.975586\n",
      "Train Epoch: 726 [28672/54000 (53%)] Loss: -1581.928711\n",
      "Train Epoch: 726 [32768/54000 (61%)] Loss: -1580.863892\n",
      "Train Epoch: 726 [36864/54000 (68%)] Loss: -1573.807983\n",
      "Train Epoch: 726 [40960/54000 (76%)] Loss: -1579.500977\n",
      "Train Epoch: 726 [45056/54000 (83%)] Loss: -1572.755981\n",
      "Train Epoch: 726 [49152/54000 (91%)] Loss: -1574.048828\n",
      "Train Epoch: 726 [53248/54000 (99%)] Loss: -1574.628052\n",
      "    epoch          : 726\n",
      "    loss           : -1576.129023113522\n",
      "    ess            : 3.801849480488854\n",
      "    log_marginal   : 1576.2520225488745\n",
      "    val_loss       : -1575.439956665039\n",
      "    val_ess        : 3.7908684511979422\n",
      "    val_log_marginal: 1575.5671793619792\n",
      "Train Epoch: 727 [0/54000 (0%)] Loss: -1571.315552\n",
      "Train Epoch: 727 [4096/54000 (8%)] Loss: -1574.875000\n",
      "Train Epoch: 727 [8192/54000 (15%)] Loss: -1574.137451\n",
      "Train Epoch: 727 [12288/54000 (23%)] Loss: -1577.990723\n",
      "Train Epoch: 727 [16384/54000 (30%)] Loss: -1576.992432\n",
      "Train Epoch: 727 [20480/54000 (38%)] Loss: -1578.585693\n",
      "Train Epoch: 727 [24576/54000 (46%)] Loss: -1581.940430\n",
      "Train Epoch: 727 [28672/54000 (53%)] Loss: -1571.676025\n",
      "Train Epoch: 727 [32768/54000 (61%)] Loss: -1581.293701\n",
      "Train Epoch: 727 [36864/54000 (68%)] Loss: -1573.821289\n",
      "Train Epoch: 727 [40960/54000 (76%)] Loss: -1576.594727\n",
      "Train Epoch: 727 [45056/54000 (83%)] Loss: -1578.418457\n",
      "Train Epoch: 727 [49152/54000 (91%)] Loss: -1579.671631\n",
      "Train Epoch: 727 [53248/54000 (99%)] Loss: -1583.391968\n",
      "    epoch          : 727\n",
      "    loss           : -1576.2087552762146\n",
      "    ess            : 3.792308407372208\n",
      "    log_marginal   : 1576.337916658953\n",
      "    val_loss       : -1576.183314005534\n",
      "    val_ess        : 3.7984966238339744\n",
      "    val_log_marginal: 1576.3098551432292\n",
      "Train Epoch: 728 [0/54000 (0%)] Loss: -1576.990601\n",
      "Train Epoch: 728 [4096/54000 (8%)] Loss: -1573.903076\n",
      "Train Epoch: 728 [8192/54000 (15%)] Loss: -1576.221436\n",
      "Train Epoch: 728 [12288/54000 (23%)] Loss: -1572.537476\n",
      "Train Epoch: 728 [16384/54000 (30%)] Loss: -1580.217163\n",
      "Train Epoch: 728 [20480/54000 (38%)] Loss: -1581.247803\n",
      "Train Epoch: 728 [24576/54000 (46%)] Loss: -1573.005737\n",
      "Train Epoch: 728 [28672/54000 (53%)] Loss: -1576.549194\n",
      "Train Epoch: 728 [32768/54000 (61%)] Loss: -1579.926636\n",
      "Train Epoch: 728 [36864/54000 (68%)] Loss: -1576.021484\n",
      "Train Epoch: 728 [40960/54000 (76%)] Loss: -1574.950317\n",
      "Train Epoch: 728 [45056/54000 (83%)] Loss: -1570.696045\n",
      "Train Epoch: 728 [49152/54000 (91%)] Loss: -1576.602051\n",
      "Train Epoch: 728 [53248/54000 (99%)] Loss: -1566.364258\n",
      "    epoch          : 728\n",
      "    loss           : -1576.2934246334419\n",
      "    ess            : 3.7968582282134142\n",
      "    log_marginal   : 1576.4178327949126\n",
      "    val_loss       : -1577.0682932535808\n",
      "    val_ess        : 3.7965327401955924\n",
      "    val_log_marginal: 1577.193094889323\n",
      "Train Epoch: 729 [0/54000 (0%)] Loss: -1579.229980\n",
      "Train Epoch: 729 [4096/54000 (8%)] Loss: -1575.215332\n",
      "Train Epoch: 729 [8192/54000 (15%)] Loss: -1582.049316\n",
      "Train Epoch: 729 [12288/54000 (23%)] Loss: -1579.020630\n",
      "Train Epoch: 729 [16384/54000 (30%)] Loss: -1573.462646\n",
      "Train Epoch: 729 [20480/54000 (38%)] Loss: -1577.358398\n",
      "Train Epoch: 729 [24576/54000 (46%)] Loss: -1579.926025\n",
      "Train Epoch: 729 [28672/54000 (53%)] Loss: -1579.217285\n",
      "Train Epoch: 729 [32768/54000 (61%)] Loss: -1582.940186\n",
      "Train Epoch: 729 [36864/54000 (68%)] Loss: -1586.198608\n",
      "Train Epoch: 729 [40960/54000 (76%)] Loss: -1579.028076\n",
      "Train Epoch: 729 [45056/54000 (83%)] Loss: -1579.551392\n",
      "Train Epoch: 729 [49152/54000 (91%)] Loss: -1571.425049\n",
      "Train Epoch: 729 [53248/54000 (99%)] Loss: -1580.801270\n",
      "    epoch          : 729\n",
      "    loss           : -1576.4990205448385\n",
      "    ess            : 3.7961352662452588\n",
      "    log_marginal   : 1576.6188380526141\n",
      "    val_loss       : -1576.2169392903645\n",
      "    val_ess        : 3.808639337619146\n",
      "    val_log_marginal: 1576.3333384195964\n",
      "Train Epoch: 730 [0/54000 (0%)] Loss: -1582.181885\n",
      "Train Epoch: 730 [4096/54000 (8%)] Loss: -1578.219360\n",
      "Train Epoch: 730 [8192/54000 (15%)] Loss: -1577.247681\n",
      "Train Epoch: 730 [12288/54000 (23%)] Loss: -1579.933105\n",
      "Train Epoch: 730 [16384/54000 (30%)] Loss: -1572.719238\n",
      "Train Epoch: 730 [20480/54000 (38%)] Loss: -1582.683105\n",
      "Train Epoch: 730 [24576/54000 (46%)] Loss: -1581.361816\n",
      "Train Epoch: 730 [28672/54000 (53%)] Loss: -1578.963257\n",
      "Train Epoch: 730 [32768/54000 (61%)] Loss: -1573.416382\n",
      "Train Epoch: 730 [36864/54000 (68%)] Loss: -1582.892334\n",
      "Train Epoch: 730 [40960/54000 (76%)] Loss: -1579.124023\n",
      "Train Epoch: 730 [45056/54000 (83%)] Loss: -1579.413574\n",
      "Train Epoch: 730 [49152/54000 (91%)] Loss: -1579.121094\n",
      "Train Epoch: 730 [53248/54000 (99%)] Loss: -1574.139160\n",
      "    epoch          : 730\n",
      "    loss           : -1576.4067417524436\n",
      "    ess            : 3.792167298601702\n",
      "    log_marginal   : 1576.5310990030732\n",
      "    val_loss       : -1576.6002705891926\n",
      "    val_ess        : 3.7885767122109733\n",
      "    val_log_marginal: 1576.7275797526042\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch730.pth ...\n",
      "Train Epoch: 731 [0/54000 (0%)] Loss: -1580.857178\n",
      "Train Epoch: 731 [4096/54000 (8%)] Loss: -1577.555420\n",
      "Train Epoch: 731 [8192/54000 (15%)] Loss: -1574.784668\n",
      "Train Epoch: 731 [12288/54000 (23%)] Loss: -1577.922363\n",
      "Train Epoch: 731 [16384/54000 (30%)] Loss: -1576.402832\n",
      "Train Epoch: 731 [20480/54000 (38%)] Loss: -1580.836304\n",
      "Train Epoch: 731 [24576/54000 (46%)] Loss: -1582.420532\n",
      "Train Epoch: 731 [28672/54000 (53%)] Loss: -1577.864014\n",
      "Train Epoch: 731 [32768/54000 (61%)] Loss: -1578.274536\n",
      "Train Epoch: 731 [36864/54000 (68%)] Loss: -1581.261353\n",
      "Train Epoch: 731 [40960/54000 (76%)] Loss: -1571.450684\n",
      "Train Epoch: 731 [45056/54000 (83%)] Loss: -1577.994995\n",
      "Train Epoch: 731 [49152/54000 (91%)] Loss: -1575.545410\n",
      "Train Epoch: 731 [53248/54000 (99%)] Loss: -1578.652100\n",
      "    epoch          : 731\n",
      "    loss           : -1576.3805961428095\n",
      "    ess            : 3.7933652886847185\n",
      "    log_marginal   : 1576.5066652704754\n",
      "    val_loss       : -1576.5432434082031\n",
      "    val_ess        : 3.7864608565966287\n",
      "    val_log_marginal: 1576.6663767496746\n",
      "Train Epoch: 732 [0/54000 (0%)] Loss: -1570.212646\n",
      "Train Epoch: 732 [4096/54000 (8%)] Loss: -1582.554565\n",
      "Train Epoch: 732 [8192/54000 (15%)] Loss: -1573.634277\n",
      "Train Epoch: 732 [12288/54000 (23%)] Loss: -1576.115234\n",
      "Train Epoch: 732 [16384/54000 (30%)] Loss: -1581.240723\n",
      "Train Epoch: 732 [20480/54000 (38%)] Loss: -1581.238037\n",
      "Train Epoch: 732 [24576/54000 (46%)] Loss: -1578.712769\n",
      "Train Epoch: 732 [28672/54000 (53%)] Loss: -1571.249023\n",
      "Train Epoch: 732 [32768/54000 (61%)] Loss: -1575.597412\n",
      "Train Epoch: 732 [36864/54000 (68%)] Loss: -1579.837402\n",
      "Train Epoch: 732 [40960/54000 (76%)] Loss: -1569.852295\n",
      "Train Epoch: 732 [45056/54000 (83%)] Loss: -1584.041992\n",
      "Train Epoch: 732 [49152/54000 (91%)] Loss: -1574.342041\n",
      "Train Epoch: 732 [53248/54000 (99%)] Loss: -1580.772949\n",
      "    epoch          : 732\n",
      "    loss           : -1576.8098838769995\n",
      "    ess            : 3.792523740027188\n",
      "    log_marginal   : 1576.9353380248444\n",
      "    val_loss       : -1576.582987467448\n",
      "    val_ess        : 3.790423701206843\n",
      "    val_log_marginal: 1576.7099304199219\n",
      "Train Epoch: 733 [0/54000 (0%)] Loss: -1576.706909\n",
      "Train Epoch: 733 [4096/54000 (8%)] Loss: -1579.714722\n",
      "Train Epoch: 733 [8192/54000 (15%)] Loss: -1578.845825\n",
      "Train Epoch: 733 [12288/54000 (23%)] Loss: -1574.301025\n",
      "Train Epoch: 733 [16384/54000 (30%)] Loss: -1581.380615\n",
      "Train Epoch: 733 [20480/54000 (38%)] Loss: -1572.962280\n",
      "Train Epoch: 733 [24576/54000 (46%)] Loss: -1573.329834\n",
      "Train Epoch: 733 [28672/54000 (53%)] Loss: -1577.023193\n",
      "Train Epoch: 733 [32768/54000 (61%)] Loss: -1580.523926\n",
      "Train Epoch: 733 [36864/54000 (68%)] Loss: -1577.974854\n",
      "Train Epoch: 733 [40960/54000 (76%)] Loss: -1574.336670\n",
      "Train Epoch: 733 [45056/54000 (83%)] Loss: -1570.470703\n",
      "Train Epoch: 733 [49152/54000 (91%)] Loss: -1574.395386\n",
      "Train Epoch: 733 [53248/54000 (99%)] Loss: -1576.803223\n",
      "    epoch          : 733\n",
      "    loss           : -1576.7780622871\n",
      "    ess            : 3.7908201002961652\n",
      "    log_marginal   : 1576.9079641911655\n",
      "    val_loss       : -1576.5662180582683\n",
      "    val_ess        : 3.7926126619180045\n",
      "    val_log_marginal: 1576.6873067220051\n",
      "Train Epoch: 734 [0/54000 (0%)] Loss: -1572.033569\n",
      "Train Epoch: 734 [4096/54000 (8%)] Loss: -1572.171631\n",
      "Train Epoch: 734 [8192/54000 (15%)] Loss: -1569.456055\n",
      "Train Epoch: 734 [12288/54000 (23%)] Loss: -1581.998535\n",
      "Train Epoch: 734 [16384/54000 (30%)] Loss: -1572.956543\n",
      "Train Epoch: 734 [20480/54000 (38%)] Loss: -1570.085693\n",
      "Train Epoch: 734 [24576/54000 (46%)] Loss: -1575.727783\n",
      "Train Epoch: 734 [28672/54000 (53%)] Loss: -1578.016846\n",
      "Train Epoch: 734 [32768/54000 (61%)] Loss: -1576.807251\n",
      "Train Epoch: 734 [36864/54000 (68%)] Loss: -1569.864746\n",
      "Train Epoch: 734 [40960/54000 (76%)] Loss: -1576.826416\n",
      "Train Epoch: 734 [45056/54000 (83%)] Loss: -1575.523315\n",
      "Train Epoch: 734 [49152/54000 (91%)] Loss: -1574.840698\n",
      "Train Epoch: 734 [53248/54000 (99%)] Loss: -1583.398682\n",
      "    epoch          : 734\n",
      "    loss           : -1576.9592944683056\n",
      "    ess            : 3.793959306879631\n",
      "    log_marginal   : 1577.0840410711642\n",
      "    val_loss       : -1576.5591125488281\n",
      "    val_ess        : 3.7938538789749146\n",
      "    val_log_marginal: 1576.6849212646484\n",
      "Train Epoch: 735 [0/54000 (0%)] Loss: -1583.280029\n",
      "Train Epoch: 735 [4096/54000 (8%)] Loss: -1573.819580\n",
      "Train Epoch: 735 [8192/54000 (15%)] Loss: -1580.153564\n",
      "Train Epoch: 735 [12288/54000 (23%)] Loss: -1580.930908\n",
      "Train Epoch: 735 [16384/54000 (30%)] Loss: -1571.264893\n",
      "Train Epoch: 735 [20480/54000 (38%)] Loss: -1575.052124\n",
      "Train Epoch: 735 [24576/54000 (46%)] Loss: -1576.607422\n",
      "Train Epoch: 735 [28672/54000 (53%)] Loss: -1577.187744\n",
      "Train Epoch: 735 [32768/54000 (61%)] Loss: -1574.931641\n",
      "Train Epoch: 735 [36864/54000 (68%)] Loss: -1572.502197\n",
      "Train Epoch: 735 [40960/54000 (76%)] Loss: -1581.557251\n",
      "Train Epoch: 735 [45056/54000 (83%)] Loss: -1581.977661\n",
      "Train Epoch: 735 [49152/54000 (91%)] Loss: -1574.290039\n",
      "Train Epoch: 735 [53248/54000 (99%)] Loss: -1574.036133\n",
      "    epoch          : 735\n",
      "    loss           : -1577.0479244575681\n",
      "    ess            : 3.792737114485971\n",
      "    log_marginal   : 1577.1764292061612\n",
      "    val_loss       : -1577.4373168945312\n",
      "    val_ess        : 3.801972915728887\n",
      "    val_log_marginal: 1577.5629425048828\n",
      "Train Epoch: 736 [0/54000 (0%)] Loss: -1580.405273\n",
      "Train Epoch: 736 [4096/54000 (8%)] Loss: -1577.408569\n",
      "Train Epoch: 736 [8192/54000 (15%)] Loss: -1572.873169\n",
      "Train Epoch: 736 [12288/54000 (23%)] Loss: -1583.642822\n",
      "Train Epoch: 736 [16384/54000 (30%)] Loss: -1575.408691\n",
      "Train Epoch: 736 [20480/54000 (38%)] Loss: -1565.628174\n",
      "Train Epoch: 736 [24576/54000 (46%)] Loss: -1570.041016\n",
      "Train Epoch: 736 [28672/54000 (53%)] Loss: -1577.298706\n",
      "Train Epoch: 736 [32768/54000 (61%)] Loss: -1576.481201\n",
      "Train Epoch: 736 [36864/54000 (68%)] Loss: -1581.252686\n",
      "Train Epoch: 736 [40960/54000 (76%)] Loss: -1579.171875\n",
      "Train Epoch: 736 [45056/54000 (83%)] Loss: -1577.341797\n",
      "Train Epoch: 736 [49152/54000 (91%)] Loss: -1574.236084\n",
      "Train Epoch: 736 [53248/54000 (99%)] Loss: -1573.629028\n",
      "    epoch          : 736\n",
      "    loss           : -1577.0694950338789\n",
      "    ess            : 3.7908922541198007\n",
      "    log_marginal   : 1577.1965123759626\n",
      "    val_loss       : -1576.7936045328777\n",
      "    val_ess        : 3.7939400176207223\n",
      "    val_log_marginal: 1576.922083536784\n",
      "Train Epoch: 737 [0/54000 (0%)] Loss: -1576.133057\n",
      "Train Epoch: 737 [4096/54000 (8%)] Loss: -1571.930420\n",
      "Train Epoch: 737 [8192/54000 (15%)] Loss: -1581.394165\n",
      "Train Epoch: 737 [12288/54000 (23%)] Loss: -1575.515869\n",
      "Train Epoch: 737 [16384/54000 (30%)] Loss: -1574.259766\n",
      "Train Epoch: 737 [20480/54000 (38%)] Loss: -1578.532837\n",
      "Train Epoch: 737 [24576/54000 (46%)] Loss: -1580.558228\n",
      "Train Epoch: 737 [28672/54000 (53%)] Loss: -1580.337524\n",
      "Train Epoch: 737 [32768/54000 (61%)] Loss: -1575.572510\n",
      "Train Epoch: 737 [36864/54000 (68%)] Loss: -1578.848145\n",
      "Train Epoch: 737 [40960/54000 (76%)] Loss: -1572.987549\n",
      "Train Epoch: 737 [45056/54000 (83%)] Loss: -1576.045898\n",
      "Train Epoch: 737 [49152/54000 (91%)] Loss: -1580.260986\n",
      "Train Epoch: 737 [53248/54000 (99%)] Loss: -1570.609375\n",
      "    epoch          : 737\n",
      "    loss           : -1577.374009552725\n",
      "    ess            : 3.7932228138096526\n",
      "    log_marginal   : 1577.4996037053836\n",
      "    val_loss       : -1576.9493967692058\n",
      "    val_ess        : 3.7880218029022217\n",
      "    val_log_marginal: 1577.0762532552083\n",
      "Train Epoch: 738 [0/54000 (0%)] Loss: -1575.213623\n",
      "Train Epoch: 738 [4096/54000 (8%)] Loss: -1571.257080\n",
      "Train Epoch: 738 [8192/54000 (15%)] Loss: -1572.270996\n",
      "Train Epoch: 738 [12288/54000 (23%)] Loss: -1581.312012\n",
      "Train Epoch: 738 [16384/54000 (30%)] Loss: -1575.790771\n",
      "Train Epoch: 738 [20480/54000 (38%)] Loss: -1581.143555\n",
      "Train Epoch: 738 [24576/54000 (46%)] Loss: -1570.773926\n",
      "Train Epoch: 738 [28672/54000 (53%)] Loss: -1576.738892\n",
      "Train Epoch: 738 [32768/54000 (61%)] Loss: -1577.436035\n",
      "Train Epoch: 738 [36864/54000 (68%)] Loss: -1574.981201\n",
      "Train Epoch: 738 [40960/54000 (76%)] Loss: -1574.404785\n",
      "Train Epoch: 738 [45056/54000 (83%)] Loss: -1582.437256\n",
      "Train Epoch: 738 [49152/54000 (91%)] Loss: -1581.027466\n",
      "Train Epoch: 738 [53248/54000 (99%)] Loss: -1571.833618\n",
      "    epoch          : 738\n",
      "    loss           : -1577.4945652676984\n",
      "    ess            : 3.7964199109100054\n",
      "    log_marginal   : 1577.6222213094268\n",
      "    val_loss       : -1576.4803059895833\n",
      "    val_ess        : 3.7907313903172812\n",
      "    val_log_marginal: 1576.6078847249348\n",
      "Train Epoch: 739 [0/54000 (0%)] Loss: -1575.597900\n",
      "Train Epoch: 739 [4096/54000 (8%)] Loss: -1568.358643\n",
      "Train Epoch: 739 [8192/54000 (15%)] Loss: -1574.858765\n",
      "Train Epoch: 739 [12288/54000 (23%)] Loss: -1578.809082\n",
      "Train Epoch: 739 [16384/54000 (30%)] Loss: -1576.941895\n",
      "Train Epoch: 739 [20480/54000 (38%)] Loss: -1575.621826\n",
      "Train Epoch: 739 [24576/54000 (46%)] Loss: -1574.929932\n",
      "Train Epoch: 739 [28672/54000 (53%)] Loss: -1575.415527\n",
      "Train Epoch: 739 [32768/54000 (61%)] Loss: -1577.587891\n",
      "Train Epoch: 739 [36864/54000 (68%)] Loss: -1575.201782\n",
      "Train Epoch: 739 [40960/54000 (76%)] Loss: -1573.374634\n",
      "Train Epoch: 739 [45056/54000 (83%)] Loss: -1571.395386\n",
      "Train Epoch: 739 [49152/54000 (91%)] Loss: -1573.186279\n",
      "Train Epoch: 739 [53248/54000 (99%)] Loss: -1578.214600\n",
      "    epoch          : 739\n",
      "    loss           : -1577.3361156879444\n",
      "    ess            : 3.790416707359784\n",
      "    log_marginal   : 1577.4651995473564\n",
      "    val_loss       : -1577.527837117513\n",
      "    val_ess        : 3.802904854218165\n",
      "    val_log_marginal: 1577.6504618326824\n",
      "Train Epoch: 740 [0/54000 (0%)] Loss: -1577.857178\n",
      "Train Epoch: 740 [4096/54000 (8%)] Loss: -1575.800293\n",
      "Train Epoch: 740 [8192/54000 (15%)] Loss: -1576.567627\n",
      "Train Epoch: 740 [12288/54000 (23%)] Loss: -1576.438477\n",
      "Train Epoch: 740 [16384/54000 (30%)] Loss: -1579.535156\n",
      "Train Epoch: 740 [20480/54000 (38%)] Loss: -1577.581055\n",
      "Train Epoch: 740 [24576/54000 (46%)] Loss: -1583.612061\n",
      "Train Epoch: 740 [28672/54000 (53%)] Loss: -1574.115967\n",
      "Train Epoch: 740 [32768/54000 (61%)] Loss: -1571.767822\n",
      "Train Epoch: 740 [36864/54000 (68%)] Loss: -1575.961548\n",
      "Train Epoch: 740 [40960/54000 (76%)] Loss: -1585.070435\n",
      "Train Epoch: 740 [45056/54000 (83%)] Loss: -1578.454590\n",
      "Train Epoch: 740 [49152/54000 (91%)] Loss: -1582.001465\n",
      "Train Epoch: 740 [53248/54000 (99%)] Loss: -1569.392822\n",
      "    epoch          : 740\n",
      "    loss           : -1577.8101291746889\n",
      "    ess            : 3.7940944325867423\n",
      "    log_marginal   : 1577.9346744483116\n",
      "    val_loss       : -1577.174555460612\n",
      "    val_ess        : 3.787789801756541\n",
      "    val_log_marginal: 1577.3062947591145\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch740.pth ...\n",
      "Train Epoch: 741 [0/54000 (0%)] Loss: -1567.478516\n",
      "Train Epoch: 741 [4096/54000 (8%)] Loss: -1577.120728\n",
      "Train Epoch: 741 [8192/54000 (15%)] Loss: -1577.676392\n",
      "Train Epoch: 741 [12288/54000 (23%)] Loss: -1576.728760\n",
      "Train Epoch: 741 [16384/54000 (30%)] Loss: -1581.532349\n",
      "Train Epoch: 741 [20480/54000 (38%)] Loss: -1582.091187\n",
      "Train Epoch: 741 [24576/54000 (46%)] Loss: -1576.273560\n",
      "Train Epoch: 741 [28672/54000 (53%)] Loss: -1584.992920\n",
      "Train Epoch: 741 [32768/54000 (61%)] Loss: -1573.620605\n",
      "Train Epoch: 741 [36864/54000 (68%)] Loss: -1580.255249\n",
      "Train Epoch: 741 [40960/54000 (76%)] Loss: -1583.534912\n",
      "Train Epoch: 741 [45056/54000 (83%)] Loss: -1577.249512\n",
      "Train Epoch: 741 [49152/54000 (91%)] Loss: -1575.587158\n",
      "Train Epoch: 741 [53248/54000 (99%)] Loss: -1584.689941\n",
      "    epoch          : 741\n",
      "    loss           : -1577.6537166071164\n",
      "    ess            : 3.793065168281302\n",
      "    log_marginal   : 1577.7828253434168\n",
      "    val_loss       : -1577.7397918701172\n",
      "    val_ess        : 3.8007978796958923\n",
      "    val_log_marginal: 1577.8495585123699\n",
      "Train Epoch: 742 [0/54000 (0%)] Loss: -1579.385498\n",
      "Train Epoch: 742 [4096/54000 (8%)] Loss: -1576.312500\n",
      "Train Epoch: 742 [8192/54000 (15%)] Loss: -1573.271973\n",
      "Train Epoch: 742 [12288/54000 (23%)] Loss: -1583.983032\n",
      "Train Epoch: 742 [16384/54000 (30%)] Loss: -1575.693604\n",
      "Train Epoch: 742 [20480/54000 (38%)] Loss: -1584.462769\n",
      "Train Epoch: 742 [24576/54000 (46%)] Loss: -1581.960449\n",
      "Train Epoch: 742 [28672/54000 (53%)] Loss: -1579.337402\n",
      "Train Epoch: 742 [32768/54000 (61%)] Loss: -1576.250000\n",
      "Train Epoch: 742 [36864/54000 (68%)] Loss: -1577.422363\n",
      "Train Epoch: 742 [40960/54000 (76%)] Loss: -1578.722900\n",
      "Train Epoch: 742 [45056/54000 (83%)] Loss: -1575.696289\n",
      "Train Epoch: 742 [49152/54000 (91%)] Loss: -1577.515991\n",
      "Train Epoch: 742 [53248/54000 (99%)] Loss: -1579.364380\n",
      "    epoch          : 742\n",
      "    loss           : -1577.3134597850637\n",
      "    ess            : 3.793305726977886\n",
      "    log_marginal   : 1577.4391453458234\n",
      "    val_loss       : -1577.1665751139324\n",
      "    val_ess        : 3.7895016372203827\n",
      "    val_log_marginal: 1577.2897186279297\n",
      "Train Epoch: 743 [0/54000 (0%)] Loss: -1571.595825\n",
      "Train Epoch: 743 [4096/54000 (8%)] Loss: -1577.209473\n",
      "Train Epoch: 743 [8192/54000 (15%)] Loss: -1574.358154\n",
      "Train Epoch: 743 [12288/54000 (23%)] Loss: -1584.443848\n",
      "Train Epoch: 743 [16384/54000 (30%)] Loss: -1573.408813\n",
      "Train Epoch: 743 [20480/54000 (38%)] Loss: -1573.570068\n",
      "Train Epoch: 743 [24576/54000 (46%)] Loss: -1569.693481\n",
      "Train Epoch: 743 [28672/54000 (53%)] Loss: -1577.760742\n",
      "Train Epoch: 743 [32768/54000 (61%)] Loss: -1573.127930\n",
      "Train Epoch: 743 [36864/54000 (68%)] Loss: -1588.273682\n",
      "Train Epoch: 743 [40960/54000 (76%)] Loss: -1576.732178\n",
      "Train Epoch: 743 [45056/54000 (83%)] Loss: -1579.236694\n",
      "Train Epoch: 743 [49152/54000 (91%)] Loss: -1573.727539\n",
      "Train Epoch: 743 [53248/54000 (99%)] Loss: -1573.845947\n",
      "    epoch          : 743\n",
      "    loss           : -1577.536885483005\n",
      "    ess            : 3.7885749859832476\n",
      "    log_marginal   : 1577.6654342000518\n",
      "    val_loss       : -1577.8966369628906\n",
      "    val_ess        : 3.792978455622991\n",
      "    val_log_marginal: 1578.0263061523438\n",
      "Train Epoch: 744 [0/54000 (0%)] Loss: -1580.923096\n",
      "Train Epoch: 744 [4096/54000 (8%)] Loss: -1583.646729\n",
      "Train Epoch: 744 [8192/54000 (15%)] Loss: -1575.774170\n",
      "Train Epoch: 744 [12288/54000 (23%)] Loss: -1573.621094\n",
      "Train Epoch: 744 [16384/54000 (30%)] Loss: -1581.046265\n",
      "Train Epoch: 744 [20480/54000 (38%)] Loss: -1570.886597\n",
      "Train Epoch: 744 [24576/54000 (46%)] Loss: -1576.860840\n",
      "Train Epoch: 744 [28672/54000 (53%)] Loss: -1578.001587\n",
      "Train Epoch: 744 [32768/54000 (61%)] Loss: -1576.380615\n",
      "Train Epoch: 744 [36864/54000 (68%)] Loss: -1578.997070\n",
      "Train Epoch: 744 [40960/54000 (76%)] Loss: -1573.164062\n",
      "Train Epoch: 744 [45056/54000 (83%)] Loss: -1578.282593\n",
      "Train Epoch: 744 [49152/54000 (91%)] Loss: -1572.226562\n",
      "Train Epoch: 744 [53248/54000 (99%)] Loss: -1574.456787\n",
      "    epoch          : 744\n",
      "    loss           : -1577.9042714195793\n",
      "    ess            : 3.789444532439607\n",
      "    log_marginal   : 1578.0309925531324\n",
      "    val_loss       : -1576.970209757487\n",
      "    val_ess        : 3.801839977502823\n",
      "    val_log_marginal: 1577.0861256917317\n",
      "Train Epoch: 745 [0/54000 (0%)] Loss: -1574.323975\n",
      "Train Epoch: 745 [4096/54000 (8%)] Loss: -1579.865234\n",
      "Train Epoch: 745 [8192/54000 (15%)] Loss: -1574.027100\n",
      "Train Epoch: 745 [12288/54000 (23%)] Loss: -1580.517578\n",
      "Train Epoch: 745 [16384/54000 (30%)] Loss: -1571.226807\n",
      "Train Epoch: 745 [20480/54000 (38%)] Loss: -1578.662476\n",
      "Train Epoch: 745 [24576/54000 (46%)] Loss: -1573.035645\n",
      "Train Epoch: 745 [28672/54000 (53%)] Loss: -1573.228638\n",
      "Train Epoch: 745 [32768/54000 (61%)] Loss: -1585.264160\n",
      "Train Epoch: 745 [36864/54000 (68%)] Loss: -1577.652344\n",
      "Train Epoch: 745 [40960/54000 (76%)] Loss: -1581.333252\n",
      "Train Epoch: 745 [45056/54000 (83%)] Loss: -1586.319824\n",
      "Train Epoch: 745 [49152/54000 (91%)] Loss: -1579.591309\n",
      "Train Epoch: 745 [53248/54000 (99%)] Loss: -1570.067139\n",
      "    epoch          : 745\n",
      "    loss           : -1577.8002247019401\n",
      "    ess            : 3.794275139180405\n",
      "    log_marginal   : 1577.9252975970082\n",
      "    val_loss       : -1577.7123006184895\n",
      "    val_ess        : 3.8042125006516776\n",
      "    val_log_marginal: 1577.8331247965496\n",
      "Train Epoch: 746 [0/54000 (0%)] Loss: -1580.029541\n",
      "Train Epoch: 746 [4096/54000 (8%)] Loss: -1581.954346\n",
      "Train Epoch: 746 [8192/54000 (15%)] Loss: -1576.957520\n",
      "Train Epoch: 746 [12288/54000 (23%)] Loss: -1574.747070\n",
      "Train Epoch: 746 [16384/54000 (30%)] Loss: -1575.180176\n",
      "Train Epoch: 746 [20480/54000 (38%)] Loss: -1580.638428\n",
      "Train Epoch: 746 [24576/54000 (46%)] Loss: -1579.518188\n",
      "Train Epoch: 746 [28672/54000 (53%)] Loss: -1582.550537\n",
      "Train Epoch: 746 [32768/54000 (61%)] Loss: -1573.547119\n",
      "Train Epoch: 746 [36864/54000 (68%)] Loss: -1579.021362\n",
      "Train Epoch: 746 [40960/54000 (76%)] Loss: -1579.933838\n",
      "Train Epoch: 746 [45056/54000 (83%)] Loss: -1575.911377\n",
      "Train Epoch: 746 [49152/54000 (91%)] Loss: -1578.903687\n",
      "Train Epoch: 746 [53248/54000 (99%)] Loss: -1580.264160\n",
      "    epoch          : 746\n",
      "    loss           : -1577.877727779732\n",
      "    ess            : 3.7966601046340727\n",
      "    log_marginal   : 1578.0028544783027\n",
      "    val_loss       : -1577.1499125162761\n",
      "    val_ess        : 3.7994474867979684\n",
      "    val_log_marginal: 1577.2740122477214\n",
      "Train Epoch: 747 [0/54000 (0%)] Loss: -1582.105957\n",
      "Train Epoch: 747 [4096/54000 (8%)] Loss: -1579.173096\n",
      "Train Epoch: 747 [8192/54000 (15%)] Loss: -1578.937378\n",
      "Train Epoch: 747 [12288/54000 (23%)] Loss: -1581.096680\n",
      "Train Epoch: 747 [16384/54000 (30%)] Loss: -1579.643921\n",
      "Train Epoch: 747 [20480/54000 (38%)] Loss: -1577.401978\n",
      "Train Epoch: 747 [24576/54000 (46%)] Loss: -1578.666138\n",
      "Train Epoch: 747 [28672/54000 (53%)] Loss: -1582.179199\n",
      "Train Epoch: 747 [32768/54000 (61%)] Loss: -1576.226318\n",
      "Train Epoch: 747 [36864/54000 (68%)] Loss: -1580.225464\n",
      "Train Epoch: 747 [40960/54000 (76%)] Loss: -1585.410889\n",
      "Train Epoch: 747 [45056/54000 (83%)] Loss: -1574.493408\n",
      "Train Epoch: 747 [49152/54000 (91%)] Loss: -1583.772217\n",
      "Train Epoch: 747 [53248/54000 (99%)] Loss: -1580.614868\n",
      "    epoch          : 747\n",
      "    loss           : -1577.8128424911138\n",
      "    ess            : 3.7918966426668574\n",
      "    log_marginal   : 1577.940445886404\n",
      "    val_loss       : -1577.4691518147786\n",
      "    val_ess        : 3.7849272886912027\n",
      "    val_log_marginal: 1577.5907592773438\n",
      "Train Epoch: 748 [0/54000 (0%)] Loss: -1576.890015\n",
      "Train Epoch: 748 [4096/54000 (8%)] Loss: -1584.369019\n",
      "Train Epoch: 748 [8192/54000 (15%)] Loss: -1581.923340\n",
      "Train Epoch: 748 [12288/54000 (23%)] Loss: -1566.426758\n",
      "Train Epoch: 748 [16384/54000 (30%)] Loss: -1577.721191\n",
      "Train Epoch: 748 [20480/54000 (38%)] Loss: -1577.141968\n",
      "Train Epoch: 748 [24576/54000 (46%)] Loss: -1579.957031\n",
      "Train Epoch: 748 [28672/54000 (53%)] Loss: -1581.511475\n",
      "Train Epoch: 748 [32768/54000 (61%)] Loss: -1577.665649\n",
      "Train Epoch: 748 [36864/54000 (68%)] Loss: -1584.687744\n",
      "Train Epoch: 748 [40960/54000 (76%)] Loss: -1576.948120\n",
      "Train Epoch: 748 [45056/54000 (83%)] Loss: -1576.408447\n",
      "Train Epoch: 748 [49152/54000 (91%)] Loss: -1578.441040\n",
      "Train Epoch: 748 [53248/54000 (99%)] Loss: -1578.885742\n",
      "    epoch          : 748\n",
      "    loss           : -1577.978891092454\n",
      "    ess            : 3.795522997164613\n",
      "    log_marginal   : 1578.1061537322275\n",
      "    val_loss       : -1577.7681681315105\n",
      "    val_ess        : 3.7934696972370148\n",
      "    val_log_marginal: 1577.9009602864583\n",
      "Train Epoch: 749 [0/54000 (0%)] Loss: -1575.026611\n",
      "Train Epoch: 749 [4096/54000 (8%)] Loss: -1580.407715\n",
      "Train Epoch: 749 [8192/54000 (15%)] Loss: -1576.878418\n",
      "Train Epoch: 749 [12288/54000 (23%)] Loss: -1579.678711\n",
      "Train Epoch: 749 [16384/54000 (30%)] Loss: -1572.451904\n",
      "Train Epoch: 749 [20480/54000 (38%)] Loss: -1579.675171\n",
      "Train Epoch: 749 [24576/54000 (46%)] Loss: -1579.664795\n",
      "Train Epoch: 749 [28672/54000 (53%)] Loss: -1579.380859\n",
      "Train Epoch: 749 [32768/54000 (61%)] Loss: -1581.054565\n",
      "Train Epoch: 749 [36864/54000 (68%)] Loss: -1575.508545\n",
      "Train Epoch: 749 [40960/54000 (76%)] Loss: -1581.316162\n",
      "Train Epoch: 749 [45056/54000 (83%)] Loss: -1581.822144\n",
      "Train Epoch: 749 [49152/54000 (91%)] Loss: -1570.407104\n",
      "Train Epoch: 749 [53248/54000 (99%)] Loss: -1578.513428\n",
      "    epoch          : 749\n",
      "    loss           : -1577.988799614929\n",
      "    ess            : 3.7939056242811735\n",
      "    log_marginal   : 1578.1130243816647\n",
      "    val_loss       : -1577.7954610188801\n",
      "    val_ess        : 3.795298377672831\n",
      "    val_log_marginal: 1577.9245147705078\n",
      "Train Epoch: 750 [0/54000 (0%)] Loss: -1580.302002\n",
      "Train Epoch: 750 [4096/54000 (8%)] Loss: -1579.523071\n",
      "Train Epoch: 750 [8192/54000 (15%)] Loss: -1575.745239\n",
      "Train Epoch: 750 [12288/54000 (23%)] Loss: -1582.433594\n",
      "Train Epoch: 750 [16384/54000 (30%)] Loss: -1578.599854\n",
      "Train Epoch: 750 [20480/54000 (38%)] Loss: -1578.409424\n",
      "Train Epoch: 750 [24576/54000 (46%)] Loss: -1577.911133\n",
      "Train Epoch: 750 [28672/54000 (53%)] Loss: -1575.360962\n",
      "Train Epoch: 750 [32768/54000 (61%)] Loss: -1576.929688\n",
      "Train Epoch: 750 [36864/54000 (68%)] Loss: -1577.660034\n",
      "Train Epoch: 750 [40960/54000 (76%)] Loss: -1578.992676\n",
      "Train Epoch: 750 [45056/54000 (83%)] Loss: -1577.264893\n",
      "Train Epoch: 750 [49152/54000 (91%)] Loss: -1583.911255\n",
      "Train Epoch: 750 [53248/54000 (99%)] Loss: -1576.279541\n",
      "    epoch          : 750\n",
      "    loss           : -1578.212983190166\n",
      "    ess            : 3.790132129361844\n",
      "    log_marginal   : 1578.3431026223711\n",
      "    val_loss       : -1578.092305501302\n",
      "    val_ess        : 3.786632468303045\n",
      "    val_log_marginal: 1578.223129272461\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch750.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 751 [0/54000 (0%)] Loss: -1573.388672\n",
      "Train Epoch: 751 [4096/54000 (8%)] Loss: -1579.488770\n",
      "Train Epoch: 751 [8192/54000 (15%)] Loss: -1581.391113\n",
      "Train Epoch: 751 [12288/54000 (23%)] Loss: -1578.562256\n",
      "Train Epoch: 751 [16384/54000 (30%)] Loss: -1579.386963\n",
      "Train Epoch: 751 [20480/54000 (38%)] Loss: -1576.735596\n",
      "Train Epoch: 751 [24576/54000 (46%)] Loss: -1581.228027\n",
      "Train Epoch: 751 [28672/54000 (53%)] Loss: -1578.255615\n",
      "Train Epoch: 751 [32768/54000 (61%)] Loss: -1578.902832\n",
      "Train Epoch: 751 [36864/54000 (68%)] Loss: -1573.572510\n",
      "Train Epoch: 751 [40960/54000 (76%)] Loss: -1574.613770\n",
      "Train Epoch: 751 [45056/54000 (83%)] Loss: -1573.709717\n",
      "Train Epoch: 751 [49152/54000 (91%)] Loss: -1578.144531\n",
      "Train Epoch: 751 [53248/54000 (99%)] Loss: -1580.150513\n",
      "    epoch          : 751\n",
      "    loss           : -1578.0427066748741\n",
      "    ess            : 3.789948096207533\n",
      "    log_marginal   : 1578.1716528436018\n",
      "    val_loss       : -1578.0564626057942\n",
      "    val_ess        : 3.80102476477623\n",
      "    val_log_marginal: 1578.1815897623699\n",
      "Train Epoch: 752 [0/54000 (0%)] Loss: -1584.098511\n",
      "Train Epoch: 752 [4096/54000 (8%)] Loss: -1579.651367\n",
      "Train Epoch: 752 [8192/54000 (15%)] Loss: -1577.307861\n",
      "Train Epoch: 752 [12288/54000 (23%)] Loss: -1576.609741\n",
      "Train Epoch: 752 [16384/54000 (30%)] Loss: -1580.570068\n",
      "Train Epoch: 752 [20480/54000 (38%)] Loss: -1578.813965\n",
      "Train Epoch: 752 [24576/54000 (46%)] Loss: -1580.263794\n",
      "Train Epoch: 752 [28672/54000 (53%)] Loss: -1575.825317\n",
      "Train Epoch: 752 [32768/54000 (61%)] Loss: -1574.869995\n",
      "Train Epoch: 752 [36864/54000 (68%)] Loss: -1577.079102\n",
      "Train Epoch: 752 [40960/54000 (76%)] Loss: -1578.162476\n",
      "Train Epoch: 752 [45056/54000 (83%)] Loss: -1577.182861\n",
      "Train Epoch: 752 [49152/54000 (91%)] Loss: -1581.600342\n",
      "Train Epoch: 752 [53248/54000 (99%)] Loss: -1585.716431\n",
      "    epoch          : 752\n",
      "    loss           : -1578.001041358116\n",
      "    ess            : 3.795007061619329\n",
      "    log_marginal   : 1578.1259754054354\n",
      "    val_loss       : -1577.5482279459636\n",
      "    val_ess        : 3.795021186272303\n",
      "    val_log_marginal: 1577.680425008138\n",
      "Train Epoch: 753 [0/54000 (0%)] Loss: -1578.871460\n",
      "Train Epoch: 753 [4096/54000 (8%)] Loss: -1577.197632\n",
      "Train Epoch: 753 [8192/54000 (15%)] Loss: -1571.542480\n",
      "Train Epoch: 753 [12288/54000 (23%)] Loss: -1573.389648\n",
      "Train Epoch: 753 [16384/54000 (30%)] Loss: -1578.321045\n",
      "Train Epoch: 753 [20480/54000 (38%)] Loss: -1579.447998\n",
      "Train Epoch: 753 [24576/54000 (46%)] Loss: -1579.883545\n",
      "Train Epoch: 753 [28672/54000 (53%)] Loss: -1583.476807\n",
      "Train Epoch: 753 [32768/54000 (61%)] Loss: -1574.164062\n",
      "Train Epoch: 753 [36864/54000 (68%)] Loss: -1576.429199\n",
      "Train Epoch: 753 [40960/54000 (76%)] Loss: -1577.508057\n",
      "Train Epoch: 753 [45056/54000 (83%)] Loss: -1576.481934\n",
      "Train Epoch: 753 [49152/54000 (91%)] Loss: -1573.629517\n",
      "Train Epoch: 753 [53248/54000 (99%)] Loss: -1575.126953\n",
      "    epoch          : 753\n",
      "    loss           : -1578.0237626351452\n",
      "    ess            : 3.7910686590095266\n",
      "    log_marginal   : 1578.1518282777324\n",
      "    val_loss       : -1578.392837524414\n",
      "    val_ess        : 3.799085815747579\n",
      "    val_log_marginal: 1578.5153350830078\n",
      "Train Epoch: 754 [0/54000 (0%)] Loss: -1581.920532\n",
      "Train Epoch: 754 [4096/54000 (8%)] Loss: -1574.997559\n",
      "Train Epoch: 754 [8192/54000 (15%)] Loss: -1574.754639\n",
      "Train Epoch: 754 [12288/54000 (23%)] Loss: -1577.697876\n",
      "Train Epoch: 754 [16384/54000 (30%)] Loss: -1577.458984\n",
      "Train Epoch: 754 [20480/54000 (38%)] Loss: -1572.827393\n",
      "Train Epoch: 754 [24576/54000 (46%)] Loss: -1582.564697\n",
      "Train Epoch: 754 [28672/54000 (53%)] Loss: -1585.117676\n",
      "Train Epoch: 754 [32768/54000 (61%)] Loss: -1575.264648\n",
      "Train Epoch: 754 [36864/54000 (68%)] Loss: -1574.991333\n",
      "Train Epoch: 754 [40960/54000 (76%)] Loss: -1575.217407\n",
      "Train Epoch: 754 [45056/54000 (83%)] Loss: -1575.288818\n",
      "Train Epoch: 754 [49152/54000 (91%)] Loss: -1577.963867\n",
      "Train Epoch: 754 [53248/54000 (99%)] Loss: -1568.023438\n",
      "    epoch          : 754\n",
      "    loss           : -1578.2667502452978\n",
      "    ess            : 3.7974549876570136\n",
      "    log_marginal   : 1578.3916675151806\n",
      "    val_loss       : -1578.0629984537761\n",
      "    val_ess        : 3.791041612625122\n",
      "    val_log_marginal: 1578.190689086914\n",
      "Train Epoch: 755 [0/54000 (0%)] Loss: -1578.843994\n",
      "Train Epoch: 755 [4096/54000 (8%)] Loss: -1585.441162\n",
      "Train Epoch: 755 [8192/54000 (15%)] Loss: -1576.052734\n",
      "Train Epoch: 755 [12288/54000 (23%)] Loss: -1578.380249\n",
      "Train Epoch: 755 [16384/54000 (30%)] Loss: -1577.693115\n",
      "Train Epoch: 755 [20480/54000 (38%)] Loss: -1585.238770\n",
      "Train Epoch: 755 [24576/54000 (46%)] Loss: -1575.227783\n",
      "Train Epoch: 755 [28672/54000 (53%)] Loss: -1578.377441\n",
      "Train Epoch: 755 [32768/54000 (61%)] Loss: -1584.479614\n",
      "Train Epoch: 755 [36864/54000 (68%)] Loss: -1571.023804\n",
      "Train Epoch: 755 [40960/54000 (76%)] Loss: -1578.816406\n",
      "Train Epoch: 755 [45056/54000 (83%)] Loss: -1577.431885\n",
      "Train Epoch: 755 [49152/54000 (91%)] Loss: -1574.575928\n",
      "Train Epoch: 755 [53248/54000 (99%)] Loss: -1581.645752\n",
      "    epoch          : 755\n",
      "    loss           : -1578.4559580726082\n",
      "    ess            : 3.7894769754454987\n",
      "    log_marginal   : 1578.5873392837307\n",
      "    val_loss       : -1577.5184377034504\n",
      "    val_ess        : 3.800824840863546\n",
      "    val_log_marginal: 1577.6387023925781\n",
      "Train Epoch: 756 [0/54000 (0%)] Loss: -1580.639282\n",
      "Train Epoch: 756 [4096/54000 (8%)] Loss: -1582.458984\n",
      "Train Epoch: 756 [8192/54000 (15%)] Loss: -1576.678711\n",
      "Train Epoch: 756 [12288/54000 (23%)] Loss: -1579.520264\n",
      "Train Epoch: 756 [16384/54000 (30%)] Loss: -1581.723999\n",
      "Train Epoch: 756 [20480/54000 (38%)] Loss: -1576.537109\n",
      "Train Epoch: 756 [24576/54000 (46%)] Loss: -1577.226440\n",
      "Train Epoch: 756 [28672/54000 (53%)] Loss: -1577.187012\n",
      "Train Epoch: 756 [32768/54000 (61%)] Loss: -1574.084473\n",
      "Train Epoch: 756 [36864/54000 (68%)] Loss: -1577.933350\n",
      "Train Epoch: 756 [40960/54000 (76%)] Loss: -1572.128784\n",
      "Train Epoch: 756 [45056/54000 (83%)] Loss: -1579.277588\n",
      "Train Epoch: 756 [49152/54000 (91%)] Loss: -1580.625122\n",
      "Train Epoch: 756 [53248/54000 (99%)] Loss: -1578.779541\n",
      "    epoch          : 756\n",
      "    loss           : -1578.632241488633\n",
      "    ess            : 3.7932416940752365\n",
      "    log_marginal   : 1578.7604020105155\n",
      "    val_loss       : -1578.4130757649739\n",
      "    val_ess        : 3.781474322080612\n",
      "    val_log_marginal: 1578.5524444580078\n",
      "Train Epoch: 757 [0/54000 (0%)] Loss: -1578.798584\n",
      "Train Epoch: 757 [4096/54000 (8%)] Loss: -1582.616699\n",
      "Train Epoch: 757 [8192/54000 (15%)] Loss: -1585.505371\n",
      "Train Epoch: 757 [12288/54000 (23%)] Loss: -1584.385986\n",
      "Train Epoch: 757 [16384/54000 (30%)] Loss: -1578.692871\n",
      "Train Epoch: 757 [20480/54000 (38%)] Loss: -1571.103271\n",
      "Train Epoch: 757 [24576/54000 (46%)] Loss: -1574.560425\n",
      "Train Epoch: 757 [28672/54000 (53%)] Loss: -1570.869873\n",
      "Train Epoch: 757 [32768/54000 (61%)] Loss: -1579.219971\n",
      "Train Epoch: 757 [36864/54000 (68%)] Loss: -1582.296875\n",
      "Train Epoch: 757 [40960/54000 (76%)] Loss: -1582.251099\n",
      "Train Epoch: 757 [45056/54000 (83%)] Loss: -1575.544922\n",
      "Train Epoch: 757 [49152/54000 (91%)] Loss: -1581.569458\n",
      "Train Epoch: 757 [53248/54000 (99%)] Loss: -1581.691162\n",
      "    epoch          : 757\n",
      "    loss           : -1578.251942711419\n",
      "    ess            : 3.7973293930433374\n",
      "    log_marginal   : 1578.374398904954\n",
      "    val_loss       : -1577.6704203287761\n",
      "    val_ess        : 3.7959914604822793\n",
      "    val_log_marginal: 1577.7938385009766\n",
      "Train Epoch: 758 [0/54000 (0%)] Loss: -1572.989502\n",
      "Train Epoch: 758 [4096/54000 (8%)] Loss: -1573.885254\n",
      "Train Epoch: 758 [8192/54000 (15%)] Loss: -1583.887451\n",
      "Train Epoch: 758 [12288/54000 (23%)] Loss: -1570.542603\n",
      "Train Epoch: 758 [16384/54000 (30%)] Loss: -1571.566528\n",
      "Train Epoch: 758 [20480/54000 (38%)] Loss: -1574.091675\n",
      "Train Epoch: 758 [24576/54000 (46%)] Loss: -1575.640747\n",
      "Train Epoch: 758 [28672/54000 (53%)] Loss: -1578.732422\n",
      "Train Epoch: 758 [32768/54000 (61%)] Loss: -1578.490479\n",
      "Train Epoch: 758 [36864/54000 (68%)] Loss: -1580.935547\n",
      "Train Epoch: 758 [40960/54000 (76%)] Loss: -1572.492676\n",
      "Train Epoch: 758 [45056/54000 (83%)] Loss: -1568.086670\n",
      "Train Epoch: 758 [49152/54000 (91%)] Loss: -1583.382202\n",
      "Train Epoch: 758 [53248/54000 (99%)] Loss: -1575.248779\n",
      "    epoch          : 758\n",
      "    loss           : -1578.474635408953\n",
      "    ess            : 3.7933172558156234\n",
      "    log_marginal   : 1578.6040415108487\n",
      "    val_loss       : -1578.9208475748699\n",
      "    val_ess        : 3.7978778878847756\n",
      "    val_log_marginal: 1579.0456085205078\n",
      "Train Epoch: 759 [0/54000 (0%)] Loss: -1577.590332\n",
      "Train Epoch: 759 [4096/54000 (8%)] Loss: -1581.862549\n",
      "Train Epoch: 759 [8192/54000 (15%)] Loss: -1578.992920\n",
      "Train Epoch: 759 [12288/54000 (23%)] Loss: -1576.218262\n",
      "Train Epoch: 759 [16384/54000 (30%)] Loss: -1576.026611\n",
      "Train Epoch: 759 [20480/54000 (38%)] Loss: -1582.596924\n",
      "Train Epoch: 759 [24576/54000 (46%)] Loss: -1581.524658\n",
      "Train Epoch: 759 [28672/54000 (53%)] Loss: -1576.259644\n",
      "Train Epoch: 759 [32768/54000 (61%)] Loss: -1574.820190\n",
      "Train Epoch: 759 [36864/54000 (68%)] Loss: -1576.352051\n",
      "Train Epoch: 759 [40960/54000 (76%)] Loss: -1569.033691\n",
      "Train Epoch: 759 [45056/54000 (83%)] Loss: -1575.037354\n",
      "Train Epoch: 759 [49152/54000 (91%)] Loss: -1575.685303\n",
      "Train Epoch: 759 [53248/54000 (99%)] Loss: -1581.984375\n",
      "    epoch          : 759\n",
      "    loss           : -1578.4513483273474\n",
      "    ess            : 3.792201869295672\n",
      "    log_marginal   : 1578.5799138218306\n",
      "    val_loss       : -1577.8457743326824\n",
      "    val_ess        : 3.794210652510325\n",
      "    val_log_marginal: 1577.9712931315105\n",
      "Train Epoch: 760 [0/54000 (0%)] Loss: -1577.670898\n",
      "Train Epoch: 760 [4096/54000 (8%)] Loss: -1575.054810\n",
      "Train Epoch: 760 [8192/54000 (15%)] Loss: -1581.281250\n",
      "Train Epoch: 760 [12288/54000 (23%)] Loss: -1570.552734\n",
      "Train Epoch: 760 [16384/54000 (30%)] Loss: -1577.929199\n",
      "Train Epoch: 760 [20480/54000 (38%)] Loss: -1579.486694\n",
      "Train Epoch: 760 [24576/54000 (46%)] Loss: -1583.264648\n",
      "Train Epoch: 760 [28672/54000 (53%)] Loss: -1582.073730\n",
      "Train Epoch: 760 [32768/54000 (61%)] Loss: -1573.845459\n",
      "Train Epoch: 760 [36864/54000 (68%)] Loss: -1584.149536\n",
      "Train Epoch: 760 [40960/54000 (76%)] Loss: -1579.673828\n",
      "Train Epoch: 760 [45056/54000 (83%)] Loss: -1578.437500\n",
      "Train Epoch: 760 [49152/54000 (91%)] Loss: -1583.841309\n",
      "Train Epoch: 760 [53248/54000 (99%)] Loss: -1574.989990\n",
      "    epoch          : 760\n",
      "    loss           : -1578.4508467398548\n",
      "    ess            : 3.7888972092578763\n",
      "    log_marginal   : 1578.5796233986227\n",
      "    val_loss       : -1578.8494567871094\n",
      "    val_ess        : 3.7864447136720023\n",
      "    val_log_marginal: 1578.9864095052083\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch760.pth ...\n",
      "Train Epoch: 761 [0/54000 (0%)] Loss: -1579.693359\n",
      "Train Epoch: 761 [4096/54000 (8%)] Loss: -1578.393188\n",
      "Train Epoch: 761 [8192/54000 (15%)] Loss: -1570.102539\n",
      "Train Epoch: 761 [12288/54000 (23%)] Loss: -1579.459229\n",
      "Train Epoch: 761 [16384/54000 (30%)] Loss: -1573.512695\n",
      "Train Epoch: 761 [20480/54000 (38%)] Loss: -1575.338989\n",
      "Train Epoch: 761 [24576/54000 (46%)] Loss: -1571.844482\n",
      "Train Epoch: 761 [28672/54000 (53%)] Loss: -1581.027344\n",
      "Train Epoch: 761 [32768/54000 (61%)] Loss: -1575.201172\n",
      "Train Epoch: 761 [36864/54000 (68%)] Loss: -1579.082153\n",
      "Train Epoch: 761 [40960/54000 (76%)] Loss: -1583.305664\n",
      "Train Epoch: 761 [45056/54000 (83%)] Loss: -1578.710693\n",
      "Train Epoch: 761 [49152/54000 (91%)] Loss: -1580.309937\n",
      "Train Epoch: 761 [53248/54000 (99%)] Loss: -1574.603638\n",
      "    epoch          : 761\n",
      "    loss           : -1578.5813555242892\n",
      "    ess            : 3.7926284961790837\n",
      "    log_marginal   : 1578.7077440017772\n",
      "    val_loss       : -1578.4491780598958\n",
      "    val_ess        : 3.789388875166575\n",
      "    val_log_marginal: 1578.5897521972656\n",
      "Train Epoch: 762 [0/54000 (0%)] Loss: -1584.006714\n",
      "Train Epoch: 762 [4096/54000 (8%)] Loss: -1580.644287\n",
      "Train Epoch: 762 [8192/54000 (15%)] Loss: -1583.457153\n",
      "Train Epoch: 762 [12288/54000 (23%)] Loss: -1582.669189\n",
      "Train Epoch: 762 [16384/54000 (30%)] Loss: -1575.596558\n",
      "Train Epoch: 762 [20480/54000 (38%)] Loss: -1575.589600\n",
      "Train Epoch: 762 [24576/54000 (46%)] Loss: -1575.148682\n",
      "Train Epoch: 762 [28672/54000 (53%)] Loss: -1584.522705\n",
      "Train Epoch: 762 [32768/54000 (61%)] Loss: -1578.861816\n",
      "Train Epoch: 762 [36864/54000 (68%)] Loss: -1576.903076\n",
      "Train Epoch: 762 [40960/54000 (76%)] Loss: -1578.946289\n",
      "Train Epoch: 762 [45056/54000 (83%)] Loss: -1578.168457\n",
      "Train Epoch: 762 [49152/54000 (91%)] Loss: -1577.412842\n",
      "Train Epoch: 762 [53248/54000 (99%)] Loss: -1577.106445\n",
      "    epoch          : 762\n",
      "    loss           : -1578.7866459706383\n",
      "    ess            : 3.7935591037804484\n",
      "    log_marginal   : 1578.9141498583754\n",
      "    val_loss       : -1578.873051961263\n",
      "    val_ess        : 3.7884978453318277\n",
      "    val_log_marginal: 1579.0055592854817\n",
      "Train Epoch: 763 [0/54000 (0%)] Loss: -1579.217285\n",
      "Train Epoch: 763 [4096/54000 (8%)] Loss: -1587.872314\n",
      "Train Epoch: 763 [8192/54000 (15%)] Loss: -1585.029663\n",
      "Train Epoch: 763 [12288/54000 (23%)] Loss: -1581.768799\n",
      "Train Epoch: 763 [16384/54000 (30%)] Loss: -1572.571777\n",
      "Train Epoch: 763 [20480/54000 (38%)] Loss: -1579.450317\n",
      "Train Epoch: 763 [24576/54000 (46%)] Loss: -1577.423584\n",
      "Train Epoch: 763 [28672/54000 (53%)] Loss: -1574.467041\n",
      "Train Epoch: 763 [32768/54000 (61%)] Loss: -1577.538086\n",
      "Train Epoch: 763 [36864/54000 (68%)] Loss: -1574.781128\n",
      "Train Epoch: 763 [40960/54000 (76%)] Loss: -1576.403564\n",
      "Train Epoch: 763 [45056/54000 (83%)] Loss: -1574.102051\n",
      "Train Epoch: 763 [49152/54000 (91%)] Loss: -1583.368408\n",
      "Train Epoch: 763 [53248/54000 (99%)] Loss: -1578.239502\n",
      "    epoch          : 763\n",
      "    loss           : -1578.6765582188611\n",
      "    ess            : 3.7909516022668632\n",
      "    log_marginal   : 1578.8066822793246\n",
      "    val_loss       : -1578.9819997151692\n",
      "    val_ess        : 3.7887327075004578\n",
      "    val_log_marginal: 1579.1029968261719\n",
      "Train Epoch: 764 [0/54000 (0%)] Loss: -1575.035400\n",
      "Train Epoch: 764 [4096/54000 (8%)] Loss: -1575.349121\n",
      "Train Epoch: 764 [8192/54000 (15%)] Loss: -1576.791138\n",
      "Train Epoch: 764 [12288/54000 (23%)] Loss: -1573.623535\n",
      "Train Epoch: 764 [16384/54000 (30%)] Loss: -1585.467529\n",
      "Train Epoch: 764 [20480/54000 (38%)] Loss: -1580.793213\n",
      "Train Epoch: 764 [24576/54000 (46%)] Loss: -1581.296509\n",
      "Train Epoch: 764 [28672/54000 (53%)] Loss: -1577.576904\n",
      "Train Epoch: 764 [32768/54000 (61%)] Loss: -1580.924561\n",
      "Train Epoch: 764 [36864/54000 (68%)] Loss: -1577.879517\n",
      "Train Epoch: 764 [40960/54000 (76%)] Loss: -1577.642578\n",
      "Train Epoch: 764 [45056/54000 (83%)] Loss: -1576.676025\n",
      "Train Epoch: 764 [49152/54000 (91%)] Loss: -1570.554932\n",
      "Train Epoch: 764 [53248/54000 (99%)] Loss: -1587.854004\n",
      "    epoch          : 764\n",
      "    loss           : -1578.4546818303836\n",
      "    ess            : 3.7923315204150305\n",
      "    log_marginal   : 1578.5815013144254\n",
      "    val_loss       : -1579.0362497965496\n",
      "    val_ess        : 3.8027799328168235\n",
      "    val_log_marginal: 1579.1518859863281\n",
      "Train Epoch: 765 [0/54000 (0%)] Loss: -1576.237061\n",
      "Train Epoch: 765 [4096/54000 (8%)] Loss: -1582.896973\n",
      "Train Epoch: 765 [8192/54000 (15%)] Loss: -1581.088135\n",
      "Train Epoch: 765 [12288/54000 (23%)] Loss: -1572.302612\n",
      "Train Epoch: 765 [16384/54000 (30%)] Loss: -1574.606689\n",
      "Train Epoch: 765 [20480/54000 (38%)] Loss: -1576.818115\n",
      "Train Epoch: 765 [24576/54000 (46%)] Loss: -1582.640503\n",
      "Train Epoch: 765 [28672/54000 (53%)] Loss: -1573.073486\n",
      "Train Epoch: 765 [32768/54000 (61%)] Loss: -1581.439453\n",
      "Train Epoch: 765 [36864/54000 (68%)] Loss: -1574.276245\n",
      "Train Epoch: 765 [40960/54000 (76%)] Loss: -1576.574951\n",
      "Train Epoch: 765 [45056/54000 (83%)] Loss: -1574.169434\n",
      "Train Epoch: 765 [49152/54000 (91%)] Loss: -1580.870239\n",
      "Train Epoch: 765 [53248/54000 (99%)] Loss: -1577.568604\n",
      "    epoch          : 765\n",
      "    loss           : -1578.6535742881738\n",
      "    ess            : 3.796947070207641\n",
      "    log_marginal   : 1578.779284725822\n",
      "    val_loss       : -1577.6124420166016\n",
      "    val_ess        : 3.8068232933680215\n",
      "    val_log_marginal: 1577.7303263346355\n",
      "Train Epoch: 766 [0/54000 (0%)] Loss: -1578.013916\n",
      "Train Epoch: 766 [4096/54000 (8%)] Loss: -1575.418213\n",
      "Train Epoch: 766 [8192/54000 (15%)] Loss: -1578.478760\n",
      "Train Epoch: 766 [12288/54000 (23%)] Loss: -1574.715576\n",
      "Train Epoch: 766 [16384/54000 (30%)] Loss: -1572.556152\n",
      "Train Epoch: 766 [20480/54000 (38%)] Loss: -1575.588989\n",
      "Train Epoch: 766 [24576/54000 (46%)] Loss: -1582.155518\n",
      "Train Epoch: 766 [28672/54000 (53%)] Loss: -1575.882812\n",
      "Train Epoch: 766 [32768/54000 (61%)] Loss: -1574.010498\n",
      "Train Epoch: 766 [36864/54000 (68%)] Loss: -1584.990723\n",
      "Train Epoch: 766 [40960/54000 (76%)] Loss: -1571.822266\n",
      "Train Epoch: 766 [45056/54000 (83%)] Loss: -1576.390869\n",
      "Train Epoch: 766 [49152/54000 (91%)] Loss: -1581.338257\n",
      "Train Epoch: 766 [53248/54000 (99%)] Loss: -1575.973145\n",
      "    epoch          : 766\n",
      "    loss           : -1578.6446000953422\n",
      "    ess            : 3.7916793913637856\n",
      "    log_marginal   : 1578.772408291062\n",
      "    val_loss       : -1578.8096669514973\n",
      "    val_ess        : 3.7896040280659995\n",
      "    val_log_marginal: 1578.9432983398438\n",
      "Train Epoch: 767 [0/54000 (0%)] Loss: -1573.978516\n",
      "Train Epoch: 767 [4096/54000 (8%)] Loss: -1577.023438\n",
      "Train Epoch: 767 [8192/54000 (15%)] Loss: -1579.682007\n",
      "Train Epoch: 767 [12288/54000 (23%)] Loss: -1579.764648\n",
      "Train Epoch: 767 [16384/54000 (30%)] Loss: -1578.799072\n",
      "Train Epoch: 767 [20480/54000 (38%)] Loss: -1581.895386\n",
      "Train Epoch: 767 [24576/54000 (46%)] Loss: -1576.230469\n",
      "Train Epoch: 767 [28672/54000 (53%)] Loss: -1574.592163\n",
      "Train Epoch: 767 [32768/54000 (61%)] Loss: -1573.858398\n",
      "Train Epoch: 767 [36864/54000 (68%)] Loss: -1580.287842\n",
      "Train Epoch: 767 [40960/54000 (76%)] Loss: -1578.337646\n",
      "Train Epoch: 767 [45056/54000 (83%)] Loss: -1580.172607\n",
      "Train Epoch: 767 [49152/54000 (91%)] Loss: -1580.251831\n",
      "Train Epoch: 767 [53248/54000 (99%)] Loss: -1591.434814\n",
      "    epoch          : 767\n",
      "    loss           : -1578.64833625685\n",
      "    ess            : 3.7945171555071644\n",
      "    log_marginal   : 1578.7738164386478\n",
      "    val_loss       : -1579.1114857991536\n",
      "    val_ess        : 3.801817466815313\n",
      "    val_log_marginal: 1579.2281901041667\n",
      "Train Epoch: 768 [0/54000 (0%)] Loss: -1585.699829\n",
      "Train Epoch: 768 [4096/54000 (8%)] Loss: -1576.494019\n",
      "Train Epoch: 768 [8192/54000 (15%)] Loss: -1577.470215\n",
      "Train Epoch: 768 [12288/54000 (23%)] Loss: -1575.464111\n",
      "Train Epoch: 768 [16384/54000 (30%)] Loss: -1574.183228\n",
      "Train Epoch: 768 [20480/54000 (38%)] Loss: -1573.686768\n",
      "Train Epoch: 768 [24576/54000 (46%)] Loss: -1583.101196\n",
      "Train Epoch: 768 [28672/54000 (53%)] Loss: -1574.968506\n",
      "Train Epoch: 768 [32768/54000 (61%)] Loss: -1582.744507\n",
      "Train Epoch: 768 [36864/54000 (68%)] Loss: -1579.478516\n",
      "Train Epoch: 768 [40960/54000 (76%)] Loss: -1576.657959\n",
      "Train Epoch: 768 [45056/54000 (83%)] Loss: -1580.751953\n",
      "Train Epoch: 768 [49152/54000 (91%)] Loss: -1573.402588\n",
      "Train Epoch: 768 [53248/54000 (99%)] Loss: -1576.391602\n",
      "    epoch          : 768\n",
      "    loss           : -1578.4452563823681\n",
      "    ess            : 3.796087614167923\n",
      "    log_marginal   : 1578.5696379313538\n",
      "    val_loss       : -1578.6213684082031\n",
      "    val_ess        : 3.797124058008194\n",
      "    val_log_marginal: 1578.7453918457031\n",
      "Train Epoch: 769 [0/54000 (0%)] Loss: -1585.694336\n",
      "Train Epoch: 769 [4096/54000 (8%)] Loss: -1576.927979\n",
      "Train Epoch: 769 [8192/54000 (15%)] Loss: -1580.766846\n",
      "Train Epoch: 769 [12288/54000 (23%)] Loss: -1579.082275\n",
      "Train Epoch: 769 [16384/54000 (30%)] Loss: -1577.483643\n",
      "Train Epoch: 769 [20480/54000 (38%)] Loss: -1572.311035\n",
      "Train Epoch: 769 [24576/54000 (46%)] Loss: -1583.475098\n",
      "Train Epoch: 769 [28672/54000 (53%)] Loss: -1577.363892\n",
      "Train Epoch: 769 [32768/54000 (61%)] Loss: -1573.491821\n",
      "Train Epoch: 769 [36864/54000 (68%)] Loss: -1576.414307\n",
      "Train Epoch: 769 [40960/54000 (76%)] Loss: -1578.615356\n",
      "Train Epoch: 769 [45056/54000 (83%)] Loss: -1577.072998\n",
      "Train Epoch: 769 [49152/54000 (91%)] Loss: -1581.516357\n",
      "Train Epoch: 769 [53248/54000 (99%)] Loss: -1577.770020\n",
      "    epoch          : 769\n",
      "    loss           : -1578.7241465491707\n",
      "    ess            : 3.7929629997054546\n",
      "    log_marginal   : 1578.8502324542728\n",
      "    val_loss       : -1578.2782796223958\n",
      "    val_ess        : 3.788263499736786\n",
      "    val_log_marginal: 1578.4033813476562\n",
      "Train Epoch: 770 [0/54000 (0%)] Loss: -1576.847412\n",
      "Train Epoch: 770 [4096/54000 (8%)] Loss: -1586.659180\n",
      "Train Epoch: 770 [8192/54000 (15%)] Loss: -1581.941650\n",
      "Train Epoch: 770 [12288/54000 (23%)] Loss: -1576.978394\n",
      "Train Epoch: 770 [16384/54000 (30%)] Loss: -1581.109375\n",
      "Train Epoch: 770 [20480/54000 (38%)] Loss: -1579.020142\n",
      "Train Epoch: 770 [24576/54000 (46%)] Loss: -1573.454346\n",
      "Train Epoch: 770 [28672/54000 (53%)] Loss: -1580.537476\n",
      "Train Epoch: 770 [32768/54000 (61%)] Loss: -1584.842285\n",
      "Train Epoch: 770 [36864/54000 (68%)] Loss: -1578.484863\n",
      "Train Epoch: 770 [40960/54000 (76%)] Loss: -1582.125244\n",
      "Train Epoch: 770 [45056/54000 (83%)] Loss: -1578.795532\n",
      "Train Epoch: 770 [49152/54000 (91%)] Loss: -1576.848877\n",
      "Train Epoch: 770 [53248/54000 (99%)] Loss: -1576.007812\n",
      "    epoch          : 770\n",
      "    loss           : -1578.892824001222\n",
      "    ess            : 3.7965655552832436\n",
      "    log_marginal   : 1579.019325292506\n",
      "    val_loss       : -1578.3354797363281\n",
      "    val_ess        : 3.7931387523810067\n",
      "    val_log_marginal: 1578.465087890625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch770.pth ...\n",
      "Train Epoch: 771 [0/54000 (0%)] Loss: -1577.167725\n",
      "Train Epoch: 771 [4096/54000 (8%)] Loss: -1579.047363\n",
      "Train Epoch: 771 [8192/54000 (15%)] Loss: -1584.502197\n",
      "Train Epoch: 771 [12288/54000 (23%)] Loss: -1580.487793\n",
      "Train Epoch: 771 [16384/54000 (30%)] Loss: -1578.382568\n",
      "Train Epoch: 771 [20480/54000 (38%)] Loss: -1576.513062\n",
      "Train Epoch: 771 [24576/54000 (46%)] Loss: -1578.839111\n",
      "Train Epoch: 771 [28672/54000 (53%)] Loss: -1580.099609\n",
      "Train Epoch: 771 [32768/54000 (61%)] Loss: -1580.898315\n",
      "Train Epoch: 771 [36864/54000 (68%)] Loss: -1579.585571\n",
      "Train Epoch: 771 [40960/54000 (76%)] Loss: -1583.646606\n",
      "Train Epoch: 771 [45056/54000 (83%)] Loss: -1575.087158\n",
      "Train Epoch: 771 [49152/54000 (91%)] Loss: -1580.866577\n",
      "Train Epoch: 771 [53248/54000 (99%)] Loss: -1579.584717\n",
      "    epoch          : 771\n",
      "    loss           : -1578.872350900659\n",
      "    ess            : 3.7890838446775317\n",
      "    log_marginal   : 1579.0026485208086\n",
      "    val_loss       : -1577.7865346272786\n",
      "    val_ess        : 3.791620761156082\n",
      "    val_log_marginal: 1577.9118754069011\n",
      "Train Epoch: 772 [0/54000 (0%)] Loss: -1575.906738\n",
      "Train Epoch: 772 [4096/54000 (8%)] Loss: -1578.226807\n",
      "Train Epoch: 772 [8192/54000 (15%)] Loss: -1577.041016\n",
      "Train Epoch: 772 [12288/54000 (23%)] Loss: -1584.172119\n",
      "Train Epoch: 772 [16384/54000 (30%)] Loss: -1576.756592\n",
      "Train Epoch: 772 [20480/54000 (38%)] Loss: -1580.930298\n",
      "Train Epoch: 772 [24576/54000 (46%)] Loss: -1569.958008\n",
      "Train Epoch: 772 [28672/54000 (53%)] Loss: -1578.192017\n",
      "Train Epoch: 772 [32768/54000 (61%)] Loss: -1577.579834\n",
      "Train Epoch: 772 [36864/54000 (68%)] Loss: -1580.851807\n",
      "Train Epoch: 772 [40960/54000 (76%)] Loss: -1578.661011\n",
      "Train Epoch: 772 [45056/54000 (83%)] Loss: -1585.789307\n",
      "Train Epoch: 772 [49152/54000 (91%)] Loss: -1577.469727\n",
      "Train Epoch: 772 [53248/54000 (99%)] Loss: -1575.103027\n",
      "    epoch          : 772\n",
      "    loss           : -1578.9831953726673\n",
      "    ess            : 3.797519282707106\n",
      "    log_marginal   : 1579.1069040886034\n",
      "    val_loss       : -1578.8409678141277\n",
      "    val_ess        : 3.7898146410783133\n",
      "    val_log_marginal: 1578.980204264323\n",
      "Train Epoch: 773 [0/54000 (0%)] Loss: -1575.274414\n",
      "Train Epoch: 773 [4096/54000 (8%)] Loss: -1576.970337\n",
      "Train Epoch: 773 [8192/54000 (15%)] Loss: -1577.031982\n",
      "Train Epoch: 773 [12288/54000 (23%)] Loss: -1584.283081\n",
      "Train Epoch: 773 [16384/54000 (30%)] Loss: -1578.568237\n",
      "Train Epoch: 773 [20480/54000 (38%)] Loss: -1581.136108\n",
      "Train Epoch: 773 [24576/54000 (46%)] Loss: -1575.523682\n",
      "Train Epoch: 773 [28672/54000 (53%)] Loss: -1584.355957\n",
      "Train Epoch: 773 [32768/54000 (61%)] Loss: -1575.240601\n",
      "Train Epoch: 773 [36864/54000 (68%)] Loss: -1582.674072\n",
      "Train Epoch: 773 [40960/54000 (76%)] Loss: -1584.349854\n",
      "Train Epoch: 773 [45056/54000 (83%)] Loss: -1576.852661\n",
      "Train Epoch: 773 [49152/54000 (91%)] Loss: -1577.645996\n",
      "Train Epoch: 773 [53248/54000 (99%)] Loss: -1575.930908\n",
      "    epoch          : 773\n",
      "    loss           : -1579.0591803817388\n",
      "    ess            : 3.7949859372812424\n",
      "    log_marginal   : 1579.1855248907732\n",
      "    val_loss       : -1578.4883829752605\n",
      "    val_ess        : 3.7981358468532562\n",
      "    val_log_marginal: 1578.6156921386719\n",
      "Train Epoch: 774 [0/54000 (0%)] Loss: -1584.175903\n",
      "Train Epoch: 774 [4096/54000 (8%)] Loss: -1579.305420\n",
      "Train Epoch: 774 [8192/54000 (15%)] Loss: -1582.359985\n",
      "Train Epoch: 774 [12288/54000 (23%)] Loss: -1579.091553\n",
      "Train Epoch: 774 [16384/54000 (30%)] Loss: -1572.131470\n",
      "Train Epoch: 774 [20480/54000 (38%)] Loss: -1576.490112\n",
      "Train Epoch: 774 [24576/54000 (46%)] Loss: -1576.718384\n",
      "Train Epoch: 774 [28672/54000 (53%)] Loss: -1577.005371\n",
      "Train Epoch: 774 [32768/54000 (61%)] Loss: -1574.901978\n",
      "Train Epoch: 774 [36864/54000 (68%)] Loss: -1580.436279\n",
      "Train Epoch: 774 [40960/54000 (76%)] Loss: -1579.601318\n",
      "Train Epoch: 774 [45056/54000 (83%)] Loss: -1580.737427\n",
      "Train Epoch: 774 [49152/54000 (91%)] Loss: -1578.883545\n",
      "Train Epoch: 774 [53248/54000 (99%)] Loss: -1579.021973\n",
      "    epoch          : 774\n",
      "    loss           : -1579.1092731783176\n",
      "    ess            : 3.795332748178057\n",
      "    log_marginal   : 1579.2357756266663\n",
      "    val_loss       : -1578.971211751302\n",
      "    val_ess        : 3.7947220702966056\n",
      "    val_log_marginal: 1579.1010996500652\n",
      "Train Epoch: 775 [0/54000 (0%)] Loss: -1580.395020\n",
      "Train Epoch: 775 [4096/54000 (8%)] Loss: -1581.930176\n",
      "Train Epoch: 775 [8192/54000 (15%)] Loss: -1587.671631\n",
      "Train Epoch: 775 [12288/54000 (23%)] Loss: -1582.437256\n",
      "Train Epoch: 775 [16384/54000 (30%)] Loss: -1582.663574\n",
      "Train Epoch: 775 [20480/54000 (38%)] Loss: -1582.467529\n",
      "Train Epoch: 775 [24576/54000 (46%)] Loss: -1584.140137\n",
      "Train Epoch: 775 [28672/54000 (53%)] Loss: -1578.794434\n",
      "Train Epoch: 775 [32768/54000 (61%)] Loss: -1579.233398\n",
      "Train Epoch: 775 [36864/54000 (68%)] Loss: -1577.543945\n",
      "Train Epoch: 775 [40960/54000 (76%)] Loss: -1576.368896\n",
      "Train Epoch: 775 [45056/54000 (83%)] Loss: -1578.933838\n",
      "Train Epoch: 775 [49152/54000 (91%)] Loss: -1591.202393\n",
      "Train Epoch: 775 [53248/54000 (99%)] Loss: -1580.719604\n",
      "    epoch          : 775\n",
      "    loss           : -1579.4498800124038\n",
      "    ess            : 3.792013380764785\n",
      "    log_marginal   : 1579.5772843925874\n",
      "    val_loss       : -1579.3648020426433\n",
      "    val_ess        : 3.7964164714018502\n",
      "    val_log_marginal: 1579.4954121907551\n",
      "Train Epoch: 776 [0/54000 (0%)] Loss: -1581.493530\n",
      "Train Epoch: 776 [4096/54000 (8%)] Loss: -1580.179688\n",
      "Train Epoch: 776 [8192/54000 (15%)] Loss: -1581.440308\n",
      "Train Epoch: 776 [12288/54000 (23%)] Loss: -1580.488647\n",
      "Train Epoch: 776 [16384/54000 (30%)] Loss: -1577.611450\n",
      "Train Epoch: 776 [20480/54000 (38%)] Loss: -1579.905762\n",
      "Train Epoch: 776 [24576/54000 (46%)] Loss: -1578.511597\n",
      "Train Epoch: 776 [28672/54000 (53%)] Loss: -1578.828979\n",
      "Train Epoch: 776 [32768/54000 (61%)] Loss: -1577.876953\n",
      "Train Epoch: 776 [36864/54000 (68%)] Loss: -1574.164062\n",
      "Train Epoch: 776 [40960/54000 (76%)] Loss: -1574.201660\n",
      "Train Epoch: 776 [45056/54000 (83%)] Loss: -1578.579590\n",
      "Train Epoch: 776 [49152/54000 (91%)] Loss: -1584.581909\n",
      "Train Epoch: 776 [53248/54000 (99%)] Loss: -1585.865967\n",
      "    epoch          : 776\n",
      "    loss           : -1579.239891305354\n",
      "    ess            : 3.7941728372709447\n",
      "    log_marginal   : 1579.368256627666\n",
      "    val_loss       : -1578.756871541341\n",
      "    val_ess        : 3.7940839529037476\n",
      "    val_log_marginal: 1578.8848775227864\n",
      "Train Epoch: 777 [0/54000 (0%)] Loss: -1577.048340\n",
      "Train Epoch: 777 [4096/54000 (8%)] Loss: -1578.993408\n",
      "Train Epoch: 777 [8192/54000 (15%)] Loss: -1578.752441\n",
      "Train Epoch: 777 [12288/54000 (23%)] Loss: -1581.907471\n",
      "Train Epoch: 777 [16384/54000 (30%)] Loss: -1578.750977\n",
      "Train Epoch: 777 [20480/54000 (38%)] Loss: -1575.682373\n",
      "Train Epoch: 777 [24576/54000 (46%)] Loss: -1578.364624\n",
      "Train Epoch: 777 [28672/54000 (53%)] Loss: -1585.832275\n",
      "Train Epoch: 777 [32768/54000 (61%)] Loss: -1584.946655\n",
      "Train Epoch: 777 [36864/54000 (68%)] Loss: -1568.911865\n",
      "Train Epoch: 777 [40960/54000 (76%)] Loss: -1584.736694\n",
      "Train Epoch: 777 [45056/54000 (83%)] Loss: -1575.962769\n",
      "Train Epoch: 777 [49152/54000 (91%)] Loss: -1585.432373\n",
      "Train Epoch: 777 [53248/54000 (99%)] Loss: -1579.877563\n",
      "    epoch          : 777\n",
      "    loss           : -1579.656455957494\n",
      "    ess            : 3.7924154821730336\n",
      "    log_marginal   : 1579.7817145614263\n",
      "    val_loss       : -1578.3063151041667\n",
      "    val_ess        : 3.7942124009132385\n",
      "    val_log_marginal: 1578.433858235677\n",
      "Train Epoch: 778 [0/54000 (0%)] Loss: -1573.632080\n",
      "Train Epoch: 778 [4096/54000 (8%)] Loss: -1574.239014\n",
      "Train Epoch: 778 [8192/54000 (15%)] Loss: -1577.585693\n",
      "Train Epoch: 778 [12288/54000 (23%)] Loss: -1585.884155\n",
      "Train Epoch: 778 [16384/54000 (30%)] Loss: -1574.872070\n",
      "Train Epoch: 778 [20480/54000 (38%)] Loss: -1578.847900\n",
      "Train Epoch: 778 [24576/54000 (46%)] Loss: -1574.170166\n",
      "Train Epoch: 778 [28672/54000 (53%)] Loss: -1574.740479\n",
      "Train Epoch: 778 [32768/54000 (61%)] Loss: -1591.415527\n",
      "Train Epoch: 778 [36864/54000 (68%)] Loss: -1580.600098\n",
      "Train Epoch: 778 [40960/54000 (76%)] Loss: -1585.151123\n",
      "Train Epoch: 778 [45056/54000 (83%)] Loss: -1575.019287\n",
      "Train Epoch: 778 [49152/54000 (91%)] Loss: -1578.814209\n",
      "Train Epoch: 778 [53248/54000 (99%)] Loss: -1576.905029\n",
      "    epoch          : 778\n",
      "    loss           : -1579.4248376638404\n",
      "    ess            : 3.7953692906275744\n",
      "    log_marginal   : 1579.548160498741\n",
      "    val_loss       : -1577.7499542236328\n",
      "    val_ess        : 3.8058233559131622\n",
      "    val_log_marginal: 1577.8659413655598\n",
      "Train Epoch: 779 [0/54000 (0%)] Loss: -1575.664062\n",
      "Train Epoch: 779 [4096/54000 (8%)] Loss: -1583.888306\n",
      "Train Epoch: 779 [8192/54000 (15%)] Loss: -1581.104126\n",
      "Train Epoch: 779 [12288/54000 (23%)] Loss: -1575.023926\n",
      "Train Epoch: 779 [16384/54000 (30%)] Loss: -1582.094360\n",
      "Train Epoch: 779 [20480/54000 (38%)] Loss: -1573.899902\n",
      "Train Epoch: 779 [24576/54000 (46%)] Loss: -1583.243774\n",
      "Train Epoch: 779 [28672/54000 (53%)] Loss: -1578.174561\n",
      "Train Epoch: 779 [32768/54000 (61%)] Loss: -1576.359497\n",
      "Train Epoch: 779 [36864/54000 (68%)] Loss: -1580.239746\n",
      "Train Epoch: 779 [40960/54000 (76%)] Loss: -1570.003418\n",
      "Train Epoch: 779 [45056/54000 (83%)] Loss: -1574.658203\n",
      "Train Epoch: 779 [49152/54000 (91%)] Loss: -1581.261963\n",
      "Train Epoch: 779 [53248/54000 (99%)] Loss: -1573.320557\n",
      "    epoch          : 779\n",
      "    loss           : -1579.261073107968\n",
      "    ess            : 3.795565989345171\n",
      "    log_marginal   : 1579.387281661915\n",
      "    val_loss       : -1579.711420694987\n",
      "    val_ess        : 3.783782790104548\n",
      "    val_log_marginal: 1579.840855916341\n",
      "Train Epoch: 780 [0/54000 (0%)] Loss: -1582.557373\n",
      "Train Epoch: 780 [4096/54000 (8%)] Loss: -1577.585327\n",
      "Train Epoch: 780 [8192/54000 (15%)] Loss: -1591.103516\n",
      "Train Epoch: 780 [12288/54000 (23%)] Loss: -1576.108398\n",
      "Train Epoch: 780 [16384/54000 (30%)] Loss: -1575.035034\n",
      "Train Epoch: 780 [20480/54000 (38%)] Loss: -1580.986328\n",
      "Train Epoch: 780 [24576/54000 (46%)] Loss: -1581.527344\n",
      "Train Epoch: 780 [28672/54000 (53%)] Loss: -1583.500977\n",
      "Train Epoch: 780 [32768/54000 (61%)] Loss: -1585.947510\n",
      "Train Epoch: 780 [36864/54000 (68%)] Loss: -1573.715576\n",
      "Train Epoch: 780 [40960/54000 (76%)] Loss: -1576.729004\n",
      "Train Epoch: 780 [45056/54000 (83%)] Loss: -1583.376221\n",
      "Train Epoch: 780 [49152/54000 (91%)] Loss: -1576.585449\n",
      "Train Epoch: 780 [53248/54000 (99%)] Loss: -1580.095215\n",
      "    epoch          : 780\n",
      "    loss           : -1579.3682149733413\n",
      "    ess            : 3.7948095222220037\n",
      "    log_marginal   : 1579.493656393476\n",
      "    val_loss       : -1578.5775756835938\n",
      "    val_ess        : 3.8039364914099374\n",
      "    val_log_marginal: 1578.6961212158203\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch780.pth ...\n",
      "Train Epoch: 781 [0/54000 (0%)] Loss: -1583.072144\n",
      "Train Epoch: 781 [4096/54000 (8%)] Loss: -1580.476196\n",
      "Train Epoch: 781 [8192/54000 (15%)] Loss: -1582.338867\n",
      "Train Epoch: 781 [12288/54000 (23%)] Loss: -1583.248291\n",
      "Train Epoch: 781 [16384/54000 (30%)] Loss: -1574.130981\n",
      "Train Epoch: 781 [20480/54000 (38%)] Loss: -1583.777344\n",
      "Train Epoch: 781 [24576/54000 (46%)] Loss: -1572.136230\n",
      "Train Epoch: 781 [28672/54000 (53%)] Loss: -1576.756592\n",
      "Train Epoch: 781 [32768/54000 (61%)] Loss: -1582.004150\n",
      "Train Epoch: 781 [36864/54000 (68%)] Loss: -1580.778809\n",
      "Train Epoch: 781 [40960/54000 (76%)] Loss: -1579.914795\n",
      "Train Epoch: 781 [45056/54000 (83%)] Loss: -1579.258789\n",
      "Train Epoch: 781 [49152/54000 (91%)] Loss: -1576.644531\n",
      "Train Epoch: 781 [53248/54000 (99%)] Loss: -1577.504150\n",
      "    epoch          : 781\n",
      "    loss           : -1579.4838126666173\n",
      "    ess            : 3.7927679303698065\n",
      "    log_marginal   : 1579.6118893013181\n",
      "    val_loss       : -1579.4167175292969\n",
      "    val_ess        : 3.810234139362971\n",
      "    val_log_marginal: 1579.5284016927083\n",
      "Train Epoch: 782 [0/54000 (0%)] Loss: -1578.735840\n",
      "Train Epoch: 782 [4096/54000 (8%)] Loss: -1589.270630\n",
      "Train Epoch: 782 [8192/54000 (15%)] Loss: -1585.699463\n",
      "Train Epoch: 782 [12288/54000 (23%)] Loss: -1574.721680\n",
      "Train Epoch: 782 [16384/54000 (30%)] Loss: -1571.712158\n",
      "Train Epoch: 782 [20480/54000 (38%)] Loss: -1584.523682\n",
      "Train Epoch: 782 [24576/54000 (46%)] Loss: -1583.677002\n",
      "Train Epoch: 782 [28672/54000 (53%)] Loss: -1577.708740\n",
      "Train Epoch: 782 [32768/54000 (61%)] Loss: -1579.232422\n",
      "Train Epoch: 782 [36864/54000 (68%)] Loss: -1579.241943\n",
      "Train Epoch: 782 [40960/54000 (76%)] Loss: -1579.570068\n",
      "Train Epoch: 782 [45056/54000 (83%)] Loss: -1583.291992\n",
      "Train Epoch: 782 [49152/54000 (91%)] Loss: -1575.054932\n",
      "Train Epoch: 782 [53248/54000 (99%)] Loss: -1582.386475\n",
      "    epoch          : 782\n",
      "    loss           : -1579.4472824024363\n",
      "    ess            : 3.795003161046177\n",
      "    log_marginal   : 1579.5724542265255\n",
      "    val_loss       : -1578.4542032877605\n",
      "    val_ess        : 3.7936530311902366\n",
      "    val_log_marginal: 1578.5968983968098\n",
      "Train Epoch: 783 [0/54000 (0%)] Loss: -1579.284912\n",
      "Train Epoch: 783 [4096/54000 (8%)] Loss: -1578.470215\n",
      "Train Epoch: 783 [8192/54000 (15%)] Loss: -1579.334229\n",
      "Train Epoch: 783 [12288/54000 (23%)] Loss: -1573.577393\n",
      "Train Epoch: 783 [16384/54000 (30%)] Loss: -1578.419189\n",
      "Train Epoch: 783 [20480/54000 (38%)] Loss: -1571.876221\n",
      "Train Epoch: 783 [24576/54000 (46%)] Loss: -1578.727539\n",
      "Train Epoch: 783 [28672/54000 (53%)] Loss: -1583.819092\n",
      "Train Epoch: 783 [32768/54000 (61%)] Loss: -1579.208862\n",
      "Train Epoch: 783 [36864/54000 (68%)] Loss: -1584.258667\n",
      "Train Epoch: 783 [40960/54000 (76%)] Loss: -1579.883789\n",
      "Train Epoch: 783 [45056/54000 (83%)] Loss: -1580.428833\n",
      "Train Epoch: 783 [49152/54000 (91%)] Loss: -1577.318848\n",
      "Train Epoch: 783 [53248/54000 (99%)] Loss: -1584.818237\n",
      "    epoch          : 783\n",
      "    loss           : -1579.3645112096415\n",
      "    ess            : 3.790539373153759\n",
      "    log_marginal   : 1579.4946879165432\n",
      "    val_loss       : -1578.8909098307292\n",
      "    val_ess        : 3.7947880228360495\n",
      "    val_log_marginal: 1579.0127563476562\n",
      "Train Epoch: 784 [0/54000 (0%)] Loss: -1587.417969\n",
      "Train Epoch: 784 [4096/54000 (8%)] Loss: -1578.084961\n",
      "Train Epoch: 784 [8192/54000 (15%)] Loss: -1583.828857\n",
      "Train Epoch: 784 [12288/54000 (23%)] Loss: -1584.741699\n",
      "Train Epoch: 784 [16384/54000 (30%)] Loss: -1578.787720\n",
      "Train Epoch: 784 [20480/54000 (38%)] Loss: -1581.572876\n",
      "Train Epoch: 784 [24576/54000 (46%)] Loss: -1577.674438\n",
      "Train Epoch: 784 [28672/54000 (53%)] Loss: -1580.740479\n",
      "Train Epoch: 784 [32768/54000 (61%)] Loss: -1580.778809\n",
      "Train Epoch: 784 [36864/54000 (68%)] Loss: -1574.192749\n",
      "Train Epoch: 784 [40960/54000 (76%)] Loss: -1581.388916\n",
      "Train Epoch: 784 [45056/54000 (83%)] Loss: -1578.867432\n",
      "Train Epoch: 784 [49152/54000 (91%)] Loss: -1581.381348\n",
      "Train Epoch: 784 [53248/54000 (99%)] Loss: -1581.283203\n",
      "    epoch          : 784\n",
      "    loss           : -1579.759063286804\n",
      "    ess            : 3.7968624033634133\n",
      "    log_marginal   : 1579.881837673097\n",
      "    val_loss       : -1579.2050679524739\n",
      "    val_ess        : 3.789726654688517\n",
      "    val_log_marginal: 1579.3355051676433\n",
      "Train Epoch: 785 [0/54000 (0%)] Loss: -1578.965576\n",
      "Train Epoch: 785 [4096/54000 (8%)] Loss: -1579.650513\n",
      "Train Epoch: 785 [8192/54000 (15%)] Loss: -1584.467529\n",
      "Train Epoch: 785 [12288/54000 (23%)] Loss: -1580.839355\n",
      "Train Epoch: 785 [16384/54000 (30%)] Loss: -1573.561157\n",
      "Train Epoch: 785 [20480/54000 (38%)] Loss: -1575.361694\n",
      "Train Epoch: 785 [24576/54000 (46%)] Loss: -1582.675415\n",
      "Train Epoch: 785 [28672/54000 (53%)] Loss: -1579.616455\n",
      "Train Epoch: 785 [32768/54000 (61%)] Loss: -1583.393921\n",
      "Train Epoch: 785 [36864/54000 (68%)] Loss: -1582.538086\n",
      "Train Epoch: 785 [40960/54000 (76%)] Loss: -1578.792725\n",
      "Train Epoch: 785 [45056/54000 (83%)] Loss: -1579.577148\n",
      "Train Epoch: 785 [49152/54000 (91%)] Loss: -1578.425293\n",
      "Train Epoch: 785 [53248/54000 (99%)] Loss: -1578.369141\n",
      "    epoch          : 785\n",
      "    loss           : -1579.9141255600193\n",
      "    ess            : 3.792590830563369\n",
      "    log_marginal   : 1580.0432724794505\n",
      "    val_loss       : -1579.363016764323\n",
      "    val_ess        : 3.792314718166987\n",
      "    val_log_marginal: 1579.5025787353516\n",
      "Train Epoch: 786 [0/54000 (0%)] Loss: -1577.139160\n",
      "Train Epoch: 786 [4096/54000 (8%)] Loss: -1583.362915\n",
      "Train Epoch: 786 [8192/54000 (15%)] Loss: -1574.236328\n",
      "Train Epoch: 786 [12288/54000 (23%)] Loss: -1581.175781\n",
      "Train Epoch: 786 [16384/54000 (30%)] Loss: -1579.821289\n",
      "Train Epoch: 786 [20480/54000 (38%)] Loss: -1575.513672\n",
      "Train Epoch: 786 [24576/54000 (46%)] Loss: -1579.094971\n",
      "Train Epoch: 786 [28672/54000 (53%)] Loss: -1574.386719\n",
      "Train Epoch: 786 [32768/54000 (61%)] Loss: -1583.083862\n",
      "Train Epoch: 786 [36864/54000 (68%)] Loss: -1587.257568\n",
      "Train Epoch: 786 [40960/54000 (76%)] Loss: -1579.322144\n",
      "Train Epoch: 786 [45056/54000 (83%)] Loss: -1578.803223\n",
      "Train Epoch: 786 [49152/54000 (91%)] Loss: -1583.119263\n",
      "Train Epoch: 786 [53248/54000 (99%)] Loss: -1583.430176\n",
      "    epoch          : 786\n",
      "    loss           : -1579.851959951681\n",
      "    ess            : 3.794479731699867\n",
      "    log_marginal   : 1579.9793921014143\n",
      "    val_loss       : -1580.3213297526042\n",
      "    val_ess        : 3.787507871786753\n",
      "    val_log_marginal: 1580.458043416341\n",
      "Train Epoch: 787 [0/54000 (0%)] Loss: -1574.763550\n",
      "Train Epoch: 787 [4096/54000 (8%)] Loss: -1574.843262\n",
      "Train Epoch: 787 [8192/54000 (15%)] Loss: -1579.258301\n",
      "Train Epoch: 787 [12288/54000 (23%)] Loss: -1583.394165\n",
      "Train Epoch: 787 [16384/54000 (30%)] Loss: -1580.821411\n",
      "Train Epoch: 787 [20480/54000 (38%)] Loss: -1580.058838\n",
      "Train Epoch: 787 [24576/54000 (46%)] Loss: -1577.178589\n",
      "Train Epoch: 787 [28672/54000 (53%)] Loss: -1580.245850\n",
      "Train Epoch: 787 [32768/54000 (61%)] Loss: -1578.639404\n",
      "Train Epoch: 787 [36864/54000 (68%)] Loss: -1572.886963\n",
      "Train Epoch: 787 [40960/54000 (76%)] Loss: -1570.217041\n",
      "Train Epoch: 787 [45056/54000 (83%)] Loss: -1580.067627\n",
      "Train Epoch: 787 [49152/54000 (91%)] Loss: -1582.659668\n",
      "Train Epoch: 787 [53248/54000 (99%)] Loss: -1584.046753\n",
      "    epoch          : 787\n",
      "    loss           : -1579.719676230191\n",
      "    ess            : 3.7929016865825202\n",
      "    log_marginal   : 1579.8513160452458\n",
      "    val_loss       : -1579.7857157389324\n",
      "    val_ess        : 3.7965645690759025\n",
      "    val_log_marginal: 1579.9068857828777\n",
      "Train Epoch: 788 [0/54000 (0%)] Loss: -1580.357300\n",
      "Train Epoch: 788 [4096/54000 (8%)] Loss: -1580.803955\n",
      "Train Epoch: 788 [8192/54000 (15%)] Loss: -1583.377930\n",
      "Train Epoch: 788 [12288/54000 (23%)] Loss: -1579.274414\n",
      "Train Epoch: 788 [16384/54000 (30%)] Loss: -1579.607422\n",
      "Train Epoch: 788 [20480/54000 (38%)] Loss: -1578.052124\n",
      "Train Epoch: 788 [24576/54000 (46%)] Loss: -1581.439453\n",
      "Train Epoch: 788 [28672/54000 (53%)] Loss: -1579.541260\n",
      "Train Epoch: 788 [32768/54000 (61%)] Loss: -1577.802368\n",
      "Train Epoch: 788 [36864/54000 (68%)] Loss: -1584.795532\n",
      "Train Epoch: 788 [40960/54000 (76%)] Loss: -1584.399414\n",
      "Train Epoch: 788 [45056/54000 (83%)] Loss: -1578.190674\n",
      "Train Epoch: 788 [49152/54000 (91%)] Loss: -1577.827393\n",
      "Train Epoch: 788 [53248/54000 (99%)] Loss: -1584.161377\n",
      "    epoch          : 788\n",
      "    loss           : -1579.6758130692758\n",
      "    ess            : 3.792370123885819\n",
      "    log_marginal   : 1579.805900103673\n",
      "    val_loss       : -1578.8896382649739\n",
      "    val_ess        : 3.7913638651371\n",
      "    val_log_marginal: 1579.0170796712239\n",
      "Train Epoch: 789 [0/54000 (0%)] Loss: -1581.260864\n",
      "Train Epoch: 789 [4096/54000 (8%)] Loss: -1577.733643\n",
      "Train Epoch: 789 [8192/54000 (15%)] Loss: -1586.330322\n",
      "Train Epoch: 789 [12288/54000 (23%)] Loss: -1581.972168\n",
      "Train Epoch: 789 [16384/54000 (30%)] Loss: -1582.041260\n",
      "Train Epoch: 789 [20480/54000 (38%)] Loss: -1580.053711\n",
      "Train Epoch: 789 [24576/54000 (46%)] Loss: -1577.314941\n",
      "Train Epoch: 789 [28672/54000 (53%)] Loss: -1586.522339\n",
      "Train Epoch: 789 [32768/54000 (61%)] Loss: -1576.498779\n",
      "Train Epoch: 789 [36864/54000 (68%)] Loss: -1579.548096\n",
      "Train Epoch: 789 [40960/54000 (76%)] Loss: -1580.569580\n",
      "Train Epoch: 789 [45056/54000 (83%)] Loss: -1580.611572\n",
      "Train Epoch: 789 [49152/54000 (91%)] Loss: -1585.714722\n",
      "Train Epoch: 789 [53248/54000 (99%)] Loss: -1578.656860\n",
      "    epoch          : 789\n",
      "    loss           : -1579.4730635367298\n",
      "    ess            : 3.7919441930490647\n",
      "    log_marginal   : 1579.6047351710604\n",
      "    val_loss       : -1578.531717936198\n",
      "    val_ess        : 3.8069820006688437\n",
      "    val_log_marginal: 1578.6548156738281\n",
      "Train Epoch: 790 [0/54000 (0%)] Loss: -1581.524170\n",
      "Train Epoch: 790 [4096/54000 (8%)] Loss: -1581.157227\n",
      "Train Epoch: 790 [8192/54000 (15%)] Loss: -1579.686035\n",
      "Train Epoch: 790 [12288/54000 (23%)] Loss: -1579.184204\n",
      "Train Epoch: 790 [16384/54000 (30%)] Loss: -1584.393188\n",
      "Train Epoch: 790 [20480/54000 (38%)] Loss: -1573.634521\n",
      "Train Epoch: 790 [24576/54000 (46%)] Loss: -1576.095215\n",
      "Train Epoch: 790 [28672/54000 (53%)] Loss: -1573.820679\n",
      "Train Epoch: 790 [32768/54000 (61%)] Loss: -1578.588257\n",
      "Train Epoch: 790 [36864/54000 (68%)] Loss: -1584.071045\n",
      "Train Epoch: 790 [40960/54000 (76%)] Loss: -1574.268066\n",
      "Train Epoch: 790 [45056/54000 (83%)] Loss: -1583.139160\n",
      "Train Epoch: 790 [49152/54000 (91%)] Loss: -1578.889404\n",
      "Train Epoch: 790 [53248/54000 (99%)] Loss: -1580.873535\n",
      "    epoch          : 790\n",
      "    loss           : -1579.5711669921875\n",
      "    ess            : 3.793699700685474\n",
      "    log_marginal   : 1579.6958100377665\n",
      "    val_loss       : -1579.8289031982422\n",
      "    val_ess        : 3.7879933615525565\n",
      "    val_log_marginal: 1579.9675547281902\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch790.pth ...\n",
      "Train Epoch: 791 [0/54000 (0%)] Loss: -1578.623047\n",
      "Train Epoch: 791 [4096/54000 (8%)] Loss: -1587.682129\n",
      "Train Epoch: 791 [8192/54000 (15%)] Loss: -1580.012085\n",
      "Train Epoch: 791 [12288/54000 (23%)] Loss: -1580.155518\n",
      "Train Epoch: 791 [16384/54000 (30%)] Loss: -1581.611816\n",
      "Train Epoch: 791 [20480/54000 (38%)] Loss: -1584.572510\n",
      "Train Epoch: 791 [24576/54000 (46%)] Loss: -1580.104736\n",
      "Train Epoch: 791 [28672/54000 (53%)] Loss: -1576.364258\n",
      "Train Epoch: 791 [32768/54000 (61%)] Loss: -1581.296631\n",
      "Train Epoch: 791 [36864/54000 (68%)] Loss: -1581.953125\n",
      "Train Epoch: 791 [40960/54000 (76%)] Loss: -1578.294922\n",
      "Train Epoch: 791 [45056/54000 (83%)] Loss: -1581.253174\n",
      "Train Epoch: 791 [49152/54000 (91%)] Loss: -1581.518311\n",
      "Train Epoch: 791 [53248/54000 (99%)] Loss: -1578.833740\n",
      "    epoch          : 791\n",
      "    loss           : -1579.8391066998668\n",
      "    ess            : 3.7914277275591663\n",
      "    log_marginal   : 1579.9678312907288\n",
      "    val_loss       : -1579.8246968587239\n",
      "    val_ess        : 3.792599360148112\n",
      "    val_log_marginal: 1579.9568939208984\n",
      "Train Epoch: 792 [0/54000 (0%)] Loss: -1580.151245\n",
      "Train Epoch: 792 [4096/54000 (8%)] Loss: -1582.562744\n",
      "Train Epoch: 792 [8192/54000 (15%)] Loss: -1577.799927\n",
      "Train Epoch: 792 [12288/54000 (23%)] Loss: -1582.760986\n",
      "Train Epoch: 792 [16384/54000 (30%)] Loss: -1578.356079\n",
      "Train Epoch: 792 [20480/54000 (38%)] Loss: -1579.523193\n",
      "Train Epoch: 792 [24576/54000 (46%)] Loss: -1579.163330\n",
      "Train Epoch: 792 [28672/54000 (53%)] Loss: -1582.979248\n",
      "Train Epoch: 792 [32768/54000 (61%)] Loss: -1583.467041\n",
      "Train Epoch: 792 [36864/54000 (68%)] Loss: -1578.794678\n",
      "Train Epoch: 792 [40960/54000 (76%)] Loss: -1576.349976\n",
      "Train Epoch: 792 [45056/54000 (83%)] Loss: -1581.376831\n",
      "Train Epoch: 792 [49152/54000 (91%)] Loss: -1575.976318\n",
      "Train Epoch: 792 [53248/54000 (99%)] Loss: -1578.861450\n",
      "    epoch          : 792\n",
      "    loss           : -1579.7192660507997\n",
      "    ess            : 3.7935373127742964\n",
      "    log_marginal   : 1579.850031125037\n",
      "    val_loss       : -1578.696029663086\n",
      "    val_ess        : 3.780545840660731\n",
      "    val_log_marginal: 1578.8357238769531\n",
      "Train Epoch: 793 [0/54000 (0%)] Loss: -1580.309570\n",
      "Train Epoch: 793 [4096/54000 (8%)] Loss: -1580.547363\n",
      "Train Epoch: 793 [8192/54000 (15%)] Loss: -1580.312012\n",
      "Train Epoch: 793 [12288/54000 (23%)] Loss: -1582.052979\n",
      "Train Epoch: 793 [16384/54000 (30%)] Loss: -1576.570435\n",
      "Train Epoch: 793 [20480/54000 (38%)] Loss: -1578.569702\n",
      "Train Epoch: 793 [24576/54000 (46%)] Loss: -1582.526001\n",
      "Train Epoch: 793 [28672/54000 (53%)] Loss: -1578.667603\n",
      "Train Epoch: 793 [32768/54000 (61%)] Loss: -1575.078979\n",
      "Train Epoch: 793 [36864/54000 (68%)] Loss: -1576.715820\n",
      "Train Epoch: 793 [40960/54000 (76%)] Loss: -1583.542969\n",
      "Train Epoch: 793 [45056/54000 (83%)] Loss: -1584.784180\n",
      "Train Epoch: 793 [49152/54000 (91%)] Loss: -1582.656738\n",
      "Train Epoch: 793 [53248/54000 (99%)] Loss: -1583.162598\n",
      "    epoch          : 793\n",
      "    loss           : -1579.9253421439944\n",
      "    ess            : 3.793845736019984\n",
      "    log_marginal   : 1580.0539689629\n",
      "    val_loss       : -1579.6970469156902\n",
      "    val_ess        : 3.806780536969503\n",
      "    val_log_marginal: 1579.8173522949219\n",
      "Train Epoch: 794 [0/54000 (0%)] Loss: -1582.619385\n",
      "Train Epoch: 794 [4096/54000 (8%)] Loss: -1577.699951\n",
      "Train Epoch: 794 [8192/54000 (15%)] Loss: -1579.476807\n",
      "Train Epoch: 794 [12288/54000 (23%)] Loss: -1571.292969\n",
      "Train Epoch: 794 [16384/54000 (30%)] Loss: -1577.484619\n",
      "Train Epoch: 794 [20480/54000 (38%)] Loss: -1584.270386\n",
      "Train Epoch: 794 [24576/54000 (46%)] Loss: -1581.611084\n",
      "Train Epoch: 794 [28672/54000 (53%)] Loss: -1582.284180\n",
      "Train Epoch: 794 [32768/54000 (61%)] Loss: -1579.283813\n",
      "Train Epoch: 794 [36864/54000 (68%)] Loss: -1577.130859\n",
      "Train Epoch: 794 [40960/54000 (76%)] Loss: -1578.538330\n",
      "Train Epoch: 794 [45056/54000 (83%)] Loss: -1585.504883\n",
      "Train Epoch: 794 [49152/54000 (91%)] Loss: -1581.170166\n",
      "Train Epoch: 794 [53248/54000 (99%)] Loss: -1572.971436\n",
      "    epoch          : 794\n",
      "    loss           : -1580.0210406407361\n",
      "    ess            : 3.7941550225443184\n",
      "    log_marginal   : 1580.1480244279473\n",
      "    val_loss       : -1579.722620646159\n",
      "    val_ess        : 3.8065936267375946\n",
      "    val_log_marginal: 1579.8452453613281\n",
      "Train Epoch: 795 [0/54000 (0%)] Loss: -1576.396851\n",
      "Train Epoch: 795 [4096/54000 (8%)] Loss: -1578.238037\n",
      "Train Epoch: 795 [8192/54000 (15%)] Loss: -1577.579956\n",
      "Train Epoch: 795 [12288/54000 (23%)] Loss: -1583.207520\n",
      "Train Epoch: 795 [16384/54000 (30%)] Loss: -1585.790405\n",
      "Train Epoch: 795 [20480/54000 (38%)] Loss: -1576.597656\n",
      "Train Epoch: 795 [24576/54000 (46%)] Loss: -1584.643677\n",
      "Train Epoch: 795 [28672/54000 (53%)] Loss: -1583.590332\n",
      "Train Epoch: 795 [32768/54000 (61%)] Loss: -1590.415283\n",
      "Train Epoch: 795 [36864/54000 (68%)] Loss: -1582.466431\n",
      "Train Epoch: 795 [40960/54000 (76%)] Loss: -1580.912598\n",
      "Train Epoch: 795 [45056/54000 (83%)] Loss: -1573.209717\n",
      "Train Epoch: 795 [49152/54000 (91%)] Loss: -1583.494141\n",
      "Train Epoch: 795 [53248/54000 (99%)] Loss: -1578.734619\n",
      "    epoch          : 795\n",
      "    loss           : -1580.1308044144328\n",
      "    ess            : 3.7970923236196077\n",
      "    log_marginal   : 1580.2551506729487\n",
      "    val_loss       : -1580.3036600748699\n",
      "    val_ess        : 3.797091672817866\n",
      "    val_log_marginal: 1580.4335072835286\n",
      "Train Epoch: 796 [0/54000 (0%)] Loss: -1581.642212\n",
      "Train Epoch: 796 [4096/54000 (8%)] Loss: -1577.547485\n",
      "Train Epoch: 796 [8192/54000 (15%)] Loss: -1577.302002\n",
      "Train Epoch: 796 [12288/54000 (23%)] Loss: -1581.706299\n",
      "Train Epoch: 796 [16384/54000 (30%)] Loss: -1579.628906\n",
      "Train Epoch: 796 [20480/54000 (38%)] Loss: -1580.137573\n",
      "Train Epoch: 796 [24576/54000 (46%)] Loss: -1577.700928\n",
      "Train Epoch: 796 [28672/54000 (53%)] Loss: -1579.662354\n",
      "Train Epoch: 796 [32768/54000 (61%)] Loss: -1580.163086\n",
      "Train Epoch: 796 [36864/54000 (68%)] Loss: -1578.478638\n",
      "Train Epoch: 796 [40960/54000 (76%)] Loss: -1578.765381\n",
      "Train Epoch: 796 [45056/54000 (83%)] Loss: -1579.933105\n",
      "Train Epoch: 796 [49152/54000 (91%)] Loss: -1577.699707\n",
      "Train Epoch: 796 [53248/54000 (99%)] Loss: -1583.834595\n",
      "    epoch          : 796\n",
      "    loss           : -1580.4784543005776\n",
      "    ess            : 3.7949154004101504\n",
      "    log_marginal   : 1580.6055023048727\n",
      "    val_loss       : -1579.4673919677734\n",
      "    val_ess        : 3.805171569188436\n",
      "    val_log_marginal: 1579.5841725667317\n",
      "Train Epoch: 797 [0/54000 (0%)] Loss: -1582.677368\n",
      "Train Epoch: 797 [4096/54000 (8%)] Loss: -1577.424194\n",
      "Train Epoch: 797 [8192/54000 (15%)] Loss: -1583.413696\n",
      "Train Epoch: 797 [12288/54000 (23%)] Loss: -1583.142212\n",
      "Train Epoch: 797 [16384/54000 (30%)] Loss: -1579.037842\n",
      "Train Epoch: 797 [20480/54000 (38%)] Loss: -1575.971313\n",
      "Train Epoch: 797 [24576/54000 (46%)] Loss: -1577.232544\n",
      "Train Epoch: 797 [28672/54000 (53%)] Loss: -1574.062744\n",
      "Train Epoch: 797 [32768/54000 (61%)] Loss: -1583.819824\n",
      "Train Epoch: 797 [36864/54000 (68%)] Loss: -1576.325073\n",
      "Train Epoch: 797 [40960/54000 (76%)] Loss: -1579.375488\n",
      "Train Epoch: 797 [45056/54000 (83%)] Loss: -1580.627930\n",
      "Train Epoch: 797 [49152/54000 (91%)] Loss: -1584.092773\n",
      "Train Epoch: 797 [53248/54000 (99%)] Loss: -1594.243652\n",
      "    epoch          : 797\n",
      "    loss           : -1579.9011294107302\n",
      "    ess            : 3.7928144287724064\n",
      "    log_marginal   : 1580.028245681835\n",
      "    val_loss       : -1580.1827239990234\n",
      "    val_ess        : 3.7894848783810935\n",
      "    val_log_marginal: 1580.3160654703777\n",
      "Train Epoch: 798 [0/54000 (0%)] Loss: -1581.746216\n",
      "Train Epoch: 798 [4096/54000 (8%)] Loss: -1578.024170\n",
      "Train Epoch: 798 [8192/54000 (15%)] Loss: -1583.935547\n",
      "Train Epoch: 798 [12288/54000 (23%)] Loss: -1580.180664\n",
      "Train Epoch: 798 [16384/54000 (30%)] Loss: -1588.668823\n",
      "Train Epoch: 798 [20480/54000 (38%)] Loss: -1576.289062\n",
      "Train Epoch: 798 [24576/54000 (46%)] Loss: -1586.670654\n",
      "Train Epoch: 798 [28672/54000 (53%)] Loss: -1575.486938\n",
      "Train Epoch: 798 [32768/54000 (61%)] Loss: -1582.129639\n",
      "Train Epoch: 798 [36864/54000 (68%)] Loss: -1576.592041\n",
      "Train Epoch: 798 [40960/54000 (76%)] Loss: -1574.151123\n",
      "Train Epoch: 798 [45056/54000 (83%)] Loss: -1584.090088\n",
      "Train Epoch: 798 [49152/54000 (91%)] Loss: -1582.062500\n",
      "Train Epoch: 798 [53248/54000 (99%)] Loss: -1581.521362\n",
      "    epoch          : 798\n",
      "    loss           : -1580.095347906176\n",
      "    ess            : 3.7900048307897922\n",
      "    log_marginal   : 1580.2269402815832\n",
      "    val_loss       : -1579.4889831542969\n",
      "    val_ess        : 3.7967008550961814\n",
      "    val_log_marginal: 1579.608118693034\n",
      "Train Epoch: 799 [0/54000 (0%)] Loss: -1579.954590\n",
      "Train Epoch: 799 [4096/54000 (8%)] Loss: -1584.083496\n",
      "Train Epoch: 799 [8192/54000 (15%)] Loss: -1577.286865\n",
      "Train Epoch: 799 [12288/54000 (23%)] Loss: -1585.465820\n",
      "Train Epoch: 799 [16384/54000 (30%)] Loss: -1585.312866\n",
      "Train Epoch: 799 [20480/54000 (38%)] Loss: -1579.730713\n",
      "Train Epoch: 799 [24576/54000 (46%)] Loss: -1584.609253\n",
      "Train Epoch: 799 [28672/54000 (53%)] Loss: -1576.510498\n",
      "Train Epoch: 799 [32768/54000 (61%)] Loss: -1583.272949\n",
      "Train Epoch: 799 [36864/54000 (68%)] Loss: -1581.177734\n",
      "Train Epoch: 799 [40960/54000 (76%)] Loss: -1573.471680\n",
      "Train Epoch: 799 [45056/54000 (83%)] Loss: -1582.112915\n",
      "Train Epoch: 799 [49152/54000 (91%)] Loss: -1574.887817\n",
      "Train Epoch: 799 [53248/54000 (99%)] Loss: -1581.952271\n",
      "    epoch          : 799\n",
      "    loss           : -1580.1851528945128\n",
      "    ess            : 3.7930512586476115\n",
      "    log_marginal   : 1580.3129495195867\n",
      "    val_loss       : -1579.4696299235027\n",
      "    val_ess        : 3.789256582657496\n",
      "    val_log_marginal: 1579.5915425618489\n",
      "Train Epoch: 800 [0/54000 (0%)] Loss: -1578.805908\n",
      "Train Epoch: 800 [4096/54000 (8%)] Loss: -1575.530640\n",
      "Train Epoch: 800 [8192/54000 (15%)] Loss: -1580.650513\n",
      "Train Epoch: 800 [12288/54000 (23%)] Loss: -1579.267334\n",
      "Train Epoch: 800 [16384/54000 (30%)] Loss: -1583.291748\n",
      "Train Epoch: 800 [20480/54000 (38%)] Loss: -1577.740601\n",
      "Train Epoch: 800 [24576/54000 (46%)] Loss: -1582.199097\n",
      "Train Epoch: 800 [28672/54000 (53%)] Loss: -1580.067871\n",
      "Train Epoch: 800 [32768/54000 (61%)] Loss: -1585.351807\n",
      "Train Epoch: 800 [36864/54000 (68%)] Loss: -1585.977417\n",
      "Train Epoch: 800 [40960/54000 (76%)] Loss: -1580.025757\n",
      "Train Epoch: 800 [45056/54000 (83%)] Loss: -1576.775269\n",
      "Train Epoch: 800 [49152/54000 (91%)] Loss: -1581.607300\n",
      "Train Epoch: 800 [53248/54000 (99%)] Loss: -1579.039551\n",
      "    epoch          : 800\n",
      "    loss           : -1580.2745824153953\n",
      "    ess            : 3.7942768340992137\n",
      "    log_marginal   : 1580.400122186019\n",
      "    val_loss       : -1580.0433959960938\n",
      "    val_ess        : 3.793300767739614\n",
      "    val_log_marginal: 1580.1708526611328\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [0/54000 (0%)] Loss: -1577.124268\n",
      "Train Epoch: 801 [4096/54000 (8%)] Loss: -1588.948853\n",
      "Train Epoch: 801 [8192/54000 (15%)] Loss: -1581.705811\n",
      "Train Epoch: 801 [12288/54000 (23%)] Loss: -1583.149170\n",
      "Train Epoch: 801 [16384/54000 (30%)] Loss: -1579.591309\n",
      "Train Epoch: 801 [20480/54000 (38%)] Loss: -1575.593384\n",
      "Train Epoch: 801 [24576/54000 (46%)] Loss: -1574.598633\n",
      "Train Epoch: 801 [28672/54000 (53%)] Loss: -1578.234863\n",
      "Train Epoch: 801 [32768/54000 (61%)] Loss: -1579.694458\n",
      "Train Epoch: 801 [36864/54000 (68%)] Loss: -1581.761475\n",
      "Train Epoch: 801 [40960/54000 (76%)] Loss: -1578.231079\n",
      "Train Epoch: 801 [45056/54000 (83%)] Loss: -1580.553955\n",
      "Train Epoch: 801 [49152/54000 (91%)] Loss: -1579.954834\n",
      "Train Epoch: 801 [53248/54000 (99%)] Loss: -1576.830688\n",
      "    epoch          : 801\n",
      "    loss           : -1580.2261598415284\n",
      "    ess            : 3.792853636764237\n",
      "    log_marginal   : 1580.3564441554354\n",
      "    val_loss       : -1580.0536244710286\n",
      "    val_ess        : 3.799346089363098\n",
      "    val_log_marginal: 1580.1652018229167\n",
      "Train Epoch: 802 [0/54000 (0%)] Loss: -1581.569336\n",
      "Train Epoch: 802 [4096/54000 (8%)] Loss: -1576.789795\n",
      "Train Epoch: 802 [8192/54000 (15%)] Loss: -1582.184326\n",
      "Train Epoch: 802 [12288/54000 (23%)] Loss: -1576.190063\n",
      "Train Epoch: 802 [16384/54000 (30%)] Loss: -1582.108887\n",
      "Train Epoch: 802 [20480/54000 (38%)] Loss: -1571.722412\n",
      "Train Epoch: 802 [24576/54000 (46%)] Loss: -1580.217041\n",
      "Train Epoch: 802 [28672/54000 (53%)] Loss: -1583.556030\n",
      "Train Epoch: 802 [32768/54000 (61%)] Loss: -1575.940430\n",
      "Train Epoch: 802 [36864/54000 (68%)] Loss: -1582.017090\n",
      "Train Epoch: 802 [40960/54000 (76%)] Loss: -1582.052246\n",
      "Train Epoch: 802 [45056/54000 (83%)] Loss: -1576.999268\n",
      "Train Epoch: 802 [49152/54000 (91%)] Loss: -1586.187500\n",
      "Train Epoch: 802 [53248/54000 (99%)] Loss: -1581.567871\n",
      "    epoch          : 802\n",
      "    loss           : -1580.37542753536\n",
      "    ess            : 3.7920542102289425\n",
      "    log_marginal   : 1580.5052108403065\n",
      "    val_loss       : -1580.005620320638\n",
      "    val_ess        : 3.794811189174652\n",
      "    val_log_marginal: 1580.1341451009114\n",
      "Train Epoch: 803 [0/54000 (0%)] Loss: -1574.853638\n",
      "Train Epoch: 803 [4096/54000 (8%)] Loss: -1577.329102\n",
      "Train Epoch: 803 [8192/54000 (15%)] Loss: -1578.306885\n",
      "Train Epoch: 803 [12288/54000 (23%)] Loss: -1575.704834\n",
      "Train Epoch: 803 [16384/54000 (30%)] Loss: -1583.692383\n",
      "Train Epoch: 803 [20480/54000 (38%)] Loss: -1583.112427\n",
      "Train Epoch: 803 [24576/54000 (46%)] Loss: -1580.731567\n",
      "Train Epoch: 803 [28672/54000 (53%)] Loss: -1582.593018\n",
      "Train Epoch: 803 [32768/54000 (61%)] Loss: -1580.656128\n",
      "Train Epoch: 803 [36864/54000 (68%)] Loss: -1578.509277\n",
      "Train Epoch: 803 [40960/54000 (76%)] Loss: -1590.207764\n",
      "Train Epoch: 803 [45056/54000 (83%)] Loss: -1579.012451\n",
      "Train Epoch: 803 [49152/54000 (91%)] Loss: -1584.749878\n",
      "Train Epoch: 803 [53248/54000 (99%)] Loss: -1582.998291\n",
      "    epoch          : 803\n",
      "    loss           : -1580.4230667765107\n",
      "    ess            : 3.790547543792363\n",
      "    log_marginal   : 1580.5526950348044\n",
      "    val_loss       : -1579.715835571289\n",
      "    val_ess        : 3.792930821577708\n",
      "    val_log_marginal: 1579.838363647461\n",
      "Train Epoch: 804 [0/54000 (0%)] Loss: -1576.874512\n",
      "Train Epoch: 804 [4096/54000 (8%)] Loss: -1582.031982\n",
      "Train Epoch: 804 [8192/54000 (15%)] Loss: -1578.061523\n",
      "Train Epoch: 804 [12288/54000 (23%)] Loss: -1579.748535\n",
      "Train Epoch: 804 [16384/54000 (30%)] Loss: -1584.189819\n",
      "Train Epoch: 804 [20480/54000 (38%)] Loss: -1573.816528\n",
      "Train Epoch: 804 [24576/54000 (46%)] Loss: -1572.376709\n",
      "Train Epoch: 804 [28672/54000 (53%)] Loss: -1574.564453\n",
      "Train Epoch: 804 [32768/54000 (61%)] Loss: -1578.008057\n",
      "Train Epoch: 804 [36864/54000 (68%)] Loss: -1579.624023\n",
      "Train Epoch: 804 [40960/54000 (76%)] Loss: -1577.306885\n",
      "Train Epoch: 804 [45056/54000 (83%)] Loss: -1582.580811\n",
      "Train Epoch: 804 [49152/54000 (91%)] Loss: -1582.887695\n",
      "Train Epoch: 804 [53248/54000 (99%)] Loss: -1576.498291\n",
      "    epoch          : 804\n",
      "    loss           : -1580.4322972591453\n",
      "    ess            : 3.792977222334152\n",
      "    log_marginal   : 1580.5644097350785\n",
      "    val_loss       : -1579.6666564941406\n",
      "    val_ess        : 3.7982560892899833\n",
      "    val_log_marginal: 1579.7848663330078\n",
      "Train Epoch: 805 [0/54000 (0%)] Loss: -1588.015991\n",
      "Train Epoch: 805 [4096/54000 (8%)] Loss: -1575.716309\n",
      "Train Epoch: 805 [8192/54000 (15%)] Loss: -1580.115723\n",
      "Train Epoch: 805 [12288/54000 (23%)] Loss: -1580.394043\n",
      "Train Epoch: 805 [16384/54000 (30%)] Loss: -1578.290039\n",
      "Train Epoch: 805 [20480/54000 (38%)] Loss: -1575.725952\n",
      "Train Epoch: 805 [24576/54000 (46%)] Loss: -1580.108032\n",
      "Train Epoch: 805 [28672/54000 (53%)] Loss: -1585.544556\n",
      "Train Epoch: 805 [32768/54000 (61%)] Loss: -1580.047852\n",
      "Train Epoch: 805 [36864/54000 (68%)] Loss: -1580.082642\n",
      "Train Epoch: 805 [40960/54000 (76%)] Loss: -1586.463379\n",
      "Train Epoch: 805 [45056/54000 (83%)] Loss: -1584.385376\n",
      "Train Epoch: 805 [49152/54000 (91%)] Loss: -1581.528687\n",
      "Train Epoch: 805 [53248/54000 (99%)] Loss: -1587.364258\n",
      "    epoch          : 805\n",
      "    loss           : -1580.4500512579607\n",
      "    ess            : 3.791424284614093\n",
      "    log_marginal   : 1580.5795967861375\n",
      "    val_loss       : -1580.6153259277344\n",
      "    val_ess        : 3.799919714530309\n",
      "    val_log_marginal: 1580.744405110677\n",
      "Train Epoch: 806 [0/54000 (0%)] Loss: -1581.967529\n",
      "Train Epoch: 806 [4096/54000 (8%)] Loss: -1586.125244\n",
      "Train Epoch: 806 [8192/54000 (15%)] Loss: -1577.085938\n",
      "Train Epoch: 806 [12288/54000 (23%)] Loss: -1582.428833\n",
      "Train Epoch: 806 [16384/54000 (30%)] Loss: -1580.967041\n",
      "Train Epoch: 806 [20480/54000 (38%)] Loss: -1579.508789\n",
      "Train Epoch: 806 [24576/54000 (46%)] Loss: -1578.676636\n",
      "Train Epoch: 806 [28672/54000 (53%)] Loss: -1580.067261\n",
      "Train Epoch: 806 [32768/54000 (61%)] Loss: -1583.114258\n",
      "Train Epoch: 806 [36864/54000 (68%)] Loss: -1576.063232\n",
      "Train Epoch: 806 [40960/54000 (76%)] Loss: -1587.349854\n",
      "Train Epoch: 806 [45056/54000 (83%)] Loss: -1578.973145\n",
      "Train Epoch: 806 [49152/54000 (91%)] Loss: -1580.460815\n",
      "Train Epoch: 806 [53248/54000 (99%)] Loss: -1588.891357\n",
      "    epoch          : 806\n",
      "    loss           : -1580.484532360782\n",
      "    ess            : 3.7927686117271677\n",
      "    log_marginal   : 1580.614126485671\n",
      "    val_loss       : -1580.1460418701172\n",
      "    val_ess        : 3.792986750602722\n",
      "    val_log_marginal: 1580.2687327067058\n",
      "Train Epoch: 807 [0/54000 (0%)] Loss: -1576.197510\n",
      "Train Epoch: 807 [4096/54000 (8%)] Loss: -1582.684692\n",
      "Train Epoch: 807 [8192/54000 (15%)] Loss: -1582.247559\n",
      "Train Epoch: 807 [12288/54000 (23%)] Loss: -1581.273193\n",
      "Train Epoch: 807 [16384/54000 (30%)] Loss: -1572.978760\n",
      "Train Epoch: 807 [20480/54000 (38%)] Loss: -1581.726318\n",
      "Train Epoch: 807 [24576/54000 (46%)] Loss: -1584.112305\n",
      "Train Epoch: 807 [28672/54000 (53%)] Loss: -1584.022949\n",
      "Train Epoch: 807 [32768/54000 (61%)] Loss: -1585.137207\n",
      "Train Epoch: 807 [36864/54000 (68%)] Loss: -1578.677002\n",
      "Train Epoch: 807 [40960/54000 (76%)] Loss: -1585.450317\n",
      "Train Epoch: 807 [45056/54000 (83%)] Loss: -1583.973389\n",
      "Train Epoch: 807 [49152/54000 (91%)] Loss: -1580.067871\n",
      "Train Epoch: 807 [53248/54000 (99%)] Loss: -1576.770508\n",
      "    epoch          : 807\n",
      "    loss           : -1580.559624694535\n",
      "    ess            : 3.7954240975221754\n",
      "    log_marginal   : 1580.6869324598267\n",
      "    val_loss       : -1581.0200754801433\n",
      "    val_ess        : 3.8043182591597238\n",
      "    val_log_marginal: 1581.1354522705078\n",
      "Train Epoch: 808 [0/54000 (0%)] Loss: -1586.149658\n",
      "Train Epoch: 808 [4096/54000 (8%)] Loss: -1583.272339\n",
      "Train Epoch: 808 [8192/54000 (15%)] Loss: -1585.686279\n",
      "Train Epoch: 808 [12288/54000 (23%)] Loss: -1584.392090\n",
      "Train Epoch: 808 [16384/54000 (30%)] Loss: -1585.799438\n",
      "Train Epoch: 808 [20480/54000 (38%)] Loss: -1579.535156\n",
      "Train Epoch: 808 [24576/54000 (46%)] Loss: -1580.791504\n",
      "Train Epoch: 808 [28672/54000 (53%)] Loss: -1580.568604\n",
      "Train Epoch: 808 [32768/54000 (61%)] Loss: -1584.918457\n",
      "Train Epoch: 808 [36864/54000 (68%)] Loss: -1575.182373\n",
      "Train Epoch: 808 [40960/54000 (76%)] Loss: -1578.020508\n",
      "Train Epoch: 808 [45056/54000 (83%)] Loss: -1579.122437\n",
      "Train Epoch: 808 [49152/54000 (91%)] Loss: -1578.254028\n",
      "Train Epoch: 808 [53248/54000 (99%)] Loss: -1574.335693\n",
      "    epoch          : 808\n",
      "    loss           : -1580.6387517124556\n",
      "    ess            : 3.794190048606475\n",
      "    log_marginal   : 1580.764305367854\n",
      "    val_loss       : -1580.0880177815754\n",
      "    val_ess        : 3.797416170438131\n",
      "    val_log_marginal: 1580.2077941894531\n",
      "Train Epoch: 809 [0/54000 (0%)] Loss: -1585.054688\n",
      "Train Epoch: 809 [4096/54000 (8%)] Loss: -1579.515625\n",
      "Train Epoch: 809 [8192/54000 (15%)] Loss: -1580.147461\n",
      "Train Epoch: 809 [12288/54000 (23%)] Loss: -1579.656738\n",
      "Train Epoch: 809 [16384/54000 (30%)] Loss: -1579.890015\n",
      "Train Epoch: 809 [20480/54000 (38%)] Loss: -1582.305420\n",
      "Train Epoch: 809 [24576/54000 (46%)] Loss: -1575.112793\n",
      "Train Epoch: 809 [28672/54000 (53%)] Loss: -1583.221680\n",
      "Train Epoch: 809 [32768/54000 (61%)] Loss: -1571.673340\n",
      "Train Epoch: 809 [36864/54000 (68%)] Loss: -1575.707275\n",
      "Train Epoch: 809 [40960/54000 (76%)] Loss: -1586.010376\n",
      "Train Epoch: 809 [45056/54000 (83%)] Loss: -1578.018555\n",
      "Train Epoch: 809 [49152/54000 (91%)] Loss: -1575.239502\n",
      "Train Epoch: 809 [53248/54000 (99%)] Loss: -1578.862305\n",
      "    epoch          : 809\n",
      "    loss           : -1580.4550364706754\n",
      "    ess            : 3.7945553951353825\n",
      "    log_marginal   : 1580.5836141143366\n",
      "    val_loss       : -1580.648696899414\n",
      "    val_ess        : 3.801639666159948\n",
      "    val_log_marginal: 1580.7727610270183\n",
      "Train Epoch: 810 [0/54000 (0%)] Loss: -1579.076660\n",
      "Train Epoch: 810 [4096/54000 (8%)] Loss: -1578.866699\n",
      "Train Epoch: 810 [8192/54000 (15%)] Loss: -1582.561035\n",
      "Train Epoch: 810 [12288/54000 (23%)] Loss: -1582.408447\n",
      "Train Epoch: 810 [16384/54000 (30%)] Loss: -1580.454590\n",
      "Train Epoch: 810 [20480/54000 (38%)] Loss: -1577.348999\n",
      "Train Epoch: 810 [24576/54000 (46%)] Loss: -1578.179321\n",
      "Train Epoch: 810 [28672/54000 (53%)] Loss: -1582.936646\n",
      "Train Epoch: 810 [32768/54000 (61%)] Loss: -1576.726685\n",
      "Train Epoch: 810 [36864/54000 (68%)] Loss: -1572.797485\n",
      "Train Epoch: 810 [40960/54000 (76%)] Loss: -1577.689453\n",
      "Train Epoch: 810 [45056/54000 (83%)] Loss: -1580.530273\n",
      "Train Epoch: 810 [49152/54000 (91%)] Loss: -1583.663452\n",
      "Train Epoch: 810 [53248/54000 (99%)] Loss: -1576.444824\n",
      "    epoch          : 810\n",
      "    loss           : -1580.7390356561018\n",
      "    ess            : 3.7958568554918912\n",
      "    log_marginal   : 1580.8676144568276\n",
      "    val_loss       : -1580.2194010416667\n",
      "    val_ess        : 3.801441212495168\n",
      "    val_log_marginal: 1580.3380177815754\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch810.pth ...\n",
      "Train Epoch: 811 [0/54000 (0%)] Loss: -1575.781982\n",
      "Train Epoch: 811 [4096/54000 (8%)] Loss: -1583.549316\n",
      "Train Epoch: 811 [8192/54000 (15%)] Loss: -1580.124268\n",
      "Train Epoch: 811 [12288/54000 (23%)] Loss: -1578.350586\n",
      "Train Epoch: 811 [16384/54000 (30%)] Loss: -1578.548828\n",
      "Train Epoch: 811 [20480/54000 (38%)] Loss: -1585.320190\n",
      "Train Epoch: 811 [24576/54000 (46%)] Loss: -1582.785767\n",
      "Train Epoch: 811 [28672/54000 (53%)] Loss: -1578.308838\n",
      "Train Epoch: 811 [32768/54000 (61%)] Loss: -1574.211914\n",
      "Train Epoch: 811 [36864/54000 (68%)] Loss: -1584.842163\n",
      "Train Epoch: 811 [40960/54000 (76%)] Loss: -1575.740967\n",
      "Train Epoch: 811 [45056/54000 (83%)] Loss: -1583.399170\n",
      "Train Epoch: 811 [49152/54000 (91%)] Loss: -1577.970703\n",
      "Train Epoch: 811 [53248/54000 (99%)] Loss: -1582.085938\n",
      "    epoch          : 811\n",
      "    loss           : -1580.2411785396919\n",
      "    ess            : 3.791793084257587\n",
      "    log_marginal   : 1580.369516092454\n",
      "    val_loss       : -1580.2795817057292\n",
      "    val_ess        : 3.804199675718943\n",
      "    val_log_marginal: 1580.3997446695964\n",
      "Train Epoch: 812 [0/54000 (0%)] Loss: -1586.101562\n",
      "Train Epoch: 812 [4096/54000 (8%)] Loss: -1577.176025\n",
      "Train Epoch: 812 [8192/54000 (15%)] Loss: -1579.717163\n",
      "Train Epoch: 812 [12288/54000 (23%)] Loss: -1578.900391\n",
      "Train Epoch: 812 [16384/54000 (30%)] Loss: -1576.477295\n",
      "Train Epoch: 812 [20480/54000 (38%)] Loss: -1579.706543\n",
      "Train Epoch: 812 [24576/54000 (46%)] Loss: -1583.275879\n",
      "Train Epoch: 812 [28672/54000 (53%)] Loss: -1577.626221\n",
      "Train Epoch: 812 [32768/54000 (61%)] Loss: -1580.389648\n",
      "Train Epoch: 812 [36864/54000 (68%)] Loss: -1577.945801\n",
      "Train Epoch: 812 [40960/54000 (76%)] Loss: -1583.376709\n",
      "Train Epoch: 812 [45056/54000 (83%)] Loss: -1579.958496\n",
      "Train Epoch: 812 [49152/54000 (91%)] Loss: -1586.501709\n",
      "Train Epoch: 812 [53248/54000 (99%)] Loss: -1576.839600\n",
      "    epoch          : 812\n",
      "    loss           : -1580.304035494113\n",
      "    ess            : 3.794899654614417\n",
      "    log_marginal   : 1580.4289984680465\n",
      "    val_loss       : -1578.9998016357422\n",
      "    val_ess        : 3.784218410650889\n",
      "    val_log_marginal: 1579.138656616211\n",
      "Train Epoch: 813 [0/54000 (0%)] Loss: -1577.442261\n",
      "Train Epoch: 813 [4096/54000 (8%)] Loss: -1580.314697\n",
      "Train Epoch: 813 [8192/54000 (15%)] Loss: -1582.796875\n",
      "Train Epoch: 813 [12288/54000 (23%)] Loss: -1580.257690\n",
      "Train Epoch: 813 [16384/54000 (30%)] Loss: -1575.975098\n",
      "Train Epoch: 813 [20480/54000 (38%)] Loss: -1576.918091\n",
      "Train Epoch: 813 [24576/54000 (46%)] Loss: -1582.603027\n",
      "Train Epoch: 813 [28672/54000 (53%)] Loss: -1584.072510\n",
      "Train Epoch: 813 [32768/54000 (61%)] Loss: -1578.627441\n",
      "Train Epoch: 813 [36864/54000 (68%)] Loss: -1586.596191\n",
      "Train Epoch: 813 [40960/54000 (76%)] Loss: -1577.100098\n",
      "Train Epoch: 813 [45056/54000 (83%)] Loss: -1573.365723\n",
      "Train Epoch: 813 [49152/54000 (91%)] Loss: -1584.947510\n",
      "Train Epoch: 813 [53248/54000 (99%)] Loss: -1573.282593\n",
      "    epoch          : 813\n",
      "    loss           : -1580.348658846453\n",
      "    ess            : 3.7926106091359215\n",
      "    log_marginal   : 1580.4776443553762\n",
      "    val_loss       : -1579.859868367513\n",
      "    val_ess        : 3.7965285579363504\n",
      "    val_log_marginal: 1579.9847819010417\n",
      "Train Epoch: 814 [0/54000 (0%)] Loss: -1580.016357\n",
      "Train Epoch: 814 [4096/54000 (8%)] Loss: -1587.361084\n",
      "Train Epoch: 814 [8192/54000 (15%)] Loss: -1578.646484\n",
      "Train Epoch: 814 [12288/54000 (23%)] Loss: -1573.880615\n",
      "Train Epoch: 814 [16384/54000 (30%)] Loss: -1583.467896\n",
      "Train Epoch: 814 [20480/54000 (38%)] Loss: -1578.318848\n",
      "Train Epoch: 814 [24576/54000 (46%)] Loss: -1573.893433\n",
      "Train Epoch: 814 [28672/54000 (53%)] Loss: -1580.750732\n",
      "Train Epoch: 814 [32768/54000 (61%)] Loss: -1577.473389\n",
      "Train Epoch: 814 [36864/54000 (68%)] Loss: -1585.535889\n",
      "Train Epoch: 814 [40960/54000 (76%)] Loss: -1581.877075\n",
      "Train Epoch: 814 [45056/54000 (83%)] Loss: -1578.311279\n",
      "Train Epoch: 814 [49152/54000 (91%)] Loss: -1578.920166\n",
      "Train Epoch: 814 [53248/54000 (99%)] Loss: -1583.207886\n",
      "    epoch          : 814\n",
      "    loss           : -1580.336661822423\n",
      "    ess            : 3.8008555699298734\n",
      "    log_marginal   : 1580.4599782934686\n",
      "    val_loss       : -1580.233678181966\n",
      "    val_ess        : 3.7979900340239205\n",
      "    val_log_marginal: 1580.3512369791667\n",
      "Train Epoch: 815 [0/54000 (0%)] Loss: -1580.756714\n",
      "Train Epoch: 815 [4096/54000 (8%)] Loss: -1580.480225\n",
      "Train Epoch: 815 [8192/54000 (15%)] Loss: -1569.709595\n",
      "Train Epoch: 815 [12288/54000 (23%)] Loss: -1586.628906\n",
      "Train Epoch: 815 [16384/54000 (30%)] Loss: -1580.866089\n",
      "Train Epoch: 815 [20480/54000 (38%)] Loss: -1582.604492\n",
      "Train Epoch: 815 [24576/54000 (46%)] Loss: -1579.963989\n",
      "Train Epoch: 815 [28672/54000 (53%)] Loss: -1582.614746\n",
      "Train Epoch: 815 [32768/54000 (61%)] Loss: -1584.060059\n",
      "Train Epoch: 815 [36864/54000 (68%)] Loss: -1583.390747\n",
      "Train Epoch: 815 [40960/54000 (76%)] Loss: -1573.856689\n",
      "Train Epoch: 815 [45056/54000 (83%)] Loss: -1581.230713\n",
      "Train Epoch: 815 [49152/54000 (91%)] Loss: -1581.638184\n",
      "Train Epoch: 815 [53248/54000 (99%)] Loss: -1584.770752\n",
      "    epoch          : 815\n",
      "    loss           : -1580.3148233856634\n",
      "    ess            : 3.7917681542618014\n",
      "    log_marginal   : 1580.4465563444164\n",
      "    val_loss       : -1580.3050842285156\n",
      "    val_ess        : 3.8004173835118613\n",
      "    val_log_marginal: 1580.4181518554688\n",
      "Train Epoch: 816 [0/54000 (0%)] Loss: -1577.500488\n",
      "Train Epoch: 816 [4096/54000 (8%)] Loss: -1580.015869\n",
      "Train Epoch: 816 [8192/54000 (15%)] Loss: -1575.172607\n",
      "Train Epoch: 816 [12288/54000 (23%)] Loss: -1577.885498\n",
      "Train Epoch: 816 [16384/54000 (30%)] Loss: -1576.583252\n",
      "Train Epoch: 816 [20480/54000 (38%)] Loss: -1572.271851\n",
      "Train Epoch: 816 [24576/54000 (46%)] Loss: -1580.742310\n",
      "Train Epoch: 816 [28672/54000 (53%)] Loss: -1579.188232\n",
      "Train Epoch: 816 [32768/54000 (61%)] Loss: -1577.599731\n",
      "Train Epoch: 816 [36864/54000 (68%)] Loss: -1584.433105\n",
      "Train Epoch: 816 [40960/54000 (76%)] Loss: -1582.795898\n",
      "Train Epoch: 816 [45056/54000 (83%)] Loss: -1579.973145\n",
      "Train Epoch: 816 [49152/54000 (91%)] Loss: -1581.394775\n",
      "Train Epoch: 816 [53248/54000 (99%)] Loss: -1578.238037\n",
      "    epoch          : 816\n",
      "    loss           : -1580.5986385978229\n",
      "    ess            : 3.7926372080617607\n",
      "    log_marginal   : 1580.728499426096\n",
      "    val_loss       : -1579.9744720458984\n",
      "    val_ess        : 3.794969548781713\n",
      "    val_log_marginal: 1580.1061045328777\n",
      "Train Epoch: 817 [0/54000 (0%)] Loss: -1583.448975\n",
      "Train Epoch: 817 [4096/54000 (8%)] Loss: -1578.995483\n",
      "Train Epoch: 817 [8192/54000 (15%)] Loss: -1577.439941\n",
      "Train Epoch: 817 [12288/54000 (23%)] Loss: -1584.302612\n",
      "Train Epoch: 817 [16384/54000 (30%)] Loss: -1575.568359\n",
      "Train Epoch: 817 [20480/54000 (38%)] Loss: -1583.439819\n",
      "Train Epoch: 817 [24576/54000 (46%)] Loss: -1573.490234\n",
      "Train Epoch: 817 [28672/54000 (53%)] Loss: -1576.440918\n",
      "Train Epoch: 817 [32768/54000 (61%)] Loss: -1582.358887\n",
      "Train Epoch: 817 [36864/54000 (68%)] Loss: -1579.575928\n",
      "Train Epoch: 817 [40960/54000 (76%)] Loss: -1580.960205\n",
      "Train Epoch: 817 [45056/54000 (83%)] Loss: -1582.691650\n",
      "Train Epoch: 817 [49152/54000 (91%)] Loss: -1580.563477\n",
      "Train Epoch: 817 [53248/54000 (99%)] Loss: -1578.356323\n",
      "    epoch          : 817\n",
      "    loss           : -1580.3455949394624\n",
      "    ess            : 3.795382819469506\n",
      "    log_marginal   : 1580.4752937786952\n",
      "    val_loss       : -1580.4191487630208\n",
      "    val_ess        : 3.7955733040968576\n",
      "    val_log_marginal: 1580.5422668457031\n",
      "Train Epoch: 818 [0/54000 (0%)] Loss: -1576.760132\n",
      "Train Epoch: 818 [4096/54000 (8%)] Loss: -1580.279785\n",
      "Train Epoch: 818 [8192/54000 (15%)] Loss: -1574.987671\n",
      "Train Epoch: 818 [12288/54000 (23%)] Loss: -1582.069336\n",
      "Train Epoch: 818 [16384/54000 (30%)] Loss: -1579.199707\n",
      "Train Epoch: 818 [20480/54000 (38%)] Loss: -1584.961914\n",
      "Train Epoch: 818 [24576/54000 (46%)] Loss: -1581.057373\n",
      "Train Epoch: 818 [28672/54000 (53%)] Loss: -1578.990967\n",
      "Train Epoch: 818 [32768/54000 (61%)] Loss: -1581.092407\n",
      "Train Epoch: 818 [36864/54000 (68%)] Loss: -1587.016968\n",
      "Train Epoch: 818 [40960/54000 (76%)] Loss: -1579.910156\n",
      "Train Epoch: 818 [45056/54000 (83%)] Loss: -1579.623535\n",
      "Train Epoch: 818 [49152/54000 (91%)] Loss: -1579.147949\n",
      "Train Epoch: 818 [53248/54000 (99%)] Loss: -1575.497925\n",
      "    epoch          : 818\n",
      "    loss           : -1580.265382594972\n",
      "    ess            : 3.7924500788557585\n",
      "    log_marginal   : 1580.395594592343\n",
      "    val_loss       : -1580.6029713948567\n",
      "    val_ess        : 3.778720885515213\n",
      "    val_log_marginal: 1580.7479858398438\n",
      "Train Epoch: 819 [0/54000 (0%)] Loss: -1577.748291\n",
      "Train Epoch: 819 [4096/54000 (8%)] Loss: -1583.245605\n",
      "Train Epoch: 819 [8192/54000 (15%)] Loss: -1576.381470\n",
      "Train Epoch: 819 [12288/54000 (23%)] Loss: -1581.035645\n",
      "Train Epoch: 819 [16384/54000 (30%)] Loss: -1581.844727\n",
      "Train Epoch: 819 [20480/54000 (38%)] Loss: -1576.301514\n",
      "Train Epoch: 819 [24576/54000 (46%)] Loss: -1579.642700\n",
      "Train Epoch: 819 [28672/54000 (53%)] Loss: -1587.584839\n",
      "Train Epoch: 819 [32768/54000 (61%)] Loss: -1593.504150\n",
      "Train Epoch: 819 [36864/54000 (68%)] Loss: -1586.540405\n",
      "Train Epoch: 819 [40960/54000 (76%)] Loss: -1577.959961\n",
      "Train Epoch: 819 [45056/54000 (83%)] Loss: -1581.085449\n",
      "Train Epoch: 819 [49152/54000 (91%)] Loss: -1583.275146\n",
      "Train Epoch: 819 [53248/54000 (99%)] Loss: -1579.428345\n",
      "    epoch          : 819\n",
      "    loss           : -1581.339692174541\n",
      "    ess            : 3.7987346716966672\n",
      "    log_marginal   : 1581.4674708651141\n",
      "    val_loss       : -1581.2101236979167\n",
      "    val_ess        : 3.812180310487747\n",
      "    val_log_marginal: 1581.328857421875\n",
      "Train Epoch: 820 [0/54000 (0%)] Loss: -1578.697754\n",
      "Train Epoch: 820 [4096/54000 (8%)] Loss: -1580.848511\n",
      "Train Epoch: 820 [8192/54000 (15%)] Loss: -1578.907471\n",
      "Train Epoch: 820 [12288/54000 (23%)] Loss: -1580.325439\n",
      "Train Epoch: 820 [16384/54000 (30%)] Loss: -1578.864990\n",
      "Train Epoch: 820 [20480/54000 (38%)] Loss: -1579.622314\n",
      "Train Epoch: 820 [24576/54000 (46%)] Loss: -1584.262817\n",
      "Train Epoch: 820 [28672/54000 (53%)] Loss: -1581.769409\n",
      "Train Epoch: 820 [32768/54000 (61%)] Loss: -1580.611084\n",
      "Train Epoch: 820 [36864/54000 (68%)] Loss: -1584.142090\n",
      "Train Epoch: 820 [40960/54000 (76%)] Loss: -1583.120850\n",
      "Train Epoch: 820 [45056/54000 (83%)] Loss: -1582.231689\n",
      "Train Epoch: 820 [49152/54000 (91%)] Loss: -1581.723877\n",
      "Train Epoch: 820 [53248/54000 (99%)] Loss: -1580.622925\n",
      "    epoch          : 820\n",
      "    loss           : -1581.853682820831\n",
      "    ess            : 3.7964848601987575\n",
      "    log_marginal   : 1581.9764103460086\n",
      "    val_loss       : -1581.7226816813152\n",
      "    val_ess        : 3.7955688337484994\n",
      "    val_log_marginal: 1581.8486226399739\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch820.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 821 [0/54000 (0%)] Loss: -1576.574829\n",
      "Train Epoch: 821 [4096/54000 (8%)] Loss: -1579.481323\n",
      "Train Epoch: 821 [8192/54000 (15%)] Loss: -1588.714600\n",
      "Train Epoch: 821 [12288/54000 (23%)] Loss: -1583.078613\n",
      "Train Epoch: 821 [16384/54000 (30%)] Loss: -1580.447998\n",
      "Train Epoch: 821 [20480/54000 (38%)] Loss: -1584.877441\n",
      "Train Epoch: 821 [24576/54000 (46%)] Loss: -1589.228760\n",
      "Train Epoch: 821 [28672/54000 (53%)] Loss: -1587.867920\n",
      "Train Epoch: 821 [32768/54000 (61%)] Loss: -1582.447388\n",
      "Train Epoch: 821 [36864/54000 (68%)] Loss: -1582.080078\n",
      "Train Epoch: 821 [40960/54000 (76%)] Loss: -1582.941406\n",
      "Train Epoch: 821 [45056/54000 (83%)] Loss: -1581.061523\n",
      "Train Epoch: 821 [49152/54000 (91%)] Loss: -1578.081055\n",
      "Train Epoch: 821 [53248/54000 (99%)] Loss: -1584.992188\n",
      "    epoch          : 821\n",
      "    loss           : -1582.586076926281\n",
      "    ess            : 3.8007203007196364\n",
      "    log_marginal   : 1582.707315887885\n",
      "    val_loss       : -1582.4766387939453\n",
      "    val_ess        : 3.8062189519405365\n",
      "    val_log_marginal: 1582.6003316243489\n",
      "Train Epoch: 822 [0/54000 (0%)] Loss: -1588.036133\n",
      "Train Epoch: 822 [4096/54000 (8%)] Loss: -1586.481812\n",
      "Train Epoch: 822 [8192/54000 (15%)] Loss: -1581.576904\n",
      "Train Epoch: 822 [12288/54000 (23%)] Loss: -1583.128418\n",
      "Train Epoch: 822 [16384/54000 (30%)] Loss: -1582.820435\n",
      "Train Epoch: 822 [20480/54000 (38%)] Loss: -1591.323486\n",
      "Train Epoch: 822 [24576/54000 (46%)] Loss: -1583.478027\n",
      "Train Epoch: 822 [28672/54000 (53%)] Loss: -1584.706299\n",
      "Train Epoch: 822 [32768/54000 (61%)] Loss: -1582.761841\n",
      "Train Epoch: 822 [36864/54000 (68%)] Loss: -1581.137207\n",
      "Train Epoch: 822 [40960/54000 (76%)] Loss: -1585.654541\n",
      "Train Epoch: 822 [45056/54000 (83%)] Loss: -1580.218384\n",
      "Train Epoch: 822 [49152/54000 (91%)] Loss: -1582.744385\n",
      "Train Epoch: 822 [53248/54000 (99%)] Loss: -1576.307617\n",
      "    epoch          : 822\n",
      "    loss           : -1583.0124766272957\n",
      "    ess            : 3.796965543692711\n",
      "    log_marginal   : 1583.1394864484598\n",
      "    val_loss       : -1582.4723307291667\n",
      "    val_ess        : 3.7964133520921073\n",
      "    val_log_marginal: 1582.594711303711\n",
      "Train Epoch: 823 [0/54000 (0%)] Loss: -1576.179688\n",
      "Train Epoch: 823 [4096/54000 (8%)] Loss: -1589.387207\n",
      "Train Epoch: 823 [8192/54000 (15%)] Loss: -1590.300537\n",
      "Train Epoch: 823 [12288/54000 (23%)] Loss: -1584.578613\n",
      "Train Epoch: 823 [16384/54000 (30%)] Loss: -1580.906738\n",
      "Train Epoch: 823 [20480/54000 (38%)] Loss: -1580.160278\n",
      "Train Epoch: 823 [24576/54000 (46%)] Loss: -1575.175659\n",
      "Train Epoch: 823 [28672/54000 (53%)] Loss: -1583.579590\n",
      "Train Epoch: 823 [32768/54000 (61%)] Loss: -1579.659668\n",
      "Train Epoch: 823 [36864/54000 (68%)] Loss: -1585.055908\n",
      "Train Epoch: 823 [40960/54000 (76%)] Loss: -1589.009155\n",
      "Train Epoch: 823 [45056/54000 (83%)] Loss: -1585.851318\n",
      "Train Epoch: 823 [49152/54000 (91%)] Loss: -1575.650879\n",
      "Train Epoch: 823 [53248/54000 (99%)] Loss: -1583.402588\n",
      "    epoch          : 823\n",
      "    loss           : -1583.1276462066794\n",
      "    ess            : 3.7926140961488843\n",
      "    log_marginal   : 1583.2575903436018\n",
      "    val_loss       : -1582.9871114095051\n",
      "    val_ess        : 3.7862783869107566\n",
      "    val_log_marginal: 1583.1212056477864\n",
      "Train Epoch: 824 [0/54000 (0%)] Loss: -1581.312744\n",
      "Train Epoch: 824 [4096/54000 (8%)] Loss: -1585.501587\n",
      "Train Epoch: 824 [8192/54000 (15%)] Loss: -1583.224365\n",
      "Train Epoch: 824 [12288/54000 (23%)] Loss: -1581.793213\n",
      "Train Epoch: 824 [16384/54000 (30%)] Loss: -1585.745605\n",
      "Train Epoch: 824 [20480/54000 (38%)] Loss: -1583.776855\n",
      "Train Epoch: 824 [24576/54000 (46%)] Loss: -1582.658936\n",
      "Train Epoch: 824 [28672/54000 (53%)] Loss: -1578.090942\n",
      "Train Epoch: 824 [32768/54000 (61%)] Loss: -1588.340332\n",
      "Train Epoch: 824 [36864/54000 (68%)] Loss: -1589.110840\n",
      "Train Epoch: 824 [40960/54000 (76%)] Loss: -1584.794922\n",
      "Train Epoch: 824 [45056/54000 (83%)] Loss: -1580.673096\n",
      "Train Epoch: 824 [49152/54000 (91%)] Loss: -1585.868652\n",
      "Train Epoch: 824 [53248/54000 (99%)] Loss: -1578.922119\n",
      "    epoch          : 824\n",
      "    loss           : -1583.4538475868262\n",
      "    ess            : 3.8017889538082468\n",
      "    log_marginal   : 1583.5746364503111\n",
      "    val_loss       : -1583.3384602864583\n",
      "    val_ess        : 3.7981038888295493\n",
      "    val_log_marginal: 1583.4594116210938\n",
      "Train Epoch: 825 [0/54000 (0%)] Loss: -1584.214355\n",
      "Train Epoch: 825 [4096/54000 (8%)] Loss: -1579.285156\n",
      "Train Epoch: 825 [8192/54000 (15%)] Loss: -1583.496704\n",
      "Train Epoch: 825 [12288/54000 (23%)] Loss: -1581.133789\n",
      "Train Epoch: 825 [16384/54000 (30%)] Loss: -1583.581055\n",
      "Train Epoch: 825 [20480/54000 (38%)] Loss: -1584.549438\n",
      "Train Epoch: 825 [24576/54000 (46%)] Loss: -1582.204102\n",
      "Train Epoch: 825 [28672/54000 (53%)] Loss: -1587.056641\n",
      "Train Epoch: 825 [32768/54000 (61%)] Loss: -1585.619141\n",
      "Train Epoch: 825 [36864/54000 (68%)] Loss: -1585.011719\n",
      "Train Epoch: 825 [40960/54000 (76%)] Loss: -1583.306274\n",
      "Train Epoch: 825 [45056/54000 (83%)] Loss: -1582.435547\n",
      "Train Epoch: 825 [49152/54000 (91%)] Loss: -1582.526367\n",
      "Train Epoch: 825 [53248/54000 (99%)] Loss: -1585.043091\n",
      "    epoch          : 825\n",
      "    loss           : -1583.7527850544284\n",
      "    ess            : 3.795866661162173\n",
      "    log_marginal   : 1583.8764006266663\n",
      "    val_loss       : -1583.7389831542969\n",
      "    val_ess        : 3.808341473340988\n",
      "    val_log_marginal: 1583.8539784749348\n",
      "Train Epoch: 826 [0/54000 (0%)] Loss: -1584.820801\n",
      "Train Epoch: 826 [4096/54000 (8%)] Loss: -1581.807373\n",
      "Train Epoch: 826 [8192/54000 (15%)] Loss: -1577.578369\n",
      "Train Epoch: 826 [12288/54000 (23%)] Loss: -1583.383667\n",
      "Train Epoch: 826 [16384/54000 (30%)] Loss: -1588.204590\n",
      "Train Epoch: 826 [20480/54000 (38%)] Loss: -1584.098755\n",
      "Train Epoch: 826 [24576/54000 (46%)] Loss: -1582.274658\n",
      "Train Epoch: 826 [28672/54000 (53%)] Loss: -1580.059448\n",
      "Train Epoch: 826 [32768/54000 (61%)] Loss: -1593.474854\n",
      "Train Epoch: 826 [36864/54000 (68%)] Loss: -1578.894531\n",
      "Train Epoch: 826 [40960/54000 (76%)] Loss: -1591.244019\n",
      "Train Epoch: 826 [45056/54000 (83%)] Loss: -1590.204590\n",
      "Train Epoch: 826 [49152/54000 (91%)] Loss: -1583.667358\n",
      "Train Epoch: 826 [53248/54000 (99%)] Loss: -1584.126709\n",
      "    epoch          : 826\n",
      "    loss           : -1583.7841559676763\n",
      "    ess            : 3.790820631370725\n",
      "    log_marginal   : 1583.9165773798504\n",
      "    val_loss       : -1584.2812754313152\n",
      "    val_ess        : 3.8012963434060416\n",
      "    val_log_marginal: 1584.4042358398438\n",
      "Train Epoch: 827 [0/54000 (0%)] Loss: -1587.572510\n",
      "Train Epoch: 827 [4096/54000 (8%)] Loss: -1586.456543\n",
      "Train Epoch: 827 [8192/54000 (15%)] Loss: -1578.560059\n",
      "Train Epoch: 827 [12288/54000 (23%)] Loss: -1581.211182\n",
      "Train Epoch: 827 [16384/54000 (30%)] Loss: -1582.417969\n",
      "Train Epoch: 827 [20480/54000 (38%)] Loss: -1577.847290\n",
      "Train Epoch: 827 [24576/54000 (46%)] Loss: -1579.764404\n",
      "Train Epoch: 827 [28672/54000 (53%)] Loss: -1578.169312\n",
      "Train Epoch: 827 [32768/54000 (61%)] Loss: -1577.843018\n",
      "Train Epoch: 827 [36864/54000 (68%)] Loss: -1575.510376\n",
      "Train Epoch: 827 [40960/54000 (76%)] Loss: -1585.824585\n",
      "Train Epoch: 827 [45056/54000 (83%)] Loss: -1580.959351\n",
      "Train Epoch: 827 [49152/54000 (91%)] Loss: -1578.127319\n",
      "Train Epoch: 827 [53248/54000 (99%)] Loss: -1579.332520\n",
      "    epoch          : 827\n",
      "    loss           : -1583.808498870705\n",
      "    ess            : 3.793514546624857\n",
      "    log_marginal   : 1583.934168811093\n",
      "    val_loss       : -1583.9673512776692\n",
      "    val_ess        : 3.789203425248464\n",
      "    val_log_marginal: 1584.0957946777344\n",
      "Train Epoch: 828 [0/54000 (0%)] Loss: -1581.667236\n",
      "Train Epoch: 828 [4096/54000 (8%)] Loss: -1583.266479\n",
      "Train Epoch: 828 [8192/54000 (15%)] Loss: -1584.209106\n",
      "Train Epoch: 828 [12288/54000 (23%)] Loss: -1583.816162\n",
      "Train Epoch: 828 [16384/54000 (30%)] Loss: -1590.721558\n",
      "Train Epoch: 828 [20480/54000 (38%)] Loss: -1581.297363\n",
      "Train Epoch: 828 [24576/54000 (46%)] Loss: -1584.155151\n",
      "Train Epoch: 828 [28672/54000 (53%)] Loss: -1589.481323\n",
      "Train Epoch: 828 [32768/54000 (61%)] Loss: -1587.944580\n",
      "Train Epoch: 828 [36864/54000 (68%)] Loss: -1586.519043\n",
      "Train Epoch: 828 [40960/54000 (76%)] Loss: -1582.767334\n",
      "Train Epoch: 828 [45056/54000 (83%)] Loss: -1583.368896\n",
      "Train Epoch: 828 [49152/54000 (91%)] Loss: -1582.277100\n",
      "Train Epoch: 828 [53248/54000 (99%)] Loss: -1590.138062\n",
      "    epoch          : 828\n",
      "    loss           : -1584.189128568387\n",
      "    ess            : 3.798284109169838\n",
      "    log_marginal   : 1584.3115731912767\n",
      "    val_loss       : -1584.8209431966145\n",
      "    val_ess        : 3.7861581345399222\n",
      "    val_log_marginal: 1584.959732055664\n",
      "Train Epoch: 829 [0/54000 (0%)] Loss: -1580.414673\n",
      "Train Epoch: 829 [4096/54000 (8%)] Loss: -1588.518188\n",
      "Train Epoch: 829 [8192/54000 (15%)] Loss: -1579.665649\n",
      "Train Epoch: 829 [12288/54000 (23%)] Loss: -1585.393188\n",
      "Train Epoch: 829 [16384/54000 (30%)] Loss: -1580.856689\n",
      "Train Epoch: 829 [20480/54000 (38%)] Loss: -1584.539673\n",
      "Train Epoch: 829 [24576/54000 (46%)] Loss: -1585.235840\n",
      "Train Epoch: 829 [28672/54000 (53%)] Loss: -1583.971436\n",
      "Train Epoch: 829 [32768/54000 (61%)] Loss: -1583.543945\n",
      "Train Epoch: 829 [36864/54000 (68%)] Loss: -1581.284424\n",
      "Train Epoch: 829 [40960/54000 (76%)] Loss: -1591.380615\n",
      "Train Epoch: 829 [45056/54000 (83%)] Loss: -1584.185181\n",
      "Train Epoch: 829 [49152/54000 (91%)] Loss: -1586.169922\n",
      "Train Epoch: 829 [53248/54000 (99%)] Loss: -1583.561523\n",
      "    epoch          : 829\n",
      "    loss           : -1584.3853418431577\n",
      "    ess            : 3.797753708057494\n",
      "    log_marginal   : 1584.5090812213048\n",
      "    val_loss       : -1583.6248423258464\n",
      "    val_ess        : 3.7859833935896554\n",
      "    val_log_marginal: 1583.7637532552083\n",
      "Train Epoch: 830 [0/54000 (0%)] Loss: -1581.640503\n",
      "Train Epoch: 830 [4096/54000 (8%)] Loss: -1584.842285\n",
      "Train Epoch: 830 [8192/54000 (15%)] Loss: -1586.832275\n",
      "Train Epoch: 830 [12288/54000 (23%)] Loss: -1593.190186\n",
      "Train Epoch: 830 [16384/54000 (30%)] Loss: -1587.467896\n",
      "Train Epoch: 830 [20480/54000 (38%)] Loss: -1581.481323\n",
      "Train Epoch: 830 [24576/54000 (46%)] Loss: -1589.925781\n",
      "Train Epoch: 830 [28672/54000 (53%)] Loss: -1581.933228\n",
      "Train Epoch: 830 [32768/54000 (61%)] Loss: -1587.519531\n",
      "Train Epoch: 830 [36864/54000 (68%)] Loss: -1589.003540\n",
      "Train Epoch: 830 [40960/54000 (76%)] Loss: -1578.332397\n",
      "Train Epoch: 830 [45056/54000 (83%)] Loss: -1589.730469\n",
      "Train Epoch: 830 [49152/54000 (91%)] Loss: -1583.196899\n",
      "Train Epoch: 830 [53248/54000 (99%)] Loss: -1585.042236\n",
      "    epoch          : 830\n",
      "    loss           : -1584.392523742965\n",
      "    ess            : 3.7932698941343768\n",
      "    log_marginal   : 1584.5223730005923\n",
      "    val_loss       : -1584.3756306966145\n",
      "    val_ess        : 3.7997377713521323\n",
      "    val_log_marginal: 1584.4892069498699\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch830.pth ...\n",
      "Train Epoch: 831 [0/54000 (0%)] Loss: -1587.990234\n",
      "Train Epoch: 831 [4096/54000 (8%)] Loss: -1580.632568\n",
      "Train Epoch: 831 [8192/54000 (15%)] Loss: -1588.107788\n",
      "Train Epoch: 831 [12288/54000 (23%)] Loss: -1585.339844\n",
      "Train Epoch: 831 [16384/54000 (30%)] Loss: -1586.683105\n",
      "Train Epoch: 831 [20480/54000 (38%)] Loss: -1586.638428\n",
      "Train Epoch: 831 [24576/54000 (46%)] Loss: -1591.562744\n",
      "Train Epoch: 831 [28672/54000 (53%)] Loss: -1585.008057\n",
      "Train Epoch: 831 [32768/54000 (61%)] Loss: -1586.179932\n",
      "Train Epoch: 831 [36864/54000 (68%)] Loss: -1581.508057\n",
      "Train Epoch: 831 [40960/54000 (76%)] Loss: -1586.552246\n",
      "Train Epoch: 831 [45056/54000 (83%)] Loss: -1586.606689\n",
      "Train Epoch: 831 [49152/54000 (91%)] Loss: -1586.444824\n",
      "Train Epoch: 831 [53248/54000 (99%)] Loss: -1582.687500\n",
      "    epoch          : 831\n",
      "    loss           : -1584.3008327393736\n",
      "    ess            : 3.7944170569921556\n",
      "    log_marginal   : 1584.4302376842047\n",
      "    val_loss       : -1584.4076741536458\n",
      "    val_ess        : 3.807067702213923\n",
      "    val_log_marginal: 1584.5242919921875\n",
      "Train Epoch: 832 [0/54000 (0%)] Loss: -1587.053223\n",
      "Train Epoch: 832 [4096/54000 (8%)] Loss: -1584.485718\n",
      "Train Epoch: 832 [8192/54000 (15%)] Loss: -1583.152832\n",
      "Train Epoch: 832 [12288/54000 (23%)] Loss: -1580.166382\n",
      "Train Epoch: 832 [16384/54000 (30%)] Loss: -1582.735107\n",
      "Train Epoch: 832 [20480/54000 (38%)] Loss: -1580.590454\n",
      "Train Epoch: 832 [24576/54000 (46%)] Loss: -1576.021118\n",
      "Train Epoch: 832 [28672/54000 (53%)] Loss: -1586.440674\n",
      "Train Epoch: 832 [32768/54000 (61%)] Loss: -1585.630371\n",
      "Train Epoch: 832 [36864/54000 (68%)] Loss: -1586.427490\n",
      "Train Epoch: 832 [40960/54000 (76%)] Loss: -1584.386475\n",
      "Train Epoch: 832 [45056/54000 (83%)] Loss: -1586.199951\n",
      "Train Epoch: 832 [49152/54000 (91%)] Loss: -1584.259521\n",
      "Train Epoch: 832 [53248/54000 (99%)] Loss: -1581.724365\n",
      "    epoch          : 832\n",
      "    loss           : -1584.4624474692685\n",
      "    ess            : 3.797149686451772\n",
      "    log_marginal   : 1584.5889794227637\n",
      "    val_loss       : -1585.0428212483723\n",
      "    val_ess        : 3.8070712188879647\n",
      "    val_log_marginal: 1585.1634826660156\n",
      "Train Epoch: 833 [0/54000 (0%)] Loss: -1582.850830\n",
      "Train Epoch: 833 [4096/54000 (8%)] Loss: -1580.029785\n",
      "Train Epoch: 833 [8192/54000 (15%)] Loss: -1584.317017\n",
      "Train Epoch: 833 [12288/54000 (23%)] Loss: -1576.592896\n",
      "Train Epoch: 833 [16384/54000 (30%)] Loss: -1582.669434\n",
      "Train Epoch: 833 [20480/54000 (38%)] Loss: -1587.058838\n",
      "Train Epoch: 833 [24576/54000 (46%)] Loss: -1585.430664\n",
      "Train Epoch: 833 [28672/54000 (53%)] Loss: -1582.558350\n",
      "Train Epoch: 833 [32768/54000 (61%)] Loss: -1581.486694\n",
      "Train Epoch: 833 [36864/54000 (68%)] Loss: -1584.950684\n",
      "Train Epoch: 833 [40960/54000 (76%)] Loss: -1586.392822\n",
      "Train Epoch: 833 [45056/54000 (83%)] Loss: -1583.836792\n",
      "Train Epoch: 833 [49152/54000 (91%)] Loss: -1589.076660\n",
      "Train Epoch: 833 [53248/54000 (99%)] Loss: -1580.482544\n",
      "    epoch          : 833\n",
      "    loss           : -1584.3631927345602\n",
      "    ess            : 3.795996373298609\n",
      "    log_marginal   : 1584.4907249703792\n",
      "    val_loss       : -1584.661860148112\n",
      "    val_ess        : 3.8020892639954886\n",
      "    val_log_marginal: 1584.7860768636067\n",
      "Train Epoch: 834 [0/54000 (0%)] Loss: -1586.826782\n",
      "Train Epoch: 834 [4096/54000 (8%)] Loss: -1584.349121\n",
      "Train Epoch: 834 [8192/54000 (15%)] Loss: -1586.135376\n",
      "Train Epoch: 834 [12288/54000 (23%)] Loss: -1588.256348\n",
      "Train Epoch: 834 [16384/54000 (30%)] Loss: -1586.545654\n",
      "Train Epoch: 834 [20480/54000 (38%)] Loss: -1583.240234\n",
      "Train Epoch: 834 [24576/54000 (46%)] Loss: -1582.908691\n",
      "Train Epoch: 834 [28672/54000 (53%)] Loss: -1584.755249\n",
      "Train Epoch: 834 [32768/54000 (61%)] Loss: -1587.095337\n",
      "Train Epoch: 834 [36864/54000 (68%)] Loss: -1586.914795\n",
      "Train Epoch: 834 [40960/54000 (76%)] Loss: -1582.716187\n",
      "Train Epoch: 834 [45056/54000 (83%)] Loss: -1582.485229\n",
      "Train Epoch: 834 [49152/54000 (91%)] Loss: -1586.779663\n",
      "Train Epoch: 834 [53248/54000 (99%)] Loss: -1584.903076\n",
      "    epoch          : 834\n",
      "    loss           : -1584.23076727266\n",
      "    ess            : 3.7960153281406206\n",
      "    log_marginal   : 1584.357332781028\n",
      "    val_loss       : -1584.9519704182942\n",
      "    val_ess        : 3.7950213253498077\n",
      "    val_log_marginal: 1585.0718790690105\n",
      "Train Epoch: 835 [0/54000 (0%)] Loss: -1584.574829\n",
      "Train Epoch: 835 [4096/54000 (8%)] Loss: -1578.881470\n",
      "Train Epoch: 835 [8192/54000 (15%)] Loss: -1587.874268\n",
      "Train Epoch: 835 [12288/54000 (23%)] Loss: -1586.608154\n",
      "Train Epoch: 835 [16384/54000 (30%)] Loss: -1582.907959\n",
      "Train Epoch: 835 [20480/54000 (38%)] Loss: -1586.868408\n",
      "Train Epoch: 835 [24576/54000 (46%)] Loss: -1585.484131\n",
      "Train Epoch: 835 [28672/54000 (53%)] Loss: -1581.382812\n",
      "Train Epoch: 835 [32768/54000 (61%)] Loss: -1579.390625\n",
      "Train Epoch: 835 [36864/54000 (68%)] Loss: -1579.012451\n",
      "Train Epoch: 835 [40960/54000 (76%)] Loss: -1590.442261\n",
      "Train Epoch: 835 [45056/54000 (83%)] Loss: -1586.145752\n",
      "Train Epoch: 835 [49152/54000 (91%)] Loss: -1582.615479\n",
      "Train Epoch: 835 [53248/54000 (99%)] Loss: -1583.189453\n",
      "    epoch          : 835\n",
      "    loss           : -1584.4647696978673\n",
      "    ess            : 3.8011623637936127\n",
      "    log_marginal   : 1584.5905808001332\n",
      "    val_loss       : -1584.2577260335286\n",
      "    val_ess        : 3.796225438515345\n",
      "    val_log_marginal: 1584.3797810872395\n",
      "Train Epoch: 836 [0/54000 (0%)] Loss: -1590.318726\n",
      "Train Epoch: 836 [4096/54000 (8%)] Loss: -1584.449341\n",
      "Train Epoch: 836 [8192/54000 (15%)] Loss: -1582.031250\n",
      "Train Epoch: 836 [12288/54000 (23%)] Loss: -1587.211304\n",
      "Train Epoch: 836 [16384/54000 (30%)] Loss: -1582.488770\n",
      "Train Epoch: 836 [20480/54000 (38%)] Loss: -1586.562012\n",
      "Train Epoch: 836 [24576/54000 (46%)] Loss: -1584.690674\n",
      "Train Epoch: 836 [28672/54000 (53%)] Loss: -1583.277222\n",
      "Train Epoch: 836 [32768/54000 (61%)] Loss: -1590.099731\n",
      "Train Epoch: 836 [36864/54000 (68%)] Loss: -1585.151367\n",
      "Train Epoch: 836 [40960/54000 (76%)] Loss: -1580.472534\n",
      "Train Epoch: 836 [45056/54000 (83%)] Loss: -1587.240967\n",
      "Train Epoch: 836 [49152/54000 (91%)] Loss: -1583.819092\n",
      "Train Epoch: 836 [53248/54000 (99%)] Loss: -1578.821655\n",
      "    epoch          : 836\n",
      "    loss           : -1584.6183196876852\n",
      "    ess            : 3.7973109760555612\n",
      "    log_marginal   : 1584.745963001703\n",
      "    val_loss       : -1584.0996907552083\n",
      "    val_ess        : 3.798207481702169\n",
      "    val_log_marginal: 1584.2259216308594\n",
      "Train Epoch: 837 [0/54000 (0%)] Loss: -1584.381470\n",
      "Train Epoch: 837 [4096/54000 (8%)] Loss: -1579.715210\n",
      "Train Epoch: 837 [8192/54000 (15%)] Loss: -1586.447754\n",
      "Train Epoch: 837 [12288/54000 (23%)] Loss: -1577.208252\n",
      "Train Epoch: 837 [16384/54000 (30%)] Loss: -1588.428955\n",
      "Train Epoch: 837 [20480/54000 (38%)] Loss: -1583.802490\n",
      "Train Epoch: 837 [24576/54000 (46%)] Loss: -1585.994751\n",
      "Train Epoch: 837 [28672/54000 (53%)] Loss: -1589.917603\n",
      "Train Epoch: 837 [32768/54000 (61%)] Loss: -1581.045898\n",
      "Train Epoch: 837 [36864/54000 (68%)] Loss: -1589.633545\n",
      "Train Epoch: 837 [40960/54000 (76%)] Loss: -1588.021362\n",
      "Train Epoch: 837 [45056/54000 (83%)] Loss: -1589.556030\n",
      "Train Epoch: 837 [49152/54000 (91%)] Loss: -1587.403809\n",
      "Train Epoch: 837 [53248/54000 (99%)] Loss: -1582.607910\n",
      "    epoch          : 837\n",
      "    loss           : -1584.7380851275548\n",
      "    ess            : 3.795511283015753\n",
      "    log_marginal   : 1584.8671174975932\n",
      "    val_loss       : -1584.3086496988933\n",
      "    val_ess        : 3.7980669339497886\n",
      "    val_log_marginal: 1584.434590657552\n",
      "Train Epoch: 838 [0/54000 (0%)] Loss: -1584.176392\n",
      "Train Epoch: 838 [4096/54000 (8%)] Loss: -1586.545654\n",
      "Train Epoch: 838 [8192/54000 (15%)] Loss: -1583.272217\n",
      "Train Epoch: 838 [12288/54000 (23%)] Loss: -1579.781982\n",
      "Train Epoch: 838 [16384/54000 (30%)] Loss: -1585.945801\n",
      "Train Epoch: 838 [20480/54000 (38%)] Loss: -1587.064453\n",
      "Train Epoch: 838 [24576/54000 (46%)] Loss: -1591.322144\n",
      "Train Epoch: 838 [28672/54000 (53%)] Loss: -1590.409302\n",
      "Train Epoch: 838 [32768/54000 (61%)] Loss: -1588.420654\n",
      "Train Epoch: 838 [36864/54000 (68%)] Loss: -1582.752197\n",
      "Train Epoch: 838 [40960/54000 (76%)] Loss: -1581.638184\n",
      "Train Epoch: 838 [45056/54000 (83%)] Loss: -1581.665283\n",
      "Train Epoch: 838 [49152/54000 (91%)] Loss: -1578.795654\n",
      "Train Epoch: 838 [53248/54000 (99%)] Loss: -1586.234253\n",
      "    epoch          : 838\n",
      "    loss           : -1584.9926219777474\n",
      "    ess            : 3.799937199642308\n",
      "    log_marginal   : 1585.1165401223711\n",
      "    val_loss       : -1583.9844868977864\n",
      "    val_ess        : 3.8015793760617576\n",
      "    val_log_marginal: 1584.0985819498699\n",
      "Train Epoch: 839 [0/54000 (0%)] Loss: -1586.082764\n",
      "Train Epoch: 839 [4096/54000 (8%)] Loss: -1585.659668\n",
      "Train Epoch: 839 [8192/54000 (15%)] Loss: -1585.856323\n",
      "Train Epoch: 839 [12288/54000 (23%)] Loss: -1590.146484\n",
      "Train Epoch: 839 [16384/54000 (30%)] Loss: -1586.920898\n",
      "Train Epoch: 839 [20480/54000 (38%)] Loss: -1589.390259\n",
      "Train Epoch: 839 [24576/54000 (46%)] Loss: -1579.378174\n",
      "Train Epoch: 839 [28672/54000 (53%)] Loss: -1587.236084\n",
      "Train Epoch: 839 [32768/54000 (61%)] Loss: -1586.859619\n",
      "Train Epoch: 839 [36864/54000 (68%)] Loss: -1584.491455\n",
      "Train Epoch: 839 [40960/54000 (76%)] Loss: -1582.631470\n",
      "Train Epoch: 839 [45056/54000 (83%)] Loss: -1588.560059\n",
      "Train Epoch: 839 [49152/54000 (91%)] Loss: -1584.291504\n",
      "Train Epoch: 839 [53248/54000 (99%)] Loss: -1587.266724\n",
      "    epoch          : 839\n",
      "    loss           : -1584.9315688869965\n",
      "    ess            : 3.794695754751775\n",
      "    log_marginal   : 1585.061384011219\n",
      "    val_loss       : -1584.9932607014973\n",
      "    val_ess        : 3.8107249637444816\n",
      "    val_log_marginal: 1585.1061350504558\n",
      "Train Epoch: 840 [0/54000 (0%)] Loss: -1584.767700\n",
      "Train Epoch: 840 [4096/54000 (8%)] Loss: -1588.656738\n",
      "Train Epoch: 840 [8192/54000 (15%)] Loss: -1575.672607\n",
      "Train Epoch: 840 [12288/54000 (23%)] Loss: -1588.341553\n",
      "Train Epoch: 840 [16384/54000 (30%)] Loss: -1585.981812\n",
      "Train Epoch: 840 [20480/54000 (38%)] Loss: -1585.604370\n",
      "Train Epoch: 840 [24576/54000 (46%)] Loss: -1591.961304\n",
      "Train Epoch: 840 [28672/54000 (53%)] Loss: -1586.776733\n",
      "Train Epoch: 840 [32768/54000 (61%)] Loss: -1584.142822\n",
      "Train Epoch: 840 [36864/54000 (68%)] Loss: -1584.190918\n",
      "Train Epoch: 840 [40960/54000 (76%)] Loss: -1585.165649\n",
      "Train Epoch: 840 [45056/54000 (83%)] Loss: -1582.211304\n",
      "Train Epoch: 840 [49152/54000 (91%)] Loss: -1585.191406\n",
      "Train Epoch: 840 [53248/54000 (99%)] Loss: -1579.135254\n",
      "    epoch          : 840\n",
      "    loss           : -1585.2478264541987\n",
      "    ess            : 3.7935828484630134\n",
      "    log_marginal   : 1585.3779886977932\n",
      "    val_loss       : -1584.3793843587239\n",
      "    val_ess        : 3.7896094620227814\n",
      "    val_log_marginal: 1584.5082092285156\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch840.pth ...\n",
      "Train Epoch: 841 [0/54000 (0%)] Loss: -1584.586792\n",
      "Train Epoch: 841 [4096/54000 (8%)] Loss: -1591.343018\n",
      "Train Epoch: 841 [8192/54000 (15%)] Loss: -1589.323975\n",
      "Train Epoch: 841 [12288/54000 (23%)] Loss: -1586.129883\n",
      "Train Epoch: 841 [16384/54000 (30%)] Loss: -1576.742676\n",
      "Train Epoch: 841 [20480/54000 (38%)] Loss: -1586.262207\n",
      "Train Epoch: 841 [24576/54000 (46%)] Loss: -1587.569336\n",
      "Train Epoch: 841 [28672/54000 (53%)] Loss: -1584.646973\n",
      "Train Epoch: 841 [32768/54000 (61%)] Loss: -1582.118408\n",
      "Train Epoch: 841 [36864/54000 (68%)] Loss: -1585.969360\n",
      "Train Epoch: 841 [40960/54000 (76%)] Loss: -1586.710938\n",
      "Train Epoch: 841 [45056/54000 (83%)] Loss: -1584.984009\n",
      "Train Epoch: 841 [49152/54000 (91%)] Loss: -1582.058228\n",
      "Train Epoch: 841 [53248/54000 (99%)] Loss: -1586.991577\n",
      "    epoch          : 841\n",
      "    loss           : -1585.0886693294578\n",
      "    ess            : 3.7989151681203976\n",
      "    log_marginal   : 1585.2107697256367\n",
      "    val_loss       : -1584.6380208333333\n",
      "    val_ess        : 3.812213192383448\n",
      "    val_log_marginal: 1584.7500610351562\n",
      "Train Epoch: 842 [0/54000 (0%)] Loss: -1584.024536\n",
      "Train Epoch: 842 [4096/54000 (8%)] Loss: -1589.453857\n",
      "Train Epoch: 842 [8192/54000 (15%)] Loss: -1583.811035\n",
      "Train Epoch: 842 [12288/54000 (23%)] Loss: -1585.783691\n",
      "Train Epoch: 842 [16384/54000 (30%)] Loss: -1583.679199\n",
      "Train Epoch: 842 [20480/54000 (38%)] Loss: -1586.721924\n",
      "Train Epoch: 842 [24576/54000 (46%)] Loss: -1587.685547\n",
      "Train Epoch: 842 [28672/54000 (53%)] Loss: -1595.677734\n",
      "Train Epoch: 842 [32768/54000 (61%)] Loss: -1587.281982\n",
      "Train Epoch: 842 [36864/54000 (68%)] Loss: -1583.966553\n",
      "Train Epoch: 842 [40960/54000 (76%)] Loss: -1587.230225\n",
      "Train Epoch: 842 [45056/54000 (83%)] Loss: -1587.035400\n",
      "Train Epoch: 842 [49152/54000 (91%)] Loss: -1584.557495\n",
      "Train Epoch: 842 [53248/54000 (99%)] Loss: -1585.163818\n",
      "    epoch          : 842\n",
      "    loss           : -1585.223776288507\n",
      "    ess            : 3.7970550060272217\n",
      "    log_marginal   : 1585.3478830346564\n",
      "    val_loss       : -1584.844721476237\n",
      "    val_ess        : 3.809740056594213\n",
      "    val_log_marginal: 1584.9632415771484\n",
      "Train Epoch: 843 [0/54000 (0%)] Loss: -1589.066772\n",
      "Train Epoch: 843 [4096/54000 (8%)] Loss: -1578.197021\n",
      "Train Epoch: 843 [8192/54000 (15%)] Loss: -1584.622559\n",
      "Train Epoch: 843 [12288/54000 (23%)] Loss: -1586.399536\n",
      "Train Epoch: 843 [16384/54000 (30%)] Loss: -1583.609497\n",
      "Train Epoch: 843 [20480/54000 (38%)] Loss: -1581.494995\n",
      "Train Epoch: 843 [24576/54000 (46%)] Loss: -1588.911377\n",
      "Train Epoch: 843 [28672/54000 (53%)] Loss: -1575.900024\n",
      "Train Epoch: 843 [32768/54000 (61%)] Loss: -1582.020630\n",
      "Train Epoch: 843 [36864/54000 (68%)] Loss: -1585.641357\n",
      "Train Epoch: 843 [40960/54000 (76%)] Loss: -1586.971558\n",
      "Train Epoch: 843 [45056/54000 (83%)] Loss: -1590.751465\n",
      "Train Epoch: 843 [49152/54000 (91%)] Loss: -1589.974365\n",
      "Train Epoch: 843 [53248/54000 (99%)] Loss: -1590.833252\n",
      "    epoch          : 843\n",
      "    loss           : -1585.4793701171875\n",
      "    ess            : 3.7984790722905744\n",
      "    log_marginal   : 1585.6026917950237\n",
      "    val_loss       : -1585.1781158447266\n",
      "    val_ess        : 3.8083951671918235\n",
      "    val_log_marginal: 1585.2947285970051\n",
      "Train Epoch: 844 [0/54000 (0%)] Loss: -1589.735596\n",
      "Train Epoch: 844 [4096/54000 (8%)] Loss: -1587.507812\n",
      "Train Epoch: 844 [8192/54000 (15%)] Loss: -1585.083130\n",
      "Train Epoch: 844 [12288/54000 (23%)] Loss: -1586.919067\n",
      "Train Epoch: 844 [16384/54000 (30%)] Loss: -1589.959106\n",
      "Train Epoch: 844 [20480/54000 (38%)] Loss: -1581.940430\n",
      "Train Epoch: 844 [24576/54000 (46%)] Loss: -1589.320801\n",
      "Train Epoch: 844 [28672/54000 (53%)] Loss: -1584.040283\n",
      "Train Epoch: 844 [32768/54000 (61%)] Loss: -1582.498535\n",
      "Train Epoch: 844 [36864/54000 (68%)] Loss: -1586.319702\n",
      "Train Epoch: 844 [40960/54000 (76%)] Loss: -1584.956299\n",
      "Train Epoch: 844 [45056/54000 (83%)] Loss: -1586.490356\n",
      "Train Epoch: 844 [49152/54000 (91%)] Loss: -1585.286621\n",
      "Train Epoch: 844 [53248/54000 (99%)] Loss: -1588.728394\n",
      "    epoch          : 844\n",
      "    loss           : -1585.5355808926984\n",
      "    ess            : 3.7951219217472167\n",
      "    log_marginal   : 1585.6623216963492\n",
      "    val_loss       : -1585.1979522705078\n",
      "    val_ess        : 3.789953718582789\n",
      "    val_log_marginal: 1585.3258565266926\n",
      "Train Epoch: 845 [0/54000 (0%)] Loss: -1582.584473\n",
      "Train Epoch: 845 [4096/54000 (8%)] Loss: -1581.158447\n",
      "Train Epoch: 845 [8192/54000 (15%)] Loss: -1581.100830\n",
      "Train Epoch: 845 [12288/54000 (23%)] Loss: -1587.242310\n",
      "Train Epoch: 845 [16384/54000 (30%)] Loss: -1575.470215\n",
      "Train Epoch: 845 [20480/54000 (38%)] Loss: -1582.692871\n",
      "Train Epoch: 845 [24576/54000 (46%)] Loss: -1583.786133\n",
      "Train Epoch: 845 [28672/54000 (53%)] Loss: -1585.503174\n",
      "Train Epoch: 845 [32768/54000 (61%)] Loss: -1578.651611\n",
      "Train Epoch: 845 [36864/54000 (68%)] Loss: -1582.141479\n",
      "Train Epoch: 845 [40960/54000 (76%)] Loss: -1585.917480\n",
      "Train Epoch: 845 [45056/54000 (83%)] Loss: -1586.324707\n",
      "Train Epoch: 845 [49152/54000 (91%)] Loss: -1585.368042\n",
      "Train Epoch: 845 [53248/54000 (99%)] Loss: -1585.473633\n",
      "    epoch          : 845\n",
      "    loss           : -1585.482306747075\n",
      "    ess            : 3.7987099044130876\n",
      "    log_marginal   : 1585.6088236587307\n",
      "    val_loss       : -1585.0086619059246\n",
      "    val_ess        : 3.7938687105973563\n",
      "    val_log_marginal: 1585.1400807698567\n",
      "Train Epoch: 846 [0/54000 (0%)] Loss: -1585.410889\n",
      "Train Epoch: 846 [4096/54000 (8%)] Loss: -1589.857178\n",
      "Train Epoch: 846 [8192/54000 (15%)] Loss: -1577.331055\n",
      "Train Epoch: 846 [12288/54000 (23%)] Loss: -1582.417358\n",
      "Train Epoch: 846 [16384/54000 (30%)] Loss: -1583.489746\n",
      "Train Epoch: 846 [20480/54000 (38%)] Loss: -1586.011597\n",
      "Train Epoch: 846 [24576/54000 (46%)] Loss: -1590.762451\n",
      "Train Epoch: 846 [28672/54000 (53%)] Loss: -1588.945435\n",
      "Train Epoch: 846 [32768/54000 (61%)] Loss: -1583.996460\n",
      "Train Epoch: 846 [36864/54000 (68%)] Loss: -1586.124390\n",
      "Train Epoch: 846 [40960/54000 (76%)] Loss: -1592.455688\n",
      "Train Epoch: 846 [45056/54000 (83%)] Loss: -1575.990479\n",
      "Train Epoch: 846 [49152/54000 (91%)] Loss: -1590.534424\n",
      "Train Epoch: 846 [53248/54000 (99%)] Loss: -1595.859741\n",
      "    epoch          : 846\n",
      "    loss           : -1585.5375803002814\n",
      "    ess            : 3.7972903794021966\n",
      "    log_marginal   : 1585.6631131285176\n",
      "    val_loss       : -1585.5263112386067\n",
      "    val_ess        : 3.7751696507136026\n",
      "    val_log_marginal: 1585.6712188720703\n",
      "Train Epoch: 847 [0/54000 (0%)] Loss: -1586.199707\n",
      "Train Epoch: 847 [4096/54000 (8%)] Loss: -1588.504883\n",
      "Train Epoch: 847 [8192/54000 (15%)] Loss: -1581.118408\n",
      "Train Epoch: 847 [12288/54000 (23%)] Loss: -1584.355713\n",
      "Train Epoch: 847 [16384/54000 (30%)] Loss: -1591.333130\n",
      "Train Epoch: 847 [20480/54000 (38%)] Loss: -1584.565674\n",
      "Train Epoch: 847 [24576/54000 (46%)] Loss: -1582.335571\n",
      "Train Epoch: 847 [28672/54000 (53%)] Loss: -1585.560669\n",
      "Train Epoch: 847 [32768/54000 (61%)] Loss: -1585.350098\n",
      "Train Epoch: 847 [36864/54000 (68%)] Loss: -1582.958252\n",
      "Train Epoch: 847 [40960/54000 (76%)] Loss: -1588.172363\n",
      "Train Epoch: 847 [45056/54000 (83%)] Loss: -1590.355469\n",
      "Train Epoch: 847 [49152/54000 (91%)] Loss: -1586.452393\n",
      "Train Epoch: 847 [53248/54000 (99%)] Loss: -1587.197021\n",
      "    epoch          : 847\n",
      "    loss           : -1585.6088329152474\n",
      "    ess            : 3.7978429093745083\n",
      "    log_marginal   : 1585.7343825209198\n",
      "    val_loss       : -1584.5381876627605\n",
      "    val_ess        : 3.8018009662628174\n",
      "    val_log_marginal: 1584.6585540771484\n",
      "Train Epoch: 848 [0/54000 (0%)] Loss: -1586.114258\n",
      "Train Epoch: 848 [4096/54000 (8%)] Loss: -1585.062988\n",
      "Train Epoch: 848 [8192/54000 (15%)] Loss: -1588.362427\n",
      "Train Epoch: 848 [12288/54000 (23%)] Loss: -1584.358887\n",
      "Train Epoch: 848 [16384/54000 (30%)] Loss: -1588.800293\n",
      "Train Epoch: 848 [20480/54000 (38%)] Loss: -1584.609375\n",
      "Train Epoch: 848 [24576/54000 (46%)] Loss: -1590.445923\n",
      "Train Epoch: 848 [28672/54000 (53%)] Loss: -1578.247559\n",
      "Train Epoch: 848 [32768/54000 (61%)] Loss: -1583.896240\n",
      "Train Epoch: 848 [36864/54000 (68%)] Loss: -1586.069092\n",
      "Train Epoch: 848 [40960/54000 (76%)] Loss: -1576.008667\n",
      "Train Epoch: 848 [45056/54000 (83%)] Loss: -1586.491211\n",
      "Train Epoch: 848 [49152/54000 (91%)] Loss: -1582.960205\n",
      "Train Epoch: 848 [53248/54000 (99%)] Loss: -1592.766602\n",
      "    epoch          : 848\n",
      "    loss           : -1585.4803472582198\n",
      "    ess            : 3.7960048049547095\n",
      "    log_marginal   : 1585.6027722110116\n",
      "    val_loss       : -1585.3954264322917\n",
      "    val_ess        : 3.7951454321543374\n",
      "    val_log_marginal: 1585.5214029947917\n",
      "Train Epoch: 849 [0/54000 (0%)] Loss: -1588.246216\n",
      "Train Epoch: 849 [4096/54000 (8%)] Loss: -1583.177368\n",
      "Train Epoch: 849 [8192/54000 (15%)] Loss: -1584.201172\n",
      "Train Epoch: 849 [12288/54000 (23%)] Loss: -1578.664062\n",
      "Train Epoch: 849 [16384/54000 (30%)] Loss: -1582.526489\n",
      "Train Epoch: 849 [20480/54000 (38%)] Loss: -1583.037109\n",
      "Train Epoch: 849 [24576/54000 (46%)] Loss: -1586.559082\n",
      "Train Epoch: 849 [28672/54000 (53%)] Loss: -1586.497559\n",
      "Train Epoch: 849 [32768/54000 (61%)] Loss: -1592.077759\n",
      "Train Epoch: 849 [36864/54000 (68%)] Loss: -1587.703003\n",
      "Train Epoch: 849 [40960/54000 (76%)] Loss: -1589.451172\n",
      "Train Epoch: 849 [45056/54000 (83%)] Loss: -1583.870117\n",
      "Train Epoch: 849 [49152/54000 (91%)] Loss: -1578.724976\n",
      "Train Epoch: 849 [53248/54000 (99%)] Loss: -1583.069092\n",
      "    epoch          : 849\n",
      "    loss           : -1585.369177072534\n",
      "    ess            : 3.79633342824276\n",
      "    log_marginal   : 1585.4949615623148\n",
      "    val_loss       : -1585.8786061604817\n",
      "    val_ess        : 3.7985201478004456\n",
      "    val_log_marginal: 1586.0081837972004\n",
      "Train Epoch: 850 [0/54000 (0%)] Loss: -1589.106079\n",
      "Train Epoch: 850 [4096/54000 (8%)] Loss: -1584.915039\n",
      "Train Epoch: 850 [8192/54000 (15%)] Loss: -1587.169678\n",
      "Train Epoch: 850 [12288/54000 (23%)] Loss: -1582.468994\n",
      "Train Epoch: 850 [16384/54000 (30%)] Loss: -1579.115967\n",
      "Train Epoch: 850 [20480/54000 (38%)] Loss: -1581.790039\n",
      "Train Epoch: 850 [24576/54000 (46%)] Loss: -1583.796509\n",
      "Train Epoch: 850 [28672/54000 (53%)] Loss: -1580.127319\n",
      "Train Epoch: 850 [32768/54000 (61%)] Loss: -1583.696411\n",
      "Train Epoch: 850 [36864/54000 (68%)] Loss: -1587.269775\n",
      "Train Epoch: 850 [40960/54000 (76%)] Loss: -1586.475342\n",
      "Train Epoch: 850 [45056/54000 (83%)] Loss: -1586.510620\n",
      "Train Epoch: 850 [49152/54000 (91%)] Loss: -1584.671875\n",
      "Train Epoch: 850 [53248/54000 (99%)] Loss: -1595.821533\n",
      "    epoch          : 850\n",
      "    loss           : -1585.3152919968159\n",
      "    ess            : 3.796479796911303\n",
      "    log_marginal   : 1585.441133761293\n",
      "    val_loss       : -1585.2715301513672\n",
      "    val_ess        : 3.815430223941803\n",
      "    val_log_marginal: 1585.3857828776042\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [0/54000 (0%)] Loss: -1584.139404\n",
      "Train Epoch: 851 [4096/54000 (8%)] Loss: -1587.214600\n",
      "Train Epoch: 851 [8192/54000 (15%)] Loss: -1586.603516\n",
      "Train Epoch: 851 [12288/54000 (23%)] Loss: -1577.432617\n",
      "Train Epoch: 851 [16384/54000 (30%)] Loss: -1584.577637\n",
      "Train Epoch: 851 [20480/54000 (38%)] Loss: -1582.292480\n",
      "Train Epoch: 851 [24576/54000 (46%)] Loss: -1583.050049\n",
      "Train Epoch: 851 [28672/54000 (53%)] Loss: -1589.092163\n",
      "Train Epoch: 851 [32768/54000 (61%)] Loss: -1592.013428\n",
      "Train Epoch: 851 [36864/54000 (68%)] Loss: -1585.724854\n",
      "Train Epoch: 851 [40960/54000 (76%)] Loss: -1586.324097\n",
      "Train Epoch: 851 [45056/54000 (83%)] Loss: -1586.844971\n",
      "Train Epoch: 851 [49152/54000 (91%)] Loss: -1592.595947\n",
      "Train Epoch: 851 [53248/54000 (99%)] Loss: -1579.843018\n",
      "    epoch          : 851\n",
      "    loss           : -1585.2905979246889\n",
      "    ess            : 3.7941843231707386\n",
      "    log_marginal   : 1585.415884876703\n",
      "    val_loss       : -1584.6033884684246\n",
      "    val_ess        : 3.7904163897037506\n",
      "    val_log_marginal: 1584.730951944987\n",
      "Train Epoch: 852 [0/54000 (0%)] Loss: -1582.685791\n",
      "Train Epoch: 852 [4096/54000 (8%)] Loss: -1588.907471\n",
      "Train Epoch: 852 [8192/54000 (15%)] Loss: -1590.649780\n",
      "Train Epoch: 852 [12288/54000 (23%)] Loss: -1585.406494\n",
      "Train Epoch: 852 [16384/54000 (30%)] Loss: -1588.345093\n",
      "Train Epoch: 852 [20480/54000 (38%)] Loss: -1588.406250\n",
      "Train Epoch: 852 [24576/54000 (46%)] Loss: -1586.546875\n",
      "Train Epoch: 852 [28672/54000 (53%)] Loss: -1590.968750\n",
      "Train Epoch: 852 [32768/54000 (61%)] Loss: -1585.974609\n",
      "Train Epoch: 852 [36864/54000 (68%)] Loss: -1587.664062\n",
      "Train Epoch: 852 [40960/54000 (76%)] Loss: -1582.698486\n",
      "Train Epoch: 852 [45056/54000 (83%)] Loss: -1593.059204\n",
      "Train Epoch: 852 [49152/54000 (91%)] Loss: -1583.072388\n",
      "Train Epoch: 852 [53248/54000 (99%)] Loss: -1579.941406\n",
      "    epoch          : 852\n",
      "    loss           : -1585.3044653436018\n",
      "    ess            : 3.7954926818467993\n",
      "    log_marginal   : 1585.4303510765328\n",
      "    val_loss       : -1584.6181945800781\n",
      "    val_ess        : 3.795381933450699\n",
      "    val_log_marginal: 1584.7424926757812\n",
      "Train Epoch: 853 [0/54000 (0%)] Loss: -1584.887817\n",
      "Train Epoch: 853 [4096/54000 (8%)] Loss: -1579.190186\n",
      "Train Epoch: 853 [8192/54000 (15%)] Loss: -1583.655273\n",
      "Train Epoch: 853 [12288/54000 (23%)] Loss: -1582.928589\n",
      "Train Epoch: 853 [16384/54000 (30%)] Loss: -1581.072998\n",
      "Train Epoch: 853 [20480/54000 (38%)] Loss: -1586.509033\n",
      "Train Epoch: 853 [24576/54000 (46%)] Loss: -1576.052246\n",
      "Train Epoch: 853 [28672/54000 (53%)] Loss: -1590.050293\n",
      "Train Epoch: 853 [32768/54000 (61%)] Loss: -1586.948486\n",
      "Train Epoch: 853 [36864/54000 (68%)] Loss: -1585.491211\n",
      "Train Epoch: 853 [40960/54000 (76%)] Loss: -1581.566895\n",
      "Train Epoch: 853 [45056/54000 (83%)] Loss: -1586.550537\n",
      "Train Epoch: 853 [49152/54000 (91%)] Loss: -1589.158447\n",
      "Train Epoch: 853 [53248/54000 (99%)] Loss: -1589.075317\n",
      "    epoch          : 853\n",
      "    loss           : -1585.2904926318129\n",
      "    ess            : 3.793948104596251\n",
      "    log_marginal   : 1585.4203291617298\n",
      "    val_loss       : -1585.553955078125\n",
      "    val_ess        : 3.7944533626238504\n",
      "    val_log_marginal: 1585.6802978515625\n",
      "Train Epoch: 854 [0/54000 (0%)] Loss: -1589.455566\n",
      "Train Epoch: 854 [4096/54000 (8%)] Loss: -1580.560913\n",
      "Train Epoch: 854 [8192/54000 (15%)] Loss: -1587.586670\n",
      "Train Epoch: 854 [12288/54000 (23%)] Loss: -1577.684082\n",
      "Train Epoch: 854 [16384/54000 (30%)] Loss: -1582.625488\n",
      "Train Epoch: 854 [20480/54000 (38%)] Loss: -1583.584473\n",
      "Train Epoch: 854 [24576/54000 (46%)] Loss: -1589.925903\n",
      "Train Epoch: 854 [28672/54000 (53%)] Loss: -1587.010132\n",
      "Train Epoch: 854 [32768/54000 (61%)] Loss: -1590.195068\n",
      "Train Epoch: 854 [36864/54000 (68%)] Loss: -1588.655518\n",
      "Train Epoch: 854 [40960/54000 (76%)] Loss: -1593.205811\n",
      "Train Epoch: 854 [45056/54000 (83%)] Loss: -1580.165527\n",
      "Train Epoch: 854 [49152/54000 (91%)] Loss: -1580.577148\n",
      "Train Epoch: 854 [53248/54000 (99%)] Loss: -1588.866211\n",
      "    epoch          : 854\n",
      "    loss           : -1585.5297220962307\n",
      "    ess            : 3.7898432959877484\n",
      "    log_marginal   : 1585.6628221267772\n",
      "    val_loss       : -1586.110590616862\n",
      "    val_ess        : 3.8023955623308816\n",
      "    val_log_marginal: 1586.2382100423176\n",
      "Train Epoch: 855 [0/54000 (0%)] Loss: -1587.671875\n",
      "Train Epoch: 855 [4096/54000 (8%)] Loss: -1588.490845\n",
      "Train Epoch: 855 [8192/54000 (15%)] Loss: -1580.987793\n",
      "Train Epoch: 855 [12288/54000 (23%)] Loss: -1584.930420\n",
      "Train Epoch: 855 [16384/54000 (30%)] Loss: -1584.446533\n",
      "Train Epoch: 855 [20480/54000 (38%)] Loss: -1585.096191\n",
      "Train Epoch: 855 [24576/54000 (46%)] Loss: -1592.695801\n",
      "Train Epoch: 855 [28672/54000 (53%)] Loss: -1578.156250\n",
      "Train Epoch: 855 [32768/54000 (61%)] Loss: -1585.779053\n",
      "Train Epoch: 855 [36864/54000 (68%)] Loss: -1590.174927\n",
      "Train Epoch: 855 [40960/54000 (76%)] Loss: -1579.661499\n",
      "Train Epoch: 855 [45056/54000 (83%)] Loss: -1587.102539\n",
      "Train Epoch: 855 [49152/54000 (91%)] Loss: -1579.716797\n",
      "Train Epoch: 855 [53248/54000 (99%)] Loss: -1581.399658\n",
      "    epoch          : 855\n",
      "    loss           : -1585.5700047208234\n",
      "    ess            : 3.7958611018284802\n",
      "    log_marginal   : 1585.695752184538\n",
      "    val_loss       : -1585.1479237874348\n",
      "    val_ess        : 3.804732362429301\n",
      "    val_log_marginal: 1585.2677917480469\n",
      "Train Epoch: 856 [0/54000 (0%)] Loss: -1587.539185\n",
      "Train Epoch: 856 [4096/54000 (8%)] Loss: -1592.914795\n",
      "Train Epoch: 856 [8192/54000 (15%)] Loss: -1576.155273\n",
      "Train Epoch: 856 [12288/54000 (23%)] Loss: -1579.675293\n",
      "Train Epoch: 856 [16384/54000 (30%)] Loss: -1588.736328\n",
      "Train Epoch: 856 [20480/54000 (38%)] Loss: -1578.919922\n",
      "Train Epoch: 856 [24576/54000 (46%)] Loss: -1579.131226\n",
      "Train Epoch: 856 [28672/54000 (53%)] Loss: -1587.993286\n",
      "Train Epoch: 856 [32768/54000 (61%)] Loss: -1585.943359\n",
      "Train Epoch: 856 [36864/54000 (68%)] Loss: -1587.051636\n",
      "Train Epoch: 856 [40960/54000 (76%)] Loss: -1587.156738\n",
      "Train Epoch: 856 [45056/54000 (83%)] Loss: -1584.880127\n",
      "Train Epoch: 856 [49152/54000 (91%)] Loss: -1589.847168\n",
      "Train Epoch: 856 [53248/54000 (99%)] Loss: -1582.224243\n",
      "    epoch          : 856\n",
      "    loss           : -1585.5322155703866\n",
      "    ess            : 3.7996456430986596\n",
      "    log_marginal   : 1585.659012491669\n",
      "    val_loss       : -1585.2957661946614\n",
      "    val_ess        : 3.801494518915812\n",
      "    val_log_marginal: 1585.4249471028645\n",
      "Train Epoch: 857 [0/54000 (0%)] Loss: -1585.502197\n",
      "Train Epoch: 857 [4096/54000 (8%)] Loss: -1580.673340\n",
      "Train Epoch: 857 [8192/54000 (15%)] Loss: -1578.104736\n",
      "Train Epoch: 857 [12288/54000 (23%)] Loss: -1586.592529\n",
      "Train Epoch: 857 [16384/54000 (30%)] Loss: -1586.430420\n",
      "Train Epoch: 857 [20480/54000 (38%)] Loss: -1582.518677\n",
      "Train Epoch: 857 [24576/54000 (46%)] Loss: -1586.407227\n",
      "Train Epoch: 857 [28672/54000 (53%)] Loss: -1585.151367\n",
      "Train Epoch: 857 [32768/54000 (61%)] Loss: -1587.211670\n",
      "Train Epoch: 857 [36864/54000 (68%)] Loss: -1586.775391\n",
      "Train Epoch: 857 [40960/54000 (76%)] Loss: -1586.666382\n",
      "Train Epoch: 857 [45056/54000 (83%)] Loss: -1577.661865\n",
      "Train Epoch: 857 [49152/54000 (91%)] Loss: -1587.506348\n",
      "Train Epoch: 857 [53248/54000 (99%)] Loss: -1584.159912\n",
      "    epoch          : 857\n",
      "    loss           : -1585.3321521632479\n",
      "    ess            : 3.79751848496532\n",
      "    log_marginal   : 1585.4570549698237\n",
      "    val_loss       : -1584.7520802815754\n",
      "    val_ess        : 3.781678020954132\n",
      "    val_log_marginal: 1584.8992716471355\n",
      "Train Epoch: 858 [0/54000 (0%)] Loss: -1583.506958\n",
      "Train Epoch: 858 [4096/54000 (8%)] Loss: -1587.615967\n",
      "Train Epoch: 858 [8192/54000 (15%)] Loss: -1595.710693\n",
      "Train Epoch: 858 [12288/54000 (23%)] Loss: -1580.029541\n",
      "Train Epoch: 858 [16384/54000 (30%)] Loss: -1583.489258\n",
      "Train Epoch: 858 [20480/54000 (38%)] Loss: -1589.079590\n",
      "Train Epoch: 858 [24576/54000 (46%)] Loss: -1578.160889\n",
      "Train Epoch: 858 [28672/54000 (53%)] Loss: -1587.122314\n",
      "Train Epoch: 858 [32768/54000 (61%)] Loss: -1584.188721\n",
      "Train Epoch: 858 [36864/54000 (68%)] Loss: -1580.619873\n",
      "Train Epoch: 858 [40960/54000 (76%)] Loss: -1582.114014\n",
      "Train Epoch: 858 [45056/54000 (83%)] Loss: -1584.169922\n",
      "Train Epoch: 858 [49152/54000 (91%)] Loss: -1587.271851\n",
      "Train Epoch: 858 [53248/54000 (99%)] Loss: -1586.407471\n",
      "    epoch          : 858\n",
      "    loss           : -1585.6529037692535\n",
      "    ess            : 3.7914343298328994\n",
      "    log_marginal   : 1585.7856051910544\n",
      "    val_loss       : -1585.2723032633464\n",
      "    val_ess        : 3.8082660933335624\n",
      "    val_log_marginal: 1585.3798268636067\n",
      "Train Epoch: 859 [0/54000 (0%)] Loss: -1581.879639\n",
      "Train Epoch: 859 [4096/54000 (8%)] Loss: -1590.092285\n",
      "Train Epoch: 859 [8192/54000 (15%)] Loss: -1584.936768\n",
      "Train Epoch: 859 [12288/54000 (23%)] Loss: -1588.402344\n",
      "Train Epoch: 859 [16384/54000 (30%)] Loss: -1589.727905\n",
      "Train Epoch: 859 [20480/54000 (38%)] Loss: -1588.333008\n",
      "Train Epoch: 859 [24576/54000 (46%)] Loss: -1581.255615\n",
      "Train Epoch: 859 [28672/54000 (53%)] Loss: -1583.547729\n",
      "Train Epoch: 859 [32768/54000 (61%)] Loss: -1598.129028\n",
      "Train Epoch: 859 [36864/54000 (68%)] Loss: -1581.776367\n",
      "Train Epoch: 859 [40960/54000 (76%)] Loss: -1584.866699\n",
      "Train Epoch: 859 [45056/54000 (83%)] Loss: -1590.224365\n",
      "Train Epoch: 859 [49152/54000 (91%)] Loss: -1580.601929\n",
      "Train Epoch: 859 [53248/54000 (99%)] Loss: -1584.847290\n",
      "    epoch          : 859\n",
      "    loss           : -1585.6449263875518\n",
      "    ess            : 3.794978026530189\n",
      "    log_marginal   : 1585.7708821228896\n",
      "    val_loss       : -1584.8104553222656\n",
      "    val_ess        : 3.7979277670383453\n",
      "    val_log_marginal: 1584.9273274739583\n",
      "Train Epoch: 860 [0/54000 (0%)] Loss: -1584.836670\n",
      "Train Epoch: 860 [4096/54000 (8%)] Loss: -1580.261230\n",
      "Train Epoch: 860 [8192/54000 (15%)] Loss: -1591.961914\n",
      "Train Epoch: 860 [12288/54000 (23%)] Loss: -1582.112549\n",
      "Train Epoch: 860 [16384/54000 (30%)] Loss: -1586.095581\n",
      "Train Epoch: 860 [20480/54000 (38%)] Loss: -1594.434570\n",
      "Train Epoch: 860 [24576/54000 (46%)] Loss: -1586.360596\n",
      "Train Epoch: 860 [28672/54000 (53%)] Loss: -1586.732788\n",
      "Train Epoch: 860 [32768/54000 (61%)] Loss: -1590.343994\n",
      "Train Epoch: 860 [36864/54000 (68%)] Loss: -1589.228271\n",
      "Train Epoch: 860 [40960/54000 (76%)] Loss: -1585.980713\n",
      "Train Epoch: 860 [45056/54000 (83%)] Loss: -1580.752686\n",
      "Train Epoch: 860 [49152/54000 (91%)] Loss: -1582.569092\n",
      "Train Epoch: 860 [53248/54000 (99%)] Loss: -1576.138794\n",
      "    epoch          : 860\n",
      "    loss           : -1585.6538230570573\n",
      "    ess            : 3.7963659198363247\n",
      "    log_marginal   : 1585.7775491289617\n",
      "    val_loss       : -1585.1990763346355\n",
      "    val_ess        : 3.79231588045756\n",
      "    val_log_marginal: 1585.3251444498699\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch860.pth ...\n",
      "Train Epoch: 861 [0/54000 (0%)] Loss: -1582.555908\n",
      "Train Epoch: 861 [4096/54000 (8%)] Loss: -1588.918213\n",
      "Train Epoch: 861 [8192/54000 (15%)] Loss: -1588.814941\n",
      "Train Epoch: 861 [12288/54000 (23%)] Loss: -1578.789673\n",
      "Train Epoch: 861 [16384/54000 (30%)] Loss: -1581.845825\n",
      "Train Epoch: 861 [20480/54000 (38%)] Loss: -1588.700195\n",
      "Train Epoch: 861 [24576/54000 (46%)] Loss: -1588.155396\n",
      "Train Epoch: 861 [28672/54000 (53%)] Loss: -1584.764893\n",
      "Train Epoch: 861 [32768/54000 (61%)] Loss: -1581.887695\n",
      "Train Epoch: 861 [36864/54000 (68%)] Loss: -1582.876953\n",
      "Train Epoch: 861 [40960/54000 (76%)] Loss: -1582.972656\n",
      "Train Epoch: 861 [45056/54000 (83%)] Loss: -1588.734619\n",
      "Train Epoch: 861 [49152/54000 (91%)] Loss: -1585.922485\n",
      "Train Epoch: 861 [53248/54000 (99%)] Loss: -1590.482544\n",
      "    epoch          : 861\n",
      "    loss           : -1585.7470211372556\n",
      "    ess            : 3.794846560717759\n",
      "    log_marginal   : 1585.8770566822793\n",
      "    val_loss       : -1585.7178192138672\n",
      "    val_ess        : 3.795635014772415\n",
      "    val_log_marginal: 1585.8475799560547\n",
      "Train Epoch: 862 [0/54000 (0%)] Loss: -1587.773926\n",
      "Train Epoch: 862 [4096/54000 (8%)] Loss: -1588.294434\n",
      "Train Epoch: 862 [8192/54000 (15%)] Loss: -1580.043945\n",
      "Train Epoch: 862 [12288/54000 (23%)] Loss: -1580.267578\n",
      "Train Epoch: 862 [16384/54000 (30%)] Loss: -1589.382812\n",
      "Train Epoch: 862 [20480/54000 (38%)] Loss: -1588.244141\n",
      "Train Epoch: 862 [24576/54000 (46%)] Loss: -1585.889160\n",
      "Train Epoch: 862 [28672/54000 (53%)] Loss: -1581.450928\n",
      "Train Epoch: 862 [32768/54000 (61%)] Loss: -1581.753052\n",
      "Train Epoch: 862 [36864/54000 (68%)] Loss: -1580.135376\n",
      "Train Epoch: 862 [40960/54000 (76%)] Loss: -1586.089111\n",
      "Train Epoch: 862 [45056/54000 (83%)] Loss: -1585.478271\n",
      "Train Epoch: 862 [49152/54000 (91%)] Loss: -1583.263428\n",
      "Train Epoch: 862 [53248/54000 (99%)] Loss: -1585.662964\n",
      "    epoch          : 862\n",
      "    loss           : -1585.99397111504\n",
      "    ess            : 3.793200696249144\n",
      "    log_marginal   : 1586.121489466084\n",
      "    val_loss       : -1586.0408579508464\n",
      "    val_ess        : 3.800900171200434\n",
      "    val_log_marginal: 1586.164794921875\n",
      "Train Epoch: 863 [0/54000 (0%)] Loss: -1588.069092\n",
      "Train Epoch: 863 [4096/54000 (8%)] Loss: -1588.955566\n",
      "Train Epoch: 863 [8192/54000 (15%)] Loss: -1588.007690\n",
      "Train Epoch: 863 [12288/54000 (23%)] Loss: -1583.083740\n",
      "Train Epoch: 863 [16384/54000 (30%)] Loss: -1589.396240\n",
      "Train Epoch: 863 [20480/54000 (38%)] Loss: -1582.885376\n",
      "Train Epoch: 863 [24576/54000 (46%)] Loss: -1583.265137\n",
      "Train Epoch: 863 [28672/54000 (53%)] Loss: -1588.528076\n",
      "Train Epoch: 863 [32768/54000 (61%)] Loss: -1582.626099\n",
      "Train Epoch: 863 [36864/54000 (68%)] Loss: -1591.251953\n",
      "Train Epoch: 863 [40960/54000 (76%)] Loss: -1581.375244\n",
      "Train Epoch: 863 [45056/54000 (83%)] Loss: -1590.859131\n",
      "Train Epoch: 863 [49152/54000 (91%)] Loss: -1581.733276\n",
      "Train Epoch: 863 [53248/54000 (99%)] Loss: -1587.697266\n",
      "    epoch          : 863\n",
      "    loss           : -1585.8807488753332\n",
      "    ess            : 3.800098670037437\n",
      "    log_marginal   : 1586.003351437537\n",
      "    val_loss       : -1586.1049092610676\n",
      "    val_ess        : 3.7973921795686087\n",
      "    val_log_marginal: 1586.230229695638\n",
      "Train Epoch: 864 [0/54000 (0%)] Loss: -1591.217163\n",
      "Train Epoch: 864 [4096/54000 (8%)] Loss: -1582.090820\n",
      "Train Epoch: 864 [8192/54000 (15%)] Loss: -1578.944824\n",
      "Train Epoch: 864 [12288/54000 (23%)] Loss: -1586.400146\n",
      "Train Epoch: 864 [16384/54000 (30%)] Loss: -1587.421265\n",
      "Train Epoch: 864 [20480/54000 (38%)] Loss: -1587.134277\n",
      "Train Epoch: 864 [24576/54000 (46%)] Loss: -1588.797607\n",
      "Train Epoch: 864 [28672/54000 (53%)] Loss: -1581.186279\n",
      "Train Epoch: 864 [32768/54000 (61%)] Loss: -1586.930176\n",
      "Train Epoch: 864 [36864/54000 (68%)] Loss: -1583.190308\n",
      "Train Epoch: 864 [40960/54000 (76%)] Loss: -1589.064209\n",
      "Train Epoch: 864 [45056/54000 (83%)] Loss: -1584.549194\n",
      "Train Epoch: 864 [49152/54000 (91%)] Loss: -1584.559692\n",
      "Train Epoch: 864 [53248/54000 (99%)] Loss: -1599.556152\n",
      "    epoch          : 864\n",
      "    loss           : -1586.2051458132776\n",
      "    ess            : 3.7924782642256027\n",
      "    log_marginal   : 1586.3330436815017\n",
      "    val_loss       : -1586.429946899414\n",
      "    val_ess        : 3.80282594760259\n",
      "    val_log_marginal: 1586.5540873209636\n",
      "Train Epoch: 865 [0/54000 (0%)] Loss: -1586.417236\n",
      "Train Epoch: 865 [4096/54000 (8%)] Loss: -1587.874268\n",
      "Train Epoch: 865 [8192/54000 (15%)] Loss: -1594.193726\n",
      "Train Epoch: 865 [12288/54000 (23%)] Loss: -1584.797607\n",
      "Train Epoch: 865 [16384/54000 (30%)] Loss: -1582.648438\n",
      "Train Epoch: 865 [20480/54000 (38%)] Loss: -1579.960449\n",
      "Train Epoch: 865 [24576/54000 (46%)] Loss: -1584.873047\n",
      "Train Epoch: 865 [28672/54000 (53%)] Loss: -1594.588623\n",
      "Train Epoch: 865 [32768/54000 (61%)] Loss: -1585.366089\n",
      "Train Epoch: 865 [36864/54000 (68%)] Loss: -1583.431396\n",
      "Train Epoch: 865 [40960/54000 (76%)] Loss: -1584.856201\n",
      "Train Epoch: 865 [45056/54000 (83%)] Loss: -1589.708618\n",
      "Train Epoch: 865 [49152/54000 (91%)] Loss: -1588.059570\n",
      "Train Epoch: 865 [53248/54000 (99%)] Loss: -1582.838257\n",
      "    epoch          : 865\n",
      "    loss           : -1586.1580671699126\n",
      "    ess            : 3.7982516187062196\n",
      "    log_marginal   : 1586.2845470555021\n",
      "    val_loss       : -1586.6977081298828\n",
      "    val_ess        : 3.8004894455273948\n",
      "    val_log_marginal: 1586.8203379313152\n",
      "Train Epoch: 866 [0/54000 (0%)] Loss: -1589.342041\n",
      "Train Epoch: 866 [4096/54000 (8%)] Loss: -1578.887207\n",
      "Train Epoch: 866 [8192/54000 (15%)] Loss: -1585.989990\n",
      "Train Epoch: 866 [12288/54000 (23%)] Loss: -1589.426025\n",
      "Train Epoch: 866 [16384/54000 (30%)] Loss: -1584.879517\n",
      "Train Epoch: 866 [20480/54000 (38%)] Loss: -1583.067383\n",
      "Train Epoch: 866 [24576/54000 (46%)] Loss: -1586.646606\n",
      "Train Epoch: 866 [28672/54000 (53%)] Loss: -1591.200195\n",
      "Train Epoch: 866 [32768/54000 (61%)] Loss: -1585.728027\n",
      "Train Epoch: 866 [36864/54000 (68%)] Loss: -1589.307617\n",
      "Train Epoch: 866 [40960/54000 (76%)] Loss: -1586.516357\n",
      "Train Epoch: 866 [45056/54000 (83%)] Loss: -1585.035156\n",
      "Train Epoch: 866 [49152/54000 (91%)] Loss: -1587.423828\n",
      "Train Epoch: 866 [53248/54000 (99%)] Loss: -1583.689575\n",
      "    epoch          : 866\n",
      "    loss           : -1586.0533696034508\n",
      "    ess            : 3.798580938040928\n",
      "    log_marginal   : 1586.1784234069535\n",
      "    val_loss       : -1586.2779337565105\n",
      "    val_ess        : 3.789587070544561\n",
      "    val_log_marginal: 1586.4095611572266\n",
      "Train Epoch: 867 [0/54000 (0%)] Loss: -1587.419678\n",
      "Train Epoch: 867 [4096/54000 (8%)] Loss: -1585.718018\n",
      "Train Epoch: 867 [8192/54000 (15%)] Loss: -1584.565918\n",
      "Train Epoch: 867 [12288/54000 (23%)] Loss: -1591.419189\n",
      "Train Epoch: 867 [16384/54000 (30%)] Loss: -1581.546631\n",
      "Train Epoch: 867 [20480/54000 (38%)] Loss: -1589.140381\n",
      "Train Epoch: 867 [24576/54000 (46%)] Loss: -1583.014282\n",
      "Train Epoch: 867 [28672/54000 (53%)] Loss: -1581.046875\n",
      "Train Epoch: 867 [32768/54000 (61%)] Loss: -1585.604004\n",
      "Train Epoch: 867 [36864/54000 (68%)] Loss: -1581.225586\n",
      "Train Epoch: 867 [40960/54000 (76%)] Loss: -1590.082275\n",
      "Train Epoch: 867 [45056/54000 (83%)] Loss: -1587.260132\n",
      "Train Epoch: 867 [49152/54000 (91%)] Loss: -1587.691406\n",
      "Train Epoch: 867 [53248/54000 (99%)] Loss: -1581.306152\n",
      "    epoch          : 867\n",
      "    loss           : -1586.0378713020216\n",
      "    ess            : 3.7967377172262182\n",
      "    log_marginal   : 1586.166963839418\n",
      "    val_loss       : -1586.437759399414\n",
      "    val_ess        : 3.792204737663269\n",
      "    val_log_marginal: 1586.5644989013672\n",
      "Train Epoch: 868 [0/54000 (0%)] Loss: -1586.414307\n",
      "Train Epoch: 868 [4096/54000 (8%)] Loss: -1593.548096\n",
      "Train Epoch: 868 [8192/54000 (15%)] Loss: -1586.977783\n",
      "Train Epoch: 868 [12288/54000 (23%)] Loss: -1587.896240\n",
      "Train Epoch: 868 [16384/54000 (30%)] Loss: -1587.160400\n",
      "Train Epoch: 868 [20480/54000 (38%)] Loss: -1590.749268\n",
      "Train Epoch: 868 [24576/54000 (46%)] Loss: -1587.495117\n",
      "Train Epoch: 868 [28672/54000 (53%)] Loss: -1584.685425\n",
      "Train Epoch: 868 [32768/54000 (61%)] Loss: -1587.021973\n",
      "Train Epoch: 868 [36864/54000 (68%)] Loss: -1582.450195\n",
      "Train Epoch: 868 [40960/54000 (76%)] Loss: -1582.282227\n",
      "Train Epoch: 868 [45056/54000 (83%)] Loss: -1591.915283\n",
      "Train Epoch: 868 [49152/54000 (91%)] Loss: -1585.664307\n",
      "Train Epoch: 868 [53248/54000 (99%)] Loss: -1580.660889\n",
      "    epoch          : 868\n",
      "    loss           : -1585.9965797171208\n",
      "    ess            : 3.800477528459088\n",
      "    log_marginal   : 1586.120310995816\n",
      "    val_loss       : -1585.8914947509766\n",
      "    val_ess        : 3.7856417298316956\n",
      "    val_log_marginal: 1586.0350036621094\n",
      "Train Epoch: 869 [0/54000 (0%)] Loss: -1581.715576\n",
      "Train Epoch: 869 [4096/54000 (8%)] Loss: -1586.073120\n",
      "Train Epoch: 869 [8192/54000 (15%)] Loss: -1584.040527\n",
      "Train Epoch: 869 [12288/54000 (23%)] Loss: -1589.312378\n",
      "Train Epoch: 869 [16384/54000 (30%)] Loss: -1586.268188\n",
      "Train Epoch: 869 [20480/54000 (38%)] Loss: -1581.183594\n",
      "Train Epoch: 869 [24576/54000 (46%)] Loss: -1592.051025\n",
      "Train Epoch: 869 [28672/54000 (53%)] Loss: -1591.355225\n",
      "Train Epoch: 869 [32768/54000 (61%)] Loss: -1588.529663\n",
      "Train Epoch: 869 [36864/54000 (68%)] Loss: -1592.280151\n",
      "Train Epoch: 869 [40960/54000 (76%)] Loss: -1584.246826\n",
      "Train Epoch: 869 [45056/54000 (83%)] Loss: -1582.284546\n",
      "Train Epoch: 869 [49152/54000 (91%)] Loss: -1584.043701\n",
      "Train Epoch: 869 [53248/54000 (99%)] Loss: -1589.059326\n",
      "    epoch          : 869\n",
      "    loss           : -1586.0202347452607\n",
      "    ess            : 3.796959637465635\n",
      "    log_marginal   : 1586.1456015347305\n",
      "    val_loss       : -1585.463114420573\n",
      "    val_ess        : 3.793986588716507\n",
      "    val_log_marginal: 1585.5965728759766\n",
      "Train Epoch: 870 [0/54000 (0%)] Loss: -1587.587891\n",
      "Train Epoch: 870 [4096/54000 (8%)] Loss: -1588.487061\n",
      "Train Epoch: 870 [8192/54000 (15%)] Loss: -1586.923096\n",
      "Train Epoch: 870 [12288/54000 (23%)] Loss: -1587.841797\n",
      "Train Epoch: 870 [16384/54000 (30%)] Loss: -1585.304688\n",
      "Train Epoch: 870 [20480/54000 (38%)] Loss: -1594.098389\n",
      "Train Epoch: 870 [24576/54000 (46%)] Loss: -1588.559448\n",
      "Train Epoch: 870 [28672/54000 (53%)] Loss: -1587.836914\n",
      "Train Epoch: 870 [32768/54000 (61%)] Loss: -1587.387695\n",
      "Train Epoch: 870 [36864/54000 (68%)] Loss: -1584.918823\n",
      "Train Epoch: 870 [40960/54000 (76%)] Loss: -1587.676514\n",
      "Train Epoch: 870 [45056/54000 (83%)] Loss: -1583.384766\n",
      "Train Epoch: 870 [49152/54000 (91%)] Loss: -1578.945312\n",
      "Train Epoch: 870 [53248/54000 (99%)] Loss: -1589.420898\n",
      "    epoch          : 870\n",
      "    loss           : -1586.1073698070943\n",
      "    ess            : 3.798445109507484\n",
      "    log_marginal   : 1586.228739516995\n",
      "    val_loss       : -1586.2038981119792\n",
      "    val_ess        : 3.7990408837795258\n",
      "    val_log_marginal: 1586.3262176513672\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch870.pth ...\n",
      "Train Epoch: 871 [0/54000 (0%)] Loss: -1583.949585\n",
      "Train Epoch: 871 [4096/54000 (8%)] Loss: -1589.936279\n",
      "Train Epoch: 871 [8192/54000 (15%)] Loss: -1585.358154\n",
      "Train Epoch: 871 [12288/54000 (23%)] Loss: -1582.736328\n",
      "Train Epoch: 871 [16384/54000 (30%)] Loss: -1585.239014\n",
      "Train Epoch: 871 [20480/54000 (38%)] Loss: -1578.041260\n",
      "Train Epoch: 871 [24576/54000 (46%)] Loss: -1590.291992\n",
      "Train Epoch: 871 [28672/54000 (53%)] Loss: -1587.591187\n",
      "Train Epoch: 871 [32768/54000 (61%)] Loss: -1590.761475\n",
      "Train Epoch: 871 [36864/54000 (68%)] Loss: -1591.203247\n",
      "Train Epoch: 871 [40960/54000 (76%)] Loss: -1588.204468\n",
      "Train Epoch: 871 [45056/54000 (83%)] Loss: -1588.585815\n",
      "Train Epoch: 871 [49152/54000 (91%)] Loss: -1586.106445\n",
      "Train Epoch: 871 [53248/54000 (99%)] Loss: -1581.873169\n",
      "    epoch          : 871\n",
      "    loss           : -1586.1998296800948\n",
      "    ess            : 3.800963035691971\n",
      "    log_marginal   : 1586.3222702532582\n",
      "    val_loss       : -1586.1227315266926\n",
      "    val_ess        : 3.8029485841592154\n",
      "    val_log_marginal: 1586.23828125\n",
      "Train Epoch: 872 [0/54000 (0%)] Loss: -1590.024414\n",
      "Train Epoch: 872 [4096/54000 (8%)] Loss: -1582.173096\n",
      "Train Epoch: 872 [8192/54000 (15%)] Loss: -1587.509521\n",
      "Train Epoch: 872 [12288/54000 (23%)] Loss: -1584.779297\n",
      "Train Epoch: 872 [16384/54000 (30%)] Loss: -1589.252197\n",
      "Train Epoch: 872 [20480/54000 (38%)] Loss: -1586.937988\n",
      "Train Epoch: 872 [24576/54000 (46%)] Loss: -1580.154663\n",
      "Train Epoch: 872 [28672/54000 (53%)] Loss: -1583.536743\n",
      "Train Epoch: 872 [32768/54000 (61%)] Loss: -1586.217529\n",
      "Train Epoch: 872 [36864/54000 (68%)] Loss: -1589.381836\n",
      "Train Epoch: 872 [40960/54000 (76%)] Loss: -1586.715210\n",
      "Train Epoch: 872 [45056/54000 (83%)] Loss: -1581.431519\n",
      "Train Epoch: 872 [49152/54000 (91%)] Loss: -1585.583008\n",
      "Train Epoch: 872 [53248/54000 (99%)] Loss: -1585.069214\n",
      "    epoch          : 872\n",
      "    loss           : -1586.3362932973564\n",
      "    ess            : 3.7972207769963413\n",
      "    log_marginal   : 1586.4628142587383\n",
      "    val_loss       : -1586.3488210042317\n",
      "    val_ess        : 3.7875010470549264\n",
      "    val_log_marginal: 1586.4793599446614\n",
      "Train Epoch: 873 [0/54000 (0%)] Loss: -1583.470215\n",
      "Train Epoch: 873 [4096/54000 (8%)] Loss: -1581.614990\n",
      "Train Epoch: 873 [8192/54000 (15%)] Loss: -1592.215576\n",
      "Train Epoch: 873 [12288/54000 (23%)] Loss: -1588.520508\n",
      "Train Epoch: 873 [16384/54000 (30%)] Loss: -1587.522461\n",
      "Train Epoch: 873 [20480/54000 (38%)] Loss: -1590.061279\n",
      "Train Epoch: 873 [24576/54000 (46%)] Loss: -1576.582764\n",
      "Train Epoch: 873 [28672/54000 (53%)] Loss: -1579.393311\n",
      "Train Epoch: 873 [32768/54000 (61%)] Loss: -1582.034790\n",
      "Train Epoch: 873 [36864/54000 (68%)] Loss: -1581.587402\n",
      "Train Epoch: 873 [40960/54000 (76%)] Loss: -1587.656006\n",
      "Train Epoch: 873 [45056/54000 (83%)] Loss: -1587.501465\n",
      "Train Epoch: 873 [49152/54000 (91%)] Loss: -1583.027100\n",
      "Train Epoch: 873 [53248/54000 (99%)] Loss: -1589.307983\n",
      "    epoch          : 873\n",
      "    loss           : -1586.4832144642328\n",
      "    ess            : 3.7961465532745797\n",
      "    log_marginal   : 1586.6080501610634\n",
      "    val_loss       : -1586.4908447265625\n",
      "    val_ess        : 3.7811847925186157\n",
      "    val_log_marginal: 1586.63330078125\n",
      "Train Epoch: 874 [0/54000 (0%)] Loss: -1585.912598\n",
      "Train Epoch: 874 [4096/54000 (8%)] Loss: -1584.583374\n",
      "Train Epoch: 874 [8192/54000 (15%)] Loss: -1584.314697\n",
      "Train Epoch: 874 [12288/54000 (23%)] Loss: -1584.617920\n",
      "Train Epoch: 874 [16384/54000 (30%)] Loss: -1591.615723\n",
      "Train Epoch: 874 [20480/54000 (38%)] Loss: -1589.333130\n",
      "Train Epoch: 874 [24576/54000 (46%)] Loss: -1586.087036\n",
      "Train Epoch: 874 [28672/54000 (53%)] Loss: -1594.823242\n",
      "Train Epoch: 874 [32768/54000 (61%)] Loss: -1590.422485\n",
      "Train Epoch: 874 [36864/54000 (68%)] Loss: -1591.441650\n",
      "Train Epoch: 874 [40960/54000 (76%)] Loss: -1580.968994\n",
      "Train Epoch: 874 [45056/54000 (83%)] Loss: -1582.707153\n",
      "Train Epoch: 874 [49152/54000 (91%)] Loss: -1587.252930\n",
      "Train Epoch: 874 [53248/54000 (99%)] Loss: -1589.180176\n",
      "    epoch          : 874\n",
      "    loss           : -1586.324440327866\n",
      "    ess            : 3.793633424840267\n",
      "    log_marginal   : 1586.4550596119668\n",
      "    val_loss       : -1585.3519185384114\n",
      "    val_ess        : 3.800515443086624\n",
      "    val_log_marginal: 1585.4729258219402\n",
      "Train Epoch: 875 [0/54000 (0%)] Loss: -1589.325684\n",
      "Train Epoch: 875 [4096/54000 (8%)] Loss: -1588.340576\n",
      "Train Epoch: 875 [8192/54000 (15%)] Loss: -1585.846924\n",
      "Train Epoch: 875 [12288/54000 (23%)] Loss: -1583.614502\n",
      "Train Epoch: 875 [16384/54000 (30%)] Loss: -1585.905029\n",
      "Train Epoch: 875 [20480/54000 (38%)] Loss: -1581.673218\n",
      "Train Epoch: 875 [24576/54000 (46%)] Loss: -1585.960571\n",
      "Train Epoch: 875 [28672/54000 (53%)] Loss: -1580.269775\n",
      "Train Epoch: 875 [32768/54000 (61%)] Loss: -1586.273193\n",
      "Train Epoch: 875 [36864/54000 (68%)] Loss: -1586.434326\n",
      "Train Epoch: 875 [40960/54000 (76%)] Loss: -1587.141602\n",
      "Train Epoch: 875 [45056/54000 (83%)] Loss: -1586.682373\n",
      "Train Epoch: 875 [49152/54000 (91%)] Loss: -1586.035400\n",
      "Train Epoch: 875 [53248/54000 (99%)] Loss: -1587.155518\n",
      "    epoch          : 875\n",
      "    loss           : -1586.2602631627665\n",
      "    ess            : 3.7989987377871834\n",
      "    log_marginal   : 1586.3793951097823\n",
      "    val_loss       : -1586.1853739420574\n",
      "    val_ess        : 3.7963733474413552\n",
      "    val_log_marginal: 1586.3126983642578\n",
      "Train Epoch: 876 [0/54000 (0%)] Loss: -1588.666992\n",
      "Train Epoch: 876 [4096/54000 (8%)] Loss: -1588.564209\n",
      "Train Epoch: 876 [8192/54000 (15%)] Loss: -1590.525391\n",
      "Train Epoch: 876 [12288/54000 (23%)] Loss: -1587.845947\n",
      "Train Epoch: 876 [16384/54000 (30%)] Loss: -1586.644897\n",
      "Train Epoch: 876 [20480/54000 (38%)] Loss: -1581.268799\n",
      "Train Epoch: 876 [24576/54000 (46%)] Loss: -1583.405640\n",
      "Train Epoch: 876 [28672/54000 (53%)] Loss: -1592.872681\n",
      "Train Epoch: 876 [32768/54000 (61%)] Loss: -1586.738525\n",
      "Train Epoch: 876 [36864/54000 (68%)] Loss: -1583.054810\n",
      "Train Epoch: 876 [40960/54000 (76%)] Loss: -1579.930420\n",
      "Train Epoch: 876 [45056/54000 (83%)] Loss: -1588.286499\n",
      "Train Epoch: 876 [49152/54000 (91%)] Loss: -1584.797119\n",
      "Train Epoch: 876 [53248/54000 (99%)] Loss: -1584.045898\n",
      "    epoch          : 876\n",
      "    loss           : -1586.1606399029918\n",
      "    ess            : 3.7965521823738424\n",
      "    log_marginal   : 1586.287111110597\n",
      "    val_loss       : -1586.631312052409\n",
      "    val_ess        : 3.793104817469915\n",
      "    val_log_marginal: 1586.7613525390625\n",
      "Train Epoch: 877 [0/54000 (0%)] Loss: -1591.068970\n",
      "Train Epoch: 877 [4096/54000 (8%)] Loss: -1586.548096\n",
      "Train Epoch: 877 [8192/54000 (15%)] Loss: -1585.166748\n",
      "Train Epoch: 877 [12288/54000 (23%)] Loss: -1587.193604\n",
      "Train Epoch: 877 [16384/54000 (30%)] Loss: -1591.899170\n",
      "Train Epoch: 877 [20480/54000 (38%)] Loss: -1583.435547\n",
      "Train Epoch: 877 [24576/54000 (46%)] Loss: -1586.213623\n",
      "Train Epoch: 877 [28672/54000 (53%)] Loss: -1584.869629\n",
      "Train Epoch: 877 [32768/54000 (61%)] Loss: -1588.827637\n",
      "Train Epoch: 877 [36864/54000 (68%)] Loss: -1582.291260\n",
      "Train Epoch: 877 [40960/54000 (76%)] Loss: -1585.731445\n",
      "Train Epoch: 877 [45056/54000 (83%)] Loss: -1587.443359\n",
      "Train Epoch: 877 [49152/54000 (91%)] Loss: -1584.951904\n",
      "Train Epoch: 877 [53248/54000 (99%)] Loss: -1582.365479\n",
      "    epoch          : 877\n",
      "    loss           : -1586.2243808547466\n",
      "    ess            : 3.7962597343029003\n",
      "    log_marginal   : 1586.3506212279694\n",
      "    val_loss       : -1585.5735880533855\n",
      "    val_ess        : 3.7980483571688333\n",
      "    val_log_marginal: 1585.7020823160808\n",
      "Train Epoch: 878 [0/54000 (0%)] Loss: -1587.626221\n",
      "Train Epoch: 878 [4096/54000 (8%)] Loss: -1589.982788\n",
      "Train Epoch: 878 [8192/54000 (15%)] Loss: -1593.199097\n",
      "Train Epoch: 878 [12288/54000 (23%)] Loss: -1584.227539\n",
      "Train Epoch: 878 [16384/54000 (30%)] Loss: -1588.216309\n",
      "Train Epoch: 878 [20480/54000 (38%)] Loss: -1582.737549\n",
      "Train Epoch: 878 [24576/54000 (46%)] Loss: -1582.494873\n",
      "Train Epoch: 878 [28672/54000 (53%)] Loss: -1582.672241\n",
      "Train Epoch: 878 [32768/54000 (61%)] Loss: -1588.918701\n",
      "Train Epoch: 878 [36864/54000 (68%)] Loss: -1584.307007\n",
      "Train Epoch: 878 [40960/54000 (76%)] Loss: -1587.072632\n",
      "Train Epoch: 878 [45056/54000 (83%)] Loss: -1592.706543\n",
      "Train Epoch: 878 [49152/54000 (91%)] Loss: -1586.585693\n",
      "Train Epoch: 878 [53248/54000 (99%)] Loss: -1585.327637\n",
      "    epoch          : 878\n",
      "    loss           : -1586.4049349961122\n",
      "    ess            : 3.7938160568616968\n",
      "    log_marginal   : 1586.5325164071758\n",
      "    val_loss       : -1585.9569244384766\n",
      "    val_ess        : 3.808059165875117\n",
      "    val_log_marginal: 1586.0771789550781\n",
      "Train Epoch: 879 [0/54000 (0%)] Loss: -1584.113892\n",
      "Train Epoch: 879 [4096/54000 (8%)] Loss: -1582.261597\n",
      "Train Epoch: 879 [8192/54000 (15%)] Loss: -1588.724365\n",
      "Train Epoch: 879 [12288/54000 (23%)] Loss: -1581.827393\n",
      "Train Epoch: 879 [16384/54000 (30%)] Loss: -1583.986694\n",
      "Train Epoch: 879 [20480/54000 (38%)] Loss: -1582.845703\n",
      "Train Epoch: 879 [24576/54000 (46%)] Loss: -1581.287720\n",
      "Train Epoch: 879 [28672/54000 (53%)] Loss: -1585.776001\n",
      "Train Epoch: 879 [32768/54000 (61%)] Loss: -1594.949829\n",
      "Train Epoch: 879 [36864/54000 (68%)] Loss: -1583.738281\n",
      "Train Epoch: 879 [40960/54000 (76%)] Loss: -1584.196655\n",
      "Train Epoch: 879 [45056/54000 (83%)] Loss: -1583.346924\n",
      "Train Epoch: 879 [49152/54000 (91%)] Loss: -1594.462402\n",
      "Train Epoch: 879 [53248/54000 (99%)] Loss: -1586.853516\n",
      "    epoch          : 879\n",
      "    loss           : -1586.3164918727784\n",
      "    ess            : 3.7976500502129866\n",
      "    log_marginal   : 1586.4417562620336\n",
      "    val_loss       : -1586.7436421712239\n",
      "    val_ess        : 3.7931688527266183\n",
      "    val_log_marginal: 1586.8814798990886\n",
      "Train Epoch: 880 [0/54000 (0%)] Loss: -1594.430542\n",
      "Train Epoch: 880 [4096/54000 (8%)] Loss: -1584.769287\n",
      "Train Epoch: 880 [8192/54000 (15%)] Loss: -1581.817627\n",
      "Train Epoch: 880 [12288/54000 (23%)] Loss: -1579.549561\n",
      "Train Epoch: 880 [16384/54000 (30%)] Loss: -1582.465942\n",
      "Train Epoch: 880 [20480/54000 (38%)] Loss: -1588.152466\n",
      "Train Epoch: 880 [24576/54000 (46%)] Loss: -1590.628174\n",
      "Train Epoch: 880 [28672/54000 (53%)] Loss: -1577.894653\n",
      "Train Epoch: 880 [32768/54000 (61%)] Loss: -1590.924805\n",
      "Train Epoch: 880 [36864/54000 (68%)] Loss: -1594.059570\n",
      "Train Epoch: 880 [40960/54000 (76%)] Loss: -1585.894409\n",
      "Train Epoch: 880 [45056/54000 (83%)] Loss: -1584.946533\n",
      "Train Epoch: 880 [49152/54000 (91%)] Loss: -1597.005615\n",
      "Train Epoch: 880 [53248/54000 (99%)] Loss: -1584.655640\n",
      "    epoch          : 880\n",
      "    loss           : -1586.6124996528806\n",
      "    ess            : 3.794401463739115\n",
      "    log_marginal   : 1586.7399080827902\n",
      "    val_loss       : -1585.784673055013\n",
      "    val_ess        : 3.809168646732966\n",
      "    val_log_marginal: 1585.9031473795574\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch880.pth ...\n",
      "Train Epoch: 881 [0/54000 (0%)] Loss: -1584.239136\n",
      "Train Epoch: 881 [4096/54000 (8%)] Loss: -1589.303467\n",
      "Train Epoch: 881 [8192/54000 (15%)] Loss: -1585.218994\n",
      "Train Epoch: 881 [12288/54000 (23%)] Loss: -1590.399536\n",
      "Train Epoch: 881 [16384/54000 (30%)] Loss: -1589.882080\n",
      "Train Epoch: 881 [20480/54000 (38%)] Loss: -1586.839600\n",
      "Train Epoch: 881 [24576/54000 (46%)] Loss: -1587.054688\n",
      "Train Epoch: 881 [28672/54000 (53%)] Loss: -1593.398438\n",
      "Train Epoch: 881 [32768/54000 (61%)] Loss: -1588.732300\n",
      "Train Epoch: 881 [36864/54000 (68%)] Loss: -1582.825562\n",
      "Train Epoch: 881 [40960/54000 (76%)] Loss: -1591.622803\n",
      "Train Epoch: 881 [45056/54000 (83%)] Loss: -1581.202515\n",
      "Train Epoch: 881 [49152/54000 (91%)] Loss: -1588.708984\n",
      "Train Epoch: 881 [53248/54000 (99%)] Loss: -1581.878174\n",
      "    epoch          : 881\n",
      "    loss           : -1586.5574465204754\n",
      "    ess            : 3.7940365420698554\n",
      "    log_marginal   : 1586.6839946728746\n",
      "    val_loss       : -1585.6543426513672\n",
      "    val_ess        : 3.798912117878596\n",
      "    val_log_marginal: 1585.784444173177\n",
      "Train Epoch: 882 [0/54000 (0%)] Loss: -1586.288818\n",
      "Train Epoch: 882 [4096/54000 (8%)] Loss: -1584.234619\n",
      "Train Epoch: 882 [8192/54000 (15%)] Loss: -1584.904541\n",
      "Train Epoch: 882 [12288/54000 (23%)] Loss: -1592.206055\n",
      "Train Epoch: 882 [16384/54000 (30%)] Loss: -1584.572998\n",
      "Train Epoch: 882 [20480/54000 (38%)] Loss: -1587.572266\n",
      "Train Epoch: 882 [24576/54000 (46%)] Loss: -1588.828613\n",
      "Train Epoch: 882 [28672/54000 (53%)] Loss: -1587.931030\n",
      "Train Epoch: 882 [32768/54000 (61%)] Loss: -1594.542969\n",
      "Train Epoch: 882 [36864/54000 (68%)] Loss: -1586.801880\n",
      "Train Epoch: 882 [40960/54000 (76%)] Loss: -1584.424561\n",
      "Train Epoch: 882 [45056/54000 (83%)] Loss: -1588.251465\n",
      "Train Epoch: 882 [49152/54000 (91%)] Loss: -1587.145752\n",
      "Train Epoch: 882 [53248/54000 (99%)] Loss: -1584.080322\n",
      "    epoch          : 882\n",
      "    loss           : -1586.382187106598\n",
      "    ess            : 3.801091678899611\n",
      "    log_marginal   : 1586.5026971175207\n",
      "    val_loss       : -1585.6925811767578\n",
      "    val_ess        : 3.791947195927302\n",
      "    val_log_marginal: 1585.821283976237\n",
      "Train Epoch: 883 [0/54000 (0%)] Loss: -1590.286133\n",
      "Train Epoch: 883 [4096/54000 (8%)] Loss: -1592.398193\n",
      "Train Epoch: 883 [8192/54000 (15%)] Loss: -1585.007935\n",
      "Train Epoch: 883 [12288/54000 (23%)] Loss: -1585.116577\n",
      "Train Epoch: 883 [16384/54000 (30%)] Loss: -1590.302490\n",
      "Train Epoch: 883 [20480/54000 (38%)] Loss: -1593.247925\n",
      "Train Epoch: 883 [24576/54000 (46%)] Loss: -1588.565063\n",
      "Train Epoch: 883 [28672/54000 (53%)] Loss: -1582.999512\n",
      "Train Epoch: 883 [32768/54000 (61%)] Loss: -1593.050293\n",
      "Train Epoch: 883 [36864/54000 (68%)] Loss: -1583.413574\n",
      "Train Epoch: 883 [40960/54000 (76%)] Loss: -1590.272949\n",
      "Train Epoch: 883 [45056/54000 (83%)] Loss: -1584.427856\n",
      "Train Epoch: 883 [49152/54000 (91%)] Loss: -1593.008667\n",
      "Train Epoch: 883 [53248/54000 (99%)] Loss: -1592.322266\n",
      "    epoch          : 883\n",
      "    loss           : -1586.4645110939352\n",
      "    ess            : 3.7948651099092023\n",
      "    log_marginal   : 1586.5904783999185\n",
      "    val_loss       : -1585.7036895751953\n",
      "    val_ess        : 3.8074636856714883\n",
      "    val_log_marginal: 1585.8196512858074\n",
      "Train Epoch: 884 [0/54000 (0%)] Loss: -1577.764893\n",
      "Train Epoch: 884 [4096/54000 (8%)] Loss: -1577.843140\n",
      "Train Epoch: 884 [8192/54000 (15%)] Loss: -1588.841797\n",
      "Train Epoch: 884 [12288/54000 (23%)] Loss: -1587.523682\n",
      "Train Epoch: 884 [16384/54000 (30%)] Loss: -1587.438110\n",
      "Train Epoch: 884 [20480/54000 (38%)] Loss: -1583.748779\n",
      "Train Epoch: 884 [24576/54000 (46%)] Loss: -1591.270264\n",
      "Train Epoch: 884 [28672/54000 (53%)] Loss: -1584.090088\n",
      "Train Epoch: 884 [32768/54000 (61%)] Loss: -1588.229126\n",
      "Train Epoch: 884 [36864/54000 (68%)] Loss: -1584.769897\n",
      "Train Epoch: 884 [40960/54000 (76%)] Loss: -1587.511353\n",
      "Train Epoch: 884 [45056/54000 (83%)] Loss: -1590.011108\n",
      "Train Epoch: 884 [49152/54000 (91%)] Loss: -1583.880859\n",
      "Train Epoch: 884 [53248/54000 (99%)] Loss: -1583.754639\n",
      "    epoch          : 884\n",
      "    loss           : -1586.408578592454\n",
      "    ess            : 3.7987602774000844\n",
      "    log_marginal   : 1586.5319072126777\n",
      "    val_loss       : -1585.2957102457683\n",
      "    val_ess        : 3.7992378870646157\n",
      "    val_log_marginal: 1585.4111785888672\n",
      "Train Epoch: 885 [0/54000 (0%)] Loss: -1587.895508\n",
      "Train Epoch: 885 [4096/54000 (8%)] Loss: -1582.670166\n",
      "Train Epoch: 885 [8192/54000 (15%)] Loss: -1590.898438\n",
      "Train Epoch: 885 [12288/54000 (23%)] Loss: -1588.786865\n",
      "Train Epoch: 885 [16384/54000 (30%)] Loss: -1590.031738\n",
      "Train Epoch: 885 [20480/54000 (38%)] Loss: -1589.601196\n",
      "Train Epoch: 885 [24576/54000 (46%)] Loss: -1583.240479\n",
      "Train Epoch: 885 [28672/54000 (53%)] Loss: -1586.475830\n",
      "Train Epoch: 885 [32768/54000 (61%)] Loss: -1592.041504\n",
      "Train Epoch: 885 [36864/54000 (68%)] Loss: -1588.262207\n",
      "Train Epoch: 885 [40960/54000 (76%)] Loss: -1585.562500\n",
      "Train Epoch: 885 [45056/54000 (83%)] Loss: -1590.253418\n",
      "Train Epoch: 885 [49152/54000 (91%)] Loss: -1582.907471\n",
      "Train Epoch: 885 [53248/54000 (99%)] Loss: -1584.062866\n",
      "    epoch          : 885\n",
      "    loss           : -1586.4820897974673\n",
      "    ess            : 3.7926480928303508\n",
      "    log_marginal   : 1586.6086067091233\n",
      "    val_loss       : -1585.8597564697266\n",
      "    val_ess        : 3.7943421999613443\n",
      "    val_log_marginal: 1585.9887288411458\n",
      "Train Epoch: 886 [0/54000 (0%)] Loss: -1585.094727\n",
      "Train Epoch: 886 [4096/54000 (8%)] Loss: -1579.709229\n",
      "Train Epoch: 886 [8192/54000 (15%)] Loss: -1592.233398\n",
      "Train Epoch: 886 [12288/54000 (23%)] Loss: -1594.491211\n",
      "Train Epoch: 886 [16384/54000 (30%)] Loss: -1586.878174\n",
      "Train Epoch: 886 [20480/54000 (38%)] Loss: -1584.690186\n",
      "Train Epoch: 886 [24576/54000 (46%)] Loss: -1589.062988\n",
      "Train Epoch: 886 [28672/54000 (53%)] Loss: -1594.655273\n",
      "Train Epoch: 886 [32768/54000 (61%)] Loss: -1584.882812\n",
      "Train Epoch: 886 [36864/54000 (68%)] Loss: -1587.437622\n",
      "Train Epoch: 886 [40960/54000 (76%)] Loss: -1577.956299\n",
      "Train Epoch: 886 [45056/54000 (83%)] Loss: -1579.764893\n",
      "Train Epoch: 886 [49152/54000 (91%)] Loss: -1587.494141\n",
      "Train Epoch: 886 [53248/54000 (99%)] Loss: -1591.602417\n",
      "    epoch          : 886\n",
      "    loss           : -1586.7051753184242\n",
      "    ess            : 3.7973375998402092\n",
      "    log_marginal   : 1586.8294689305021\n",
      "    val_loss       : -1586.2088572184246\n",
      "    val_ess        : 3.8042015532652536\n",
      "    val_log_marginal: 1586.3301239013672\n",
      "Train Epoch: 887 [0/54000 (0%)] Loss: -1585.755737\n",
      "Train Epoch: 887 [4096/54000 (8%)] Loss: -1585.250000\n",
      "Train Epoch: 887 [8192/54000 (15%)] Loss: -1582.401367\n",
      "Train Epoch: 887 [12288/54000 (23%)] Loss: -1587.465576\n",
      "Train Epoch: 887 [16384/54000 (30%)] Loss: -1594.009888\n",
      "Train Epoch: 887 [20480/54000 (38%)] Loss: -1583.488525\n",
      "Train Epoch: 887 [24576/54000 (46%)] Loss: -1586.735840\n",
      "Train Epoch: 887 [28672/54000 (53%)] Loss: -1581.991821\n",
      "Train Epoch: 887 [32768/54000 (61%)] Loss: -1590.130005\n",
      "Train Epoch: 887 [36864/54000 (68%)] Loss: -1584.067139\n",
      "Train Epoch: 887 [40960/54000 (76%)] Loss: -1590.362305\n",
      "Train Epoch: 887 [45056/54000 (83%)] Loss: -1588.674805\n",
      "Train Epoch: 887 [49152/54000 (91%)] Loss: -1578.183960\n",
      "Train Epoch: 887 [53248/54000 (99%)] Loss: -1586.692627\n",
      "    epoch          : 887\n",
      "    loss           : -1586.453588982894\n",
      "    ess            : 3.7967850664780602\n",
      "    log_marginal   : 1586.5788319664543\n",
      "    val_loss       : -1586.4747467041016\n",
      "    val_ess        : 3.794214447339376\n",
      "    val_log_marginal: 1586.6074473063152\n",
      "Train Epoch: 888 [0/54000 (0%)] Loss: -1582.154785\n",
      "Train Epoch: 888 [4096/54000 (8%)] Loss: -1585.209229\n",
      "Train Epoch: 888 [8192/54000 (15%)] Loss: -1583.784302\n",
      "Train Epoch: 888 [12288/54000 (23%)] Loss: -1586.219238\n",
      "Train Epoch: 888 [16384/54000 (30%)] Loss: -1582.886719\n",
      "Train Epoch: 888 [20480/54000 (38%)] Loss: -1590.147461\n",
      "Train Epoch: 888 [24576/54000 (46%)] Loss: -1582.428223\n",
      "Train Epoch: 888 [28672/54000 (53%)] Loss: -1584.931274\n",
      "Train Epoch: 888 [32768/54000 (61%)] Loss: -1586.274414\n",
      "Train Epoch: 888 [36864/54000 (68%)] Loss: -1582.917969\n",
      "Train Epoch: 888 [40960/54000 (76%)] Loss: -1584.642578\n",
      "Train Epoch: 888 [45056/54000 (83%)] Loss: -1593.592285\n",
      "Train Epoch: 888 [49152/54000 (91%)] Loss: -1585.725830\n",
      "Train Epoch: 888 [53248/54000 (99%)] Loss: -1590.920654\n",
      "    epoch          : 888\n",
      "    loss           : -1586.125709859116\n",
      "    ess            : 3.79815695184102\n",
      "    log_marginal   : 1586.251287234338\n",
      "    val_loss       : -1586.606201171875\n",
      "    val_ess        : 3.7970870534578958\n",
      "    val_log_marginal: 1586.7371215820312\n",
      "Train Epoch: 889 [0/54000 (0%)] Loss: -1584.537598\n",
      "Train Epoch: 889 [4096/54000 (8%)] Loss: -1584.812256\n",
      "Train Epoch: 889 [8192/54000 (15%)] Loss: -1579.593262\n",
      "Train Epoch: 889 [12288/54000 (23%)] Loss: -1587.304199\n",
      "Train Epoch: 889 [16384/54000 (30%)] Loss: -1580.903564\n",
      "Train Epoch: 889 [20480/54000 (38%)] Loss: -1583.277344\n",
      "Train Epoch: 889 [24576/54000 (46%)] Loss: -1593.717773\n",
      "Train Epoch: 889 [28672/54000 (53%)] Loss: -1584.504883\n",
      "Train Epoch: 889 [32768/54000 (61%)] Loss: -1590.405762\n",
      "Train Epoch: 889 [36864/54000 (68%)] Loss: -1588.254883\n",
      "Train Epoch: 889 [40960/54000 (76%)] Loss: -1588.409180\n",
      "Train Epoch: 889 [45056/54000 (83%)] Loss: -1587.694824\n",
      "Train Epoch: 889 [49152/54000 (91%)] Loss: -1590.172485\n",
      "Train Epoch: 889 [53248/54000 (99%)] Loss: -1582.279297\n",
      "    epoch          : 889\n",
      "    loss           : -1586.6020178049096\n",
      "    ess            : 3.794307135857677\n",
      "    log_marginal   : 1586.728229251518\n",
      "    val_loss       : -1586.6462148030598\n",
      "    val_ess        : 3.7815638979276023\n",
      "    val_log_marginal: 1586.7761840820312\n",
      "Train Epoch: 890 [0/54000 (0%)] Loss: -1581.423584\n",
      "Train Epoch: 890 [4096/54000 (8%)] Loss: -1590.377686\n",
      "Train Epoch: 890 [8192/54000 (15%)] Loss: -1585.874634\n",
      "Train Epoch: 890 [12288/54000 (23%)] Loss: -1586.989746\n",
      "Train Epoch: 890 [16384/54000 (30%)] Loss: -1589.545898\n",
      "Train Epoch: 890 [20480/54000 (38%)] Loss: -1586.739990\n",
      "Train Epoch: 890 [24576/54000 (46%)] Loss: -1590.429688\n",
      "Train Epoch: 890 [28672/54000 (53%)] Loss: -1587.211426\n",
      "Train Epoch: 890 [32768/54000 (61%)] Loss: -1582.171875\n",
      "Train Epoch: 890 [36864/54000 (68%)] Loss: -1578.191528\n",
      "Train Epoch: 890 [40960/54000 (76%)] Loss: -1585.831177\n",
      "Train Epoch: 890 [45056/54000 (83%)] Loss: -1594.311279\n",
      "Train Epoch: 890 [49152/54000 (91%)] Loss: -1589.675781\n",
      "Train Epoch: 890 [53248/54000 (99%)] Loss: -1592.731934\n",
      "    epoch          : 890\n",
      "    loss           : -1586.767344397956\n",
      "    ess            : 3.7964285572558216\n",
      "    log_marginal   : 1586.8919168625962\n",
      "    val_loss       : -1586.0723622639973\n",
      "    val_ess        : 3.785614271958669\n",
      "    val_log_marginal: 1586.2044881184895\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch890.pth ...\n",
      "Train Epoch: 891 [0/54000 (0%)] Loss: -1587.288086\n",
      "Train Epoch: 891 [4096/54000 (8%)] Loss: -1583.212646\n",
      "Train Epoch: 891 [8192/54000 (15%)] Loss: -1587.385010\n",
      "Train Epoch: 891 [12288/54000 (23%)] Loss: -1582.453125\n",
      "Train Epoch: 891 [16384/54000 (30%)] Loss: -1590.292969\n",
      "Train Epoch: 891 [20480/54000 (38%)] Loss: -1581.197266\n",
      "Train Epoch: 891 [24576/54000 (46%)] Loss: -1585.901855\n",
      "Train Epoch: 891 [28672/54000 (53%)] Loss: -1584.355225\n",
      "Train Epoch: 891 [32768/54000 (61%)] Loss: -1583.335938\n",
      "Train Epoch: 891 [36864/54000 (68%)] Loss: -1592.050537\n",
      "Train Epoch: 891 [40960/54000 (76%)] Loss: -1592.584839\n",
      "Train Epoch: 891 [45056/54000 (83%)] Loss: -1587.477295\n",
      "Train Epoch: 891 [49152/54000 (91%)] Loss: -1584.585327\n",
      "Train Epoch: 891 [53248/54000 (99%)] Loss: -1589.609619\n",
      "    epoch          : 891\n",
      "    loss           : -1586.7880344481264\n",
      "    ess            : 3.79554176443561\n",
      "    log_marginal   : 1586.912639889107\n",
      "    val_loss       : -1586.4471791585286\n",
      "    val_ess        : 3.8018165230751038\n",
      "    val_log_marginal: 1586.5636800130208\n",
      "Train Epoch: 892 [0/54000 (0%)] Loss: -1585.266357\n",
      "Train Epoch: 892 [4096/54000 (8%)] Loss: -1581.052490\n",
      "Train Epoch: 892 [8192/54000 (15%)] Loss: -1583.266602\n",
      "Train Epoch: 892 [12288/54000 (23%)] Loss: -1591.078003\n",
      "Train Epoch: 892 [16384/54000 (30%)] Loss: -1584.979248\n",
      "Train Epoch: 892 [20480/54000 (38%)] Loss: -1581.481445\n",
      "Train Epoch: 892 [24576/54000 (46%)] Loss: -1590.804688\n",
      "Train Epoch: 892 [28672/54000 (53%)] Loss: -1584.687256\n",
      "Train Epoch: 892 [32768/54000 (61%)] Loss: -1585.220215\n",
      "Train Epoch: 892 [36864/54000 (68%)] Loss: -1583.543335\n",
      "Train Epoch: 892 [40960/54000 (76%)] Loss: -1582.890869\n",
      "Train Epoch: 892 [45056/54000 (83%)] Loss: -1583.004272\n",
      "Train Epoch: 892 [49152/54000 (91%)] Loss: -1588.773560\n",
      "Train Epoch: 892 [53248/54000 (99%)] Loss: -1585.132202\n",
      "    epoch          : 892\n",
      "    loss           : -1586.7302373370853\n",
      "    ess            : 3.7921816737730922\n",
      "    log_marginal   : 1586.8601930446534\n",
      "    val_loss       : -1585.8458455403645\n",
      "    val_ess        : 3.789874017238617\n",
      "    val_log_marginal: 1585.9824320475261\n",
      "Train Epoch: 893 [0/54000 (0%)] Loss: -1589.667969\n",
      "Train Epoch: 893 [4096/54000 (8%)] Loss: -1584.880127\n",
      "Train Epoch: 893 [8192/54000 (15%)] Loss: -1586.845215\n",
      "Train Epoch: 893 [12288/54000 (23%)] Loss: -1588.992310\n",
      "Train Epoch: 893 [16384/54000 (30%)] Loss: -1591.374756\n",
      "Train Epoch: 893 [20480/54000 (38%)] Loss: -1589.340820\n",
      "Train Epoch: 893 [24576/54000 (46%)] Loss: -1590.608398\n",
      "Train Epoch: 893 [28672/54000 (53%)] Loss: -1591.629150\n",
      "Train Epoch: 893 [32768/54000 (61%)] Loss: -1587.734131\n",
      "Train Epoch: 893 [36864/54000 (68%)] Loss: -1586.487183\n",
      "Train Epoch: 893 [40960/54000 (76%)] Loss: -1594.839355\n",
      "Train Epoch: 893 [45056/54000 (83%)] Loss: -1579.448486\n",
      "Train Epoch: 893 [49152/54000 (91%)] Loss: -1593.769775\n",
      "Train Epoch: 893 [53248/54000 (99%)] Loss: -1590.765747\n",
      "    epoch          : 893\n",
      "    loss           : -1586.7482453115742\n",
      "    ess            : 3.794716998864124\n",
      "    log_marginal   : 1586.8737521058574\n",
      "    val_loss       : -1586.255126953125\n",
      "    val_ess        : 3.7847632467746735\n",
      "    val_log_marginal: 1586.3857879638672\n",
      "Train Epoch: 894 [0/54000 (0%)] Loss: -1588.908325\n",
      "Train Epoch: 894 [4096/54000 (8%)] Loss: -1580.576660\n",
      "Train Epoch: 894 [8192/54000 (15%)] Loss: -1585.756226\n",
      "Train Epoch: 894 [12288/54000 (23%)] Loss: -1588.921875\n",
      "Train Epoch: 894 [16384/54000 (30%)] Loss: -1588.502930\n",
      "Train Epoch: 894 [20480/54000 (38%)] Loss: -1585.540527\n",
      "Train Epoch: 894 [24576/54000 (46%)] Loss: -1587.219604\n",
      "Train Epoch: 894 [28672/54000 (53%)] Loss: -1587.488281\n",
      "Train Epoch: 894 [32768/54000 (61%)] Loss: -1586.578247\n",
      "Train Epoch: 894 [36864/54000 (68%)] Loss: -1593.638916\n",
      "Train Epoch: 894 [40960/54000 (76%)] Loss: -1588.342529\n",
      "Train Epoch: 894 [45056/54000 (83%)] Loss: -1591.957764\n",
      "Train Epoch: 894 [49152/54000 (91%)] Loss: -1581.444336\n",
      "Train Epoch: 894 [53248/54000 (99%)] Loss: -1582.387817\n",
      "    epoch          : 894\n",
      "    loss           : -1586.8360219657138\n",
      "    ess            : 3.795186302673195\n",
      "    log_marginal   : 1586.9663542978008\n",
      "    val_loss       : -1585.781733194987\n",
      "    val_ess        : 3.7865826785564423\n",
      "    val_log_marginal: 1585.915562947591\n",
      "Train Epoch: 895 [0/54000 (0%)] Loss: -1590.116699\n",
      "Train Epoch: 895 [4096/54000 (8%)] Loss: -1588.179688\n",
      "Train Epoch: 895 [8192/54000 (15%)] Loss: -1581.849854\n",
      "Train Epoch: 895 [12288/54000 (23%)] Loss: -1589.001099\n",
      "Train Epoch: 895 [16384/54000 (30%)] Loss: -1580.728271\n",
      "Train Epoch: 895 [20480/54000 (38%)] Loss: -1585.365479\n",
      "Train Epoch: 895 [24576/54000 (46%)] Loss: -1578.072388\n",
      "Train Epoch: 895 [28672/54000 (53%)] Loss: -1583.766602\n",
      "Train Epoch: 895 [32768/54000 (61%)] Loss: -1586.639160\n",
      "Train Epoch: 895 [36864/54000 (68%)] Loss: -1585.427734\n",
      "Train Epoch: 895 [40960/54000 (76%)] Loss: -1582.933105\n",
      "Train Epoch: 895 [45056/54000 (83%)] Loss: -1581.244873\n",
      "Train Epoch: 895 [49152/54000 (91%)] Loss: -1582.694336\n",
      "Train Epoch: 895 [53248/54000 (99%)] Loss: -1585.742676\n",
      "    epoch          : 895\n",
      "    loss           : -1586.7667762792505\n",
      "    ess            : 3.7947323853370705\n",
      "    log_marginal   : 1586.891486434575\n",
      "    val_loss       : -1585.9485982259114\n",
      "    val_ess        : 3.790144761403402\n",
      "    val_log_marginal: 1586.081039428711\n",
      "Train Epoch: 896 [0/54000 (0%)] Loss: -1589.207642\n",
      "Train Epoch: 896 [4096/54000 (8%)] Loss: -1590.865234\n",
      "Train Epoch: 896 [8192/54000 (15%)] Loss: -1586.015137\n",
      "Train Epoch: 896 [12288/54000 (23%)] Loss: -1594.440796\n",
      "Train Epoch: 896 [16384/54000 (30%)] Loss: -1590.742554\n",
      "Train Epoch: 896 [20480/54000 (38%)] Loss: -1587.747925\n",
      "Train Epoch: 896 [24576/54000 (46%)] Loss: -1589.094604\n",
      "Train Epoch: 896 [28672/54000 (53%)] Loss: -1584.239990\n",
      "Train Epoch: 896 [32768/54000 (61%)] Loss: -1595.238281\n",
      "Train Epoch: 896 [36864/54000 (68%)] Loss: -1580.031128\n",
      "Train Epoch: 896 [40960/54000 (76%)] Loss: -1588.514282\n",
      "Train Epoch: 896 [45056/54000 (83%)] Loss: -1578.685181\n",
      "Train Epoch: 896 [49152/54000 (91%)] Loss: -1590.437256\n",
      "Train Epoch: 896 [53248/54000 (99%)] Loss: -1587.365479\n",
      "    epoch          : 896\n",
      "    loss           : -1586.9020799392772\n",
      "    ess            : 3.7945808482961065\n",
      "    log_marginal   : 1587.0271852321534\n",
      "    val_loss       : -1587.4561869303386\n",
      "    val_ess        : 3.7963267167409263\n",
      "    val_log_marginal: 1587.5743103027344\n",
      "Train Epoch: 897 [0/54000 (0%)] Loss: -1580.184326\n",
      "Train Epoch: 897 [4096/54000 (8%)] Loss: -1584.718872\n",
      "Train Epoch: 897 [8192/54000 (15%)] Loss: -1585.334595\n",
      "Train Epoch: 897 [12288/54000 (23%)] Loss: -1584.857178\n",
      "Train Epoch: 897 [16384/54000 (30%)] Loss: -1590.281128\n",
      "Train Epoch: 897 [20480/54000 (38%)] Loss: -1593.336792\n",
      "Train Epoch: 897 [24576/54000 (46%)] Loss: -1584.860718\n",
      "Train Epoch: 897 [28672/54000 (53%)] Loss: -1589.218994\n",
      "Train Epoch: 897 [32768/54000 (61%)] Loss: -1587.659180\n",
      "Train Epoch: 897 [36864/54000 (68%)] Loss: -1590.790161\n",
      "Train Epoch: 897 [40960/54000 (76%)] Loss: -1593.606689\n",
      "Train Epoch: 897 [45056/54000 (83%)] Loss: -1592.188232\n",
      "Train Epoch: 897 [49152/54000 (91%)] Loss: -1582.146729\n",
      "Train Epoch: 897 [53248/54000 (99%)] Loss: -1588.305054\n",
      "    epoch          : 897\n",
      "    loss           : -1586.9121747491483\n",
      "    ess            : 3.794660213434301\n",
      "    log_marginal   : 1587.0364457984672\n",
      "    val_loss       : -1587.3948313395183\n",
      "    val_ess        : 3.800577769676844\n",
      "    val_log_marginal: 1587.5106506347656\n",
      "Train Epoch: 898 [0/54000 (0%)] Loss: -1586.952148\n",
      "Train Epoch: 898 [4096/54000 (8%)] Loss: -1593.317017\n",
      "Train Epoch: 898 [8192/54000 (15%)] Loss: -1587.665405\n",
      "Train Epoch: 898 [12288/54000 (23%)] Loss: -1583.813721\n",
      "Train Epoch: 898 [16384/54000 (30%)] Loss: -1585.007324\n",
      "Train Epoch: 898 [20480/54000 (38%)] Loss: -1584.555420\n",
      "Train Epoch: 898 [24576/54000 (46%)] Loss: -1591.698242\n",
      "Train Epoch: 898 [28672/54000 (53%)] Loss: -1590.015625\n",
      "Train Epoch: 898 [32768/54000 (61%)] Loss: -1583.427246\n",
      "Train Epoch: 898 [36864/54000 (68%)] Loss: -1586.817627\n",
      "Train Epoch: 898 [40960/54000 (76%)] Loss: -1596.541504\n",
      "Train Epoch: 898 [45056/54000 (83%)] Loss: -1583.347900\n",
      "Train Epoch: 898 [49152/54000 (91%)] Loss: -1584.391479\n",
      "Train Epoch: 898 [53248/54000 (99%)] Loss: -1583.602295\n",
      "    epoch          : 898\n",
      "    loss           : -1586.9554969823755\n",
      "    ess            : 3.7921054939523127\n",
      "    log_marginal   : 1587.0820127369668\n",
      "    val_loss       : -1587.4116516113281\n",
      "    val_ess        : 3.7901688615481057\n",
      "    val_log_marginal: 1587.5386759440105\n",
      "Train Epoch: 899 [0/54000 (0%)] Loss: -1594.827637\n",
      "Train Epoch: 899 [4096/54000 (8%)] Loss: -1584.011597\n",
      "Train Epoch: 899 [8192/54000 (15%)] Loss: -1594.992798\n",
      "Train Epoch: 899 [12288/54000 (23%)] Loss: -1588.045532\n",
      "Train Epoch: 899 [16384/54000 (30%)] Loss: -1587.280884\n",
      "Train Epoch: 899 [20480/54000 (38%)] Loss: -1585.142090\n",
      "Train Epoch: 899 [24576/54000 (46%)] Loss: -1589.622437\n",
      "Train Epoch: 899 [28672/54000 (53%)] Loss: -1591.086426\n",
      "Train Epoch: 899 [32768/54000 (61%)] Loss: -1581.962036\n",
      "Train Epoch: 899 [36864/54000 (68%)] Loss: -1590.526367\n",
      "Train Epoch: 899 [40960/54000 (76%)] Loss: -1583.938354\n",
      "Train Epoch: 899 [45056/54000 (83%)] Loss: -1587.697266\n",
      "Train Epoch: 899 [49152/54000 (91%)] Loss: -1578.883789\n",
      "Train Epoch: 899 [53248/54000 (99%)] Loss: -1589.518311\n",
      "    epoch          : 899\n",
      "    loss           : -1587.1980668922172\n",
      "    ess            : 3.7951837557751986\n",
      "    log_marginal   : 1587.3228036600267\n",
      "    val_loss       : -1586.656494140625\n",
      "    val_ess        : 3.776924083630244\n",
      "    val_log_marginal: 1586.7936096191406\n",
      "Train Epoch: 900 [0/54000 (0%)] Loss: -1591.326782\n",
      "Train Epoch: 900 [4096/54000 (8%)] Loss: -1590.710815\n",
      "Train Epoch: 900 [8192/54000 (15%)] Loss: -1589.240356\n",
      "Train Epoch: 900 [12288/54000 (23%)] Loss: -1584.570801\n",
      "Train Epoch: 900 [16384/54000 (30%)] Loss: -1596.757812\n",
      "Train Epoch: 900 [20480/54000 (38%)] Loss: -1583.799438\n",
      "Train Epoch: 900 [24576/54000 (46%)] Loss: -1587.472900\n",
      "Train Epoch: 900 [28672/54000 (53%)] Loss: -1588.793701\n",
      "Train Epoch: 900 [32768/54000 (61%)] Loss: -1587.558350\n",
      "Train Epoch: 900 [36864/54000 (68%)] Loss: -1581.453735\n",
      "Train Epoch: 900 [40960/54000 (76%)] Loss: -1591.720703\n",
      "Train Epoch: 900 [45056/54000 (83%)] Loss: -1587.458618\n",
      "Train Epoch: 900 [49152/54000 (91%)] Loss: -1588.451660\n",
      "Train Epoch: 900 [53248/54000 (99%)] Loss: -1587.486084\n",
      "    epoch          : 900\n",
      "    loss           : -1587.161381002851\n",
      "    ess            : 3.791829795069039\n",
      "    log_marginal   : 1587.288443470453\n",
      "    val_loss       : -1586.722620646159\n",
      "    val_ess        : 3.7984329064687095\n",
      "    val_log_marginal: 1586.8463338216145\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [0/54000 (0%)] Loss: -1581.162109\n",
      "Train Epoch: 901 [4096/54000 (8%)] Loss: -1584.773682\n",
      "Train Epoch: 901 [8192/54000 (15%)] Loss: -1590.487305\n",
      "Train Epoch: 901 [12288/54000 (23%)] Loss: -1583.443359\n",
      "Train Epoch: 901 [16384/54000 (30%)] Loss: -1587.112671\n",
      "Train Epoch: 901 [20480/54000 (38%)] Loss: -1589.852417\n",
      "Train Epoch: 901 [24576/54000 (46%)] Loss: -1586.760254\n",
      "Train Epoch: 901 [28672/54000 (53%)] Loss: -1582.621704\n",
      "Train Epoch: 901 [32768/54000 (61%)] Loss: -1589.242676\n",
      "Train Epoch: 901 [36864/54000 (68%)] Loss: -1579.422729\n",
      "Train Epoch: 901 [40960/54000 (76%)] Loss: -1584.214111\n",
      "Train Epoch: 901 [45056/54000 (83%)] Loss: -1587.168945\n",
      "Train Epoch: 901 [49152/54000 (91%)] Loss: -1588.331055\n",
      "Train Epoch: 901 [53248/54000 (99%)] Loss: -1590.316772\n",
      "    epoch          : 901\n",
      "    loss           : -1587.094740447275\n",
      "    ess            : 3.7938968400819606\n",
      "    log_marginal   : 1587.218986041173\n",
      "    val_loss       : -1586.7459157307942\n",
      "    val_ess        : 3.786538412173589\n",
      "    val_log_marginal: 1586.870396931966\n",
      "Train Epoch: 902 [0/54000 (0%)] Loss: -1585.247314\n",
      "Train Epoch: 902 [4096/54000 (8%)] Loss: -1584.766357\n",
      "Train Epoch: 902 [8192/54000 (15%)] Loss: -1586.309326\n",
      "Train Epoch: 902 [12288/54000 (23%)] Loss: -1581.022461\n",
      "Train Epoch: 902 [16384/54000 (30%)] Loss: -1589.632202\n",
      "Train Epoch: 902 [20480/54000 (38%)] Loss: -1580.418457\n",
      "Train Epoch: 902 [24576/54000 (46%)] Loss: -1590.838379\n",
      "Train Epoch: 902 [28672/54000 (53%)] Loss: -1588.824219\n",
      "Train Epoch: 902 [32768/54000 (61%)] Loss: -1588.702393\n",
      "Train Epoch: 902 [36864/54000 (68%)] Loss: -1588.866699\n",
      "Train Epoch: 902 [40960/54000 (76%)] Loss: -1589.243530\n",
      "Train Epoch: 902 [45056/54000 (83%)] Loss: -1585.604980\n",
      "Train Epoch: 902 [49152/54000 (91%)] Loss: -1593.810059\n",
      "Train Epoch: 902 [53248/54000 (99%)] Loss: -1588.340820\n",
      "    epoch          : 902\n",
      "    loss           : -1586.9897524576052\n",
      "    ess            : 3.7968301716573993\n",
      "    log_marginal   : 1587.112381632294\n",
      "    val_loss       : -1586.6880798339844\n",
      "    val_ess        : 3.7951016823450723\n",
      "    val_log_marginal: 1586.8173929850261\n",
      "Train Epoch: 903 [0/54000 (0%)] Loss: -1589.557861\n",
      "Train Epoch: 903 [4096/54000 (8%)] Loss: -1587.649902\n",
      "Train Epoch: 903 [8192/54000 (15%)] Loss: -1583.407593\n",
      "Train Epoch: 903 [12288/54000 (23%)] Loss: -1584.739990\n",
      "Train Epoch: 903 [16384/54000 (30%)] Loss: -1590.876587\n",
      "Train Epoch: 903 [20480/54000 (38%)] Loss: -1593.028320\n",
      "Train Epoch: 903 [24576/54000 (46%)] Loss: -1584.106445\n",
      "Train Epoch: 903 [28672/54000 (53%)] Loss: -1591.237549\n",
      "Train Epoch: 903 [32768/54000 (61%)] Loss: -1592.853882\n",
      "Train Epoch: 903 [36864/54000 (68%)] Loss: -1585.817871\n",
      "Train Epoch: 903 [40960/54000 (76%)] Loss: -1583.094238\n",
      "Train Epoch: 903 [45056/54000 (83%)] Loss: -1585.270996\n",
      "Train Epoch: 903 [49152/54000 (91%)] Loss: -1590.160645\n",
      "Train Epoch: 903 [53248/54000 (99%)] Loss: -1584.962402\n",
      "    epoch          : 903\n",
      "    loss           : -1587.265482102525\n",
      "    ess            : 3.7970323008948594\n",
      "    log_marginal   : 1587.3881523530065\n",
      "    val_loss       : -1587.6321919759114\n",
      "    val_ess        : 3.79493177930514\n",
      "    val_log_marginal: 1587.7610117594402\n",
      "Train Epoch: 904 [0/54000 (0%)] Loss: -1587.678101\n",
      "Train Epoch: 904 [4096/54000 (8%)] Loss: -1586.163330\n",
      "Train Epoch: 904 [8192/54000 (15%)] Loss: -1595.318604\n",
      "Train Epoch: 904 [12288/54000 (23%)] Loss: -1579.580566\n",
      "Train Epoch: 904 [16384/54000 (30%)] Loss: -1582.133667\n",
      "Train Epoch: 904 [20480/54000 (38%)] Loss: -1587.863770\n",
      "Train Epoch: 904 [24576/54000 (46%)] Loss: -1593.822144\n",
      "Train Epoch: 904 [28672/54000 (53%)] Loss: -1582.463867\n",
      "Train Epoch: 904 [32768/54000 (61%)] Loss: -1587.815918\n",
      "Train Epoch: 904 [36864/54000 (68%)] Loss: -1594.098633\n",
      "Train Epoch: 904 [40960/54000 (76%)] Loss: -1583.149902\n",
      "Train Epoch: 904 [45056/54000 (83%)] Loss: -1588.422729\n",
      "Train Epoch: 904 [49152/54000 (91%)] Loss: -1585.224243\n",
      "Train Epoch: 904 [53248/54000 (99%)] Loss: -1587.111206\n",
      "    epoch          : 904\n",
      "    loss           : -1587.1397832355228\n",
      "    ess            : 3.796702353310246\n",
      "    log_marginal   : 1587.2645061185574\n",
      "    val_loss       : -1586.2988789876301\n",
      "    val_ess        : 3.7955388724803925\n",
      "    val_log_marginal: 1586.4158630371094\n",
      "Train Epoch: 905 [0/54000 (0%)] Loss: -1582.175781\n",
      "Train Epoch: 905 [4096/54000 (8%)] Loss: -1589.449463\n",
      "Train Epoch: 905 [8192/54000 (15%)] Loss: -1584.482666\n",
      "Train Epoch: 905 [12288/54000 (23%)] Loss: -1594.032227\n",
      "Train Epoch: 905 [16384/54000 (30%)] Loss: -1581.100586\n",
      "Train Epoch: 905 [20480/54000 (38%)] Loss: -1594.375000\n",
      "Train Epoch: 905 [24576/54000 (46%)] Loss: -1587.281494\n",
      "Train Epoch: 905 [28672/54000 (53%)] Loss: -1589.176880\n",
      "Train Epoch: 905 [32768/54000 (61%)] Loss: -1590.635742\n",
      "Train Epoch: 905 [36864/54000 (68%)] Loss: -1581.394531\n",
      "Train Epoch: 905 [40960/54000 (76%)] Loss: -1590.911011\n",
      "Train Epoch: 905 [45056/54000 (83%)] Loss: -1591.159912\n",
      "Train Epoch: 905 [49152/54000 (91%)] Loss: -1583.602295\n",
      "Train Epoch: 905 [53248/54000 (99%)] Loss: -1583.739014\n",
      "    epoch          : 905\n",
      "    loss           : -1586.9310748204236\n",
      "    ess            : 3.7948783404454236\n",
      "    log_marginal   : 1587.0596802336345\n",
      "    val_loss       : -1586.260477701823\n",
      "    val_ess        : 3.7948584655920663\n",
      "    val_log_marginal: 1586.3896942138672\n",
      "Train Epoch: 906 [0/54000 (0%)] Loss: -1586.450806\n",
      "Train Epoch: 906 [4096/54000 (8%)] Loss: -1588.973267\n",
      "Train Epoch: 906 [8192/54000 (15%)] Loss: -1590.274048\n",
      "Train Epoch: 906 [12288/54000 (23%)] Loss: -1589.509033\n",
      "Train Epoch: 906 [16384/54000 (30%)] Loss: -1589.443115\n",
      "Train Epoch: 906 [20480/54000 (38%)] Loss: -1583.151123\n",
      "Train Epoch: 906 [24576/54000 (46%)] Loss: -1581.394653\n",
      "Train Epoch: 906 [28672/54000 (53%)] Loss: -1585.245728\n",
      "Train Epoch: 906 [32768/54000 (61%)] Loss: -1584.024902\n",
      "Train Epoch: 906 [36864/54000 (68%)] Loss: -1586.510986\n",
      "Train Epoch: 906 [40960/54000 (76%)] Loss: -1591.801636\n",
      "Train Epoch: 906 [45056/54000 (83%)] Loss: -1583.950684\n",
      "Train Epoch: 906 [49152/54000 (91%)] Loss: -1579.045288\n",
      "Train Epoch: 906 [53248/54000 (99%)] Loss: -1582.757812\n",
      "    epoch          : 906\n",
      "    loss           : -1587.0682552391884\n",
      "    ess            : 3.7939136129984923\n",
      "    log_marginal   : 1587.19533274863\n",
      "    val_loss       : -1586.9501851399739\n",
      "    val_ess        : 3.8123199741045632\n",
      "    val_log_marginal: 1587.0587514241536\n",
      "Train Epoch: 907 [0/54000 (0%)] Loss: -1582.466064\n",
      "Train Epoch: 907 [4096/54000 (8%)] Loss: -1582.122559\n",
      "Train Epoch: 907 [8192/54000 (15%)] Loss: -1588.541260\n",
      "Train Epoch: 907 [12288/54000 (23%)] Loss: -1585.164551\n",
      "Train Epoch: 907 [16384/54000 (30%)] Loss: -1588.164062\n",
      "Train Epoch: 907 [20480/54000 (38%)] Loss: -1588.910400\n",
      "Train Epoch: 907 [24576/54000 (46%)] Loss: -1582.606934\n",
      "Train Epoch: 907 [28672/54000 (53%)] Loss: -1588.332031\n",
      "Train Epoch: 907 [32768/54000 (61%)] Loss: -1588.005127\n",
      "Train Epoch: 907 [36864/54000 (68%)] Loss: -1592.432983\n",
      "Train Epoch: 907 [40960/54000 (76%)] Loss: -1592.178711\n",
      "Train Epoch: 907 [45056/54000 (83%)] Loss: -1579.789551\n",
      "Train Epoch: 907 [49152/54000 (91%)] Loss: -1584.867798\n",
      "Train Epoch: 907 [53248/54000 (99%)] Loss: -1591.161255\n",
      "    epoch          : 907\n",
      "    loss           : -1586.762289761367\n",
      "    ess            : 3.7928339079093027\n",
      "    log_marginal   : 1586.8901708521548\n",
      "    val_loss       : -1586.5901997884114\n",
      "    val_ess        : 3.8029968241850534\n",
      "    val_log_marginal: 1586.705805460612\n",
      "Train Epoch: 908 [0/54000 (0%)] Loss: -1588.748413\n",
      "Train Epoch: 908 [4096/54000 (8%)] Loss: -1581.442993\n",
      "Train Epoch: 908 [8192/54000 (15%)] Loss: -1592.028687\n",
      "Train Epoch: 908 [12288/54000 (23%)] Loss: -1583.387939\n",
      "Train Epoch: 908 [16384/54000 (30%)] Loss: -1583.926025\n",
      "Train Epoch: 908 [20480/54000 (38%)] Loss: -1588.644287\n",
      "Train Epoch: 908 [24576/54000 (46%)] Loss: -1583.386719\n",
      "Train Epoch: 908 [28672/54000 (53%)] Loss: -1590.002686\n",
      "Train Epoch: 908 [32768/54000 (61%)] Loss: -1588.446289\n",
      "Train Epoch: 908 [36864/54000 (68%)] Loss: -1588.032471\n",
      "Train Epoch: 908 [40960/54000 (76%)] Loss: -1584.381958\n",
      "Train Epoch: 908 [45056/54000 (83%)] Loss: -1589.620239\n",
      "Train Epoch: 908 [49152/54000 (91%)] Loss: -1585.944458\n",
      "Train Epoch: 908 [53248/54000 (99%)] Loss: -1590.325317\n",
      "    epoch          : 908\n",
      "    loss           : -1586.9786718287173\n",
      "    ess            : 3.7993370435814158\n",
      "    log_marginal   : 1587.1033328087974\n",
      "    val_loss       : -1587.2215270996094\n",
      "    val_ess        : 3.7990106642246246\n",
      "    val_log_marginal: 1587.349573771159\n",
      "Train Epoch: 909 [0/54000 (0%)] Loss: -1583.408081\n",
      "Train Epoch: 909 [4096/54000 (8%)] Loss: -1588.676514\n",
      "Train Epoch: 909 [8192/54000 (15%)] Loss: -1582.317871\n",
      "Train Epoch: 909 [12288/54000 (23%)] Loss: -1585.437134\n",
      "Train Epoch: 909 [16384/54000 (30%)] Loss: -1588.564819\n",
      "Train Epoch: 909 [20480/54000 (38%)] Loss: -1585.016113\n",
      "Train Epoch: 909 [24576/54000 (46%)] Loss: -1590.549805\n",
      "Train Epoch: 909 [28672/54000 (53%)] Loss: -1588.594360\n",
      "Train Epoch: 909 [32768/54000 (61%)] Loss: -1586.748413\n",
      "Train Epoch: 909 [36864/54000 (68%)] Loss: -1581.734131\n",
      "Train Epoch: 909 [40960/54000 (76%)] Loss: -1585.349854\n",
      "Train Epoch: 909 [45056/54000 (83%)] Loss: -1596.684326\n",
      "Train Epoch: 909 [49152/54000 (91%)] Loss: -1584.769653\n",
      "Train Epoch: 909 [53248/54000 (99%)] Loss: -1584.017334\n",
      "    epoch          : 909\n",
      "    loss           : -1587.022303576718\n",
      "    ess            : 3.7954477811876632\n",
      "    log_marginal   : 1587.14886503536\n",
      "    val_loss       : -1587.7330271402996\n",
      "    val_ess        : 3.800959358612696\n",
      "    val_log_marginal: 1587.8498840332031\n",
      "Train Epoch: 910 [0/54000 (0%)] Loss: -1587.583008\n",
      "Train Epoch: 910 [4096/54000 (8%)] Loss: -1587.012573\n",
      "Train Epoch: 910 [8192/54000 (15%)] Loss: -1582.925781\n",
      "Train Epoch: 910 [12288/54000 (23%)] Loss: -1583.087891\n",
      "Train Epoch: 910 [16384/54000 (30%)] Loss: -1579.838257\n",
      "Train Epoch: 910 [20480/54000 (38%)] Loss: -1590.538574\n",
      "Train Epoch: 910 [24576/54000 (46%)] Loss: -1589.476074\n",
      "Train Epoch: 910 [28672/54000 (53%)] Loss: -1591.181885\n",
      "Train Epoch: 910 [32768/54000 (61%)] Loss: -1583.041504\n",
      "Train Epoch: 910 [36864/54000 (68%)] Loss: -1594.788208\n",
      "Train Epoch: 910 [40960/54000 (76%)] Loss: -1591.943970\n",
      "Train Epoch: 910 [45056/54000 (83%)] Loss: -1581.561768\n",
      "Train Epoch: 910 [49152/54000 (91%)] Loss: -1584.425293\n",
      "Train Epoch: 910 [53248/54000 (99%)] Loss: -1581.676270\n",
      "    epoch          : 910\n",
      "    loss           : -1587.2185185870853\n",
      "    ess            : 3.792478217897822\n",
      "    log_marginal   : 1587.3468619251703\n",
      "    val_loss       : -1587.0094401041667\n",
      "    val_ess        : 3.800703982512156\n",
      "    val_log_marginal: 1587.1279042561848\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0327_194126/checkpoint-epoch910.pth ...\n",
      "Train Epoch: 911 [0/54000 (0%)] Loss: -1586.566162\n",
      "Train Epoch: 911 [4096/54000 (8%)] Loss: -1587.199097\n",
      "Train Epoch: 911 [8192/54000 (15%)] Loss: -1586.719971\n",
      "Train Epoch: 911 [12288/54000 (23%)] Loss: -1587.969238\n",
      "Train Epoch: 911 [16384/54000 (30%)] Loss: -1581.764404\n",
      "Train Epoch: 911 [20480/54000 (38%)] Loss: -1586.898438\n",
      "Train Epoch: 911 [24576/54000 (46%)] Loss: -1582.739746\n",
      "Train Epoch: 911 [28672/54000 (53%)] Loss: -1590.048340\n",
      "Train Epoch: 911 [32768/54000 (61%)] Loss: -1585.542725\n",
      "Train Epoch: 911 [36864/54000 (68%)] Loss: -1586.262939\n",
      "Train Epoch: 911 [40960/54000 (76%)] Loss: -1585.531738\n",
      "Train Epoch: 911 [45056/54000 (83%)] Loss: -1592.521240\n",
      "Train Epoch: 911 [49152/54000 (91%)] Loss: -1587.717041\n",
      "Train Epoch: 911 [53248/54000 (99%)] Loss: -1584.608643\n",
      "    epoch          : 911\n",
      "    loss           : -1587.0615471573237\n",
      "    ess            : 3.7945753872677046\n",
      "    log_marginal   : 1587.1890626157065\n",
      "    val_loss       : -1587.304219563802\n",
      "    val_ess        : 3.7926453053951263\n",
      "    val_log_marginal: 1587.429423014323\n",
      "Train Epoch: 912 [0/54000 (0%)] Loss: -1589.541016\n",
      "Train Epoch: 912 [4096/54000 (8%)] Loss: -1585.990234\n",
      "Train Epoch: 912 [8192/54000 (15%)] Loss: -1585.577637\n",
      "Train Epoch: 912 [12288/54000 (23%)] Loss: -1588.206055\n",
      "Train Epoch: 912 [16384/54000 (30%)] Loss: -1587.667480\n",
      "Train Epoch: 912 [20480/54000 (38%)] Loss: -1581.971680\n",
      "Train Epoch: 912 [24576/54000 (46%)] Loss: -1588.144531\n",
      "Train Epoch: 912 [28672/54000 (53%)] Loss: -1587.193115\n",
      "Train Epoch: 912 [32768/54000 (61%)] Loss: -1580.788696\n",
      "Train Epoch: 912 [36864/54000 (68%)] Loss: -1586.624268\n",
      "Train Epoch: 912 [40960/54000 (76%)] Loss: -1589.050293\n",
      "Train Epoch: 912 [45056/54000 (83%)] Loss: -1589.302856\n",
      "Train Epoch: 912 [49152/54000 (91%)] Loss: -1576.735962\n",
      "Train Epoch: 912 [53248/54000 (99%)] Loss: -1587.572144\n",
      "    epoch          : 912\n",
      "    loss           : -1587.2589776640255\n",
      "    ess            : 3.7969538227641753\n",
      "    log_marginal   : 1587.3854170523548\n",
      "    val_loss       : -1586.5276133219402\n",
      "    val_ess        : 3.804908742507299\n",
      "    val_log_marginal: 1586.6484934488933\n",
      "Train Epoch: 913 [0/54000 (0%)] Loss: -1585.604492\n",
      "Train Epoch: 913 [4096/54000 (8%)] Loss: -1577.586182\n",
      "Train Epoch: 913 [8192/54000 (15%)] Loss: -1582.561157\n",
      "Train Epoch: 913 [12288/54000 (23%)] Loss: -1582.910889\n",
      "Train Epoch: 913 [16384/54000 (30%)] Loss: -1585.076416\n",
      "Train Epoch: 913 [20480/54000 (38%)] Loss: -1581.347900\n",
      "Train Epoch: 913 [24576/54000 (46%)] Loss: -1583.597778\n",
      "Train Epoch: 913 [28672/54000 (53%)] Loss: -1592.479736\n",
      "Train Epoch: 913 [32768/54000 (61%)] Loss: -1587.529907\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5b900-0121-4cf6-91b6-2c9b0b12716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.eval()\n",
    "trainer.model.cpu()\n",
    "trainer.cpu()\n",
    "trainer.train_particles.cpu()\n",
    "trainer.valid_particles.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d528cb-d45e-4a37-be86-9622aec9ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.graph.clear()\n",
    "trainer._load_particles(range(trainer.data_loader.batch_size), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26726a6-74e5-4e0f-81d5-746dba00f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in trainer.model.graph.nodes:\n",
    "    trainer.model.graph.nodes[site]['is_observed'] = trainer.model.graph.nodes[site]['value'] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb94c06-7112-4c5e-b781-0ac215a7e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2eeb8-32e3-467e-9e9a-0ac1e2af9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate_stack(\"forward\", (trainer.num_particles, trainer.data_loader.batch_size)):\n",
    "    model = pyro.condition(trainer.model, data={k: v['value'] for k, v in trainer.model.graph.nodes.items()})\n",
    "    xs = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9ba59-7b26-4ef3-9bfd-23f7c8a26464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1509d2-9afc-444e-821f-b7ccda42aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(xs.mean(dim=0)[i].squeeze().detach().cpu().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2029315-afe9-4ae8-9f64-c342ef8b830b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34a71d-84a2-48f0-8150-3607e77ed6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ppc] *",
   "language": "python",
   "name": "conda-env-ppc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
