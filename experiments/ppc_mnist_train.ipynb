{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ef93e3-8eb5-4883-8265-5fbe97d06e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/shai_hulud/ppc_experiments\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94520ed3-45be-4735-a0f2-b8f380838c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import pyro\n",
    "import torch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "import trainer.trainer as module_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac4be4-19eb-4713-a88d-9bec118c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75ea7b9-6fe5-4f8a-a825-3572e421242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1445d1-45bb-43f9-893d-7a2b2bad1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "\n",
    "config = read_json(\"experiments/ppc_mnist_config.json\")\n",
    "config = ConfigParser(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca35026-5f64-47f8-98c7-a5e228013d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistPpc(\n",
      "  (prior): GaussianPrior()\n",
      "  (decoder1): ConditionalGaussian(\n",
      "    (decoder): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=20, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder2): ConditionalGaussian(\n",
      "    (decoder): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (likelihood): MlpBernoulliLikelihood(\n",
      "    (decoder): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=256, out_features=784, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (graph): PpcGraphicalModel()\n",
      ")\n",
      "Trainable parameters: 319540\n",
      "Initialize particles: train batch 0\n",
      "Initialize particles: train batch 1\n",
      "Initialize particles: train batch 2\n",
      "Initialize particles: train batch 3\n",
      "Initialize particles: train batch 4\n",
      "Initialize particles: train batch 5\n",
      "Initialize particles: train batch 6\n",
      "Initialize particles: train batch 7\n",
      "Initialize particles: train batch 8\n",
      "Initialize particles: train batch 9\n",
      "Initialize particles: train batch 10\n",
      "Initialize particles: train batch 11\n",
      "Initialize particles: train batch 12\n",
      "Initialize particles: train batch 13\n",
      "Initialize particles: train batch 14\n",
      "Initialize particles: train batch 15\n",
      "Initialize particles: train batch 16\n",
      "Initialize particles: train batch 17\n",
      "Initialize particles: train batch 18\n",
      "Initialize particles: train batch 19\n",
      "Initialize particles: train batch 20\n",
      "Initialize particles: train batch 21\n",
      "Initialize particles: train batch 22\n",
      "Initialize particles: train batch 23\n",
      "Initialize particles: train batch 24\n",
      "Initialize particles: train batch 25\n",
      "Initialize particles: train batch 26\n",
      "Initialize particles: train batch 27\n",
      "Initialize particles: train batch 28\n",
      "Initialize particles: train batch 29\n",
      "Initialize particles: train batch 30\n",
      "Initialize particles: train batch 31\n",
      "Initialize particles: train batch 32\n",
      "Initialize particles: train batch 33\n",
      "Initialize particles: train batch 34\n",
      "Initialize particles: train batch 35\n",
      "Initialize particles: train batch 36\n",
      "Initialize particles: train batch 37\n",
      "Initialize particles: train batch 38\n",
      "Initialize particles: train batch 39\n",
      "Initialize particles: train batch 40\n",
      "Initialize particles: train batch 41\n",
      "Initialize particles: train batch 42\n",
      "Initialize particles: train batch 43\n",
      "Initialize particles: train batch 44\n",
      "Initialize particles: train batch 45\n",
      "Initialize particles: train batch 46\n",
      "Initialize particles: train batch 47\n",
      "Initialize particles: train batch 48\n",
      "Initialize particles: train batch 49\n",
      "Initialize particles: train batch 50\n",
      "Initialize particles: train batch 51\n",
      "Initialize particles: train batch 52\n",
      "Initialize particles: valid batch 0\n",
      "Initialize particles: valid batch 1\n",
      "Initialize particles: valid batch 2\n",
      "Initialize particles: valid batch 3\n",
      "Initialize particles: valid batch 4\n",
      "Initialize particles: valid batch 5\n"
     ]
    }
   ],
   "source": [
    "logger = config.get_logger('train')\n",
    "\n",
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()\n",
    "\n",
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)\n",
    "logger.info(model)\n",
    "\n",
    "# get function handles of metrics\n",
    "metrics = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# build optimizer.\n",
    "if \"lr_scheduler\" in config:\n",
    "    lr_scheduler = getattr(pyro.optim, config[\"lr_scheduler\"][\"type\"])\n",
    "    lr_scheduler = optimizer = lr_scheduler({\n",
    "        \"optimizer\": getattr(torch.optim, config[\"optimizer\"][\"type\"]),\n",
    "        \"optim_args\": config[\"optimizer\"][\"args\"][\"optim_args\"],\n",
    "        **config[\"lr_scheduler\"][\"args\"]\n",
    "    })\n",
    "else:\n",
    "    optimizer = config.init_obj('optimizer', pyro.optim)\n",
    "    lr_scheduler = None\n",
    "\n",
    "# build trainer\n",
    "# kwargs = config['trainer'].pop('args')\n",
    "trainer = config.init_obj('trainer', module_trainer, model, metrics, optimizer,\n",
    "                          config=config, data_loader=data_loader,\n",
    "                          valid_data_loader=valid_data_loader,\n",
    "                          lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5cdd31-7fae-4e6f-8fe2-ef5c023919de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved/log/Mnist_Ppc/0416_172629\n"
     ]
    }
   ],
   "source": [
    "logger.info(trainer.config.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9820b982-1a39-4bde-850e-1a1d9a92557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/54000 (0%)] Loss: 784.622192\n",
      "Train Epoch: 1 [32768/54000 (61%)] Loss: -544.218323\n",
      "    epoch          : 1\n",
      "    loss           : -424.4658193588257\n",
      "    ess            : 3.7403217171722987\n",
      "    log_marginal   : 425.38882748585826\n",
      "    val_loss       : -548.5861307779948\n",
      "    val_ess        : 3.720800439516703\n",
      "    val_log_marginal: 549.5235290527344\n",
      "Train Epoch: 2 [0/54000 (0%)] Loss: -555.097656\n",
      "Train Epoch: 2 [32768/54000 (61%)] Loss: -569.395874\n",
      "    epoch          : 2\n",
      "    loss           : -565.2021703180277\n",
      "    ess            : 3.877007057081978\n",
      "    log_marginal   : 565.3015205815153\n",
      "    val_loss       : -575.3597513834635\n",
      "    val_ess        : 3.865303079287211\n",
      "    val_log_marginal: 575.4648132324219\n",
      "Train Epoch: 3 [0/54000 (0%)] Loss: -577.675903\n",
      "Train Epoch: 3 [32768/54000 (61%)] Loss: -572.376465\n",
      "    epoch          : 3\n",
      "    loss           : -587.3464390016952\n",
      "    ess            : 3.8842968850765587\n",
      "    log_marginal   : 587.3943792379127\n",
      "    val_loss       : -605.0875651041666\n",
      "    val_ess        : 3.876797397931417\n",
      "    val_log_marginal: 605.1439310709635\n",
      "Train Epoch: 4 [0/54000 (0%)] Loss: -617.715149\n",
      "Train Epoch: 4 [32768/54000 (61%)] Loss: -625.719055\n",
      "    epoch          : 4\n",
      "    loss           : -628.4042542655513\n",
      "    ess            : 3.884313412432401\n",
      "    log_marginal   : 628.4494145231427\n",
      "    val_loss       : -654.9404296875\n",
      "    val_ess        : 3.876219073931376\n",
      "    val_log_marginal: 654.987050374349\n",
      "Train Epoch: 5 [0/54000 (0%)] Loss: -674.521851\n",
      "Train Epoch: 5 [32768/54000 (61%)] Loss: -690.469299\n",
      "    epoch          : 5\n",
      "    loss           : -684.6238334223909\n",
      "    ess            : 3.88404400393648\n",
      "    log_marginal   : 684.6691134470814\n",
      "    val_loss       : -711.4701843261719\n",
      "    val_ess        : 3.9009886980056763\n",
      "    val_log_marginal: 711.5055745442709\n",
      "Train Epoch: 6 [0/54000 (0%)] Loss: -729.269897\n",
      "Train Epoch: 6 [32768/54000 (61%)] Loss: -746.512085\n",
      "    epoch          : 6\n",
      "    loss           : -739.7373277196344\n",
      "    ess            : 3.884602618667315\n",
      "    log_marginal   : 739.7804300560141\n",
      "    val_loss       : -761.5880228678385\n",
      "    val_ess        : 3.889366626739502\n",
      "    val_log_marginal: 761.6280110677084\n",
      "Train Epoch: 7 [0/54000 (0%)] Loss: -775.978821\n",
      "Train Epoch: 7 [32768/54000 (61%)] Loss: -788.337402\n",
      "    epoch          : 7\n",
      "    loss           : -785.0849367537588\n",
      "    ess            : 3.8818937112700262\n",
      "    log_marginal   : 785.129207970961\n",
      "    val_loss       : -801.6627095540365\n",
      "    val_ess        : 3.8841344912846885\n",
      "    val_log_marginal: 801.7051595052084\n",
      "Train Epoch: 8 [0/54000 (0%)] Loss: -809.808472\n",
      "Train Epoch: 8 [32768/54000 (61%)] Loss: -815.737427\n",
      "    epoch          : 8\n",
      "    loss           : -820.7077694299086\n",
      "    ess            : 3.8809687146600687\n",
      "    log_marginal   : 820.7528663491303\n",
      "    val_loss       : -832.6881510416666\n",
      "    val_ess        : 3.876464088757833\n",
      "    val_log_marginal: 832.7334594726562\n",
      "Train Epoch: 9 [0/54000 (0%)] Loss: -836.849731\n",
      "Train Epoch: 9 [32768/54000 (61%)] Loss: -852.647400\n",
      "    epoch          : 9\n",
      "    loss           : -850.3111641362028\n",
      "    ess            : 3.8812477903546028\n",
      "    log_marginal   : 850.3559535764298\n",
      "    val_loss       : -860.1311340332031\n",
      "    val_ess        : 3.881521979967753\n",
      "    val_log_marginal: 860.1753540039062\n",
      "Train Epoch: 10 [0/54000 (0%)] Loss: -871.222412\n",
      "Train Epoch: 10 [32768/54000 (61%)] Loss: -871.786133\n",
      "    epoch          : 10\n",
      "    loss           : -876.226595896595\n",
      "    ess            : 3.879518189520206\n",
      "    log_marginal   : 876.2718068248821\n",
      "    val_loss       : -884.4559733072916\n",
      "    val_ess        : 3.881347934405009\n",
      "    val_log_marginal: 884.499013264974\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch10.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 11 [0/54000 (0%)] Loss: -896.737488\n",
      "Train Epoch: 11 [32768/54000 (61%)] Loss: -901.478027\n",
      "    epoch          : 11\n",
      "    loss           : -899.918833606648\n",
      "    ess            : 3.880975898706688\n",
      "    log_marginal   : 899.9629804503243\n",
      "    val_loss       : -907.1820983886719\n",
      "    val_ess        : 3.8720479806264243\n",
      "    val_log_marginal: 907.2311096191406\n",
      "Train Epoch: 12 [0/54000 (0%)] Loss: -924.449829\n",
      "Train Epoch: 12 [32768/54000 (61%)] Loss: -924.460815\n",
      "    epoch          : 12\n",
      "    loss           : -921.5918026330336\n",
      "    ess            : 3.8802999010625876\n",
      "    log_marginal   : 921.6362500460642\n",
      "    val_loss       : -927.5574544270834\n",
      "    val_ess        : 3.8924219210942588\n",
      "    val_log_marginal: 927.595713297526\n",
      "Train Epoch: 13 [0/54000 (0%)] Loss: -952.312988\n",
      "Train Epoch: 13 [32768/54000 (61%)] Loss: -946.752747\n",
      "    epoch          : 13\n",
      "    loss           : -941.1690835053066\n",
      "    ess            : 3.8778855665674747\n",
      "    log_marginal   : 941.2153999760466\n",
      "    val_loss       : -946.1814270019531\n",
      "    val_ess        : 3.8798211415608725\n",
      "    val_log_marginal: 946.2268880208334\n",
      "Train Epoch: 14 [0/54000 (0%)] Loss: -960.004456\n",
      "Train Epoch: 14 [32768/54000 (61%)] Loss: -954.309326\n",
      "    epoch          : 14\n",
      "    loss           : -958.985128150796\n",
      "    ess            : 3.8790039296420114\n",
      "    log_marginal   : 959.03076171875\n",
      "    val_loss       : -963.1973266601562\n",
      "    val_ess        : 3.883625109990438\n",
      "    val_log_marginal: 963.2407430013021\n",
      "Train Epoch: 15 [0/54000 (0%)] Loss: -969.446472\n",
      "Train Epoch: 15 [32768/54000 (61%)] Loss: -976.161560\n",
      "    epoch          : 15\n",
      "    loss           : -974.9868117998232\n",
      "    ess            : 3.877674791048158\n",
      "    log_marginal   : 975.0334322947376\n",
      "    val_loss       : -978.1136678059896\n",
      "    val_ess        : 3.8788899580637612\n",
      "    val_log_marginal: 978.1618041992188\n",
      "Train Epoch: 16 [0/54000 (0%)] Loss: -987.799072\n",
      "Train Epoch: 16 [32768/54000 (61%)] Loss: -986.802612\n",
      "    epoch          : 16\n",
      "    loss           : -983.7180601875737\n",
      "    ess            : 3.879609967177769\n",
      "    log_marginal   : 983.7630546137972\n",
      "    val_loss       : -968.6627909342448\n",
      "    val_ess        : 3.8917837937672934\n",
      "    val_log_marginal: 968.7011006673177\n",
      "Train Epoch: 17 [0/54000 (0%)] Loss: -980.455505\n",
      "Train Epoch: 17 [32768/54000 (61%)] Loss: -981.451416\n",
      "    epoch          : 17\n",
      "    loss           : -979.1273538841391\n",
      "    ess            : 3.8763145635712823\n",
      "    log_marginal   : 979.1745789725826\n",
      "    val_loss       : -995.1678466796875\n",
      "    val_ess        : 3.8737994035085044\n",
      "    val_log_marginal: 995.2144978841146\n",
      "Train Epoch: 18 [0/54000 (0%)] Loss: -1001.945190\n",
      "Train Epoch: 18 [32768/54000 (61%)] Loss: -1005.085693\n",
      "    epoch          : 18\n",
      "    loss           : -1004.6611143867924\n",
      "    ess            : 3.8808327126053146\n",
      "    log_marginal   : 1004.7053971200619\n",
      "    val_loss       : -1010.9333801269531\n",
      "    val_ess        : 3.878722071647644\n",
      "    val_log_marginal: 1010.9782206217448\n",
      "Train Epoch: 19 [0/54000 (0%)] Loss: -1027.169556\n",
      "Train Epoch: 19 [32768/54000 (61%)] Loss: -1019.772827\n",
      "    epoch          : 19\n",
      "    loss           : -1021.9209640790831\n",
      "    ess            : 3.872606151508835\n",
      "    log_marginal   : 1021.9688674638857\n",
      "    val_loss       : -1023.034423828125\n",
      "    val_ess        : 3.8737818002700806\n",
      "    val_log_marginal: 1023.0814107259115\n",
      "Train Epoch: 20 [0/54000 (0%)] Loss: -1036.246582\n",
      "Train Epoch: 20 [32768/54000 (61%)] Loss: -1033.210571\n",
      "    epoch          : 20\n",
      "    loss           : -1032.336831146816\n",
      "    ess            : 3.874898951008635\n",
      "    log_marginal   : 1032.385233177329\n",
      "    val_loss       : -1031.7674763997395\n",
      "    val_ess        : 3.873511632283529\n",
      "    val_log_marginal: 1031.812723795573\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch20.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 21 [0/54000 (0%)] Loss: -1041.602417\n",
      "Train Epoch: 21 [32768/54000 (61%)] Loss: -1043.019775\n",
      "    epoch          : 21\n",
      "    loss           : -1041.946798072671\n",
      "    ess            : 3.8694088953845904\n",
      "    log_marginal   : 1041.9966787662147\n",
      "    val_loss       : -1041.3922932942708\n",
      "    val_ess        : 3.874835968017578\n",
      "    val_log_marginal: 1041.436991373698\n",
      "Train Epoch: 22 [0/54000 (0%)] Loss: -1051.768066\n",
      "Train Epoch: 22 [32768/54000 (61%)] Loss: -1053.143433\n",
      "    epoch          : 22\n",
      "    loss           : -1047.9245743661556\n",
      "    ess            : 3.872402506054572\n",
      "    log_marginal   : 1047.9731975051593\n",
      "    val_loss       : -1045.8260498046875\n",
      "    val_ess        : 3.866478761037191\n",
      "    val_log_marginal: 1045.8780314127605\n",
      "Train Epoch: 23 [0/54000 (0%)] Loss: -1058.242798\n",
      "Train Epoch: 23 [32768/54000 (61%)] Loss: -1054.842529\n",
      "    epoch          : 23\n",
      "    loss           : -1054.618610885908\n",
      "    ess            : 3.8713506572651415\n",
      "    log_marginal   : 1054.6671418963738\n",
      "    val_loss       : -1047.0103963216145\n",
      "    val_ess        : 3.868246595064799\n",
      "    val_log_marginal: 1047.0604044596355\n",
      "Train Epoch: 24 [0/54000 (0%)] Loss: -1058.388428\n",
      "Train Epoch: 24 [32768/54000 (61%)] Loss: -1062.693237\n",
      "    epoch          : 24\n",
      "    loss           : -1060.3480846477005\n",
      "    ess            : 3.87591319264106\n",
      "    log_marginal   : 1060.3940982458726\n",
      "    val_loss       : -1064.2681681315105\n",
      "    val_ess        : 3.8574624061584473\n",
      "    val_log_marginal: 1064.3274536132812\n",
      "Train Epoch: 25 [0/54000 (0%)] Loss: -1071.255493\n",
      "Train Epoch: 25 [32768/54000 (61%)] Loss: -1071.454834\n",
      "    epoch          : 25\n",
      "    loss           : -1068.895731224204\n",
      "    ess            : 3.867587773305065\n",
      "    log_marginal   : 1068.9447067548645\n",
      "    val_loss       : -1067.5505777994792\n",
      "    val_ess        : 3.8534655570983887\n",
      "    val_log_marginal: 1067.6073811848958\n",
      "Train Epoch: 26 [0/54000 (0%)] Loss: -1075.509766\n",
      "Train Epoch: 26 [32768/54000 (61%)] Loss: -1074.472656\n",
      "    epoch          : 26\n",
      "    loss           : -1075.550272239829\n",
      "    ess            : 3.8670735539130443\n",
      "    log_marginal   : 1075.6002036040684\n",
      "    val_loss       : -1073.0398763020833\n",
      "    val_ess        : 3.8657127618789673\n",
      "    val_log_marginal: 1073.0899454752605\n",
      "Train Epoch: 27 [0/54000 (0%)] Loss: -1084.744751\n",
      "Train Epoch: 27 [32768/54000 (61%)] Loss: -1087.572510\n",
      "    epoch          : 27\n",
      "    loss           : -1080.8793415573407\n",
      "    ess            : 3.8689631875955834\n",
      "    log_marginal   : 1080.9282779333726\n",
      "    val_loss       : -1076.2664184570312\n",
      "    val_ess        : 3.860427498817444\n",
      "    val_log_marginal: 1076.3197428385417\n",
      "Train Epoch: 28 [0/54000 (0%)] Loss: -1087.058105\n",
      "Train Epoch: 28 [32768/54000 (61%)] Loss: -1085.575317\n",
      "    epoch          : 28\n",
      "    loss           : -1083.201042895047\n",
      "    ess            : 3.864392451520236\n",
      "    log_marginal   : 1083.2535054908608\n",
      "    val_loss       : -1082.2996419270833\n",
      "    val_ess        : 3.8730116287867227\n",
      "    val_log_marginal: 1082.3463134765625\n",
      "Train Epoch: 29 [0/54000 (0%)] Loss: -1093.920166\n",
      "Train Epoch: 29 [32768/54000 (61%)] Loss: -1087.899170\n",
      "    epoch          : 29\n",
      "    loss           : -1086.2033622309846\n",
      "    ess            : 3.8671098925032705\n",
      "    log_marginal   : 1086.253480155513\n",
      "    val_loss       : -1077.938008626302\n",
      "    val_ess        : 3.874362031618754\n",
      "    val_log_marginal: 1077.987548828125\n",
      "Train Epoch: 30 [0/54000 (0%)] Loss: -1087.263916\n",
      "Train Epoch: 30 [32768/54000 (61%)] Loss: -1096.269043\n",
      "    epoch          : 30\n",
      "    loss           : -1091.7928006154186\n",
      "    ess            : 3.8645373200470545\n",
      "    log_marginal   : 1091.8447588074882\n",
      "    val_loss       : -1091.8465169270833\n",
      "    val_ess        : 3.8690259059270224\n",
      "    val_log_marginal: 1091.895772298177\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch30.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 31 [0/54000 (0%)] Loss: -1097.697876\n",
      "Train Epoch: 31 [32768/54000 (61%)] Loss: -1094.092651\n",
      "    epoch          : 31\n",
      "    loss           : -1096.1186707694576\n",
      "    ess            : 3.861443335155271\n",
      "    log_marginal   : 1096.1715617629718\n",
      "    val_loss       : -1094.601826985677\n",
      "    val_ess        : 3.8667880296707153\n",
      "    val_log_marginal: 1094.6510620117188\n",
      "Train Epoch: 32 [0/54000 (0%)] Loss: -1102.874390\n",
      "Train Epoch: 32 [32768/54000 (61%)] Loss: -1099.590210\n",
      "    epoch          : 32\n",
      "    loss           : -1100.780402417453\n",
      "    ess            : 3.8642882581027047\n",
      "    log_marginal   : 1100.8313425891804\n",
      "    val_loss       : -1097.497802734375\n",
      "    val_ess        : 3.8727773825327554\n",
      "    val_log_marginal: 1097.5439860026042\n",
      "Train Epoch: 33 [0/54000 (0%)] Loss: -1109.112671\n",
      "Train Epoch: 33 [32768/54000 (61%)] Loss: -1110.723633\n",
      "    epoch          : 33\n",
      "    loss           : -1104.4833592828716\n",
      "    ess            : 3.8616979122161865\n",
      "    log_marginal   : 1104.5364068948998\n",
      "    val_loss       : -1099.7150268554688\n",
      "    val_ess        : 3.8608446518580117\n",
      "    val_log_marginal: 1099.7713826497395\n",
      "Train Epoch: 34 [0/54000 (0%)] Loss: -1105.909424\n",
      "Train Epoch: 34 [32768/54000 (61%)] Loss: -1102.717163\n",
      "    epoch          : 34\n",
      "    loss           : -1104.0774524616745\n",
      "    ess            : 3.8634804239812888\n",
      "    log_marginal   : 1104.1290743845814\n",
      "    val_loss       : -1103.5387369791667\n",
      "    val_ess        : 3.862457553545634\n",
      "    val_log_marginal: 1103.5901896158855\n",
      "Train Epoch: 35 [0/54000 (0%)] Loss: -1104.233521\n",
      "Train Epoch: 35 [32768/54000 (61%)] Loss: -1097.927734\n",
      "    epoch          : 35\n",
      "    loss           : -1105.5689973651238\n",
      "    ess            : 3.866914600696204\n",
      "    log_marginal   : 1105.6196749705189\n",
      "    val_loss       : -1097.55078125\n",
      "    val_ess        : 3.863553206125895\n",
      "    val_log_marginal: 1097.6022135416667\n",
      "Train Epoch: 36 [0/54000 (0%)] Loss: -1107.828735\n",
      "Train Epoch: 36 [32768/54000 (61%)] Loss: -1112.787109\n",
      "    epoch          : 36\n",
      "    loss           : -1111.1783101783608\n",
      "    ess            : 3.8574939358909175\n",
      "    log_marginal   : 1111.2328617887677\n",
      "    val_loss       : -1109.7483317057292\n",
      "    val_ess        : 3.862066149711609\n",
      "    val_log_marginal: 1109.8005777994792\n",
      "Train Epoch: 37 [0/54000 (0%)] Loss: -1113.240723\n",
      "Train Epoch: 37 [32768/54000 (61%)] Loss: -1114.470215\n",
      "    epoch          : 37\n",
      "    loss           : -1114.3666900058963\n",
      "    ess            : 3.8578641414642334\n",
      "    log_marginal   : 1114.4220477410083\n",
      "    val_loss       : -1112.9105428059895\n",
      "    val_ess        : 3.8493100007375083\n",
      "    val_log_marginal: 1112.9688517252605\n",
      "Train Epoch: 38 [0/54000 (0%)] Loss: -1120.552612\n",
      "Train Epoch: 38 [32768/54000 (61%)] Loss: -1116.797241\n",
      "    epoch          : 38\n",
      "    loss           : -1118.041830962559\n",
      "    ess            : 3.8550684092179783\n",
      "    log_marginal   : 1118.0965737396816\n",
      "    val_loss       : -1115.4264322916667\n",
      "    val_ess        : 3.8603981335957847\n",
      "    val_log_marginal: 1115.4807535807292\n",
      "Train Epoch: 39 [0/54000 (0%)] Loss: -1121.220215\n",
      "Train Epoch: 39 [32768/54000 (61%)] Loss: -1118.212280\n",
      "    epoch          : 39\n",
      "    loss           : -1120.3479165131191\n",
      "    ess            : 3.857954353656409\n",
      "    log_marginal   : 1120.4026846255897\n",
      "    val_loss       : -1114.1434326171875\n",
      "    val_ess        : 3.8498014211654663\n",
      "    val_log_marginal: 1114.1992797851562\n",
      "Train Epoch: 40 [0/54000 (0%)] Loss: -1121.610962\n",
      "Train Epoch: 40 [32768/54000 (61%)] Loss: -1119.367188\n",
      "    epoch          : 40\n",
      "    loss           : -1119.1845334610848\n",
      "    ess            : 3.8549286104598135\n",
      "    log_marginal   : 1119.2409760097287\n",
      "    val_loss       : -1118.9524536132812\n",
      "    val_ess        : 3.8531286319096885\n",
      "    val_log_marginal: 1119.0086466471355\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch40.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 41 [0/54000 (0%)] Loss: -1127.313965\n",
      "Train Epoch: 41 [32768/54000 (61%)] Loss: -1119.695312\n",
      "    epoch          : 41\n",
      "    loss           : -1119.6265454562206\n",
      "    ess            : 3.85305440650796\n",
      "    log_marginal   : 1119.6839069870282\n",
      "    val_loss       : -1112.693359375\n",
      "    val_ess        : 3.858280658721924\n",
      "    val_log_marginal: 1112.7467854817708\n",
      "Train Epoch: 42 [0/54000 (0%)] Loss: -1122.278564\n",
      "Train Epoch: 42 [32768/54000 (61%)] Loss: -1122.152832\n",
      "    epoch          : 42\n",
      "    loss           : -1124.8511133733784\n",
      "    ess            : 3.85143887321904\n",
      "    log_marginal   : 1124.9084219302772\n",
      "    val_loss       : -1122.7091674804688\n",
      "    val_ess        : 3.8524473905563354\n",
      "    val_log_marginal: 1122.7654622395833\n",
      "Train Epoch: 43 [0/54000 (0%)] Loss: -1127.206177\n",
      "Train Epoch: 43 [32768/54000 (61%)] Loss: -1126.504272\n",
      "    epoch          : 43\n",
      "    loss           : -1127.3685671248527\n",
      "    ess            : 3.8497605323791504\n",
      "    log_marginal   : 1127.426513671875\n",
      "    val_loss       : -1126.7594604492188\n",
      "    val_ess        : 3.8547580242156982\n",
      "    val_log_marginal: 1126.813741048177\n",
      "Train Epoch: 44 [0/54000 (0%)] Loss: -1126.949951\n",
      "Train Epoch: 44 [32768/54000 (61%)] Loss: -1131.739258\n",
      "    epoch          : 44\n",
      "    loss           : -1130.9014570128243\n",
      "    ess            : 3.8498219049201823\n",
      "    log_marginal   : 1130.9597974093456\n",
      "    val_loss       : -1128.8424479166667\n",
      "    val_ess        : 3.848111152648926\n",
      "    val_log_marginal: 1128.8992309570312\n",
      "Train Epoch: 45 [0/54000 (0%)] Loss: -1134.837524\n",
      "Train Epoch: 45 [32768/54000 (61%)] Loss: -1133.438232\n",
      "    epoch          : 45\n",
      "    loss           : -1132.4055774616745\n",
      "    ess            : 3.8541476996439807\n",
      "    log_marginal   : 1132.4617067732902\n",
      "    val_loss       : -1125.8548583984375\n",
      "    val_ess        : 3.8449804385503135\n",
      "    val_log_marginal: 1125.9146321614583\n",
      "Train Epoch: 46 [0/54000 (0%)] Loss: -1130.678711\n",
      "Train Epoch: 46 [32768/54000 (61%)] Loss: -1134.866455\n",
      "    epoch          : 46\n",
      "    loss           : -1131.2305608785377\n",
      "    ess            : 3.8494654241597877\n",
      "    log_marginal   : 1131.2885511866157\n",
      "    val_loss       : -1131.4710896809895\n",
      "    val_ess        : 3.839701294898987\n",
      "    val_log_marginal: 1131.5308634440105\n",
      "Train Epoch: 47 [0/54000 (0%)] Loss: -1136.457520\n",
      "Train Epoch: 47 [32768/54000 (61%)] Loss: -1133.448730\n",
      "    epoch          : 47\n",
      "    loss           : -1131.6853971661262\n",
      "    ess            : 3.8451565481581778\n",
      "    log_marginal   : 1131.7464369288032\n",
      "    val_loss       : -1125.5216674804688\n",
      "    val_ess        : 3.84849218527476\n",
      "    val_log_marginal: 1125.5827229817708\n",
      "Train Epoch: 48 [0/54000 (0%)] Loss: -1137.944336\n",
      "Train Epoch: 48 [32768/54000 (61%)] Loss: -1138.106689\n",
      "    epoch          : 48\n",
      "    loss           : -1136.1501810325767\n",
      "    ess            : 3.846620393249224\n",
      "    log_marginal   : 1136.2110319317512\n",
      "    val_loss       : -1134.032938639323\n",
      "    val_ess        : 3.8563946882883706\n",
      "    val_log_marginal: 1134.089335123698\n",
      "Train Epoch: 49 [0/54000 (0%)] Loss: -1138.600586\n",
      "Train Epoch: 49 [32768/54000 (61%)] Loss: -1140.832886\n",
      "    epoch          : 49\n",
      "    loss           : -1137.5366947965802\n",
      "    ess            : 3.83948246038185\n",
      "    log_marginal   : 1137.5986051739387\n",
      "    val_loss       : -1137.5742594401042\n",
      "    val_ess        : 3.850149909655253\n",
      "    val_log_marginal: 1137.626729329427\n",
      "Train Epoch: 50 [0/54000 (0%)] Loss: -1143.208374\n",
      "Train Epoch: 50 [32768/54000 (61%)] Loss: -1141.645508\n",
      "    epoch          : 50\n",
      "    loss           : -1140.9921736807194\n",
      "    ess            : 3.84093565311072\n",
      "    log_marginal   : 1141.053706331073\n",
      "    val_loss       : -1139.5108642578125\n",
      "    val_ess        : 3.8443722327550254\n",
      "    val_log_marginal: 1139.5767211914062\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch50.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 51 [0/54000 (0%)] Loss: -1143.174072\n",
      "Train Epoch: 51 [32768/54000 (61%)] Loss: -1143.194214\n",
      "    epoch          : 51\n",
      "    loss           : -1142.2435924602005\n",
      "    ess            : 3.838819238374818\n",
      "    log_marginal   : 1142.306474793632\n",
      "    val_loss       : -1135.9115804036458\n",
      "    val_ess        : 3.8504503965377808\n",
      "    val_log_marginal: 1135.9667358398438\n",
      "Train Epoch: 52 [0/54000 (0%)] Loss: -1141.921143\n",
      "Train Epoch: 52 [32768/54000 (61%)] Loss: -1142.009766\n",
      "    epoch          : 52\n",
      "    loss           : -1140.6843860554245\n",
      "    ess            : 3.8367899318910994\n",
      "    log_marginal   : 1140.7497328272407\n",
      "    val_loss       : -1141.400370279948\n",
      "    val_ess        : 3.834880828857422\n",
      "    val_log_marginal: 1141.4696858723958\n",
      "Train Epoch: 53 [0/54000 (0%)] Loss: -1141.195801\n",
      "Train Epoch: 53 [32768/54000 (61%)] Loss: -1142.025391\n",
      "    epoch          : 53\n",
      "    loss           : -1141.2988810989093\n",
      "    ess            : 3.836582863105918\n",
      "    log_marginal   : 1141.3626870209316\n",
      "    val_loss       : -1136.3522338867188\n",
      "    val_ess        : 3.836881915728251\n",
      "    val_log_marginal: 1136.4166870117188\n",
      "Train Epoch: 54 [0/54000 (0%)] Loss: -1142.755249\n",
      "Train Epoch: 54 [32768/54000 (61%)] Loss: -1147.345947\n",
      "    epoch          : 54\n",
      "    loss           : -1145.5472181788032\n",
      "    ess            : 3.8339144508793668\n",
      "    log_marginal   : 1145.6130532318691\n",
      "    val_loss       : -1142.8977457682292\n",
      "    val_ess        : 3.8395058711369834\n",
      "    val_log_marginal: 1142.9615478515625\n",
      "Train Epoch: 55 [0/54000 (0%)] Loss: -1146.949219\n",
      "Train Epoch: 55 [32768/54000 (61%)] Loss: -1142.818604\n",
      "    epoch          : 55\n",
      "    loss           : -1146.2698652159493\n",
      "    ess            : 3.8334451936325937\n",
      "    log_marginal   : 1146.336835753243\n",
      "    val_loss       : -1147.0478922526042\n",
      "    val_ess        : 3.8457432190577188\n",
      "    val_log_marginal: 1147.1103922526042\n",
      "Train Epoch: 56 [0/54000 (0%)] Loss: -1150.672607\n",
      "Train Epoch: 56 [32768/54000 (61%)] Loss: -1148.363281\n",
      "    epoch          : 56\n",
      "    loss           : -1149.2971099277713\n",
      "    ess            : 3.831535091939962\n",
      "    log_marginal   : 1149.3634263524468\n",
      "    val_loss       : -1148.0808919270833\n",
      "    val_ess        : 3.837502598762512\n",
      "    val_log_marginal: 1148.148417154948\n",
      "Train Epoch: 57 [0/54000 (0%)] Loss: -1151.158691\n",
      "Train Epoch: 57 [32768/54000 (61%)] Loss: -1152.073242\n",
      "    epoch          : 57\n",
      "    loss           : -1150.8498028449292\n",
      "    ess            : 3.825917959213257\n",
      "    log_marginal   : 1150.9194704451652\n",
      "    val_loss       : -1145.2920328776042\n",
      "    val_ess        : 3.843285083770752\n",
      "    val_log_marginal: 1145.3523559570312\n",
      "Train Epoch: 58 [0/54000 (0%)] Loss: -1149.377197\n",
      "Train Epoch: 58 [32768/54000 (61%)] Loss: -1148.418213\n",
      "    epoch          : 58\n",
      "    loss           : -1149.3965143167748\n",
      "    ess            : 3.8303303763551533\n",
      "    log_marginal   : 1149.464090599204\n",
      "    val_loss       : -1150.7988688151042\n",
      "    val_ess        : 3.8414801359176636\n",
      "    val_log_marginal: 1150.8618977864583\n",
      "Train Epoch: 59 [0/54000 (0%)] Loss: -1151.175293\n",
      "Train Epoch: 59 [32768/54000 (61%)] Loss: -1150.376465\n",
      "    epoch          : 59\n",
      "    loss           : -1150.7897557672466\n",
      "    ess            : 3.829637397010371\n",
      "    log_marginal   : 1150.8575946160083\n",
      "    val_loss       : -1147.4828491210938\n",
      "    val_ess        : 3.8317131201426187\n",
      "    val_log_marginal: 1147.55322265625\n",
      "Train Epoch: 60 [0/54000 (0%)] Loss: -1154.618286\n",
      "Train Epoch: 60 [32768/54000 (61%)] Loss: -1154.826172\n",
      "    epoch          : 60\n",
      "    loss           : -1154.2240842423348\n",
      "    ess            : 3.8271321800519837\n",
      "    log_marginal   : 1154.2916835568985\n",
      "    val_loss       : -1150.9698486328125\n",
      "    val_ess        : 3.819852670033773\n",
      "    val_log_marginal: 1151.0455525716145\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch60.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 61 [0/54000 (0%)] Loss: -1154.507446\n",
      "Train Epoch: 61 [32768/54000 (61%)] Loss: -1151.929199\n",
      "    epoch          : 61\n",
      "    loss           : -1154.0173501068691\n",
      "    ess            : 3.828471431192362\n",
      "    log_marginal   : 1154.0846039394162\n",
      "    val_loss       : -1155.0100708007812\n",
      "    val_ess        : 3.822326103846232\n",
      "    val_log_marginal: 1155.0817260742188\n",
      "Train Epoch: 62 [0/54000 (0%)] Loss: -1158.516602\n",
      "Train Epoch: 62 [32768/54000 (61%)] Loss: -1157.057129\n",
      "    epoch          : 62\n",
      "    loss           : -1156.781618514151\n",
      "    ess            : 3.8251528604975285\n",
      "    log_marginal   : 1156.8523686247052\n",
      "    val_loss       : -1155.1107177734375\n",
      "    val_ess        : 3.814181367556254\n",
      "    val_log_marginal: 1155.1851603190105\n",
      "Train Epoch: 63 [0/54000 (0%)] Loss: -1162.449951\n",
      "Train Epoch: 63 [32768/54000 (61%)] Loss: -1158.883179\n",
      "    epoch          : 63\n",
      "    loss           : -1158.5644208800118\n",
      "    ess            : 3.8252257581027047\n",
      "    log_marginal   : 1158.6347978699882\n",
      "    val_loss       : -1153.1249593098958\n",
      "    val_ess        : 3.817305644353231\n",
      "    val_log_marginal: 1153.2030639648438\n",
      "Train Epoch: 64 [0/54000 (0%)] Loss: -1156.479736\n",
      "Train Epoch: 64 [32768/54000 (61%)] Loss: -1158.402588\n",
      "    epoch          : 64\n",
      "    loss           : -1157.0433004127358\n",
      "    ess            : 3.817548203018476\n",
      "    log_marginal   : 1157.117514556309\n",
      "    val_loss       : -1158.462890625\n",
      "    val_ess        : 3.827903469403585\n",
      "    val_log_marginal: 1158.5340372721355\n",
      "Train Epoch: 65 [0/54000 (0%)] Loss: -1158.444092\n",
      "Train Epoch: 65 [32768/54000 (61%)] Loss: -1162.178955\n",
      "    epoch          : 65\n",
      "    loss           : -1158.7279628537735\n",
      "    ess            : 3.815824270248413\n",
      "    log_marginal   : 1158.8037915499706\n",
      "    val_loss       : -1155.7826538085938\n",
      "    val_ess        : 3.820655624071757\n",
      "    val_log_marginal: 1155.8568522135417\n",
      "Train Epoch: 66 [0/54000 (0%)] Loss: -1160.909424\n",
      "Train Epoch: 66 [32768/54000 (61%)] Loss: -1160.666260\n",
      "    epoch          : 66\n",
      "    loss           : -1161.8214065263855\n",
      "    ess            : 3.818458062297893\n",
      "    log_marginal   : 1161.8975093049823\n",
      "    val_loss       : -1158.6132202148438\n",
      "    val_ess        : 3.8215978542963662\n",
      "    val_log_marginal: 1158.682637532552\n",
      "Train Epoch: 67 [0/54000 (0%)] Loss: -1163.414062\n",
      "Train Epoch: 67 [32768/54000 (61%)] Loss: -1163.448975\n",
      "    epoch          : 67\n",
      "    loss           : -1161.3990777933373\n",
      "    ess            : 3.811966446210753\n",
      "    log_marginal   : 1161.4758807488208\n",
      "    val_loss       : -1162.7479451497395\n",
      "    val_ess        : 3.8130600452423096\n",
      "    val_log_marginal: 1162.8255004882812\n",
      "Train Epoch: 68 [0/54000 (0%)] Loss: -1165.312500\n",
      "Train Epoch: 68 [32768/54000 (61%)] Loss: -1164.337891\n",
      "    epoch          : 68\n",
      "    loss           : -1164.4908769715507\n",
      "    ess            : 3.813149929046631\n",
      "    log_marginal   : 1164.56878086306\n",
      "    val_loss       : -1163.669677734375\n",
      "    val_ess        : 3.8107041915257773\n",
      "    val_log_marginal: 1163.746358235677\n",
      "Train Epoch: 69 [0/54000 (0%)] Loss: -1166.512573\n",
      "Train Epoch: 69 [32768/54000 (61%)] Loss: -1168.056519\n",
      "    epoch          : 69\n",
      "    loss           : -1166.0056405697228\n",
      "    ess            : 3.813604957652542\n",
      "    log_marginal   : 1166.082415886645\n",
      "    val_loss       : -1161.597391764323\n",
      "    val_ess        : 3.8071199655532837\n",
      "    val_log_marginal: 1161.6760864257812\n",
      "Train Epoch: 70 [0/54000 (0%)] Loss: -1164.785400\n",
      "Train Epoch: 70 [32768/54000 (61%)] Loss: -1160.609741\n",
      "    epoch          : 70\n",
      "    loss           : -1163.786844505454\n",
      "    ess            : 3.811330642340318\n",
      "    log_marginal   : 1163.8649648990272\n",
      "    val_loss       : -1165.6689046223958\n",
      "    val_ess        : 3.813725709915161\n",
      "    val_log_marginal: 1165.7466430664062\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch70.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 71 [0/54000 (0%)] Loss: -1167.965576\n",
      "Train Epoch: 71 [32768/54000 (61%)] Loss: -1166.005127\n",
      "    epoch          : 71\n",
      "    loss           : -1165.5954359522407\n",
      "    ess            : 3.8097717447100945\n",
      "    log_marginal   : 1165.6746987396816\n",
      "    val_loss       : -1162.9600219726562\n",
      "    val_ess        : 3.8164615631103516\n",
      "    val_log_marginal: 1163.040506998698\n",
      "Train Epoch: 72 [0/54000 (0%)] Loss: -1165.897461\n",
      "Train Epoch: 72 [32768/54000 (61%)] Loss: -1170.772461\n",
      "    epoch          : 72\n",
      "    loss           : -1168.7846771816037\n",
      "    ess            : 3.8108000035555856\n",
      "    log_marginal   : 1168.863707344487\n",
      "    val_loss       : -1166.5708618164062\n",
      "    val_ess        : 3.803871472676595\n",
      "    val_log_marginal: 1166.6537068684895\n",
      "Train Epoch: 73 [0/54000 (0%)] Loss: -1168.957520\n",
      "Train Epoch: 73 [32768/54000 (61%)] Loss: -1170.609863\n",
      "    epoch          : 73\n",
      "    loss           : -1168.2042075103184\n",
      "    ess            : 3.805237149292568\n",
      "    log_marginal   : 1168.2858564268868\n",
      "    val_loss       : -1169.781717936198\n",
      "    val_ess        : 3.8165262937545776\n",
      "    val_log_marginal: 1169.8552856445312\n",
      "Train Epoch: 74 [0/54000 (0%)] Loss: -1173.440674\n",
      "Train Epoch: 74 [32768/54000 (61%)] Loss: -1175.879150\n",
      "    epoch          : 74\n",
      "    loss           : -1171.1766242261203\n",
      "    ess            : 3.8026297497299484\n",
      "    log_marginal   : 1171.2597541089328\n",
      "    val_loss       : -1171.1570841471355\n",
      "    val_ess        : 3.795830567677816\n",
      "    val_log_marginal: 1171.2461751302083\n",
      "Train Epoch: 75 [0/54000 (0%)] Loss: -1175.654541\n",
      "Train Epoch: 75 [32768/54000 (61%)] Loss: -1170.657715\n",
      "    epoch          : 75\n",
      "    loss           : -1173.0766532466096\n",
      "    ess            : 3.8041889892434173\n",
      "    log_marginal   : 1173.158997733638\n",
      "    val_loss       : -1169.1997680664062\n",
      "    val_ess        : 3.8026602268218994\n",
      "    val_log_marginal: 1169.282735188802\n",
      "Train Epoch: 76 [0/54000 (0%)] Loss: -1174.602173\n",
      "Train Epoch: 76 [32768/54000 (61%)] Loss: -1172.932007\n",
      "    epoch          : 76\n",
      "    loss           : -1170.2681147737323\n",
      "    ess            : 3.8032195972946456\n",
      "    log_marginal   : 1170.350689582105\n",
      "    val_loss       : -1172.257100423177\n",
      "    val_ess        : 3.8142665227254233\n",
      "    val_log_marginal: 1172.3330891927083\n",
      "Train Epoch: 77 [0/54000 (0%)] Loss: -1176.242676\n",
      "Train Epoch: 77 [32768/54000 (61%)] Loss: -1171.647705\n",
      "    epoch          : 77\n",
      "    loss           : -1172.3605220002948\n",
      "    ess            : 3.799477424261705\n",
      "    log_marginal   : 1172.4453838996167\n",
      "    val_loss       : -1169.9482014973958\n",
      "    val_ess        : 3.8010816176732383\n",
      "    val_log_marginal: 1170.0291137695312\n",
      "Train Epoch: 78 [0/54000 (0%)] Loss: -1172.784790\n",
      "Train Epoch: 78 [32768/54000 (61%)] Loss: -1175.678589\n",
      "    epoch          : 78\n",
      "    loss           : -1175.4607302107902\n",
      "    ess            : 3.800213058039827\n",
      "    log_marginal   : 1175.5470062831662\n",
      "    val_loss       : -1174.1454060872395\n",
      "    val_ess        : 3.7941495974858603\n",
      "    val_log_marginal: 1174.2344156901042\n",
      "Train Epoch: 79 [0/54000 (0%)] Loss: -1176.630981\n",
      "Train Epoch: 79 [32768/54000 (61%)] Loss: -1173.040405\n",
      "    epoch          : 79\n",
      "    loss           : -1174.6421773658608\n",
      "    ess            : 3.7999143105632855\n",
      "    log_marginal   : 1174.727654223172\n",
      "    val_loss       : -1175.5098876953125\n",
      "    val_ess        : 3.8065104881922402\n",
      "    val_log_marginal: 1175.5923258463542\n",
      "Train Epoch: 80 [0/54000 (0%)] Loss: -1178.496094\n",
      "Train Epoch: 80 [32768/54000 (61%)] Loss: -1174.737915\n",
      "    epoch          : 80\n",
      "    loss           : -1177.8346039394162\n",
      "    ess            : 3.797633652417165\n",
      "    log_marginal   : 1177.9212139777417\n",
      "    val_loss       : -1177.467549641927\n",
      "    val_ess        : 3.796842018763224\n",
      "    val_log_marginal: 1177.5557657877605\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch80.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 81 [0/54000 (0%)] Loss: -1177.305298\n",
      "Train Epoch: 81 [32768/54000 (61%)] Loss: -1178.560303\n",
      "    epoch          : 81\n",
      "    loss           : -1179.5733227999706\n",
      "    ess            : 3.7963971012043505\n",
      "    log_marginal   : 1179.660759691922\n",
      "    val_loss       : -1176.9143880208333\n",
      "    val_ess        : 3.7754072348276773\n",
      "    val_log_marginal: 1177.0103556315105\n",
      "Train Epoch: 82 [0/54000 (0%)] Loss: -1180.131836\n",
      "Train Epoch: 82 [32768/54000 (61%)] Loss: -1178.678955\n",
      "    epoch          : 82\n",
      "    loss           : -1176.7072661777713\n",
      "    ess            : 3.791488476519315\n",
      "    log_marginal   : 1176.7966584979363\n",
      "    val_loss       : -1177.5228881835938\n",
      "    val_ess        : 3.789240002632141\n",
      "    val_log_marginal: 1177.614522298177\n",
      "Train Epoch: 83 [0/54000 (0%)] Loss: -1180.414307\n",
      "Train Epoch: 83 [32768/54000 (61%)] Loss: -1177.453125\n",
      "    epoch          : 83\n",
      "    loss           : -1178.9909529775944\n",
      "    ess            : 3.7928043941281877\n",
      "    log_marginal   : 1179.0810615971404\n",
      "    val_loss       : -1176.56982421875\n",
      "    val_ess        : 3.784773866335551\n",
      "    val_log_marginal: 1176.6617635091145\n",
      "Train Epoch: 84 [0/54000 (0%)] Loss: -1180.450928\n",
      "Train Epoch: 84 [32768/54000 (61%)] Loss: -1182.780640\n",
      "    epoch          : 84\n",
      "    loss           : -1181.7140261092277\n",
      "    ess            : 3.7905991257361644\n",
      "    log_marginal   : 1181.8051665683963\n",
      "    val_loss       : -1181.527608235677\n",
      "    val_ess        : 3.7822767893473306\n",
      "    val_log_marginal: 1181.624287923177\n",
      "Train Epoch: 85 [0/54000 (0%)] Loss: -1184.833496\n",
      "Train Epoch: 85 [32768/54000 (61%)] Loss: -1183.072510\n",
      "    epoch          : 85\n",
      "    loss           : -1180.7017868329895\n",
      "    ess            : 3.7880413757180267\n",
      "    log_marginal   : 1180.7954470076652\n",
      "    val_loss       : -1181.4112548828125\n",
      "    val_ess        : 3.7904183069864907\n",
      "    val_log_marginal: 1181.5026245117188\n",
      "Train Epoch: 86 [0/54000 (0%)] Loss: -1180.930664\n",
      "Train Epoch: 86 [32768/54000 (61%)] Loss: -1186.319580\n",
      "    epoch          : 86\n",
      "    loss           : -1183.9868463480248\n",
      "    ess            : 3.7890600393403253\n",
      "    log_marginal   : 1184.0797533719044\n",
      "    val_loss       : -1184.2399495442708\n",
      "    val_ess        : 3.7850507895151773\n",
      "    val_log_marginal: 1184.3302408854167\n",
      "Train Epoch: 87 [0/54000 (0%)] Loss: -1182.302612\n",
      "Train Epoch: 87 [32768/54000 (61%)] Loss: -1186.791016\n",
      "    epoch          : 87\n",
      "    loss           : -1185.8022645194576\n",
      "    ess            : 3.784954107032632\n",
      "    log_marginal   : 1185.8959615455483\n",
      "    val_loss       : -1183.805419921875\n",
      "    val_ess        : 3.7867660919825235\n",
      "    val_log_marginal: 1183.8951009114583\n",
      "Train Epoch: 88 [0/54000 (0%)] Loss: -1187.363159\n",
      "Train Epoch: 88 [32768/54000 (61%)] Loss: -1182.850220\n",
      "    epoch          : 88\n",
      "    loss           : -1182.8140408497936\n",
      "    ess            : 3.7840322323565214\n",
      "    log_marginal   : 1182.9103704488502\n",
      "    val_loss       : -1183.2837524414062\n",
      "    val_ess        : 3.7965094248453775\n",
      "    val_log_marginal: 1183.3692830403645\n",
      "Train Epoch: 89 [0/54000 (0%)] Loss: -1188.914307\n",
      "Train Epoch: 89 [32768/54000 (61%)] Loss: -1184.212036\n",
      "    epoch          : 89\n",
      "    loss           : -1185.3417531139446\n",
      "    ess            : 3.7815843528171755\n",
      "    log_marginal   : 1185.4386907613502\n",
      "    val_loss       : -1183.854960123698\n",
      "    val_ess        : 3.797299941380819\n",
      "    val_log_marginal: 1183.9432576497395\n",
      "Train Epoch: 90 [0/54000 (0%)] Loss: -1187.539185\n",
      "Train Epoch: 90 [32768/54000 (61%)] Loss: -1188.057373\n",
      "    epoch          : 90\n",
      "    loss           : -1187.4741579451652\n",
      "    ess            : 3.779624003284382\n",
      "    log_marginal   : 1187.570489847435\n",
      "    val_loss       : -1188.993876139323\n",
      "    val_ess        : 3.767709414164225\n",
      "    val_log_marginal: 1189.099141438802\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch90.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 91 [0/54000 (0%)] Loss: -1189.788330\n",
      "Train Epoch: 91 [32768/54000 (61%)] Loss: -1182.357544\n",
      "    epoch          : 91\n",
      "    loss           : -1186.563315337559\n",
      "    ess            : 3.7799013380734428\n",
      "    log_marginal   : 1186.6623304834907\n",
      "    val_loss       : -1185.963134765625\n",
      "    val_ess        : 3.7784218390782676\n",
      "    val_log_marginal: 1186.0653483072917\n",
      "Train Epoch: 92 [0/54000 (0%)] Loss: -1187.945435\n",
      "Train Epoch: 92 [32768/54000 (61%)] Loss: -1188.484253\n",
      "    epoch          : 92\n",
      "    loss           : -1189.5484158497936\n",
      "    ess            : 3.7820237447630682\n",
      "    log_marginal   : 1189.6472697707843\n",
      "    val_loss       : -1189.7418823242188\n",
      "    val_ess        : 3.767273187637329\n",
      "    val_log_marginal: 1189.8526611328125\n",
      "Train Epoch: 93 [0/54000 (0%)] Loss: -1196.878662\n",
      "Train Epoch: 93 [32768/54000 (61%)] Loss: -1189.736084\n",
      "    epoch          : 93\n",
      "    loss           : -1191.5448573850235\n",
      "    ess            : 3.777593819600231\n",
      "    log_marginal   : 1191.6451830594044\n",
      "    val_loss       : -1190.7175903320312\n",
      "    val_ess        : 3.774238109588623\n",
      "    val_log_marginal: 1190.8194783528645\n",
      "Train Epoch: 94 [0/54000 (0%)] Loss: -1193.265381\n",
      "Train Epoch: 94 [32768/54000 (61%)] Loss: -1188.607056\n",
      "    epoch          : 94\n",
      "    loss           : -1188.6320294074292\n",
      "    ess            : 3.777866192583768\n",
      "    log_marginal   : 1188.731196565448\n",
      "    val_loss       : -1187.402079264323\n",
      "    val_ess        : 3.7669435342152915\n",
      "    val_log_marginal: 1187.507568359375\n",
      "Train Epoch: 95 [0/54000 (0%)] Loss: -1189.702393\n",
      "Train Epoch: 95 [32768/54000 (61%)] Loss: -1191.450684\n",
      "    epoch          : 95\n",
      "    loss           : -1191.2080884249706\n",
      "    ess            : 3.780128834382543\n",
      "    log_marginal   : 1191.3058345002948\n",
      "    val_loss       : -1190.3194783528645\n",
      "    val_ess        : 3.788330356280009\n",
      "    val_log_marginal: 1190.411844889323\n",
      "Train Epoch: 96 [0/54000 (0%)] Loss: -1192.415283\n",
      "Train Epoch: 96 [32768/54000 (61%)] Loss: -1193.652588\n",
      "    epoch          : 96\n",
      "    loss           : -1193.058490105395\n",
      "    ess            : 3.777097850475671\n",
      "    log_marginal   : 1193.1606813826652\n",
      "    val_loss       : -1195.3372192382812\n",
      "    val_ess        : 3.7785838842391968\n",
      "    val_log_marginal: 1195.4349568684895\n",
      "Train Epoch: 97 [0/54000 (0%)] Loss: -1199.562256\n",
      "Train Epoch: 97 [32768/54000 (61%)] Loss: -1185.088867\n",
      "    epoch          : 97\n",
      "    loss           : -1192.3828585642689\n",
      "    ess            : 3.7735759987021393\n",
      "    log_marginal   : 1192.486443285672\n",
      "    val_loss       : -1190.0194498697917\n",
      "    val_ess        : 3.7773424784342446\n",
      "    val_log_marginal: 1190.1205037434895\n",
      "Train Epoch: 98 [0/54000 (0%)] Loss: -1193.786743\n",
      "Train Epoch: 98 [32768/54000 (61%)] Loss: -1193.580322\n",
      "    epoch          : 98\n",
      "    loss           : -1194.6395563089623\n",
      "    ess            : 3.77649846616781\n",
      "    log_marginal   : 1194.7394996499115\n",
      "    val_loss       : -1194.4973958333333\n",
      "    val_ess        : 3.7682402531305947\n",
      "    val_log_marginal: 1194.603535970052\n",
      "Train Epoch: 99 [0/54000 (0%)] Loss: -1198.838989\n",
      "Train Epoch: 99 [32768/54000 (61%)] Loss: -1197.338501\n",
      "    epoch          : 99\n",
      "    loss           : -1197.1358895931603\n",
      "    ess            : 3.771678384744896\n",
      "    log_marginal   : 1197.2402850456958\n",
      "    val_loss       : -1196.8640747070312\n",
      "    val_ess        : 3.769489566485087\n",
      "    val_log_marginal: 1196.9650065104167\n",
      "Train Epoch: 100 [0/54000 (0%)] Loss: -1199.601807\n",
      "Train Epoch: 100 [32768/54000 (61%)] Loss: -1194.671631\n",
      "    epoch          : 100\n",
      "    loss           : -1194.9890390072228\n",
      "    ess            : 3.772829537121755\n",
      "    log_marginal   : 1195.0925362065154\n",
      "    val_loss       : -1191.1465861002605\n",
      "    val_ess        : 3.7763357162475586\n",
      "    val_log_marginal: 1191.2455037434895\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [0/54000 (0%)] Loss: -1191.749268\n",
      "Train Epoch: 101 [32768/54000 (61%)] Loss: -1195.305664\n",
      "    epoch          : 101\n",
      "    loss           : -1196.168841667895\n",
      "    ess            : 3.7689648799176485\n",
      "    log_marginal   : 1196.2743058114681\n",
      "    val_loss       : -1196.6966756184895\n",
      "    val_ess        : 3.774066686630249\n",
      "    val_log_marginal: 1196.802754720052\n",
      "Train Epoch: 102 [0/54000 (0%)] Loss: -1197.467529\n",
      "Train Epoch: 102 [32768/54000 (61%)] Loss: -1195.644531\n",
      "    epoch          : 102\n",
      "    loss           : -1197.658571639151\n",
      "    ess            : 3.7682714822157375\n",
      "    log_marginal   : 1197.7643282908314\n",
      "    val_loss       : -1198.9996134440105\n",
      "    val_ess        : 3.7638763984044394\n",
      "    val_log_marginal: 1199.1083374023438\n",
      "Train Epoch: 103 [0/54000 (0%)] Loss: -1201.000854\n",
      "Train Epoch: 103 [32768/54000 (61%)] Loss: -1197.807373\n",
      "    epoch          : 103\n",
      "    loss           : -1198.7993808962265\n",
      "    ess            : 3.7683201870828307\n",
      "    log_marginal   : 1198.9053747788914\n",
      "    val_loss       : -1193.650858561198\n",
      "    val_ess        : 3.757538596789042\n",
      "    val_log_marginal: 1193.76220703125\n",
      "Train Epoch: 104 [0/54000 (0%)] Loss: -1195.805664\n",
      "Train Epoch: 104 [32768/54000 (61%)] Loss: -1198.310059\n",
      "    epoch          : 104\n",
      "    loss           : -1198.5359992261203\n",
      "    ess            : 3.769069194793701\n",
      "    log_marginal   : 1198.6449135834316\n",
      "    val_loss       : -1199.5855712890625\n",
      "    val_ess        : 3.7741915384928384\n",
      "    val_log_marginal: 1199.6931966145833\n",
      "Train Epoch: 105 [0/54000 (0%)] Loss: -1198.232178\n",
      "Train Epoch: 105 [32768/54000 (61%)] Loss: -1205.449707\n",
      "    epoch          : 105\n",
      "    loss           : -1201.299982034935\n",
      "    ess            : 3.7626817136440636\n",
      "    log_marginal   : 1201.4111765735554\n",
      "    val_loss       : -1201.720682779948\n",
      "    val_ess        : 3.7755391597747803\n",
      "    val_log_marginal: 1201.8225708007812\n",
      "Train Epoch: 106 [0/54000 (0%)] Loss: -1202.949097\n",
      "Train Epoch: 106 [32768/54000 (61%)] Loss: -1202.807739\n",
      "    epoch          : 106\n",
      "    loss           : -1202.1213701356132\n",
      "    ess            : 3.7678595174033687\n",
      "    log_marginal   : 1202.2304318985848\n",
      "    val_loss       : -1197.3843383789062\n",
      "    val_ess        : 3.776423374811808\n",
      "    val_log_marginal: 1197.4840291341145\n",
      "Train Epoch: 107 [0/54000 (0%)] Loss: -1203.348267\n",
      "Train Epoch: 107 [32768/54000 (61%)] Loss: -1195.582886\n",
      "    epoch          : 107\n",
      "    loss           : -1199.649840156987\n",
      "    ess            : 3.7709321480876996\n",
      "    log_marginal   : 1199.7560966059846\n",
      "    val_loss       : -1200.5669555664062\n",
      "    val_ess        : 3.762308120727539\n",
      "    val_log_marginal: 1200.6822306315105\n",
      "Train Epoch: 108 [0/54000 (0%)] Loss: -1199.637085\n",
      "Train Epoch: 108 [32768/54000 (61%)] Loss: -1202.046875\n",
      "    epoch          : 108\n",
      "    loss           : -1202.1795700361145\n",
      "    ess            : 3.764497995376587\n",
      "    log_marginal   : 1202.2897695865272\n",
      "    val_loss       : -1201.2057698567708\n",
      "    val_ess        : 3.767847259839376\n",
      "    val_log_marginal: 1201.3131713867188\n",
      "Train Epoch: 109 [0/54000 (0%)] Loss: -1205.182495\n",
      "Train Epoch: 109 [32768/54000 (61%)] Loss: -1205.401123\n",
      "    epoch          : 109\n",
      "    loss           : -1204.8061016730542\n",
      "    ess            : 3.7674942511432574\n",
      "    log_marginal   : 1204.9170797096108\n",
      "    val_loss       : -1202.818359375\n",
      "    val_ess        : 3.76918359597524\n",
      "    val_log_marginal: 1202.9243774414062\n",
      "Train Epoch: 110 [0/54000 (0%)] Loss: -1204.228027\n",
      "Train Epoch: 110 [32768/54000 (61%)] Loss: -1201.108032\n",
      "    epoch          : 110\n",
      "    loss           : -1203.0018540868218\n",
      "    ess            : 3.768142583235255\n",
      "    log_marginal   : 1203.1111645968456\n",
      "    val_loss       : -1203.6283772786458\n",
      "    val_ess        : 3.768737475077311\n",
      "    val_log_marginal: 1203.7337036132812\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch110.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 111 [0/54000 (0%)] Loss: -1205.866455\n",
      "Train Epoch: 111 [32768/54000 (61%)] Loss: -1208.216064\n",
      "    epoch          : 111\n",
      "    loss           : -1205.812739534198\n",
      "    ess            : 3.762723540360073\n",
      "    log_marginal   : 1205.9254150390625\n",
      "    val_loss       : -1205.8689575195312\n",
      "    val_ess        : 3.7722453673680625\n",
      "    val_log_marginal: 1205.9798583984375\n",
      "Train Epoch: 112 [0/54000 (0%)] Loss: -1208.389038\n",
      "Train Epoch: 112 [32768/54000 (61%)] Loss: -1206.463013\n",
      "    epoch          : 112\n",
      "    loss           : -1207.6968948076355\n",
      "    ess            : 3.762512854810031\n",
      "    log_marginal   : 1207.8091810694282\n",
      "    val_loss       : -1205.9154459635417\n",
      "    val_ess        : 3.7610892057418823\n",
      "    val_log_marginal: 1206.0238240559895\n",
      "Train Epoch: 113 [0/54000 (0%)] Loss: -1206.516113\n",
      "Train Epoch: 113 [32768/54000 (61%)] Loss: -1203.757812\n",
      "    epoch          : 113\n",
      "    loss           : -1204.8563324550412\n",
      "    ess            : 3.7640208748151673\n",
      "    log_marginal   : 1204.9681926223468\n",
      "    val_loss       : -1203.9873860677083\n",
      "    val_ess        : 3.7685718536376953\n",
      "    val_log_marginal: 1204.0919799804688\n",
      "Train Epoch: 114 [0/54000 (0%)] Loss: -1209.690430\n",
      "Train Epoch: 114 [32768/54000 (61%)] Loss: -1209.907959\n",
      "    epoch          : 114\n",
      "    loss           : -1207.4666471661262\n",
      "    ess            : 3.7669374357979253\n",
      "    log_marginal   : 1207.5755569170105\n",
      "    val_loss       : -1207.0142211914062\n",
      "    val_ess        : 3.774555246035258\n",
      "    val_log_marginal: 1207.1177368164062\n",
      "Train Epoch: 115 [0/54000 (0%)] Loss: -1213.849243\n",
      "Train Epoch: 115 [32768/54000 (61%)] Loss: -1207.559082\n",
      "    epoch          : 115\n",
      "    loss           : -1209.544901146079\n",
      "    ess            : 3.759847820929761\n",
      "    log_marginal   : 1209.659403099204\n",
      "    val_loss       : -1210.038818359375\n",
      "    val_ess        : 3.760176142056783\n",
      "    val_log_marginal: 1210.155497233073\n",
      "Train Epoch: 116 [0/54000 (0%)] Loss: -1211.463135\n",
      "Train Epoch: 116 [32768/54000 (61%)] Loss: -1206.158813\n",
      "    epoch          : 116\n",
      "    loss           : -1207.606143591539\n",
      "    ess            : 3.7642237330382726\n",
      "    log_marginal   : 1207.718059035967\n",
      "    val_loss       : -1205.4069417317708\n",
      "    val_ess        : 3.758871912956238\n",
      "    val_log_marginal: 1205.5179443359375\n",
      "Train Epoch: 117 [0/54000 (0%)] Loss: -1205.940918\n",
      "Train Epoch: 117 [32768/54000 (61%)] Loss: -1215.281738\n",
      "    epoch          : 117\n",
      "    loss           : -1209.7562463148586\n",
      "    ess            : 3.7620168991808622\n",
      "    log_marginal   : 1209.868548699145\n",
      "    val_loss       : -1209.7568766276042\n",
      "    val_ess        : 3.757649381955465\n",
      "    val_log_marginal: 1209.873026529948\n",
      "Train Epoch: 118 [0/54000 (0%)] Loss: -1212.246704\n",
      "Train Epoch: 118 [32768/54000 (61%)] Loss: -1210.828735\n",
      "    epoch          : 118\n",
      "    loss           : -1212.0473471587559\n",
      "    ess            : 3.7598849557480722\n",
      "    log_marginal   : 1212.1618790536556\n",
      "    val_loss       : -1212.6367797851562\n",
      "    val_ess        : 3.7707488536834717\n",
      "    val_log_marginal: 1212.7439982096355\n",
      "Train Epoch: 119 [0/54000 (0%)] Loss: -1216.551636\n",
      "Train Epoch: 119 [32768/54000 (61%)] Loss: -1210.444336\n",
      "    epoch          : 119\n",
      "    loss           : -1210.0697113612912\n",
      "    ess            : 3.7619361022733293\n",
      "    log_marginal   : 1210.182414504717\n",
      "    val_loss       : -1206.0955810546875\n",
      "    val_ess        : 3.7740326722462973\n",
      "    val_log_marginal: 1206.2021077473958\n",
      "Train Epoch: 120 [0/54000 (0%)] Loss: -1206.154053\n",
      "Train Epoch: 120 [32768/54000 (61%)] Loss: -1211.659058\n",
      "    epoch          : 120\n",
      "    loss           : -1210.7045437794811\n",
      "    ess            : 3.75987324174845\n",
      "    log_marginal   : 1210.8176983527417\n",
      "    val_loss       : -1211.6788126627605\n",
      "    val_ess        : 3.772066275278727\n",
      "    val_log_marginal: 1211.7924194335938\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch120.pth ...\n",
      "Train Epoch: 121 [0/54000 (0%)] Loss: -1214.860840\n",
      "Train Epoch: 121 [32768/54000 (61%)] Loss: -1212.771484\n",
      "    epoch          : 121\n",
      "    loss           : -1212.7222531876473\n",
      "    ess            : 3.7597659488893904\n",
      "    log_marginal   : 1212.8379067474941\n",
      "    val_loss       : -1213.7376098632812\n",
      "    val_ess        : 3.7659664154052734\n",
      "    val_log_marginal: 1213.8449300130208\n",
      "Train Epoch: 122 [0/54000 (0%)] Loss: -1219.714355\n",
      "Train Epoch: 122 [32768/54000 (61%)] Loss: -1212.511108\n",
      "    epoch          : 122\n",
      "    loss           : -1213.6225862323113\n",
      "    ess            : 3.760308468116904\n",
      "    log_marginal   : 1213.7370259986733\n",
      "    val_loss       : -1208.8861694335938\n",
      "    val_ess        : 3.7627071142196655\n",
      "    val_log_marginal: 1208.997782389323\n",
      "Train Epoch: 123 [0/54000 (0%)] Loss: -1212.602295\n",
      "Train Epoch: 123 [32768/54000 (61%)] Loss: -1214.841553\n",
      "    epoch          : 123\n",
      "    loss           : -1212.3043581404777\n",
      "    ess            : 3.762753815021155\n",
      "    log_marginal   : 1212.4170244324882\n",
      "    val_loss       : -1213.5767822265625\n",
      "    val_ess        : 3.767238656679789\n",
      "    val_log_marginal: 1213.676534016927\n",
      "Train Epoch: 124 [0/54000 (0%)] Loss: -1216.870239\n",
      "Train Epoch: 124 [32768/54000 (61%)] Loss: -1213.417603\n",
      "    epoch          : 124\n",
      "    loss           : -1215.1011294958726\n",
      "    ess            : 3.7611137291170516\n",
      "    log_marginal   : 1215.216594192217\n",
      "    val_loss       : -1215.3280639648438\n",
      "    val_ess        : 3.75467848777771\n",
      "    val_log_marginal: 1215.4469401041667\n",
      "Train Epoch: 125 [0/54000 (0%)] Loss: -1220.233887\n",
      "Train Epoch: 125 [32768/54000 (61%)] Loss: -1217.695068\n",
      "    epoch          : 125\n",
      "    loss           : -1216.5386801665684\n",
      "    ess            : 3.756976658443235\n",
      "    log_marginal   : 1216.6528827019458\n",
      "    val_loss       : -1213.2371215820312\n",
      "    val_ess        : 3.7468350330988565\n",
      "    val_log_marginal: 1213.35888671875\n",
      "Train Epoch: 126 [0/54000 (0%)] Loss: -1213.504517\n",
      "Train Epoch: 126 [32768/54000 (61%)] Loss: -1213.124756\n",
      "    epoch          : 126\n",
      "    loss           : -1213.8171847361439\n",
      "    ess            : 3.764021059252181\n",
      "    log_marginal   : 1213.92962070681\n",
      "    val_loss       : -1214.3429158528645\n",
      "    val_ess        : 3.7553583780924478\n",
      "    val_log_marginal: 1214.4603271484375\n",
      "Train Epoch: 127 [0/54000 (0%)] Loss: -1217.031006\n",
      "Train Epoch: 127 [32768/54000 (61%)] Loss: -1217.567871\n",
      "    epoch          : 127\n",
      "    loss           : -1216.578534971993\n",
      "    ess            : 3.759748841231724\n",
      "    log_marginal   : 1216.6932994914505\n",
      "    val_loss       : -1216.2625325520833\n",
      "    val_ess        : 3.756391167640686\n",
      "    val_log_marginal: 1216.3770955403645\n",
      "Train Epoch: 128 [0/54000 (0%)] Loss: -1221.192261\n",
      "Train Epoch: 128 [32768/54000 (61%)] Loss: -1218.151611\n",
      "    epoch          : 128\n",
      "    loss           : -1218.762580151828\n",
      "    ess            : 3.761972332900425\n",
      "    log_marginal   : 1218.876651404039\n",
      "    val_loss       : -1217.9730428059895\n",
      "    val_ess        : 3.7561106284459433\n",
      "    val_log_marginal: 1218.089823404948\n",
      "Train Epoch: 129 [0/54000 (0%)] Loss: -1218.836670\n",
      "Train Epoch: 129 [32768/54000 (61%)] Loss: -1214.769531\n",
      "    epoch          : 129\n",
      "    loss           : -1216.308651330336\n",
      "    ess            : 3.7641695310484686\n",
      "    log_marginal   : 1216.4215847951061\n",
      "    val_loss       : -1215.5963541666667\n",
      "    val_ess        : 3.7465219100316367\n",
      "    val_log_marginal: 1215.7172444661458\n",
      "Train Epoch: 130 [0/54000 (0%)] Loss: -1219.026367\n",
      "Train Epoch: 130 [32768/54000 (61%)] Loss: -1222.568115\n",
      "    epoch          : 130\n",
      "    loss           : -1218.8695759323407\n",
      "    ess            : 3.7612392587481804\n",
      "    log_marginal   : 1218.9828963369694\n",
      "    val_loss       : -1218.937235514323\n",
      "    val_ess        : 3.769475976626078\n",
      "    val_log_marginal: 1219.0414428710938\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch130.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 131 [0/54000 (0%)] Loss: -1223.629883\n",
      "Train Epoch: 131 [32768/54000 (61%)] Loss: -1221.747437\n",
      "    epoch          : 131\n",
      "    loss           : -1221.1814425486439\n",
      "    ess            : 3.7635718696522265\n",
      "    log_marginal   : 1221.2942032724056\n",
      "    val_loss       : -1220.8768107096355\n",
      "    val_ess        : 3.7624199787775674\n",
      "    val_log_marginal: 1220.9918212890625\n",
      "Train Epoch: 132 [0/54000 (0%)] Loss: -1225.827148\n",
      "Train Epoch: 132 [32768/54000 (61%)] Loss: -1218.895630\n",
      "    epoch          : 132\n",
      "    loss           : -1218.5980754348468\n",
      "    ess            : 3.7591081475311854\n",
      "    log_marginal   : 1218.7126234522407\n",
      "    val_loss       : -1216.1802571614583\n",
      "    val_ess        : 3.75612203280131\n",
      "    val_log_marginal: 1216.2951253255208\n",
      "Train Epoch: 133 [0/54000 (0%)] Loss: -1218.040039\n",
      "Train Epoch: 133 [32768/54000 (61%)] Loss: -1224.507690\n",
      "    epoch          : 133\n",
      "    loss           : -1220.3269227225826\n",
      "    ess            : 3.760487781380707\n",
      "    log_marginal   : 1220.4406461895637\n",
      "    val_loss       : -1220.7578735351562\n",
      "    val_ess        : 3.7605470418930054\n",
      "    val_log_marginal: 1220.8673299153645\n",
      "Train Epoch: 134 [0/54000 (0%)] Loss: -1219.780273\n",
      "Train Epoch: 134 [32768/54000 (61%)] Loss: -1220.520386\n",
      "    epoch          : 134\n",
      "    loss           : -1222.5674634249706\n",
      "    ess            : 3.7557162383817277\n",
      "    log_marginal   : 1222.6837734006485\n",
      "    val_loss       : -1223.279052734375\n",
      "    val_ess        : 3.7546101808547974\n",
      "    val_log_marginal: 1223.3907470703125\n",
      "Train Epoch: 135 [0/54000 (0%)] Loss: -1228.371826\n",
      "Train Epoch: 135 [32768/54000 (61%)] Loss: -1219.069336\n",
      "    epoch          : 135\n",
      "    loss           : -1221.4380688937206\n",
      "    ess            : 3.755411737370041\n",
      "    log_marginal   : 1221.555829893868\n",
      "    val_loss       : -1217.480936686198\n",
      "    val_ess        : 3.7692736784617105\n",
      "    val_log_marginal: 1217.5919392903645\n",
      "Train Epoch: 136 [0/54000 (0%)] Loss: -1223.632202\n",
      "Train Epoch: 136 [32768/54000 (61%)] Loss: -1218.079834\n",
      "    epoch          : 136\n",
      "    loss           : -1221.54087512898\n",
      "    ess            : 3.7574460776347034\n",
      "    log_marginal   : 1221.6600871535968\n",
      "    val_loss       : -1222.4660237630208\n",
      "    val_ess        : 3.7594537337621055\n",
      "    val_log_marginal: 1222.5789591471355\n",
      "Train Epoch: 137 [0/54000 (0%)] Loss: -1226.281006\n",
      "Train Epoch: 137 [32768/54000 (61%)] Loss: -1223.224854\n",
      "    epoch          : 137\n",
      "    loss           : -1223.902219376474\n",
      "    ess            : 3.758627432697224\n",
      "    log_marginal   : 1224.0178982716686\n",
      "    val_loss       : -1224.8624877929688\n",
      "    val_ess        : 3.753419836362203\n",
      "    val_log_marginal: 1224.9783935546875\n",
      "Train Epoch: 138 [0/54000 (0%)] Loss: -1229.409424\n",
      "Train Epoch: 138 [32768/54000 (61%)] Loss: -1223.490356\n",
      "    epoch          : 138\n",
      "    loss           : -1224.627264058815\n",
      "    ess            : 3.7571278563085593\n",
      "    log_marginal   : 1224.7438273879718\n",
      "    val_loss       : -1220.1107991536458\n",
      "    val_ess        : 3.7587004899978638\n",
      "    val_log_marginal: 1220.229248046875\n",
      "Train Epoch: 139 [0/54000 (0%)] Loss: -1223.161133\n",
      "Train Epoch: 139 [32768/54000 (61%)] Loss: -1222.140259\n",
      "    epoch          : 139\n",
      "    loss           : -1222.7859854068397\n",
      "    ess            : 3.7556782893414766\n",
      "    log_marginal   : 1222.9040711600826\n",
      "    val_loss       : -1223.7658081054688\n",
      "    val_ess        : 3.771509369214376\n",
      "    val_log_marginal: 1223.8723754882812\n",
      "Train Epoch: 140 [0/54000 (0%)] Loss: -1226.837646\n",
      "Train Epoch: 140 [32768/54000 (61%)] Loss: -1227.020996\n",
      "    epoch          : 140\n",
      "    loss           : -1225.722089659493\n",
      "    ess            : 3.760837806845611\n",
      "    log_marginal   : 1225.835138284935\n",
      "    val_loss       : -1225.8046264648438\n",
      "    val_ess        : 3.760024309158325\n",
      "    val_log_marginal: 1225.9205322265625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch140.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 141 [0/54000 (0%)] Loss: -1228.060669\n",
      "Train Epoch: 141 [32768/54000 (61%)] Loss: -1226.559814\n",
      "    epoch          : 141\n",
      "    loss           : -1227.3090382701946\n",
      "    ess            : 3.7602497541679525\n",
      "    log_marginal   : 1227.4243924122936\n",
      "    val_loss       : -1223.938985188802\n",
      "    val_ess        : 3.758714278539022\n",
      "    val_log_marginal: 1224.0550333658855\n",
      "Train Epoch: 142 [0/54000 (0%)] Loss: -1224.846436\n",
      "Train Epoch: 142 [32768/54000 (61%)] Loss: -1227.725220\n",
      "    epoch          : 142\n",
      "    loss           : -1224.6283811173348\n",
      "    ess            : 3.7602087956554486\n",
      "    log_marginal   : 1224.7439448518573\n",
      "    val_loss       : -1224.6873982747395\n",
      "    val_ess        : 3.7556107441584268\n",
      "    val_log_marginal: 1224.808085123698\n",
      "Train Epoch: 143 [0/54000 (0%)] Loss: -1230.543701\n",
      "Train Epoch: 143 [32768/54000 (61%)] Loss: -1228.362549\n",
      "    epoch          : 143\n",
      "    loss           : -1227.4695169700767\n",
      "    ess            : 3.755370409983509\n",
      "    log_marginal   : 1227.5889593160377\n",
      "    val_loss       : -1227.1365559895833\n",
      "    val_ess        : 3.7650352716445923\n",
      "    val_log_marginal: 1227.2464396158855\n",
      "Train Epoch: 144 [0/54000 (0%)] Loss: -1229.845093\n",
      "Train Epoch: 144 [32768/54000 (61%)] Loss: -1228.905518\n",
      "    epoch          : 144\n",
      "    loss           : -1229.406618514151\n",
      "    ess            : 3.758189745669095\n",
      "    log_marginal   : 1229.5240800965507\n",
      "    val_loss       : -1228.3465169270833\n",
      "    val_ess        : 3.73762309551239\n",
      "    val_log_marginal: 1228.4735921223958\n",
      "Train Epoch: 145 [0/54000 (0%)] Loss: -1232.667480\n",
      "Train Epoch: 145 [32768/54000 (61%)] Loss: -1225.521973\n",
      "    epoch          : 145\n",
      "    loss           : -1227.0527873489093\n",
      "    ess            : 3.763577749144356\n",
      "    log_marginal   : 1227.1657576650944\n",
      "    val_loss       : -1225.8545735677083\n",
      "    val_ess        : 3.7641144593556723\n",
      "    val_log_marginal: 1225.9678344726562\n",
      "Train Epoch: 146 [0/54000 (0%)] Loss: -1229.624512\n",
      "Train Epoch: 146 [32768/54000 (61%)] Loss: -1227.176270\n",
      "    epoch          : 146\n",
      "    loss           : -1229.0125502100532\n",
      "    ess            : 3.760936584112779\n",
      "    log_marginal   : 1229.1259650464328\n",
      "    val_loss       : -1229.5576578776042\n",
      "    val_ess        : 3.7659925619761148\n",
      "    val_log_marginal: 1229.6692708333333\n",
      "Train Epoch: 147 [0/54000 (0%)] Loss: -1229.324951\n",
      "Train Epoch: 147 [32768/54000 (61%)] Loss: -1228.331543\n",
      "    epoch          : 147\n",
      "    loss           : -1231.2834173238502\n",
      "    ess            : 3.758056843055869\n",
      "    log_marginal   : 1231.3987898916569\n",
      "    val_loss       : -1231.7555338541667\n",
      "    val_ess        : 3.7704672813415527\n",
      "    val_log_marginal: 1231.8602701822917\n",
      "Train Epoch: 148 [0/54000 (0%)] Loss: -1231.371582\n",
      "Train Epoch: 148 [32768/54000 (61%)] Loss: -1229.228271\n",
      "    epoch          : 148\n",
      "    loss           : -1229.3109913951946\n",
      "    ess            : 3.7595318623308867\n",
      "    log_marginal   : 1229.4266403486145\n",
      "    val_loss       : -1226.2955729166667\n",
      "    val_ess        : 3.7577435970306396\n",
      "    val_log_marginal: 1226.4054158528645\n",
      "Train Epoch: 149 [0/54000 (0%)] Loss: -1228.353760\n",
      "Train Epoch: 149 [32768/54000 (61%)] Loss: -1230.073730\n",
      "    epoch          : 149\n",
      "    loss           : -1230.4404158682194\n",
      "    ess            : 3.7582811904403397\n",
      "    log_marginal   : 1230.559061302329\n",
      "    val_loss       : -1231.2510579427083\n",
      "    val_ess        : 3.7538568576176963\n",
      "    val_log_marginal: 1231.367431640625\n",
      "Train Epoch: 150 [0/54000 (0%)] Loss: -1234.210205\n",
      "Train Epoch: 150 [32768/54000 (61%)] Loss: -1231.021729\n",
      "    epoch          : 150\n",
      "    loss           : -1232.8816171322228\n",
      "    ess            : 3.7593364625606895\n",
      "    log_marginal   : 1232.9971923828125\n",
      "    val_loss       : -1233.6255696614583\n",
      "    val_ess        : 3.741722067197164\n",
      "    val_log_marginal: 1233.7551879882812\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch150.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 151 [0/54000 (0%)] Loss: -1239.807617\n",
      "Train Epoch: 151 [32768/54000 (61%)] Loss: -1230.980957\n",
      "    epoch          : 151\n",
      "    loss           : -1232.336061873526\n",
      "    ess            : 3.7574777783087963\n",
      "    log_marginal   : 1232.4546405144458\n",
      "    val_loss       : -1228.0134887695312\n",
      "    val_ess        : 3.753793160120646\n",
      "    val_log_marginal: 1228.1324666341145\n",
      "Train Epoch: 152 [0/54000 (0%)] Loss: -1230.948486\n",
      "Train Epoch: 152 [32768/54000 (61%)] Loss: -1230.649170\n",
      "    epoch          : 152\n",
      "    loss           : -1231.4877699366157\n",
      "    ess            : 3.7579199997883923\n",
      "    log_marginal   : 1231.6050679908608\n",
      "    val_loss       : -1232.4720255533855\n",
      "    val_ess        : 3.7562526861826577\n",
      "    val_log_marginal: 1232.5887044270833\n",
      "Train Epoch: 153 [0/54000 (0%)] Loss: -1234.799561\n",
      "Train Epoch: 153 [32768/54000 (61%)] Loss: -1233.639404\n",
      "    epoch          : 153\n",
      "    loss           : -1234.2938232421875\n",
      "    ess            : 3.7580826777332232\n",
      "    log_marginal   : 1234.4080925707547\n",
      "    val_loss       : -1235.0151774088542\n",
      "    val_ess        : 3.753836433092753\n",
      "    val_log_marginal: 1235.139912923177\n",
      "Train Epoch: 154 [0/54000 (0%)] Loss: -1236.624634\n",
      "Train Epoch: 154 [32768/54000 (61%)] Loss: -1240.240723\n",
      "    epoch          : 154\n",
      "    loss           : -1235.5107145489387\n",
      "    ess            : 3.7580799246734045\n",
      "    log_marginal   : 1235.626543153007\n",
      "    val_loss       : -1232.0780639648438\n",
      "    val_ess        : 3.7522438764572144\n",
      "    val_log_marginal: 1232.1962280273438\n",
      "Train Epoch: 155 [0/54000 (0%)] Loss: -1234.892578\n",
      "Train Epoch: 155 [32768/54000 (61%)] Loss: -1233.640747\n",
      "    epoch          : 155\n",
      "    loss           : -1233.3044525722287\n",
      "    ess            : 3.755462367579622\n",
      "    log_marginal   : 1233.422036224941\n",
      "    val_loss       : -1233.8772379557292\n",
      "    val_ess        : 3.75174073378245\n",
      "    val_log_marginal: 1233.9965006510417\n",
      "Train Epoch: 156 [0/54000 (0%)] Loss: -1236.238525\n",
      "Train Epoch: 156 [32768/54000 (61%)] Loss: -1237.893677\n",
      "    epoch          : 156\n",
      "    loss           : -1236.0743822781544\n",
      "    ess            : 3.755620686513073\n",
      "    log_marginal   : 1236.1914223724941\n",
      "    val_loss       : -1236.2818400065105\n",
      "    val_ess        : 3.7588096459706626\n",
      "    val_log_marginal: 1236.3958740234375\n",
      "Train Epoch: 157 [0/54000 (0%)] Loss: -1236.359131\n",
      "Train Epoch: 157 [32768/54000 (61%)] Loss: -1236.792114\n",
      "    epoch          : 157\n",
      "    loss           : -1237.8500078309257\n",
      "    ess            : 3.756097064827973\n",
      "    log_marginal   : 1237.966548127948\n",
      "    val_loss       : -1236.3440348307292\n",
      "    val_ess        : 3.7641095320383706\n",
      "    val_log_marginal: 1236.458719889323\n",
      "Train Epoch: 158 [0/54000 (0%)] Loss: -1239.898193\n",
      "Train Epoch: 158 [32768/54000 (61%)] Loss: -1232.795898\n",
      "    epoch          : 158\n",
      "    loss           : -1235.394754661704\n",
      "    ess            : 3.756892370727827\n",
      "    log_marginal   : 1235.5112673201652\n",
      "    val_loss       : -1234.9323120117188\n",
      "    val_ess        : 3.749708652496338\n",
      "    val_log_marginal: 1235.0604858398438\n",
      "Train Epoch: 159 [0/54000 (0%)] Loss: -1239.044189\n",
      "Train Epoch: 159 [32768/54000 (61%)] Loss: -1243.923340\n",
      "    epoch          : 159\n",
      "    loss           : -1237.8397216796875\n",
      "    ess            : 3.749191891472295\n",
      "    log_marginal   : 1237.9602995098762\n",
      "    val_loss       : -1238.6343180338542\n",
      "    val_ess        : 3.7454492251078286\n",
      "    val_log_marginal: 1238.7589518229167\n",
      "Train Epoch: 160 [0/54000 (0%)] Loss: -1239.672363\n",
      "Train Epoch: 160 [32768/54000 (61%)] Loss: -1239.544189\n",
      "    epoch          : 160\n",
      "    loss           : -1239.9936039762677\n",
      "    ess            : 3.7530551451557086\n",
      "    log_marginal   : 1240.111443285672\n",
      "    val_loss       : -1239.9776611328125\n",
      "    val_ess        : 3.758762240409851\n",
      "    val_log_marginal: 1240.0841064453125\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch160.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 161 [0/54000 (0%)] Loss: -1243.945190\n",
      "Train Epoch: 161 [32768/54000 (61%)] Loss: -1236.136597\n",
      "    epoch          : 161\n",
      "    loss           : -1237.8751911667157\n",
      "    ess            : 3.7543065952804855\n",
      "    log_marginal   : 1237.9963125552772\n",
      "    val_loss       : -1235.538818359375\n",
      "    val_ess        : 3.753484050432841\n",
      "    val_log_marginal: 1235.6588338216145\n",
      "Train Epoch: 162 [0/54000 (0%)] Loss: -1236.323120\n",
      "Train Epoch: 162 [32768/54000 (61%)] Loss: -1241.578979\n",
      "    epoch          : 162\n",
      "    loss           : -1239.1710873010024\n",
      "    ess            : 3.75073663693554\n",
      "    log_marginal   : 1239.291425596993\n",
      "    val_loss       : -1240.221211751302\n",
      "    val_ess        : 3.759496728579203\n",
      "    val_log_marginal: 1240.339335123698\n",
      "Train Epoch: 163 [0/54000 (0%)] Loss: -1241.901123\n",
      "Train Epoch: 163 [32768/54000 (61%)] Loss: -1240.820312\n",
      "    epoch          : 163\n",
      "    loss           : -1241.6991726857311\n",
      "    ess            : 3.7546217576512753\n",
      "    log_marginal   : 1241.8190319133255\n",
      "    val_loss       : -1242.5588785807292\n",
      "    val_ess        : 3.747128168741862\n",
      "    val_log_marginal: 1242.686503092448\n",
      "Train Epoch: 164 [0/54000 (0%)] Loss: -1244.817627\n",
      "Train Epoch: 164 [32768/54000 (61%)] Loss: -1240.712646\n",
      "    epoch          : 164\n",
      "    loss           : -1240.7498871425412\n",
      "    ess            : 3.751313402967633\n",
      "    log_marginal   : 1240.868772110849\n",
      "    val_loss       : -1237.5844319661458\n",
      "    val_ess        : 3.7467042207717896\n",
      "    val_log_marginal: 1237.707275390625\n",
      "Train Epoch: 165 [0/54000 (0%)] Loss: -1239.312012\n",
      "Train Epoch: 165 [32768/54000 (61%)] Loss: -1241.011108\n",
      "    epoch          : 165\n",
      "    loss           : -1240.1627289394162\n",
      "    ess            : 3.750817339375334\n",
      "    log_marginal   : 1240.2794189453125\n",
      "    val_loss       : -1241.2914428710938\n",
      "    val_ess        : 3.7371696631113687\n",
      "    val_log_marginal: 1241.4209391276042\n",
      "Train Epoch: 166 [0/54000 (0%)] Loss: -1239.713379\n",
      "Train Epoch: 166 [32768/54000 (61%)] Loss: -1241.559570\n",
      "    epoch          : 166\n",
      "    loss           : -1242.8917006006782\n",
      "    ess            : 3.749253255016399\n",
      "    log_marginal   : 1243.0129763045402\n",
      "    val_loss       : -1243.743916829427\n",
      "    val_ess        : 3.7592589457829795\n",
      "    val_log_marginal: 1243.8568115234375\n",
      "Train Epoch: 167 [0/54000 (0%)] Loss: -1247.068848\n",
      "Train Epoch: 167 [32768/54000 (61%)] Loss: -1245.827148\n",
      "    epoch          : 167\n",
      "    loss           : -1244.0047515293338\n",
      "    ess            : 3.7505065135236055\n",
      "    log_marginal   : 1244.123654923349\n",
      "    val_loss       : -1240.557393391927\n",
      "    val_ess        : 3.7538472414016724\n",
      "    val_log_marginal: 1240.6753540039062\n",
      "Train Epoch: 168 [0/54000 (0%)] Loss: -1244.827881\n",
      "Train Epoch: 168 [32768/54000 (61%)] Loss: -1241.835205\n",
      "    epoch          : 168\n",
      "    loss           : -1241.6623235738502\n",
      "    ess            : 3.7522643107288287\n",
      "    log_marginal   : 1241.7798104915978\n",
      "    val_loss       : -1242.4861653645833\n",
      "    val_ess        : 3.7482730944951377\n",
      "    val_log_marginal: 1242.6159057617188\n",
      "Train Epoch: 169 [0/54000 (0%)] Loss: -1243.266846\n",
      "Train Epoch: 169 [32768/54000 (61%)] Loss: -1246.417480\n",
      "    epoch          : 169\n",
      "    loss           : -1244.574333910672\n",
      "    ess            : 3.7519711053596354\n",
      "    log_marginal   : 1244.6941608932782\n",
      "    val_loss       : -1244.917500813802\n",
      "    val_ess        : 3.7413253784179688\n",
      "    val_log_marginal: 1245.0406901041667\n",
      "Train Epoch: 170 [0/54000 (0%)] Loss: -1251.364380\n",
      "Train Epoch: 170 [32768/54000 (61%)] Loss: -1246.336792\n",
      "    epoch          : 170\n",
      "    loss           : -1246.5451199513561\n",
      "    ess            : 3.747777718418049\n",
      "    log_marginal   : 1246.6665845187206\n",
      "    val_loss       : -1245.284444173177\n",
      "    val_ess        : 3.7425662676493325\n",
      "    val_log_marginal: 1245.4037679036458\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch170.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 171 [0/54000 (0%)] Loss: -1249.706787\n",
      "Train Epoch: 171 [32768/54000 (61%)] Loss: -1243.586304\n",
      "    epoch          : 171\n",
      "    loss           : -1244.2229902159493\n",
      "    ess            : 3.7545028902449697\n",
      "    log_marginal   : 1244.3388948260613\n",
      "    val_loss       : -1243.400410970052\n",
      "    val_ess        : 3.736596703529358\n",
      "    val_log_marginal: 1243.527099609375\n",
      "Train Epoch: 172 [0/54000 (0%)] Loss: -1247.384888\n",
      "Train Epoch: 172 [32768/54000 (61%)] Loss: -1248.808228\n",
      "    epoch          : 172\n",
      "    loss           : -1246.420290389151\n",
      "    ess            : 3.7544394798998564\n",
      "    log_marginal   : 1246.537187684257\n",
      "    val_loss       : -1246.9405110677083\n",
      "    val_ess        : 3.742018699645996\n",
      "    val_log_marginal: 1247.058125813802\n",
      "Train Epoch: 173 [0/54000 (0%)] Loss: -1248.008789\n",
      "Train Epoch: 173 [32768/54000 (61%)] Loss: -1247.623291\n",
      "    epoch          : 173\n",
      "    loss           : -1248.5211872604657\n",
      "    ess            : 3.7516964786457567\n",
      "    log_marginal   : 1248.6405789357311\n",
      "    val_loss       : -1248.158223470052\n",
      "    val_ess        : 3.746442953745524\n",
      "    val_log_marginal: 1248.2743733723958\n",
      "Train Epoch: 174 [0/54000 (0%)] Loss: -1246.758057\n",
      "Train Epoch: 174 [32768/54000 (61%)] Loss: -1247.592773\n",
      "    epoch          : 174\n",
      "    loss           : -1246.6462148990272\n",
      "    ess            : 3.7501183500829733\n",
      "    log_marginal   : 1246.7631144973468\n",
      "    val_loss       : -1244.550557454427\n",
      "    val_ess        : 3.740874965985616\n",
      "    val_log_marginal: 1244.6779174804688\n",
      "Train Epoch: 175 [0/54000 (0%)] Loss: -1246.568604\n",
      "Train Epoch: 175 [32768/54000 (61%)] Loss: -1246.460327\n",
      "    epoch          : 175\n",
      "    loss           : -1247.5898045953716\n",
      "    ess            : 3.7507063307852113\n",
      "    log_marginal   : 1247.7077774911556\n",
      "    val_loss       : -1248.5743611653645\n",
      "    val_ess        : 3.759297569592794\n",
      "    val_log_marginal: 1248.6904703776042\n",
      "Train Epoch: 176 [0/54000 (0%)] Loss: -1250.280273\n",
      "Train Epoch: 176 [32768/54000 (61%)] Loss: -1250.888184\n",
      "    epoch          : 176\n",
      "    loss           : -1249.966267135908\n",
      "    ess            : 3.7488457751723954\n",
      "    log_marginal   : 1250.0863451687794\n",
      "    val_loss       : -1251.3341878255208\n",
      "    val_ess        : 3.752910057703654\n",
      "    val_log_marginal: 1251.4501546223958\n",
      "Train Epoch: 177 [0/54000 (0%)] Loss: -1255.148560\n",
      "Train Epoch: 177 [32768/54000 (61%)] Loss: -1246.902954\n",
      "    epoch          : 177\n",
      "    loss           : -1249.7167024432488\n",
      "    ess            : 3.7483950740886183\n",
      "    log_marginal   : 1249.8376533940154\n",
      "    val_loss       : -1245.8289794921875\n",
      "    val_ess        : 3.7595344384511313\n",
      "    val_log_marginal: 1245.9498291015625\n",
      "Train Epoch: 178 [0/54000 (0%)] Loss: -1249.111572\n",
      "Train Epoch: 178 [32768/54000 (61%)] Loss: -1247.119751\n",
      "    epoch          : 178\n",
      "    loss           : -1248.17954700398\n",
      "    ess            : 3.7463448272561126\n",
      "    log_marginal   : 1248.2999221513855\n",
      "    val_loss       : -1249.304463704427\n",
      "    val_ess        : 3.7488379875818887\n",
      "    val_log_marginal: 1249.4297281901042\n",
      "Train Epoch: 179 [0/54000 (0%)] Loss: -1251.978271\n",
      "Train Epoch: 179 [32768/54000 (61%)] Loss: -1249.035889\n",
      "    epoch          : 179\n",
      "    loss           : -1251.037821067954\n",
      "    ess            : 3.751381995542994\n",
      "    log_marginal   : 1251.1566254237912\n",
      "    val_loss       : -1251.6171264648438\n",
      "    val_ess        : 3.7591540018717446\n",
      "    val_log_marginal: 1251.724365234375\n",
      "Train Epoch: 180 [0/54000 (0%)] Loss: -1253.774536\n",
      "Train Epoch: 180 [32768/54000 (61%)] Loss: -1248.941772\n",
      "    epoch          : 180\n",
      "    loss           : -1252.7224213222287\n",
      "    ess            : 3.7495697084462867\n",
      "    log_marginal   : 1252.8391643020343\n",
      "    val_loss       : -1250.7349446614583\n",
      "    val_ess        : 3.7500625451405845\n",
      "    val_log_marginal: 1250.853006998698\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch180.pth ...\n",
      "Train Epoch: 181 [0/54000 (0%)] Loss: -1254.322754\n",
      "Train Epoch: 181 [32768/54000 (61%)] Loss: -1249.819214\n",
      "    epoch          : 181\n",
      "    loss           : -1250.6709421985554\n",
      "    ess            : 3.7474970367719544\n",
      "    log_marginal   : 1250.7917319243809\n",
      "    val_loss       : -1250.7389526367188\n",
      "    val_ess        : 3.7562857468922934\n",
      "    val_log_marginal: 1250.8519897460938\n",
      "Train Epoch: 182 [0/54000 (0%)] Loss: -1255.513916\n",
      "Train Epoch: 182 [32768/54000 (61%)] Loss: -1254.434570\n",
      "    epoch          : 182\n",
      "    loss           : -1253.2366459684552\n",
      "    ess            : 3.7484427578044386\n",
      "    log_marginal   : 1253.356710182046\n",
      "    val_loss       : -1254.1663411458333\n",
      "    val_ess        : 3.741714358329773\n",
      "    val_log_marginal: 1254.289286295573\n",
      "Train Epoch: 183 [0/54000 (0%)] Loss: -1256.149780\n",
      "Train Epoch: 183 [32768/54000 (61%)] Loss: -1256.420898\n",
      "    epoch          : 183\n",
      "    loss           : -1255.0806055608784\n",
      "    ess            : 3.748875581993247\n",
      "    log_marginal   : 1255.1982859485554\n",
      "    val_loss       : -1254.4924926757812\n",
      "    val_ess        : 3.739150365193685\n",
      "    val_log_marginal: 1254.6172281901042\n",
      "Train Epoch: 184 [0/54000 (0%)] Loss: -1254.254639\n",
      "Train Epoch: 184 [32768/54000 (61%)] Loss: -1254.822876\n",
      "    epoch          : 184\n",
      "    loss           : -1253.0733872899468\n",
      "    ess            : 3.7503083067120246\n",
      "    log_marginal   : 1253.192813513414\n",
      "    val_loss       : -1252.0328979492188\n",
      "    val_ess        : 3.744626005490621\n",
      "    val_log_marginal: 1252.152119954427\n",
      "Train Epoch: 185 [0/54000 (0%)] Loss: -1254.961426\n",
      "Train Epoch: 185 [32768/54000 (61%)] Loss: -1260.884766\n",
      "    epoch          : 185\n",
      "    loss           : -1254.6662574624115\n",
      "    ess            : 3.7452004540641353\n",
      "    log_marginal   : 1254.7890625\n",
      "    val_loss       : -1255.7015584309895\n",
      "    val_ess        : 3.7594585021336875\n",
      "    val_log_marginal: 1255.8146158854167\n",
      "Train Epoch: 186 [0/54000 (0%)] Loss: -1258.884155\n",
      "Train Epoch: 186 [32768/54000 (61%)] Loss: -1255.628662\n",
      "    epoch          : 186\n",
      "    loss           : -1257.134500755454\n",
      "    ess            : 3.7464179542829408\n",
      "    log_marginal   : 1257.2561472766804\n",
      "    val_loss       : -1257.642578125\n",
      "    val_ess        : 3.730245272318522\n",
      "    val_log_marginal: 1257.7706705729167\n",
      "Train Epoch: 187 [0/54000 (0%)] Loss: -1257.414062\n",
      "Train Epoch: 187 [32768/54000 (61%)] Loss: -1255.586182\n",
      "    epoch          : 187\n",
      "    loss           : -1255.8997180866745\n",
      "    ess            : 3.742877222457022\n",
      "    log_marginal   : 1256.0217515477593\n",
      "    val_loss       : -1252.2455240885417\n",
      "    val_ess        : 3.7485233147939048\n",
      "    val_log_marginal: 1252.365743001302\n",
      "Train Epoch: 188 [0/54000 (0%)] Loss: -1256.699219\n",
      "Train Epoch: 188 [32768/54000 (61%)] Loss: -1257.471191\n",
      "    epoch          : 188\n",
      "    loss           : -1255.9873369324882\n",
      "    ess            : 3.7492208390865684\n",
      "    log_marginal   : 1256.1066825434846\n",
      "    val_loss       : -1256.907979329427\n",
      "    val_ess        : 3.7368202209472656\n",
      "    val_log_marginal: 1257.0313720703125\n",
      "Train Epoch: 189 [0/54000 (0%)] Loss: -1255.298096\n",
      "Train Epoch: 189 [32768/54000 (61%)] Loss: -1261.824341\n",
      "    epoch          : 189\n",
      "    loss           : -1258.590216870578\n",
      "    ess            : 3.7463564422895326\n",
      "    log_marginal   : 1258.711727502211\n",
      "    val_loss       : -1259.6251627604167\n",
      "    val_ess        : 3.7497854232788086\n",
      "    val_log_marginal: 1259.7461954752605\n",
      "Train Epoch: 190 [0/54000 (0%)] Loss: -1260.455566\n",
      "Train Epoch: 190 [32768/54000 (61%)] Loss: -1257.489258\n",
      "    epoch          : 190\n",
      "    loss           : -1259.1423017393868\n",
      "    ess            : 3.7434789864522107\n",
      "    log_marginal   : 1259.2636833910672\n",
      "    val_loss       : -1255.7320149739583\n",
      "    val_ess        : 3.746938467025757\n",
      "    val_log_marginal: 1255.8562622070312\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch190.pth ...\n",
      "Train Epoch: 191 [0/54000 (0%)] Loss: -1259.470337\n",
      "Train Epoch: 191 [32768/54000 (61%)] Loss: -1256.704956\n",
      "    epoch          : 191\n",
      "    loss           : -1257.437371020047\n",
      "    ess            : 3.749946315333528\n",
      "    log_marginal   : 1257.5548671506485\n",
      "    val_loss       : -1257.7194213867188\n",
      "    val_ess        : 3.7410360972086587\n",
      "    val_log_marginal: 1257.8446858723958\n",
      "Train Epoch: 192 [0/54000 (0%)] Loss: -1261.245361\n",
      "Train Epoch: 192 [32768/54000 (61%)] Loss: -1259.180176\n",
      "    epoch          : 192\n",
      "    loss           : -1260.1948933151532\n",
      "    ess            : 3.744365584175542\n",
      "    log_marginal   : 1260.3178964290978\n",
      "    val_loss       : -1260.638407389323\n",
      "    val_ess        : 3.7361891667048135\n",
      "    val_log_marginal: 1260.7691650390625\n",
      "Train Epoch: 193 [0/54000 (0%)] Loss: -1265.208618\n",
      "Train Epoch: 193 [32768/54000 (61%)] Loss: -1263.082520\n",
      "    epoch          : 193\n",
      "    loss           : -1261.7572942769752\n",
      "    ess            : 3.7465114458551945\n",
      "    log_marginal   : 1261.879753832547\n",
      "    val_loss       : -1260.084493001302\n",
      "    val_ess        : 3.761014143625895\n",
      "    val_log_marginal: 1260.2014567057292\n",
      "Train Epoch: 194 [0/54000 (0%)] Loss: -1263.278809\n",
      "Train Epoch: 194 [32768/54000 (61%)] Loss: -1258.435547\n",
      "    epoch          : 194\n",
      "    loss           : -1259.8334154812794\n",
      "    ess            : 3.7445582893659486\n",
      "    log_marginal   : 1259.955971771816\n",
      "    val_loss       : -1259.0518188476562\n",
      "    val_ess        : 3.739384134610494\n",
      "    val_log_marginal: 1259.175069173177\n",
      "Train Epoch: 195 [0/54000 (0%)] Loss: -1261.019531\n",
      "Train Epoch: 195 [32768/54000 (61%)] Loss: -1263.298340\n",
      "    epoch          : 195\n",
      "    loss           : -1261.8134166789505\n",
      "    ess            : 3.7385138655608556\n",
      "    log_marginal   : 1261.9410976193985\n",
      "    val_loss       : -1262.561055501302\n",
      "    val_ess        : 3.7464102109273276\n",
      "    val_log_marginal: 1262.6778361002605\n",
      "Train Epoch: 196 [0/54000 (0%)] Loss: -1264.909302\n",
      "Train Epoch: 196 [32768/54000 (61%)] Loss: -1261.975952\n",
      "    epoch          : 196\n",
      "    loss           : -1264.07965663694\n",
      "    ess            : 3.7460438665354028\n",
      "    log_marginal   : 1264.2004233306309\n",
      "    val_loss       : -1263.4873046875\n",
      "    val_ess        : 3.7322434186935425\n",
      "    val_log_marginal: 1263.6142985026042\n",
      "Train Epoch: 197 [0/54000 (0%)] Loss: -1266.224365\n",
      "Train Epoch: 197 [32768/54000 (61%)] Loss: -1262.396973\n",
      "    epoch          : 197\n",
      "    loss           : -1262.3001202277417\n",
      "    ess            : 3.74202118279799\n",
      "    log_marginal   : 1262.4236784161262\n",
      "    val_loss       : -1260.274881998698\n",
      "    val_ess        : 3.7470431327819824\n",
      "    val_log_marginal: 1260.4002685546875\n",
      "Train Epoch: 198 [0/54000 (0%)] Loss: -1261.067749\n",
      "Train Epoch: 198 [32768/54000 (61%)] Loss: -1259.882080\n",
      "    epoch          : 198\n",
      "    loss           : -1263.3270010318397\n",
      "    ess            : 3.745705244676122\n",
      "    log_marginal   : 1263.4454506928066\n",
      "    val_loss       : -1264.2107747395833\n",
      "    val_ess        : 3.7468096017837524\n",
      "    val_log_marginal: 1264.3290201822917\n",
      "Train Epoch: 199 [0/54000 (0%)] Loss: -1266.906006\n",
      "Train Epoch: 199 [32768/54000 (61%)] Loss: -1267.753906\n",
      "    epoch          : 199\n",
      "    loss           : -1265.833880730395\n",
      "    ess            : 3.743809749495308\n",
      "    log_marginal   : 1265.957109559257\n",
      "    val_loss       : -1266.2307739257812\n",
      "    val_ess        : 3.7473888794581094\n",
      "    val_log_marginal: 1266.3536580403645\n",
      "Train Epoch: 200 [0/54000 (0%)] Loss: -1271.846191\n",
      "Train Epoch: 200 [32768/54000 (61%)] Loss: -1264.473633\n",
      "    epoch          : 200\n",
      "    loss           : -1265.321652970224\n",
      "    ess            : 3.747070200038406\n",
      "    log_marginal   : 1265.4417010613208\n",
      "    val_loss       : -1261.6929321289062\n",
      "    val_ess        : 3.7377678553263345\n",
      "    val_log_marginal: 1261.8150227864583\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [0/54000 (0%)] Loss: -1265.265381\n",
      "Train Epoch: 201 [32768/54000 (61%)] Loss: -1264.127197\n",
      "    epoch          : 201\n",
      "    loss           : -1264.2839793079304\n",
      "    ess            : 3.7434590492608413\n",
      "    log_marginal   : 1264.4049602004718\n",
      "    val_loss       : -1264.9644571940105\n",
      "    val_ess        : 3.7446369330088296\n",
      "    val_log_marginal: 1265.0874837239583\n",
      "Train Epoch: 202 [0/54000 (0%)] Loss: -1265.168945\n",
      "Train Epoch: 202 [32768/54000 (61%)] Loss: -1263.687500\n",
      "    epoch          : 202\n",
      "    loss           : -1267.1201240971404\n",
      "    ess            : 3.73818390774277\n",
      "    log_marginal   : 1267.2451287035672\n",
      "    val_loss       : -1267.827860514323\n",
      "    val_ess        : 3.7299549182256064\n",
      "    val_log_marginal: 1267.959452311198\n",
      "Train Epoch: 203 [0/54000 (0%)] Loss: -1271.231689\n",
      "Train Epoch: 203 [32768/54000 (61%)] Loss: -1269.149414\n",
      "    epoch          : 203\n",
      "    loss           : -1268.4512778228184\n",
      "    ess            : 3.738363616871384\n",
      "    log_marginal   : 1268.5745550191627\n",
      "    val_loss       : -1266.1278483072917\n",
      "    val_ess        : 3.7526532411575317\n",
      "    val_log_marginal: 1266.2442220052083\n",
      "Train Epoch: 204 [0/54000 (0%)] Loss: -1266.554077\n",
      "Train Epoch: 204 [32768/54000 (61%)] Loss: -1265.423340\n",
      "    epoch          : 204\n",
      "    loss           : -1266.2561426702534\n",
      "    ess            : 3.741219124704037\n",
      "    log_marginal   : 1266.3770890145931\n",
      "    val_loss       : -1265.8038533528645\n",
      "    val_ess        : 3.7413854598999023\n",
      "    val_log_marginal: 1265.9287923177083\n",
      "Train Epoch: 205 [0/54000 (0%)] Loss: -1266.953613\n",
      "Train Epoch: 205 [32768/54000 (61%)] Loss: -1266.179443\n",
      "    epoch          : 205\n",
      "    loss           : -1268.6953562610554\n",
      "    ess            : 3.7370596336868576\n",
      "    log_marginal   : 1268.8214618035083\n",
      "    val_loss       : -1269.1792805989583\n",
      "    val_ess        : 3.7353458801905313\n",
      "    val_log_marginal: 1269.3055419921875\n",
      "Train Epoch: 206 [0/54000 (0%)] Loss: -1270.194092\n",
      "Train Epoch: 206 [32768/54000 (61%)] Loss: -1272.263428\n",
      "    epoch          : 206\n",
      "    loss           : -1270.7368509544517\n",
      "    ess            : 3.738101788286893\n",
      "    log_marginal   : 1270.862189526828\n",
      "    val_loss       : -1269.8812052408855\n",
      "    val_ess        : 3.7354427178700766\n",
      "    val_log_marginal: 1270.0064086914062\n",
      "Train Epoch: 207 [0/54000 (0%)] Loss: -1270.476196\n",
      "Train Epoch: 207 [32768/54000 (61%)] Loss: -1269.046631\n",
      "    epoch          : 207\n",
      "    loss           : -1268.792646300118\n",
      "    ess            : 3.7391275234942167\n",
      "    log_marginal   : 1268.914555387677\n",
      "    val_loss       : -1267.3192342122395\n",
      "    val_ess        : 3.741263667742411\n",
      "    val_log_marginal: 1267.4366251627605\n",
      "Train Epoch: 208 [0/54000 (0%)] Loss: -1272.173584\n",
      "Train Epoch: 208 [32768/54000 (61%)] Loss: -1274.895020\n",
      "    epoch          : 208\n",
      "    loss           : -1270.467326614092\n",
      "    ess            : 3.7384568925173776\n",
      "    log_marginal   : 1270.5911519752358\n",
      "    val_loss       : -1271.4656575520833\n",
      "    val_ess        : 3.738340735435486\n",
      "    val_log_marginal: 1271.5873209635417\n",
      "Train Epoch: 209 [0/54000 (0%)] Loss: -1271.289062\n",
      "Train Epoch: 209 [32768/54000 (61%)] Loss: -1273.707642\n",
      "    epoch          : 209\n",
      "    loss           : -1272.7118772110848\n",
      "    ess            : 3.7438004151830135\n",
      "    log_marginal   : 1272.8315245430424\n",
      "    val_loss       : -1272.7423706054688\n",
      "    val_ess        : 3.7486745913823447\n",
      "    val_log_marginal: 1272.861104329427\n",
      "Train Epoch: 210 [0/54000 (0%)] Loss: -1273.499023\n",
      "Train Epoch: 210 [32768/54000 (61%)] Loss: -1269.022705\n",
      "    epoch          : 210\n",
      "    loss           : -1271.7035672169811\n",
      "    ess            : 3.740734320766521\n",
      "    log_marginal   : 1271.825066332547\n",
      "    val_loss       : -1268.8731689453125\n",
      "    val_ess        : 3.748262127240499\n",
      "    val_log_marginal: 1268.992431640625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch210.pth ...\n",
      "Train Epoch: 211 [0/54000 (0%)] Loss: -1271.677734\n",
      "Train Epoch: 211 [32768/54000 (61%)] Loss: -1273.525757\n",
      "    epoch          : 211\n",
      "    loss           : -1271.640786224941\n",
      "    ess            : 3.7367431982508243\n",
      "    log_marginal   : 1271.763750184257\n",
      "    val_loss       : -1272.4041341145833\n",
      "    val_ess        : 3.7338430086771646\n",
      "    val_log_marginal: 1272.5343017578125\n",
      "Train Epoch: 212 [0/54000 (0%)] Loss: -1274.521240\n",
      "Train Epoch: 212 [32768/54000 (61%)] Loss: -1274.574097\n",
      "    epoch          : 212\n",
      "    loss           : -1274.2979068396226\n",
      "    ess            : 3.741891469595567\n",
      "    log_marginal   : 1274.419739921138\n",
      "    val_loss       : -1274.9808349609375\n",
      "    val_ess        : 3.7347381114959717\n",
      "    val_log_marginal: 1275.1082356770833\n",
      "Train Epoch: 213 [0/54000 (0%)] Loss: -1274.282715\n",
      "Train Epoch: 213 [32768/54000 (61%)] Loss: -1275.041016\n",
      "    epoch          : 213\n",
      "    loss           : -1274.7879776864681\n",
      "    ess            : 3.7338601643184446\n",
      "    log_marginal   : 1274.9148801407723\n",
      "    val_loss       : -1271.763448079427\n",
      "    val_ess        : 3.737675587336222\n",
      "    val_log_marginal: 1271.887471516927\n",
      "Train Epoch: 214 [0/54000 (0%)] Loss: -1275.049316\n",
      "Train Epoch: 214 [32768/54000 (61%)] Loss: -1270.085449\n",
      "    epoch          : 214\n",
      "    loss           : -1273.146505103921\n",
      "    ess            : 3.738946023977028\n",
      "    log_marginal   : 1273.2687343381485\n",
      "    val_loss       : -1273.666280110677\n",
      "    val_ess        : 3.7339497407277427\n",
      "    val_log_marginal: 1273.7888793945312\n",
      "Train Epoch: 215 [0/54000 (0%)] Loss: -1277.544189\n",
      "Train Epoch: 215 [32768/54000 (61%)] Loss: -1275.224609\n",
      "    epoch          : 215\n",
      "    loss           : -1275.7141596956073\n",
      "    ess            : 3.737545184369357\n",
      "    log_marginal   : 1275.8390836895637\n",
      "    val_loss       : -1276.0984293619792\n",
      "    val_ess        : 3.7366433143615723\n",
      "    val_log_marginal: 1276.2262776692708\n",
      "Train Epoch: 216 [0/54000 (0%)] Loss: -1280.248047\n",
      "Train Epoch: 216 [32768/54000 (61%)] Loss: -1277.947266\n",
      "    epoch          : 216\n",
      "    loss           : -1277.4119389372052\n",
      "    ess            : 3.739644905306258\n",
      "    log_marginal   : 1277.5358702461674\n",
      "    val_loss       : -1276.0116373697917\n",
      "    val_ess        : 3.7467588583628335\n",
      "    val_log_marginal: 1276.1271565755208\n",
      "Train Epoch: 217 [0/54000 (0%)] Loss: -1279.082275\n",
      "Train Epoch: 217 [32768/54000 (61%)] Loss: -1273.377197\n",
      "    epoch          : 217\n",
      "    loss           : -1275.4591985738502\n",
      "    ess            : 3.7334670210784338\n",
      "    log_marginal   : 1275.5829156839623\n",
      "    val_loss       : -1274.6325276692708\n",
      "    val_ess        : 3.7287441889444985\n",
      "    val_log_marginal: 1274.7550048828125\n",
      "Train Epoch: 218 [0/54000 (0%)] Loss: -1278.908447\n",
      "Train Epoch: 218 [32768/54000 (61%)] Loss: -1274.875000\n",
      "    epoch          : 218\n",
      "    loss           : -1277.339194243809\n",
      "    ess            : 3.734981078021931\n",
      "    log_marginal   : 1277.464641067217\n",
      "    val_loss       : -1278.056660970052\n",
      "    val_ess        : 3.7431366443634033\n",
      "    val_log_marginal: 1278.1729532877605\n",
      "Train Epoch: 219 [0/54000 (0%)] Loss: -1281.623657\n",
      "Train Epoch: 219 [32768/54000 (61%)] Loss: -1277.235107\n",
      "    epoch          : 219\n",
      "    loss           : -1279.550412735849\n",
      "    ess            : 3.729915776342716\n",
      "    log_marginal   : 1279.677001953125\n",
      "    val_loss       : -1279.3681030273438\n",
      "    val_ess        : 3.729663054148356\n",
      "    val_log_marginal: 1279.4936930338542\n",
      "Train Epoch: 220 [0/54000 (0%)] Loss: -1280.917480\n",
      "Train Epoch: 220 [32768/54000 (61%)] Loss: -1278.028442\n",
      "    epoch          : 220\n",
      "    loss           : -1278.254477446934\n",
      "    ess            : 3.735848512289659\n",
      "    log_marginal   : 1278.3795511497642\n",
      "    val_loss       : -1275.6250610351562\n",
      "    val_ess        : 3.7191027800242105\n",
      "    val_log_marginal: 1275.7615152994792\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch220.pth ...\n",
      "Train Epoch: 221 [0/54000 (0%)] Loss: -1277.002197\n",
      "Train Epoch: 221 [32768/54000 (61%)] Loss: -1277.765625\n",
      "    epoch          : 221\n",
      "    loss           : -1278.6575351931015\n",
      "    ess            : 3.736670062227069\n",
      "    log_marginal   : 1278.7819225383255\n",
      "    val_loss       : -1279.519063313802\n",
      "    val_ess        : 3.733293970425924\n",
      "    val_log_marginal: 1279.6424153645833\n",
      "Train Epoch: 222 [0/54000 (0%)] Loss: -1283.059570\n",
      "Train Epoch: 222 [32768/54000 (61%)] Loss: -1278.908813\n",
      "    epoch          : 222\n",
      "    loss           : -1281.0066885318397\n",
      "    ess            : 3.733518654445432\n",
      "    log_marginal   : 1281.1326535782723\n",
      "    val_loss       : -1281.7589314778645\n",
      "    val_ess        : 3.742513577143351\n",
      "    val_log_marginal: 1281.8764038085938\n",
      "Train Epoch: 223 [0/54000 (0%)] Loss: -1281.310303\n",
      "Train Epoch: 223 [32768/54000 (61%)] Loss: -1278.927002\n",
      "    epoch          : 223\n",
      "    loss           : -1281.4179756596404\n",
      "    ess            : 3.7326221061202713\n",
      "    log_marginal   : 1281.5428766214623\n",
      "    val_loss       : -1278.5284423828125\n",
      "    val_ess        : 3.7459617058436074\n",
      "    val_log_marginal: 1278.643534342448\n",
      "Train Epoch: 224 [0/54000 (0%)] Loss: -1282.528320\n",
      "Train Epoch: 224 [32768/54000 (61%)] Loss: -1280.631592\n",
      "    epoch          : 224\n",
      "    loss           : -1279.9620269199588\n",
      "    ess            : 3.7337417557554424\n",
      "    log_marginal   : 1280.0869278817806\n",
      "    val_loss       : -1280.8025309244792\n",
      "    val_ess        : 3.737245043118795\n",
      "    val_log_marginal: 1280.9209798177083\n",
      "Train Epoch: 225 [0/54000 (0%)] Loss: -1284.260254\n",
      "Train Epoch: 225 [32768/54000 (61%)] Loss: -1280.789917\n",
      "    epoch          : 225\n",
      "    loss           : -1282.5885055829895\n",
      "    ess            : 3.733401689889296\n",
      "    log_marginal   : 1282.715046432783\n",
      "    val_loss       : -1283.483154296875\n",
      "    val_ess        : 3.7436459064483643\n",
      "    val_log_marginal: 1283.5992228190105\n",
      "Train Epoch: 226 [0/54000 (0%)] Loss: -1283.032104\n",
      "Train Epoch: 226 [32768/54000 (61%)] Loss: -1285.017334\n",
      "    epoch          : 226\n",
      "    loss           : -1284.1534746278007\n",
      "    ess            : 3.730296598290497\n",
      "    log_marginal   : 1284.2810311947228\n",
      "    val_loss       : -1283.0143636067708\n",
      "    val_ess        : 3.7397398551305137\n",
      "    val_log_marginal: 1283.1373494466145\n",
      "Train Epoch: 227 [0/54000 (0%)] Loss: -1285.812744\n",
      "Train Epoch: 227 [32768/54000 (61%)] Loss: -1284.456177\n",
      "    epoch          : 227\n",
      "    loss           : -1282.3432156544811\n",
      "    ess            : 3.737600857356809\n",
      "    log_marginal   : 1282.4650141877948\n",
      "    val_loss       : -1281.778828938802\n",
      "    val_ess        : 3.7339669466018677\n",
      "    val_log_marginal: 1281.9024454752605\n",
      "Train Epoch: 228 [0/54000 (0%)] Loss: -1283.564087\n",
      "Train Epoch: 228 [32768/54000 (61%)] Loss: -1283.832642\n",
      "    epoch          : 228\n",
      "    loss           : -1284.2723388671875\n",
      "    ess            : 3.731878496565909\n",
      "    log_marginal   : 1284.3970210237323\n",
      "    val_loss       : -1284.7416381835938\n",
      "    val_ess        : 3.7271765867869058\n",
      "    val_log_marginal: 1284.8697713216145\n",
      "Train Epoch: 229 [0/54000 (0%)] Loss: -1288.476807\n",
      "Train Epoch: 229 [32768/54000 (61%)] Loss: -1287.010864\n",
      "    epoch          : 229\n",
      "    loss           : -1286.2720440558667\n",
      "    ess            : 3.7330594107789814\n",
      "    log_marginal   : 1286.3983868293042\n",
      "    val_loss       : -1286.1013590494792\n",
      "    val_ess        : 3.715841849644979\n",
      "    val_log_marginal: 1286.2376098632812\n",
      "Train Epoch: 230 [0/54000 (0%)] Loss: -1287.328613\n",
      "Train Epoch: 230 [32768/54000 (61%)] Loss: -1281.265869\n",
      "    epoch          : 230\n",
      "    loss           : -1285.1999534750885\n",
      "    ess            : 3.7329442006237104\n",
      "    log_marginal   : 1285.325133125737\n",
      "    val_loss       : -1282.8211466471355\n",
      "    val_ess        : 3.734372099240621\n",
      "    val_log_marginal: 1282.9454549153645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch230.pth ...\n",
      "Train Epoch: 231 [0/54000 (0%)] Loss: -1287.297607\n",
      "Train Epoch: 231 [32768/54000 (61%)] Loss: -1287.707520\n",
      "    epoch          : 231\n",
      "    loss           : -1285.3766767393868\n",
      "    ess            : 3.7238842226424307\n",
      "    log_marginal   : 1285.5080750663326\n",
      "    val_loss       : -1286.1566569010417\n",
      "    val_ess        : 3.7407776912053428\n",
      "    val_log_marginal: 1286.2767944335938\n",
      "Train Epoch: 232 [0/54000 (0%)] Loss: -1291.023438\n",
      "Train Epoch: 232 [32768/54000 (61%)] Loss: -1288.975586\n",
      "    epoch          : 232\n",
      "    loss           : -1287.9322463701355\n",
      "    ess            : 3.730540230589093\n",
      "    log_marginal   : 1288.06048008181\n",
      "    val_loss       : -1288.5016072591145\n",
      "    val_ess        : 3.7352152665456138\n",
      "    val_log_marginal: 1288.6221313476562\n",
      "Train Epoch: 233 [0/54000 (0%)] Loss: -1290.544922\n",
      "Train Epoch: 233 [32768/54000 (61%)] Loss: -1287.341309\n",
      "    epoch          : 233\n",
      "    loss           : -1288.3935869324882\n",
      "    ess            : 3.7336853990014993\n",
      "    log_marginal   : 1288.5172856168927\n",
      "    val_loss       : -1285.292704264323\n",
      "    val_ess        : 3.7334561347961426\n",
      "    val_log_marginal: 1285.4221801757812\n",
      "Train Epoch: 234 [0/54000 (0%)] Loss: -1286.725342\n",
      "Train Epoch: 234 [32768/54000 (61%)] Loss: -1285.391113\n",
      "    epoch          : 234\n",
      "    loss           : -1286.8177812684257\n",
      "    ess            : 3.7296554682389744\n",
      "    log_marginal   : 1286.9432902785968\n",
      "    val_loss       : -1286.9268595377605\n",
      "    val_ess        : 3.7384926478068032\n",
      "    val_log_marginal: 1287.054707845052\n",
      "Train Epoch: 235 [0/54000 (0%)] Loss: -1290.361328\n",
      "Train Epoch: 235 [32768/54000 (61%)] Loss: -1288.945068\n",
      "    epoch          : 235\n",
      "    loss           : -1289.3533037293632\n",
      "    ess            : 3.727250229637578\n",
      "    log_marginal   : 1289.4823090175412\n",
      "    val_loss       : -1290.014424641927\n",
      "    val_ess        : 3.731138984362284\n",
      "    val_log_marginal: 1290.1414591471355\n",
      "Train Epoch: 236 [0/54000 (0%)] Loss: -1292.370483\n",
      "Train Epoch: 236 [32768/54000 (61%)] Loss: -1290.974854\n",
      "    epoch          : 236\n",
      "    loss           : -1291.1358181935436\n",
      "    ess            : 3.7281806963794635\n",
      "    log_marginal   : 1291.264669166421\n",
      "    val_loss       : -1289.4295654296875\n",
      "    val_ess        : 3.743126392364502\n",
      "    val_log_marginal: 1289.545430501302\n",
      "Train Epoch: 237 [0/54000 (0%)] Loss: -1289.925781\n",
      "Train Epoch: 237 [32768/54000 (61%)] Loss: -1287.409790\n",
      "    epoch          : 237\n",
      "    loss           : -1289.503173828125\n",
      "    ess            : 3.7279433799239823\n",
      "    log_marginal   : 1289.631368385171\n",
      "    val_loss       : -1287.9830729166667\n",
      "    val_ess        : 3.736563762029012\n",
      "    val_log_marginal: 1288.103271484375\n",
      "Train Epoch: 238 [0/54000 (0%)] Loss: -1292.668945\n",
      "Train Epoch: 238 [32768/54000 (61%)] Loss: -1288.143799\n",
      "    epoch          : 238\n",
      "    loss           : -1290.9165269383843\n",
      "    ess            : 3.732043999545979\n",
      "    log_marginal   : 1291.0407069943985\n",
      "    val_loss       : -1291.3304036458333\n",
      "    val_ess        : 3.752586245536804\n",
      "    val_log_marginal: 1291.4452718098958\n",
      "Train Epoch: 239 [0/54000 (0%)] Loss: -1292.489258\n",
      "Train Epoch: 239 [32768/54000 (61%)] Loss: -1293.763184\n",
      "    epoch          : 239\n",
      "    loss           : -1292.9956768683667\n",
      "    ess            : 3.72715854194929\n",
      "    log_marginal   : 1293.1261216649468\n",
      "    val_loss       : -1293.000467936198\n",
      "    val_ess        : 3.7333919604619346\n",
      "    val_log_marginal: 1293.1246134440105\n",
      "Train Epoch: 240 [0/54000 (0%)] Loss: -1293.218506\n",
      "Train Epoch: 240 [32768/54000 (61%)] Loss: -1294.534912\n",
      "    epoch          : 240\n",
      "    loss           : -1292.2606869103774\n",
      "    ess            : 3.7250350376345076\n",
      "    log_marginal   : 1292.3910234559257\n",
      "    val_loss       : -1289.587137858073\n",
      "    val_ess        : 3.7230562766393027\n",
      "    val_log_marginal: 1289.7249145507812\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch240.pth ...\n",
      "Train Epoch: 241 [0/54000 (0%)] Loss: -1293.289551\n",
      "Train Epoch: 241 [32768/54000 (61%)] Loss: -1289.465820\n",
      "    epoch          : 241\n",
      "    loss           : -1291.8940084205483\n",
      "    ess            : 3.727994873838605\n",
      "    log_marginal   : 1292.0211342865566\n",
      "    val_loss       : -1292.3109944661458\n",
      "    val_ess        : 3.729928414026896\n",
      "    val_log_marginal: 1292.4358520507812\n",
      "Train Epoch: 242 [0/54000 (0%)] Loss: -1292.093140\n",
      "Train Epoch: 242 [32768/54000 (61%)] Loss: -1293.920898\n",
      "    epoch          : 242\n",
      "    loss           : -1294.397050965507\n",
      "    ess            : 3.7256573686059915\n",
      "    log_marginal   : 1294.5258489644752\n",
      "    val_loss       : -1294.9886474609375\n",
      "    val_ess        : 3.7305527528127036\n",
      "    val_log_marginal: 1295.1141967773438\n",
      "Train Epoch: 243 [0/54000 (0%)] Loss: -1297.247314\n",
      "Train Epoch: 243 [32768/54000 (61%)] Loss: -1294.738647\n",
      "    epoch          : 243\n",
      "    loss           : -1295.3835725604363\n",
      "    ess            : 3.7263221830691933\n",
      "    log_marginal   : 1295.509579064711\n",
      "    val_loss       : -1293.2563883463542\n",
      "    val_ess        : 3.7470495303471885\n",
      "    val_log_marginal: 1293.3746744791667\n",
      "Train Epoch: 244 [0/54000 (0%)] Loss: -1291.659424\n",
      "Train Epoch: 244 [32768/54000 (61%)] Loss: -1294.233154\n",
      "    epoch          : 244\n",
      "    loss           : -1293.661211121757\n",
      "    ess            : 3.7263868304918395\n",
      "    log_marginal   : 1293.7911330888855\n",
      "    val_loss       : -1293.2970784505208\n",
      "    val_ess        : 3.727908213933309\n",
      "    val_log_marginal: 1293.423848470052\n",
      "Train Epoch: 245 [0/54000 (0%)] Loss: -1294.849609\n",
      "Train Epoch: 245 [32768/54000 (61%)] Loss: -1293.653809\n",
      "    epoch          : 245\n",
      "    loss           : -1296.0206068506782\n",
      "    ess            : 3.7260966885764644\n",
      "    log_marginal   : 1296.1493772110848\n",
      "    val_loss       : -1296.341796875\n",
      "    val_ess        : 3.719464818636576\n",
      "    val_log_marginal: 1296.4786173502605\n",
      "Train Epoch: 246 [0/54000 (0%)] Loss: -1301.820312\n",
      "Train Epoch: 246 [32768/54000 (61%)] Loss: -1298.217163\n",
      "    epoch          : 246\n",
      "    loss           : -1297.8628160008843\n",
      "    ess            : 3.7213508273070715\n",
      "    log_marginal   : 1297.9945552034198\n",
      "    val_loss       : -1296.4811604817708\n",
      "    val_ess        : 3.7167765299479165\n",
      "    val_log_marginal: 1296.6160685221355\n",
      "Train Epoch: 247 [0/54000 (0%)] Loss: -1299.119629\n",
      "Train Epoch: 247 [32768/54000 (61%)] Loss: -1291.640625\n",
      "    epoch          : 247\n",
      "    loss           : -1296.5665421395931\n",
      "    ess            : 3.7268374640986606\n",
      "    log_marginal   : 1296.695478331368\n",
      "    val_loss       : -1294.6597086588542\n",
      "    val_ess        : 3.74151611328125\n",
      "    val_log_marginal: 1294.778055826823\n",
      "Train Epoch: 248 [0/54000 (0%)] Loss: -1295.746582\n",
      "Train Epoch: 248 [32768/54000 (61%)] Loss: -1298.154541\n",
      "    epoch          : 248\n",
      "    loss           : -1297.4826844413326\n",
      "    ess            : 3.72887311791474\n",
      "    log_marginal   : 1297.6094187610554\n",
      "    val_loss       : -1297.5173746744792\n",
      "    val_ess        : 3.722871462504069\n",
      "    val_log_marginal: 1297.6521402994792\n",
      "Train Epoch: 249 [0/54000 (0%)] Loss: -1300.548584\n",
      "Train Epoch: 249 [32768/54000 (61%)] Loss: -1297.842773\n",
      "    epoch          : 249\n",
      "    loss           : -1299.719404112618\n",
      "    ess            : 3.724554808634632\n",
      "    log_marginal   : 1299.8483333947524\n",
      "    val_loss       : -1299.51123046875\n",
      "    val_ess        : 3.718030571937561\n",
      "    val_log_marginal: 1299.6478474934895\n",
      "Train Epoch: 250 [0/54000 (0%)] Loss: -1301.708252\n",
      "Train Epoch: 250 [32768/54000 (61%)] Loss: -1298.367188\n",
      "    epoch          : 250\n",
      "    loss           : -1299.3390514445755\n",
      "    ess            : 3.723177693924814\n",
      "    log_marginal   : 1299.4694455704598\n",
      "    val_loss       : -1296.6349487304688\n",
      "    val_ess        : 3.728563149770101\n",
      "    val_log_marginal: 1296.7588704427083\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch250.pth ...\n",
      "Train Epoch: 251 [0/54000 (0%)] Loss: -1300.355957\n",
      "Train Epoch: 251 [32768/54000 (61%)] Loss: -1298.887695\n",
      "    epoch          : 251\n",
      "    loss           : -1298.8913320865272\n",
      "    ess            : 3.726641412051219\n",
      "    log_marginal   : 1299.0190199366157\n",
      "    val_loss       : -1298.945292154948\n",
      "    val_ess        : 3.717088977495829\n",
      "    val_log_marginal: 1299.0845336914062\n",
      "Train Epoch: 252 [0/54000 (0%)] Loss: -1304.003784\n",
      "Train Epoch: 252 [32768/54000 (61%)] Loss: -1300.838013\n",
      "    epoch          : 252\n",
      "    loss           : -1301.1239773732311\n",
      "    ess            : 3.7258407214902483\n",
      "    log_marginal   : 1301.2510157171284\n",
      "    val_loss       : -1301.1620076497395\n",
      "    val_ess        : 3.714783867200216\n",
      "    val_log_marginal: 1301.2991739908855\n",
      "Train Epoch: 253 [0/54000 (0%)] Loss: -1303.143188\n",
      "Train Epoch: 253 [32768/54000 (61%)] Loss: -1297.963623\n",
      "    epoch          : 253\n",
      "    loss           : -1302.1616717644458\n",
      "    ess            : 3.7243674926038057\n",
      "    log_marginal   : 1302.290324660967\n",
      "    val_loss       : -1299.7708129882812\n",
      "    val_ess        : 3.72588582833608\n",
      "    val_log_marginal: 1299.895284016927\n",
      "Train Epoch: 254 [0/54000 (0%)] Loss: -1304.431885\n",
      "Train Epoch: 254 [32768/54000 (61%)] Loss: -1297.837646\n",
      "    epoch          : 254\n",
      "    loss           : -1300.8040978773586\n",
      "    ess            : 3.7270675155351745\n",
      "    log_marginal   : 1300.9333818543632\n",
      "    val_loss       : -1299.7067464192708\n",
      "    val_ess        : 3.7187686761220298\n",
      "    val_log_marginal: 1299.8440755208333\n",
      "Train Epoch: 255 [0/54000 (0%)] Loss: -1301.332031\n",
      "Train Epoch: 255 [32768/54000 (61%)] Loss: -1303.792236\n",
      "    epoch          : 255\n",
      "    loss           : -1302.5536418410968\n",
      "    ess            : 3.726861908750714\n",
      "    log_marginal   : 1302.681255988355\n",
      "    val_loss       : -1302.6596069335938\n",
      "    val_ess        : 3.710332671801249\n",
      "    val_log_marginal: 1302.7999471028645\n",
      "Train Epoch: 256 [0/54000 (0%)] Loss: -1307.050415\n",
      "Train Epoch: 256 [32768/54000 (61%)] Loss: -1306.489746\n",
      "    epoch          : 256\n",
      "    loss           : -1304.4911856021522\n",
      "    ess            : 3.724190833433619\n",
      "    log_marginal   : 1304.6203429024174\n",
      "    val_loss       : -1303.838399251302\n",
      "    val_ess        : 3.722741643587748\n",
      "    val_log_marginal: 1303.9647216796875\n",
      "Train Epoch: 257 [0/54000 (0%)] Loss: -1305.201416\n",
      "Train Epoch: 257 [32768/54000 (61%)] Loss: -1302.116211\n",
      "    epoch          : 257\n",
      "    loss           : -1303.4146267872936\n",
      "    ess            : 3.723229966073666\n",
      "    log_marginal   : 1303.5468588775059\n",
      "    val_loss       : -1301.4035034179688\n",
      "    val_ess        : 3.7246065537134805\n",
      "    val_log_marginal: 1301.5274861653645\n",
      "Train Epoch: 258 [0/54000 (0%)] Loss: -1304.211548\n",
      "Train Epoch: 258 [32768/54000 (61%)] Loss: -1308.424194\n",
      "    epoch          : 258\n",
      "    loss           : -1303.7807893573113\n",
      "    ess            : 3.7251037696622453\n",
      "    log_marginal   : 1303.909709426592\n",
      "    val_loss       : -1304.234110514323\n",
      "    val_ess        : 3.7139092683792114\n",
      "    val_log_marginal: 1304.3684895833333\n",
      "Train Epoch: 259 [0/54000 (0%)] Loss: -1306.098145\n",
      "Train Epoch: 259 [32768/54000 (61%)] Loss: -1306.507080\n",
      "    epoch          : 259\n",
      "    loss           : -1306.0535358932782\n",
      "    ess            : 3.7226344459461718\n",
      "    log_marginal   : 1306.1818594302772\n",
      "    val_loss       : -1306.2168986002605\n",
      "    val_ess        : 3.707792599995931\n",
      "    val_log_marginal: 1306.3553466796875\n",
      "Train Epoch: 260 [0/54000 (0%)] Loss: -1305.015991\n",
      "Train Epoch: 260 [32768/54000 (61%)] Loss: -1304.705566\n",
      "    epoch          : 260\n",
      "    loss           : -1306.4059805240272\n",
      "    ess            : 3.7247831371595277\n",
      "    log_marginal   : 1306.5328875847583\n",
      "    val_loss       : -1304.0499674479167\n",
      "    val_ess        : 3.726514379183451\n",
      "    val_log_marginal: 1304.1715901692708\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch260.pth ...\n",
      "Train Epoch: 261 [0/54000 (0%)] Loss: -1309.579102\n",
      "Train Epoch: 261 [32768/54000 (61%)] Loss: -1305.509766\n",
      "    epoch          : 261\n",
      "    loss           : -1305.3851594744988\n",
      "    ess            : 3.7238015768662938\n",
      "    log_marginal   : 1305.5126953125\n",
      "    val_loss       : -1305.3712972005208\n",
      "    val_ess        : 3.7371618350346885\n",
      "    val_log_marginal: 1305.4867553710938\n",
      "Train Epoch: 262 [0/54000 (0%)] Loss: -1304.942993\n",
      "Train Epoch: 262 [32768/54000 (61%)] Loss: -1305.784180\n",
      "    epoch          : 262\n",
      "    loss           : -1307.4912984596108\n",
      "    ess            : 3.72083362543358\n",
      "    log_marginal   : 1307.6222269310142\n",
      "    val_loss       : -1308.0891927083333\n",
      "    val_ess        : 3.7173784176508584\n",
      "    val_log_marginal: 1308.220438639323\n",
      "Train Epoch: 263 [0/54000 (0%)] Loss: -1310.256714\n",
      "Train Epoch: 263 [32768/54000 (61%)] Loss: -1311.362061\n",
      "    epoch          : 263\n",
      "    loss           : -1308.9209007407135\n",
      "    ess            : 3.720436892419491\n",
      "    log_marginal   : 1309.0539021042157\n",
      "    val_loss       : -1307.3446044921875\n",
      "    val_ess        : 3.71554704507192\n",
      "    val_log_marginal: 1307.4776407877605\n",
      "Train Epoch: 264 [0/54000 (0%)] Loss: -1309.518799\n",
      "Train Epoch: 264 [32768/54000 (61%)] Loss: -1306.250000\n",
      "    epoch          : 264\n",
      "    loss           : -1307.5846177586968\n",
      "    ess            : 3.7229879757143416\n",
      "    log_marginal   : 1307.7137911814564\n",
      "    val_loss       : -1306.5201822916667\n",
      "    val_ess        : 3.7225865920384726\n",
      "    val_log_marginal: 1306.648213704427\n",
      "Train Epoch: 265 [0/54000 (0%)] Loss: -1308.538452\n",
      "Train Epoch: 265 [32768/54000 (61%)] Loss: -1311.343506\n",
      "    epoch          : 265\n",
      "    loss           : -1308.8186150316922\n",
      "    ess            : 3.7203171478127532\n",
      "    log_marginal   : 1308.9502045253537\n",
      "    val_loss       : -1309.0569254557292\n",
      "    val_ess        : 3.724588314692179\n",
      "    val_log_marginal: 1309.1856892903645\n",
      "Train Epoch: 266 [0/54000 (0%)] Loss: -1314.895996\n",
      "Train Epoch: 266 [32768/54000 (61%)] Loss: -1310.530029\n",
      "    epoch          : 266\n",
      "    loss           : -1310.8073891693691\n",
      "    ess            : 3.722058912493148\n",
      "    log_marginal   : 1310.935724222435\n",
      "    val_loss       : -1310.8377278645833\n",
      "    val_ess        : 3.7316322326660156\n",
      "    val_log_marginal: 1310.9638264973958\n",
      "Train Epoch: 267 [0/54000 (0%)] Loss: -1311.511597\n",
      "Train Epoch: 267 [32768/54000 (61%)] Loss: -1307.618652\n",
      "    epoch          : 267\n",
      "    loss           : -1310.0386433151532\n",
      "    ess            : 3.722227888287238\n",
      "    log_marginal   : 1310.1665384544517\n",
      "    val_loss       : -1307.5565592447917\n",
      "    val_ess        : 3.720122734705607\n",
      "    val_log_marginal: 1307.6891072591145\n",
      "Train Epoch: 268 [0/54000 (0%)] Loss: -1309.838501\n",
      "Train Epoch: 268 [32768/54000 (61%)] Loss: -1311.037842\n",
      "    epoch          : 268\n",
      "    loss           : -1310.009682709316\n",
      "    ess            : 3.7220082013112195\n",
      "    log_marginal   : 1310.139445754717\n",
      "    val_loss       : -1310.1315511067708\n",
      "    val_ess        : 3.732916752497355\n",
      "    val_log_marginal: 1310.2572021484375\n",
      "Train Epoch: 269 [0/54000 (0%)] Loss: -1314.775269\n",
      "Train Epoch: 269 [32768/54000 (61%)] Loss: -1313.620850\n",
      "    epoch          : 269\n",
      "    loss           : -1312.2261962890625\n",
      "    ess            : 3.721414665006242\n",
      "    log_marginal   : 1312.3558764187794\n",
      "    val_loss       : -1312.9086303710938\n",
      "    val_ess        : 3.727534810702006\n",
      "    val_log_marginal: 1313.0256958007812\n",
      "Train Epoch: 270 [0/54000 (0%)] Loss: -1312.475342\n",
      "Train Epoch: 270 [32768/54000 (61%)] Loss: -1310.625488\n",
      "    epoch          : 270\n",
      "    loss           : -1313.2208781692218\n",
      "    ess            : 3.715784243817599\n",
      "    log_marginal   : 1313.3532645747346\n",
      "    val_loss       : -1311.1519571940105\n",
      "    val_ess        : 3.716047763824463\n",
      "    val_log_marginal: 1311.283915201823\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch270.pth ...\n",
      "Train Epoch: 271 [0/54000 (0%)] Loss: -1313.924072\n",
      "Train Epoch: 271 [32768/54000 (61%)] Loss: -1309.422852\n",
      "    epoch          : 271\n",
      "    loss           : -1311.9934358416863\n",
      "    ess            : 3.7260117170945652\n",
      "    log_marginal   : 1312.121941332547\n",
      "    val_loss       : -1311.16552734375\n",
      "    val_ess        : 3.718355099360148\n",
      "    val_log_marginal: 1311.2935994466145\n",
      "Train Epoch: 272 [0/54000 (0%)] Loss: -1311.381836\n",
      "Train Epoch: 272 [32768/54000 (61%)] Loss: -1311.223145\n",
      "    epoch          : 272\n",
      "    loss           : -1313.6409658755897\n",
      "    ess            : 3.722017432158848\n",
      "    log_marginal   : 1313.7697892099056\n",
      "    val_loss       : -1314.001688639323\n",
      "    val_ess        : 3.7134273052215576\n",
      "    val_log_marginal: 1314.1359252929688\n",
      "Train Epoch: 273 [0/54000 (0%)] Loss: -1318.734741\n",
      "Train Epoch: 273 [32768/54000 (61%)] Loss: -1316.830566\n",
      "    epoch          : 273\n",
      "    loss           : -1315.3938494988208\n",
      "    ess            : 3.722504957666937\n",
      "    log_marginal   : 1315.523495080336\n",
      "    val_loss       : -1314.5242309570312\n",
      "    val_ess        : 3.7158040603001914\n",
      "    val_log_marginal: 1314.6561482747395\n",
      "Train Epoch: 274 [0/54000 (0%)] Loss: -1316.693604\n",
      "Train Epoch: 274 [32768/54000 (61%)] Loss: -1310.756470\n",
      "    epoch          : 274\n",
      "    loss           : -1314.4389418116157\n",
      "    ess            : 3.721147082886606\n",
      "    log_marginal   : 1314.5697159677181\n",
      "    val_loss       : -1312.291035970052\n",
      "    val_ess        : 3.710142970085144\n",
      "    val_log_marginal: 1312.4287109375\n",
      "Train Epoch: 275 [0/54000 (0%)] Loss: -1314.536377\n",
      "Train Epoch: 275 [32768/54000 (61%)] Loss: -1316.131348\n",
      "    epoch          : 275\n",
      "    loss           : -1314.8222495025059\n",
      "    ess            : 3.7153332818229243\n",
      "    log_marginal   : 1314.9568308704304\n",
      "    val_loss       : -1315.2164510091145\n",
      "    val_ess        : 3.71765398979187\n",
      "    val_log_marginal: 1315.345458984375\n",
      "Train Epoch: 276 [0/54000 (0%)] Loss: -1316.330566\n",
      "Train Epoch: 276 [32768/54000 (61%)] Loss: -1316.335571\n",
      "    epoch          : 276\n",
      "    loss           : -1316.9129270157723\n",
      "    ess            : 3.7193061585696237\n",
      "    log_marginal   : 1317.0451798349056\n",
      "    val_loss       : -1317.0378011067708\n",
      "    val_ess        : 3.7308412392934165\n",
      "    val_log_marginal: 1317.1576741536458\n",
      "Train Epoch: 277 [0/54000 (0%)] Loss: -1318.017578\n",
      "Train Epoch: 277 [32768/54000 (61%)] Loss: -1317.685181\n",
      "    epoch          : 277\n",
      "    loss           : -1317.390385465802\n",
      "    ess            : 3.7230546114579686\n",
      "    log_marginal   : 1317.5189047759434\n",
      "    val_loss       : -1315.2533772786458\n",
      "    val_ess        : 3.722825606664022\n",
      "    val_log_marginal: 1315.3902384440105\n",
      "Train Epoch: 278 [0/54000 (0%)] Loss: -1318.987305\n",
      "Train Epoch: 278 [32768/54000 (61%)] Loss: -1316.364258\n",
      "    epoch          : 278\n",
      "    loss           : -1316.3642278707252\n",
      "    ess            : 3.727054978316685\n",
      "    log_marginal   : 1316.4908769715507\n",
      "    val_loss       : -1315.8831176757812\n",
      "    val_ess        : 3.7098330656687417\n",
      "    val_log_marginal: 1316.016621907552\n",
      "Train Epoch: 279 [0/54000 (0%)] Loss: -1320.728760\n",
      "Train Epoch: 279 [32768/54000 (61%)] Loss: -1321.513428\n",
      "    epoch          : 279\n",
      "    loss           : -1318.2234024911556\n",
      "    ess            : 3.7209418764654196\n",
      "    log_marginal   : 1318.3519770784198\n",
      "    val_loss       : -1318.4863688151042\n",
      "    val_ess        : 3.720221678415934\n",
      "    val_log_marginal: 1318.6246744791667\n",
      "Train Epoch: 280 [0/54000 (0%)] Loss: -1323.337036\n",
      "Train Epoch: 280 [32768/54000 (61%)] Loss: -1315.187134\n",
      "    epoch          : 280\n",
      "    loss           : -1319.8391182377654\n",
      "    ess            : 3.7219823936246477\n",
      "    log_marginal   : 1319.9694985443691\n",
      "    val_loss       : -1318.6799926757812\n",
      "    val_ess        : 3.728402853012085\n",
      "    val_log_marginal: 1318.8104654947917\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch280.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 281 [0/54000 (0%)] Loss: -1325.756592\n",
      "Train Epoch: 281 [32768/54000 (61%)] Loss: -1317.931885\n",
      "    epoch          : 281\n",
      "    loss           : -1318.5432151938385\n",
      "    ess            : 3.7201167457508593\n",
      "    log_marginal   : 1318.6741091170402\n",
      "    val_loss       : -1316.651387532552\n",
      "    val_ess        : 3.716492454210917\n",
      "    val_log_marginal: 1316.7842203776042\n",
      "Train Epoch: 282 [0/54000 (0%)] Loss: -1321.476318\n",
      "Train Epoch: 282 [32768/54000 (61%)] Loss: -1318.168457\n",
      "    epoch          : 282\n",
      "    loss           : -1319.5890675670696\n",
      "    ess            : 3.717736451130993\n",
      "    log_marginal   : 1319.720723853921\n",
      "    val_loss       : -1319.9109700520833\n",
      "    val_ess        : 3.7135503689448037\n",
      "    val_log_marginal: 1320.0485026041667\n",
      "Train Epoch: 283 [0/54000 (0%)] Loss: -1321.007812\n",
      "Train Epoch: 283 [32768/54000 (61%)] Loss: -1321.777344\n",
      "    epoch          : 283\n",
      "    loss           : -1321.5651394826061\n",
      "    ess            : 3.7240620874009043\n",
      "    log_marginal   : 1321.691364792158\n",
      "    val_loss       : -1321.6453857421875\n",
      "    val_ess        : 3.7188319762547812\n",
      "    val_log_marginal: 1321.7775472005208\n",
      "Train Epoch: 284 [0/54000 (0%)] Loss: -1320.858276\n",
      "Train Epoch: 284 [32768/54000 (61%)] Loss: -1320.211182\n",
      "    epoch          : 284\n",
      "    loss           : -1321.3785515551297\n",
      "    ess            : 3.714323151786372\n",
      "    log_marginal   : 1321.5125525132664\n",
      "    val_loss       : -1318.9531860351562\n",
      "    val_ess        : 3.7144253253936768\n",
      "    val_log_marginal: 1319.0867513020833\n",
      "Train Epoch: 285 [0/54000 (0%)] Loss: -1321.850342\n",
      "Train Epoch: 285 [32768/54000 (61%)] Loss: -1319.734375\n",
      "    epoch          : 285\n",
      "    loss           : -1320.9475189784787\n",
      "    ess            : 3.7228101784328245\n",
      "    log_marginal   : 1321.077450158461\n",
      "    val_loss       : -1320.9705810546875\n",
      "    val_ess        : 3.7235524654388428\n",
      "    val_log_marginal: 1321.0963338216145\n",
      "Train Epoch: 286 [0/54000 (0%)] Loss: -1321.279053\n",
      "Train Epoch: 286 [32768/54000 (61%)] Loss: -1322.821777\n",
      "    epoch          : 286\n",
      "    loss           : -1322.887004348467\n",
      "    ess            : 3.7205363939393243\n",
      "    log_marginal   : 1323.0171451208726\n",
      "    val_loss       : -1323.0943603515625\n",
      "    val_ess        : 3.71584419409434\n",
      "    val_log_marginal: 1323.2255452473958\n",
      "Train Epoch: 287 [0/54000 (0%)] Loss: -1326.276611\n",
      "Train Epoch: 287 [32768/54000 (61%)] Loss: -1326.957520\n",
      "    epoch          : 287\n",
      "    loss           : -1323.8602179761203\n",
      "    ess            : 3.719789833392737\n",
      "    log_marginal   : 1323.9902044332252\n",
      "    val_loss       : -1322.0799763997395\n",
      "    val_ess        : 3.711297591527303\n",
      "    val_log_marginal: 1322.2118530273438\n",
      "Train Epoch: 288 [0/54000 (0%)] Loss: -1326.208496\n",
      "Train Epoch: 288 [32768/54000 (61%)] Loss: -1320.908936\n",
      "    epoch          : 288\n",
      "    loss           : -1322.6336808114681\n",
      "    ess            : 3.7206405648645364\n",
      "    log_marginal   : 1322.764731353184\n",
      "    val_loss       : -1321.5554606119792\n",
      "    val_ess        : 3.7233245372772217\n",
      "    val_log_marginal: 1321.6832275390625\n",
      "Train Epoch: 289 [0/54000 (0%)] Loss: -1323.817627\n",
      "Train Epoch: 289 [32768/54000 (61%)] Loss: -1323.253174\n",
      "    epoch          : 289\n",
      "    loss           : -1324.0430654849647\n",
      "    ess            : 3.718277247446888\n",
      "    log_marginal   : 1324.1747494103774\n",
      "    val_loss       : -1324.137471516927\n",
      "    val_ess        : 3.7208927472432456\n",
      "    val_log_marginal: 1324.267822265625\n",
      "Train Epoch: 290 [0/54000 (0%)] Loss: -1326.694824\n",
      "Train Epoch: 290 [32768/54000 (61%)] Loss: -1325.313232\n",
      "    epoch          : 290\n",
      "    loss           : -1325.8887432746167\n",
      "    ess            : 3.7135399917386613\n",
      "    log_marginal   : 1326.0233453714623\n",
      "    val_loss       : -1325.1641235351562\n",
      "    val_ess        : 3.7130421797434487\n",
      "    val_log_marginal: 1325.2947591145833\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch290.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 291 [0/54000 (0%)] Loss: -1327.960449\n",
      "Train Epoch: 291 [32768/54000 (61%)] Loss: -1324.572754\n",
      "    epoch          : 291\n",
      "    loss           : -1325.0369389372052\n",
      "    ess            : 3.716563161813988\n",
      "    log_marginal   : 1325.1697859854069\n",
      "    val_loss       : -1322.6702880859375\n",
      "    val_ess        : 3.7155493895212808\n",
      "    val_log_marginal: 1322.8004353841145\n",
      "Train Epoch: 292 [0/54000 (0%)] Loss: -1326.687378\n",
      "Train Epoch: 292 [32768/54000 (61%)] Loss: -1325.666992\n",
      "    epoch          : 292\n",
      "    loss           : -1325.3452171469635\n",
      "    ess            : 3.7211035422559053\n",
      "    log_marginal   : 1325.4772212190448\n",
      "    val_loss       : -1325.5712483723958\n",
      "    val_ess        : 3.7374691565831504\n",
      "    val_log_marginal: 1325.6858723958333\n",
      "Train Epoch: 293 [0/54000 (0%)] Loss: -1327.630737\n",
      "Train Epoch: 293 [32768/54000 (61%)] Loss: -1328.997559\n",
      "    epoch          : 293\n",
      "    loss           : -1327.3432317769752\n",
      "    ess            : 3.716358873079408\n",
      "    log_marginal   : 1327.4757932267098\n",
      "    val_loss       : -1327.4827880859375\n",
      "    val_ess        : 3.7262891928354898\n",
      "    val_log_marginal: 1327.6104125976562\n",
      "Train Epoch: 294 [0/54000 (0%)] Loss: -1328.422607\n",
      "Train Epoch: 294 [32768/54000 (61%)] Loss: -1326.870972\n",
      "    epoch          : 294\n",
      "    loss           : -1327.8166411777713\n",
      "    ess            : 3.7167421421914733\n",
      "    log_marginal   : 1327.9509346440154\n",
      "    val_loss       : -1325.7884928385417\n",
      "    val_ess        : 3.7071175972620645\n",
      "    val_log_marginal: 1325.9247639973958\n",
      "Train Epoch: 295 [0/54000 (0%)] Loss: -1328.636719\n",
      "Train Epoch: 295 [32768/54000 (61%)] Loss: -1325.233643\n",
      "    epoch          : 295\n",
      "    loss           : -1326.957701485112\n",
      "    ess            : 3.7182384347015955\n",
      "    log_marginal   : 1327.090046432783\n",
      "    val_loss       : -1326.1521809895833\n",
      "    val_ess        : 3.713356137275696\n",
      "    val_log_marginal: 1326.285868326823\n",
      "Train Epoch: 296 [0/54000 (0%)] Loss: -1328.162964\n",
      "Train Epoch: 296 [32768/54000 (61%)] Loss: -1330.657959\n",
      "    epoch          : 296\n",
      "    loss           : -1328.5401749520931\n",
      "    ess            : 3.71644759628008\n",
      "    log_marginal   : 1328.6738004864387\n",
      "    val_loss       : -1328.56982421875\n",
      "    val_ess        : 3.7186423540115356\n",
      "    val_log_marginal: 1328.698954264323\n",
      "Train Epoch: 297 [0/54000 (0%)] Loss: -1333.143799\n",
      "Train Epoch: 297 [32768/54000 (61%)] Loss: -1330.050781\n",
      "    epoch          : 297\n",
      "    loss           : -1329.9141062610554\n",
      "    ess            : 3.7147960302964695\n",
      "    log_marginal   : 1330.0481026127654\n",
      "    val_loss       : -1328.644287109375\n",
      "    val_ess        : 3.720163861910502\n",
      "    val_log_marginal: 1328.7792154947917\n",
      "Train Epoch: 298 [0/54000 (0%)] Loss: -1330.441650\n",
      "Train Epoch: 298 [32768/54000 (61%)] Loss: -1329.013184\n",
      "    epoch          : 298\n",
      "    loss           : -1329.000997291421\n",
      "    ess            : 3.7173245717894354\n",
      "    log_marginal   : 1329.1320455299233\n",
      "    val_loss       : -1327.2645670572917\n",
      "    val_ess        : 3.7284138600031533\n",
      "    val_log_marginal: 1327.395528157552\n",
      "Train Epoch: 299 [0/54000 (0%)] Loss: -1328.707764\n",
      "Train Epoch: 299 [32768/54000 (61%)] Loss: -1331.859009\n",
      "    epoch          : 299\n",
      "    loss           : -1329.4548455004422\n",
      "    ess            : 3.716067966425194\n",
      "    log_marginal   : 1329.5866561025944\n",
      "    val_loss       : -1329.442138671875\n",
      "    val_ess        : 3.7185453176498413\n",
      "    val_log_marginal: 1329.5764973958333\n",
      "Train Epoch: 300 [0/54000 (0%)] Loss: -1331.981201\n",
      "Train Epoch: 300 [32768/54000 (61%)] Loss: -1333.880859\n",
      "    epoch          : 300\n",
      "    loss           : -1331.5536257186027\n",
      "    ess            : 3.71495033660025\n",
      "    log_marginal   : 1331.6869564416274\n",
      "    val_loss       : -1331.078857421875\n",
      "    val_ess        : 3.708663066228231\n",
      "    val_log_marginal: 1331.218485514323\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch300.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 301 [0/54000 (0%)] Loss: -1334.102173\n",
      "Train Epoch: 301 [32768/54000 (61%)] Loss: -1331.255127\n",
      "    epoch          : 301\n",
      "    loss           : -1331.6281415831368\n",
      "    ess            : 3.7164915822586924\n",
      "    log_marginal   : 1331.7605671432782\n",
      "    val_loss       : -1329.1795043945312\n",
      "    val_ess        : 3.7438798745473227\n",
      "    val_log_marginal: 1329.294921875\n",
      "Train Epoch: 302 [0/54000 (0%)] Loss: -1331.020752\n",
      "Train Epoch: 302 [32768/54000 (61%)] Loss: -1331.087402\n",
      "    epoch          : 302\n",
      "    loss           : -1330.793295806309\n",
      "    ess            : 3.7163040323077507\n",
      "    log_marginal   : 1330.9267094450177\n",
      "    val_loss       : -1330.4296061197917\n",
      "    val_ess        : 3.7028497060139975\n",
      "    val_log_marginal: 1330.574462890625\n",
      "Train Epoch: 303 [0/54000 (0%)] Loss: -1335.172119\n",
      "Train Epoch: 303 [32768/54000 (61%)] Loss: -1331.187622\n",
      "    epoch          : 303\n",
      "    loss           : -1332.6208680350826\n",
      "    ess            : 3.723691409488894\n",
      "    log_marginal   : 1332.7502165020637\n",
      "    val_loss       : -1333.129374186198\n",
      "    val_ess        : 3.7255062659581504\n",
      "    val_log_marginal: 1333.252217610677\n",
      "Train Epoch: 304 [0/54000 (0%)] Loss: -1334.245850\n",
      "Train Epoch: 304 [32768/54000 (61%)] Loss: -1335.227417\n",
      "    epoch          : 304\n",
      "    loss           : -1333.9143665241745\n",
      "    ess            : 3.7178903030899337\n",
      "    log_marginal   : 1334.0452558409493\n",
      "    val_loss       : -1332.3843180338542\n",
      "    val_ess        : 3.7232662041982016\n",
      "    val_log_marginal: 1332.5075073242188\n",
      "Train Epoch: 305 [0/54000 (0%)] Loss: -1332.767334\n",
      "Train Epoch: 305 [32768/54000 (61%)] Loss: -1331.984863\n",
      "    epoch          : 305\n",
      "    loss           : -1332.8808893167748\n",
      "    ess            : 3.715330825661713\n",
      "    log_marginal   : 1333.0161777712265\n",
      "    val_loss       : -1331.6994222005208\n",
      "    val_ess        : 3.725738525390625\n",
      "    val_log_marginal: 1331.8244222005208\n",
      "Train Epoch: 306 [0/54000 (0%)] Loss: -1336.044678\n",
      "Train Epoch: 306 [32768/54000 (61%)] Loss: -1334.970947\n",
      "    epoch          : 306\n",
      "    loss           : -1334.095905807783\n",
      "    ess            : 3.716065528257838\n",
      "    log_marginal   : 1334.2281494140625\n",
      "    val_loss       : -1334.0904337565105\n",
      "    val_ess        : 3.7137537797292075\n",
      "    val_log_marginal: 1334.2239786783855\n",
      "Train Epoch: 307 [0/54000 (0%)] Loss: -1335.313599\n",
      "Train Epoch: 307 [32768/54000 (61%)] Loss: -1336.126709\n",
      "    epoch          : 307\n",
      "    loss           : -1335.5428604989681\n",
      "    ess            : 3.711060532983744\n",
      "    log_marginal   : 1335.6784829193691\n",
      "    val_loss       : -1335.3831380208333\n",
      "    val_ess        : 3.7145838340123496\n",
      "    val_log_marginal: 1335.5149739583333\n",
      "Train Epoch: 308 [0/54000 (0%)] Loss: -1337.963623\n",
      "Train Epoch: 308 [32768/54000 (61%)] Loss: -1332.928711\n",
      "    epoch          : 308\n",
      "    loss           : -1335.2209702977593\n",
      "    ess            : 3.7079817079148203\n",
      "    log_marginal   : 1335.3565305313973\n",
      "    val_loss       : -1333.2985229492188\n",
      "    val_ess        : 3.7290279865264893\n",
      "    val_log_marginal: 1333.41796875\n",
      "Train Epoch: 309 [0/54000 (0%)] Loss: -1335.117676\n",
      "Train Epoch: 309 [32768/54000 (61%)] Loss: -1330.896118\n",
      "    epoch          : 309\n",
      "    loss           : -1335.0369136018573\n",
      "    ess            : 3.7166510258080825\n",
      "    log_marginal   : 1335.167439010908\n",
      "    val_loss       : -1334.7110595703125\n",
      "    val_ess        : 3.714687983194987\n",
      "    val_log_marginal: 1334.8455403645833\n",
      "Train Epoch: 310 [0/54000 (0%)] Loss: -1339.851074\n",
      "Train Epoch: 310 [32768/54000 (61%)] Loss: -1337.440308\n",
      "    epoch          : 310\n",
      "    loss           : -1336.8561090433373\n",
      "    ess            : 3.7166231443297186\n",
      "    log_marginal   : 1336.9873852999706\n",
      "    val_loss       : -1336.7048746744792\n",
      "    val_ess        : 3.714482386906942\n",
      "    val_log_marginal: 1336.8348999023438\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch310.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 311 [0/54000 (0%)] Loss: -1339.733154\n",
      "Train Epoch: 311 [32768/54000 (61%)] Loss: -1335.858398\n",
      "    epoch          : 311\n",
      "    loss           : -1337.6303273326946\n",
      "    ess            : 3.709755911017364\n",
      "    log_marginal   : 1337.7678452977593\n",
      "    val_loss       : -1335.7415568033855\n",
      "    val_ess        : 3.7081218163172402\n",
      "    val_log_marginal: 1335.8795572916667\n",
      "Train Epoch: 312 [0/54000 (0%)] Loss: -1336.648682\n",
      "Train Epoch: 312 [32768/54000 (61%)] Loss: -1337.793579\n",
      "    epoch          : 312\n",
      "    loss           : -1336.8349885760613\n",
      "    ess            : 3.7176268100738525\n",
      "    log_marginal   : 1336.9672943691037\n",
      "    val_loss       : -1335.5701904296875\n",
      "    val_ess        : 3.7207981745402017\n",
      "    val_log_marginal: 1335.7062581380208\n",
      "Train Epoch: 313 [0/54000 (0%)] Loss: -1337.799194\n",
      "Train Epoch: 313 [32768/54000 (61%)] Loss: -1340.677490\n",
      "    epoch          : 313\n",
      "    loss           : -1337.896355395047\n",
      "    ess            : 3.715419796277892\n",
      "    log_marginal   : 1338.0294696160083\n",
      "    val_loss       : -1337.4441324869792\n",
      "    val_ess        : 3.716855843861898\n",
      "    val_log_marginal: 1337.5699259440105\n",
      "Train Epoch: 314 [0/54000 (0%)] Loss: -1339.518555\n",
      "Train Epoch: 314 [32768/54000 (61%)] Loss: -1340.230469\n",
      "    epoch          : 314\n",
      "    loss           : -1339.4304222250885\n",
      "    ess            : 3.710575148744403\n",
      "    log_marginal   : 1339.565611641362\n",
      "    val_loss       : -1338.5610758463542\n",
      "    val_ess        : 3.716625928878784\n",
      "    val_log_marginal: 1338.7063395182292\n",
      "Train Epoch: 315 [0/54000 (0%)] Loss: -1339.415527\n",
      "Train Epoch: 315 [32768/54000 (61%)] Loss: -1339.529541\n",
      "    epoch          : 315\n",
      "    loss           : -1339.3280305682488\n",
      "    ess            : 3.717811215598628\n",
      "    log_marginal   : 1339.458012418927\n",
      "    val_loss       : -1336.706298828125\n",
      "    val_ess        : 3.7188490629196167\n",
      "    val_log_marginal: 1336.8365478515625\n",
      "Train Epoch: 316 [0/54000 (0%)] Loss: -1340.518799\n",
      "Train Epoch: 316 [32768/54000 (61%)] Loss: -1339.335449\n",
      "    epoch          : 316\n",
      "    loss           : -1338.969560731132\n",
      "    ess            : 3.709639733692385\n",
      "    log_marginal   : 1339.1065788988797\n",
      "    val_loss       : -1338.5538533528645\n",
      "    val_ess        : 3.716840664545695\n",
      "    val_log_marginal: 1338.6873982747395\n",
      "Train Epoch: 317 [0/54000 (0%)] Loss: -1340.351318\n",
      "Train Epoch: 317 [32768/54000 (61%)] Loss: -1340.371338\n",
      "    epoch          : 317\n",
      "    loss           : -1340.701395286704\n",
      "    ess            : 3.7161813861918898\n",
      "    log_marginal   : 1340.834170935289\n",
      "    val_loss       : -1340.3883666992188\n",
      "    val_ess        : 3.7053322792053223\n",
      "    val_log_marginal: 1340.5302734375\n",
      "Train Epoch: 318 [0/54000 (0%)] Loss: -1342.648193\n",
      "Train Epoch: 318 [32768/54000 (61%)] Loss: -1340.661133\n",
      "    epoch          : 318\n",
      "    loss           : -1341.5502837558963\n",
      "    ess            : 3.7146407433275908\n",
      "    log_marginal   : 1341.6857380417157\n",
      "    val_loss       : -1339.8828125\n",
      "    val_ess        : 3.69709849357605\n",
      "    val_log_marginal: 1340.0297444661458\n",
      "Train Epoch: 319 [0/54000 (0%)] Loss: -1342.410645\n",
      "Train Epoch: 319 [32768/54000 (61%)] Loss: -1339.913330\n",
      "    epoch          : 319\n",
      "    loss           : -1340.6527099609375\n",
      "    ess            : 3.7167921786038383\n",
      "    log_marginal   : 1340.7832514924823\n",
      "    val_loss       : -1339.2830810546875\n",
      "    val_ess        : 3.7144825061162314\n",
      "    val_log_marginal: 1339.421162923177\n",
      "Train Epoch: 320 [0/54000 (0%)] Loss: -1338.411133\n",
      "Train Epoch: 320 [32768/54000 (61%)] Loss: -1343.593018\n",
      "    epoch          : 320\n",
      "    loss           : -1341.7820929761203\n",
      "    ess            : 3.713856670091737\n",
      "    log_marginal   : 1341.9178374668338\n",
      "    val_loss       : -1341.5413004557292\n",
      "    val_ess        : 3.7223411401112876\n",
      "    val_log_marginal: 1341.66748046875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch320.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 321 [0/54000 (0%)] Loss: -1343.532227\n",
      "Train Epoch: 321 [32768/54000 (61%)] Loss: -1341.678711\n",
      "    epoch          : 321\n",
      "    loss           : -1343.2090580778302\n",
      "    ess            : 3.7132801694690056\n",
      "    log_marginal   : 1343.3413385355248\n",
      "    val_loss       : -1342.5233968098958\n",
      "    val_ess        : 3.7267225980758667\n",
      "    val_log_marginal: 1342.645751953125\n",
      "Train Epoch: 322 [0/54000 (0%)] Loss: -1344.385010\n",
      "Train Epoch: 322 [32768/54000 (61%)] Loss: -1345.303467\n",
      "    epoch          : 322\n",
      "    loss           : -1342.9037763487618\n",
      "    ess            : 3.715183190579684\n",
      "    log_marginal   : 1343.0370955557194\n",
      "    val_loss       : -1340.7362670898438\n",
      "    val_ess        : 3.7098276217778525\n",
      "    val_log_marginal: 1340.8677164713542\n",
      "Train Epoch: 323 [0/54000 (0%)] Loss: -1342.827148\n",
      "Train Epoch: 323 [32768/54000 (61%)] Loss: -1341.213379\n",
      "    epoch          : 323\n",
      "    loss           : -1342.9466806087853\n",
      "    ess            : 3.7174566826730406\n",
      "    log_marginal   : 1343.0796865787147\n",
      "    val_loss       : -1342.1869303385417\n",
      "    val_ess        : 3.7019407749176025\n",
      "    val_log_marginal: 1342.3285522460938\n",
      "Train Epoch: 324 [0/54000 (0%)] Loss: -1346.102539\n",
      "Train Epoch: 324 [32768/54000 (61%)] Loss: -1345.200562\n",
      "    epoch          : 324\n",
      "    loss           : -1344.5428604989681\n",
      "    ess            : 3.7141650757699645\n",
      "    log_marginal   : 1344.677361254422\n",
      "    val_loss       : -1344.344706217448\n",
      "    val_ess        : 3.7192105054855347\n",
      "    val_log_marginal: 1344.47021484375\n",
      "Train Epoch: 325 [0/54000 (0%)] Loss: -1347.121094\n",
      "Train Epoch: 325 [32768/54000 (61%)] Loss: -1339.704102\n",
      "    epoch          : 325\n",
      "    loss           : -1345.2465889408904\n",
      "    ess            : 3.718962453446298\n",
      "    log_marginal   : 1345.3762644641804\n",
      "    val_loss       : -1343.5878295898438\n",
      "    val_ess        : 3.720056494077047\n",
      "    val_log_marginal: 1343.719217936198\n",
      "Train Epoch: 326 [0/54000 (0%)] Loss: -1346.862061\n",
      "Train Epoch: 326 [32768/54000 (61%)] Loss: -1345.659424\n",
      "    epoch          : 326\n",
      "    loss           : -1344.3770867113797\n",
      "    ess            : 3.7168787200495883\n",
      "    log_marginal   : 1344.5098876953125\n",
      "    val_loss       : -1343.2581583658855\n",
      "    val_ess        : 3.718215505282084\n",
      "    val_log_marginal: 1343.385009765625\n",
      "Train Epoch: 327 [0/54000 (0%)] Loss: -1343.743652\n",
      "Train Epoch: 327 [32768/54000 (61%)] Loss: -1346.739502\n",
      "    epoch          : 327\n",
      "    loss           : -1345.6635880380306\n",
      "    ess            : 3.7145596135337398\n",
      "    log_marginal   : 1345.7948113207547\n",
      "    val_loss       : -1344.9834594726562\n",
      "    val_ess        : 3.7086743911107383\n",
      "    val_log_marginal: 1345.125956217448\n",
      "Train Epoch: 328 [0/54000 (0%)] Loss: -1348.337158\n",
      "Train Epoch: 328 [32768/54000 (61%)] Loss: -1345.393188\n",
      "    epoch          : 328\n",
      "    loss           : -1346.8826443654186\n",
      "    ess            : 3.718472611229375\n",
      "    log_marginal   : 1347.0114630933078\n",
      "    val_loss       : -1345.7145182291667\n",
      "    val_ess        : 3.709647258122762\n",
      "    val_log_marginal: 1345.8526000976562\n",
      "Train Epoch: 329 [0/54000 (0%)] Loss: -1348.428467\n",
      "Train Epoch: 329 [32768/54000 (61%)] Loss: -1346.885010\n",
      "    epoch          : 329\n",
      "    loss           : -1346.5477824660968\n",
      "    ess            : 3.7195195431979196\n",
      "    log_marginal   : 1346.6784598872346\n",
      "    val_loss       : -1344.7334391276042\n",
      "    val_ess        : 3.72316304842631\n",
      "    val_log_marginal: 1344.8573608398438\n",
      "Train Epoch: 330 [0/54000 (0%)] Loss: -1345.155273\n",
      "Train Epoch: 330 [32768/54000 (61%)] Loss: -1345.862671\n",
      "    epoch          : 330\n",
      "    loss           : -1346.6738557635613\n",
      "    ess            : 3.7138220364192747\n",
      "    log_marginal   : 1346.8043305019162\n",
      "    val_loss       : -1346.3448893229167\n",
      "    val_ess        : 3.7391355832417807\n",
      "    val_log_marginal: 1346.4695841471355\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch330.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 331 [0/54000 (0%)] Loss: -1348.487549\n",
      "Train Epoch: 331 [32768/54000 (61%)] Loss: -1345.305298\n",
      "    epoch          : 331\n",
      "    loss           : -1348.2348149137677\n",
      "    ess            : 3.7197308720282787\n",
      "    log_marginal   : 1348.367182893573\n",
      "    val_loss       : -1347.9280802408855\n",
      "    val_ess        : 3.724245071411133\n",
      "    val_log_marginal: 1348.0616251627605\n",
      "Train Epoch: 332 [0/54000 (0%)] Loss: -1349.760864\n",
      "Train Epoch: 332 [32768/54000 (61%)] Loss: -1350.204224\n",
      "    epoch          : 332\n",
      "    loss           : -1348.6899920769458\n",
      "    ess            : 3.7213890822428577\n",
      "    log_marginal   : 1348.820473724941\n",
      "    val_loss       : -1346.9747314453125\n",
      "    val_ess        : 3.7141777674357095\n",
      "    val_log_marginal: 1347.1112670898438\n",
      "Train Epoch: 333 [0/54000 (0%)] Loss: -1348.024170\n",
      "Train Epoch: 333 [32768/54000 (61%)] Loss: -1346.735840\n",
      "    epoch          : 333\n",
      "    loss           : -1348.014768204599\n",
      "    ess            : 3.718385138601627\n",
      "    log_marginal   : 1348.1440982458726\n",
      "    val_loss       : -1346.9225056966145\n",
      "    val_ess        : 3.7105712890625\n",
      "    val_log_marginal: 1347.056396484375\n",
      "Train Epoch: 334 [0/54000 (0%)] Loss: -1348.642334\n",
      "Train Epoch: 334 [32768/54000 (61%)] Loss: -1351.226318\n",
      "    epoch          : 334\n",
      "    loss           : -1349.1028269641804\n",
      "    ess            : 3.71668090010589\n",
      "    log_marginal   : 1349.235653283461\n",
      "    val_loss       : -1348.9832356770833\n",
      "    val_ess        : 3.7072407007217407\n",
      "    val_log_marginal: 1349.1197916666667\n",
      "Train Epoch: 335 [0/54000 (0%)] Loss: -1352.608276\n",
      "Train Epoch: 335 [32768/54000 (61%)] Loss: -1349.513550\n",
      "    epoch          : 335\n",
      "    loss           : -1350.2207791310436\n",
      "    ess            : 3.716357226641673\n",
      "    log_marginal   : 1350.3514887971698\n",
      "    val_loss       : -1349.3777872721355\n",
      "    val_ess        : 3.7012035051981607\n",
      "    val_log_marginal: 1349.5279337565105\n",
      "Train Epoch: 336 [0/54000 (0%)] Loss: -1349.292236\n",
      "Train Epoch: 336 [32768/54000 (61%)] Loss: -1353.348877\n",
      "    epoch          : 336\n",
      "    loss           : -1349.9498037662147\n",
      "    ess            : 3.717183810360027\n",
      "    log_marginal   : 1350.0825057119694\n",
      "    val_loss       : -1348.2750244140625\n",
      "    val_ess        : 3.7149327198664346\n",
      "    val_log_marginal: 1348.4129638671875\n",
      "Train Epoch: 337 [0/54000 (0%)] Loss: -1348.815674\n",
      "Train Epoch: 337 [32768/54000 (61%)] Loss: -1350.953613\n",
      "    epoch          : 337\n",
      "    loss           : -1350.1830087337853\n",
      "    ess            : 3.7134704139997377\n",
      "    log_marginal   : 1350.3159663362323\n",
      "    val_loss       : -1349.9435628255208\n",
      "    val_ess        : 3.7248868147532144\n",
      "    val_log_marginal: 1350.0743001302083\n",
      "Train Epoch: 338 [0/54000 (0%)] Loss: -1352.723022\n",
      "Train Epoch: 338 [32768/54000 (61%)] Loss: -1350.541748\n",
      "    epoch          : 338\n",
      "    loss           : -1351.6228464954304\n",
      "    ess            : 3.716111952403806\n",
      "    log_marginal   : 1351.7559054392689\n",
      "    val_loss       : -1351.1302693684895\n",
      "    val_ess        : 3.7235835790634155\n",
      "    val_log_marginal: 1351.2623291015625\n",
      "Train Epoch: 339 [0/54000 (0%)] Loss: -1353.783203\n",
      "Train Epoch: 339 [32768/54000 (61%)] Loss: -1352.691895\n",
      "    epoch          : 339\n",
      "    loss           : -1352.1269370025059\n",
      "    ess            : 3.714646240450301\n",
      "    log_marginal   : 1352.2587568175118\n",
      "    val_loss       : -1350.3148803710938\n",
      "    val_ess        : 3.713767131169637\n",
      "    val_log_marginal: 1350.4542439778645\n",
      "Train Epoch: 340 [0/54000 (0%)] Loss: -1354.223145\n",
      "Train Epoch: 340 [32768/54000 (61%)] Loss: -1351.114380\n",
      "    epoch          : 340\n",
      "    loss           : -1351.691717183815\n",
      "    ess            : 3.7142460796068297\n",
      "    log_marginal   : 1351.8266509433963\n",
      "    val_loss       : -1350.5313313802083\n",
      "    val_ess        : 3.716639677683512\n",
      "    val_log_marginal: 1350.665059407552\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch340.pth ...\n",
      "Train Epoch: 341 [0/54000 (0%)] Loss: -1354.275879\n",
      "Train Epoch: 341 [32768/54000 (61%)] Loss: -1351.480957\n",
      "    epoch          : 341\n",
      "    loss           : -1352.651056253685\n",
      "    ess            : 3.714523625823687\n",
      "    log_marginal   : 1352.7837374705189\n",
      "    val_loss       : -1352.2509358723958\n",
      "    val_ess        : 3.727246363957723\n",
      "    val_log_marginal: 1352.3819580078125\n",
      "Train Epoch: 342 [0/54000 (0%)] Loss: -1356.471924\n",
      "Train Epoch: 342 [32768/54000 (61%)] Loss: -1352.190796\n",
      "    epoch          : 342\n",
      "    loss           : -1353.7033299859966\n",
      "    ess            : 3.7123974899076067\n",
      "    log_marginal   : 1353.8413454451652\n",
      "    val_loss       : -1353.17626953125\n",
      "    val_ess        : 3.709777037302653\n",
      "    val_log_marginal: 1353.312276204427\n",
      "Train Epoch: 343 [0/54000 (0%)] Loss: -1353.267090\n",
      "Train Epoch: 343 [32768/54000 (61%)] Loss: -1353.990234\n",
      "    epoch          : 343\n",
      "    loss           : -1353.3504845961086\n",
      "    ess            : 3.7145360325867274\n",
      "    log_marginal   : 1353.4849715322819\n",
      "    val_loss       : -1351.7655639648438\n",
      "    val_ess        : 3.712422728538513\n",
      "    val_log_marginal: 1351.9024861653645\n",
      "Train Epoch: 344 [0/54000 (0%)] Loss: -1354.874146\n",
      "Train Epoch: 344 [32768/54000 (61%)] Loss: -1355.463135\n",
      "    epoch          : 344\n",
      "    loss           : -1353.5612539615272\n",
      "    ess            : 3.7168789044866024\n",
      "    log_marginal   : 1353.69468372273\n",
      "    val_loss       : -1353.2633870442708\n",
      "    val_ess        : 3.7168466647466025\n",
      "    val_log_marginal: 1353.3917032877605\n",
      "Train Epoch: 345 [0/54000 (0%)] Loss: -1354.880859\n",
      "Train Epoch: 345 [32768/54000 (61%)] Loss: -1354.948242\n",
      "    epoch          : 345\n",
      "    loss           : -1354.9110729289505\n",
      "    ess            : 3.713801527923008\n",
      "    log_marginal   : 1355.0458984375\n",
      "    val_loss       : -1354.9436848958333\n",
      "    val_ess        : 3.710780660311381\n",
      "    val_log_marginal: 1355.08056640625\n",
      "Train Epoch: 346 [0/54000 (0%)] Loss: -1357.039795\n",
      "Train Epoch: 346 [32768/54000 (61%)] Loss: -1353.408936\n",
      "    epoch          : 346\n",
      "    loss           : -1355.4408626916274\n",
      "    ess            : 3.72049277683474\n",
      "    log_marginal   : 1355.571173901828\n",
      "    val_loss       : -1353.6662190755208\n",
      "    val_ess        : 3.7182991902033486\n",
      "    val_log_marginal: 1353.8058675130208\n",
      "Train Epoch: 347 [0/54000 (0%)] Loss: -1352.352539\n",
      "Train Epoch: 347 [32768/54000 (61%)] Loss: -1355.140869\n",
      "    epoch          : 347\n",
      "    loss           : -1354.8810735738502\n",
      "    ess            : 3.721153533683633\n",
      "    log_marginal   : 1355.012534087559\n",
      "    val_loss       : -1353.6339925130208\n",
      "    val_ess        : 3.7176260153452554\n",
      "    val_log_marginal: 1353.7672526041667\n",
      "Train Epoch: 348 [0/54000 (0%)] Loss: -1356.581299\n",
      "Train Epoch: 348 [32768/54000 (61%)] Loss: -1352.268555\n",
      "    epoch          : 348\n",
      "    loss           : -1355.7906240787147\n",
      "    ess            : 3.7152888459979363\n",
      "    log_marginal   : 1355.923765938237\n",
      "    val_loss       : -1355.6449584960938\n",
      "    val_ess        : 3.710956891377767\n",
      "    val_log_marginal: 1355.786865234375\n",
      "Train Epoch: 349 [0/54000 (0%)] Loss: -1359.186279\n",
      "Train Epoch: 349 [32768/54000 (61%)] Loss: -1356.576416\n",
      "    epoch          : 349\n",
      "    loss           : -1357.1593915831368\n",
      "    ess            : 3.719091042032782\n",
      "    log_marginal   : 1357.2910662956958\n",
      "    val_loss       : -1356.0752766927083\n",
      "    val_ess        : 3.7075491746266684\n",
      "    val_log_marginal: 1356.2224527994792\n",
      "Train Epoch: 350 [0/54000 (0%)] Loss: -1358.185791\n",
      "Train Epoch: 350 [32768/54000 (61%)] Loss: -1355.305542\n",
      "    epoch          : 350\n",
      "    loss           : -1356.8580414394162\n",
      "    ess            : 3.7158725126734318\n",
      "    log_marginal   : 1356.9895733527417\n",
      "    val_loss       : -1355.0321858723958\n",
      "    val_ess        : 3.717953085899353\n",
      "    val_log_marginal: 1355.1624552408855\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch350.pth ...\n",
      "Train Epoch: 351 [0/54000 (0%)] Loss: -1360.042725\n",
      "Train Epoch: 351 [32768/54000 (61%)] Loss: -1356.933350\n",
      "    epoch          : 351\n",
      "    loss           : -1356.668192161704\n",
      "    ess            : 3.718205447466868\n",
      "    log_marginal   : 1356.800723669664\n",
      "    val_loss       : -1356.4135131835938\n",
      "    val_ess        : 3.7246530453364053\n",
      "    val_log_marginal: 1356.5437825520833\n",
      "Train Epoch: 352 [0/54000 (0%)] Loss: -1362.173218\n",
      "Train Epoch: 352 [32768/54000 (61%)] Loss: -1356.237671\n",
      "    epoch          : 352\n",
      "    loss           : -1358.1811408276828\n",
      "    ess            : 3.7138614159710004\n",
      "    log_marginal   : 1358.315190153302\n",
      "    val_loss       : -1357.7511393229167\n",
      "    val_ess        : 3.712653636932373\n",
      "    val_log_marginal: 1357.8902180989583\n",
      "Train Epoch: 353 [0/54000 (0%)] Loss: -1360.983887\n",
      "Train Epoch: 353 [32768/54000 (61%)] Loss: -1359.050781\n",
      "    epoch          : 353\n",
      "    loss           : -1358.7172160598468\n",
      "    ess            : 3.7193124474219554\n",
      "    log_marginal   : 1358.849250073703\n",
      "    val_loss       : -1357.299560546875\n",
      "    val_ess        : 3.7137778600056968\n",
      "    val_log_marginal: 1357.4498901367188\n",
      "Train Epoch: 354 [0/54000 (0%)] Loss: -1358.734375\n",
      "Train Epoch: 354 [32768/54000 (61%)] Loss: -1357.222046\n",
      "    epoch          : 354\n",
      "    loss           : -1358.0641813458137\n",
      "    ess            : 3.718947815445234\n",
      "    log_marginal   : 1358.1930968086674\n",
      "    val_loss       : -1357.0020141601562\n",
      "    val_ess        : 3.7279388904571533\n",
      "    val_log_marginal: 1357.1226196289062\n",
      "Train Epoch: 355 [0/54000 (0%)] Loss: -1361.682861\n",
      "Train Epoch: 355 [32768/54000 (61%)] Loss: -1358.707275\n",
      "    epoch          : 355\n",
      "    loss           : -1358.8628920069282\n",
      "    ess            : 3.7154303586707926\n",
      "    log_marginal   : 1358.9937582915684\n",
      "    val_loss       : -1358.7508341471355\n",
      "    val_ess        : 3.7097767988840737\n",
      "    val_log_marginal: 1358.8822428385417\n",
      "Train Epoch: 356 [0/54000 (0%)] Loss: -1362.898438\n",
      "Train Epoch: 356 [32768/54000 (61%)] Loss: -1361.244873\n",
      "    epoch          : 356\n",
      "    loss           : -1360.2137082657723\n",
      "    ess            : 3.716193239643889\n",
      "    log_marginal   : 1360.3482965433373\n",
      "    val_loss       : -1359.5282796223958\n",
      "    val_ess        : 3.7205379406611123\n",
      "    val_log_marginal: 1359.6667887369792\n",
      "Train Epoch: 357 [0/54000 (0%)] Loss: -1362.436890\n",
      "Train Epoch: 357 [32768/54000 (61%)] Loss: -1357.700562\n",
      "    epoch          : 357\n",
      "    loss           : -1360.0890813863502\n",
      "    ess            : 3.715751926853972\n",
      "    log_marginal   : 1360.2251252948113\n",
      "    val_loss       : -1358.1974690755208\n",
      "    val_ess        : 3.7091451485951743\n",
      "    val_log_marginal: 1358.3353881835938\n",
      "Train Epoch: 358 [0/54000 (0%)] Loss: -1359.473145\n",
      "Train Epoch: 358 [32768/54000 (61%)] Loss: -1360.179810\n",
      "    epoch          : 358\n",
      "    loss           : -1359.637368256191\n",
      "    ess            : 3.710814251089996\n",
      "    log_marginal   : 1359.7741883475826\n",
      "    val_loss       : -1358.993876139323\n",
      "    val_ess        : 3.725215435028076\n",
      "    val_log_marginal: 1359.1183675130208\n",
      "Train Epoch: 359 [0/54000 (0%)] Loss: -1361.971802\n",
      "Train Epoch: 359 [32768/54000 (61%)] Loss: -1363.299805\n",
      "    epoch          : 359\n",
      "    loss           : -1361.1180051407723\n",
      "    ess            : 3.719598851113949\n",
      "    log_marginal   : 1361.2518725125294\n",
      "    val_loss       : -1360.871317545573\n",
      "    val_ess        : 3.7249199946721396\n",
      "    val_log_marginal: 1361.002665201823\n",
      "Train Epoch: 360 [0/54000 (0%)] Loss: -1360.952148\n",
      "Train Epoch: 360 [32768/54000 (61%)] Loss: -1363.194336\n",
      "    epoch          : 360\n",
      "    loss           : -1361.8094159971993\n",
      "    ess            : 3.714923323325391\n",
      "    log_marginal   : 1361.9438983269458\n",
      "    val_loss       : -1360.2954508463542\n",
      "    val_ess        : 3.7199670871098838\n",
      "    val_log_marginal: 1360.4186401367188\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch360.pth ...\n",
      "Train Epoch: 361 [0/54000 (0%)] Loss: -1360.898193\n",
      "Train Epoch: 361 [32768/54000 (61%)] Loss: -1360.014648\n",
      "    epoch          : 361\n",
      "    loss           : -1361.2066143683667\n",
      "    ess            : 3.7162116338621893\n",
      "    log_marginal   : 1361.3417738428657\n",
      "    val_loss       : -1359.9830118815105\n",
      "    val_ess        : 3.724614898363749\n",
      "    val_log_marginal: 1360.1173909505208\n",
      "Train Epoch: 362 [0/54000 (0%)] Loss: -1360.653809\n",
      "Train Epoch: 362 [32768/54000 (61%)] Loss: -1360.622192\n",
      "    epoch          : 362\n",
      "    loss           : -1361.8598195201946\n",
      "    ess            : 3.7158878029517406\n",
      "    log_marginal   : 1361.99309726931\n",
      "    val_loss       : -1361.7060139973958\n",
      "    val_ess        : 3.7197213570276895\n",
      "    val_log_marginal: 1361.8351440429688\n",
      "Train Epoch: 363 [0/54000 (0%)] Loss: -1363.901123\n",
      "Train Epoch: 363 [32768/54000 (61%)] Loss: -1362.672974\n",
      "    epoch          : 363\n",
      "    loss           : -1363.1450310473172\n",
      "    ess            : 3.715026617050171\n",
      "    log_marginal   : 1363.2787441037735\n",
      "    val_loss       : -1362.2000935872395\n",
      "    val_ess        : 3.713275750478109\n",
      "    val_log_marginal: 1362.3299560546875\n",
      "Train Epoch: 364 [0/54000 (0%)] Loss: -1363.173096\n",
      "Train Epoch: 364 [32768/54000 (61%)] Loss: -1365.817383\n",
      "    epoch          : 364\n",
      "    loss           : -1363.1424906028892\n",
      "    ess            : 3.719403617786911\n",
      "    log_marginal   : 1363.2734121646522\n",
      "    val_loss       : -1361.2249959309895\n",
      "    val_ess        : 3.7144739230473838\n",
      "    val_log_marginal: 1361.362813313802\n",
      "Train Epoch: 365 [0/54000 (0%)] Loss: -1360.090332\n",
      "Train Epoch: 365 [32768/54000 (61%)] Loss: -1360.744751\n",
      "    epoch          : 365\n",
      "    loss           : -1362.8792724609375\n",
      "    ess            : 3.7154677678953925\n",
      "    log_marginal   : 1363.0122507923054\n",
      "    val_loss       : -1362.4319254557292\n",
      "    val_ess        : 3.7114411989847818\n",
      "    val_log_marginal: 1362.577372233073\n",
      "Train Epoch: 366 [0/54000 (0%)] Loss: -1364.984497\n",
      "Train Epoch: 366 [32768/54000 (61%)] Loss: -1363.102417\n",
      "    epoch          : 366\n",
      "    loss           : -1364.0060850899174\n",
      "    ess            : 3.7181627255565717\n",
      "    log_marginal   : 1364.1388630417157\n",
      "    val_loss       : -1363.76416015625\n",
      "    val_ess        : 3.7191898425420127\n",
      "    val_log_marginal: 1363.891337076823\n",
      "Train Epoch: 367 [0/54000 (0%)] Loss: -1363.105225\n",
      "Train Epoch: 367 [32768/54000 (61%)] Loss: -1365.740601\n",
      "    epoch          : 367\n",
      "    loss           : -1364.5899865492336\n",
      "    ess            : 3.720738028580288\n",
      "    log_marginal   : 1364.7199960384728\n",
      "    val_loss       : -1363.5397135416667\n",
      "    val_ess        : 3.728161334991455\n",
      "    val_log_marginal: 1363.6658528645833\n",
      "Train Epoch: 368 [0/54000 (0%)] Loss: -1362.242432\n",
      "Train Epoch: 368 [32768/54000 (61%)] Loss: -1362.811523\n",
      "    epoch          : 368\n",
      "    loss           : -1364.323854842276\n",
      "    ess            : 3.714485874715841\n",
      "    log_marginal   : 1364.4574020673645\n",
      "    val_loss       : -1362.7883707682292\n",
      "    val_ess        : 3.7167464097340903\n",
      "    val_log_marginal: 1362.9158935546875\n",
      "Train Epoch: 369 [0/54000 (0%)] Loss: -1360.970703\n",
      "Train Epoch: 369 [32768/54000 (61%)] Loss: -1366.937622\n",
      "    epoch          : 369\n",
      "    loss           : -1364.8613926149765\n",
      "    ess            : 3.7222702323265797\n",
      "    log_marginal   : 1364.9907756301593\n",
      "    val_loss       : -1364.2962443033855\n",
      "    val_ess        : 3.7117003202438354\n",
      "    val_log_marginal: 1364.429443359375\n",
      "Train Epoch: 370 [0/54000 (0%)] Loss: -1365.119873\n",
      "Train Epoch: 370 [32768/54000 (61%)] Loss: -1366.734375\n",
      "    epoch          : 370\n",
      "    loss           : -1366.074888985112\n",
      "    ess            : 3.719033790084551\n",
      "    log_marginal   : 1366.208367113797\n",
      "    val_loss       : -1364.9874064127605\n",
      "    val_ess        : 3.719826618830363\n",
      "    val_log_marginal: 1365.1161092122395\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch370.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 371 [0/54000 (0%)] Loss: -1364.624268\n",
      "Train Epoch: 371 [32768/54000 (61%)] Loss: -1367.148560\n",
      "    epoch          : 371\n",
      "    loss           : -1365.9503657502948\n",
      "    ess            : 3.721723093176788\n",
      "    log_marginal   : 1366.0784750884434\n",
      "    val_loss       : -1364.4027709960938\n",
      "    val_ess        : 3.7281401554743447\n",
      "    val_log_marginal: 1364.5332845052083\n",
      "Train Epoch: 372 [0/54000 (0%)] Loss: -1363.999756\n",
      "Train Epoch: 372 [32768/54000 (61%)] Loss: -1365.003662\n",
      "    epoch          : 372\n",
      "    loss           : -1365.7603460347877\n",
      "    ess            : 3.722467651907003\n",
      "    log_marginal   : 1365.8901505380306\n",
      "    val_loss       : -1365.0072021484375\n",
      "    val_ess        : 3.729981541633606\n",
      "    val_log_marginal: 1365.1284586588542\n",
      "Train Epoch: 373 [0/54000 (0%)] Loss: -1366.062988\n",
      "Train Epoch: 373 [32768/54000 (61%)] Loss: -1364.485840\n",
      "    epoch          : 373\n",
      "    loss           : -1366.8628090912441\n",
      "    ess            : 3.7216259443534994\n",
      "    log_marginal   : 1366.992592865566\n",
      "    val_loss       : -1366.526835123698\n",
      "    val_ess        : 3.7176453669865928\n",
      "    val_log_marginal: 1366.6602986653645\n",
      "Train Epoch: 374 [0/54000 (0%)] Loss: -1367.348389\n",
      "Train Epoch: 374 [32768/54000 (61%)] Loss: -1363.243530\n",
      "    epoch          : 374\n",
      "    loss           : -1367.391472582547\n",
      "    ess            : 3.7243861702253236\n",
      "    log_marginal   : 1367.523234817217\n",
      "    val_loss       : -1365.8896077473958\n",
      "    val_ess        : 3.7345561583836875\n",
      "    val_log_marginal: 1366.0126546223958\n",
      "Train Epoch: 375 [0/54000 (0%)] Loss: -1369.067383\n",
      "Train Epoch: 375 [32768/54000 (61%)] Loss: -1369.439941\n",
      "    epoch          : 375\n",
      "    loss           : -1367.1303526680424\n",
      "    ess            : 3.724315197962635\n",
      "    log_marginal   : 1367.2598761792453\n",
      "    val_loss       : -1365.8593343098958\n",
      "    val_ess        : 3.7315030097961426\n",
      "    val_log_marginal: 1365.9868570963542\n",
      "Train Epoch: 376 [0/54000 (0%)] Loss: -1366.276855\n",
      "Train Epoch: 376 [32768/54000 (61%)] Loss: -1364.067383\n",
      "    epoch          : 376\n",
      "    loss           : -1367.669194059552\n",
      "    ess            : 3.718148798312781\n",
      "    log_marginal   : 1367.802895599941\n",
      "    val_loss       : -1367.085205078125\n",
      "    val_ess        : 3.7218443950017295\n",
      "    val_log_marginal: 1367.2168579101562\n",
      "Train Epoch: 377 [0/54000 (0%)] Loss: -1367.390625\n",
      "Train Epoch: 377 [32768/54000 (61%)] Loss: -1365.276611\n",
      "    epoch          : 377\n",
      "    loss           : -1368.4786054503243\n",
      "    ess            : 3.723391015574617\n",
      "    log_marginal   : 1368.6102041568397\n",
      "    val_loss       : -1368.2966715494792\n",
      "    val_ess        : 3.730918288230896\n",
      "    val_log_marginal: 1368.4286092122395\n",
      "Train Epoch: 378 [0/54000 (0%)] Loss: -1369.417236\n",
      "Train Epoch: 378 [32768/54000 (61%)] Loss: -1372.005005\n",
      "    epoch          : 378\n",
      "    loss           : -1368.851177863355\n",
      "    ess            : 3.723916269698233\n",
      "    log_marginal   : 1368.9787989202534\n",
      "    val_loss       : -1367.6776123046875\n",
      "    val_ess        : 3.7284130652745566\n",
      "    val_log_marginal: 1367.8023478190105\n",
      "Train Epoch: 379 [0/54000 (0%)] Loss: -1367.818359\n",
      "Train Epoch: 379 [32768/54000 (61%)] Loss: -1370.299072\n",
      "    epoch          : 379\n",
      "    loss           : -1368.7137036593456\n",
      "    ess            : 3.7254422385737582\n",
      "    log_marginal   : 1368.8430866745282\n",
      "    val_loss       : -1367.8768920898438\n",
      "    val_ess        : 3.7195304234822593\n",
      "    val_log_marginal: 1367.998514811198\n",
      "Train Epoch: 380 [0/54000 (0%)] Loss: -1370.866211\n",
      "Train Epoch: 380 [32768/54000 (61%)] Loss: -1369.607300\n",
      "    epoch          : 380\n",
      "    loss           : -1369.4445938974056\n",
      "    ess            : 3.728193939856763\n",
      "    log_marginal   : 1369.573917029039\n",
      "    val_loss       : -1368.8546956380208\n",
      "    val_ess        : 3.7067507902781167\n",
      "    val_log_marginal: 1368.9922688802083\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch380.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 381 [0/54000 (0%)] Loss: -1373.028931\n",
      "Train Epoch: 381 [32768/54000 (61%)] Loss: -1371.657227\n",
      "    epoch          : 381\n",
      "    loss           : -1370.1727456146816\n",
      "    ess            : 3.7221067176674896\n",
      "    log_marginal   : 1370.3034345518868\n",
      "    val_loss       : -1369.2280680338542\n",
      "    val_ess        : 3.7262266476949057\n",
      "    val_log_marginal: 1369.3709106445312\n",
      "Train Epoch: 382 [0/54000 (0%)] Loss: -1371.940674\n",
      "Train Epoch: 382 [32768/54000 (61%)] Loss: -1368.530518\n",
      "    epoch          : 382\n",
      "    loss           : -1370.0013888377064\n",
      "    ess            : 3.717996025985142\n",
      "    log_marginal   : 1370.1322896705483\n",
      "    val_loss       : -1368.8660074869792\n",
      "    val_ess        : 3.7242718935012817\n",
      "    val_log_marginal: 1369.0013631184895\n",
      "Train Epoch: 383 [0/54000 (0%)] Loss: -1371.484619\n",
      "Train Epoch: 383 [32768/54000 (61%)] Loss: -1369.998779\n",
      "    epoch          : 383\n",
      "    loss           : -1370.2426274137677\n",
      "    ess            : 3.724240464984246\n",
      "    log_marginal   : 1370.3726714512088\n",
      "    val_loss       : -1370.011006673177\n",
      "    val_ess        : 3.730562170346578\n",
      "    val_log_marginal: 1370.1347045898438\n",
      "Train Epoch: 384 [0/54000 (0%)] Loss: -1372.346558\n",
      "Train Epoch: 384 [32768/54000 (61%)] Loss: -1369.417969\n",
      "    epoch          : 384\n",
      "    loss           : -1371.0759139150944\n",
      "    ess            : 3.720193664982634\n",
      "    log_marginal   : 1371.2079801739387\n",
      "    val_loss       : -1370.640380859375\n",
      "    val_ess        : 3.735195279121399\n",
      "    val_log_marginal: 1370.7640991210938\n",
      "Train Epoch: 385 [0/54000 (0%)] Loss: -1366.231934\n",
      "Train Epoch: 385 [32768/54000 (61%)] Loss: -1370.175781\n",
      "    epoch          : 385\n",
      "    loss           : -1371.398930387677\n",
      "    ess            : 3.7187270173486673\n",
      "    log_marginal   : 1371.5342303581958\n",
      "    val_loss       : -1370.2357991536458\n",
      "    val_ess        : 3.738829771677653\n",
      "    val_log_marginal: 1370.3609822591145\n",
      "Train Epoch: 386 [0/54000 (0%)] Loss: -1370.364990\n",
      "Train Epoch: 386 [32768/54000 (61%)] Loss: -1370.561035\n",
      "    epoch          : 386\n",
      "    loss           : -1371.263017762382\n",
      "    ess            : 3.7200943029151774\n",
      "    log_marginal   : 1371.3931516251473\n",
      "    val_loss       : -1370.5609130859375\n",
      "    val_ess        : 3.7218436002731323\n",
      "    val_log_marginal: 1370.703125\n",
      "Train Epoch: 387 [0/54000 (0%)] Loss: -1371.824707\n",
      "Train Epoch: 387 [32768/54000 (61%)] Loss: -1370.178711\n",
      "    epoch          : 387\n",
      "    loss           : -1371.9984660598468\n",
      "    ess            : 3.7196094719868786\n",
      "    log_marginal   : 1372.1326950361145\n",
      "    val_loss       : -1371.542704264323\n",
      "    val_ess        : 3.7211459477742515\n",
      "    val_log_marginal: 1371.6685180664062\n",
      "Train Epoch: 388 [0/54000 (0%)] Loss: -1375.321533\n",
      "Train Epoch: 388 [32768/54000 (61%)] Loss: -1371.568481\n",
      "    epoch          : 388\n",
      "    loss           : -1372.7539407982017\n",
      "    ess            : 3.728414238623853\n",
      "    log_marginal   : 1372.881960311026\n",
      "    val_loss       : -1372.0459594726562\n",
      "    val_ess        : 3.7232324679692588\n",
      "    val_log_marginal: 1372.1698608398438\n",
      "Train Epoch: 389 [0/54000 (0%)] Loss: -1371.687134\n",
      "Train Epoch: 389 [32768/54000 (61%)] Loss: -1373.214600\n",
      "    epoch          : 389\n",
      "    loss           : -1372.68687122273\n",
      "    ess            : 3.724122110402809\n",
      "    log_marginal   : 1372.8181705114976\n",
      "    val_loss       : -1371.6057942708333\n",
      "    val_ess        : 3.7322078148523965\n",
      "    val_log_marginal: 1371.7258911132812\n",
      "Train Epoch: 390 [0/54000 (0%)] Loss: -1373.499512\n",
      "Train Epoch: 390 [32768/54000 (61%)] Loss: -1372.782471\n",
      "    epoch          : 390\n",
      "    loss           : -1372.8560030955189\n",
      "    ess            : 3.718013875889328\n",
      "    log_marginal   : 1372.9888685694282\n",
      "    val_loss       : -1372.2781575520833\n",
      "    val_ess        : 3.7320649226506553\n",
      "    val_log_marginal: 1372.4037475585938\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch390.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 391 [0/54000 (0%)] Loss: -1373.896240\n",
      "Train Epoch: 391 [32768/54000 (61%)] Loss: -1373.161133\n",
      "    epoch          : 391\n",
      "    loss           : -1373.5852649616745\n",
      "    ess            : 3.725832777203254\n",
      "    log_marginal   : 1373.7139662256782\n",
      "    val_loss       : -1372.8904622395833\n",
      "    val_ess        : 3.7061933676401773\n",
      "    val_log_marginal: 1373.0330810546875\n",
      "Train Epoch: 392 [0/54000 (0%)] Loss: -1371.488037\n",
      "Train Epoch: 392 [32768/54000 (61%)] Loss: -1372.086914\n",
      "    epoch          : 392\n",
      "    loss           : -1374.0103183962265\n",
      "    ess            : 3.7241960156638667\n",
      "    log_marginal   : 1374.1402173312206\n",
      "    val_loss       : -1373.0458984375\n",
      "    val_ess        : 3.7300442854563394\n",
      "    val_log_marginal: 1373.1693522135417\n",
      "Train Epoch: 393 [0/54000 (0%)] Loss: -1377.426270\n",
      "Train Epoch: 393 [32768/54000 (61%)] Loss: -1377.443604\n",
      "    epoch          : 393\n",
      "    loss           : -1373.9605252247936\n",
      "    ess            : 3.7192120642032265\n",
      "    log_marginal   : 1374.0925822707843\n",
      "    val_loss       : -1373.2178141276042\n",
      "    val_ess        : 3.727354367574056\n",
      "    val_log_marginal: 1373.3492838541667\n",
      "Train Epoch: 394 [0/54000 (0%)] Loss: -1376.624512\n",
      "Train Epoch: 394 [32768/54000 (61%)] Loss: -1376.001953\n",
      "    epoch          : 394\n",
      "    loss           : -1374.437115363355\n",
      "    ess            : 3.7224573099388265\n",
      "    log_marginal   : 1374.5673229289505\n",
      "    val_loss       : -1374.1143188476562\n",
      "    val_ess        : 3.7218945423762\n",
      "    val_log_marginal: 1374.2415974934895\n",
      "Train Epoch: 395 [0/54000 (0%)] Loss: -1373.147705\n",
      "Train Epoch: 395 [32768/54000 (61%)] Loss: -1375.617065\n",
      "    epoch          : 395\n",
      "    loss           : -1375.192304503243\n",
      "    ess            : 3.7234506202193924\n",
      "    log_marginal   : 1375.3205036667157\n",
      "    val_loss       : -1374.2775268554688\n",
      "    val_ess        : 3.7257973353068032\n",
      "    val_log_marginal: 1374.406026204427\n",
      "Train Epoch: 396 [0/54000 (0%)] Loss: -1376.320435\n",
      "Train Epoch: 396 [32768/54000 (61%)] Loss: -1374.460938\n",
      "    epoch          : 396\n",
      "    loss           : -1375.4719054024174\n",
      "    ess            : 3.7258463175791614\n",
      "    log_marginal   : 1375.6005629053657\n",
      "    val_loss       : -1374.4462890625\n",
      "    val_ess        : 3.727476795514425\n",
      "    val_log_marginal: 1374.577168782552\n",
      "Train Epoch: 397 [0/54000 (0%)] Loss: -1374.355103\n",
      "Train Epoch: 397 [32768/54000 (61%)] Loss: -1375.250732\n",
      "    epoch          : 397\n",
      "    loss           : -1375.2585886829304\n",
      "    ess            : 3.715543364578823\n",
      "    log_marginal   : 1375.3935569907135\n",
      "    val_loss       : -1374.4754842122395\n",
      "    val_ess        : 3.718640923500061\n",
      "    val_log_marginal: 1374.6038411458333\n",
      "Train Epoch: 398 [0/54000 (0%)] Loss: -1373.479736\n",
      "Train Epoch: 398 [32768/54000 (61%)] Loss: -1376.020508\n",
      "    epoch          : 398\n",
      "    loss           : -1375.7205465064858\n",
      "    ess            : 3.7264971688108623\n",
      "    log_marginal   : 1375.8494089954304\n",
      "    val_loss       : -1375.6671142578125\n",
      "    val_ess        : 3.735028704007467\n",
      "    val_log_marginal: 1375.7908528645833\n",
      "Train Epoch: 399 [0/54000 (0%)] Loss: -1381.616821\n",
      "Train Epoch: 399 [32768/54000 (61%)] Loss: -1374.376709\n",
      "    epoch          : 399\n",
      "    loss           : -1376.474480395047\n",
      "    ess            : 3.7232546356489076\n",
      "    log_marginal   : 1376.605874115566\n",
      "    val_loss       : -1375.8157145182292\n",
      "    val_ess        : 3.7259246508280435\n",
      "    val_log_marginal: 1375.943359375\n",
      "Train Epoch: 400 [0/54000 (0%)] Loss: -1375.178223\n",
      "Train Epoch: 400 [32768/54000 (61%)] Loss: -1377.091797\n",
      "    epoch          : 400\n",
      "    loss           : -1376.5923243108784\n",
      "    ess            : 3.7245345790431186\n",
      "    log_marginal   : 1376.7221495430424\n",
      "    val_loss       : -1375.5348307291667\n",
      "    val_ess        : 3.729084293047587\n",
      "    val_log_marginal: 1375.6634928385417\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [0/54000 (0%)] Loss: -1379.296265\n",
      "Train Epoch: 401 [32768/54000 (61%)] Loss: -1375.927002\n",
      "    epoch          : 401\n",
      "    loss           : -1376.7230708284198\n",
      "    ess            : 3.723218229581725\n",
      "    log_marginal   : 1376.851935620578\n",
      "    val_loss       : -1376.373046875\n",
      "    val_ess        : 3.7281192541122437\n",
      "    val_log_marginal: 1376.5059407552083\n",
      "Train Epoch: 402 [0/54000 (0%)] Loss: -1378.727295\n",
      "Train Epoch: 402 [32768/54000 (61%)] Loss: -1378.303101\n",
      "    epoch          : 402\n",
      "    loss           : -1377.2980358195755\n",
      "    ess            : 3.7305020746195092\n",
      "    log_marginal   : 1377.4258157982017\n",
      "    val_loss       : -1376.9115804036458\n",
      "    val_ess        : 3.721023917198181\n",
      "    val_log_marginal: 1377.0503336588542\n",
      "Train Epoch: 403 [0/54000 (0%)] Loss: -1379.939453\n",
      "Train Epoch: 403 [32768/54000 (61%)] Loss: -1379.552979\n",
      "    epoch          : 403\n",
      "    loss           : -1377.777997862618\n",
      "    ess            : 3.7226104781312763\n",
      "    log_marginal   : 1377.9079198297466\n",
      "    val_loss       : -1377.1226806640625\n",
      "    val_ess        : 3.718105991681417\n",
      "    val_log_marginal: 1377.255615234375\n",
      "Train Epoch: 404 [0/54000 (0%)] Loss: -1376.491699\n",
      "Train Epoch: 404 [32768/54000 (61%)] Loss: -1376.480713\n",
      "    epoch          : 404\n",
      "    loss           : -1377.8950886276532\n",
      "    ess            : 3.7243956125007487\n",
      "    log_marginal   : 1378.0250866008255\n",
      "    val_loss       : -1377.129618326823\n",
      "    val_ess        : 3.739951014518738\n",
      "    val_log_marginal: 1377.2507731119792\n",
      "Train Epoch: 405 [0/54000 (0%)] Loss: -1380.733398\n",
      "Train Epoch: 405 [32768/54000 (61%)] Loss: -1375.512085\n",
      "    epoch          : 405\n",
      "    loss           : -1378.2755011792453\n",
      "    ess            : 3.7224957493116273\n",
      "    log_marginal   : 1378.405844634434\n",
      "    val_loss       : -1378.2860717773438\n",
      "    val_ess        : 3.727299610773722\n",
      "    val_log_marginal: 1378.4165649414062\n",
      "Train Epoch: 406 [0/54000 (0%)] Loss: -1381.311279\n",
      "Train Epoch: 406 [32768/54000 (61%)] Loss: -1377.877930\n",
      "    epoch          : 406\n",
      "    loss           : -1379.026491561026\n",
      "    ess            : 3.73054331653523\n",
      "    log_marginal   : 1379.150229400059\n",
      "    val_loss       : -1378.2436930338542\n",
      "    val_ess        : 3.7208765347798667\n",
      "    val_log_marginal: 1378.3809000651042\n",
      "Train Epoch: 407 [0/54000 (0%)] Loss: -1383.426514\n",
      "Train Epoch: 407 [32768/54000 (61%)] Loss: -1380.898438\n",
      "    epoch          : 407\n",
      "    loss           : -1379.0117671174823\n",
      "    ess            : 3.7315550615202704\n",
      "    log_marginal   : 1379.1371609669811\n",
      "    val_loss       : -1378.0349934895833\n",
      "    val_ess        : 3.728724161783854\n",
      "    val_log_marginal: 1378.1626790364583\n",
      "Train Epoch: 408 [0/54000 (0%)] Loss: -1380.767822\n",
      "Train Epoch: 408 [32768/54000 (61%)] Loss: -1376.015015\n",
      "    epoch          : 408\n",
      "    loss           : -1379.1623443027713\n",
      "    ess            : 3.727463110437933\n",
      "    log_marginal   : 1379.290018333579\n",
      "    val_loss       : -1378.7819010416667\n",
      "    val_ess        : 3.7343114614486694\n",
      "    val_log_marginal: 1378.906962076823\n",
      "Train Epoch: 409 [0/54000 (0%)] Loss: -1377.842529\n",
      "Train Epoch: 409 [32768/54000 (61%)] Loss: -1379.945190\n",
      "    epoch          : 409\n",
      "    loss           : -1379.9406369767098\n",
      "    ess            : 3.7264692018616876\n",
      "    log_marginal   : 1380.0697735480542\n",
      "    val_loss       : -1379.4941813151042\n",
      "    val_ess        : 3.737185796101888\n",
      "    val_log_marginal: 1379.624267578125\n",
      "Train Epoch: 410 [0/54000 (0%)] Loss: -1380.067627\n",
      "Train Epoch: 410 [32768/54000 (61%)] Loss: -1377.042480\n",
      "    epoch          : 410\n",
      "    loss           : -1380.3179309772995\n",
      "    ess            : 3.7316479143106713\n",
      "    log_marginal   : 1380.4455658534787\n",
      "    val_loss       : -1379.2103474934895\n",
      "    val_ess        : 3.7279866139094033\n",
      "    val_log_marginal: 1379.3477376302083\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch410.pth ...\n",
      "Train Epoch: 411 [0/54000 (0%)] Loss: -1383.039795\n",
      "Train Epoch: 411 [32768/54000 (61%)] Loss: -1379.849365\n",
      "    epoch          : 411\n",
      "    loss           : -1380.1920004790684\n",
      "    ess            : 3.7288372291708893\n",
      "    log_marginal   : 1380.3201075140034\n",
      "    val_loss       : -1379.4278157552083\n",
      "    val_ess        : 3.72256338596344\n",
      "    val_log_marginal: 1379.5623168945312\n",
      "Train Epoch: 412 [0/54000 (0%)] Loss: -1382.305786\n",
      "Train Epoch: 412 [32768/54000 (61%)] Loss: -1377.065430\n",
      "    epoch          : 412\n",
      "    loss           : -1380.7314130675118\n",
      "    ess            : 3.7264145815147542\n",
      "    log_marginal   : 1380.8600106869103\n",
      "    val_loss       : -1380.3512369791667\n",
      "    val_ess        : 3.7289864222208657\n",
      "    val_log_marginal: 1380.4751790364583\n",
      "Train Epoch: 413 [0/54000 (0%)] Loss: -1380.739990\n",
      "Train Epoch: 413 [32768/54000 (61%)] Loss: -1379.902710\n",
      "    epoch          : 413\n",
      "    loss           : -1381.416388745578\n",
      "    ess            : 3.7210188901649333\n",
      "    log_marginal   : 1381.551274137677\n",
      "    val_loss       : -1380.821309407552\n",
      "    val_ess        : 3.7211214303970337\n",
      "    val_log_marginal: 1380.9477945963542\n",
      "Train Epoch: 414 [0/54000 (0%)] Loss: -1383.158936\n",
      "Train Epoch: 414 [32768/54000 (61%)] Loss: -1380.171875\n",
      "    epoch          : 414\n",
      "    loss           : -1381.267905181309\n",
      "    ess            : 3.7302052614823826\n",
      "    log_marginal   : 1381.3959454230542\n",
      "    val_loss       : -1380.3639322916667\n",
      "    val_ess        : 3.728570818901062\n",
      "    val_log_marginal: 1380.4892985026042\n",
      "Train Epoch: 415 [0/54000 (0%)] Loss: -1379.673584\n",
      "Train Epoch: 415 [32768/54000 (61%)] Loss: -1382.055786\n",
      "    epoch          : 415\n",
      "    loss           : -1381.275275464328\n",
      "    ess            : 3.728557636153023\n",
      "    log_marginal   : 1381.4038016841096\n",
      "    val_loss       : -1380.9764607747395\n",
      "    val_ess        : 3.7259432474772134\n",
      "    val_log_marginal: 1381.1075642903645\n",
      "Train Epoch: 416 [0/54000 (0%)] Loss: -1382.560913\n",
      "Train Epoch: 416 [32768/54000 (61%)] Loss: -1381.723633\n",
      "    epoch          : 416\n",
      "    loss           : -1382.0950927734375\n",
      "    ess            : 3.7250454695719593\n",
      "    log_marginal   : 1382.225180571934\n",
      "    val_loss       : -1381.9153849283855\n",
      "    val_ess        : 3.724893887837728\n",
      "    val_log_marginal: 1382.0481567382812\n",
      "Train Epoch: 417 [0/54000 (0%)] Loss: -1385.181152\n",
      "Train Epoch: 417 [32768/54000 (61%)] Loss: -1383.523438\n",
      "    epoch          : 417\n",
      "    loss           : -1382.2815816627358\n",
      "    ess            : 3.727042076722631\n",
      "    log_marginal   : 1382.4122199292453\n",
      "    val_loss       : -1381.5919392903645\n",
      "    val_ess        : 3.7297209103902182\n",
      "    val_log_marginal: 1381.7169392903645\n",
      "Train Epoch: 418 [0/54000 (0%)] Loss: -1382.980347\n",
      "Train Epoch: 418 [32768/54000 (61%)] Loss: -1383.361572\n",
      "    epoch          : 418\n",
      "    loss           : -1382.3980597729953\n",
      "    ess            : 3.728661496684236\n",
      "    log_marginal   : 1382.5263671875\n",
      "    val_loss       : -1381.67333984375\n",
      "    val_ess        : 3.7300700743993125\n",
      "    val_log_marginal: 1381.80322265625\n",
      "Train Epoch: 419 [0/54000 (0%)] Loss: -1381.503540\n",
      "Train Epoch: 419 [32768/54000 (61%)] Loss: -1381.698242\n",
      "    epoch          : 419\n",
      "    loss           : -1382.9369241966392\n",
      "    ess            : 3.7293331892985218\n",
      "    log_marginal   : 1383.0662473282723\n",
      "    val_loss       : -1382.9606323242188\n",
      "    val_ess        : 3.737846851348877\n",
      "    val_log_marginal: 1383.0842692057292\n",
      "Train Epoch: 420 [0/54000 (0%)] Loss: -1384.145264\n",
      "Train Epoch: 420 [32768/54000 (61%)] Loss: -1382.236084\n",
      "    epoch          : 420\n",
      "    loss           : -1383.5297966723172\n",
      "    ess            : 3.7266922266978137\n",
      "    log_marginal   : 1383.6587098319576\n",
      "    val_loss       : -1382.8746134440105\n",
      "    val_ess        : 3.7346312602361045\n",
      "    val_log_marginal: 1383.0017700195312\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch420.pth ...\n",
      "Train Epoch: 421 [0/54000 (0%)] Loss: -1386.793823\n",
      "Train Epoch: 421 [32768/54000 (61%)] Loss: -1382.765015\n",
      "    epoch          : 421\n",
      "    loss           : -1383.731196565448\n",
      "    ess            : 3.72373458574403\n",
      "    log_marginal   : 1383.8614271631782\n",
      "    val_loss       : -1382.930928548177\n",
      "    val_ess        : 3.73251481850942\n",
      "    val_log_marginal: 1383.0583902994792\n",
      "Train Epoch: 422 [0/54000 (0%)] Loss: -1379.571045\n",
      "Train Epoch: 422 [32768/54000 (61%)] Loss: -1384.999756\n",
      "    epoch          : 422\n",
      "    loss           : -1383.6271627174233\n",
      "    ess            : 3.731061085215155\n",
      "    log_marginal   : 1383.7573011866157\n",
      "    val_loss       : -1383.0494588216145\n",
      "    val_ess        : 3.7302791277567544\n",
      "    val_log_marginal: 1383.1761067708333\n",
      "Train Epoch: 423 [0/54000 (0%)] Loss: -1385.360840\n",
      "Train Epoch: 423 [32768/54000 (61%)] Loss: -1383.807129\n",
      "    epoch          : 423\n",
      "    loss           : -1384.2600327977593\n",
      "    ess            : 3.725943520384015\n",
      "    log_marginal   : 1384.3897912367336\n",
      "    val_loss       : -1384.2359415690105\n",
      "    val_ess        : 3.7207284371058145\n",
      "    val_log_marginal: 1384.3768513997395\n",
      "Train Epoch: 424 [0/54000 (0%)] Loss: -1387.694214\n",
      "Train Epoch: 424 [32768/54000 (61%)] Loss: -1385.418823\n",
      "    epoch          : 424\n",
      "    loss           : -1384.7976811247052\n",
      "    ess            : 3.729696759637797\n",
      "    log_marginal   : 1384.926456091539\n",
      "    val_loss       : -1384.015848795573\n",
      "    val_ess        : 3.733141779899597\n",
      "    val_log_marginal: 1384.140645345052\n",
      "Train Epoch: 425 [0/54000 (0%)] Loss: -1386.128174\n",
      "Train Epoch: 425 [32768/54000 (61%)] Loss: -1385.067627\n",
      "    epoch          : 425\n",
      "    loss           : -1384.8627745430424\n",
      "    ess            : 3.7305238831718013\n",
      "    log_marginal   : 1384.9901998267983\n",
      "    val_loss       : -1384.0288696289062\n",
      "    val_ess        : 3.720724026362101\n",
      "    val_log_marginal: 1384.1584065755208\n",
      "Train Epoch: 426 [0/54000 (0%)] Loss: -1389.101562\n",
      "Train Epoch: 426 [32768/54000 (61%)] Loss: -1386.448730\n",
      "    epoch          : 426\n",
      "    loss           : -1385.0489548017395\n",
      "    ess            : 3.726097250884434\n",
      "    log_marginal   : 1385.179401901533\n",
      "    val_loss       : -1384.413838704427\n",
      "    val_ess        : 3.7319337924321494\n",
      "    val_log_marginal: 1384.544921875\n",
      "Train Epoch: 427 [0/54000 (0%)] Loss: -1390.114502\n",
      "Train Epoch: 427 [32768/54000 (61%)] Loss: -1384.242065\n",
      "    epoch          : 427\n",
      "    loss           : -1385.6342520084022\n",
      "    ess            : 3.7301648157947467\n",
      "    log_marginal   : 1385.7615068543632\n",
      "    val_loss       : -1385.2516479492188\n",
      "    val_ess        : 3.739788293838501\n",
      "    val_log_marginal: 1385.370625813802\n",
      "Train Epoch: 428 [0/54000 (0%)] Loss: -1388.505127\n",
      "Train Epoch: 428 [32768/54000 (61%)] Loss: -1385.513428\n",
      "    epoch          : 428\n",
      "    loss           : -1385.8928406913326\n",
      "    ess            : 3.7318270566328517\n",
      "    log_marginal   : 1386.019697081368\n",
      "    val_loss       : -1385.0896606445312\n",
      "    val_ess        : 3.7398452361424765\n",
      "    val_log_marginal: 1385.2083943684895\n",
      "Train Epoch: 429 [0/54000 (0%)] Loss: -1387.722290\n",
      "Train Epoch: 429 [32768/54000 (61%)] Loss: -1388.943848\n",
      "    epoch          : 429\n",
      "    loss           : -1386.0353128685142\n",
      "    ess            : 3.73134690410686\n",
      "    log_marginal   : 1386.1628878611439\n",
      "    val_loss       : -1385.1670735677083\n",
      "    val_ess        : 3.7397620677948\n",
      "    val_log_marginal: 1385.2852172851562\n",
      "Train Epoch: 430 [0/54000 (0%)] Loss: -1387.018188\n",
      "Train Epoch: 430 [32768/54000 (61%)] Loss: -1387.444092\n",
      "    epoch          : 430\n",
      "    loss           : -1386.4672736401828\n",
      "    ess            : 3.723976198232399\n",
      "    log_marginal   : 1386.5980754348468\n",
      "    val_loss       : -1386.0642700195312\n",
      "    val_ess        : 3.750396450360616\n",
      "    val_log_marginal: 1386.1826782226562\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch430.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 431 [0/54000 (0%)] Loss: -1390.743286\n",
      "Train Epoch: 431 [32768/54000 (61%)] Loss: -1388.601196\n",
      "    epoch          : 431\n",
      "    loss           : -1386.8845076650944\n",
      "    ess            : 3.7247477747359365\n",
      "    log_marginal   : 1387.0165647110848\n",
      "    val_loss       : -1386.3116251627605\n",
      "    val_ess        : 3.735489845275879\n",
      "    val_log_marginal: 1386.4389241536458\n",
      "Train Epoch: 432 [0/54000 (0%)] Loss: -1385.691406\n",
      "Train Epoch: 432 [32768/54000 (61%)] Loss: -1388.915039\n",
      "    epoch          : 432\n",
      "    loss           : -1387.1349660045696\n",
      "    ess            : 3.732853983933071\n",
      "    log_marginal   : 1387.2632711158608\n",
      "    val_loss       : -1386.3889770507812\n",
      "    val_ess        : 3.739459236462911\n",
      "    val_log_marginal: 1386.5113932291667\n",
      "Train Epoch: 433 [0/54000 (0%)] Loss: -1384.467041\n",
      "Train Epoch: 433 [32768/54000 (61%)] Loss: -1386.935425\n",
      "    epoch          : 433\n",
      "    loss           : -1387.3422252727005\n",
      "    ess            : 3.73211566907055\n",
      "    log_marginal   : 1387.4714747015034\n",
      "    val_loss       : -1386.8393147786458\n",
      "    val_ess        : 3.7420543829600015\n",
      "    val_log_marginal: 1386.9572143554688\n",
      "Train Epoch: 434 [0/54000 (0%)] Loss: -1387.483887\n",
      "Train Epoch: 434 [32768/54000 (61%)] Loss: -1384.398438\n",
      "    epoch          : 434\n",
      "    loss           : -1387.7788016841096\n",
      "    ess            : 3.7314061083883607\n",
      "    log_marginal   : 1387.9074683999115\n",
      "    val_loss       : -1386.8948364257812\n",
      "    val_ess        : 3.749976873397827\n",
      "    val_log_marginal: 1387.006856282552\n",
      "Train Epoch: 435 [0/54000 (0%)] Loss: -1389.015503\n",
      "Train Epoch: 435 [32768/54000 (61%)] Loss: -1388.863770\n",
      "    epoch          : 435\n",
      "    loss           : -1388.1723448555424\n",
      "    ess            : 3.7330304811585626\n",
      "    log_marginal   : 1388.2972066627358\n",
      "    val_loss       : -1387.2862141927083\n",
      "    val_ess        : 3.745507518450419\n",
      "    val_log_marginal: 1387.4088948567708\n",
      "Train Epoch: 436 [0/54000 (0%)] Loss: -1392.518555\n",
      "Train Epoch: 436 [32768/54000 (61%)] Loss: -1386.799072\n",
      "    epoch          : 436\n",
      "    loss           : -1388.2406213148586\n",
      "    ess            : 3.7288487092503964\n",
      "    log_marginal   : 1388.3703521152713\n",
      "    val_loss       : -1387.1377563476562\n",
      "    val_ess        : 3.719013532002767\n",
      "    val_log_marginal: 1387.27783203125\n",
      "Train Epoch: 437 [0/54000 (0%)] Loss: -1389.575195\n",
      "Train Epoch: 437 [32768/54000 (61%)] Loss: -1390.092529\n",
      "    epoch          : 437\n",
      "    loss           : -1388.445047630454\n",
      "    ess            : 3.736211101963835\n",
      "    log_marginal   : 1388.5708883033608\n",
      "    val_loss       : -1387.6923421223958\n",
      "    val_ess        : 3.735358397165934\n",
      "    val_log_marginal: 1387.8159993489583\n",
      "Train Epoch: 438 [0/54000 (0%)] Loss: -1387.343506\n",
      "Train Epoch: 438 [32768/54000 (61%)] Loss: -1387.114502\n",
      "    epoch          : 438\n",
      "    loss           : -1389.1015164357311\n",
      "    ess            : 3.7299714223393856\n",
      "    log_marginal   : 1389.2308833284198\n",
      "    val_loss       : -1388.2276814778645\n",
      "    val_ess        : 3.7309815486272178\n",
      "    val_log_marginal: 1388.3605346679688\n",
      "Train Epoch: 439 [0/54000 (0%)] Loss: -1390.550781\n",
      "Train Epoch: 439 [32768/54000 (61%)] Loss: -1390.356201\n",
      "    epoch          : 439\n",
      "    loss           : -1389.3612267836086\n",
      "    ess            : 3.729563587116745\n",
      "    log_marginal   : 1389.4908216944282\n",
      "    val_loss       : -1388.1163533528645\n",
      "    val_ess        : 3.7349048852920532\n",
      "    val_log_marginal: 1388.2460327148438\n",
      "Train Epoch: 440 [0/54000 (0%)] Loss: -1390.047607\n",
      "Train Epoch: 440 [32768/54000 (61%)] Loss: -1393.062744\n",
      "    epoch          : 440\n",
      "    loss           : -1389.321404223172\n",
      "    ess            : 3.730337867197001\n",
      "    log_marginal   : 1389.451945754717\n",
      "    val_loss       : -1388.4917602539062\n",
      "    val_ess        : 3.7406980196634927\n",
      "    val_log_marginal: 1388.6225992838542\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch440.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 441 [0/54000 (0%)] Loss: -1391.452881\n",
      "Train Epoch: 441 [32768/54000 (61%)] Loss: -1389.765381\n",
      "    epoch          : 441\n",
      "    loss           : -1389.8141583136792\n",
      "    ess            : 3.7311837358294793\n",
      "    log_marginal   : 1389.9420995172466\n",
      "    val_loss       : -1389.2862141927083\n",
      "    val_ess        : 3.759378751118978\n",
      "    val_log_marginal: 1389.4000244140625\n",
      "Train Epoch: 442 [0/54000 (0%)] Loss: -1394.048950\n",
      "Train Epoch: 442 [32768/54000 (61%)] Loss: -1391.351074\n",
      "    epoch          : 442\n",
      "    loss           : -1390.5713996167453\n",
      "    ess            : 3.7311472262976304\n",
      "    log_marginal   : 1390.6974383660083\n",
      "    val_loss       : -1390.0045979817708\n",
      "    val_ess        : 3.7258748213450112\n",
      "    val_log_marginal: 1390.1377970377605\n",
      "Train Epoch: 443 [0/54000 (0%)] Loss: -1392.633301\n",
      "Train Epoch: 443 [32768/54000 (61%)] Loss: -1392.845947\n",
      "    epoch          : 443\n",
      "    loss           : -1390.6208611254422\n",
      "    ess            : 3.7284191779370577\n",
      "    log_marginal   : 1390.7524782576652\n",
      "    val_loss       : -1389.5296427408855\n",
      "    val_ess        : 3.7262682914733887\n",
      "    val_log_marginal: 1389.6593831380208\n",
      "Train Epoch: 444 [0/54000 (0%)] Loss: -1393.648193\n",
      "Train Epoch: 444 [32768/54000 (61%)] Loss: -1388.905273\n",
      "    epoch          : 444\n",
      "    loss           : -1390.7592381891216\n",
      "    ess            : 3.731826512318737\n",
      "    log_marginal   : 1390.8855878721993\n",
      "    val_loss       : -1389.8754475911458\n",
      "    val_ess        : 3.7382777531941733\n",
      "    val_log_marginal: 1389.9973754882812\n",
      "Train Epoch: 445 [0/54000 (0%)] Loss: -1388.709717\n",
      "Train Epoch: 445 [32768/54000 (61%)] Loss: -1389.954590\n",
      "    epoch          : 445\n",
      "    loss           : -1391.2171884212853\n",
      "    ess            : 3.7314703104630955\n",
      "    log_marginal   : 1391.3466244103774\n",
      "    val_loss       : -1390.5998128255208\n",
      "    val_ess        : 3.734435757001241\n",
      "    val_log_marginal: 1390.7228393554688\n",
      "Train Epoch: 446 [0/54000 (0%)] Loss: -1391.592041\n",
      "Train Epoch: 446 [32768/54000 (61%)] Loss: -1389.333496\n",
      "    epoch          : 446\n",
      "    loss           : -1391.587241118809\n",
      "    ess            : 3.730487234187576\n",
      "    log_marginal   : 1391.7172321823407\n",
      "    val_loss       : -1390.56494140625\n",
      "    val_ess        : 3.73314638932546\n",
      "    val_log_marginal: 1390.6988932291667\n",
      "Train Epoch: 447 [0/54000 (0%)] Loss: -1392.248291\n",
      "Train Epoch: 447 [32768/54000 (61%)] Loss: -1391.384521\n",
      "    epoch          : 447\n",
      "    loss           : -1391.8083173643868\n",
      "    ess            : 3.7307882938744887\n",
      "    log_marginal   : 1391.9378454820164\n",
      "    val_loss       : -1390.788309733073\n",
      "    val_ess        : 3.738347887992859\n",
      "    val_log_marginal: 1390.9200032552083\n",
      "Train Epoch: 448 [0/54000 (0%)] Loss: -1392.282959\n",
      "Train Epoch: 448 [32768/54000 (61%)] Loss: -1389.876343\n",
      "    epoch          : 448\n",
      "    loss           : -1392.0721550707547\n",
      "    ess            : 3.7334376955932043\n",
      "    log_marginal   : 1392.197021484375\n",
      "    val_loss       : -1391.0556030273438\n",
      "    val_ess        : 3.7261681159337363\n",
      "    val_log_marginal: 1391.1924235026042\n",
      "Train Epoch: 449 [0/54000 (0%)] Loss: -1396.417480\n",
      "Train Epoch: 449 [32768/54000 (61%)] Loss: -1395.922607\n",
      "    epoch          : 449\n",
      "    loss           : -1392.416934607164\n",
      "    ess            : 3.7276366836619825\n",
      "    log_marginal   : 1392.5478607753537\n",
      "    val_loss       : -1392.1593424479167\n",
      "    val_ess        : 3.7361850341161094\n",
      "    val_log_marginal: 1392.2796020507812\n",
      "Train Epoch: 450 [0/54000 (0%)] Loss: -1393.231201\n",
      "Train Epoch: 450 [32768/54000 (61%)] Loss: -1389.827637\n",
      "    epoch          : 450\n",
      "    loss           : -1392.8657572044517\n",
      "    ess            : 3.728506974454196\n",
      "    log_marginal   : 1392.9945552034198\n",
      "    val_loss       : -1392.0484619140625\n",
      "    val_ess        : 3.752121647198995\n",
      "    val_log_marginal: 1392.1592407226562\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [0/54000 (0%)] Loss: -1392.474976\n",
      "Train Epoch: 451 [32768/54000 (61%)] Loss: -1393.717407\n",
      "    epoch          : 451\n",
      "    loss           : -1392.9379859780365\n",
      "    ess            : 3.7299294426756084\n",
      "    log_marginal   : 1393.0682948850235\n",
      "    val_loss       : -1392.1358439127605\n",
      "    val_ess        : 3.739012122154236\n",
      "    val_log_marginal: 1392.2596842447917\n",
      "Train Epoch: 452 [0/54000 (0%)] Loss: -1394.798584\n",
      "Train Epoch: 452 [32768/54000 (61%)] Loss: -1392.774414\n",
      "    epoch          : 452\n",
      "    loss           : -1393.1943082989387\n",
      "    ess            : 3.7322233667913474\n",
      "    log_marginal   : 1393.3231201171875\n",
      "    val_loss       : -1392.6168009440105\n",
      "    val_ess        : 3.7238686084747314\n",
      "    val_log_marginal: 1392.75341796875\n",
      "Train Epoch: 453 [0/54000 (0%)] Loss: -1391.274292\n",
      "Train Epoch: 453 [32768/54000 (61%)] Loss: -1391.045166\n",
      "    epoch          : 453\n",
      "    loss           : -1393.627155807783\n",
      "    ess            : 3.7317787026459315\n",
      "    log_marginal   : 1393.7557603368218\n",
      "    val_loss       : -1392.8026529947917\n",
      "    val_ess        : 3.7114707231521606\n",
      "    val_log_marginal: 1392.946533203125\n",
      "Train Epoch: 454 [0/54000 (0%)] Loss: -1392.101562\n",
      "Train Epoch: 454 [32768/54000 (61%)] Loss: -1392.139648\n",
      "    epoch          : 454\n",
      "    loss           : -1393.8947592681309\n",
      "    ess            : 3.7355604396676116\n",
      "    log_marginal   : 1394.024112341539\n",
      "    val_loss       : -1392.8165079752605\n",
      "    val_ess        : 3.735933542251587\n",
      "    val_log_marginal: 1392.9429524739583\n",
      "Train Epoch: 455 [0/54000 (0%)] Loss: -1395.307617\n",
      "Train Epoch: 455 [32768/54000 (61%)] Loss: -1394.799561\n",
      "    epoch          : 455\n",
      "    loss           : -1394.054998433815\n",
      "    ess            : 3.736911224869062\n",
      "    log_marginal   : 1394.1811845887382\n",
      "    val_loss       : -1393.116943359375\n",
      "    val_ess        : 3.7376842896143594\n",
      "    val_log_marginal: 1393.2424723307292\n",
      "Train Epoch: 456 [0/54000 (0%)] Loss: -1396.356201\n",
      "Train Epoch: 456 [32768/54000 (61%)] Loss: -1391.469727\n",
      "    epoch          : 456\n",
      "    loss           : -1394.1595758402123\n",
      "    ess            : 3.727382376508893\n",
      "    log_marginal   : 1394.290398363797\n",
      "    val_loss       : -1393.8099161783855\n",
      "    val_ess        : 3.730537931124369\n",
      "    val_log_marginal: 1393.940185546875\n",
      "Train Epoch: 457 [0/54000 (0%)] Loss: -1394.331543\n",
      "Train Epoch: 457 [32768/54000 (61%)] Loss: -1395.449219\n",
      "    epoch          : 457\n",
      "    loss           : -1394.7219307377654\n",
      "    ess            : 3.7315451738969334\n",
      "    log_marginal   : 1394.8505675117924\n",
      "    val_loss       : -1393.6350708007812\n",
      "    val_ess        : 3.7271092732747397\n",
      "    val_log_marginal: 1393.7683919270833\n",
      "Train Epoch: 458 [0/54000 (0%)] Loss: -1397.269287\n",
      "Train Epoch: 458 [32768/54000 (61%)] Loss: -1390.438232\n",
      "    epoch          : 458\n",
      "    loss           : -1395.0317728294517\n",
      "    ess            : 3.7326702711717137\n",
      "    log_marginal   : 1395.1607412662147\n",
      "    val_loss       : -1393.9149576822917\n",
      "    val_ess        : 3.7152827183405557\n",
      "    val_log_marginal: 1394.055196126302\n",
      "Train Epoch: 459 [0/54000 (0%)] Loss: -1396.151855\n",
      "Train Epoch: 459 [32768/54000 (61%)] Loss: -1396.483643\n",
      "    epoch          : 459\n",
      "    loss           : -1395.2044585605838\n",
      "    ess            : 3.7328253377158687\n",
      "    log_marginal   : 1395.3318032318691\n",
      "    val_loss       : -1394.2545572916667\n",
      "    val_ess        : 3.7288911739985147\n",
      "    val_log_marginal: 1394.3874918619792\n",
      "Train Epoch: 460 [0/54000 (0%)] Loss: -1398.043213\n",
      "Train Epoch: 460 [32768/54000 (61%)] Loss: -1396.433105\n",
      "    epoch          : 460\n",
      "    loss           : -1395.6244218934257\n",
      "    ess            : 3.7302066650030747\n",
      "    log_marginal   : 1395.7532383181015\n",
      "    val_loss       : -1394.8685099283855\n",
      "    val_ess        : 3.7411338885625205\n",
      "    val_log_marginal: 1394.983866373698\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch460.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 461 [0/54000 (0%)] Loss: -1397.141724\n",
      "Train Epoch: 461 [32768/54000 (61%)] Loss: -1394.929810\n",
      "    epoch          : 461\n",
      "    loss           : -1395.8846965285968\n",
      "    ess            : 3.7342297940883995\n",
      "    log_marginal   : 1396.011677292158\n",
      "    val_loss       : -1394.9104614257812\n",
      "    val_ess        : 3.741934657096863\n",
      "    val_log_marginal: 1395.0378011067708\n",
      "Train Epoch: 462 [0/54000 (0%)] Loss: -1395.352661\n",
      "Train Epoch: 462 [32768/54000 (61%)] Loss: -1393.330566\n",
      "    epoch          : 462\n",
      "    loss           : -1396.0478423496463\n",
      "    ess            : 3.7325015337962024\n",
      "    log_marginal   : 1396.176435362618\n",
      "    val_loss       : -1395.2231852213542\n",
      "    val_ess        : 3.7410360177357993\n",
      "    val_log_marginal: 1395.3421630859375\n",
      "Train Epoch: 463 [0/54000 (0%)] Loss: -1397.091064\n",
      "Train Epoch: 463 [32768/54000 (61%)] Loss: -1397.128784\n",
      "    epoch          : 463\n",
      "    loss           : -1396.3736203751473\n",
      "    ess            : 3.736499179084346\n",
      "    log_marginal   : 1396.4998019236439\n",
      "    val_loss       : -1395.6012369791667\n",
      "    val_ess        : 3.7361005942026773\n",
      "    val_log_marginal: 1395.7242431640625\n",
      "Train Epoch: 464 [0/54000 (0%)] Loss: -1395.437134\n",
      "Train Epoch: 464 [32768/54000 (61%)] Loss: -1394.287842\n",
      "    epoch          : 464\n",
      "    loss           : -1396.6839300191627\n",
      "    ess            : 3.732844780076225\n",
      "    log_marginal   : 1396.8134005564564\n",
      "    val_loss       : -1395.7918090820312\n",
      "    val_ess        : 3.7260802586873374\n",
      "    val_log_marginal: 1395.9163818359375\n",
      "Train Epoch: 465 [0/54000 (0%)] Loss: -1398.253662\n",
      "Train Epoch: 465 [32768/54000 (61%)] Loss: -1395.266113\n",
      "    epoch          : 465\n",
      "    loss           : -1396.9658640735554\n",
      "    ess            : 3.7308066026219784\n",
      "    log_marginal   : 1397.0946712853774\n",
      "    val_loss       : -1395.9649454752605\n",
      "    val_ess        : 3.743590315183004\n",
      "    val_log_marginal: 1396.0891520182292\n",
      "Train Epoch: 466 [0/54000 (0%)] Loss: -1398.614258\n",
      "Train Epoch: 466 [32768/54000 (61%)] Loss: -1395.597168\n",
      "    epoch          : 466\n",
      "    loss           : -1397.320234190743\n",
      "    ess            : 3.731536959702114\n",
      "    log_marginal   : 1397.4491542600235\n",
      "    val_loss       : -1396.5320638020833\n",
      "    val_ess        : 3.72793702284495\n",
      "    val_log_marginal: 1396.6619059244792\n",
      "Train Epoch: 467 [0/54000 (0%)] Loss: -1396.483643\n",
      "Train Epoch: 467 [32768/54000 (61%)] Loss: -1395.466919\n",
      "    epoch          : 467\n",
      "    loss           : -1397.574504348467\n",
      "    ess            : 3.7328541548746936\n",
      "    log_marginal   : 1397.703530365566\n",
      "    val_loss       : -1396.7763061523438\n",
      "    val_ess        : 3.738135655721029\n",
      "    val_log_marginal: 1396.8934326171875\n",
      "Train Epoch: 468 [0/54000 (0%)] Loss: -1397.730225\n",
      "Train Epoch: 468 [32768/54000 (61%)] Loss: -1398.101318\n",
      "    epoch          : 468\n",
      "    loss           : -1397.8201650943397\n",
      "    ess            : 3.734077844979628\n",
      "    log_marginal   : 1397.9468855947819\n",
      "    val_loss       : -1397.092529296875\n",
      "    val_ess        : 3.7499340772628784\n",
      "    val_log_marginal: 1397.2143961588542\n",
      "Train Epoch: 469 [0/54000 (0%)] Loss: -1401.492676\n",
      "Train Epoch: 469 [32768/54000 (61%)] Loss: -1395.760498\n",
      "    epoch          : 469\n",
      "    loss           : -1398.0269821454895\n",
      "    ess            : 3.733272961850436\n",
      "    log_marginal   : 1398.1555406102593\n",
      "    val_loss       : -1397.8094278971355\n",
      "    val_ess        : 3.7387642860412598\n",
      "    val_log_marginal: 1397.9349568684895\n",
      "Train Epoch: 470 [0/54000 (0%)] Loss: -1399.213623\n",
      "Train Epoch: 470 [32768/54000 (61%)] Loss: -1401.116089\n",
      "    epoch          : 470\n",
      "    loss           : -1398.4689181345814\n",
      "    ess            : 3.7362429825764782\n",
      "    log_marginal   : 1398.5946712853774\n",
      "    val_loss       : -1398.0497639973958\n",
      "    val_ess        : 3.7302498817443848\n",
      "    val_log_marginal: 1398.1816813151042\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch470.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 471 [0/54000 (0%)] Loss: -1399.788574\n",
      "Train Epoch: 471 [32768/54000 (61%)] Loss: -1396.125732\n",
      "    epoch          : 471\n",
      "    loss           : -1398.5739653965213\n",
      "    ess            : 3.7352950438013615\n",
      "    log_marginal   : 1398.701961877211\n",
      "    val_loss       : -1397.932149251302\n",
      "    val_ess        : 3.7274548212687173\n",
      "    val_log_marginal: 1398.0653076171875\n",
      "Train Epoch: 472 [0/54000 (0%)] Loss: -1400.032349\n",
      "Train Epoch: 472 [32768/54000 (61%)] Loss: -1397.484253\n",
      "    epoch          : 472\n",
      "    loss           : -1398.7651643573113\n",
      "    ess            : 3.7337198932215854\n",
      "    log_marginal   : 1398.8947062942218\n",
      "    val_loss       : -1398.238037109375\n",
      "    val_ess        : 3.740092913309733\n",
      "    val_log_marginal: 1398.3594970703125\n",
      "Train Epoch: 473 [0/54000 (0%)] Loss: -1397.847656\n",
      "Train Epoch: 473 [32768/54000 (61%)] Loss: -1396.978027\n",
      "    epoch          : 473\n",
      "    loss           : -1399.1865510760613\n",
      "    ess            : 3.73986150633614\n",
      "    log_marginal   : 1399.3107219192218\n",
      "    val_loss       : -1398.5524088541667\n",
      "    val_ess        : 3.751355250676473\n",
      "    val_log_marginal: 1398.6734212239583\n",
      "Train Epoch: 474 [0/54000 (0%)] Loss: -1399.550537\n",
      "Train Epoch: 474 [32768/54000 (61%)] Loss: -1396.187012\n",
      "    epoch          : 474\n",
      "    loss           : -1399.5572740086968\n",
      "    ess            : 3.742232516126813\n",
      "    log_marginal   : 1399.6788468270931\n",
      "    val_loss       : -1398.6058349609375\n",
      "    val_ess        : 3.7491914431254068\n",
      "    val_log_marginal: 1398.7186482747395\n",
      "Train Epoch: 475 [0/54000 (0%)] Loss: -1402.561035\n",
      "Train Epoch: 475 [32768/54000 (61%)] Loss: -1401.820557\n",
      "    epoch          : 475\n",
      "    loss           : -1399.6898538841392\n",
      "    ess            : 3.7368142964704982\n",
      "    log_marginal   : 1399.8145959242336\n",
      "    val_loss       : -1398.7443033854167\n",
      "    val_ess        : 3.7481496334075928\n",
      "    val_log_marginal: 1398.8611653645833\n",
      "Train Epoch: 476 [0/54000 (0%)] Loss: -1402.714600\n",
      "Train Epoch: 476 [32768/54000 (61%)] Loss: -1403.465088\n",
      "    epoch          : 476\n",
      "    loss           : -1400.0280508365272\n",
      "    ess            : 3.7393359103292787\n",
      "    log_marginal   : 1400.1526316516804\n",
      "    val_loss       : -1399.0691731770833\n",
      "    val_ess        : 3.751984159151713\n",
      "    val_log_marginal: 1399.1863403320312\n",
      "Train Epoch: 477 [0/54000 (0%)] Loss: -1401.965576\n",
      "Train Epoch: 477 [32768/54000 (61%)] Loss: -1399.305908\n",
      "    epoch          : 477\n",
      "    loss           : -1400.3206902270047\n",
      "    ess            : 3.736313945842239\n",
      "    log_marginal   : 1400.4467520084022\n",
      "    val_loss       : -1399.5729573567708\n",
      "    val_ess        : 3.7367345889409385\n",
      "    val_log_marginal: 1399.6981201171875\n",
      "Train Epoch: 478 [0/54000 (0%)] Loss: -1400.919312\n",
      "Train Epoch: 478 [32768/54000 (61%)] Loss: -1400.557373\n",
      "    epoch          : 478\n",
      "    loss           : -1400.5118569428066\n",
      "    ess            : 3.7346820516406365\n",
      "    log_marginal   : 1400.6366220150353\n",
      "    val_loss       : -1399.8131306966145\n",
      "    val_ess        : 3.736022671063741\n",
      "    val_log_marginal: 1399.9435017903645\n",
      "Train Epoch: 479 [0/54000 (0%)] Loss: -1401.395508\n",
      "Train Epoch: 479 [32768/54000 (61%)] Loss: -1401.976807\n",
      "    epoch          : 479\n",
      "    loss           : -1400.8100470776828\n",
      "    ess            : 3.7353285573563486\n",
      "    log_marginal   : 1400.9368643130897\n",
      "    val_loss       : -1399.9750366210938\n",
      "    val_ess        : 3.7257553339004517\n",
      "    val_log_marginal: 1400.1053263346355\n",
      "Train Epoch: 480 [0/54000 (0%)] Loss: -1403.850098\n",
      "Train Epoch: 480 [32768/54000 (61%)] Loss: -1402.941772\n",
      "    epoch          : 480\n",
      "    loss           : -1401.0293567585495\n",
      "    ess            : 3.7391108521875345\n",
      "    log_marginal   : 1401.1523092017983\n",
      "    val_loss       : -1400.5657552083333\n",
      "    val_ess        : 3.7426867882410684\n",
      "    val_log_marginal: 1400.6893310546875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch480.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 481 [0/54000 (0%)] Loss: -1400.664185\n",
      "Train Epoch: 481 [32768/54000 (61%)] Loss: -1400.741455\n",
      "    epoch          : 481\n",
      "    loss           : -1401.5503528522995\n",
      "    ess            : 3.7392331429247587\n",
      "    log_marginal   : 1401.6744753279777\n",
      "    val_loss       : -1400.4339192708333\n",
      "    val_ess        : 3.738378564516703\n",
      "    val_log_marginal: 1400.553731282552\n",
      "Train Epoch: 482 [0/54000 (0%)] Loss: -1399.306885\n",
      "Train Epoch: 482 [32768/54000 (61%)] Loss: -1402.671265\n",
      "    epoch          : 482\n",
      "    loss           : -1401.6841119730248\n",
      "    ess            : 3.737076349978177\n",
      "    log_marginal   : 1401.8087572781544\n",
      "    val_loss       : -1400.5298665364583\n",
      "    val_ess        : 3.739097277323405\n",
      "    val_log_marginal: 1400.6591186523438\n",
      "Train Epoch: 483 [0/54000 (0%)] Loss: -1400.947144\n",
      "Train Epoch: 483 [32768/54000 (61%)] Loss: -1407.528320\n",
      "    epoch          : 483\n",
      "    loss           : -1401.8878404149468\n",
      "    ess            : 3.73821599978321\n",
      "    log_marginal   : 1402.0142937426297\n",
      "    val_loss       : -1400.9803670247395\n",
      "    val_ess        : 3.7321239709854126\n",
      "    val_log_marginal: 1401.113037109375\n",
      "Train Epoch: 484 [0/54000 (0%)] Loss: -1398.697021\n",
      "Train Epoch: 484 [32768/54000 (61%)] Loss: -1404.135986\n",
      "    epoch          : 484\n",
      "    loss           : -1402.0689351783608\n",
      "    ess            : 3.732905756752446\n",
      "    log_marginal   : 1402.1993500331662\n",
      "    val_loss       : -1401.4963785807292\n",
      "    val_ess        : 3.7413076957066855\n",
      "    val_log_marginal: 1401.6216227213542\n",
      "Train Epoch: 485 [0/54000 (0%)] Loss: -1402.964966\n",
      "Train Epoch: 485 [32768/54000 (61%)] Loss: -1402.481689\n",
      "    epoch          : 485\n",
      "    loss           : -1402.4750861401828\n",
      "    ess            : 3.7402533135324156\n",
      "    log_marginal   : 1402.5992385576355\n",
      "    val_loss       : -1401.7497965494792\n",
      "    val_ess        : 3.7366655667622886\n",
      "    val_log_marginal: 1401.8788045247395\n",
      "Train Epoch: 486 [0/54000 (0%)] Loss: -1403.527222\n",
      "Train Epoch: 486 [32768/54000 (61%)] Loss: -1402.657227\n",
      "    epoch          : 486\n",
      "    loss           : -1402.6705161040684\n",
      "    ess            : 3.736996448264932\n",
      "    log_marginal   : 1402.7979114460495\n",
      "    val_loss       : -1401.6854248046875\n",
      "    val_ess        : 3.7325849135716758\n",
      "    val_log_marginal: 1401.8138631184895\n",
      "Train Epoch: 487 [0/54000 (0%)] Loss: -1404.528442\n",
      "Train Epoch: 487 [32768/54000 (61%)] Loss: -1401.234375\n",
      "    epoch          : 487\n",
      "    loss           : -1403.0351907982017\n",
      "    ess            : 3.7380830296930276\n",
      "    log_marginal   : 1403.1639726746757\n",
      "    val_loss       : -1402.0426228841145\n",
      "    val_ess        : 3.748907685279846\n",
      "    val_log_marginal: 1402.1653442382812\n",
      "Train Epoch: 488 [0/54000 (0%)] Loss: -1404.826416\n",
      "Train Epoch: 488 [32768/54000 (61%)] Loss: -1404.166870\n",
      "    epoch          : 488\n",
      "    loss           : -1403.302183906987\n",
      "    ess            : 3.7397852123908275\n",
      "    log_marginal   : 1403.4271401459316\n",
      "    val_loss       : -1402.5178833007812\n",
      "    val_ess        : 3.735399087270101\n",
      "    val_log_marginal: 1402.634745279948\n",
      "Train Epoch: 489 [0/54000 (0%)] Loss: -1405.653076\n",
      "Train Epoch: 489 [32768/54000 (61%)] Loss: -1399.665894\n",
      "    epoch          : 489\n",
      "    loss           : -1403.5596578346108\n",
      "    ess            : 3.738387697147873\n",
      "    log_marginal   : 1403.6859130859375\n",
      "    val_loss       : -1402.818827311198\n",
      "    val_ess        : 3.735194762547811\n",
      "    val_log_marginal: 1402.9443969726562\n",
      "Train Epoch: 490 [0/54000 (0%)] Loss: -1402.671143\n",
      "Train Epoch: 490 [32768/54000 (61%)] Loss: -1404.189941\n",
      "    epoch          : 490\n",
      "    loss           : -1403.8439480763561\n",
      "    ess            : 3.7390381885024735\n",
      "    log_marginal   : 1403.9695169700767\n",
      "    val_loss       : -1402.9287923177083\n",
      "    val_ess        : 3.747436205546061\n",
      "    val_log_marginal: 1403.0470174153645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch490.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 491 [0/54000 (0%)] Loss: -1404.890869\n",
      "Train Epoch: 491 [32768/54000 (61%)] Loss: -1404.017822\n",
      "    epoch          : 491\n",
      "    loss           : -1403.9976898769162\n",
      "    ess            : 3.739447368765777\n",
      "    log_marginal   : 1404.1232679834907\n",
      "    val_loss       : -1403.4048868815105\n",
      "    val_ess        : 3.7445066769917807\n",
      "    val_log_marginal: 1403.5304158528645\n",
      "Train Epoch: 492 [0/54000 (0%)] Loss: -1403.495972\n",
      "Train Epoch: 492 [32768/54000 (61%)] Loss: -1405.885742\n",
      "    epoch          : 492\n",
      "    loss           : -1404.351541771079\n",
      "    ess            : 3.740990202381926\n",
      "    log_marginal   : 1404.476728331368\n",
      "    val_loss       : -1403.762430826823\n",
      "    val_ess        : 3.730734626452128\n",
      "    val_log_marginal: 1403.8913167317708\n",
      "Train Epoch: 493 [0/54000 (0%)] Loss: -1405.165771\n",
      "Train Epoch: 493 [32768/54000 (61%)] Loss: -1407.813477\n",
      "    epoch          : 493\n",
      "    loss           : -1404.5532088369694\n",
      "    ess            : 3.7449815588177375\n",
      "    log_marginal   : 1404.6792222508843\n",
      "    val_loss       : -1404.0306193033855\n",
      "    val_ess        : 3.7372548977533975\n",
      "    val_log_marginal: 1404.160400390625\n",
      "Train Epoch: 494 [0/54000 (0%)] Loss: -1404.920654\n",
      "Train Epoch: 494 [32768/54000 (61%)] Loss: -1403.956055\n",
      "    epoch          : 494\n",
      "    loss           : -1404.9587287183078\n",
      "    ess            : 3.7384971402726084\n",
      "    log_marginal   : 1405.085329451651\n",
      "    val_loss       : -1404.3544514973958\n",
      "    val_ess        : 3.7565411726633706\n",
      "    val_log_marginal: 1404.4614664713542\n",
      "Train Epoch: 495 [0/54000 (0%)] Loss: -1403.178955\n",
      "Train Epoch: 495 [32768/54000 (61%)] Loss: -1408.228760\n",
      "    epoch          : 495\n",
      "    loss           : -1405.1404177107902\n",
      "    ess            : 3.740785409819405\n",
      "    log_marginal   : 1405.2655927550118\n",
      "    val_loss       : -1404.5785725911458\n",
      "    val_ess        : 3.730907440185547\n",
      "    val_log_marginal: 1404.7122802734375\n",
      "Train Epoch: 496 [0/54000 (0%)] Loss: -1406.126465\n",
      "Train Epoch: 496 [32768/54000 (61%)] Loss: -1403.068726\n",
      "    epoch          : 496\n",
      "    loss           : -1405.4385525685436\n",
      "    ess            : 3.7408805163401477\n",
      "    log_marginal   : 1405.5669590212265\n",
      "    val_loss       : -1405.38037109375\n",
      "    val_ess        : 3.7440691788991294\n",
      "    val_log_marginal: 1405.5071614583333\n",
      "Train Epoch: 497 [0/54000 (0%)] Loss: -1405.145996\n",
      "Train Epoch: 497 [32768/54000 (61%)] Loss: -1405.835938\n",
      "    epoch          : 497\n",
      "    loss           : -1405.7842695128243\n",
      "    ess            : 3.7431090462882564\n",
      "    log_marginal   : 1405.9099812057782\n",
      "    val_loss       : -1405.2762654622395\n",
      "    val_ess        : 3.745750387509664\n",
      "    val_log_marginal: 1405.4071858723958\n",
      "Train Epoch: 498 [0/54000 (0%)] Loss: -1410.227539\n",
      "Train Epoch: 498 [32768/54000 (61%)] Loss: -1405.153320\n",
      "    epoch          : 498\n",
      "    loss           : -1405.8972237065154\n",
      "    ess            : 3.739288973358442\n",
      "    log_marginal   : 1406.0229722508843\n",
      "    val_loss       : -1405.3406372070312\n",
      "    val_ess        : 3.738759756088257\n",
      "    val_log_marginal: 1405.4651489257812\n",
      "Train Epoch: 499 [0/54000 (0%)] Loss: -1403.269287\n",
      "Train Epoch: 499 [32768/54000 (61%)] Loss: -1407.196289\n",
      "    epoch          : 499\n",
      "    loss           : -1406.3069446491745\n",
      "    ess            : 3.740931272506714\n",
      "    log_marginal   : 1406.4336006596404\n",
      "    val_loss       : -1405.4774373372395\n",
      "    val_ess        : 3.7374669710795083\n",
      "    val_log_marginal: 1405.6070556640625\n",
      "Train Epoch: 500 [0/54000 (0%)] Loss: -1409.741455\n",
      "Train Epoch: 500 [32768/54000 (61%)] Loss: -1409.373779\n",
      "    epoch          : 500\n",
      "    loss           : -1406.6044369103774\n",
      "    ess            : 3.7401103838434757\n",
      "    log_marginal   : 1406.7315098024765\n",
      "    val_loss       : -1405.9844156901042\n",
      "    val_ess        : 3.7465606133143106\n",
      "    val_log_marginal: 1406.1079508463542\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch500.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 501 [0/54000 (0%)] Loss: -1405.255127\n",
      "Train Epoch: 501 [32768/54000 (61%)] Loss: -1406.680176\n",
      "    epoch          : 501\n",
      "    loss           : -1406.9088848761792\n",
      "    ess            : 3.7400486379299522\n",
      "    log_marginal   : 1407.0340115529186\n",
      "    val_loss       : -1406.2992553710938\n",
      "    val_ess        : 3.7466627756754556\n",
      "    val_log_marginal: 1406.4214884440105\n",
      "Train Epoch: 502 [0/54000 (0%)] Loss: -1407.698242\n",
      "Train Epoch: 502 [32768/54000 (61%)] Loss: -1407.780640\n",
      "    epoch          : 502\n",
      "    loss           : -1407.1355279886498\n",
      "    ess            : 3.7451667155859605\n",
      "    log_marginal   : 1407.2580750663326\n",
      "    val_loss       : -1406.44921875\n",
      "    val_ess        : 3.742744207382202\n",
      "    val_log_marginal: 1406.5808512369792\n",
      "Train Epoch: 503 [0/54000 (0%)] Loss: -1405.305542\n",
      "Train Epoch: 503 [32768/54000 (61%)] Loss: -1406.214600\n",
      "    epoch          : 503\n",
      "    loss           : -1407.408576245578\n",
      "    ess            : 3.7380242527655834\n",
      "    log_marginal   : 1407.5345689305718\n",
      "    val_loss       : -1406.8755696614583\n",
      "    val_ess        : 3.744607925415039\n",
      "    val_log_marginal: 1406.9983723958333\n",
      "Train Epoch: 504 [0/54000 (0%)] Loss: -1412.063477\n",
      "Train Epoch: 504 [32768/54000 (61%)] Loss: -1406.584473\n",
      "    epoch          : 504\n",
      "    loss           : -1407.7754850567512\n",
      "    ess            : 3.7444993414968812\n",
      "    log_marginal   : 1407.8980505601414\n",
      "    val_loss       : -1407.5669962565105\n",
      "    val_ess        : 3.7372366189956665\n",
      "    val_log_marginal: 1407.6981811523438\n",
      "Train Epoch: 505 [0/54000 (0%)] Loss: -1408.236084\n",
      "Train Epoch: 505 [32768/54000 (61%)] Loss: -1407.111328\n",
      "    epoch          : 505\n",
      "    loss           : -1408.2536874447228\n",
      "    ess            : 3.741233429818783\n",
      "    log_marginal   : 1408.3793761055424\n",
      "    val_loss       : -1407.6130981445312\n",
      "    val_ess        : 3.747776826222738\n",
      "    val_log_marginal: 1407.738016764323\n",
      "Train Epoch: 506 [0/54000 (0%)] Loss: -1406.295288\n",
      "Train Epoch: 506 [32768/54000 (61%)] Loss: -1408.906738\n",
      "    epoch          : 506\n",
      "    loss           : -1408.3118274616745\n",
      "    ess            : 3.7417899842532174\n",
      "    log_marginal   : 1408.438190964033\n",
      "    val_loss       : -1407.4774576822917\n",
      "    val_ess        : 3.7445561488469443\n",
      "    val_log_marginal: 1407.6021118164062\n",
      "Train Epoch: 507 [0/54000 (0%)] Loss: -1407.727051\n",
      "Train Epoch: 507 [32768/54000 (61%)] Loss: -1408.782471\n",
      "    epoch          : 507\n",
      "    loss           : -1408.394779997052\n",
      "    ess            : 3.743492211935655\n",
      "    log_marginal   : 1408.518674454599\n",
      "    val_loss       : -1407.8466389973958\n",
      "    val_ess        : 3.7372434536616006\n",
      "    val_log_marginal: 1407.9755045572917\n",
      "Train Epoch: 508 [0/54000 (0%)] Loss: -1414.785889\n",
      "Train Epoch: 508 [32768/54000 (61%)] Loss: -1407.378906\n",
      "    epoch          : 508\n",
      "    loss           : -1408.9548639261498\n",
      "    ess            : 3.743138866604499\n",
      "    log_marginal   : 1409.0786985001473\n",
      "    val_loss       : -1408.2232462565105\n",
      "    val_ess        : 3.7457465728123984\n",
      "    val_log_marginal: 1408.345479329427\n",
      "Train Epoch: 509 [0/54000 (0%)] Loss: -1411.283325\n",
      "Train Epoch: 509 [32768/54000 (61%)] Loss: -1412.070312\n",
      "    epoch          : 509\n",
      "    loss           : -1409.1432852115272\n",
      "    ess            : 3.744715488181924\n",
      "    log_marginal   : 1409.266191590507\n",
      "    val_loss       : -1408.5708618164062\n",
      "    val_ess        : 3.741874615351359\n",
      "    val_log_marginal: 1408.698974609375\n",
      "Train Epoch: 510 [0/54000 (0%)] Loss: -1409.887451\n",
      "Train Epoch: 510 [32768/54000 (61%)] Loss: -1406.550049\n",
      "    epoch          : 510\n",
      "    loss           : -1409.3620283018868\n",
      "    ess            : 3.7406724578929396\n",
      "    log_marginal   : 1409.4868002837559\n",
      "    val_loss       : -1408.6776123046875\n",
      "    val_ess        : 3.7319363355636597\n",
      "    val_log_marginal: 1408.8023071289062\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch510.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 511 [0/54000 (0%)] Loss: -1408.520508\n",
      "Train Epoch: 511 [32768/54000 (61%)] Loss: -1409.662109\n",
      "    epoch          : 511\n",
      "    loss           : -1409.6212319428066\n",
      "    ess            : 3.7435950828048417\n",
      "    log_marginal   : 1409.747563200177\n",
      "    val_loss       : -1409.037577311198\n",
      "    val_ess        : 3.7389363050460815\n",
      "    val_log_marginal: 1409.1590169270833\n",
      "Train Epoch: 512 [0/54000 (0%)] Loss: -1409.975708\n",
      "Train Epoch: 512 [32768/54000 (61%)] Loss: -1409.427368\n",
      "    epoch          : 512\n",
      "    loss           : -1409.7988258217865\n",
      "    ess            : 3.7425586007676035\n",
      "    log_marginal   : 1409.9237267836086\n",
      "    val_loss       : -1409.4995727539062\n",
      "    val_ess        : 3.7525347073872886\n",
      "    val_log_marginal: 1409.6158447265625\n",
      "Train Epoch: 513 [0/54000 (0%)] Loss: -1410.874268\n",
      "Train Epoch: 513 [32768/54000 (61%)] Loss: -1408.008301\n",
      "    epoch          : 513\n",
      "    loss           : -1409.9571256817512\n",
      "    ess            : 3.7400599110801265\n",
      "    log_marginal   : 1410.0846246683373\n",
      "    val_loss       : -1409.349873860677\n",
      "    val_ess        : 3.743623892466227\n",
      "    val_log_marginal: 1409.470947265625\n",
      "Train Epoch: 514 [0/54000 (0%)] Loss: -1412.309570\n",
      "Train Epoch: 514 [32768/54000 (61%)] Loss: -1411.516235\n",
      "    epoch          : 514\n",
      "    loss           : -1410.3169267762382\n",
      "    ess            : 3.7470072710289144\n",
      "    log_marginal   : 1410.4396788399174\n",
      "    val_loss       : -1409.8003743489583\n",
      "    val_ess        : 3.7370904684066772\n",
      "    val_log_marginal: 1409.9346110026042\n",
      "Train Epoch: 515 [0/54000 (0%)] Loss: -1410.979614\n",
      "Train Epoch: 515 [32768/54000 (61%)] Loss: -1409.558594\n",
      "    epoch          : 515\n",
      "    loss           : -1410.5396475162147\n",
      "    ess            : 3.7427595831313223\n",
      "    log_marginal   : 1410.6632609817218\n",
      "    val_loss       : -1409.8916625976562\n",
      "    val_ess        : 3.7302285035451255\n",
      "    val_log_marginal: 1410.0208740234375\n",
      "Train Epoch: 516 [0/54000 (0%)] Loss: -1411.395020\n",
      "Train Epoch: 516 [32768/54000 (61%)] Loss: -1411.736572\n",
      "    epoch          : 516\n",
      "    loss           : -1410.699727760171\n",
      "    ess            : 3.7382530896168835\n",
      "    log_marginal   : 1410.828311560289\n",
      "    val_loss       : -1410.0770874023438\n",
      "    val_ess        : 3.750170111656189\n",
      "    val_log_marginal: 1410.1903279622395\n",
      "Train Epoch: 517 [0/54000 (0%)] Loss: -1410.664795\n",
      "Train Epoch: 517 [32768/54000 (61%)] Loss: -1411.205811\n",
      "    epoch          : 517\n",
      "    loss           : -1411.0028122236145\n",
      "    ess            : 3.7415510213600016\n",
      "    log_marginal   : 1411.1271327756485\n",
      "    val_loss       : -1410.6644083658855\n",
      "    val_ess        : 3.751801013946533\n",
      "    val_log_marginal: 1410.7812906901042\n",
      "Train Epoch: 518 [0/54000 (0%)] Loss: -1413.869141\n",
      "Train Epoch: 518 [32768/54000 (61%)] Loss: -1410.079834\n",
      "    epoch          : 518\n",
      "    loss           : -1411.176446878685\n",
      "    ess            : 3.739423149036911\n",
      "    log_marginal   : 1411.3031742887677\n",
      "    val_loss       : -1410.730244954427\n",
      "    val_ess        : 3.743521730105082\n",
      "    val_log_marginal: 1410.8501586914062\n",
      "Train Epoch: 519 [0/54000 (0%)] Loss: -1414.015137\n",
      "Train Epoch: 519 [32768/54000 (61%)] Loss: -1409.769531\n",
      "    epoch          : 519\n",
      "    loss           : -1411.4144955041274\n",
      "    ess            : 3.744107093451158\n",
      "    log_marginal   : 1411.5395968455189\n",
      "    val_loss       : -1410.7419840494792\n",
      "    val_ess        : 3.7412317991256714\n",
      "    val_log_marginal: 1410.8748372395833\n",
      "Train Epoch: 520 [0/54000 (0%)] Loss: -1410.050415\n",
      "Train Epoch: 520 [32768/54000 (61%)] Loss: -1409.401123\n",
      "    epoch          : 520\n",
      "    loss           : -1411.7289440227005\n",
      "    ess            : 3.744512288075573\n",
      "    log_marginal   : 1411.8524469339623\n",
      "    val_loss       : -1411.2201334635417\n",
      "    val_ess        : 3.7599941889444985\n",
      "    val_log_marginal: 1411.3341674804688\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch520.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 521 [0/54000 (0%)] Loss: -1411.793701\n",
      "Train Epoch: 521 [32768/54000 (61%)] Loss: -1410.858154\n",
      "    epoch          : 521\n",
      "    loss           : -1411.97426158977\n",
      "    ess            : 3.737418251217536\n",
      "    log_marginal   : 1412.103739036704\n",
      "    val_loss       : -1411.4837239583333\n",
      "    val_ess        : 3.746722420056661\n",
      "    val_log_marginal: 1411.6044311523438\n",
      "Train Epoch: 522 [0/54000 (0%)] Loss: -1415.568481\n",
      "Train Epoch: 522 [32768/54000 (61%)] Loss: -1413.907593\n",
      "    epoch          : 522\n",
      "    loss           : -1412.2843708542157\n",
      "    ess            : 3.7418245279564046\n",
      "    log_marginal   : 1412.4104372420402\n",
      "    val_loss       : -1411.8889567057292\n",
      "    val_ess        : 3.739033063252767\n",
      "    val_log_marginal: 1412.0153198242188\n",
      "Train Epoch: 523 [0/54000 (0%)] Loss: -1414.349609\n",
      "Train Epoch: 523 [32768/54000 (61%)] Loss: -1414.255005\n",
      "    epoch          : 523\n",
      "    loss           : -1412.6415117371757\n",
      "    ess            : 3.742732547364145\n",
      "    log_marginal   : 1412.766051094487\n",
      "    val_loss       : -1412.0711873372395\n",
      "    val_ess        : 3.732215325037638\n",
      "    val_log_marginal: 1412.201151529948\n",
      "Train Epoch: 524 [0/54000 (0%)] Loss: -1412.437500\n",
      "Train Epoch: 524 [32768/54000 (61%)] Loss: -1411.382935\n",
      "    epoch          : 524\n",
      "    loss           : -1412.7283659161262\n",
      "    ess            : 3.7447836983878657\n",
      "    log_marginal   : 1412.8527440484966\n",
      "    val_loss       : -1412.1084391276042\n",
      "    val_ess        : 3.730967958768209\n",
      "    val_log_marginal: 1412.2381184895833\n",
      "Train Epoch: 525 [0/54000 (0%)] Loss: -1409.787720\n",
      "Train Epoch: 525 [32768/54000 (61%)] Loss: -1413.532471\n",
      "    epoch          : 525\n",
      "    loss           : -1413.1510884986733\n",
      "    ess            : 3.7416237300297\n",
      "    log_marginal   : 1413.2748954341096\n",
      "    val_loss       : -1412.5172932942708\n",
      "    val_ess        : 3.7455766995747886\n",
      "    val_log_marginal: 1412.6324259440105\n",
      "Train Epoch: 526 [0/54000 (0%)] Loss: -1413.010498\n",
      "Train Epoch: 526 [32768/54000 (61%)] Loss: -1411.828857\n",
      "    epoch          : 526\n",
      "    loss           : -1413.5711508696934\n",
      "    ess            : 3.747719274376923\n",
      "    log_marginal   : 1413.6928112102005\n",
      "    val_loss       : -1412.6293334960938\n",
      "    val_ess        : 3.746631304423014\n",
      "    val_log_marginal: 1412.7584635416667\n",
      "Train Epoch: 527 [0/54000 (0%)] Loss: -1414.554688\n",
      "Train Epoch: 527 [32768/54000 (61%)] Loss: -1413.985107\n",
      "    epoch          : 527\n",
      "    loss           : -1413.68568737102\n",
      "    ess            : 3.7457974766785243\n",
      "    log_marginal   : 1413.8100424712559\n",
      "    val_loss       : -1413.041280110677\n",
      "    val_ess        : 3.7506017684936523\n",
      "    val_log_marginal: 1413.161885579427\n",
      "Train Epoch: 528 [0/54000 (0%)] Loss: -1414.786377\n",
      "Train Epoch: 528 [32768/54000 (61%)] Loss: -1413.520996\n",
      "    epoch          : 528\n",
      "    loss           : -1413.8746337890625\n",
      "    ess            : 3.7471395663495333\n",
      "    log_marginal   : 1413.9974157945164\n",
      "    val_loss       : -1413.5507202148438\n",
      "    val_ess        : 3.7463366985321045\n",
      "    val_log_marginal: 1413.6769002278645\n",
      "Train Epoch: 529 [0/54000 (0%)] Loss: -1414.724243\n",
      "Train Epoch: 529 [32768/54000 (61%)] Loss: -1414.567139\n",
      "    epoch          : 529\n",
      "    loss           : -1414.2122526348762\n",
      "    ess            : 3.743919035173812\n",
      "    log_marginal   : 1414.3347467386498\n",
      "    val_loss       : -1413.5543009440105\n",
      "    val_ess        : 3.756538987159729\n",
      "    val_log_marginal: 1413.6758219401042\n",
      "Train Epoch: 530 [0/54000 (0%)] Loss: -1415.638428\n",
      "Train Epoch: 530 [32768/54000 (61%)] Loss: -1410.342285\n",
      "    epoch          : 530\n",
      "    loss           : -1414.5471559920402\n",
      "    ess            : 3.743135258836566\n",
      "    log_marginal   : 1414.6727502211086\n",
      "    val_loss       : -1413.9317220052083\n",
      "    val_ess        : 3.758716106414795\n",
      "    val_log_marginal: 1414.0531412760417\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch530.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 531 [0/54000 (0%)] Loss: -1418.734619\n",
      "Train Epoch: 531 [32768/54000 (61%)] Loss: -1413.782471\n",
      "    epoch          : 531\n",
      "    loss           : -1414.83684726931\n",
      "    ess            : 3.7476279240734174\n",
      "    log_marginal   : 1414.9620568617336\n",
      "    val_loss       : -1414.2347005208333\n",
      "    val_ess        : 3.746757706006368\n",
      "    val_log_marginal: 1414.3562622070312\n",
      "Train Epoch: 532 [0/54000 (0%)] Loss: -1412.521729\n",
      "Train Epoch: 532 [32768/54000 (61%)] Loss: -1413.837524\n",
      "    epoch          : 532\n",
      "    loss           : -1414.9520010318397\n",
      "    ess            : 3.7475406763688572\n",
      "    log_marginal   : 1415.0742026275059\n",
      "    val_loss       : -1414.40380859375\n",
      "    val_ess        : 3.747130354245504\n",
      "    val_log_marginal: 1414.530029296875\n",
      "Train Epoch: 533 [0/54000 (0%)] Loss: -1416.293335\n",
      "Train Epoch: 533 [32768/54000 (61%)] Loss: -1414.999878\n",
      "    epoch          : 533\n",
      "    loss           : -1415.250223411704\n",
      "    ess            : 3.746474823861752\n",
      "    log_marginal   : 1415.3744149837853\n",
      "    val_loss       : -1414.94580078125\n",
      "    val_ess        : 3.748997131983439\n",
      "    val_log_marginal: 1415.0641276041667\n",
      "Train Epoch: 534 [0/54000 (0%)] Loss: -1415.462891\n",
      "Train Epoch: 534 [32768/54000 (61%)] Loss: -1417.101562\n",
      "    epoch          : 534\n",
      "    loss           : -1415.5552149358784\n",
      "    ess            : 3.739344686832068\n",
      "    log_marginal   : 1415.6811845887382\n",
      "    val_loss       : -1414.811299641927\n",
      "    val_ess        : 3.749777356783549\n",
      "    val_log_marginal: 1414.9263712565105\n",
      "Train Epoch: 535 [0/54000 (0%)] Loss: -1416.187256\n",
      "Train Epoch: 535 [32768/54000 (61%)] Loss: -1412.170410\n",
      "    epoch          : 535\n",
      "    loss           : -1415.7241464290978\n",
      "    ess            : 3.7451956721971618\n",
      "    log_marginal   : 1415.849001326651\n",
      "    val_loss       : -1415.0072631835938\n",
      "    val_ess        : 3.747551202774048\n",
      "    val_log_marginal: 1415.127705891927\n",
      "Train Epoch: 536 [0/54000 (0%)] Loss: -1417.958252\n",
      "Train Epoch: 536 [32768/54000 (61%)] Loss: -1414.473145\n",
      "    epoch          : 536\n",
      "    loss           : -1416.0220164173054\n",
      "    ess            : 3.744003511824698\n",
      "    log_marginal   : 1416.145867113797\n",
      "    val_loss       : -1415.4573364257812\n",
      "    val_ess        : 3.7547746896743774\n",
      "    val_log_marginal: 1415.5836181640625\n",
      "Train Epoch: 537 [0/54000 (0%)] Loss: -1414.248901\n",
      "Train Epoch: 537 [32768/54000 (61%)] Loss: -1413.347656\n",
      "    epoch          : 537\n",
      "    loss           : -1416.3014883365272\n",
      "    ess            : 3.739502304005173\n",
      "    log_marginal   : 1416.4315715285968\n",
      "    val_loss       : -1415.6610921223958\n",
      "    val_ess        : 3.7579123179117837\n",
      "    val_log_marginal: 1415.7811889648438\n",
      "Train Epoch: 538 [0/54000 (0%)] Loss: -1414.770142\n",
      "Train Epoch: 538 [32768/54000 (61%)] Loss: -1413.984985\n",
      "    epoch          : 538\n",
      "    loss           : -1416.6329046285377\n",
      "    ess            : 3.745775335239914\n",
      "    log_marginal   : 1416.7559814453125\n",
      "    val_loss       : -1416.2599080403645\n",
      "    val_ess        : 3.743741790453593\n",
      "    val_log_marginal: 1416.383321126302\n",
      "Train Epoch: 539 [0/54000 (0%)] Loss: -1420.302979\n",
      "Train Epoch: 539 [32768/54000 (61%)] Loss: -1415.927124\n",
      "    epoch          : 539\n",
      "    loss           : -1416.6804521668632\n",
      "    ess            : 3.745682531932615\n",
      "    log_marginal   : 1416.8041093934257\n",
      "    val_loss       : -1416.014628092448\n",
      "    val_ess        : 3.735940853754679\n",
      "    val_log_marginal: 1416.1393432617188\n",
      "Train Epoch: 540 [0/54000 (0%)] Loss: -1418.402344\n",
      "Train Epoch: 540 [32768/54000 (61%)] Loss: -1419.006104\n",
      "    epoch          : 540\n",
      "    loss           : -1417.040059791421\n",
      "    ess            : 3.747711015197466\n",
      "    log_marginal   : 1417.1627082104953\n",
      "    val_loss       : -1416.0474039713542\n",
      "    val_ess        : 3.754639228185018\n",
      "    val_log_marginal: 1416.166259765625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch540.pth ...\n",
      "Train Epoch: 541 [0/54000 (0%)] Loss: -1415.378662\n",
      "Train Epoch: 541 [32768/54000 (61%)] Loss: -1416.072998\n",
      "    epoch          : 541\n",
      "    loss           : -1417.2749299823113\n",
      "    ess            : 3.7398095580766784\n",
      "    log_marginal   : 1417.4015767799233\n",
      "    val_loss       : -1416.746805826823\n",
      "    val_ess        : 3.749144275983175\n",
      "    val_log_marginal: 1416.8660888671875\n",
      "Train Epoch: 542 [0/54000 (0%)] Loss: -1418.122803\n",
      "Train Epoch: 542 [32768/54000 (61%)] Loss: -1414.038574\n",
      "    epoch          : 542\n",
      "    loss           : -1417.6094970703125\n",
      "    ess            : 3.746441940091691\n",
      "    log_marginal   : 1417.7343819096404\n",
      "    val_loss       : -1416.7430419921875\n",
      "    val_ess        : 3.7523462772369385\n",
      "    val_log_marginal: 1416.8613688151042\n",
      "Train Epoch: 543 [0/54000 (0%)] Loss: -1419.180176\n",
      "Train Epoch: 543 [32768/54000 (61%)] Loss: -1418.412964\n",
      "    epoch          : 543\n",
      "    loss           : -1417.9114759913032\n",
      "    ess            : 3.7481168306098795\n",
      "    log_marginal   : 1418.0336937094635\n",
      "    val_loss       : -1417.334452311198\n",
      "    val_ess        : 3.743190328280131\n",
      "    val_log_marginal: 1417.4611206054688\n",
      "Train Epoch: 544 [0/54000 (0%)] Loss: -1418.636719\n",
      "Train Epoch: 544 [32768/54000 (61%)] Loss: -1422.093140\n",
      "    epoch          : 544\n",
      "    loss           : -1418.1468828309257\n",
      "    ess            : 3.7496452961327895\n",
      "    log_marginal   : 1418.2670460826946\n",
      "    val_loss       : -1417.170918782552\n",
      "    val_ess        : 3.739277203877767\n",
      "    val_log_marginal: 1417.29541015625\n",
      "Train Epoch: 545 [0/54000 (0%)] Loss: -1423.301514\n",
      "Train Epoch: 545 [32768/54000 (61%)] Loss: -1420.325928\n",
      "    epoch          : 545\n",
      "    loss           : -1418.3176868366745\n",
      "    ess            : 3.7434755001427993\n",
      "    log_marginal   : 1418.4422400132664\n",
      "    val_loss       : -1417.6926879882812\n",
      "    val_ess        : 3.7444215615590415\n",
      "    val_log_marginal: 1417.8119506835938\n",
      "Train Epoch: 546 [0/54000 (0%)] Loss: -1418.944092\n",
      "Train Epoch: 546 [32768/54000 (61%)] Loss: -1420.342041\n",
      "    epoch          : 546\n",
      "    loss           : -1418.574649450914\n",
      "    ess            : 3.7489176966109365\n",
      "    log_marginal   : 1418.6974291531544\n",
      "    val_loss       : -1417.9290974934895\n",
      "    val_ess        : 3.7519364754358926\n",
      "    val_log_marginal: 1418.0445353190105\n",
      "Train Epoch: 547 [0/54000 (0%)] Loss: -1417.152100\n",
      "Train Epoch: 547 [32768/54000 (61%)] Loss: -1419.591919\n",
      "    epoch          : 547\n",
      "    loss           : -1418.9287662146226\n",
      "    ess            : 3.7422028667521925\n",
      "    log_marginal   : 1419.0561270084022\n",
      "    val_loss       : -1418.1880900065105\n",
      "    val_ess        : 3.745837688446045\n",
      "    val_log_marginal: 1418.313496907552\n",
      "Train Epoch: 548 [0/54000 (0%)] Loss: -1420.662598\n",
      "Train Epoch: 548 [32768/54000 (61%)] Loss: -1421.366577\n",
      "    epoch          : 548\n",
      "    loss           : -1419.0888856132076\n",
      "    ess            : 3.7477037951631367\n",
      "    log_marginal   : 1419.2116722250885\n",
      "    val_loss       : -1418.1827189127605\n",
      "    val_ess        : 3.739436229070028\n",
      "    val_log_marginal: 1418.3118896484375\n",
      "Train Epoch: 549 [0/54000 (0%)] Loss: -1420.523438\n",
      "Train Epoch: 549 [32768/54000 (61%)] Loss: -1419.022583\n",
      "    epoch          : 549\n",
      "    loss           : -1419.29680820681\n",
      "    ess            : 3.7460156431737937\n",
      "    log_marginal   : 1419.4220661667157\n",
      "    val_loss       : -1418.4961751302083\n",
      "    val_ess        : 3.7409359216690063\n",
      "    val_log_marginal: 1418.6198120117188\n",
      "Train Epoch: 550 [0/54000 (0%)] Loss: -1418.277100\n",
      "Train Epoch: 550 [32768/54000 (61%)] Loss: -1421.306519\n",
      "    epoch          : 550\n",
      "    loss           : -1419.6578000626473\n",
      "    ess            : 3.749558111406722\n",
      "    log_marginal   : 1419.7809620983196\n",
      "    val_loss       : -1418.6298014322917\n",
      "    val_ess        : 3.746126413345337\n",
      "    val_log_marginal: 1418.7494303385417\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch550.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 551 [0/54000 (0%)] Loss: -1419.496826\n",
      "Train Epoch: 551 [32768/54000 (61%)] Loss: -1417.884521\n",
      "    epoch          : 551\n",
      "    loss           : -1419.7102580520343\n",
      "    ess            : 3.7498268316376886\n",
      "    log_marginal   : 1419.8313518020343\n",
      "    val_loss       : -1418.9262084960938\n",
      "    val_ess        : 3.7558993101119995\n",
      "    val_log_marginal: 1419.0396118164062\n",
      "Train Epoch: 552 [0/54000 (0%)] Loss: -1420.313721\n",
      "Train Epoch: 552 [32768/54000 (61%)] Loss: -1420.266602\n",
      "    epoch          : 552\n",
      "    loss           : -1419.9779582473468\n",
      "    ess            : 3.747674622625675\n",
      "    log_marginal   : 1420.1023041347287\n",
      "    val_loss       : -1419.439717610677\n",
      "    val_ess        : 3.7429638703664145\n",
      "    val_log_marginal: 1419.5592447916667\n",
      "Train Epoch: 553 [0/54000 (0%)] Loss: -1423.227173\n",
      "Train Epoch: 553 [32768/54000 (61%)] Loss: -1421.236694\n",
      "    epoch          : 553\n",
      "    loss           : -1420.1923528707252\n",
      "    ess            : 3.745503511068956\n",
      "    log_marginal   : 1420.3182027564858\n",
      "    val_loss       : -1419.3956909179688\n",
      "    val_ess        : 3.7517131567001343\n",
      "    val_log_marginal: 1419.5181477864583\n",
      "Train Epoch: 554 [0/54000 (0%)] Loss: -1421.604004\n",
      "Train Epoch: 554 [32768/54000 (61%)] Loss: -1422.377441\n",
      "    epoch          : 554\n",
      "    loss           : -1420.5188057377654\n",
      "    ess            : 3.7509620279636025\n",
      "    log_marginal   : 1420.6401551444576\n",
      "    val_loss       : -1419.5880330403645\n",
      "    val_ess        : 3.7509552637736\n",
      "    val_log_marginal: 1419.7047322591145\n",
      "Train Epoch: 555 [0/54000 (0%)] Loss: -1418.936279\n",
      "Train Epoch: 555 [32768/54000 (61%)] Loss: -1419.597046\n",
      "    epoch          : 555\n",
      "    loss           : -1420.7340963111733\n",
      "    ess            : 3.744900901362581\n",
      "    log_marginal   : 1420.8594855542453\n",
      "    val_loss       : -1419.8766479492188\n",
      "    val_ess        : 3.7488169272740683\n",
      "    val_log_marginal: 1419.99853515625\n",
      "Train Epoch: 556 [0/54000 (0%)] Loss: -1421.810059\n",
      "Train Epoch: 556 [32768/54000 (61%)] Loss: -1420.859375\n",
      "    epoch          : 556\n",
      "    loss           : -1421.0687509212853\n",
      "    ess            : 3.749389801385268\n",
      "    log_marginal   : 1421.192631559552\n",
      "    val_loss       : -1420.0466715494792\n",
      "    val_ess        : 3.7595564126968384\n",
      "    val_log_marginal: 1420.167236328125\n",
      "Train Epoch: 557 [0/54000 (0%)] Loss: -1421.966797\n",
      "Train Epoch: 557 [32768/54000 (61%)] Loss: -1421.984619\n",
      "    epoch          : 557\n",
      "    loss           : -1421.2881412146226\n",
      "    ess            : 3.7474266583064817\n",
      "    log_marginal   : 1421.4128809515034\n",
      "    val_loss       : -1420.1658935546875\n",
      "    val_ess        : 3.7447470823923745\n",
      "    val_log_marginal: 1420.2979125976562\n",
      "Train Epoch: 558 [0/54000 (0%)] Loss: -1421.033936\n",
      "Train Epoch: 558 [32768/54000 (61%)] Loss: -1419.188110\n",
      "    epoch          : 558\n",
      "    loss           : -1421.486837135171\n",
      "    ess            : 3.7485504735190913\n",
      "    log_marginal   : 1421.6101972471993\n",
      "    val_loss       : -1420.424560546875\n",
      "    val_ess        : 3.752049128214518\n",
      "    val_log_marginal: 1420.5479939778645\n",
      "Train Epoch: 559 [0/54000 (0%)] Loss: -1424.559082\n",
      "Train Epoch: 559 [32768/54000 (61%)] Loss: -1421.828247\n",
      "    epoch          : 559\n",
      "    loss           : -1421.771795308815\n",
      "    ess            : 3.749352410154523\n",
      "    log_marginal   : 1421.8958210495282\n",
      "    val_loss       : -1420.776387532552\n",
      "    val_ess        : 3.7416170040766397\n",
      "    val_log_marginal: 1420.9026692708333\n",
      "Train Epoch: 560 [0/54000 (0%)] Loss: -1421.329468\n",
      "Train Epoch: 560 [32768/54000 (61%)] Loss: -1420.308350\n",
      "    epoch          : 560\n",
      "    loss           : -1421.989630933078\n",
      "    ess            : 3.7510788665627532\n",
      "    log_marginal   : 1422.1091999557782\n",
      "    val_loss       : -1421.1857096354167\n",
      "    val_ess        : 3.742963949839274\n",
      "    val_log_marginal: 1421.3173217773438\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch560.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 561 [0/54000 (0%)] Loss: -1423.360229\n",
      "Train Epoch: 561 [32768/54000 (61%)] Loss: -1423.350586\n",
      "    epoch          : 561\n",
      "    loss           : -1422.256405236586\n",
      "    ess            : 3.7512019895157724\n",
      "    log_marginal   : 1422.3786644125885\n",
      "    val_loss       : -1421.4544881184895\n",
      "    val_ess        : 3.7478366692860923\n",
      "    val_log_marginal: 1421.5807495117188\n",
      "Train Epoch: 562 [0/54000 (0%)] Loss: -1424.317139\n",
      "Train Epoch: 562 [32768/54000 (61%)] Loss: -1421.745850\n",
      "    epoch          : 562\n",
      "    loss           : -1422.56061366819\n",
      "    ess            : 3.7474408374642425\n",
      "    log_marginal   : 1422.683953051297\n",
      "    val_loss       : -1421.6119384765625\n",
      "    val_ess        : 3.759438951810201\n",
      "    val_log_marginal: 1421.7288614908855\n",
      "Train Epoch: 563 [0/54000 (0%)] Loss: -1422.090088\n",
      "Train Epoch: 563 [32768/54000 (61%)] Loss: -1422.487061\n",
      "    epoch          : 563\n",
      "    loss           : -1422.7519370025059\n",
      "    ess            : 3.7502177706304587\n",
      "    log_marginal   : 1422.8740257407135\n",
      "    val_loss       : -1421.8884684244792\n",
      "    val_ess        : 3.745903412501017\n",
      "    val_log_marginal: 1422.0216471354167\n",
      "Train Epoch: 564 [0/54000 (0%)] Loss: -1424.930176\n",
      "Train Epoch: 564 [32768/54000 (61%)] Loss: -1423.175049\n",
      "    epoch          : 564\n",
      "    loss           : -1423.0291172243515\n",
      "    ess            : 3.7465883470931143\n",
      "    log_marginal   : 1423.155943672612\n",
      "    val_loss       : -1422.205810546875\n",
      "    val_ess        : 3.7460184892018638\n",
      "    val_log_marginal: 1422.3299763997395\n",
      "Train Epoch: 565 [0/54000 (0%)] Loss: -1425.482910\n",
      "Train Epoch: 565 [32768/54000 (61%)] Loss: -1425.845215\n",
      "    epoch          : 565\n",
      "    loss           : -1423.384708044664\n",
      "    ess            : 3.7491201814615502\n",
      "    log_marginal   : 1423.5085955925708\n",
      "    val_loss       : -1421.959981282552\n",
      "    val_ess        : 3.7534850041071572\n",
      "    val_log_marginal: 1422.0791422526042\n",
      "Train Epoch: 566 [0/54000 (0%)] Loss: -1425.199707\n",
      "Train Epoch: 566 [32768/54000 (61%)] Loss: -1425.248657\n",
      "    epoch          : 566\n",
      "    loss           : -1423.5383646263267\n",
      "    ess            : 3.750642902446243\n",
      "    log_marginal   : 1423.6600848503833\n",
      "    val_loss       : -1422.7062174479167\n",
      "    val_ess        : 3.743372321128845\n",
      "    val_log_marginal: 1422.8364868164062\n",
      "Train Epoch: 567 [0/54000 (0%)] Loss: -1423.560791\n",
      "Train Epoch: 567 [32768/54000 (61%)] Loss: -1422.688843\n",
      "    epoch          : 567\n",
      "    loss           : -1423.7781521779186\n",
      "    ess            : 3.7544205638597594\n",
      "    log_marginal   : 1423.8971638229657\n",
      "    val_loss       : -1422.7808634440105\n",
      "    val_ess        : 3.756399671236674\n",
      "    val_log_marginal: 1422.8963216145833\n",
      "Train Epoch: 568 [0/54000 (0%)] Loss: -1423.477173\n",
      "Train Epoch: 568 [32768/54000 (61%)] Loss: -1424.551514\n",
      "    epoch          : 568\n",
      "    loss           : -1424.0541761866157\n",
      "    ess            : 3.752945994431118\n",
      "    log_marginal   : 1424.176140551297\n",
      "    val_loss       : -1423.1765747070312\n",
      "    val_ess        : 3.740481416384379\n",
      "    val_log_marginal: 1423.3135986328125\n",
      "Train Epoch: 569 [0/54000 (0%)] Loss: -1421.710693\n",
      "Train Epoch: 569 [32768/54000 (61%)] Loss: -1421.105469\n",
      "    epoch          : 569\n",
      "    loss           : -1424.2127455225532\n",
      "    ess            : 3.7503241862890855\n",
      "    log_marginal   : 1424.3361839438385\n",
      "    val_loss       : -1423.2347208658855\n",
      "    val_ess        : 3.748955329259237\n",
      "    val_log_marginal: 1423.3613891601562\n",
      "Train Epoch: 570 [0/54000 (0%)] Loss: -1424.968018\n",
      "Train Epoch: 570 [32768/54000 (61%)] Loss: -1426.127075\n",
      "    epoch          : 570\n",
      "    loss           : -1424.5220002948113\n",
      "    ess            : 3.751558344319182\n",
      "    log_marginal   : 1424.6429927034198\n",
      "    val_loss       : -1423.4812622070312\n",
      "    val_ess        : 3.7594067255655923\n",
      "    val_log_marginal: 1423.6003824869792\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch570.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 571 [0/54000 (0%)] Loss: -1425.889160\n",
      "Train Epoch: 571 [32768/54000 (61%)] Loss: -1425.102051\n",
      "    epoch          : 571\n",
      "    loss           : -1424.57958984375\n",
      "    ess            : 3.751241427547527\n",
      "    log_marginal   : 1424.7027127247936\n",
      "    val_loss       : -1423.7508748372395\n",
      "    val_ess        : 3.759389082590739\n",
      "    val_log_marginal: 1423.8701171875\n",
      "Train Epoch: 572 [0/54000 (0%)] Loss: -1424.979004\n",
      "Train Epoch: 572 [32768/54000 (61%)] Loss: -1419.192383\n",
      "    epoch          : 572\n",
      "    loss           : -1424.7597794442806\n",
      "    ess            : 3.74563101102721\n",
      "    log_marginal   : 1424.8877229510613\n",
      "    val_loss       : -1423.7424723307292\n",
      "    val_ess        : 3.7564205328623452\n",
      "    val_log_marginal: 1423.8614298502605\n",
      "Train Epoch: 573 [0/54000 (0%)] Loss: -1429.108276\n",
      "Train Epoch: 573 [32768/54000 (61%)] Loss: -1423.506226\n",
      "    epoch          : 573\n",
      "    loss           : -1425.069943985849\n",
      "    ess            : 3.751472824024704\n",
      "    log_marginal   : 1425.1929309772995\n",
      "    val_loss       : -1424.4402872721355\n",
      "    val_ess        : 3.7447352409362793\n",
      "    val_log_marginal: 1424.569580078125\n",
      "Train Epoch: 574 [0/54000 (0%)] Loss: -1427.048096\n",
      "Train Epoch: 574 [32768/54000 (61%)] Loss: -1425.835938\n",
      "    epoch          : 574\n",
      "    loss           : -1425.358154296875\n",
      "    ess            : 3.748425636651381\n",
      "    log_marginal   : 1425.4850959058078\n",
      "    val_loss       : -1424.4049886067708\n",
      "    val_ess        : 3.765048344930013\n",
      "    val_log_marginal: 1424.5207112630208\n",
      "Train Epoch: 575 [0/54000 (0%)] Loss: -1428.053711\n",
      "Train Epoch: 575 [32768/54000 (61%)] Loss: -1424.852051\n",
      "    epoch          : 575\n",
      "    loss           : -1425.6224411298645\n",
      "    ess            : 3.7487449960888557\n",
      "    log_marginal   : 1425.7487332326061\n",
      "    val_loss       : -1424.6944173177083\n",
      "    val_ess        : 3.7586241960525513\n",
      "    val_log_marginal: 1424.8103434244792\n",
      "Train Epoch: 576 [0/54000 (0%)] Loss: -1424.658325\n",
      "Train Epoch: 576 [32768/54000 (61%)] Loss: -1425.674805\n",
      "    epoch          : 576\n",
      "    loss           : -1425.8381531913326\n",
      "    ess            : 3.7495693440707223\n",
      "    log_marginal   : 1425.9614419037441\n",
      "    val_loss       : -1425.2456868489583\n",
      "    val_ess        : 3.751965800921122\n",
      "    val_log_marginal: 1425.3672281901042\n",
      "Train Epoch: 577 [0/54000 (0%)] Loss: -1428.875977\n",
      "Train Epoch: 577 [32768/54000 (61%)] Loss: -1429.376831\n",
      "    epoch          : 577\n",
      "    loss           : -1426.0535888671875\n",
      "    ess            : 3.751355769499293\n",
      "    log_marginal   : 1426.1759125331662\n",
      "    val_loss       : -1425.1912434895833\n",
      "    val_ess        : 3.7430783112843833\n",
      "    val_log_marginal: 1425.3163452148438\n",
      "Train Epoch: 578 [0/54000 (0%)] Loss: -1429.533569\n",
      "Train Epoch: 578 [32768/54000 (61%)] Loss: -1425.580566\n",
      "    epoch          : 578\n",
      "    loss           : -1426.2455363723468\n",
      "    ess            : 3.750259003549252\n",
      "    log_marginal   : 1426.3717662883255\n",
      "    val_loss       : -1425.720194498698\n",
      "    val_ess        : 3.7634126345316568\n",
      "    val_log_marginal: 1425.8323771158855\n",
      "Train Epoch: 579 [0/54000 (0%)] Loss: -1426.184448\n",
      "Train Epoch: 579 [32768/54000 (61%)] Loss: -1428.854492\n",
      "    epoch          : 579\n",
      "    loss           : -1426.5797441590507\n",
      "    ess            : 3.750752619977267\n",
      "    log_marginal   : 1426.7017730137088\n",
      "    val_loss       : -1425.5980834960938\n",
      "    val_ess        : 3.751884659131368\n",
      "    val_log_marginal: 1425.7211303710938\n",
      "Train Epoch: 580 [0/54000 (0%)] Loss: -1425.656982\n",
      "Train Epoch: 580 [32768/54000 (61%)] Loss: -1428.589355\n",
      "    epoch          : 580\n",
      "    loss           : -1426.7884406323703\n",
      "    ess            : 3.751406836059858\n",
      "    log_marginal   : 1426.911455262382\n",
      "    val_loss       : -1426.0174967447917\n",
      "    val_ess        : 3.7574315468470254\n",
      "    val_log_marginal: 1426.1373291015625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch580.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 581 [0/54000 (0%)] Loss: -1427.813965\n",
      "Train Epoch: 581 [32768/54000 (61%)] Loss: -1427.482178\n",
      "    epoch          : 581\n",
      "    loss           : -1427.104206589033\n",
      "    ess            : 3.749050837642742\n",
      "    log_marginal   : 1427.2259751805718\n",
      "    val_loss       : -1426.6632893880208\n",
      "    val_ess        : 3.746346354484558\n",
      "    val_log_marginal: 1426.7882690429688\n",
      "Train Epoch: 582 [0/54000 (0%)] Loss: -1430.281372\n",
      "Train Epoch: 582 [32768/54000 (61%)] Loss: -1425.623047\n",
      "    epoch          : 582\n",
      "    loss           : -1427.4141154739093\n",
      "    ess            : 3.7481634706821083\n",
      "    log_marginal   : 1427.5376137787441\n",
      "    val_loss       : -1426.2380981445312\n",
      "    val_ess        : 3.745836098988851\n",
      "    val_log_marginal: 1426.3642985026042\n",
      "Train Epoch: 583 [0/54000 (0%)] Loss: -1426.447510\n",
      "Train Epoch: 583 [32768/54000 (61%)] Loss: -1428.905029\n",
      "    epoch          : 583\n",
      "    loss           : -1427.4976530255012\n",
      "    ess            : 3.7461033497216567\n",
      "    log_marginal   : 1427.6241754495873\n",
      "    val_loss       : -1426.59375\n",
      "    val_ess        : 3.7550361156463623\n",
      "    val_log_marginal: 1426.7123413085938\n",
      "Train Epoch: 584 [0/54000 (0%)] Loss: -1429.700684\n",
      "Train Epoch: 584 [32768/54000 (61%)] Loss: -1426.873901\n",
      "    epoch          : 584\n",
      "    loss           : -1427.7010083468456\n",
      "    ess            : 3.750838833035163\n",
      "    log_marginal   : 1427.8250571196934\n",
      "    val_loss       : -1427.0728963216145\n",
      "    val_ess        : 3.7425634066263833\n",
      "    val_log_marginal: 1427.2005411783855\n",
      "Train Epoch: 585 [0/54000 (0%)] Loss: -1430.198486\n",
      "Train Epoch: 585 [32768/54000 (61%)] Loss: -1429.783936\n",
      "    epoch          : 585\n",
      "    loss           : -1427.9317143278302\n",
      "    ess            : 3.7514675338313266\n",
      "    log_marginal   : 1428.056281323703\n",
      "    val_loss       : -1427.1534016927083\n",
      "    val_ess        : 3.754866043726603\n",
      "    val_log_marginal: 1427.2767333984375\n",
      "Train Epoch: 586 [0/54000 (0%)] Loss: -1426.681641\n",
      "Train Epoch: 586 [32768/54000 (61%)] Loss: -1428.203857\n",
      "    epoch          : 586\n",
      "    loss           : -1428.2550901017098\n",
      "    ess            : 3.7511071798936375\n",
      "    log_marginal   : 1428.376828751474\n",
      "    val_loss       : -1426.835917154948\n",
      "    val_ess        : 3.7479332288106284\n",
      "    val_log_marginal: 1426.9545084635417\n",
      "Train Epoch: 587 [0/54000 (0%)] Loss: -1430.692871\n",
      "Train Epoch: 587 [32768/54000 (61%)] Loss: -1426.528809\n",
      "    epoch          : 587\n",
      "    loss           : -1428.565756743809\n",
      "    ess            : 3.7503762605055324\n",
      "    log_marginal   : 1428.689395544664\n",
      "    val_loss       : -1427.5875651041667\n",
      "    val_ess        : 3.751943031946818\n",
      "    val_log_marginal: 1427.7051391601562\n",
      "Train Epoch: 588 [0/54000 (0%)] Loss: -1433.373535\n",
      "Train Epoch: 588 [32768/54000 (61%)] Loss: -1426.380615\n",
      "    epoch          : 588\n",
      "    loss           : -1428.688108048349\n",
      "    ess            : 3.751664827454765\n",
      "    log_marginal   : 1428.8099227041569\n",
      "    val_loss       : -1427.795878092448\n",
      "    val_ess        : 3.741405646006266\n",
      "    val_log_marginal: 1427.926981608073\n",
      "Train Epoch: 589 [0/54000 (0%)] Loss: -1426.150146\n",
      "Train Epoch: 589 [32768/54000 (61%)] Loss: -1428.969482\n",
      "    epoch          : 589\n",
      "    loss           : -1428.9825301260319\n",
      "    ess            : 3.7486563493620673\n",
      "    log_marginal   : 1429.1082510318397\n",
      "    val_loss       : -1428.2096557617188\n",
      "    val_ess        : 3.7566280364990234\n",
      "    val_log_marginal: 1428.3347981770833\n",
      "Train Epoch: 590 [0/54000 (0%)] Loss: -1427.382324\n",
      "Train Epoch: 590 [32768/54000 (61%)] Loss: -1429.944214\n",
      "    epoch          : 590\n",
      "    loss           : -1429.359250626474\n",
      "    ess            : 3.7519989013671875\n",
      "    log_marginal   : 1429.4824103589328\n",
      "    val_loss       : -1428.2347412109375\n",
      "    val_ess        : 3.7450225353240967\n",
      "    val_log_marginal: 1428.3646850585938\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch590.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 591 [0/54000 (0%)] Loss: -1429.326660\n",
      "Train Epoch: 591 [32768/54000 (61%)] Loss: -1429.336304\n",
      "    epoch          : 591\n",
      "    loss           : -1429.3888791642098\n",
      "    ess            : 3.751890097024306\n",
      "    log_marginal   : 1429.511168281987\n",
      "    val_loss       : -1428.2760009765625\n",
      "    val_ess        : 3.7485511302948\n",
      "    val_log_marginal: 1428.398193359375\n",
      "Train Epoch: 592 [0/54000 (0%)] Loss: -1431.045898\n",
      "Train Epoch: 592 [32768/54000 (61%)] Loss: -1430.504395\n",
      "    epoch          : 592\n",
      "    loss           : -1429.3643937020931\n",
      "    ess            : 3.75248377278166\n",
      "    log_marginal   : 1429.4860540426002\n",
      "    val_loss       : -1428.504170735677\n",
      "    val_ess        : 3.7533476750055947\n",
      "    val_log_marginal: 1428.629150390625\n",
      "Train Epoch: 593 [0/54000 (0%)] Loss: -1429.067993\n",
      "Train Epoch: 593 [32768/54000 (61%)] Loss: -1430.616211\n",
      "    epoch          : 593\n",
      "    loss           : -1429.8078129606427\n",
      "    ess            : 3.751965158390549\n",
      "    log_marginal   : 1429.9299754016804\n",
      "    val_loss       : -1429.0677693684895\n",
      "    val_ess        : 3.7526372273763022\n",
      "    val_log_marginal: 1429.1929117838542\n",
      "Train Epoch: 594 [0/54000 (0%)] Loss: -1429.069824\n",
      "Train Epoch: 594 [32768/54000 (61%)] Loss: -1429.887939\n",
      "    epoch          : 594\n",
      "    loss           : -1429.9992030881485\n",
      "    ess            : 3.7492911185858384\n",
      "    log_marginal   : 1430.1250322449882\n",
      "    val_loss       : -1429.3949788411458\n",
      "    val_ess        : 3.7641026973724365\n",
      "    val_log_marginal: 1429.504903157552\n",
      "Train Epoch: 595 [0/54000 (0%)] Loss: -1432.880859\n",
      "Train Epoch: 595 [32768/54000 (61%)] Loss: -1430.108276\n",
      "    epoch          : 595\n",
      "    loss           : -1430.169251639888\n",
      "    ess            : 3.7562106015547267\n",
      "    log_marginal   : 1430.2896636387088\n",
      "    val_loss       : -1429.573018391927\n",
      "    val_ess        : 3.7547714710235596\n",
      "    val_log_marginal: 1429.6961059570312\n",
      "Train Epoch: 596 [0/54000 (0%)] Loss: -1432.759033\n",
      "Train Epoch: 596 [32768/54000 (61%)] Loss: -1427.255127\n",
      "    epoch          : 596\n",
      "    loss           : -1430.5424482237618\n",
      "    ess            : 3.7535218112873583\n",
      "    log_marginal   : 1430.6635972508843\n",
      "    val_loss       : -1430.0345052083333\n",
      "    val_ess        : 3.7563324769337973\n",
      "    val_log_marginal: 1430.1593017578125\n",
      "Train Epoch: 597 [0/54000 (0%)] Loss: -1432.155029\n",
      "Train Epoch: 597 [32768/54000 (61%)] Loss: -1428.174561\n",
      "    epoch          : 597\n",
      "    loss           : -1430.8173344450177\n",
      "    ess            : 3.754271043921417\n",
      "    log_marginal   : 1430.9378408755897\n",
      "    val_loss       : -1430.2928263346355\n",
      "    val_ess        : 3.746917406717936\n",
      "    val_log_marginal: 1430.4176432291667\n",
      "Train Epoch: 598 [0/54000 (0%)] Loss: -1432.173340\n",
      "Train Epoch: 598 [32768/54000 (61%)] Loss: -1429.834839\n",
      "    epoch          : 598\n",
      "    loss           : -1430.8912491708431\n",
      "    ess            : 3.7468614848154895\n",
      "    log_marginal   : 1431.0154937168338\n",
      "    val_loss       : -1430.2820231119792\n",
      "    val_ess        : 3.772217273712158\n",
      "    val_log_marginal: 1430.3912353515625\n",
      "Train Epoch: 599 [0/54000 (0%)] Loss: -1435.374023\n",
      "Train Epoch: 599 [32768/54000 (61%)] Loss: -1430.598633\n",
      "    epoch          : 599\n",
      "    loss           : -1431.1445611917748\n",
      "    ess            : 3.753217562189642\n",
      "    log_marginal   : 1431.267400777565\n",
      "    val_loss       : -1430.8011881510417\n",
      "    val_ess        : 3.7426259915033975\n",
      "    val_log_marginal: 1430.9321695963542\n",
      "Train Epoch: 600 [0/54000 (0%)] Loss: -1432.327148\n",
      "Train Epoch: 600 [32768/54000 (61%)] Loss: -1429.138794\n",
      "    epoch          : 600\n",
      "    loss           : -1431.484978441922\n",
      "    ess            : 3.752458671353898\n",
      "    log_marginal   : 1431.6069727483784\n",
      "    val_loss       : -1430.8985799153645\n",
      "    val_ess        : 3.7494614919026694\n",
      "    val_log_marginal: 1431.0225219726562\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch600.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 601 [0/54000 (0%)] Loss: -1432.276489\n",
      "Train Epoch: 601 [32768/54000 (61%)] Loss: -1428.773071\n",
      "    epoch          : 601\n",
      "    loss           : -1431.864138045401\n",
      "    ess            : 3.749857448182016\n",
      "    log_marginal   : 1431.9877676334022\n",
      "    val_loss       : -1431.6445719401042\n",
      "    val_ess        : 3.7642990350723267\n",
      "    val_log_marginal: 1431.7675170898438\n",
      "Train Epoch: 602 [0/54000 (0%)] Loss: -1431.685547\n",
      "Train Epoch: 602 [32768/54000 (61%)] Loss: -1434.837646\n",
      "    epoch          : 602\n",
      "    loss           : -1432.0593607200767\n",
      "    ess            : 3.75500502676334\n",
      "    log_marginal   : 1432.180841409935\n",
      "    val_loss       : -1431.5983479817708\n",
      "    val_ess        : 3.745430827140808\n",
      "    val_log_marginal: 1431.722188313802\n",
      "Train Epoch: 603 [0/54000 (0%)] Loss: -1429.169434\n",
      "Train Epoch: 603 [32768/54000 (61%)] Loss: -1431.753662\n",
      "    epoch          : 603\n",
      "    loss           : -1432.30873424602\n",
      "    ess            : 3.754810045350273\n",
      "    log_marginal   : 1432.4293489276238\n",
      "    val_loss       : -1431.573486328125\n",
      "    val_ess        : 3.7694066365559897\n",
      "    val_log_marginal: 1431.6838785807292\n",
      "Train Epoch: 604 [0/54000 (0%)] Loss: -1432.482666\n",
      "Train Epoch: 604 [32768/54000 (61%)] Loss: -1432.886475\n",
      "    epoch          : 604\n",
      "    loss           : -1432.5446086379718\n",
      "    ess            : 3.755569174604596\n",
      "    log_marginal   : 1432.6673054245282\n",
      "    val_loss       : -1431.8151041666667\n",
      "    val_ess        : 3.7507702906926474\n",
      "    val_log_marginal: 1431.93896484375\n",
      "Train Epoch: 605 [0/54000 (0%)] Loss: -1433.939453\n",
      "Train Epoch: 605 [32768/54000 (61%)] Loss: -1432.513672\n",
      "    epoch          : 605\n",
      "    loss           : -1432.8330216317806\n",
      "    ess            : 3.7503837459492235\n",
      "    log_marginal   : 1432.9590097103478\n",
      "    val_loss       : -1432.0558268229167\n",
      "    val_ess        : 3.744404117266337\n",
      "    val_log_marginal: 1432.1968994140625\n",
      "Train Epoch: 606 [0/54000 (0%)] Loss: -1433.441650\n",
      "Train Epoch: 606 [32768/54000 (61%)] Loss: -1435.917358\n",
      "    epoch          : 606\n",
      "    loss           : -1432.9873415389152\n",
      "    ess            : 3.7566775196003466\n",
      "    log_marginal   : 1433.1051647258255\n",
      "    val_loss       : -1432.554463704427\n",
      "    val_ess        : 3.7600001891454062\n",
      "    val_log_marginal: 1432.677714029948\n",
      "Train Epoch: 607 [0/54000 (0%)] Loss: -1435.456665\n",
      "Train Epoch: 607 [32768/54000 (61%)] Loss: -1429.121826\n",
      "    epoch          : 607\n",
      "    loss           : -1433.1461527122642\n",
      "    ess            : 3.7509961668050513\n",
      "    log_marginal   : 1433.2724425117924\n",
      "    val_loss       : -1432.6008707682292\n",
      "    val_ess        : 3.7516581217447915\n",
      "    val_log_marginal: 1432.7186889648438\n",
      "Train Epoch: 608 [0/54000 (0%)] Loss: -1433.940796\n",
      "Train Epoch: 608 [32768/54000 (61%)] Loss: -1431.146606\n",
      "    epoch          : 608\n",
      "    loss           : -1433.3762183999115\n",
      "    ess            : 3.7564559342726223\n",
      "    log_marginal   : 1433.4971877763855\n",
      "    val_loss       : -1432.773417154948\n",
      "    val_ess        : 3.7541553576787314\n",
      "    val_log_marginal: 1432.8932495117188\n",
      "Train Epoch: 609 [0/54000 (0%)] Loss: -1434.360962\n",
      "Train Epoch: 609 [32768/54000 (61%)] Loss: -1432.664185\n",
      "    epoch          : 609\n",
      "    loss           : -1433.6309192585495\n",
      "    ess            : 3.753576485615856\n",
      "    log_marginal   : 1433.7547284971993\n",
      "    val_loss       : -1432.9768676757812\n",
      "    val_ess        : 3.7707923650741577\n",
      "    val_log_marginal: 1433.093017578125\n",
      "Train Epoch: 610 [0/54000 (0%)] Loss: -1433.223022\n",
      "Train Epoch: 610 [32768/54000 (61%)] Loss: -1434.057373\n",
      "    epoch          : 610\n",
      "    loss           : -1433.9520033350532\n",
      "    ess            : 3.7593957253222197\n",
      "    log_marginal   : 1434.074831404776\n",
      "    val_loss       : -1433.1878255208333\n",
      "    val_ess        : 3.7522968848546348\n",
      "    val_log_marginal: 1433.3068440755208\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch610.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 611 [0/54000 (0%)] Loss: -1433.044678\n",
      "Train Epoch: 611 [32768/54000 (61%)] Loss: -1434.951660\n",
      "    epoch          : 611\n",
      "    loss           : -1434.055233361586\n",
      "    ess            : 3.754693440671237\n",
      "    log_marginal   : 1434.1802725162147\n",
      "    val_loss       : -1433.419453938802\n",
      "    val_ess        : 3.7612564166386924\n",
      "    val_log_marginal: 1433.542744954427\n",
      "Train Epoch: 612 [0/54000 (0%)] Loss: -1433.843262\n",
      "Train Epoch: 612 [32768/54000 (61%)] Loss: -1433.962646\n",
      "    epoch          : 612\n",
      "    loss           : -1434.4064204377948\n",
      "    ess            : 3.7554904919750287\n",
      "    log_marginal   : 1434.5271710089917\n",
      "    val_loss       : -1433.888651529948\n",
      "    val_ess        : 3.7605220079421997\n",
      "    val_log_marginal: 1434.0105590820312\n",
      "Train Epoch: 613 [0/54000 (0%)] Loss: -1436.481689\n",
      "Train Epoch: 613 [32768/54000 (61%)] Loss: -1437.032959\n",
      "    epoch          : 613\n",
      "    loss           : -1434.6246798533314\n",
      "    ess            : 3.753906825803361\n",
      "    log_marginal   : 1434.744264998526\n",
      "    val_loss       : -1433.6988321940105\n",
      "    val_ess        : 3.757155696551005\n",
      "    val_log_marginal: 1433.8177693684895\n",
      "Train Epoch: 614 [0/54000 (0%)] Loss: -1433.848633\n",
      "Train Epoch: 614 [32768/54000 (61%)] Loss: -1434.720703\n",
      "    epoch          : 614\n",
      "    loss           : -1434.8455672354069\n",
      "    ess            : 3.753566917383446\n",
      "    log_marginal   : 1434.9658041900059\n",
      "    val_loss       : -1434.2556966145833\n",
      "    val_ess        : 3.755113363265991\n",
      "    val_log_marginal: 1434.3810017903645\n",
      "Train Epoch: 615 [0/54000 (0%)] Loss: -1434.534180\n",
      "Train Epoch: 615 [32768/54000 (61%)] Loss: -1434.513306\n",
      "    epoch          : 615\n",
      "    loss           : -1435.0915918890034\n",
      "    ess            : 3.7535065165105856\n",
      "    log_marginal   : 1435.2146548864976\n",
      "    val_loss       : -1434.3493245442708\n",
      "    val_ess        : 3.766236583391825\n",
      "    val_log_marginal: 1434.4598795572917\n",
      "Train Epoch: 616 [0/54000 (0%)] Loss: -1433.103271\n",
      "Train Epoch: 616 [32768/54000 (61%)] Loss: -1434.791260\n",
      "    epoch          : 616\n",
      "    loss           : -1435.363177605395\n",
      "    ess            : 3.7515097249229\n",
      "    log_marginal   : 1435.4883987138855\n",
      "    val_loss       : -1434.3552652994792\n",
      "    val_ess        : 3.7647433280944824\n",
      "    val_log_marginal: 1434.47119140625\n",
      "Train Epoch: 617 [0/54000 (0%)] Loss: -1436.338379\n",
      "Train Epoch: 617 [32768/54000 (61%)] Loss: -1434.061035\n",
      "    epoch          : 617\n",
      "    loss           : -1435.4369057709316\n",
      "    ess            : 3.7525911601084583\n",
      "    log_marginal   : 1435.5615004053657\n",
      "    val_loss       : -1434.693339029948\n",
      "    val_ess        : 3.764421304066976\n",
      "    val_log_marginal: 1434.8094278971355\n",
      "Train Epoch: 618 [0/54000 (0%)] Loss: -1434.429688\n",
      "Train Epoch: 618 [32768/54000 (61%)] Loss: -1434.615479\n",
      "    epoch          : 618\n",
      "    loss           : -1435.7723250479069\n",
      "    ess            : 3.7550433581730105\n",
      "    log_marginal   : 1435.892557396079\n",
      "    val_loss       : -1434.668436686198\n",
      "    val_ess        : 3.747061848640442\n",
      "    val_log_marginal: 1434.7908935546875\n",
      "Train Epoch: 619 [0/54000 (0%)] Loss: -1435.863037\n",
      "Train Epoch: 619 [32768/54000 (61%)] Loss: -1437.021118\n",
      "    epoch          : 619\n",
      "    loss           : -1436.0395784198113\n",
      "    ess            : 3.7539786842634095\n",
      "    log_marginal   : 1436.161558906987\n",
      "    val_loss       : -1435.0216878255208\n",
      "    val_ess        : 3.756608804066976\n",
      "    val_log_marginal: 1435.1412760416667\n",
      "Train Epoch: 620 [0/54000 (0%)] Loss: -1436.659180\n",
      "Train Epoch: 620 [32768/54000 (61%)] Loss: -1437.072144\n",
      "    epoch          : 620\n",
      "    loss           : -1436.1405328714623\n",
      "    ess            : 3.7563703599965796\n",
      "    log_marginal   : 1436.262455778302\n",
      "    val_loss       : -1435.1536051432292\n",
      "    val_ess        : 3.7586729923884072\n",
      "    val_log_marginal: 1435.2794189453125\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch620.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 621 [0/54000 (0%)] Loss: -1438.718994\n",
      "Train Epoch: 621 [32768/54000 (61%)] Loss: -1435.845825\n",
      "    epoch          : 621\n",
      "    loss           : -1436.4938527233196\n",
      "    ess            : 3.752959080462186\n",
      "    log_marginal   : 1436.6195943580483\n",
      "    val_loss       : -1435.5985107421875\n",
      "    val_ess        : 3.761216958363851\n",
      "    val_log_marginal: 1435.7164510091145\n",
      "Train Epoch: 622 [0/54000 (0%)] Loss: -1440.861816\n",
      "Train Epoch: 622 [32768/54000 (61%)] Loss: -1434.193970\n",
      "    epoch          : 622\n",
      "    loss           : -1436.5429871757076\n",
      "    ess            : 3.7533469425057464\n",
      "    log_marginal   : 1436.6658636129127\n",
      "    val_loss       : -1435.5015462239583\n",
      "    val_ess        : 3.7631804943084717\n",
      "    val_log_marginal: 1435.62255859375\n",
      "Train Epoch: 623 [0/54000 (0%)] Loss: -1433.873291\n",
      "Train Epoch: 623 [32768/54000 (61%)] Loss: -1437.932617\n",
      "    epoch          : 623\n",
      "    loss           : -1436.9315484964623\n",
      "    ess            : 3.7537682776181205\n",
      "    log_marginal   : 1437.0568962816922\n",
      "    val_loss       : -1435.740498860677\n",
      "    val_ess        : 3.7622411251068115\n",
      "    val_log_marginal: 1435.861836751302\n",
      "Train Epoch: 624 [0/54000 (0%)] Loss: -1438.486816\n",
      "Train Epoch: 624 [32768/54000 (61%)] Loss: -1439.900513\n",
      "    epoch          : 624\n",
      "    loss           : -1437.1676923643868\n",
      "    ess            : 3.755923626557836\n",
      "    log_marginal   : 1437.292538049086\n",
      "    val_loss       : -1436.27587890625\n",
      "    val_ess        : 3.7505984703699746\n",
      "    val_log_marginal: 1436.4031575520833\n",
      "Train Epoch: 625 [0/54000 (0%)] Loss: -1435.953125\n",
      "Train Epoch: 625 [32768/54000 (61%)] Loss: -1438.786377\n",
      "    epoch          : 625\n",
      "    loss           : -1437.3658193912147\n",
      "    ess            : 3.7581505550528473\n",
      "    log_marginal   : 1437.487908129422\n",
      "    val_loss       : -1436.7601725260417\n",
      "    val_ess        : 3.7728641827901206\n",
      "    val_log_marginal: 1436.8678792317708\n",
      "Train Epoch: 626 [0/54000 (0%)] Loss: -1438.437622\n",
      "Train Epoch: 626 [32768/54000 (61%)] Loss: -1439.110840\n",
      "    epoch          : 626\n",
      "    loss           : -1437.5744306456368\n",
      "    ess            : 3.7564638605657614\n",
      "    log_marginal   : 1437.69496471477\n",
      "    val_loss       : -1436.6290079752605\n",
      "    val_ess        : 3.7545477151870728\n",
      "    val_log_marginal: 1436.7452799479167\n",
      "Train Epoch: 627 [0/54000 (0%)] Loss: -1440.339233\n",
      "Train Epoch: 627 [32768/54000 (61%)] Loss: -1438.208496\n",
      "    epoch          : 627\n",
      "    loss           : -1437.7978861107017\n",
      "    ess            : 3.7570070005812735\n",
      "    log_marginal   : 1437.919074292453\n",
      "    val_loss       : -1436.8530883789062\n",
      "    val_ess        : 3.75551172097524\n",
      "    val_log_marginal: 1436.9755859375\n",
      "Train Epoch: 628 [0/54000 (0%)] Loss: -1437.647705\n",
      "Train Epoch: 628 [32768/54000 (61%)] Loss: -1438.075195\n",
      "    epoch          : 628\n",
      "    loss           : -1438.041888542895\n",
      "    ess            : 3.7531775528529905\n",
      "    log_marginal   : 1438.1662113981427\n",
      "    val_loss       : -1437.2733968098958\n",
      "    val_ess        : 3.74566642443339\n",
      "    val_log_marginal: 1437.4058024088542\n",
      "Train Epoch: 629 [0/54000 (0%)] Loss: -1438.915894\n",
      "Train Epoch: 629 [32768/54000 (61%)] Loss: -1436.572266\n",
      "    epoch          : 629\n",
      "    loss           : -1438.2544313826652\n",
      "    ess            : 3.759875814869719\n",
      "    log_marginal   : 1438.3728280697228\n",
      "    val_loss       : -1437.352315266927\n",
      "    val_ess        : 3.758576512336731\n",
      "    val_log_marginal: 1437.4684041341145\n",
      "Train Epoch: 630 [0/54000 (0%)] Loss: -1439.025879\n",
      "Train Epoch: 630 [32768/54000 (61%)] Loss: -1438.631836\n",
      "    epoch          : 630\n",
      "    loss           : -1438.4869223540684\n",
      "    ess            : 3.758671953993024\n",
      "    log_marginal   : 1438.6062909971993\n",
      "    val_loss       : -1437.642354329427\n",
      "    val_ess        : 3.7407460610071817\n",
      "    val_log_marginal: 1437.7747599283855\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch630.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 631 [0/54000 (0%)] Loss: -1440.207275\n",
      "Train Epoch: 631 [32768/54000 (61%)] Loss: -1439.788574\n",
      "    epoch          : 631\n",
      "    loss           : -1438.681255988355\n",
      "    ess            : 3.7512835781529263\n",
      "    log_marginal   : 1438.8055581146816\n",
      "    val_loss       : -1437.82666015625\n",
      "    val_ess        : 3.763574242591858\n",
      "    val_log_marginal: 1437.9429321289062\n",
      "Train Epoch: 632 [0/54000 (0%)] Loss: -1440.240112\n",
      "Train Epoch: 632 [32768/54000 (61%)] Loss: -1436.663086\n",
      "    epoch          : 632\n",
      "    loss           : -1438.9267140514446\n",
      "    ess            : 3.7585621195019416\n",
      "    log_marginal   : 1439.0445694833431\n",
      "    val_loss       : -1438.147928873698\n",
      "    val_ess        : 3.7671522299448648\n",
      "    val_log_marginal: 1438.2631022135417\n",
      "Train Epoch: 633 [0/54000 (0%)] Loss: -1438.623291\n",
      "Train Epoch: 633 [32768/54000 (61%)] Loss: -1440.279297\n",
      "    epoch          : 633\n",
      "    loss           : -1439.1360254827534\n",
      "    ess            : 3.7576351660602496\n",
      "    log_marginal   : 1439.2560551481427\n",
      "    val_loss       : -1438.0550740559895\n",
      "    val_ess        : 3.7595354318618774\n",
      "    val_log_marginal: 1438.174784342448\n",
      "Train Epoch: 634 [0/54000 (0%)] Loss: -1440.122070\n",
      "Train Epoch: 634 [32768/54000 (61%)] Loss: -1441.136719\n",
      "    epoch          : 634\n",
      "    loss           : -1439.3226525648586\n",
      "    ess            : 3.7568804183096254\n",
      "    log_marginal   : 1439.443686431309\n",
      "    val_loss       : -1438.0408732096355\n",
      "    val_ess        : 3.751870354016622\n",
      "    val_log_marginal: 1438.1646931966145\n",
      "Train Epoch: 635 [0/54000 (0%)] Loss: -1439.591309\n",
      "Train Epoch: 635 [32768/54000 (61%)] Loss: -1438.749756\n",
      "    epoch          : 635\n",
      "    loss           : -1439.6583528338738\n",
      "    ess            : 3.757888393582038\n",
      "    log_marginal   : 1439.782111401828\n",
      "    val_loss       : -1438.913309733073\n",
      "    val_ess        : 3.758099993069967\n",
      "    val_log_marginal: 1439.035400390625\n",
      "Train Epoch: 636 [0/54000 (0%)] Loss: -1442.501831\n",
      "Train Epoch: 636 [32768/54000 (61%)] Loss: -1437.524048\n",
      "    epoch          : 636\n",
      "    loss           : -1439.9023575692806\n",
      "    ess            : 3.7543602484577105\n",
      "    log_marginal   : 1440.0242919921875\n",
      "    val_loss       : -1439.2664998372395\n",
      "    val_ess        : 3.7515262365341187\n",
      "    val_log_marginal: 1439.3900960286458\n",
      "Train Epoch: 637 [0/54000 (0%)] Loss: -1441.750488\n",
      "Train Epoch: 637 [32768/54000 (61%)] Loss: -1440.436401\n",
      "    epoch          : 637\n",
      "    loss           : -1440.1376814932194\n",
      "    ess            : 3.753691038995419\n",
      "    log_marginal   : 1440.2620365934552\n",
      "    val_loss       : -1439.1515706380208\n",
      "    val_ess        : 3.756027658780416\n",
      "    val_log_marginal: 1439.2654622395833\n",
      "Train Epoch: 638 [0/54000 (0%)] Loss: -1442.802490\n",
      "Train Epoch: 638 [32768/54000 (61%)] Loss: -1437.725098\n",
      "    epoch          : 638\n",
      "    loss           : -1440.3390376252948\n",
      "    ess            : 3.756810485192065\n",
      "    log_marginal   : 1440.4614027491157\n",
      "    val_loss       : -1439.2292073567708\n",
      "    val_ess        : 3.765317678451538\n",
      "    val_log_marginal: 1439.3456420898438\n",
      "Train Epoch: 639 [0/54000 (0%)] Loss: -1443.538574\n",
      "Train Epoch: 639 [32768/54000 (61%)] Loss: -1438.703369\n",
      "    epoch          : 639\n",
      "    loss           : -1440.748357808815\n",
      "    ess            : 3.7572714697639897\n",
      "    log_marginal   : 1440.8693041531544\n",
      "    val_loss       : -1439.777811686198\n",
      "    val_ess        : 3.760152578353882\n",
      "    val_log_marginal: 1439.902323404948\n",
      "Train Epoch: 640 [0/54000 (0%)] Loss: -1442.828125\n",
      "Train Epoch: 640 [32768/54000 (61%)] Loss: -1443.889648\n",
      "    epoch          : 640\n",
      "    loss           : -1441.025759139151\n",
      "    ess            : 3.7518060927121146\n",
      "    log_marginal   : 1441.151834739829\n",
      "    val_loss       : -1439.7980346679688\n",
      "    val_ess        : 3.7594786087671914\n",
      "    val_log_marginal: 1439.915506998698\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch640.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 641 [0/54000 (0%)] Loss: -1439.612549\n",
      "Train Epoch: 641 [32768/54000 (61%)] Loss: -1440.841064\n",
      "    epoch          : 641\n",
      "    loss           : -1441.1056576135024\n",
      "    ess            : 3.7572737729774333\n",
      "    log_marginal   : 1441.2263782429245\n",
      "    val_loss       : -1440.2597249348958\n",
      "    val_ess        : 3.7412290970484414\n",
      "    val_log_marginal: 1440.3959554036458\n",
      "Train Epoch: 642 [0/54000 (0%)] Loss: -1442.568481\n",
      "Train Epoch: 642 [32768/54000 (61%)] Loss: -1445.444092\n",
      "    epoch          : 642\n",
      "    loss           : -1441.275312315743\n",
      "    ess            : 3.757633483634805\n",
      "    log_marginal   : 1441.3952659750885\n",
      "    val_loss       : -1440.4199625651042\n",
      "    val_ess        : 3.7464664777119956\n",
      "    val_log_marginal: 1440.5420328776042\n",
      "Train Epoch: 643 [0/54000 (0%)] Loss: -1443.924683\n",
      "Train Epoch: 643 [32768/54000 (61%)] Loss: -1441.393188\n",
      "    epoch          : 643\n",
      "    loss           : -1441.4836748231132\n",
      "    ess            : 3.758660658350531\n",
      "    log_marginal   : 1441.6011870762088\n",
      "    val_loss       : -1440.597900390625\n",
      "    val_ess        : 3.755948543548584\n",
      "    val_log_marginal: 1440.7238362630208\n",
      "Train Epoch: 644 [0/54000 (0%)] Loss: -1444.456665\n",
      "Train Epoch: 644 [32768/54000 (61%)] Loss: -1441.923584\n",
      "    epoch          : 644\n",
      "    loss           : -1441.7788316258843\n",
      "    ess            : 3.7594176508345694\n",
      "    log_marginal   : 1441.897295106132\n",
      "    val_loss       : -1440.9141031901042\n",
      "    val_ess        : 3.7591829697291055\n",
      "    val_log_marginal: 1441.0349527994792\n",
      "Train Epoch: 645 [0/54000 (0%)] Loss: -1442.000122\n",
      "Train Epoch: 645 [32768/54000 (61%)] Loss: -1439.852295\n",
      "    epoch          : 645\n",
      "    loss           : -1441.8767550486439\n",
      "    ess            : 3.7590662668336114\n",
      "    log_marginal   : 1441.9984591502064\n",
      "    val_loss       : -1441.114034016927\n",
      "    val_ess        : 3.7472130060195923\n",
      "    val_log_marginal: 1441.239522298177\n",
      "Train Epoch: 646 [0/54000 (0%)] Loss: -1445.314697\n",
      "Train Epoch: 646 [32768/54000 (61%)] Loss: -1437.953125\n",
      "    epoch          : 646\n",
      "    loss           : -1442.1146862102005\n",
      "    ess            : 3.7557858071237242\n",
      "    log_marginal   : 1442.236083984375\n",
      "    val_loss       : -1441.201680501302\n",
      "    val_ess        : 3.7639083862304688\n",
      "    val_log_marginal: 1441.3214518229167\n",
      "Train Epoch: 647 [0/54000 (0%)] Loss: -1442.621094\n",
      "Train Epoch: 647 [32768/54000 (61%)] Loss: -1443.039062\n",
      "    epoch          : 647\n",
      "    loss           : -1442.3647276680424\n",
      "    ess            : 3.7539679599258133\n",
      "    log_marginal   : 1442.486878593013\n",
      "    val_loss       : -1441.4303385416667\n",
      "    val_ess        : 3.7555256684621177\n",
      "    val_log_marginal: 1441.5492553710938\n",
      "Train Epoch: 648 [0/54000 (0%)] Loss: -1441.076660\n",
      "Train Epoch: 648 [32768/54000 (61%)] Loss: -1440.004639\n",
      "    epoch          : 648\n",
      "    loss           : -1442.5132526901532\n",
      "    ess            : 3.7567842861391463\n",
      "    log_marginal   : 1442.6360554245282\n",
      "    val_loss       : -1441.7438151041667\n",
      "    val_ess        : 3.7573667764663696\n",
      "    val_log_marginal: 1441.8583170572917\n",
      "Train Epoch: 649 [0/54000 (0%)] Loss: -1444.533691\n",
      "Train Epoch: 649 [32768/54000 (61%)] Loss: -1441.701172\n",
      "    epoch          : 649\n",
      "    loss           : -1442.9304084058078\n",
      "    ess            : 3.7558189563031465\n",
      "    log_marginal   : 1443.0537132407135\n",
      "    val_loss       : -1442.041280110677\n",
      "    val_ess        : 3.758326530456543\n",
      "    val_log_marginal: 1442.1651000976562\n",
      "Train Epoch: 650 [0/54000 (0%)] Loss: -1441.354248\n",
      "Train Epoch: 650 [32768/54000 (61%)] Loss: -1441.952637\n",
      "    epoch          : 650\n",
      "    loss           : -1443.2616312278892\n",
      "    ess            : 3.7605922671983825\n",
      "    log_marginal   : 1443.381508881191\n",
      "    val_loss       : -1441.9310506184895\n",
      "    val_ess        : 3.765405257542928\n",
      "    val_log_marginal: 1442.0421346028645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [0/54000 (0%)] Loss: -1443.246216\n",
      "Train Epoch: 651 [32768/54000 (61%)] Loss: -1441.454346\n",
      "    epoch          : 651\n",
      "    loss           : -1443.2164928508255\n",
      "    ess            : 3.7563421321365067\n",
      "    log_marginal   : 1443.340253721993\n",
      "    val_loss       : -1442.4552815755208\n",
      "    val_ess        : 3.7615116437276206\n",
      "    val_log_marginal: 1442.5713907877605\n",
      "Train Epoch: 652 [0/54000 (0%)] Loss: -1442.940674\n",
      "Train Epoch: 652 [32768/54000 (61%)] Loss: -1442.590454\n",
      "    epoch          : 652\n",
      "    loss           : -1443.468282447671\n",
      "    ess            : 3.76147354323909\n",
      "    log_marginal   : 1443.5880748820755\n",
      "    val_loss       : -1442.8011271158855\n",
      "    val_ess        : 3.768803834915161\n",
      "    val_log_marginal: 1442.9183756510417\n",
      "Train Epoch: 653 [0/54000 (0%)] Loss: -1445.683105\n",
      "Train Epoch: 653 [32768/54000 (61%)] Loss: -1443.659424\n",
      "    epoch          : 653\n",
      "    loss           : -1443.687251252948\n",
      "    ess            : 3.7609164309951493\n",
      "    log_marginal   : 1443.8070068359375\n",
      "    val_loss       : -1442.901102701823\n",
      "    val_ess        : 3.7556491692860923\n",
      "    val_log_marginal: 1443.0259195963542\n",
      "Train Epoch: 654 [0/54000 (0%)] Loss: -1443.717285\n",
      "Train Epoch: 654 [32768/54000 (61%)] Loss: -1444.183350\n",
      "    epoch          : 654\n",
      "    loss           : -1443.9206174454598\n",
      "    ess            : 3.7579016820439755\n",
      "    log_marginal   : 1444.0426232679836\n",
      "    val_loss       : -1443.214619954427\n",
      "    val_ess        : 3.746666153271993\n",
      "    val_log_marginal: 1443.343729654948\n",
      "Train Epoch: 655 [0/54000 (0%)] Loss: -1444.233643\n",
      "Train Epoch: 655 [32768/54000 (61%)] Loss: -1444.443115\n",
      "    epoch          : 655\n",
      "    loss           : -1444.0468980321343\n",
      "    ess            : 3.7586628850900903\n",
      "    log_marginal   : 1444.1683395673645\n",
      "    val_loss       : -1443.109375\n",
      "    val_ess        : 3.761289676030477\n",
      "    val_log_marginal: 1443.2330322265625\n",
      "Train Epoch: 656 [0/54000 (0%)] Loss: -1445.043945\n",
      "Train Epoch: 656 [32768/54000 (61%)] Loss: -1445.227295\n",
      "    epoch          : 656\n",
      "    loss           : -1444.2452899285083\n",
      "    ess            : 3.7551392429279833\n",
      "    log_marginal   : 1444.3708104547466\n",
      "    val_loss       : -1443.5272013346355\n",
      "    val_ess        : 3.7705183823903403\n",
      "    val_log_marginal: 1443.640360514323\n",
      "Train Epoch: 657 [0/54000 (0%)] Loss: -1444.177490\n",
      "Train Epoch: 657 [32768/54000 (61%)] Loss: -1445.052612\n",
      "    epoch          : 657\n",
      "    loss           : -1444.4489492740272\n",
      "    ess            : 3.760177436864601\n",
      "    log_marginal   : 1444.567986254422\n",
      "    val_loss       : -1444.1158243815105\n",
      "    val_ess        : 3.7547579606374106\n",
      "    val_log_marginal: 1444.2371622721355\n",
      "Train Epoch: 658 [0/54000 (0%)] Loss: -1441.117188\n",
      "Train Epoch: 658 [32768/54000 (61%)] Loss: -1447.589600\n",
      "    epoch          : 658\n",
      "    loss           : -1444.7049652675412\n",
      "    ess            : 3.757403832561565\n",
      "    log_marginal   : 1444.8262110296284\n",
      "    val_loss       : -1443.8741251627605\n",
      "    val_ess        : 3.7663158973058066\n",
      "    val_log_marginal: 1443.9917602539062\n",
      "Train Epoch: 659 [0/54000 (0%)] Loss: -1445.461182\n",
      "Train Epoch: 659 [32768/54000 (61%)] Loss: -1443.650513\n",
      "    epoch          : 659\n",
      "    loss           : -1444.9817539431015\n",
      "    ess            : 3.754980816031402\n",
      "    log_marginal   : 1445.1061113465507\n",
      "    val_loss       : -1444.4037475585938\n",
      "    val_ess        : 3.763044516245524\n",
      "    val_log_marginal: 1444.5233154296875\n",
      "Train Epoch: 660 [0/54000 (0%)] Loss: -1448.046387\n",
      "Train Epoch: 660 [32768/54000 (61%)] Loss: -1442.728638\n",
      "    epoch          : 660\n",
      "    loss           : -1445.0688223209022\n",
      "    ess            : 3.7564166042039977\n",
      "    log_marginal   : 1445.1899805608784\n",
      "    val_loss       : -1444.3107503255208\n",
      "    val_ess        : 3.7549369732538858\n",
      "    val_log_marginal: 1444.4317220052083\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch660.pth ...\n",
      "Train Epoch: 661 [0/54000 (0%)] Loss: -1445.929443\n",
      "Train Epoch: 661 [32768/54000 (61%)] Loss: -1443.328979\n",
      "    epoch          : 661\n",
      "    loss           : -1445.3403182119694\n",
      "    ess            : 3.7578745203198127\n",
      "    log_marginal   : 1445.463929374263\n",
      "    val_loss       : -1444.8394368489583\n",
      "    val_ess        : 3.7568188905715942\n",
      "    val_log_marginal: 1444.952860514323\n",
      "Train Epoch: 662 [0/54000 (0%)] Loss: -1448.422119\n",
      "Train Epoch: 662 [32768/54000 (61%)] Loss: -1443.353638\n",
      "    epoch          : 662\n",
      "    loss           : -1445.5861678213444\n",
      "    ess            : 3.7626699861490502\n",
      "    log_marginal   : 1445.705670050855\n",
      "    val_loss       : -1445.0008951822917\n",
      "    val_ess        : 3.766950011253357\n",
      "    val_log_marginal: 1445.1150309244792\n",
      "Train Epoch: 663 [0/54000 (0%)] Loss: -1447.701660\n",
      "Train Epoch: 663 [32768/54000 (61%)] Loss: -1443.715210\n",
      "    epoch          : 663\n",
      "    loss           : -1445.880900832842\n",
      "    ess            : 3.7569290646966897\n",
      "    log_marginal   : 1446.0066793189858\n",
      "    val_loss       : -1445.7231038411458\n",
      "    val_ess        : 3.759617328643799\n",
      "    val_log_marginal: 1445.8533121744792\n",
      "Train Epoch: 664 [0/54000 (0%)] Loss: -1444.557739\n",
      "Train Epoch: 664 [32768/54000 (61%)] Loss: -1444.189453\n",
      "    epoch          : 664\n",
      "    loss           : -1445.9679807267098\n",
      "    ess            : 3.7590334865282165\n",
      "    log_marginal   : 1446.089723982901\n",
      "    val_loss       : -1445.4402465820312\n",
      "    val_ess        : 3.758614182472229\n",
      "    val_log_marginal: 1445.5658772786458\n",
      "Train Epoch: 665 [0/54000 (0%)] Loss: -1448.196777\n",
      "Train Epoch: 665 [32768/54000 (61%)] Loss: -1448.932861\n",
      "    epoch          : 665\n",
      "    loss           : -1446.3558487802181\n",
      "    ess            : 3.7551987171173096\n",
      "    log_marginal   : 1446.4807382259728\n",
      "    val_loss       : -1445.9019571940105\n",
      "    val_ess        : 3.7564255793889365\n",
      "    val_log_marginal: 1446.0222778320312\n",
      "Train Epoch: 666 [0/54000 (0%)] Loss: -1448.204346\n",
      "Train Epoch: 666 [32768/54000 (61%)] Loss: -1445.418701\n",
      "    epoch          : 666\n",
      "    loss           : -1446.5688453530365\n",
      "    ess            : 3.762324441154048\n",
      "    log_marginal   : 1446.6894093639446\n",
      "    val_loss       : -1445.9756876627605\n",
      "    val_ess        : 3.7714312076568604\n",
      "    val_log_marginal: 1446.097880045573\n",
      "Train Epoch: 667 [0/54000 (0%)] Loss: -1449.127441\n",
      "Train Epoch: 667 [32768/54000 (61%)] Loss: -1444.744873\n",
      "    epoch          : 667\n",
      "    loss           : -1446.7117390182782\n",
      "    ess            : 3.76255893257429\n",
      "    log_marginal   : 1446.829838590802\n",
      "    val_loss       : -1445.8037109375\n",
      "    val_ess        : 3.7540410359700522\n",
      "    val_log_marginal: 1445.9315185546875\n",
      "Train Epoch: 668 [0/54000 (0%)] Loss: -1444.875122\n",
      "Train Epoch: 668 [32768/54000 (61%)] Loss: -1445.377075\n",
      "    epoch          : 668\n",
      "    loss           : -1446.9974250073703\n",
      "    ess            : 3.7646294989675844\n",
      "    log_marginal   : 1447.1162086342865\n",
      "    val_loss       : -1446.2724609375\n",
      "    val_ess        : 3.7495086193084717\n",
      "    val_log_marginal: 1446.3971354166667\n",
      "Train Epoch: 669 [0/54000 (0%)] Loss: -1448.889160\n",
      "Train Epoch: 669 [32768/54000 (61%)] Loss: -1443.868652\n",
      "    epoch          : 669\n",
      "    loss           : -1447.1426264924823\n",
      "    ess            : 3.758165085090781\n",
      "    log_marginal   : 1447.2674790868218\n",
      "    val_loss       : -1446.1742757161458\n",
      "    val_ess        : 3.752983331680298\n",
      "    val_log_marginal: 1446.2961832682292\n",
      "Train Epoch: 670 [0/54000 (0%)] Loss: -1450.682983\n",
      "Train Epoch: 670 [32768/54000 (61%)] Loss: -1445.409302\n",
      "    epoch          : 670\n",
      "    loss           : -1447.3598932230248\n",
      "    ess            : 3.7593111047204935\n",
      "    log_marginal   : 1447.4787943138267\n",
      "    val_loss       : -1446.6703084309895\n",
      "    val_ess        : 3.7662136952082315\n",
      "    val_log_marginal: 1446.785664876302\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch670.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 671 [0/54000 (0%)] Loss: -1449.946045\n",
      "Train Epoch: 671 [32768/54000 (61%)] Loss: -1447.880615\n",
      "    epoch          : 671\n",
      "    loss           : -1447.4223471587559\n",
      "    ess            : 3.7602492098538383\n",
      "    log_marginal   : 1447.54457408977\n",
      "    val_loss       : -1446.7521158854167\n",
      "    val_ess        : 3.7649232943852744\n",
      "    val_log_marginal: 1446.8646240234375\n",
      "Train Epoch: 672 [0/54000 (0%)] Loss: -1453.313354\n",
      "Train Epoch: 672 [32768/54000 (61%)] Loss: -1448.503784\n",
      "    epoch          : 672\n",
      "    loss           : -1447.6413482090213\n",
      "    ess            : 3.757830111485607\n",
      "    log_marginal   : 1447.7658553213444\n",
      "    val_loss       : -1447.036153157552\n",
      "    val_ess        : 3.7651338974634805\n",
      "    val_log_marginal: 1447.1517333984375\n",
      "Train Epoch: 673 [0/54000 (0%)] Loss: -1450.212769\n",
      "Train Epoch: 673 [32768/54000 (61%)] Loss: -1446.955688\n",
      "    epoch          : 673\n",
      "    loss           : -1447.9385686910377\n",
      "    ess            : 3.765285222035534\n",
      "    log_marginal   : 1448.0599411298645\n",
      "    val_loss       : -1447.1124064127605\n",
      "    val_ess        : 3.7511018911997476\n",
      "    val_log_marginal: 1447.248026529948\n",
      "Train Epoch: 674 [0/54000 (0%)] Loss: -1450.160767\n",
      "Train Epoch: 674 [32768/54000 (61%)] Loss: -1448.145264\n",
      "    epoch          : 674\n",
      "    loss           : -1448.2067940190154\n",
      "    ess            : 3.7614951943451502\n",
      "    log_marginal   : 1448.3240483122052\n",
      "    val_loss       : -1447.480204264323\n",
      "    val_ess        : 3.764518976211548\n",
      "    val_log_marginal: 1447.5949096679688\n",
      "Train Epoch: 675 [0/54000 (0%)] Loss: -1447.865234\n",
      "Train Epoch: 675 [32768/54000 (61%)] Loss: -1448.688110\n",
      "    epoch          : 675\n",
      "    loss           : -1448.4568009286556\n",
      "    ess            : 3.7596208869286305\n",
      "    log_marginal   : 1448.579341096698\n",
      "    val_loss       : -1447.9957275390625\n",
      "    val_ess        : 3.7674556970596313\n",
      "    val_log_marginal: 1448.1171264648438\n",
      "Train Epoch: 676 [0/54000 (0%)] Loss: -1449.161377\n",
      "Train Epoch: 676 [32768/54000 (61%)] Loss: -1445.811157\n",
      "    epoch          : 676\n",
      "    loss           : -1448.6006250921284\n",
      "    ess            : 3.758791923522949\n",
      "    log_marginal   : 1448.7249249152417\n",
      "    val_loss       : -1447.8693237304688\n",
      "    val_ess        : 3.758779684702555\n",
      "    val_log_marginal: 1447.9868570963542\n",
      "Train Epoch: 677 [0/54000 (0%)] Loss: -1448.557739\n",
      "Train Epoch: 677 [32768/54000 (61%)] Loss: -1449.067505\n",
      "    epoch          : 677\n",
      "    loss           : -1448.804728957842\n",
      "    ess            : 3.7589396215834707\n",
      "    log_marginal   : 1448.9264606979657\n",
      "    val_loss       : -1448.156473795573\n",
      "    val_ess        : 3.759680906931559\n",
      "    val_log_marginal: 1448.2814127604167\n",
      "Train Epoch: 678 [0/54000 (0%)] Loss: -1450.950684\n",
      "Train Epoch: 678 [32768/54000 (61%)] Loss: -1447.964600\n",
      "    epoch          : 678\n",
      "    loss           : -1448.9560869324882\n",
      "    ess            : 3.759954587468561\n",
      "    log_marginal   : 1449.077392578125\n",
      "    val_loss       : -1448.3226114908855\n",
      "    val_ess        : 3.74812920888265\n",
      "    val_log_marginal: 1448.451904296875\n",
      "Train Epoch: 679 [0/54000 (0%)] Loss: -1450.585693\n",
      "Train Epoch: 679 [32768/54000 (61%)] Loss: -1451.264160\n",
      "    epoch          : 679\n",
      "    loss           : -1449.1712162809552\n",
      "    ess            : 3.7650951394494974\n",
      "    log_marginal   : 1449.2909718639446\n",
      "    val_loss       : -1448.462666829427\n",
      "    val_ess        : 3.76097309589386\n",
      "    val_log_marginal: 1448.5785319010417\n",
      "Train Epoch: 680 [0/54000 (0%)] Loss: -1449.613525\n",
      "Train Epoch: 680 [32768/54000 (61%)] Loss: -1449.428467\n",
      "    epoch          : 680\n",
      "    loss           : -1449.5570068359375\n",
      "    ess            : 3.762909488857917\n",
      "    log_marginal   : 1449.6764998525944\n",
      "    val_loss       : -1448.8059692382812\n",
      "    val_ess        : 3.7606579065322876\n",
      "    val_log_marginal: 1448.921162923177\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch680.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 681 [0/54000 (0%)] Loss: -1448.711304\n",
      "Train Epoch: 681 [32768/54000 (61%)] Loss: -1451.357544\n",
      "    epoch          : 681\n",
      "    loss           : -1449.7248857606132\n",
      "    ess            : 3.7575690161507085\n",
      "    log_marginal   : 1449.8484047943691\n",
      "    val_loss       : -1448.649149576823\n",
      "    val_ess        : 3.755219499270121\n",
      "    val_log_marginal: 1448.7749430338542\n",
      "Train Epoch: 682 [0/54000 (0%)] Loss: -1452.833374\n",
      "Train Epoch: 682 [32768/54000 (61%)] Loss: -1449.254395\n",
      "    epoch          : 682\n",
      "    loss           : -1449.9062569096404\n",
      "    ess            : 3.7592919547602817\n",
      "    log_marginal   : 1450.0269522037147\n",
      "    val_loss       : -1449.1903279622395\n",
      "    val_ess        : 3.7630041042963662\n",
      "    val_log_marginal: 1449.314921061198\n",
      "Train Epoch: 683 [0/54000 (0%)] Loss: -1451.756348\n",
      "Train Epoch: 683 [32768/54000 (61%)] Loss: -1449.364502\n",
      "    epoch          : 683\n",
      "    loss           : -1450.1830755269752\n",
      "    ess            : 3.7606291635981144\n",
      "    log_marginal   : 1450.3042729215802\n",
      "    val_loss       : -1449.252705891927\n",
      "    val_ess        : 3.7664079666137695\n",
      "    val_log_marginal: 1449.3616943359375\n",
      "Train Epoch: 684 [0/54000 (0%)] Loss: -1453.566162\n",
      "Train Epoch: 684 [32768/54000 (61%)] Loss: -1451.326294\n",
      "    epoch          : 684\n",
      "    loss           : -1450.4585882222877\n",
      "    ess            : 3.766117469319757\n",
      "    log_marginal   : 1450.5778693433078\n",
      "    val_loss       : -1449.7955932617188\n",
      "    val_ess        : 3.7514663537343345\n",
      "    val_log_marginal: 1449.920918782552\n",
      "Train Epoch: 685 [0/54000 (0%)] Loss: -1446.642456\n",
      "Train Epoch: 685 [32768/54000 (61%)] Loss: -1450.762451\n",
      "    epoch          : 685\n",
      "    loss           : -1450.5937154517983\n",
      "    ess            : 3.7593070246138662\n",
      "    log_marginal   : 1450.7130887013561\n",
      "    val_loss       : -1449.6747029622395\n",
      "    val_ess        : 3.760843555132548\n",
      "    val_log_marginal: 1449.7989095052083\n",
      "Train Epoch: 686 [0/54000 (0%)] Loss: -1453.310791\n",
      "Train Epoch: 686 [32768/54000 (61%)] Loss: -1450.026855\n",
      "    epoch          : 686\n",
      "    loss           : -1450.7131900427476\n",
      "    ess            : 3.7559961327966653\n",
      "    log_marginal   : 1450.838503279776\n",
      "    val_loss       : -1449.663594563802\n",
      "    val_ess        : 3.772748430569967\n",
      "    val_log_marginal: 1449.7774658203125\n",
      "Train Epoch: 687 [0/54000 (0%)] Loss: -1449.442627\n",
      "Train Epoch: 687 [32768/54000 (61%)] Loss: -1449.931885\n",
      "    epoch          : 687\n",
      "    loss           : -1450.990275832842\n",
      "    ess            : 3.7581479729346507\n",
      "    log_marginal   : 1451.110434478184\n",
      "    val_loss       : -1449.9618733723958\n",
      "    val_ess        : 3.7621235450108848\n",
      "    val_log_marginal: 1450.0730590820312\n",
      "Train Epoch: 688 [0/54000 (0%)] Loss: -1454.327637\n",
      "Train Epoch: 688 [32768/54000 (61%)] Loss: -1452.635620\n",
      "    epoch          : 688\n",
      "    loss           : -1451.1984471734966\n",
      "    ess            : 3.75746166481162\n",
      "    log_marginal   : 1451.3186173349056\n",
      "    val_loss       : -1450.4429728190105\n",
      "    val_ess        : 3.7727757692337036\n",
      "    val_log_marginal: 1450.5628255208333\n",
      "Train Epoch: 689 [0/54000 (0%)] Loss: -1452.977539\n",
      "Train Epoch: 689 [32768/54000 (61%)] Loss: -1450.007812\n",
      "    epoch          : 689\n",
      "    loss           : -1451.278995154039\n",
      "    ess            : 3.7611278857824937\n",
      "    log_marginal   : 1451.3983730100235\n",
      "    val_loss       : -1450.5767211914062\n",
      "    val_ess        : 3.7586433490117392\n",
      "    val_log_marginal: 1450.6978759765625\n",
      "Train Epoch: 690 [0/54000 (0%)] Loss: -1453.462769\n",
      "Train Epoch: 690 [32768/54000 (61%)] Loss: -1453.290039\n",
      "    epoch          : 690\n",
      "    loss           : -1451.6602575913914\n",
      "    ess            : 3.7609743352206246\n",
      "    log_marginal   : 1451.7821966207252\n",
      "    val_loss       : -1450.9835205078125\n",
      "    val_ess        : 3.771783788998922\n",
      "    val_log_marginal: 1451.0989583333333\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch690.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 691 [0/54000 (0%)] Loss: -1450.480469\n",
      "Train Epoch: 691 [32768/54000 (61%)] Loss: -1450.268799\n",
      "    epoch          : 691\n",
      "    loss           : -1451.8836462632664\n",
      "    ess            : 3.757583217800788\n",
      "    log_marginal   : 1452.0079460863797\n",
      "    val_loss       : -1450.9402669270833\n",
      "    val_ess        : 3.7584873835245767\n",
      "    val_log_marginal: 1451.062479654948\n",
      "Train Epoch: 692 [0/54000 (0%)] Loss: -1453.262817\n",
      "Train Epoch: 692 [32768/54000 (61%)] Loss: -1454.303467\n",
      "    epoch          : 692\n",
      "    loss           : -1452.0083721808667\n",
      "    ess            : 3.7578811915415637\n",
      "    log_marginal   : 1452.1297100714917\n",
      "    val_loss       : -1450.9519856770833\n",
      "    val_ess        : 3.756091356277466\n",
      "    val_log_marginal: 1451.0823974609375\n",
      "Train Epoch: 693 [0/54000 (0%)] Loss: -1452.394165\n",
      "Train Epoch: 693 [32768/54000 (61%)] Loss: -1448.925293\n",
      "    epoch          : 693\n",
      "    loss           : -1452.2465474830483\n",
      "    ess            : 3.756713885181355\n",
      "    log_marginal   : 1452.3687905365566\n",
      "    val_loss       : -1451.3720092773438\n",
      "    val_ess        : 3.764927625656128\n",
      "    val_log_marginal: 1451.4896647135417\n",
      "Train Epoch: 694 [0/54000 (0%)] Loss: -1455.950806\n",
      "Train Epoch: 694 [32768/54000 (61%)] Loss: -1451.125488\n",
      "    epoch          : 694\n",
      "    loss           : -1452.4151357974647\n",
      "    ess            : 3.7571833448589973\n",
      "    log_marginal   : 1452.5371231942806\n",
      "    val_loss       : -1451.470967610677\n",
      "    val_ess        : 3.764044483502706\n",
      "    val_log_marginal: 1451.587646484375\n",
      "Train Epoch: 695 [0/54000 (0%)] Loss: -1451.955566\n",
      "Train Epoch: 695 [32768/54000 (61%)] Loss: -1449.802734\n",
      "    epoch          : 695\n",
      "    loss           : -1452.6507268941627\n",
      "    ess            : 3.7599068722634947\n",
      "    log_marginal   : 1452.7697362359966\n",
      "    val_loss       : -1452.0426635742188\n",
      "    val_ess        : 3.765639861424764\n",
      "    val_log_marginal: 1452.1576741536458\n",
      "Train Epoch: 696 [0/54000 (0%)] Loss: -1453.430176\n",
      "Train Epoch: 696 [32768/54000 (61%)] Loss: -1453.954834\n",
      "    epoch          : 696\n",
      "    loss           : -1452.8384526090802\n",
      "    ess            : 3.761870690111844\n",
      "    log_marginal   : 1452.9605758954895\n",
      "    val_loss       : -1452.035624186198\n",
      "    val_ess        : 3.7546476125717163\n",
      "    val_log_marginal: 1452.1612345377605\n",
      "Train Epoch: 697 [0/54000 (0%)] Loss: -1452.998047\n",
      "Train Epoch: 697 [32768/54000 (61%)] Loss: -1455.305542\n",
      "    epoch          : 697\n",
      "    loss           : -1453.1603819649174\n",
      "    ess            : 3.7613130110614703\n",
      "    log_marginal   : 1453.2827470887382\n",
      "    val_loss       : -1452.189208984375\n",
      "    val_ess        : 3.765104293823242\n",
      "    val_log_marginal: 1452.3013916015625\n",
      "Train Epoch: 698 [0/54000 (0%)] Loss: -1456.429688\n",
      "Train Epoch: 698 [32768/54000 (61%)] Loss: -1455.413330\n",
      "    epoch          : 698\n",
      "    loss           : -1453.3897751142395\n",
      "    ess            : 3.757689251089996\n",
      "    log_marginal   : 1453.513489921138\n",
      "    val_loss       : -1452.1148681640625\n",
      "    val_ess        : 3.7654652198155723\n",
      "    val_log_marginal: 1452.2260131835938\n",
      "Train Epoch: 699 [0/54000 (0%)] Loss: -1451.467529\n",
      "Train Epoch: 699 [32768/54000 (61%)] Loss: -1452.933350\n",
      "    epoch          : 699\n",
      "    loss           : -1453.439494582842\n",
      "    ess            : 3.7586257277794606\n",
      "    log_marginal   : 1453.562582915684\n",
      "    val_loss       : -1452.7520751953125\n",
      "    val_ess        : 3.756040334701538\n",
      "    val_log_marginal: 1452.8770345052083\n",
      "Train Epoch: 700 [0/54000 (0%)] Loss: -1457.702148\n",
      "Train Epoch: 700 [32768/54000 (61%)] Loss: -1456.090820\n",
      "    epoch          : 700\n",
      "    loss           : -1453.7516145526238\n",
      "    ess            : 3.762876371167741\n",
      "    log_marginal   : 1453.8742744877654\n",
      "    val_loss       : -1452.8585815429688\n",
      "    val_ess        : 3.7604097525278726\n",
      "    val_log_marginal: 1452.9864095052083\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch700.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 701 [0/54000 (0%)] Loss: -1456.813232\n",
      "Train Epoch: 701 [32768/54000 (61%)] Loss: -1454.163818\n",
      "    epoch          : 701\n",
      "    loss           : -1453.9938481168927\n",
      "    ess            : 3.762367752363097\n",
      "    log_marginal   : 1454.1133710753243\n",
      "    val_loss       : -1453.0907796223958\n",
      "    val_ess        : 3.7702646255493164\n",
      "    val_log_marginal: 1453.2104899088542\n",
      "Train Epoch: 702 [0/54000 (0%)] Loss: -1455.768433\n",
      "Train Epoch: 702 [32768/54000 (61%)] Loss: -1456.866333\n",
      "    epoch          : 702\n",
      "    loss           : -1454.2251897847877\n",
      "    ess            : 3.7613491292269723\n",
      "    log_marginal   : 1454.3463963922466\n",
      "    val_loss       : -1453.5427856445312\n",
      "    val_ess        : 3.7606266339619956\n",
      "    val_log_marginal: 1453.661376953125\n",
      "Train Epoch: 703 [0/54000 (0%)] Loss: -1452.942383\n",
      "Train Epoch: 703 [32768/54000 (61%)] Loss: -1451.441528\n",
      "    epoch          : 703\n",
      "    loss           : -1454.3672335642689\n",
      "    ess            : 3.762793977305574\n",
      "    log_marginal   : 1454.4875004606427\n",
      "    val_loss       : -1453.6957194010417\n",
      "    val_ess        : 3.75335685412089\n",
      "    val_log_marginal: 1453.8172607421875\n",
      "Train Epoch: 704 [0/54000 (0%)] Loss: -1452.459473\n",
      "Train Epoch: 704 [32768/54000 (61%)] Loss: -1453.733765\n",
      "    epoch          : 704\n",
      "    loss           : -1454.6389068027713\n",
      "    ess            : 3.7598272584519297\n",
      "    log_marginal   : 1454.7611222177181\n",
      "    val_loss       : -1453.6209716796875\n",
      "    val_ess        : 3.7820882399876914\n",
      "    val_log_marginal: 1453.7220865885417\n",
      "Train Epoch: 705 [0/54000 (0%)] Loss: -1456.925781\n",
      "Train Epoch: 705 [32768/54000 (61%)] Loss: -1456.645020\n",
      "    epoch          : 705\n",
      "    loss           : -1454.768715912441\n",
      "    ess            : 3.7621492799722924\n",
      "    log_marginal   : 1454.8892684072819\n",
      "    val_loss       : -1454.4238688151042\n",
      "    val_ess        : 3.7599775791168213\n",
      "    val_log_marginal: 1454.54541015625\n",
      "Train Epoch: 706 [0/54000 (0%)] Loss: -1453.315430\n",
      "Train Epoch: 706 [32768/54000 (61%)] Loss: -1454.797607\n",
      "    epoch          : 706\n",
      "    loss           : -1454.970640938237\n",
      "    ess            : 3.761503318570695\n",
      "    log_marginal   : 1455.093485130454\n",
      "    val_loss       : -1454.1187947591145\n",
      "    val_ess        : 3.772966225941976\n",
      "    val_log_marginal: 1454.2325236002605\n",
      "Train Epoch: 707 [0/54000 (0%)] Loss: -1455.116577\n",
      "Train Epoch: 707 [32768/54000 (61%)] Loss: -1456.119263\n",
      "    epoch          : 707\n",
      "    loss           : -1455.313117261203\n",
      "    ess            : 3.7648713498745323\n",
      "    log_marginal   : 1455.4328083542157\n",
      "    val_loss       : -1454.6585083007812\n",
      "    val_ess        : 3.7561858892440796\n",
      "    val_log_marginal: 1454.7783203125\n",
      "Train Epoch: 708 [0/54000 (0%)] Loss: -1458.213501\n",
      "Train Epoch: 708 [32768/54000 (61%)] Loss: -1456.323364\n",
      "    epoch          : 708\n",
      "    loss           : -1455.4660160856427\n",
      "    ess            : 3.7598522744088805\n",
      "    log_marginal   : 1455.5864741487323\n",
      "    val_loss       : -1454.5086059570312\n",
      "    val_ess        : 3.7580053408940635\n",
      "    val_log_marginal: 1454.6269124348958\n",
      "Train Epoch: 709 [0/54000 (0%)] Loss: -1459.239746\n",
      "Train Epoch: 709 [32768/54000 (61%)] Loss: -1456.240967\n",
      "    epoch          : 709\n",
      "    loss           : -1455.6114824403007\n",
      "    ess            : 3.7577281313122444\n",
      "    log_marginal   : 1455.736150777565\n",
      "    val_loss       : -1454.687255859375\n",
      "    val_ess        : 3.7664955457051597\n",
      "    val_log_marginal: 1454.809102376302\n",
      "Train Epoch: 710 [0/54000 (0%)] Loss: -1454.884033\n",
      "Train Epoch: 710 [32768/54000 (61%)] Loss: -1457.090088\n",
      "    epoch          : 710\n",
      "    loss           : -1455.8620720629422\n",
      "    ess            : 3.758941304008916\n",
      "    log_marginal   : 1455.9849531065743\n",
      "    val_loss       : -1454.900410970052\n",
      "    val_ess        : 3.7609939177831015\n",
      "    val_log_marginal: 1455.0179443359375\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch710.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 711 [0/54000 (0%)] Loss: -1459.630615\n",
      "Train Epoch: 711 [32768/54000 (61%)] Loss: -1454.001587\n",
      "    epoch          : 711\n",
      "    loss           : -1455.9474936431309\n",
      "    ess            : 3.760640706656114\n",
      "    log_marginal   : 1456.0692392025353\n",
      "    val_loss       : -1454.7564086914062\n",
      "    val_ess        : 3.75227161248525\n",
      "    val_log_marginal: 1454.8861287434895\n",
      "Train Epoch: 712 [0/54000 (0%)] Loss: -1457.775269\n",
      "Train Epoch: 712 [32768/54000 (61%)] Loss: -1454.573242\n",
      "    epoch          : 712\n",
      "    loss           : -1456.0322495946343\n",
      "    ess            : 3.7598060436968535\n",
      "    log_marginal   : 1456.1540849793632\n",
      "    val_loss       : -1454.8209635416667\n",
      "    val_ess        : 3.7600709199905396\n",
      "    val_log_marginal: 1454.9335530598958\n",
      "Train Epoch: 713 [0/54000 (0%)] Loss: -1457.260498\n",
      "Train Epoch: 713 [32768/54000 (61%)] Loss: -1455.525635\n",
      "    epoch          : 713\n",
      "    loss           : -1456.3205658534787\n",
      "    ess            : 3.7592794805202843\n",
      "    log_marginal   : 1456.444699845224\n",
      "    val_loss       : -1455.3011067708333\n",
      "    val_ess        : 3.763234774271647\n",
      "    val_log_marginal: 1455.4222412109375\n",
      "Train Epoch: 714 [0/54000 (0%)] Loss: -1456.848389\n",
      "Train Epoch: 714 [32768/54000 (61%)] Loss: -1456.100586\n",
      "    epoch          : 714\n",
      "    loss           : -1456.694621535967\n",
      "    ess            : 3.763055477502211\n",
      "    log_marginal   : 1456.8170327240566\n",
      "    val_loss       : -1455.4808349609375\n",
      "    val_ess        : 3.7655404011408486\n",
      "    val_log_marginal: 1455.6005249023438\n",
      "Train Epoch: 715 [0/54000 (0%)] Loss: -1458.650391\n",
      "Train Epoch: 715 [32768/54000 (61%)] Loss: -1457.162842\n",
      "    epoch          : 715\n",
      "    loss           : -1456.7903707252358\n",
      "    ess            : 3.7656348471371635\n",
      "    log_marginal   : 1456.9076158055718\n",
      "    val_loss       : -1455.9324137369792\n",
      "    val_ess        : 3.7581688165664673\n",
      "    val_log_marginal: 1456.0664469401042\n",
      "Train Epoch: 716 [0/54000 (0%)] Loss: -1456.928955\n",
      "Train Epoch: 716 [32768/54000 (61%)] Loss: -1458.638306\n",
      "    epoch          : 716\n",
      "    loss           : -1457.1213079488502\n",
      "    ess            : 3.7654914181187467\n",
      "    log_marginal   : 1457.2403932967277\n",
      "    val_loss       : -1456.2632649739583\n",
      "    val_ess        : 3.762598474820455\n",
      "    val_log_marginal: 1456.3749186197917\n",
      "Train Epoch: 717 [0/54000 (0%)] Loss: -1456.901611\n",
      "Train Epoch: 717 [32768/54000 (61%)] Loss: -1454.543701\n",
      "    epoch          : 717\n",
      "    loss           : -1457.3782705630897\n",
      "    ess            : 3.7657560402492307\n",
      "    log_marginal   : 1457.4994195902123\n",
      "    val_loss       : -1456.3766479492188\n",
      "    val_ess        : 3.7574079831441245\n",
      "    val_log_marginal: 1456.4993693033855\n",
      "Train Epoch: 718 [0/54000 (0%)] Loss: -1456.534180\n",
      "Train Epoch: 718 [32768/54000 (61%)] Loss: -1456.479492\n",
      "    epoch          : 718\n",
      "    loss           : -1457.5063775980248\n",
      "    ess            : 3.760845422744751\n",
      "    log_marginal   : 1457.6315111844044\n",
      "    val_loss       : -1456.3272298177083\n",
      "    val_ess        : 3.7615198691685996\n",
      "    val_log_marginal: 1456.45751953125\n",
      "Train Epoch: 719 [0/54000 (0%)] Loss: -1459.799316\n",
      "Train Epoch: 719 [32768/54000 (61%)] Loss: -1459.167969\n",
      "    epoch          : 719\n",
      "    loss           : -1457.5927895599941\n",
      "    ess            : 3.7525814749159903\n",
      "    log_marginal   : 1457.7191899137677\n",
      "    val_loss       : -1456.4292399088542\n",
      "    val_ess        : 3.762840231259664\n",
      "    val_log_marginal: 1456.54736328125\n",
      "Train Epoch: 720 [0/54000 (0%)] Loss: -1458.800171\n",
      "Train Epoch: 720 [32768/54000 (61%)] Loss: -1456.845703\n",
      "    epoch          : 720\n",
      "    loss           : -1458.0033327498527\n",
      "    ess            : 3.7632275032547287\n",
      "    log_marginal   : 1458.1215543926887\n",
      "    val_loss       : -1456.7749430338542\n",
      "    val_ess        : 3.7735390663146973\n",
      "    val_log_marginal: 1456.8826293945312\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch720.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 721 [0/54000 (0%)] Loss: -1458.658691\n",
      "Train Epoch: 721 [32768/54000 (61%)] Loss: -1457.392578\n",
      "    epoch          : 721\n",
      "    loss           : -1458.3179355837265\n",
      "    ess            : 3.758864555718764\n",
      "    log_marginal   : 1458.4402200950767\n",
      "    val_loss       : -1456.9697672526042\n",
      "    val_ess        : 3.7625961701075235\n",
      "    val_log_marginal: 1457.0871988932292\n",
      "Train Epoch: 722 [0/54000 (0%)] Loss: -1461.340576\n",
      "Train Epoch: 722 [32768/54000 (61%)] Loss: -1458.767334\n",
      "    epoch          : 722\n",
      "    loss           : -1458.4614948776532\n",
      "    ess            : 3.7619227328390443\n",
      "    log_marginal   : 1458.5831598245873\n",
      "    val_loss       : -1457.1732788085938\n",
      "    val_ess        : 3.7624712387720742\n",
      "    val_log_marginal: 1457.2962646484375\n",
      "Train Epoch: 723 [0/54000 (0%)] Loss: -1461.217407\n",
      "Train Epoch: 723 [32768/54000 (61%)] Loss: -1459.049683\n",
      "    epoch          : 723\n",
      "    loss           : -1458.6432783018868\n",
      "    ess            : 3.7601539593822553\n",
      "    log_marginal   : 1458.764275316922\n",
      "    val_loss       : -1457.571756998698\n",
      "    val_ess        : 3.762342651685079\n",
      "    val_log_marginal: 1457.6869710286458\n",
      "Train Epoch: 724 [0/54000 (0%)] Loss: -1458.509155\n",
      "Train Epoch: 724 [32768/54000 (61%)] Loss: -1458.825439\n",
      "    epoch          : 724\n",
      "    loss           : -1458.8990317290684\n",
      "    ess            : 3.7587590487498157\n",
      "    log_marginal   : 1459.0222191000885\n",
      "    val_loss       : -1457.75830078125\n",
      "    val_ess        : 3.7699281374613443\n",
      "    val_log_marginal: 1457.8780517578125\n",
      "Train Epoch: 725 [0/54000 (0%)] Loss: -1460.041626\n",
      "Train Epoch: 725 [32768/54000 (61%)] Loss: -1458.713867\n",
      "    epoch          : 725\n",
      "    loss           : -1459.1993316074588\n",
      "    ess            : 3.765713138400384\n",
      "    log_marginal   : 1459.3176361659787\n",
      "    val_loss       : -1457.9035237630208\n",
      "    val_ess        : 3.75317374865214\n",
      "    val_log_marginal: 1458.0381673177083\n",
      "Train Epoch: 726 [0/54000 (0%)] Loss: -1461.353760\n",
      "Train Epoch: 726 [32768/54000 (61%)] Loss: -1459.272095\n",
      "    epoch          : 726\n",
      "    loss           : -1459.3339037625294\n",
      "    ess            : 3.7652388923573046\n",
      "    log_marginal   : 1459.4514137124115\n",
      "    val_loss       : -1458.1293334960938\n",
      "    val_ess        : 3.761467178662618\n",
      "    val_log_marginal: 1458.2528483072917\n",
      "Train Epoch: 727 [0/54000 (0%)] Loss: -1456.886841\n",
      "Train Epoch: 727 [32768/54000 (61%)] Loss: -1459.827637\n",
      "    epoch          : 727\n",
      "    loss           : -1459.5615602889152\n",
      "    ess            : 3.7647267692493944\n",
      "    log_marginal   : 1459.6790978773586\n",
      "    val_loss       : -1458.275899251302\n",
      "    val_ess        : 3.7805646657943726\n",
      "    val_log_marginal: 1458.3842163085938\n",
      "Train Epoch: 728 [0/54000 (0%)] Loss: -1461.049927\n",
      "Train Epoch: 728 [32768/54000 (61%)] Loss: -1460.655762\n",
      "    epoch          : 728\n",
      "    loss           : -1459.5974443543632\n",
      "    ess            : 3.7645973574440434\n",
      "    log_marginal   : 1459.7195469118515\n",
      "    val_loss       : -1458.4344685872395\n",
      "    val_ess        : 3.7617357969284058\n",
      "    val_log_marginal: 1458.55615234375\n",
      "Train Epoch: 729 [0/54000 (0%)] Loss: -1460.564209\n",
      "Train Epoch: 729 [32768/54000 (61%)] Loss: -1459.684082\n",
      "    epoch          : 729\n",
      "    loss           : -1459.7925818101414\n",
      "    ess            : 3.7633948056203015\n",
      "    log_marginal   : 1459.9138045400944\n",
      "    val_loss       : -1458.9257405598958\n",
      "    val_ess        : 3.757216493288676\n",
      "    val_log_marginal: 1459.0458577473958\n",
      "Train Epoch: 730 [0/54000 (0%)] Loss: -1462.823242\n",
      "Train Epoch: 730 [32768/54000 (61%)] Loss: -1455.707642\n",
      "    epoch          : 730\n",
      "    loss           : -1459.9878321233784\n",
      "    ess            : 3.7640038031452105\n",
      "    log_marginal   : 1460.103520231427\n",
      "    val_loss       : -1458.9616292317708\n",
      "    val_ess        : 3.765687902768453\n",
      "    val_log_marginal: 1459.0788167317708\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch730.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 731 [0/54000 (0%)] Loss: -1459.740601\n",
      "Train Epoch: 731 [32768/54000 (61%)] Loss: -1460.585449\n",
      "    epoch          : 731\n",
      "    loss           : -1460.2420700361145\n",
      "    ess            : 3.760094944036232\n",
      "    log_marginal   : 1460.367316479953\n",
      "    val_loss       : -1458.9124552408855\n",
      "    val_ess        : 3.759424567222595\n",
      "    val_log_marginal: 1459.0394694010417\n",
      "Train Epoch: 732 [0/54000 (0%)] Loss: -1462.294434\n",
      "Train Epoch: 732 [32768/54000 (61%)] Loss: -1461.360840\n",
      "    epoch          : 732\n",
      "    loss           : -1460.4234204562206\n",
      "    ess            : 3.766874857668607\n",
      "    log_marginal   : 1460.5403384802476\n",
      "    val_loss       : -1459.2578938802083\n",
      "    val_ess        : 3.7597431739171348\n",
      "    val_log_marginal: 1459.3829956054688\n",
      "Train Epoch: 733 [0/54000 (0%)] Loss: -1461.486084\n",
      "Train Epoch: 733 [32768/54000 (61%)] Loss: -1463.463623\n",
      "    epoch          : 733\n",
      "    loss           : -1460.6316678029186\n",
      "    ess            : 3.7695028466998406\n",
      "    log_marginal   : 1460.7481574292453\n",
      "    val_loss       : -1459.590311686198\n",
      "    val_ess        : 3.764626463254293\n",
      "    val_log_marginal: 1459.7076416015625\n",
      "Train Epoch: 734 [0/54000 (0%)] Loss: -1458.215332\n",
      "Train Epoch: 734 [32768/54000 (61%)] Loss: -1461.010254\n",
      "    epoch          : 734\n",
      "    loss           : -1460.8993242371757\n",
      "    ess            : 3.7679705529842735\n",
      "    log_marginal   : 1461.018144715507\n",
      "    val_loss       : -1459.8988037109375\n",
      "    val_ess        : 3.780929128328959\n",
      "    val_log_marginal: 1460.0110473632812\n",
      "Train Epoch: 735 [0/54000 (0%)] Loss: -1462.532959\n",
      "Train Epoch: 735 [32768/54000 (61%)] Loss: -1461.174927\n",
      "    epoch          : 735\n",
      "    loss           : -1461.0777495762088\n",
      "    ess            : 3.7648966582316272\n",
      "    log_marginal   : 1461.1981431493218\n",
      "    val_loss       : -1460.2860310872395\n",
      "    val_ess        : 3.7679056326548257\n",
      "    val_log_marginal: 1460.3988444010417\n",
      "Train Epoch: 736 [0/54000 (0%)] Loss: -1462.032715\n",
      "Train Epoch: 736 [32768/54000 (61%)] Loss: -1460.414917\n",
      "    epoch          : 736\n",
      "    loss           : -1461.2705930313973\n",
      "    ess            : 3.7638428796012446\n",
      "    log_marginal   : 1461.3889758991745\n",
      "    val_loss       : -1459.9382731119792\n",
      "    val_ess        : 3.7441808780034385\n",
      "    val_log_marginal: 1460.0768025716145\n",
      "Train Epoch: 737 [0/54000 (0%)] Loss: -1461.927246\n",
      "Train Epoch: 737 [32768/54000 (61%)] Loss: -1463.224121\n",
      "    epoch          : 737\n",
      "    loss           : -1461.3735466723172\n",
      "    ess            : 3.7617289075311624\n",
      "    log_marginal   : 1461.4990096182194\n",
      "    val_loss       : -1460.6210530598958\n",
      "    val_ess        : 3.764867146809896\n",
      "    val_log_marginal: 1460.7400919596355\n",
      "Train Epoch: 738 [0/54000 (0%)] Loss: -1460.920776\n",
      "Train Epoch: 738 [32768/54000 (61%)] Loss: -1464.122070\n",
      "    epoch          : 738\n",
      "    loss           : -1461.6170769457547\n",
      "    ess            : 3.7615499631413876\n",
      "    log_marginal   : 1461.741153357164\n",
      "    val_loss       : -1460.6886393229167\n",
      "    val_ess        : 3.7767417828241983\n",
      "    val_log_marginal: 1460.8074340820312\n",
      "Train Epoch: 739 [0/54000 (0%)] Loss: -1460.227173\n",
      "Train Epoch: 739 [32768/54000 (61%)] Loss: -1461.486572\n",
      "    epoch          : 739\n",
      "    loss           : -1461.904057340802\n",
      "    ess            : 3.7635300699269996\n",
      "    log_marginal   : 1462.0255863981427\n",
      "    val_loss       : -1461.009745279948\n",
      "    val_ess        : 3.7619645992914834\n",
      "    val_log_marginal: 1461.142110188802\n",
      "Train Epoch: 740 [0/54000 (0%)] Loss: -1462.817383\n",
      "Train Epoch: 740 [32768/54000 (61%)] Loss: -1463.680298\n",
      "    epoch          : 740\n",
      "    loss           : -1462.0139344413326\n",
      "    ess            : 3.7618571992190377\n",
      "    log_marginal   : 1462.1378588406544\n",
      "    val_loss       : -1460.9818725585938\n",
      "    val_ess        : 3.7627220153808594\n",
      "    val_log_marginal: 1461.094746907552\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch740.pth ...\n",
      "Train Epoch: 741 [0/54000 (0%)] Loss: -1461.005005\n",
      "Train Epoch: 741 [32768/54000 (61%)] Loss: -1461.859131\n",
      "    epoch          : 741\n",
      "    loss           : -1462.202963775059\n",
      "    ess            : 3.758342576476763\n",
      "    log_marginal   : 1462.3281894899765\n",
      "    val_loss       : -1461.5641072591145\n",
      "    val_ess        : 3.7656359672546387\n",
      "    val_log_marginal: 1461.6868082682292\n",
      "Train Epoch: 742 [0/54000 (0%)] Loss: -1462.959961\n",
      "Train Epoch: 742 [32768/54000 (61%)] Loss: -1462.868164\n",
      "    epoch          : 742\n",
      "    loss           : -1462.4471320386203\n",
      "    ess            : 3.760013940199366\n",
      "    log_marginal   : 1462.5717312794811\n",
      "    val_loss       : -1461.1786702473958\n",
      "    val_ess        : 3.769316832224528\n",
      "    val_log_marginal: 1461.3001505533855\n",
      "Train Epoch: 743 [0/54000 (0%)] Loss: -1461.959595\n",
      "Train Epoch: 743 [32768/54000 (61%)] Loss: -1461.161377\n",
      "    epoch          : 743\n",
      "    loss           : -1462.6626368108784\n",
      "    ess            : 3.764224848657284\n",
      "    log_marginal   : 1462.7822772331958\n",
      "    val_loss       : -1461.7701212565105\n",
      "    val_ess        : 3.7593485911687217\n",
      "    val_log_marginal: 1461.8925374348958\n",
      "Train Epoch: 744 [0/54000 (0%)] Loss: -1467.917236\n",
      "Train Epoch: 744 [32768/54000 (61%)] Loss: -1462.727905\n",
      "    epoch          : 744\n",
      "    loss           : -1462.7204820165093\n",
      "    ess            : 3.7625928374956237\n",
      "    log_marginal   : 1462.8417093528892\n",
      "    val_loss       : -1461.5818888346355\n",
      "    val_ess        : 3.760537346204122\n",
      "    val_log_marginal: 1461.7056274414062\n",
      "Train Epoch: 745 [0/54000 (0%)] Loss: -1461.676025\n",
      "Train Epoch: 745 [32768/54000 (61%)] Loss: -1467.273682\n",
      "    epoch          : 745\n",
      "    loss           : -1462.9744826982605\n",
      "    ess            : 3.7653574313757554\n",
      "    log_marginal   : 1463.094487028302\n",
      "    val_loss       : -1462.447977701823\n",
      "    val_ess        : 3.7640231053034463\n",
      "    val_log_marginal: 1462.5719604492188\n",
      "Train Epoch: 746 [0/54000 (0%)] Loss: -1465.075684\n",
      "Train Epoch: 746 [32768/54000 (61%)] Loss: -1462.106812\n",
      "    epoch          : 746\n",
      "    loss           : -1463.2014321381191\n",
      "    ess            : 3.7665214718512767\n",
      "    log_marginal   : 1463.319819612323\n",
      "    val_loss       : -1462.400166829427\n",
      "    val_ess        : 3.760262608528137\n",
      "    val_log_marginal: 1462.519307454427\n",
      "Train Epoch: 747 [0/54000 (0%)] Loss: -1465.824097\n",
      "Train Epoch: 747 [32768/54000 (61%)] Loss: -1464.813354\n",
      "    epoch          : 747\n",
      "    loss           : -1463.5396244840802\n",
      "    ess            : 3.765615031404315\n",
      "    log_marginal   : 1463.6597554908608\n",
      "    val_loss       : -1462.4676310221355\n",
      "    val_ess        : 3.7539698282877603\n",
      "    val_log_marginal: 1462.5999552408855\n",
      "Train Epoch: 748 [0/54000 (0%)] Loss: -1463.018555\n",
      "Train Epoch: 748 [32768/54000 (61%)] Loss: -1466.123657\n",
      "    epoch          : 748\n",
      "    loss           : -1463.7070335532135\n",
      "    ess            : 3.7702446253794544\n",
      "    log_marginal   : 1463.824748489092\n",
      "    val_loss       : -1462.7477213541667\n",
      "    val_ess        : 3.771394371986389\n",
      "    val_log_marginal: 1462.861063639323\n",
      "Train Epoch: 749 [0/54000 (0%)] Loss: -1464.796997\n",
      "Train Epoch: 749 [32768/54000 (61%)] Loss: -1463.919189\n",
      "    epoch          : 749\n",
      "    loss           : -1463.8372296027417\n",
      "    ess            : 3.758973670455645\n",
      "    log_marginal   : 1463.9607279075767\n",
      "    val_loss       : -1462.985087076823\n",
      "    val_ess        : 3.766297698020935\n",
      "    val_log_marginal: 1463.1070149739583\n",
      "Train Epoch: 750 [0/54000 (0%)] Loss: -1466.740356\n",
      "Train Epoch: 750 [32768/54000 (61%)] Loss: -1462.843750\n",
      "    epoch          : 750\n",
      "    loss           : -1464.1097066627358\n",
      "    ess            : 3.7669177820097723\n",
      "    log_marginal   : 1464.2265072228774\n",
      "    val_loss       : -1463.167744954427\n",
      "    val_ess        : 3.765088160832723\n",
      "    val_log_marginal: 1463.288350423177\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch750.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 751 [0/54000 (0%)] Loss: -1460.370605\n",
      "Train Epoch: 751 [32768/54000 (61%)] Loss: -1463.855957\n",
      "    epoch          : 751\n",
      "    loss           : -1464.3297741008255\n",
      "    ess            : 3.7678817758020364\n",
      "    log_marginal   : 1464.446694428066\n",
      "    val_loss       : -1463.6879475911458\n",
      "    val_ess        : 3.7527191638946533\n",
      "    val_log_marginal: 1463.8194580078125\n",
      "Train Epoch: 752 [0/54000 (0%)] Loss: -1469.642578\n",
      "Train Epoch: 752 [32768/54000 (61%)] Loss: -1464.986084\n",
      "    epoch          : 752\n",
      "    loss           : -1464.5728598540684\n",
      "    ess            : 3.7687619047344856\n",
      "    log_marginal   : 1464.6934929613797\n",
      "    val_loss       : -1463.4964396158855\n",
      "    val_ess        : 3.7683947483698526\n",
      "    val_log_marginal: 1463.617919921875\n",
      "Train Epoch: 753 [0/54000 (0%)] Loss: -1466.286865\n",
      "Train Epoch: 753 [32768/54000 (61%)] Loss: -1462.621704\n",
      "    epoch          : 753\n",
      "    loss           : -1464.7353976267689\n",
      "    ess            : 3.767352468562576\n",
      "    log_marginal   : 1464.8539048680718\n",
      "    val_loss       : -1463.6868693033855\n",
      "    val_ess        : 3.7629995743433633\n",
      "    val_log_marginal: 1463.807840983073\n",
      "Train Epoch: 754 [0/54000 (0%)] Loss: -1462.259033\n",
      "Train Epoch: 754 [32768/54000 (61%)] Loss: -1461.342041\n",
      "    epoch          : 754\n",
      "    loss           : -1464.9712881412147\n",
      "    ess            : 3.762497991885779\n",
      "    log_marginal   : 1465.0918452424823\n",
      "    val_loss       : -1464.3143107096355\n",
      "    val_ess        : 3.7745760679244995\n",
      "    val_log_marginal: 1464.4341227213542\n",
      "Train Epoch: 755 [0/54000 (0%)] Loss: -1465.359985\n",
      "Train Epoch: 755 [32768/54000 (61%)] Loss: -1464.985596\n",
      "    epoch          : 755\n",
      "    loss           : -1465.085714088296\n",
      "    ess            : 3.769053522145973\n",
      "    log_marginal   : 1465.2041867813973\n",
      "    val_loss       : -1464.0851643880208\n",
      "    val_ess        : 3.7707525889078775\n",
      "    val_log_marginal: 1464.203145345052\n",
      "Train Epoch: 756 [0/54000 (0%)] Loss: -1466.299683\n",
      "Train Epoch: 756 [32768/54000 (61%)] Loss: -1463.090332\n",
      "    epoch          : 756\n",
      "    loss           : -1465.2063932598762\n",
      "    ess            : 3.7635863412101314\n",
      "    log_marginal   : 1465.3314162920105\n",
      "    val_loss       : -1464.357177734375\n",
      "    val_ess        : 3.757688323656718\n",
      "    val_log_marginal: 1464.482442220052\n",
      "Train Epoch: 757 [0/54000 (0%)] Loss: -1466.844116\n",
      "Train Epoch: 757 [32768/54000 (61%)] Loss: -1465.546997\n",
      "    epoch          : 757\n",
      "    loss           : -1465.519572707842\n",
      "    ess            : 3.7617498343845583\n",
      "    log_marginal   : 1465.6428706331073\n",
      "    val_loss       : -1464.60888671875\n",
      "    val_ess        : 3.775580565134684\n",
      "    val_log_marginal: 1464.7210489908855\n",
      "Train Epoch: 758 [0/54000 (0%)] Loss: -1462.880981\n",
      "Train Epoch: 758 [32768/54000 (61%)] Loss: -1463.006714\n",
      "    epoch          : 758\n",
      "    loss           : -1465.6707026643573\n",
      "    ess            : 3.766713515767511\n",
      "    log_marginal   : 1465.7899515403892\n",
      "    val_loss       : -1464.995869954427\n",
      "    val_ess        : 3.7660121520360312\n",
      "    val_log_marginal: 1465.112325032552\n",
      "Train Epoch: 759 [0/54000 (0%)] Loss: -1465.104980\n",
      "Train Epoch: 759 [32768/54000 (61%)] Loss: -1466.001953\n",
      "    epoch          : 759\n",
      "    loss           : -1465.822208044664\n",
      "    ess            : 3.7682102401301547\n",
      "    log_marginal   : 1465.93889805056\n",
      "    val_loss       : -1464.8660685221355\n",
      "    val_ess        : 3.7655121882756553\n",
      "    val_log_marginal: 1464.9837646484375\n",
      "Train Epoch: 760 [0/54000 (0%)] Loss: -1467.070801\n",
      "Train Epoch: 760 [32768/54000 (61%)] Loss: -1462.891235\n",
      "    epoch          : 760\n",
      "    loss           : -1466.250981168927\n",
      "    ess            : 3.7625021979493916\n",
      "    log_marginal   : 1466.3749631485848\n",
      "    val_loss       : -1465.431620279948\n",
      "    val_ess        : 3.7819252014160156\n",
      "    val_log_marginal: 1465.5406087239583\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch760.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 761 [0/54000 (0%)] Loss: -1465.523560\n",
      "Train Epoch: 761 [32768/54000 (61%)] Loss: -1464.124512\n",
      "    epoch          : 761\n",
      "    loss           : -1466.3117560620578\n",
      "    ess            : 3.761087678513437\n",
      "    log_marginal   : 1466.4386723356427\n",
      "    val_loss       : -1465.0410970052083\n",
      "    val_ess        : 3.766731301943461\n",
      "    val_log_marginal: 1465.1670939127605\n",
      "Train Epoch: 762 [0/54000 (0%)] Loss: -1468.153687\n",
      "Train Epoch: 762 [32768/54000 (61%)] Loss: -1464.310547\n",
      "    epoch          : 762\n",
      "    loss           : -1466.437541457842\n",
      "    ess            : 3.7672792605634005\n",
      "    log_marginal   : 1466.5576010650059\n",
      "    val_loss       : -1465.4451497395833\n",
      "    val_ess        : 3.7688780228296914\n",
      "    val_log_marginal: 1465.5616861979167\n",
      "Train Epoch: 763 [0/54000 (0%)] Loss: -1467.310547\n",
      "Train Epoch: 763 [32768/54000 (61%)] Loss: -1465.594971\n",
      "    epoch          : 763\n",
      "    loss           : -1466.668586011203\n",
      "    ess            : 3.7596702350760407\n",
      "    log_marginal   : 1466.7955368329895\n",
      "    val_loss       : -1465.4061889648438\n",
      "    val_ess        : 3.7579593658447266\n",
      "    val_log_marginal: 1465.5262247721355\n",
      "Train Epoch: 764 [0/54000 (0%)] Loss: -1468.089355\n",
      "Train Epoch: 764 [32768/54000 (61%)] Loss: -1467.135742\n",
      "    epoch          : 764\n",
      "    loss           : -1466.7887216244103\n",
      "    ess            : 3.7687549501095177\n",
      "    log_marginal   : 1466.906940964033\n",
      "    val_loss       : -1465.787577311198\n",
      "    val_ess        : 3.7612150510152182\n",
      "    val_log_marginal: 1465.9118041992188\n",
      "Train Epoch: 765 [0/54000 (0%)] Loss: -1468.533691\n",
      "Train Epoch: 765 [32768/54000 (61%)] Loss: -1464.588867\n",
      "    epoch          : 765\n",
      "    loss           : -1467.072261018573\n",
      "    ess            : 3.7660989671383263\n",
      "    log_marginal   : 1467.1935551481427\n",
      "    val_loss       : -1466.105712890625\n",
      "    val_ess        : 3.758317708969116\n",
      "    val_log_marginal: 1466.2289632161458\n",
      "Train Epoch: 766 [0/54000 (0%)] Loss: -1468.301025\n",
      "Train Epoch: 766 [32768/54000 (61%)] Loss: -1465.983643\n",
      "    epoch          : 766\n",
      "    loss           : -1467.3499041863208\n",
      "    ess            : 3.7608046126815506\n",
      "    log_marginal   : 1467.4758392909787\n",
      "    val_loss       : -1466.3478597005208\n",
      "    val_ess        : 3.7562739849090576\n",
      "    val_log_marginal: 1466.4723510742188\n",
      "Train Epoch: 767 [0/54000 (0%)] Loss: -1467.545654\n",
      "Train Epoch: 767 [32768/54000 (61%)] Loss: -1467.782471\n",
      "    epoch          : 767\n",
      "    loss           : -1467.4924800081073\n",
      "    ess            : 3.7636140697407274\n",
      "    log_marginal   : 1467.6159760097287\n",
      "    val_loss       : -1466.5921834309895\n",
      "    val_ess        : 3.767599582672119\n",
      "    val_log_marginal: 1466.7066853841145\n",
      "Train Epoch: 768 [0/54000 (0%)] Loss: -1470.214844\n",
      "Train Epoch: 768 [32768/54000 (61%)] Loss: -1471.192017\n",
      "    epoch          : 768\n",
      "    loss           : -1467.6734480947819\n",
      "    ess            : 3.763413429260254\n",
      "    log_marginal   : 1467.7989363760319\n",
      "    val_loss       : -1466.840087890625\n",
      "    val_ess        : 3.7749212185541787\n",
      "    val_log_marginal: 1466.9534912109375\n",
      "Train Epoch: 769 [0/54000 (0%)] Loss: -1470.412598\n",
      "Train Epoch: 769 [32768/54000 (61%)] Loss: -1463.405029\n",
      "    epoch          : 769\n",
      "    loss           : -1467.805850622789\n",
      "    ess            : 3.7615269085146346\n",
      "    log_marginal   : 1467.9270710495282\n",
      "    val_loss       : -1466.8112182617188\n",
      "    val_ess        : 3.7572315533955893\n",
      "    val_log_marginal: 1466.9381510416667\n",
      "Train Epoch: 770 [0/54000 (0%)] Loss: -1467.930664\n",
      "Train Epoch: 770 [32768/54000 (61%)] Loss: -1469.171143\n",
      "    epoch          : 770\n",
      "    loss           : -1467.9082722214032\n",
      "    ess            : 3.765462007162706\n",
      "    log_marginal   : 1468.0288523548054\n",
      "    val_loss       : -1467.1126912434895\n",
      "    val_ess        : 3.7603843609491983\n",
      "    val_log_marginal: 1467.2403767903645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch770.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 771 [0/54000 (0%)] Loss: -1469.122925\n",
      "Train Epoch: 771 [32768/54000 (61%)] Loss: -1470.774780\n",
      "    epoch          : 771\n",
      "    loss           : -1468.172425468013\n",
      "    ess            : 3.765110861580327\n",
      "    log_marginal   : 1468.292485075177\n",
      "    val_loss       : -1467.15234375\n",
      "    val_ess        : 3.769106388092041\n",
      "    val_log_marginal: 1467.2656656901042\n",
      "Train Epoch: 772 [0/54000 (0%)] Loss: -1466.729736\n",
      "Train Epoch: 772 [32768/54000 (61%)] Loss: -1467.247070\n",
      "    epoch          : 772\n",
      "    loss           : -1468.3125299417748\n",
      "    ess            : 3.7643739367431066\n",
      "    log_marginal   : 1468.4301688716096\n",
      "    val_loss       : -1467.1678059895833\n",
      "    val_ess        : 3.7578516403834024\n",
      "    val_log_marginal: 1467.289082845052\n",
      "Train Epoch: 773 [0/54000 (0%)] Loss: -1465.938477\n",
      "Train Epoch: 773 [32768/54000 (61%)] Loss: -1469.483398\n",
      "    epoch          : 773\n",
      "    loss           : -1468.5903251216096\n",
      "    ess            : 3.7630929991884052\n",
      "    log_marginal   : 1468.7123332473468\n",
      "    val_loss       : -1467.6553955078125\n",
      "    val_ess        : 3.7654634714126587\n",
      "    val_log_marginal: 1467.7821451822917\n",
      "Train Epoch: 774 [0/54000 (0%)] Loss: -1470.547485\n",
      "Train Epoch: 774 [32768/54000 (61%)] Loss: -1467.538574\n",
      "    epoch          : 774\n",
      "    loss           : -1468.908120209316\n",
      "    ess            : 3.7662256888623507\n",
      "    log_marginal   : 1469.0278757923054\n",
      "    val_loss       : -1468.09423828125\n",
      "    val_ess        : 3.7682984272638955\n",
      "    val_log_marginal: 1468.2198282877605\n",
      "Train Epoch: 775 [0/54000 (0%)] Loss: -1469.985840\n",
      "Train Epoch: 775 [32768/54000 (61%)] Loss: -1466.877930\n",
      "    epoch          : 775\n",
      "    loss           : -1468.9122544774468\n",
      "    ess            : 3.7661959090322816\n",
      "    log_marginal   : 1469.0306511645047\n",
      "    val_loss       : -1468.0038452148438\n",
      "    val_ess        : 3.771863063176473\n",
      "    val_log_marginal: 1468.1173299153645\n",
      "Train Epoch: 776 [0/54000 (0%)] Loss: -1467.683594\n",
      "Train Epoch: 776 [32768/54000 (61%)] Loss: -1468.400879\n",
      "    epoch          : 776\n",
      "    loss           : -1469.307612581073\n",
      "    ess            : 3.7668371560438625\n",
      "    log_marginal   : 1469.4268660635319\n",
      "    val_loss       : -1468.2347005208333\n",
      "    val_ess        : 3.7729507287343345\n",
      "    val_log_marginal: 1468.343037923177\n",
      "Train Epoch: 777 [0/54000 (0%)] Loss: -1469.728149\n",
      "Train Epoch: 777 [32768/54000 (61%)] Loss: -1469.863037\n",
      "    epoch          : 777\n",
      "    loss           : -1469.4131803692512\n",
      "    ess            : 3.766300934665608\n",
      "    log_marginal   : 1469.5329912293632\n",
      "    val_loss       : -1468.561014811198\n",
      "    val_ess        : 3.7645594676335654\n",
      "    val_log_marginal: 1468.6817626953125\n",
      "Train Epoch: 778 [0/54000 (0%)] Loss: -1470.899170\n",
      "Train Epoch: 778 [32768/54000 (61%)] Loss: -1472.636475\n",
      "    epoch          : 778\n",
      "    loss           : -1469.578207915684\n",
      "    ess            : 3.7649421062109605\n",
      "    log_marginal   : 1469.6983872899468\n",
      "    val_loss       : -1468.413798014323\n",
      "    val_ess        : 3.7644914786020913\n",
      "    val_log_marginal: 1468.5421142578125\n",
      "Train Epoch: 779 [0/54000 (0%)] Loss: -1469.578857\n",
      "Train Epoch: 779 [32768/54000 (61%)] Loss: -1469.003906\n",
      "    epoch          : 779\n",
      "    loss           : -1469.7208574403007\n",
      "    ess            : 3.764276531507384\n",
      "    log_marginal   : 1469.845624815743\n",
      "    val_loss       : -1468.804178873698\n",
      "    val_ess        : 3.7634259462356567\n",
      "    val_log_marginal: 1468.92724609375\n",
      "Train Epoch: 780 [0/54000 (0%)] Loss: -1472.207764\n",
      "Train Epoch: 780 [32768/54000 (61%)] Loss: -1469.241943\n",
      "    epoch          : 780\n",
      "    loss           : -1470.0070063752948\n",
      "    ess            : 3.769912647751142\n",
      "    log_marginal   : 1470.1264325987618\n",
      "    val_loss       : -1468.993896484375\n",
      "    val_ess        : 3.7637969652811685\n",
      "    val_log_marginal: 1469.1169026692708\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch780.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 781 [0/54000 (0%)] Loss: -1472.429443\n",
      "Train Epoch: 781 [32768/54000 (61%)] Loss: -1468.669678\n",
      "    epoch          : 781\n",
      "    loss           : -1470.2061306935436\n",
      "    ess            : 3.765329693848232\n",
      "    log_marginal   : 1470.3285533977005\n",
      "    val_loss       : -1469.1865234375\n",
      "    val_ess        : 3.7727771997451782\n",
      "    val_log_marginal: 1469.3021647135417\n",
      "Train Epoch: 782 [0/54000 (0%)] Loss: -1470.283569\n",
      "Train Epoch: 782 [32768/54000 (61%)] Loss: -1466.169434\n",
      "    epoch          : 782\n",
      "    loss           : -1470.3309694686027\n",
      "    ess            : 3.7594238227268435\n",
      "    log_marginal   : 1470.4563126474056\n",
      "    val_loss       : -1469.5208129882812\n",
      "    val_ess        : 3.7605942487716675\n",
      "    val_log_marginal: 1469.6414388020833\n",
      "Train Epoch: 783 [0/54000 (0%)] Loss: -1470.248291\n",
      "Train Epoch: 783 [32768/54000 (61%)] Loss: -1470.968384\n",
      "    epoch          : 783\n",
      "    loss           : -1470.669106537441\n",
      "    ess            : 3.7618683374152995\n",
      "    log_marginal   : 1470.7927545511498\n",
      "    val_loss       : -1469.4494222005208\n",
      "    val_ess        : 3.771954377492269\n",
      "    val_log_marginal: 1469.56591796875\n",
      "Train Epoch: 784 [0/54000 (0%)] Loss: -1474.391357\n",
      "Train Epoch: 784 [32768/54000 (61%)] Loss: -1470.405151\n",
      "    epoch          : 784\n",
      "    loss           : -1470.854922888414\n",
      "    ess            : 3.76666444202639\n",
      "    log_marginal   : 1470.972941848467\n",
      "    val_loss       : -1469.8355712890625\n",
      "    val_ess        : 3.7633541425069175\n",
      "    val_log_marginal: 1469.9646809895833\n",
      "Train Epoch: 785 [0/54000 (0%)] Loss: -1472.999634\n",
      "Train Epoch: 785 [32768/54000 (61%)] Loss: -1473.751465\n",
      "    epoch          : 785\n",
      "    loss           : -1471.1449665573407\n",
      "    ess            : 3.7711129953276434\n",
      "    log_marginal   : 1471.2640288730838\n",
      "    val_loss       : -1470.0305582682292\n",
      "    val_ess        : 3.7675335009892783\n",
      "    val_log_marginal: 1470.1529337565105\n",
      "Train Epoch: 786 [0/54000 (0%)] Loss: -1473.107910\n",
      "Train Epoch: 786 [32768/54000 (61%)] Loss: -1472.286133\n",
      "    epoch          : 786\n",
      "    loss           : -1471.3269803029186\n",
      "    ess            : 3.7628260288598403\n",
      "    log_marginal   : 1471.451068230395\n",
      "    val_loss       : -1470.3583374023438\n",
      "    val_ess        : 3.766255776087443\n",
      "    val_log_marginal: 1470.4874471028645\n",
      "Train Epoch: 787 [0/54000 (0%)] Loss: -1470.283203\n",
      "Train Epoch: 787 [32768/54000 (61%)] Loss: -1470.229614\n",
      "    epoch          : 787\n",
      "    loss           : -1471.474240860849\n",
      "    ess            : 3.7622936941542715\n",
      "    log_marginal   : 1471.594560731132\n",
      "    val_loss       : -1470.3633219401042\n",
      "    val_ess        : 3.7615315119425454\n",
      "    val_log_marginal: 1470.488545735677\n",
      "Train Epoch: 788 [0/54000 (0%)] Loss: -1472.068726\n",
      "Train Epoch: 788 [32768/54000 (61%)] Loss: -1472.438232\n",
      "    epoch          : 788\n",
      "    loss           : -1471.527037422612\n",
      "    ess            : 3.765666178937228\n",
      "    log_marginal   : 1471.6496743256191\n",
      "    val_loss       : -1470.4486694335938\n",
      "    val_ess        : 3.7627158562342324\n",
      "    val_log_marginal: 1470.5712483723958\n",
      "Train Epoch: 789 [0/54000 (0%)] Loss: -1473.074707\n",
      "Train Epoch: 789 [32768/54000 (61%)] Loss: -1467.628174\n",
      "    epoch          : 789\n",
      "    loss           : -1471.7619767099056\n",
      "    ess            : 3.7654537119955385\n",
      "    log_marginal   : 1471.882075471698\n",
      "    val_loss       : -1470.8656616210938\n",
      "    val_ess        : 3.7550336917241416\n",
      "    val_log_marginal: 1470.9955037434895\n",
      "Train Epoch: 790 [0/54000 (0%)] Loss: -1470.848022\n",
      "Train Epoch: 790 [32768/54000 (61%)] Loss: -1471.070435\n",
      "    epoch          : 790\n",
      "    loss           : -1471.9008420548348\n",
      "    ess            : 3.7631636970448046\n",
      "    log_marginal   : 1472.024662809552\n",
      "    val_loss       : -1470.953145345052\n",
      "    val_ess        : 3.7746627728144326\n",
      "    val_log_marginal: 1471.066182454427\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch790.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 791 [0/54000 (0%)] Loss: -1474.360962\n",
      "Train Epoch: 791 [32768/54000 (61%)] Loss: -1472.860229\n",
      "    epoch          : 791\n",
      "    loss           : -1472.2693147479363\n",
      "    ess            : 3.7678188962756463\n",
      "    log_marginal   : 1472.3895148511203\n",
      "    val_loss       : -1471.5210367838542\n",
      "    val_ess        : 3.7612975041071572\n",
      "    val_log_marginal: 1471.6507161458333\n",
      "Train Epoch: 792 [0/54000 (0%)] Loss: -1472.044434\n",
      "Train Epoch: 792 [32768/54000 (61%)] Loss: -1474.978760\n",
      "    epoch          : 792\n",
      "    loss           : -1472.4187334168632\n",
      "    ess            : 3.769092118965005\n",
      "    log_marginal   : 1472.5383139556309\n",
      "    val_loss       : -1471.3252766927083\n",
      "    val_ess        : 3.7670603593190513\n",
      "    val_log_marginal: 1471.444559733073\n",
      "Train Epoch: 793 [0/54000 (0%)] Loss: -1473.023804\n",
      "Train Epoch: 793 [32768/54000 (61%)] Loss: -1473.463379\n",
      "    epoch          : 793\n",
      "    loss           : -1472.6239290057488\n",
      "    ess            : 3.7648406208686107\n",
      "    log_marginal   : 1472.747392762382\n",
      "    val_loss       : -1471.7368570963542\n",
      "    val_ess        : 3.754977822303772\n",
      "    val_log_marginal: 1471.8594970703125\n",
      "Train Epoch: 794 [0/54000 (0%)] Loss: -1474.282715\n",
      "Train Epoch: 794 [32768/54000 (61%)] Loss: -1471.048340\n",
      "    epoch          : 794\n",
      "    loss           : -1472.8259254311615\n",
      "    ess            : 3.7663153927281217\n",
      "    log_marginal   : 1472.94545299602\n",
      "    val_loss       : -1471.9583740234375\n",
      "    val_ess        : 3.7774160305658975\n",
      "    val_log_marginal: 1472.0705973307292\n",
      "Train Epoch: 795 [0/54000 (0%)] Loss: -1471.029785\n",
      "Train Epoch: 795 [32768/54000 (61%)] Loss: -1473.820312\n",
      "    epoch          : 795\n",
      "    loss           : -1473.0253768057194\n",
      "    ess            : 3.7619062999509416\n",
      "    log_marginal   : 1473.1495568617336\n",
      "    val_loss       : -1472.429951985677\n",
      "    val_ess        : 3.7656474113464355\n",
      "    val_log_marginal: 1472.5478922526042\n",
      "Train Epoch: 796 [0/54000 (0%)] Loss: -1474.035889\n",
      "Train Epoch: 796 [32768/54000 (61%)] Loss: -1472.348389\n",
      "    epoch          : 796\n",
      "    loss           : -1473.1993937942218\n",
      "    ess            : 3.76512573799997\n",
      "    log_marginal   : 1473.3190203972583\n",
      "    val_loss       : -1472.1737060546875\n",
      "    val_ess        : 3.7629600365956626\n",
      "    val_log_marginal: 1472.294413248698\n",
      "Train Epoch: 797 [0/54000 (0%)] Loss: -1474.081177\n",
      "Train Epoch: 797 [32768/54000 (61%)] Loss: -1474.037354\n",
      "    epoch          : 797\n",
      "    loss           : -1473.4163588038032\n",
      "    ess            : 3.7636579432577455\n",
      "    log_marginal   : 1473.5417296211674\n",
      "    val_loss       : -1472.4885660807292\n",
      "    val_ess        : 3.7503718535105386\n",
      "    val_log_marginal: 1472.6204427083333\n",
      "Train Epoch: 798 [0/54000 (0%)] Loss: -1474.250977\n",
      "Train Epoch: 798 [32768/54000 (61%)] Loss: -1473.636475\n",
      "    epoch          : 798\n",
      "    loss           : -1473.5244739460495\n",
      "    ess            : 3.76615206700451\n",
      "    log_marginal   : 1473.6475254274765\n",
      "    val_loss       : -1472.787577311198\n",
      "    val_ess        : 3.7696429093678794\n",
      "    val_log_marginal: 1472.907694498698\n",
      "Train Epoch: 799 [0/54000 (0%)] Loss: -1471.479980\n",
      "Train Epoch: 799 [32768/54000 (61%)] Loss: -1472.764893\n",
      "    epoch          : 799\n",
      "    loss           : -1473.641472582547\n",
      "    ess            : 3.767249305293245\n",
      "    log_marginal   : 1473.7611613723468\n",
      "    val_loss       : -1472.5250447591145\n",
      "    val_ess        : 3.7621681690216064\n",
      "    val_log_marginal: 1472.6509602864583\n",
      "Train Epoch: 800 [0/54000 (0%)] Loss: -1473.605957\n",
      "Train Epoch: 800 [32768/54000 (61%)] Loss: -1474.647705\n",
      "    epoch          : 800\n",
      "    loss           : -1473.8521567290684\n",
      "    ess            : 3.7643059469618887\n",
      "    log_marginal   : 1473.9749133991745\n",
      "    val_loss       : -1472.8016357421875\n",
      "    val_ess        : 3.7630284229914346\n",
      "    val_log_marginal: 1472.9201253255208\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch800.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 801 [0/54000 (0%)] Loss: -1475.067627\n",
      "Train Epoch: 801 [32768/54000 (61%)] Loss: -1473.144043\n",
      "    epoch          : 801\n",
      "    loss           : -1474.1403347951061\n",
      "    ess            : 3.7693405916106024\n",
      "    log_marginal   : 1474.2590355063385\n",
      "    val_loss       : -1473.257792154948\n",
      "    val_ess        : 3.766202727953593\n",
      "    val_log_marginal: 1473.382100423177\n",
      "Train Epoch: 802 [0/54000 (0%)] Loss: -1473.600586\n",
      "Train Epoch: 802 [32768/54000 (61%)] Loss: -1473.153564\n",
      "    epoch          : 802\n",
      "    loss           : -1474.2638998931309\n",
      "    ess            : 3.762334441238979\n",
      "    log_marginal   : 1474.38930065227\n",
      "    val_loss       : -1473.4596557617188\n",
      "    val_ess        : 3.775177995363871\n",
      "    val_log_marginal: 1473.5755818684895\n",
      "Train Epoch: 803 [0/54000 (0%)] Loss: -1472.252441\n",
      "Train Epoch: 803 [32768/54000 (61%)] Loss: -1471.679565\n",
      "    epoch          : 803\n",
      "    loss           : -1474.3291407171284\n",
      "    ess            : 3.7613902946688094\n",
      "    log_marginal   : 1474.454532263414\n",
      "    val_loss       : -1473.4226888020833\n",
      "    val_ess        : 3.7629501819610596\n",
      "    val_log_marginal: 1473.5469767252605\n",
      "Train Epoch: 804 [0/54000 (0%)] Loss: -1472.965332\n",
      "Train Epoch: 804 [32768/54000 (61%)] Loss: -1476.288330\n",
      "    epoch          : 804\n",
      "    loss           : -1474.5232117850826\n",
      "    ess            : 3.7629180089482723\n",
      "    log_marginal   : 1474.6466916642098\n",
      "    val_loss       : -1473.7549235026042\n",
      "    val_ess        : 3.7540623346964517\n",
      "    val_log_marginal: 1473.8945922851562\n",
      "Train Epoch: 805 [0/54000 (0%)] Loss: -1476.855103\n",
      "Train Epoch: 805 [32768/54000 (61%)] Loss: -1472.220825\n",
      "    epoch          : 805\n",
      "    loss           : -1474.762997033461\n",
      "    ess            : 3.765921394779997\n",
      "    log_marginal   : 1474.8847011350235\n",
      "    val_loss       : -1473.7041625976562\n",
      "    val_ess        : 3.7661646207173667\n",
      "    val_log_marginal: 1473.8283284505208\n",
      "Train Epoch: 806 [0/54000 (0%)] Loss: -1475.873779\n",
      "Train Epoch: 806 [32768/54000 (61%)] Loss: -1477.802368\n",
      "    epoch          : 806\n",
      "    loss           : -1474.97210117556\n",
      "    ess            : 3.7627632932842903\n",
      "    log_marginal   : 1475.0979119066922\n",
      "    val_loss       : -1473.8716837565105\n",
      "    val_ess        : 3.7646172046661377\n",
      "    val_log_marginal: 1473.9990234375\n",
      "Train Epoch: 807 [0/54000 (0%)] Loss: -1474.845337\n",
      "Train Epoch: 807 [32768/54000 (61%)] Loss: -1476.820557\n",
      "    epoch          : 807\n",
      "    loss           : -1475.0856012308373\n",
      "    ess            : 3.767743812417084\n",
      "    log_marginal   : 1475.208136792453\n",
      "    val_loss       : -1474.5065307617188\n",
      "    val_ess        : 3.783955693244934\n",
      "    val_log_marginal: 1474.630147298177\n",
      "Train Epoch: 808 [0/54000 (0%)] Loss: -1477.236328\n",
      "Train Epoch: 808 [32768/54000 (61%)] Loss: -1476.180420\n",
      "    epoch          : 808\n",
      "    loss           : -1475.294843565743\n",
      "    ess            : 3.765114280412782\n",
      "    log_marginal   : 1475.4187357200767\n",
      "    val_loss       : -1474.3646036783855\n",
      "    val_ess        : 3.7616934776306152\n",
      "    val_log_marginal: 1474.490254720052\n",
      "Train Epoch: 809 [0/54000 (0%)] Loss: -1477.043579\n",
      "Train Epoch: 809 [32768/54000 (61%)] Loss: -1478.175293\n",
      "    epoch          : 809\n",
      "    loss           : -1475.5756997162441\n",
      "    ess            : 3.765897813832985\n",
      "    log_marginal   : 1475.6974637013561\n",
      "    val_loss       : -1474.9255777994792\n",
      "    val_ess        : 3.7661560773849487\n",
      "    val_log_marginal: 1475.047383626302\n",
      "Train Epoch: 810 [0/54000 (0%)] Loss: -1474.633057\n",
      "Train Epoch: 810 [32768/54000 (61%)] Loss: -1472.448242\n",
      "    epoch          : 810\n",
      "    loss           : -1475.7348563716096\n",
      "    ess            : 3.7679282944157437\n",
      "    log_marginal   : 1475.8545428581958\n",
      "    val_loss       : -1474.875712076823\n",
      "    val_ess        : 3.766196608543396\n",
      "    val_log_marginal: 1475.0030721028645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch810.pth ...\n",
      "Train Epoch: 811 [0/54000 (0%)] Loss: -1475.718018\n",
      "Train Epoch: 811 [32768/54000 (61%)] Loss: -1472.889893\n",
      "    epoch          : 811\n",
      "    loss           : -1475.8663836785083\n",
      "    ess            : 3.766447814005726\n",
      "    log_marginal   : 1475.9846536888267\n",
      "    val_loss       : -1475.5208740234375\n",
      "    val_ess        : 3.7789870500564575\n",
      "    val_log_marginal: 1475.6387939453125\n",
      "Train Epoch: 812 [0/54000 (0%)] Loss: -1478.096558\n",
      "Train Epoch: 812 [32768/54000 (61%)] Loss: -1479.341309\n",
      "    epoch          : 812\n",
      "    loss           : -1476.125935104658\n",
      "    ess            : 3.761060597761622\n",
      "    log_marginal   : 1476.2505412551593\n",
      "    val_loss       : -1475.510518391927\n",
      "    val_ess        : 3.7653185526529946\n",
      "    val_log_marginal: 1475.6361490885417\n",
      "Train Epoch: 813 [0/54000 (0%)] Loss: -1478.304688\n",
      "Train Epoch: 813 [32768/54000 (61%)] Loss: -1474.661987\n",
      "    epoch          : 813\n",
      "    loss           : -1476.3544023621757\n",
      "    ess            : 3.767723267933108\n",
      "    log_marginal   : 1476.4747613870873\n",
      "    val_loss       : -1475.6339721679688\n",
      "    val_ess        : 3.765950838724772\n",
      "    val_log_marginal: 1475.7560424804688\n",
      "Train Epoch: 814 [0/54000 (0%)] Loss: -1476.923096\n",
      "Train Epoch: 814 [32768/54000 (61%)] Loss: -1475.771484\n",
      "    epoch          : 814\n",
      "    loss           : -1476.4050431161556\n",
      "    ess            : 3.768225242506783\n",
      "    log_marginal   : 1476.5285990013267\n",
      "    val_loss       : -1475.5631103515625\n",
      "    val_ess        : 3.7641038497289023\n",
      "    val_log_marginal: 1475.6810913085938\n",
      "Train Epoch: 815 [0/54000 (0%)] Loss: -1478.000488\n",
      "Train Epoch: 815 [32768/54000 (61%)] Loss: -1479.759277\n",
      "    epoch          : 815\n",
      "    loss           : -1476.4151887713738\n",
      "    ess            : 3.7648272874220363\n",
      "    log_marginal   : 1476.5391016546284\n",
      "    val_loss       : -1475.8934122721355\n",
      "    val_ess        : 3.782643715540568\n",
      "    val_log_marginal: 1476.0011800130208\n",
      "Train Epoch: 816 [0/54000 (0%)] Loss: -1478.047119\n",
      "Train Epoch: 816 [32768/54000 (61%)] Loss: -1475.457764\n",
      "    epoch          : 816\n",
      "    loss           : -1476.6171782871463\n",
      "    ess            : 3.7647057074420855\n",
      "    log_marginal   : 1476.737875884434\n",
      "    val_loss       : -1475.9768473307292\n",
      "    val_ess        : 3.7731940746307373\n",
      "    val_log_marginal: 1476.0894368489583\n",
      "Train Epoch: 817 [0/54000 (0%)] Loss: -1476.364258\n",
      "Train Epoch: 817 [32768/54000 (61%)] Loss: -1477.362427\n",
      "    epoch          : 817\n",
      "    loss           : -1476.7436339180424\n",
      "    ess            : 3.7690114435159936\n",
      "    log_marginal   : 1476.8645940816627\n",
      "    val_loss       : -1475.7689615885417\n",
      "    val_ess        : 3.7502710819244385\n",
      "    val_log_marginal: 1475.909932454427\n",
      "Train Epoch: 818 [0/54000 (0%)] Loss: -1476.799316\n",
      "Train Epoch: 818 [32768/54000 (61%)] Loss: -1475.386963\n",
      "    epoch          : 818\n",
      "    loss           : -1477.0256278559846\n",
      "    ess            : 3.7694368767288498\n",
      "    log_marginal   : 1477.1443216575767\n",
      "    val_loss       : -1476.45458984375\n",
      "    val_ess        : 3.766916791598002\n",
      "    val_log_marginal: 1476.5718790690105\n",
      "Train Epoch: 819 [0/54000 (0%)] Loss: -1480.543823\n",
      "Train Epoch: 819 [32768/54000 (61%)] Loss: -1479.664795\n",
      "    epoch          : 819\n",
      "    loss           : -1477.4142306345814\n",
      "    ess            : 3.768279898841426\n",
      "    log_marginal   : 1477.5374801923645\n",
      "    val_loss       : -1476.210713704427\n",
      "    val_ess        : 3.764858603477478\n",
      "    val_log_marginal: 1476.330586751302\n",
      "Train Epoch: 820 [0/54000 (0%)] Loss: -1477.233887\n",
      "Train Epoch: 820 [32768/54000 (61%)] Loss: -1477.565796\n",
      "    epoch          : 820\n",
      "    loss           : -1477.4106468344635\n",
      "    ess            : 3.765277138296163\n",
      "    log_marginal   : 1477.5338503279777\n",
      "    val_loss       : -1476.6238199869792\n",
      "    val_ess        : 3.769576986630758\n",
      "    val_log_marginal: 1476.7495524088542\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch820.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 821 [0/54000 (0%)] Loss: -1477.728882\n",
      "Train Epoch: 821 [32768/54000 (61%)] Loss: -1477.972168\n",
      "    epoch          : 821\n",
      "    loss           : -1477.6656378979953\n",
      "    ess            : 3.770560673947604\n",
      "    log_marginal   : 1477.7830280807782\n",
      "    val_loss       : -1476.5384724934895\n",
      "    val_ess        : 3.7509986559549966\n",
      "    val_log_marginal: 1476.671854654948\n",
      "Train Epoch: 822 [0/54000 (0%)] Loss: -1478.670898\n",
      "Train Epoch: 822 [32768/54000 (61%)] Loss: -1476.148560\n",
      "    epoch          : 822\n",
      "    loss           : -1477.8396802218456\n",
      "    ess            : 3.7650575232955643\n",
      "    log_marginal   : 1477.9633397516216\n",
      "    val_loss       : -1476.6001383463542\n",
      "    val_ess        : 3.7550730307896933\n",
      "    val_log_marginal: 1476.7322591145833\n",
      "Train Epoch: 823 [0/54000 (0%)] Loss: -1476.710083\n",
      "Train Epoch: 823 [32768/54000 (61%)] Loss: -1474.795166\n",
      "    epoch          : 823\n",
      "    loss           : -1478.0654458099941\n",
      "    ess            : 3.7673948036049896\n",
      "    log_marginal   : 1478.1853511018573\n",
      "    val_loss       : -1477.2472534179688\n",
      "    val_ess        : 3.767304460207621\n",
      "    val_log_marginal: 1477.3721720377605\n",
      "Train Epoch: 824 [0/54000 (0%)] Loss: -1479.640625\n",
      "Train Epoch: 824 [32768/54000 (61%)] Loss: -1477.753174\n",
      "    epoch          : 824\n",
      "    loss           : -1478.2618984006485\n",
      "    ess            : 3.766370309973663\n",
      "    log_marginal   : 1478.385825103184\n",
      "    val_loss       : -1477.2984415690105\n",
      "    val_ess        : 3.788988471031189\n",
      "    val_log_marginal: 1477.3997599283855\n",
      "Train Epoch: 825 [0/54000 (0%)] Loss: -1478.174805\n",
      "Train Epoch: 825 [32768/54000 (61%)] Loss: -1478.075195\n",
      "    epoch          : 825\n",
      "    loss           : -1478.4154213959316\n",
      "    ess            : 3.770057516277961\n",
      "    log_marginal   : 1478.53362461306\n",
      "    val_loss       : -1477.5382080078125\n",
      "    val_ess        : 3.7692571878433228\n",
      "    val_log_marginal: 1477.656494140625\n",
      "Train Epoch: 826 [0/54000 (0%)] Loss: -1475.525635\n",
      "Train Epoch: 826 [32768/54000 (61%)] Loss: -1481.769409\n",
      "    epoch          : 826\n",
      "    loss           : -1478.5252846771816\n",
      "    ess            : 3.7688717752132774\n",
      "    log_marginal   : 1478.6471430940448\n",
      "    val_loss       : -1477.8213704427083\n",
      "    val_ess        : 3.7822234630584717\n",
      "    val_log_marginal: 1477.9266967773438\n",
      "Train Epoch: 827 [0/54000 (0%)] Loss: -1480.652588\n",
      "Train Epoch: 827 [32768/54000 (61%)] Loss: -1477.258545\n",
      "    epoch          : 827\n",
      "    loss           : -1478.7377399948407\n",
      "    ess            : 3.76417956712111\n",
      "    log_marginal   : 1478.8635184809846\n",
      "    val_loss       : -1477.890625\n",
      "    val_ess        : 3.7702582279841104\n",
      "    val_log_marginal: 1478.0157877604167\n",
      "Train Epoch: 828 [0/54000 (0%)] Loss: -1478.921875\n",
      "Train Epoch: 828 [32768/54000 (61%)] Loss: -1479.548218\n",
      "    epoch          : 828\n",
      "    loss           : -1479.0040859006485\n",
      "    ess            : 3.769533890598225\n",
      "    log_marginal   : 1479.1288670953716\n",
      "    val_loss       : -1477.9241943359375\n",
      "    val_ess        : 3.751466075579325\n",
      "    val_log_marginal: 1478.0588989257812\n",
      "Train Epoch: 829 [0/54000 (0%)] Loss: -1481.743652\n",
      "Train Epoch: 829 [32768/54000 (61%)] Loss: -1476.624878\n",
      "    epoch          : 829\n",
      "    loss           : -1479.0892794627064\n",
      "    ess            : 3.769352485548775\n",
      "    log_marginal   : 1479.2103939416274\n",
      "    val_loss       : -1478.1075032552083\n",
      "    val_ess        : 3.758424758911133\n",
      "    val_log_marginal: 1478.2305501302083\n",
      "Train Epoch: 830 [0/54000 (0%)] Loss: -1479.713135\n",
      "Train Epoch: 830 [32768/54000 (61%)] Loss: -1479.243896\n",
      "    epoch          : 830\n",
      "    loss           : -1479.3474765993515\n",
      "    ess            : 3.769243316830329\n",
      "    log_marginal   : 1479.4675776643573\n",
      "    val_loss       : -1478.2520955403645\n",
      "    val_ess        : 3.76064670085907\n",
      "    val_log_marginal: 1478.3683064778645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch830.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 831 [0/54000 (0%)] Loss: -1478.854370\n",
      "Train Epoch: 831 [32768/54000 (61%)] Loss: -1481.009766\n",
      "    epoch          : 831\n",
      "    loss           : -1479.562276588296\n",
      "    ess            : 3.766858069401867\n",
      "    log_marginal   : 1479.682990308078\n",
      "    val_loss       : -1478.5302124023438\n",
      "    val_ess        : 3.7523380517959595\n",
      "    val_log_marginal: 1478.6606852213542\n",
      "Train Epoch: 832 [0/54000 (0%)] Loss: -1479.418945\n",
      "Train Epoch: 832 [32768/54000 (61%)] Loss: -1480.239014\n",
      "    epoch          : 832\n",
      "    loss           : -1479.7928812278892\n",
      "    ess            : 3.768363318353329\n",
      "    log_marginal   : 1479.9125078309257\n",
      "    val_loss       : -1478.6223754882812\n",
      "    val_ess        : 3.7584798336029053\n",
      "    val_log_marginal: 1478.752461751302\n",
      "Train Epoch: 833 [0/54000 (0%)] Loss: -1482.182983\n",
      "Train Epoch: 833 [32768/54000 (61%)] Loss: -1481.534302\n",
      "    epoch          : 833\n",
      "    loss           : -1479.9454345703125\n",
      "    ess            : 3.765452020573166\n",
      "    log_marginal   : 1480.0694303692512\n",
      "    val_loss       : -1479.38232421875\n",
      "    val_ess        : 3.7624072631200156\n",
      "    val_log_marginal: 1479.5116373697917\n",
      "Train Epoch: 834 [0/54000 (0%)] Loss: -1481.477295\n",
      "Train Epoch: 834 [32768/54000 (61%)] Loss: -1480.487671\n",
      "    epoch          : 834\n",
      "    loss           : -1479.983419166421\n",
      "    ess            : 3.7624666870764965\n",
      "    log_marginal   : 1480.1094049417748\n",
      "    val_loss       : -1479.0784505208333\n",
      "    val_ess        : 3.7716262340545654\n",
      "    val_log_marginal: 1479.202392578125\n",
      "Train Epoch: 835 [0/54000 (0%)] Loss: -1478.621460\n",
      "Train Epoch: 835 [32768/54000 (61%)] Loss: -1477.150391\n",
      "    epoch          : 835\n",
      "    loss           : -1480.2926923643868\n",
      "    ess            : 3.7689040876784414\n",
      "    log_marginal   : 1480.414083228921\n",
      "    val_loss       : -1479.4440511067708\n",
      "    val_ess        : 3.774263858795166\n",
      "    val_log_marginal: 1479.5629069010417\n",
      "Train Epoch: 836 [0/54000 (0%)] Loss: -1485.283569\n",
      "Train Epoch: 836 [32768/54000 (61%)] Loss: -1480.123047\n",
      "    epoch          : 836\n",
      "    loss           : -1480.391134010171\n",
      "    ess            : 3.7675211654519134\n",
      "    log_marginal   : 1480.5131559551887\n",
      "    val_loss       : -1479.7288818359375\n",
      "    val_ess        : 3.760952631632487\n",
      "    val_log_marginal: 1479.860087076823\n",
      "Train Epoch: 837 [0/54000 (0%)] Loss: -1482.166016\n",
      "Train Epoch: 837 [32768/54000 (61%)] Loss: -1478.022095\n",
      "    epoch          : 837\n",
      "    loss           : -1480.6380523105838\n",
      "    ess            : 3.7660525294969665\n",
      "    log_marginal   : 1480.7586094118515\n",
      "    val_loss       : -1479.611104329427\n",
      "    val_ess        : 3.7676179011662803\n",
      "    val_log_marginal: 1479.7320556640625\n",
      "Train Epoch: 838 [0/54000 (0%)] Loss: -1480.001831\n",
      "Train Epoch: 838 [32768/54000 (61%)] Loss: -1482.633057\n",
      "    epoch          : 838\n",
      "    loss           : -1480.8373654923348\n",
      "    ess            : 3.7715308531275333\n",
      "    log_marginal   : 1480.9577936136498\n",
      "    val_loss       : -1479.8541259765625\n",
      "    val_ess        : 3.7673577070236206\n",
      "    val_log_marginal: 1479.978251139323\n",
      "Train Epoch: 839 [0/54000 (0%)] Loss: -1482.028687\n",
      "Train Epoch: 839 [32768/54000 (61%)] Loss: -1480.006104\n",
      "    epoch          : 839\n",
      "    loss           : -1481.1474494214328\n",
      "    ess            : 3.769567309685473\n",
      "    log_marginal   : 1481.2677347435142\n",
      "    val_loss       : -1480.507303873698\n",
      "    val_ess        : 3.784410278002421\n",
      "    val_log_marginal: 1480.616190592448\n",
      "Train Epoch: 840 [0/54000 (0%)] Loss: -1481.144287\n",
      "Train Epoch: 840 [32768/54000 (61%)] Loss: -1481.623169\n",
      "    epoch          : 840\n",
      "    loss           : -1481.197514372052\n",
      "    ess            : 3.766495124349054\n",
      "    log_marginal   : 1481.3189006301593\n",
      "    val_loss       : -1480.801493326823\n",
      "    val_ess        : 3.769713560740153\n",
      "    val_log_marginal: 1480.9261067708333\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch840.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 841 [0/54000 (0%)] Loss: -1480.654297\n",
      "Train Epoch: 841 [32768/54000 (61%)] Loss: -1478.812744\n",
      "    epoch          : 841\n",
      "    loss           : -1481.4240215949292\n",
      "    ess            : 3.7700989111414493\n",
      "    log_marginal   : 1481.5426232679836\n",
      "    val_loss       : -1480.8179321289062\n",
      "    val_ess        : 3.7711781660715737\n",
      "    val_log_marginal: 1480.9353637695312\n",
      "Train Epoch: 842 [0/54000 (0%)] Loss: -1483.414185\n",
      "Train Epoch: 842 [32768/54000 (61%)] Loss: -1482.347168\n",
      "    epoch          : 842\n",
      "    loss           : -1481.579407889888\n",
      "    ess            : 3.7655707215363123\n",
      "    log_marginal   : 1481.7043940706073\n",
      "    val_loss       : -1480.7350260416667\n",
      "    val_ess        : 3.768212596575419\n",
      "    val_log_marginal: 1480.8510131835938\n",
      "Train Epoch: 843 [0/54000 (0%)] Loss: -1484.506348\n",
      "Train Epoch: 843 [32768/54000 (61%)] Loss: -1480.812622\n",
      "    epoch          : 843\n",
      "    loss           : -1481.8175509470814\n",
      "    ess            : 3.770914037272615\n",
      "    log_marginal   : 1481.9402039725826\n",
      "    val_loss       : -1481.2239176432292\n",
      "    val_ess        : 3.7733624378840127\n",
      "    val_log_marginal: 1481.3460489908855\n",
      "Train Epoch: 844 [0/54000 (0%)] Loss: -1483.696167\n",
      "Train Epoch: 844 [32768/54000 (61%)] Loss: -1483.758057\n",
      "    epoch          : 844\n",
      "    loss           : -1482.009380988355\n",
      "    ess            : 3.7725698453075482\n",
      "    log_marginal   : 1482.1298505675118\n",
      "    val_loss       : -1481.3678792317708\n",
      "    val_ess        : 3.7738589445749917\n",
      "    val_log_marginal: 1481.483642578125\n",
      "Train Epoch: 845 [0/54000 (0%)] Loss: -1482.125610\n",
      "Train Epoch: 845 [32768/54000 (61%)] Loss: -1479.847290\n",
      "    epoch          : 845\n",
      "    loss           : -1482.037109375\n",
      "    ess            : 3.7702340090049886\n",
      "    log_marginal   : 1482.1544696160083\n",
      "    val_loss       : -1481.1017252604167\n",
      "    val_ess        : 3.7619422674179077\n",
      "    val_log_marginal: 1481.2237141927083\n",
      "Train Epoch: 846 [0/54000 (0%)] Loss: -1483.164551\n",
      "Train Epoch: 846 [32768/54000 (61%)] Loss: -1482.276123\n",
      "    epoch          : 846\n",
      "    loss           : -1482.2568082989387\n",
      "    ess            : 3.7677505196265453\n",
      "    log_marginal   : 1482.37750819944\n",
      "    val_loss       : -1481.61572265625\n",
      "    val_ess        : 3.771698991457621\n",
      "    val_log_marginal: 1481.7311401367188\n",
      "Train Epoch: 847 [0/54000 (0%)] Loss: -1481.968994\n",
      "Train Epoch: 847 [32768/54000 (61%)] Loss: -1477.506104\n",
      "    epoch          : 847\n",
      "    loss           : -1482.4450430240272\n",
      "    ess            : 3.7660251968311815\n",
      "    log_marginal   : 1482.5693175117924\n",
      "    val_loss       : -1481.5474650065105\n",
      "    val_ess        : 3.7838988304138184\n",
      "    val_log_marginal: 1481.6552734375\n",
      "Train Epoch: 848 [0/54000 (0%)] Loss: -1486.616821\n",
      "Train Epoch: 848 [32768/54000 (61%)] Loss: -1481.742432\n",
      "    epoch          : 848\n",
      "    loss           : -1482.6045843160377\n",
      "    ess            : 3.7631564095335186\n",
      "    log_marginal   : 1482.7281586269162\n",
      "    val_loss       : -1482.152079264323\n",
      "    val_ess        : 3.7748363415400186\n",
      "    val_log_marginal: 1482.272969563802\n",
      "Train Epoch: 849 [0/54000 (0%)] Loss: -1487.199951\n",
      "Train Epoch: 849 [32768/54000 (61%)] Loss: -1482.221191\n",
      "    epoch          : 849\n",
      "    loss           : -1482.5105832657723\n",
      "    ess            : 3.7680406435480656\n",
      "    log_marginal   : 1482.629924270342\n",
      "    val_loss       : -1481.773193359375\n",
      "    val_ess        : 3.7708561420440674\n",
      "    val_log_marginal: 1481.8900553385417\n",
      "Train Epoch: 850 [0/54000 (0%)] Loss: -1486.161499\n",
      "Train Epoch: 850 [32768/54000 (61%)] Loss: -1484.366577\n",
      "    epoch          : 850\n",
      "    loss           : -1482.8297372494103\n",
      "    ess            : 3.76956596464481\n",
      "    log_marginal   : 1482.9487857458726\n",
      "    val_loss       : -1482.046895345052\n",
      "    val_ess        : 3.7783204714457193\n",
      "    val_log_marginal: 1482.161641438802\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [0/54000 (0%)] Loss: -1478.945068\n",
      "Train Epoch: 851 [32768/54000 (61%)] Loss: -1483.255127\n",
      "    epoch          : 851\n",
      "    loss           : -1482.9787574624115\n",
      "    ess            : 3.768587184402178\n",
      "    log_marginal   : 1483.0995610075177\n",
      "    val_loss       : -1482.0406087239583\n",
      "    val_ess        : 3.7654110193252563\n",
      "    val_log_marginal: 1482.1666463216145\n",
      "Train Epoch: 852 [0/54000 (0%)] Loss: -1483.817627\n",
      "Train Epoch: 852 [32768/54000 (61%)] Loss: -1482.552246\n",
      "    epoch          : 852\n",
      "    loss           : -1483.1262183999115\n",
      "    ess            : 3.771867369705776\n",
      "    log_marginal   : 1483.2429590765034\n",
      "    val_loss       : -1482.267110188802\n",
      "    val_ess        : 3.766573985417684\n",
      "    val_log_marginal: 1482.391581217448\n",
      "Train Epoch: 853 [0/54000 (0%)] Loss: -1483.530273\n",
      "Train Epoch: 853 [32768/54000 (61%)] Loss: -1485.304077\n",
      "    epoch          : 853\n",
      "    loss           : -1483.3436371425412\n",
      "    ess            : 3.7694199445112697\n",
      "    log_marginal   : 1483.4663431419517\n",
      "    val_loss       : -1482.723388671875\n",
      "    val_ess        : 3.7779535055160522\n",
      "    val_log_marginal: 1482.8361206054688\n",
      "Train Epoch: 854 [0/54000 (0%)] Loss: -1484.733887\n",
      "Train Epoch: 854 [32768/54000 (61%)] Loss: -1485.625366\n",
      "    epoch          : 854\n",
      "    loss           : -1483.5584601636203\n",
      "    ess            : 3.7711752675614267\n",
      "    log_marginal   : 1483.6808345002948\n",
      "    val_loss       : -1482.84912109375\n",
      "    val_ess        : 3.758071859677633\n",
      "    val_log_marginal: 1482.9752604166667\n",
      "Train Epoch: 855 [0/54000 (0%)] Loss: -1484.606323\n",
      "Train Epoch: 855 [32768/54000 (61%)] Loss: -1482.938721\n",
      "    epoch          : 855\n",
      "    loss           : -1483.6429328198703\n",
      "    ess            : 3.7621158923742906\n",
      "    log_marginal   : 1483.7703074329304\n",
      "    val_loss       : -1482.9750569661458\n",
      "    val_ess        : 3.774174372355143\n",
      "    val_log_marginal: 1483.090840657552\n",
      "Train Epoch: 856 [0/54000 (0%)] Loss: -1485.605957\n",
      "Train Epoch: 856 [32768/54000 (61%)] Loss: -1485.220825\n",
      "    epoch          : 856\n",
      "    loss           : -1483.9705442032723\n",
      "    ess            : 3.7702731231473527\n",
      "    log_marginal   : 1484.0924026201355\n",
      "    val_loss       : -1483.2609049479167\n",
      "    val_ess        : 3.768893559773763\n",
      "    val_log_marginal: 1483.387227376302\n",
      "Train Epoch: 857 [0/54000 (0%)] Loss: -1484.132446\n",
      "Train Epoch: 857 [32768/54000 (61%)] Loss: -1486.164551\n",
      "    epoch          : 857\n",
      "    loss           : -1484.0268370430424\n",
      "    ess            : 3.7731271374900386\n",
      "    log_marginal   : 1484.1449734669811\n",
      "    val_loss       : -1483.4849446614583\n",
      "    val_ess        : 3.77489443620046\n",
      "    val_log_marginal: 1483.6036173502605\n",
      "Train Epoch: 858 [0/54000 (0%)] Loss: -1483.795898\n",
      "Train Epoch: 858 [32768/54000 (61%)] Loss: -1482.414917\n",
      "    epoch          : 858\n",
      "    loss           : -1484.1312209795105\n",
      "    ess            : 3.769122695023159\n",
      "    log_marginal   : 1484.2523769162735\n",
      "    val_loss       : -1483.72705078125\n",
      "    val_ess        : 3.765888770421346\n",
      "    val_log_marginal: 1483.8446044921875\n",
      "Train Epoch: 859 [0/54000 (0%)] Loss: -1486.056885\n",
      "Train Epoch: 859 [32768/54000 (61%)] Loss: -1486.726562\n",
      "    epoch          : 859\n",
      "    loss           : -1484.4575425633843\n",
      "    ess            : 3.7688011268399797\n",
      "    log_marginal   : 1484.5773833652713\n",
      "    val_loss       : -1483.646219889323\n",
      "    val_ess        : 3.763401468594869\n",
      "    val_log_marginal: 1483.7694498697917\n",
      "Train Epoch: 860 [0/54000 (0%)] Loss: -1484.195801\n",
      "Train Epoch: 860 [32768/54000 (61%)] Loss: -1484.703613\n",
      "    epoch          : 860\n",
      "    loss           : -1484.488654370578\n",
      "    ess            : 3.7740779867712058\n",
      "    log_marginal   : 1484.6055148142689\n",
      "    val_loss       : -1483.4971110026042\n",
      "    val_ess        : 3.774462421735128\n",
      "    val_log_marginal: 1483.6172485351562\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch860.pth ...\n",
      "Train Epoch: 861 [0/54000 (0%)] Loss: -1487.555786\n",
      "Train Epoch: 861 [32768/54000 (61%)] Loss: -1481.614380\n",
      "    epoch          : 861\n",
      "    loss           : -1484.6017006928066\n",
      "    ess            : 3.7660000504187816\n",
      "    log_marginal   : 1484.7273501989976\n",
      "    val_loss       : -1483.8489379882812\n",
      "    val_ess        : 3.7552418311436973\n",
      "    val_log_marginal: 1483.976053873698\n",
      "Train Epoch: 862 [0/54000 (0%)] Loss: -1484.505493\n",
      "Train Epoch: 862 [32768/54000 (61%)] Loss: -1483.490479\n",
      "    epoch          : 862\n",
      "    loss           : -1484.8575209131782\n",
      "    ess            : 3.7675787772772447\n",
      "    log_marginal   : 1484.9767214217277\n",
      "    val_loss       : -1483.915791829427\n",
      "    val_ess        : 3.7659615675608316\n",
      "    val_log_marginal: 1484.0389404296875\n",
      "Train Epoch: 863 [0/54000 (0%)] Loss: -1489.869873\n",
      "Train Epoch: 863 [32768/54000 (61%)] Loss: -1484.735107\n",
      "    epoch          : 863\n",
      "    loss           : -1484.8823933151532\n",
      "    ess            : 3.770878054061026\n",
      "    log_marginal   : 1485.0027546432782\n",
      "    val_loss       : -1484.0228068033855\n",
      "    val_ess        : 3.7690007289250693\n",
      "    val_log_marginal: 1484.1343383789062\n",
      "Train Epoch: 864 [0/54000 (0%)] Loss: -1487.634155\n",
      "Train Epoch: 864 [32768/54000 (61%)] Loss: -1485.312256\n",
      "    epoch          : 864\n",
      "    loss           : -1484.996176665684\n",
      "    ess            : 3.766471858294505\n",
      "    log_marginal   : 1485.1186776790978\n",
      "    val_loss       : -1484.409423828125\n",
      "    val_ess        : 3.782137155532837\n",
      "    val_log_marginal: 1484.5289713541667\n",
      "Train Epoch: 865 [0/54000 (0%)] Loss: -1488.099365\n",
      "Train Epoch: 865 [32768/54000 (61%)] Loss: -1487.439453\n",
      "    epoch          : 865\n",
      "    loss           : -1485.0585223503833\n",
      "    ess            : 3.7650942892398476\n",
      "    log_marginal   : 1485.1855192364387\n",
      "    val_loss       : -1484.2089436848958\n",
      "    val_ess        : 3.7857394218444824\n",
      "    val_log_marginal: 1484.322041829427\n",
      "Train Epoch: 866 [0/54000 (0%)] Loss: -1487.578491\n",
      "Train Epoch: 866 [32768/54000 (61%)] Loss: -1483.911377\n",
      "    epoch          : 866\n",
      "    loss           : -1485.2944704451652\n",
      "    ess            : 3.7671741269669443\n",
      "    log_marginal   : 1485.4188577903892\n",
      "    val_loss       : -1484.4661458333333\n",
      "    val_ess        : 3.768268267313639\n",
      "    val_log_marginal: 1484.5940551757812\n",
      "Train Epoch: 867 [0/54000 (0%)] Loss: -1486.066406\n",
      "Train Epoch: 867 [32768/54000 (61%)] Loss: -1486.481689\n",
      "    epoch          : 867\n",
      "    loss           : -1485.5981145894752\n",
      "    ess            : 3.766911691089846\n",
      "    log_marginal   : 1485.7188421285377\n",
      "    val_loss       : -1484.6878458658855\n",
      "    val_ess        : 3.7630168199539185\n",
      "    val_log_marginal: 1484.8117268880208\n",
      "Train Epoch: 868 [0/54000 (0%)] Loss: -1488.293701\n",
      "Train Epoch: 868 [32768/54000 (61%)] Loss: -1485.402588\n",
      "    epoch          : 868\n",
      "    loss           : -1485.7188927992336\n",
      "    ess            : 3.768950007996469\n",
      "    log_marginal   : 1485.8403688826652\n",
      "    val_loss       : -1484.82275390625\n",
      "    val_ess        : 3.769791007041931\n",
      "    val_log_marginal: 1484.9459635416667\n",
      "Train Epoch: 869 [0/54000 (0%)] Loss: -1484.096680\n",
      "Train Epoch: 869 [32768/54000 (61%)] Loss: -1487.583252\n",
      "    epoch          : 869\n",
      "    loss           : -1485.9562596734966\n",
      "    ess            : 3.770433524869523\n",
      "    log_marginal   : 1486.0738110812206\n",
      "    val_loss       : -1484.8167724609375\n",
      "    val_ess        : 3.750394264856974\n",
      "    val_log_marginal: 1484.9561157226562\n",
      "Train Epoch: 870 [0/54000 (0%)] Loss: -1487.326416\n",
      "Train Epoch: 870 [32768/54000 (61%)] Loss: -1488.583618\n",
      "    epoch          : 870\n",
      "    loss           : -1486.221394089033\n",
      "    ess            : 3.77052552295181\n",
      "    log_marginal   : 1486.342414136203\n",
      "    val_loss       : -1485.0555826822917\n",
      "    val_ess        : 3.75245467821757\n",
      "    val_log_marginal: 1485.190205891927\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch870.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 871 [0/54000 (0%)] Loss: -1485.620117\n",
      "Train Epoch: 871 [32768/54000 (61%)] Loss: -1486.788330\n",
      "    epoch          : 871\n",
      "    loss           : -1486.3609480947819\n",
      "    ess            : 3.764347490274681\n",
      "    log_marginal   : 1486.487201042895\n",
      "    val_loss       : -1484.9603271484375\n",
      "    val_ess        : 3.7539897362391152\n",
      "    val_log_marginal: 1485.0888264973958\n",
      "Train Epoch: 872 [0/54000 (0%)] Loss: -1487.447754\n",
      "Train Epoch: 872 [32768/54000 (61%)] Loss: -1485.961914\n",
      "    epoch          : 872\n",
      "    loss           : -1486.4474660045696\n",
      "    ess            : 3.7665020564817033\n",
      "    log_marginal   : 1486.5709850383255\n",
      "    val_loss       : -1485.2551879882812\n",
      "    val_ess        : 3.775115172068278\n",
      "    val_log_marginal: 1485.378153483073\n",
      "Train Epoch: 873 [0/54000 (0%)] Loss: -1484.786255\n",
      "Train Epoch: 873 [32768/54000 (61%)] Loss: -1485.122070\n",
      "    epoch          : 873\n",
      "    loss           : -1486.5942290683963\n",
      "    ess            : 3.7698275233214757\n",
      "    log_marginal   : 1486.7177250700177\n",
      "    val_loss       : -1485.6948852539062\n",
      "    val_ess        : 3.774926463762919\n",
      "    val_log_marginal: 1485.818603515625\n",
      "Train Epoch: 874 [0/54000 (0%)] Loss: -1485.746704\n",
      "Train Epoch: 874 [32768/54000 (61%)] Loss: -1487.551025\n",
      "    epoch          : 874\n",
      "    loss           : -1486.8824186505012\n",
      "    ess            : 3.770147737467064\n",
      "    log_marginal   : 1487.002383825914\n",
      "    val_loss       : -1485.8578491210938\n",
      "    val_ess        : 3.7722872495651245\n",
      "    val_log_marginal: 1485.9808349609375\n",
      "Train Epoch: 875 [0/54000 (0%)] Loss: -1492.028809\n",
      "Train Epoch: 875 [32768/54000 (61%)] Loss: -1490.025635\n",
      "    epoch          : 875\n",
      "    loss           : -1487.1524036335495\n",
      "    ess            : 3.771283658045643\n",
      "    log_marginal   : 1487.27378528523\n",
      "    val_loss       : -1486.1749877929688\n",
      "    val_ess        : 3.7817587852478027\n",
      "    val_log_marginal: 1486.2874755859375\n",
      "Train Epoch: 876 [0/54000 (0%)] Loss: -1488.809814\n",
      "Train Epoch: 876 [32768/54000 (61%)] Loss: -1488.602295\n",
      "    epoch          : 876\n",
      "    loss           : -1487.2209726009728\n",
      "    ess            : 3.769275723763232\n",
      "    log_marginal   : 1487.342893204599\n",
      "    val_loss       : -1486.0357666015625\n",
      "    val_ess        : 3.7649110555648804\n",
      "    val_log_marginal: 1486.1620279947917\n",
      "Train Epoch: 877 [0/54000 (0%)] Loss: -1489.658447\n",
      "Train Epoch: 877 [32768/54000 (61%)] Loss: -1486.656250\n",
      "    epoch          : 877\n",
      "    loss           : -1487.329143020342\n",
      "    ess            : 3.76051005777323\n",
      "    log_marginal   : 1487.4564784787735\n",
      "    val_loss       : -1485.7660115559895\n",
      "    val_ess        : 3.758845329284668\n",
      "    val_log_marginal: 1485.8944905598958\n",
      "Train Epoch: 878 [0/54000 (0%)] Loss: -1492.571289\n",
      "Train Epoch: 878 [32768/54000 (61%)] Loss: -1486.747314\n",
      "    epoch          : 878\n",
      "    loss           : -1487.5000967349647\n",
      "    ess            : 3.7696512645145632\n",
      "    log_marginal   : 1487.619608177329\n",
      "    val_loss       : -1486.7198486328125\n",
      "    val_ess        : 3.7713181575139365\n",
      "    val_log_marginal: 1486.839335123698\n",
      "Train Epoch: 879 [0/54000 (0%)] Loss: -1489.460449\n",
      "Train Epoch: 879 [32768/54000 (61%)] Loss: -1490.267090\n",
      "    epoch          : 879\n",
      "    loss           : -1487.7372977778596\n",
      "    ess            : 3.7728324296339504\n",
      "    log_marginal   : 1487.860148879717\n",
      "    val_loss       : -1486.7064005533855\n",
      "    val_ess        : 3.7807583014170327\n",
      "    val_log_marginal: 1486.820556640625\n",
      "Train Epoch: 880 [0/54000 (0%)] Loss: -1492.139404\n",
      "Train Epoch: 880 [32768/54000 (61%)] Loss: -1485.612671\n",
      "    epoch          : 880\n",
      "    loss           : -1487.7109720482017\n",
      "    ess            : 3.7692867809871458\n",
      "    log_marginal   : 1487.831729529039\n",
      "    val_loss       : -1486.546895345052\n",
      "    val_ess        : 3.768001079559326\n",
      "    val_log_marginal: 1486.6617838541667\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch880.pth ...\n",
      "Train Epoch: 881 [0/54000 (0%)] Loss: -1485.064697\n",
      "Train Epoch: 881 [32768/54000 (61%)] Loss: -1487.110596\n",
      "    epoch          : 881\n",
      "    loss           : -1487.7826549602005\n",
      "    ess            : 3.769957807828795\n",
      "    log_marginal   : 1487.906899506191\n",
      "    val_loss       : -1486.594706217448\n",
      "    val_ess        : 3.759069283803304\n",
      "    val_log_marginal: 1486.7283935546875\n",
      "Train Epoch: 882 [0/54000 (0%)] Loss: -1489.523682\n",
      "Train Epoch: 882 [32768/54000 (61%)] Loss: -1490.733887\n",
      "    epoch          : 882\n",
      "    loss           : -1487.9607209979363\n",
      "    ess            : 3.7748152354978166\n",
      "    log_marginal   : 1488.0780927550118\n",
      "    val_loss       : -1487.170145670573\n",
      "    val_ess        : 3.769134998321533\n",
      "    val_log_marginal: 1487.2952067057292\n",
      "Train Epoch: 883 [0/54000 (0%)] Loss: -1488.774048\n",
      "Train Epoch: 883 [32768/54000 (61%)] Loss: -1489.564087\n",
      "    epoch          : 883\n",
      "    loss           : -1488.0792973356427\n",
      "    ess            : 3.7693460437486754\n",
      "    log_marginal   : 1488.2032125221108\n",
      "    val_loss       : -1487.0213216145833\n",
      "    val_ess        : 3.7647685607274375\n",
      "    val_log_marginal: 1487.1451009114583\n",
      "Train Epoch: 884 [0/54000 (0%)] Loss: -1486.050537\n",
      "Train Epoch: 884 [32768/54000 (61%)] Loss: -1489.162598\n",
      "    epoch          : 884\n",
      "    loss           : -1488.3186288509728\n",
      "    ess            : 3.7666520082725667\n",
      "    log_marginal   : 1488.442205465065\n",
      "    val_loss       : -1486.9920247395833\n",
      "    val_ess        : 3.771119157473246\n",
      "    val_log_marginal: 1487.1112060546875\n",
      "Train Epoch: 885 [0/54000 (0%)] Loss: -1490.061279\n",
      "Train Epoch: 885 [32768/54000 (61%)] Loss: -1489.846924\n",
      "    epoch          : 885\n",
      "    loss           : -1488.4805240271226\n",
      "    ess            : 3.768613392452024\n",
      "    log_marginal   : 1488.60595703125\n",
      "    val_loss       : -1487.5230305989583\n",
      "    val_ess        : 3.773390531539917\n",
      "    val_log_marginal: 1487.6422729492188\n",
      "Train Epoch: 886 [0/54000 (0%)] Loss: -1488.730469\n",
      "Train Epoch: 886 [32768/54000 (61%)] Loss: -1485.898560\n",
      "    epoch          : 886\n",
      "    loss           : -1488.6356546653892\n",
      "    ess            : 3.7655747116736644\n",
      "    log_marginal   : 1488.7585126768868\n",
      "    val_loss       : -1487.4149983723958\n",
      "    val_ess        : 3.763919711112976\n",
      "    val_log_marginal: 1487.5424397786458\n",
      "Train Epoch: 887 [0/54000 (0%)] Loss: -1492.391602\n",
      "Train Epoch: 887 [32768/54000 (61%)] Loss: -1488.867065\n",
      "    epoch          : 887\n",
      "    loss           : -1488.8220030586674\n",
      "    ess            : 3.7682592823820293\n",
      "    log_marginal   : 1488.9443912146226\n",
      "    val_loss       : -1487.6094767252605\n",
      "    val_ess        : 3.767897605895996\n",
      "    val_log_marginal: 1487.7344360351562\n",
      "Train Epoch: 888 [0/54000 (0%)] Loss: -1487.651611\n",
      "Train Epoch: 888 [32768/54000 (61%)] Loss: -1488.574463\n",
      "    epoch          : 888\n",
      "    loss           : -1488.9862797575177\n",
      "    ess            : 3.770958963430153\n",
      "    log_marginal   : 1489.1090087890625\n",
      "    val_loss       : -1487.7536214192708\n",
      "    val_ess        : 3.7632871866226196\n",
      "    val_log_marginal: 1487.885986328125\n",
      "Train Epoch: 889 [0/54000 (0%)] Loss: -1492.663086\n",
      "Train Epoch: 889 [32768/54000 (61%)] Loss: -1487.490479\n",
      "    epoch          : 889\n",
      "    loss           : -1489.0964240308078\n",
      "    ess            : 3.765074320559232\n",
      "    log_marginal   : 1489.2208113760319\n",
      "    val_loss       : -1488.1970825195312\n",
      "    val_ess        : 3.77607532342275\n",
      "    val_log_marginal: 1488.3155721028645\n",
      "Train Epoch: 890 [0/54000 (0%)] Loss: -1488.276611\n",
      "Train Epoch: 890 [32768/54000 (61%)] Loss: -1489.188721\n",
      "    epoch          : 890\n",
      "    loss           : -1489.2860107421875\n",
      "    ess            : 3.765943410261622\n",
      "    log_marginal   : 1489.411247973172\n",
      "    val_loss       : -1488.4317830403645\n",
      "    val_ess        : 3.77708899974823\n",
      "    val_log_marginal: 1488.5528767903645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch890.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 891 [0/54000 (0%)] Loss: -1491.514771\n",
      "Train Epoch: 891 [32768/54000 (61%)] Loss: -1489.539429\n",
      "    epoch          : 891\n",
      "    loss           : -1489.4337319428066\n",
      "    ess            : 3.7660556919169874\n",
      "    log_marginal   : 1489.5578682377654\n",
      "    val_loss       : -1488.4805297851562\n",
      "    val_ess        : 3.7710641622543335\n",
      "    val_log_marginal: 1488.604227701823\n",
      "Train Epoch: 892 [0/54000 (0%)] Loss: -1490.088867\n",
      "Train Epoch: 892 [32768/54000 (61%)] Loss: -1487.051270\n",
      "    epoch          : 892\n",
      "    loss           : -1489.5598881559552\n",
      "    ess            : 3.7680452724672713\n",
      "    log_marginal   : 1489.6846509249706\n",
      "    val_loss       : -1488.936055501302\n",
      "    val_ess        : 3.7725112438201904\n",
      "    val_log_marginal: 1489.0530395507812\n",
      "Train Epoch: 893 [0/54000 (0%)] Loss: -1489.267578\n",
      "Train Epoch: 893 [32768/54000 (61%)] Loss: -1491.622070\n",
      "    epoch          : 893\n",
      "    loss           : -1489.6924173607017\n",
      "    ess            : 3.7659863076120055\n",
      "    log_marginal   : 1489.8168876216096\n",
      "    val_loss       : -1488.8121541341145\n",
      "    val_ess        : 3.773613135019938\n",
      "    val_log_marginal: 1488.9300130208333\n",
      "Train Epoch: 894 [0/54000 (0%)] Loss: -1491.206787\n",
      "Train Epoch: 894 [32768/54000 (61%)] Loss: -1488.009033\n",
      "    epoch          : 894\n",
      "    loss           : -1489.9089286372346\n",
      "    ess            : 3.770796627368567\n",
      "    log_marginal   : 1490.0303333210495\n",
      "    val_loss       : -1488.8661092122395\n",
      "    val_ess        : 3.757013281186422\n",
      "    val_log_marginal: 1488.9927571614583\n",
      "Train Epoch: 895 [0/54000 (0%)] Loss: -1491.375122\n",
      "Train Epoch: 895 [32768/54000 (61%)] Loss: -1490.208740\n",
      "    epoch          : 895\n",
      "    loss           : -1490.107707473467\n",
      "    ess            : 3.770647021959413\n",
      "    log_marginal   : 1490.2312771779186\n",
      "    val_loss       : -1488.6303304036458\n",
      "    val_ess        : 3.7715578079223633\n",
      "    val_log_marginal: 1488.7496337890625\n",
      "Train Epoch: 896 [0/54000 (0%)] Loss: -1489.975342\n",
      "Train Epoch: 896 [32768/54000 (61%)] Loss: -1493.223145\n",
      "    epoch          : 896\n",
      "    loss           : -1490.244670364092\n",
      "    ess            : 3.766802675319168\n",
      "    log_marginal   : 1490.366782134434\n",
      "    val_loss       : -1489.5495198567708\n",
      "    val_ess        : 3.7654033501942954\n",
      "    val_log_marginal: 1489.6834309895833\n",
      "Train Epoch: 897 [0/54000 (0%)] Loss: -1492.143799\n",
      "Train Epoch: 897 [32768/54000 (61%)] Loss: -1491.420776\n",
      "    epoch          : 897\n",
      "    loss           : -1490.3242164467865\n",
      "    ess            : 3.760682911243079\n",
      "    log_marginal   : 1490.45228893352\n",
      "    val_loss       : -1489.1024780273438\n",
      "    val_ess        : 3.7693458000818887\n",
      "    val_log_marginal: 1489.2261555989583\n",
      "Train Epoch: 898 [0/54000 (0%)] Loss: -1492.237915\n",
      "Train Epoch: 898 [32768/54000 (61%)] Loss: -1487.625000\n",
      "    epoch          : 898\n",
      "    loss           : -1490.4094330409787\n",
      "    ess            : 3.7633978780710473\n",
      "    log_marginal   : 1490.5371231942806\n",
      "    val_loss       : -1489.6586100260417\n",
      "    val_ess        : 3.777610460917155\n",
      "    val_log_marginal: 1489.774149576823\n",
      "Train Epoch: 899 [0/54000 (0%)] Loss: -1497.002197\n",
      "Train Epoch: 899 [32768/54000 (61%)] Loss: -1490.282349\n",
      "    epoch          : 899\n",
      "    loss           : -1490.6170792489681\n",
      "    ess            : 3.771864594153638\n",
      "    log_marginal   : 1490.7400086600826\n",
      "    val_loss       : -1489.5661214192708\n",
      "    val_ess        : 3.7750340700149536\n",
      "    val_log_marginal: 1489.6842041015625\n",
      "Train Epoch: 900 [0/54000 (0%)] Loss: -1495.539062\n",
      "Train Epoch: 900 [32768/54000 (61%)] Loss: -1489.633057\n",
      "    epoch          : 900\n",
      "    loss           : -1490.8285418816333\n",
      "    ess            : 3.7699122203970856\n",
      "    log_marginal   : 1490.9488479326355\n",
      "    val_loss       : -1489.6448567708333\n",
      "    val_ess        : 3.7728956937789917\n",
      "    val_log_marginal: 1489.7647705078125\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [0/54000 (0%)] Loss: -1493.920654\n",
      "Train Epoch: 901 [32768/54000 (61%)] Loss: -1489.341919\n",
      "    epoch          : 901\n",
      "    loss           : -1491.0357896336968\n",
      "    ess            : 3.7667065071609787\n",
      "    log_marginal   : 1491.1612548828125\n",
      "    val_loss       : -1490.3931070963542\n",
      "    val_ess        : 3.7668647368748984\n",
      "    val_log_marginal: 1490.5130615234375\n",
      "Train Epoch: 902 [0/54000 (0%)] Loss: -1493.441162\n",
      "Train Epoch: 902 [32768/54000 (61%)] Loss: -1490.796997\n",
      "    epoch          : 902\n",
      "    loss           : -1491.0135912625294\n",
      "    ess            : 3.7654734377591117\n",
      "    log_marginal   : 1491.1406157871463\n",
      "    val_loss       : -1490.3153686523438\n",
      "    val_ess        : 3.76105531056722\n",
      "    val_log_marginal: 1490.4461669921875\n",
      "Train Epoch: 903 [0/54000 (0%)] Loss: -1492.882080\n",
      "Train Epoch: 903 [32768/54000 (61%)] Loss: -1492.822754\n",
      "    epoch          : 903\n",
      "    loss           : -1491.1555820681015\n",
      "    ess            : 3.7680655155541762\n",
      "    log_marginal   : 1491.279789762677\n",
      "    val_loss       : -1490.1633911132812\n",
      "    val_ess        : 3.759987195332845\n",
      "    val_log_marginal: 1490.3074340820312\n",
      "Train Epoch: 904 [0/54000 (0%)] Loss: -1493.904785\n",
      "Train Epoch: 904 [32768/54000 (61%)] Loss: -1488.588623\n",
      "    epoch          : 904\n",
      "    loss           : -1491.3580207104953\n",
      "    ess            : 3.7676116835396245\n",
      "    log_marginal   : 1491.483948905513\n",
      "    val_loss       : -1490.4151611328125\n",
      "    val_ess        : 3.7658154567082724\n",
      "    val_log_marginal: 1490.5411173502605\n",
      "Train Epoch: 905 [0/54000 (0%)] Loss: -1492.383545\n",
      "Train Epoch: 905 [32768/54000 (61%)] Loss: -1490.263550\n",
      "    epoch          : 905\n",
      "    loss           : -1491.59165637898\n",
      "    ess            : 3.770890969150471\n",
      "    log_marginal   : 1491.7127800707547\n",
      "    val_loss       : -1490.5060628255208\n",
      "    val_ess        : 3.7652814388275146\n",
      "    val_log_marginal: 1490.6234537760417\n",
      "Train Epoch: 906 [0/54000 (0%)] Loss: -1492.950439\n",
      "Train Epoch: 906 [32768/54000 (61%)] Loss: -1493.985352\n",
      "    epoch          : 906\n",
      "    loss           : -1491.6665522737323\n",
      "    ess            : 3.7664884486288392\n",
      "    log_marginal   : 1491.7912943138267\n",
      "    val_loss       : -1490.7985432942708\n",
      "    val_ess        : 3.7681735356648765\n",
      "    val_log_marginal: 1490.9291178385417\n",
      "Train Epoch: 907 [0/54000 (0%)] Loss: -1490.969116\n",
      "Train Epoch: 907 [32768/54000 (61%)] Loss: -1490.631836\n",
      "    epoch          : 907\n",
      "    loss           : -1491.9002109743515\n",
      "    ess            : 3.7737901075830997\n",
      "    log_marginal   : 1492.0210697965802\n",
      "    val_loss       : -1491.005839029948\n",
      "    val_ess        : 3.7752150297164917\n",
      "    val_log_marginal: 1491.1269124348958\n",
      "Train Epoch: 908 [0/54000 (0%)] Loss: -1495.138916\n",
      "Train Epoch: 908 [32768/54000 (61%)] Loss: -1492.558594\n",
      "    epoch          : 908\n",
      "    loss           : -1491.9218819096404\n",
      "    ess            : 3.7677409109079614\n",
      "    log_marginal   : 1492.0474093455189\n",
      "    val_loss       : -1491.2204996744792\n",
      "    val_ess        : 3.7773987849553428\n",
      "    val_log_marginal: 1491.3318277994792\n",
      "Train Epoch: 909 [0/54000 (0%)] Loss: -1490.317993\n",
      "Train Epoch: 909 [32768/54000 (61%)] Loss: -1492.442627\n",
      "    epoch          : 909\n",
      "    loss           : -1492.1318382407135\n",
      "    ess            : 3.7653715340596325\n",
      "    log_marginal   : 1492.257075471698\n",
      "    val_loss       : -1491.3907877604167\n",
      "    val_ess        : 3.779562473297119\n",
      "    val_log_marginal: 1491.5097045898438\n",
      "Train Epoch: 910 [0/54000 (0%)] Loss: -1493.891968\n",
      "Train Epoch: 910 [32768/54000 (61%)] Loss: -1491.599365\n",
      "    epoch          : 910\n",
      "    loss           : -1492.3209965543927\n",
      "    ess            : 3.769827869703185\n",
      "    log_marginal   : 1492.4409456073113\n",
      "    val_loss       : -1491.330790201823\n",
      "    val_ess        : 3.7582023541132608\n",
      "    val_log_marginal: 1491.4611206054688\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch910.pth ...\n",
      "Train Epoch: 911 [0/54000 (0%)] Loss: -1493.876709\n",
      "Train Epoch: 911 [32768/54000 (61%)] Loss: -1491.202881\n",
      "    epoch          : 911\n",
      "    loss           : -1492.3126520120873\n",
      "    ess            : 3.767851708070287\n",
      "    log_marginal   : 1492.4405655770931\n",
      "    val_loss       : -1491.4844563802083\n",
      "    val_ess        : 3.78139591217041\n",
      "    val_log_marginal: 1491.5994873046875\n",
      "Train Epoch: 912 [0/54000 (0%)] Loss: -1494.379883\n",
      "Train Epoch: 912 [32768/54000 (61%)] Loss: -1491.611328\n",
      "    epoch          : 912\n",
      "    loss           : -1492.6119384765625\n",
      "    ess            : 3.7694217259029172\n",
      "    log_marginal   : 1492.7333132186027\n",
      "    val_loss       : -1491.528076171875\n",
      "    val_ess        : 3.769038359324137\n",
      "    val_log_marginal: 1491.655049641927\n",
      "Train Epoch: 913 [0/54000 (0%)] Loss: -1495.068115\n",
      "Train Epoch: 913 [32768/54000 (61%)] Loss: -1490.839478\n",
      "    epoch          : 913\n",
      "    loss           : -1492.7785529370578\n",
      "    ess            : 3.767386067588374\n",
      "    log_marginal   : 1492.9036727041569\n",
      "    val_loss       : -1491.534647623698\n",
      "    val_ess        : 3.764615615208944\n",
      "    val_log_marginal: 1491.6586303710938\n",
      "Train Epoch: 914 [0/54000 (0%)] Loss: -1492.711426\n",
      "Train Epoch: 914 [32768/54000 (61%)] Loss: -1494.000488\n",
      "    epoch          : 914\n",
      "    loss           : -1492.8977142909787\n",
      "    ess            : 3.774759000202395\n",
      "    log_marginal   : 1493.0164034861439\n",
      "    val_loss       : -1492.0703735351562\n",
      "    val_ess        : 3.779179493586222\n",
      "    val_log_marginal: 1492.1878865559895\n",
      "Train Epoch: 915 [0/54000 (0%)] Loss: -1496.354736\n",
      "Train Epoch: 915 [32768/54000 (61%)] Loss: -1492.158203\n",
      "    epoch          : 915\n",
      "    loss           : -1493.0501570791569\n",
      "    ess            : 3.770020934770692\n",
      "    log_marginal   : 1493.173993956368\n",
      "    val_loss       : -1492.0644938151042\n",
      "    val_ess        : 3.762231628100077\n",
      "    val_log_marginal: 1492.1902669270833\n",
      "Train Epoch: 916 [0/54000 (0%)] Loss: -1494.137451\n",
      "Train Epoch: 916 [32768/54000 (61%)] Loss: -1492.062500\n",
      "    epoch          : 916\n",
      "    loss           : -1493.2526394826061\n",
      "    ess            : 3.7739035363467233\n",
      "    log_marginal   : 1493.3737862065154\n",
      "    val_loss       : -1492.3599039713542\n",
      "    val_ess        : 3.76338259379069\n",
      "    val_log_marginal: 1492.4844970703125\n",
      "Train Epoch: 917 [0/54000 (0%)] Loss: -1494.848267\n",
      "Train Epoch: 917 [32768/54000 (61%)] Loss: -1492.464966\n",
      "    epoch          : 917\n",
      "    loss           : -1493.5108435288914\n",
      "    ess            : 3.770685281393663\n",
      "    log_marginal   : 1493.6326397589917\n",
      "    val_loss       : -1492.5147501627605\n",
      "    val_ess        : 3.7744240760803223\n",
      "    val_log_marginal: 1492.6309204101562\n",
      "Train Epoch: 918 [0/54000 (0%)] Loss: -1495.103271\n",
      "Train Epoch: 918 [32768/54000 (61%)] Loss: -1492.336304\n",
      "    epoch          : 918\n",
      "    loss           : -1493.6685007923054\n",
      "    ess            : 3.7730905244935236\n",
      "    log_marginal   : 1493.7924159787735\n",
      "    val_loss       : -1492.4263509114583\n",
      "    val_ess        : 3.7612916231155396\n",
      "    val_log_marginal: 1492.5596720377605\n",
      "Train Epoch: 919 [0/54000 (0%)] Loss: -1494.563599\n",
      "Train Epoch: 919 [32768/54000 (61%)] Loss: -1493.984131\n",
      "    epoch          : 919\n",
      "    loss           : -1493.6523575692806\n",
      "    ess            : 3.7689125897749416\n",
      "    log_marginal   : 1493.7742182893573\n",
      "    val_loss       : -1492.7484334309895\n",
      "    val_ess        : 3.7646180788675943\n",
      "    val_log_marginal: 1492.8711344401042\n",
      "Train Epoch: 920 [0/54000 (0%)] Loss: -1493.387329\n",
      "Train Epoch: 920 [32768/54000 (61%)] Loss: -1493.392334\n",
      "    epoch          : 920\n",
      "    loss           : -1493.7117873857605\n",
      "    ess            : 3.7677212931075186\n",
      "    log_marginal   : 1493.83698085569\n",
      "    val_loss       : -1492.9468790690105\n",
      "    val_ess        : 3.7673375606536865\n",
      "    val_log_marginal: 1493.0758666992188\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch920.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 921 [0/54000 (0%)] Loss: -1494.213623\n",
      "Train Epoch: 921 [32768/54000 (61%)] Loss: -1494.466553\n",
      "    epoch          : 921\n",
      "    loss           : -1493.8416655918338\n",
      "    ess            : 3.7722538057363257\n",
      "    log_marginal   : 1493.9632361070164\n",
      "    val_loss       : -1493.3706868489583\n",
      "    val_ess        : 3.7720499833424888\n",
      "    val_log_marginal: 1493.4946695963542\n",
      "Train Epoch: 922 [0/54000 (0%)] Loss: -1498.384644\n",
      "Train Epoch: 922 [32768/54000 (61%)] Loss: -1496.688965\n",
      "    epoch          : 922\n",
      "    loss           : -1493.9901422464623\n",
      "    ess            : 3.7748713718270355\n",
      "    log_marginal   : 1494.108762345224\n",
      "    val_loss       : -1493.457295735677\n",
      "    val_ess        : 3.7616254488627114\n",
      "    val_log_marginal: 1493.5907389322917\n",
      "Train Epoch: 923 [0/54000 (0%)] Loss: -1494.735352\n",
      "Train Epoch: 923 [32768/54000 (61%)] Loss: -1493.945801\n",
      "    epoch          : 923\n",
      "    loss           : -1494.0601345997936\n",
      "    ess            : 3.770627165740391\n",
      "    log_marginal   : 1494.1795746425412\n",
      "    val_loss       : -1493.614501953125\n",
      "    val_ess        : 3.7852754990259805\n",
      "    val_log_marginal: 1493.7229614257812\n",
      "Train Epoch: 924 [0/54000 (0%)] Loss: -1493.240967\n",
      "Train Epoch: 924 [32768/54000 (61%)] Loss: -1494.887329\n",
      "    epoch          : 924\n",
      "    loss           : -1494.3135709942512\n",
      "    ess            : 3.7661048061442823\n",
      "    log_marginal   : 1494.4384235885907\n",
      "    val_loss       : -1493.8069661458333\n",
      "    val_ess        : 3.7772520780563354\n",
      "    val_log_marginal: 1493.9301147460938\n",
      "Train Epoch: 925 [0/54000 (0%)] Loss: -1494.406982\n",
      "Train Epoch: 925 [32768/54000 (61%)] Loss: -1492.253906\n",
      "    epoch          : 925\n",
      "    loss           : -1494.4547994361733\n",
      "    ess            : 3.77186673992085\n",
      "    log_marginal   : 1494.5778048533314\n",
      "    val_loss       : -1493.7865600585938\n",
      "    val_ess        : 3.77016282081604\n",
      "    val_log_marginal: 1493.9174397786458\n",
      "Train Epoch: 926 [0/54000 (0%)] Loss: -1493.831909\n",
      "Train Epoch: 926 [32768/54000 (61%)] Loss: -1496.001709\n",
      "    epoch          : 926\n",
      "    loss           : -1494.5257245909493\n",
      "    ess            : 3.7691714763641357\n",
      "    log_marginal   : 1494.6495683778007\n",
      "    val_loss       : -1493.7845865885417\n",
      "    val_ess        : 3.7785605986913047\n",
      "    val_log_marginal: 1493.9052327473958\n",
      "Train Epoch: 927 [0/54000 (0%)] Loss: -1491.604736\n",
      "Train Epoch: 927 [32768/54000 (61%)] Loss: -1493.647095\n",
      "    epoch          : 927\n",
      "    loss           : -1494.7395963848762\n",
      "    ess            : 3.766084077223292\n",
      "    log_marginal   : 1494.8650178729363\n",
      "    val_loss       : -1494.1675618489583\n",
      "    val_ess        : 3.7638541062672934\n",
      "    val_log_marginal: 1494.292215983073\n",
      "Train Epoch: 928 [0/54000 (0%)] Loss: -1493.990845\n",
      "Train Epoch: 928 [32768/54000 (61%)] Loss: -1493.820557\n",
      "    epoch          : 928\n",
      "    loss           : -1495.0016099461968\n",
      "    ess            : 3.7746207444172986\n",
      "    log_marginal   : 1495.1226714512088\n",
      "    val_loss       : -1494.4237467447917\n",
      "    val_ess        : 3.775109569231669\n",
      "    val_log_marginal: 1494.5327962239583\n",
      "Train Epoch: 929 [0/54000 (0%)] Loss: -1496.264648\n",
      "Train Epoch: 929 [32768/54000 (61%)] Loss: -1495.215454\n",
      "    epoch          : 929\n",
      "    loss           : -1495.1240234375\n",
      "    ess            : 3.7655615131810025\n",
      "    log_marginal   : 1495.2518771189564\n",
      "    val_loss       : -1494.470967610677\n",
      "    val_ess        : 3.77161173025767\n",
      "    val_log_marginal: 1494.5868326822917\n",
      "Train Epoch: 930 [0/54000 (0%)] Loss: -1496.925537\n",
      "Train Epoch: 930 [32768/54000 (61%)] Loss: -1491.346436\n",
      "    epoch          : 930\n",
      "    loss           : -1495.2463701356132\n",
      "    ess            : 3.77029842250752\n",
      "    log_marginal   : 1495.36928112102\n",
      "    val_loss       : -1494.6712036132812\n",
      "    val_ess        : 3.760236144065857\n",
      "    val_log_marginal: 1494.8058471679688\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch930.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 931 [0/54000 (0%)] Loss: -1495.479248\n",
      "Train Epoch: 931 [32768/54000 (61%)] Loss: -1494.798950\n",
      "    epoch          : 931\n",
      "    loss           : -1495.2988143057194\n",
      "    ess            : 3.7670252907950923\n",
      "    log_marginal   : 1495.4244476894162\n",
      "    val_loss       : -1494.425557454427\n",
      "    val_ess        : 3.767418543497721\n",
      "    val_log_marginal: 1494.5470377604167\n",
      "Train Epoch: 932 [0/54000 (0%)] Loss: -1494.211060\n",
      "Train Epoch: 932 [32768/54000 (61%)] Loss: -1495.172974\n",
      "    epoch          : 932\n",
      "    loss           : -1495.4213752026828\n",
      "    ess            : 3.7662801427661248\n",
      "    log_marginal   : 1495.5481210384728\n",
      "    val_loss       : -1495.0274658203125\n",
      "    val_ess        : 3.7660776376724243\n",
      "    val_log_marginal: 1495.150899251302\n",
      "Train Epoch: 933 [0/54000 (0%)] Loss: -1498.771973\n",
      "Train Epoch: 933 [32768/54000 (61%)] Loss: -1492.838745\n",
      "    epoch          : 933\n",
      "    loss           : -1495.4721541494694\n",
      "    ess            : 3.769178035124293\n",
      "    log_marginal   : 1495.5955142614976\n",
      "    val_loss       : -1495.064453125\n",
      "    val_ess        : 3.7867488861083984\n",
      "    val_log_marginal: 1495.1798909505208\n",
      "Train Epoch: 934 [0/54000 (0%)] Loss: -1499.183105\n",
      "Train Epoch: 934 [32768/54000 (61%)] Loss: -1495.873779\n",
      "    epoch          : 934\n",
      "    loss           : -1495.6116943359375\n",
      "    ess            : 3.7707100004520058\n",
      "    log_marginal   : 1495.732364294664\n",
      "    val_loss       : -1494.7971598307292\n",
      "    val_ess        : 3.767168879508972\n",
      "    val_log_marginal: 1494.923075358073\n",
      "Train Epoch: 935 [0/54000 (0%)] Loss: -1495.668091\n",
      "Train Epoch: 935 [32768/54000 (61%)] Loss: -1499.058105\n",
      "    epoch          : 935\n",
      "    loss           : -1495.7697776938385\n",
      "    ess            : 3.765674015261092\n",
      "    log_marginal   : 1495.8954202903892\n",
      "    val_loss       : -1494.8288167317708\n",
      "    val_ess        : 3.7620009183883667\n",
      "    val_log_marginal: 1494.950927734375\n",
      "Train Epoch: 936 [0/54000 (0%)] Loss: -1497.034424\n",
      "Train Epoch: 936 [32768/54000 (61%)] Loss: -1494.486816\n",
      "    epoch          : 936\n",
      "    loss           : -1495.8671137971698\n",
      "    ess            : 3.7723996684236347\n",
      "    log_marginal   : 1495.9918995983196\n",
      "    val_loss       : -1495.2273966471355\n",
      "    val_ess        : 3.7676020860671997\n",
      "    val_log_marginal: 1495.363260904948\n",
      "Train Epoch: 937 [0/54000 (0%)] Loss: -1498.891846\n",
      "Train Epoch: 937 [32768/54000 (61%)] Loss: -1496.261230\n",
      "    epoch          : 937\n",
      "    loss           : -1496.0530775538032\n",
      "    ess            : 3.7673863374961996\n",
      "    log_marginal   : 1496.1770572302476\n",
      "    val_loss       : -1495.3326416015625\n",
      "    val_ess        : 3.764752229054769\n",
      "    val_log_marginal: 1495.470458984375\n",
      "Train Epoch: 938 [0/54000 (0%)] Loss: -1500.219482\n",
      "Train Epoch: 938 [32768/54000 (61%)] Loss: -1495.356689\n",
      "    epoch          : 938\n",
      "    loss           : -1496.1907912920105\n",
      "    ess            : 3.7669851824922382\n",
      "    log_marginal   : 1496.317990860849\n",
      "    val_loss       : -1495.4103190104167\n",
      "    val_ess        : 3.7744205792744956\n",
      "    val_log_marginal: 1495.537333170573\n",
      "Train Epoch: 939 [0/54000 (0%)] Loss: -1498.455566\n",
      "Train Epoch: 939 [32768/54000 (61%)] Loss: -1496.086426\n",
      "    epoch          : 939\n",
      "    loss           : -1496.3401362581073\n",
      "    ess            : 3.771551658522408\n",
      "    log_marginal   : 1496.4604860701652\n",
      "    val_loss       : -1495.518046061198\n",
      "    val_ess        : 3.7869966427485147\n",
      "    val_log_marginal: 1495.6255289713542\n",
      "Train Epoch: 940 [0/54000 (0%)] Loss: -1498.373535\n",
      "Train Epoch: 940 [32768/54000 (61%)] Loss: -1494.446777\n",
      "    epoch          : 940\n",
      "    loss           : -1496.4410861033314\n",
      "    ess            : 3.769943912074251\n",
      "    log_marginal   : 1496.5630758033608\n",
      "    val_loss       : -1495.7451985677083\n",
      "    val_ess        : 3.7833425203959146\n",
      "    val_log_marginal: 1495.8569946289062\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch940.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 941 [0/54000 (0%)] Loss: -1494.859863\n",
      "Train Epoch: 941 [32768/54000 (61%)] Loss: -1494.947510\n",
      "    epoch          : 941\n",
      "    loss           : -1496.5875612654777\n",
      "    ess            : 3.772744174273509\n",
      "    log_marginal   : 1496.709286095961\n",
      "    val_loss       : -1495.57666015625\n",
      "    val_ess        : 3.766270637512207\n",
      "    val_log_marginal: 1495.7015991210938\n",
      "Train Epoch: 942 [0/54000 (0%)] Loss: -1499.305420\n",
      "Train Epoch: 942 [32768/54000 (61%)] Loss: -1495.873291\n",
      "    epoch          : 942\n",
      "    loss           : -1496.6708984375\n",
      "    ess            : 3.771980510567719\n",
      "    log_marginal   : 1496.7936505011792\n",
      "    val_loss       : -1496.0093790690105\n",
      "    val_ess        : 3.7689609130223594\n",
      "    val_log_marginal: 1496.1355997721355\n",
      "Train Epoch: 943 [0/54000 (0%)] Loss: -1497.775146\n",
      "Train Epoch: 943 [32768/54000 (61%)] Loss: -1493.573242\n",
      "    epoch          : 943\n",
      "    loss           : -1496.7153481537441\n",
      "    ess            : 3.7677065246510058\n",
      "    log_marginal   : 1496.843183409493\n",
      "    val_loss       : -1495.7828165690105\n",
      "    val_ess        : 3.7714956601460776\n",
      "    val_log_marginal: 1495.9092203776042\n",
      "Train Epoch: 944 [0/54000 (0%)] Loss: -1495.342041\n",
      "Train Epoch: 944 [32768/54000 (61%)] Loss: -1496.855713\n",
      "    epoch          : 944\n",
      "    loss           : -1496.8780310288914\n",
      "    ess            : 3.7676522012026803\n",
      "    log_marginal   : 1497.0018517836086\n",
      "    val_loss       : -1496.3632202148438\n",
      "    val_ess        : 3.772451639175415\n",
      "    val_log_marginal: 1496.4817911783855\n",
      "Train Epoch: 945 [0/54000 (0%)] Loss: -1497.135010\n",
      "Train Epoch: 945 [32768/54000 (61%)] Loss: -1496.368042\n",
      "    epoch          : 945\n",
      "    loss           : -1497.055539688974\n",
      "    ess            : 3.771102059562251\n",
      "    log_marginal   : 1497.1770203788326\n",
      "    val_loss       : -1496.578125\n",
      "    val_ess        : 3.786791205406189\n",
      "    val_log_marginal: 1496.6906331380208\n",
      "Train Epoch: 946 [0/54000 (0%)] Loss: -1497.969849\n",
      "Train Epoch: 946 [32768/54000 (61%)] Loss: -1499.024048\n",
      "    epoch          : 946\n",
      "    loss           : -1497.1921709168632\n",
      "    ess            : 3.7698271409520565\n",
      "    log_marginal   : 1497.3195731684846\n",
      "    val_loss       : -1496.3755289713542\n",
      "    val_ess        : 3.772782286008199\n",
      "    val_log_marginal: 1496.4972127278645\n",
      "Train Epoch: 947 [0/54000 (0%)] Loss: -1495.232788\n",
      "Train Epoch: 947 [32768/54000 (61%)] Loss: -1500.843140\n",
      "    epoch          : 947\n",
      "    loss           : -1497.342996849204\n",
      "    ess            : 3.769396467028924\n",
      "    log_marginal   : 1497.4663822965802\n",
      "    val_loss       : -1496.4597778320312\n",
      "    val_ess        : 3.7764837741851807\n",
      "    val_log_marginal: 1496.5809733072917\n",
      "Train Epoch: 948 [0/54000 (0%)] Loss: -1501.627075\n",
      "Train Epoch: 948 [32768/54000 (61%)] Loss: -1499.607788\n",
      "    epoch          : 948\n",
      "    loss           : -1497.5074416826355\n",
      "    ess            : 3.770386533917121\n",
      "    log_marginal   : 1497.6289500110554\n",
      "    val_loss       : -1496.9761352539062\n",
      "    val_ess        : 3.7704811493555703\n",
      "    val_log_marginal: 1497.0958455403645\n",
      "Train Epoch: 949 [0/54000 (0%)] Loss: -1499.397705\n",
      "Train Epoch: 949 [32768/54000 (61%)] Loss: -1498.383423\n",
      "    epoch          : 949\n",
      "    loss           : -1497.7312863907723\n",
      "    ess            : 3.7705513891184106\n",
      "    log_marginal   : 1497.8553236475532\n",
      "    val_loss       : -1496.9905802408855\n",
      "    val_ess        : 3.782377004623413\n",
      "    val_log_marginal: 1497.0997314453125\n",
      "Train Epoch: 950 [0/54000 (0%)] Loss: -1494.833984\n",
      "Train Epoch: 950 [32768/54000 (61%)] Loss: -1496.284424\n",
      "    epoch          : 950\n",
      "    loss           : -1497.8547823923939\n",
      "    ess            : 3.7729092094133483\n",
      "    log_marginal   : 1497.9795474646226\n",
      "    val_loss       : -1496.8446248372395\n",
      "    val_ess        : 3.771640141805013\n",
      "    val_log_marginal: 1496.9674072265625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch950.pth ...\n",
      "Train Epoch: 951 [0/54000 (0%)] Loss: -1498.741699\n",
      "Train Epoch: 951 [32768/54000 (61%)] Loss: -1496.806885\n",
      "    epoch          : 951\n",
      "    loss           : -1497.949826798349\n",
      "    ess            : 3.7688673217341586\n",
      "    log_marginal   : 1498.0728022737323\n",
      "    val_loss       : -1496.9744669596355\n",
      "    val_ess        : 3.7711772521336875\n",
      "    val_log_marginal: 1497.096455891927\n",
      "Train Epoch: 952 [0/54000 (0%)] Loss: -1499.662354\n",
      "Train Epoch: 952 [32768/54000 (61%)] Loss: -1499.715942\n",
      "    epoch          : 952\n",
      "    loss           : -1498.0044037441037\n",
      "    ess            : 3.7722167248995797\n",
      "    log_marginal   : 1498.1281761313385\n",
      "    val_loss       : -1497.3333333333333\n",
      "    val_ess        : 3.776254574457804\n",
      "    val_log_marginal: 1497.4534912109375\n",
      "Train Epoch: 953 [0/54000 (0%)] Loss: -1499.213135\n",
      "Train Epoch: 953 [32768/54000 (61%)] Loss: -1497.304199\n",
      "    epoch          : 953\n",
      "    loss           : -1498.1722458173645\n",
      "    ess            : 3.7715501695309044\n",
      "    log_marginal   : 1498.2973448555424\n",
      "    val_loss       : -1497.642333984375\n",
      "    val_ess        : 3.767869154612223\n",
      "    val_log_marginal: 1497.7659505208333\n",
      "Train Epoch: 954 [0/54000 (0%)] Loss: -1496.487793\n",
      "Train Epoch: 954 [32768/54000 (61%)] Loss: -1496.561157\n",
      "    epoch          : 954\n",
      "    loss           : -1498.3097706920696\n",
      "    ess            : 3.773608868976809\n",
      "    log_marginal   : 1498.4323039504718\n",
      "    val_loss       : -1497.7039591471355\n",
      "    val_ess        : 3.765024979909261\n",
      "    val_log_marginal: 1497.834716796875\n",
      "Train Epoch: 955 [0/54000 (0%)] Loss: -1500.572144\n",
      "Train Epoch: 955 [32768/54000 (61%)] Loss: -1498.781006\n",
      "    epoch          : 955\n",
      "    loss           : -1498.456340285967\n",
      "    ess            : 3.7688296605955878\n",
      "    log_marginal   : 1498.58049961306\n",
      "    val_loss       : -1497.4354451497395\n",
      "    val_ess        : 3.776268800099691\n",
      "    val_log_marginal: 1497.5492757161458\n",
      "Train Epoch: 956 [0/54000 (0%)] Loss: -1495.904785\n",
      "Train Epoch: 956 [32768/54000 (61%)] Loss: -1497.294922\n",
      "    epoch          : 956\n",
      "    loss           : -1498.5594067843456\n",
      "    ess            : 3.7719182248385446\n",
      "    log_marginal   : 1498.6817350567512\n",
      "    val_loss       : -1497.7890218098958\n",
      "    val_ess        : 3.7698411544164023\n",
      "    val_log_marginal: 1497.9101155598958\n",
      "Train Epoch: 957 [0/54000 (0%)] Loss: -1500.474609\n",
      "Train Epoch: 957 [32768/54000 (61%)] Loss: -1497.721680\n",
      "    epoch          : 957\n",
      "    loss           : -1498.7882863170696\n",
      "    ess            : 3.769918333809331\n",
      "    log_marginal   : 1498.911257186026\n",
      "    val_loss       : -1497.800516764323\n",
      "    val_ess        : 3.774416367212931\n",
      "    val_log_marginal: 1497.9288533528645\n",
      "Train Epoch: 958 [0/54000 (0%)] Loss: -1501.564941\n",
      "Train Epoch: 958 [32768/54000 (61%)] Loss: -1497.174072\n",
      "    epoch          : 958\n",
      "    loss           : -1498.771442917158\n",
      "    ess            : 3.7724133707442373\n",
      "    log_marginal   : 1498.8931838701355\n",
      "    val_loss       : -1497.88232421875\n",
      "    val_ess        : 3.763875365257263\n",
      "    val_log_marginal: 1498.0116170247395\n",
      "Train Epoch: 959 [0/54000 (0%)] Loss: -1502.915039\n",
      "Train Epoch: 959 [32768/54000 (61%)] Loss: -1500.256104\n",
      "    epoch          : 959\n",
      "    loss           : -1498.834046561763\n",
      "    ess            : 3.7679507732391357\n",
      "    log_marginal   : 1498.9578189489976\n",
      "    val_loss       : -1498.1859537760417\n",
      "    val_ess        : 3.763558030128479\n",
      "    val_log_marginal: 1498.3108927408855\n",
      "Train Epoch: 960 [0/54000 (0%)] Loss: -1498.578735\n",
      "Train Epoch: 960 [32768/54000 (61%)] Loss: -1499.246338\n",
      "    epoch          : 960\n",
      "    loss           : -1499.0055622604657\n",
      "    ess            : 3.7680216690279402\n",
      "    log_marginal   : 1499.1322735480542\n",
      "    val_loss       : -1498.235371907552\n",
      "    val_ess        : 3.7589708964029946\n",
      "    val_log_marginal: 1498.3638305664062\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch960.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 961 [0/54000 (0%)] Loss: -1499.852295\n",
      "Train Epoch: 961 [32768/54000 (61%)] Loss: -1500.514526\n",
      "    epoch          : 961\n",
      "    loss           : -1499.0557101267689\n",
      "    ess            : 3.7701047276550868\n",
      "    log_marginal   : 1499.1799823113208\n",
      "    val_loss       : -1498.4119669596355\n",
      "    val_ess        : 3.7655663887659707\n",
      "    val_log_marginal: 1498.5425415039062\n",
      "Train Epoch: 962 [0/54000 (0%)] Loss: -1499.451782\n",
      "Train Epoch: 962 [32768/54000 (61%)] Loss: -1500.240845\n",
      "    epoch          : 962\n",
      "    loss           : -1499.2470426739387\n",
      "    ess            : 3.76895912188404\n",
      "    log_marginal   : 1499.3731551260319\n",
      "    val_loss       : -1498.3571166992188\n",
      "    val_ess        : 3.766226371129354\n",
      "    val_log_marginal: 1498.488749186198\n",
      "Train Epoch: 963 [0/54000 (0%)] Loss: -1499.000366\n",
      "Train Epoch: 963 [32768/54000 (61%)] Loss: -1494.696777\n",
      "    epoch          : 963\n",
      "    loss           : -1499.4803812278892\n",
      "    ess            : 3.7723718319299087\n",
      "    log_marginal   : 1499.6011870762088\n",
      "    val_loss       : -1498.734619140625\n",
      "    val_ess        : 3.7727811336517334\n",
      "    val_log_marginal: 1498.8587239583333\n",
      "Train Epoch: 964 [0/54000 (0%)] Loss: -1500.275879\n",
      "Train Epoch: 964 [32768/54000 (61%)] Loss: -1499.914429\n",
      "    epoch          : 964\n",
      "    loss           : -1499.53452747273\n",
      "    ess            : 3.7670127175888926\n",
      "    log_marginal   : 1499.662655236586\n",
      "    val_loss       : -1498.9744262695312\n",
      "    val_ess        : 3.774809638659159\n",
      "    val_log_marginal: 1499.0897827148438\n",
      "Train Epoch: 965 [0/54000 (0%)] Loss: -1504.351562\n",
      "Train Epoch: 965 [32768/54000 (61%)] Loss: -1500.545410\n",
      "    epoch          : 965\n",
      "    loss           : -1499.727965156987\n",
      "    ess            : 3.773231173461338\n",
      "    log_marginal   : 1499.8504546543338\n",
      "    val_loss       : -1498.8663940429688\n",
      "    val_ess        : 3.771785855293274\n",
      "    val_log_marginal: 1498.9921875\n",
      "Train Epoch: 966 [0/54000 (0%)] Loss: -1499.932129\n",
      "Train Epoch: 966 [32768/54000 (61%)] Loss: -1500.408936\n",
      "    epoch          : 966\n",
      "    loss           : -1499.8222518057194\n",
      "    ess            : 3.7686493846605407\n",
      "    log_marginal   : 1499.9484932377654\n",
      "    val_loss       : -1499.3914591471355\n",
      "    val_ess        : 3.770000378290812\n",
      "    val_log_marginal: 1499.5120239257812\n",
      "Train Epoch: 967 [0/54000 (0%)] Loss: -1501.049805\n",
      "Train Epoch: 967 [32768/54000 (61%)] Loss: -1500.417236\n",
      "    epoch          : 967\n",
      "    loss           : -1499.9445432267098\n",
      "    ess            : 3.771066233796893\n",
      "    log_marginal   : 1500.0682488207547\n",
      "    val_loss       : -1499.548604329427\n",
      "    val_ess        : 3.7730202277501426\n",
      "    val_log_marginal: 1499.6705118815105\n",
      "Train Epoch: 968 [0/54000 (0%)] Loss: -1500.334595\n",
      "Train Epoch: 968 [32768/54000 (61%)] Loss: -1499.716431\n",
      "    epoch          : 968\n",
      "    loss           : -1499.937442419664\n",
      "    ess            : 3.770084300131168\n",
      "    log_marginal   : 1500.0626727410083\n",
      "    val_loss       : -1499.6702880859375\n",
      "    val_ess        : 3.77114999294281\n",
      "    val_log_marginal: 1499.793212890625\n",
      "Train Epoch: 969 [0/54000 (0%)] Loss: -1501.906616\n",
      "Train Epoch: 969 [32768/54000 (61%)] Loss: -1500.776978\n",
      "    epoch          : 969\n",
      "    loss           : -1500.069828825177\n",
      "    ess            : 3.7707749492717237\n",
      "    log_marginal   : 1500.194600807046\n",
      "    val_loss       : -1499.8377075195312\n",
      "    val_ess        : 3.7734933694203696\n",
      "    val_log_marginal: 1499.9632364908855\n",
      "Train Epoch: 970 [0/54000 (0%)] Loss: -1503.166504\n",
      "Train Epoch: 970 [32768/54000 (61%)] Loss: -1504.073975\n",
      "    epoch          : 970\n",
      "    loss           : -1500.3304765809257\n",
      "    ess            : 3.774107649641217\n",
      "    log_marginal   : 1500.4505730395047\n",
      "    val_loss       : -1500.2951253255208\n",
      "    val_ess        : 3.7622727950414023\n",
      "    val_log_marginal: 1500.4246826171875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch970.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 971 [0/54000 (0%)] Loss: -1502.296387\n",
      "Train Epoch: 971 [32768/54000 (61%)] Loss: -1500.156006\n",
      "    epoch          : 971\n",
      "    loss           : -1500.4339599609375\n",
      "    ess            : 3.767093887868917\n",
      "    log_marginal   : 1500.5607311320755\n",
      "    val_loss       : -1499.7205810546875\n",
      "    val_ess        : 3.764053463935852\n",
      "    val_log_marginal: 1499.8459879557292\n",
      "Train Epoch: 972 [0/54000 (0%)] Loss: -1501.011353\n",
      "Train Epoch: 972 [32768/54000 (61%)] Loss: -1502.753662\n",
      "    epoch          : 972\n",
      "    loss           : -1500.4154743698407\n",
      "    ess            : 3.7732823119973236\n",
      "    log_marginal   : 1500.536662551592\n",
      "    val_loss       : -1499.897481282552\n",
      "    val_ess        : 3.770474990208944\n",
      "    val_log_marginal: 1500.0275268554688\n",
      "Train Epoch: 973 [0/54000 (0%)] Loss: -1500.656738\n",
      "Train Epoch: 973 [32768/54000 (61%)] Loss: -1500.603149\n",
      "    epoch          : 973\n",
      "    loss           : -1500.6585324845223\n",
      "    ess            : 3.778020399921345\n",
      "    log_marginal   : 1500.7775855874115\n",
      "    val_loss       : -1499.8477172851562\n",
      "    val_ess        : 3.759462515513102\n",
      "    val_log_marginal: 1499.97998046875\n",
      "Train Epoch: 974 [0/54000 (0%)] Loss: -1497.410889\n",
      "Train Epoch: 974 [32768/54000 (61%)] Loss: -1500.985474\n",
      "    epoch          : 974\n",
      "    loss           : -1500.8933612175708\n",
      "    ess            : 3.76926914700922\n",
      "    log_marginal   : 1501.0168779481132\n",
      "    val_loss       : -1500.0460408528645\n",
      "    val_ess        : 3.7705748478571572\n",
      "    val_log_marginal: 1500.168680826823\n",
      "Train Epoch: 975 [0/54000 (0%)] Loss: -1503.347168\n",
      "Train Epoch: 975 [32768/54000 (61%)] Loss: -1500.697998\n",
      "    epoch          : 975\n",
      "    loss           : -1500.9202535377358\n",
      "    ess            : 3.7754983812008263\n",
      "    log_marginal   : 1501.0436251658314\n",
      "    val_loss       : -1500.081034342448\n",
      "    val_ess        : 3.771437327067057\n",
      "    val_log_marginal: 1500.198506673177\n",
      "Train Epoch: 976 [0/54000 (0%)] Loss: -1502.561279\n",
      "Train Epoch: 976 [32768/54000 (61%)] Loss: -1496.577759\n",
      "    epoch          : 976\n",
      "    loss           : -1501.0368997825767\n",
      "    ess            : 3.774560168104352\n",
      "    log_marginal   : 1501.1564711084907\n",
      "    val_loss       : -1500.1011759440105\n",
      "    val_ess        : 3.76775324344635\n",
      "    val_log_marginal: 1500.2295735677083\n",
      "Train Epoch: 977 [0/54000 (0%)] Loss: -1503.595093\n",
      "Train Epoch: 977 [32768/54000 (61%)] Loss: -1500.917725\n",
      "    epoch          : 977\n",
      "    loss           : -1501.1303273326946\n",
      "    ess            : 3.762999898982498\n",
      "    log_marginal   : 1501.2616081957547\n",
      "    val_loss       : -1500.2385660807292\n",
      "    val_ess        : 3.7680543263753257\n",
      "    val_log_marginal: 1500.3637288411458\n",
      "Train Epoch: 978 [0/54000 (0%)] Loss: -1502.600220\n",
      "Train Epoch: 978 [32768/54000 (61%)] Loss: -1505.097168\n",
      "    epoch          : 978\n",
      "    loss           : -1501.2945234190743\n",
      "    ess            : 3.7615407367922225\n",
      "    log_marginal   : 1501.4242703419811\n",
      "    val_loss       : -1500.4434814453125\n",
      "    val_ess        : 3.772267738978068\n",
      "    val_log_marginal: 1500.560770670573\n",
      "Train Epoch: 979 [0/54000 (0%)] Loss: -1503.228271\n",
      "Train Epoch: 979 [32768/54000 (61%)] Loss: -1503.209229\n",
      "    epoch          : 979\n",
      "    loss           : -1501.4695123636498\n",
      "    ess            : 3.772376735255403\n",
      "    log_marginal   : 1501.5911013045402\n",
      "    val_loss       : -1500.6681315104167\n",
      "    val_ess        : 3.774288058280945\n",
      "    val_log_marginal: 1500.7890218098958\n",
      "Train Epoch: 980 [0/54000 (0%)] Loss: -1502.216919\n",
      "Train Epoch: 980 [32768/54000 (61%)] Loss: -1500.805908\n",
      "    epoch          : 980\n",
      "    loss           : -1501.6044576392983\n",
      "    ess            : 3.770245579053771\n",
      "    log_marginal   : 1501.72691028523\n",
      "    val_loss       : -1500.7963256835938\n",
      "    val_ess        : 3.7726962169011435\n",
      "    val_log_marginal: 1500.908467610677\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch980.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 981 [0/54000 (0%)] Loss: -1505.416260\n",
      "Train Epoch: 981 [32768/54000 (61%)] Loss: -1501.563477\n",
      "    epoch          : 981\n",
      "    loss           : -1501.7645931603774\n",
      "    ess            : 3.771017425465134\n",
      "    log_marginal   : 1501.8859149285083\n",
      "    val_loss       : -1501.0023193359375\n",
      "    val_ess        : 3.7695987224578857\n",
      "    val_log_marginal: 1501.131083170573\n",
      "Train Epoch: 982 [0/54000 (0%)] Loss: -1502.203735\n",
      "Train Epoch: 982 [32768/54000 (61%)] Loss: -1499.571533\n",
      "    epoch          : 982\n",
      "    loss           : -1501.9737548828125\n",
      "    ess            : 3.771799379924558\n",
      "    log_marginal   : 1502.0942221587559\n",
      "    val_loss       : -1501.180887858073\n",
      "    val_ess        : 3.7859074672063193\n",
      "    val_log_marginal: 1501.29833984375\n",
      "Train Epoch: 983 [0/54000 (0%)] Loss: -1502.269653\n",
      "Train Epoch: 983 [32768/54000 (61%)] Loss: -1500.916382\n",
      "    epoch          : 983\n",
      "    loss           : -1501.9563932598762\n",
      "    ess            : 3.765859950263545\n",
      "    log_marginal   : 1502.0839682525059\n",
      "    val_loss       : -1501.1649576822917\n",
      "    val_ess        : 3.780797759691874\n",
      "    val_log_marginal: 1501.2863159179688\n",
      "Train Epoch: 984 [0/54000 (0%)] Loss: -1504.512451\n",
      "Train Epoch: 984 [32768/54000 (61%)] Loss: -1502.189453\n",
      "    epoch          : 984\n",
      "    loss           : -1501.9881499668338\n",
      "    ess            : 3.769307757323643\n",
      "    log_marginal   : 1502.114013671875\n",
      "    val_loss       : -1501.5851643880208\n",
      "    val_ess        : 3.7680653731028237\n",
      "    val_log_marginal: 1501.7168579101562\n",
      "Train Epoch: 985 [0/54000 (0%)] Loss: -1505.524292\n",
      "Train Epoch: 985 [32768/54000 (61%)] Loss: -1498.997437\n",
      "    epoch          : 985\n",
      "    loss           : -1502.1900151090802\n",
      "    ess            : 3.7687446576244428\n",
      "    log_marginal   : 1502.3141122494103\n",
      "    val_loss       : -1501.6485188802083\n",
      "    val_ess        : 3.7652058204015098\n",
      "    val_log_marginal: 1501.7755940755208\n",
      "Train Epoch: 986 [0/54000 (0%)] Loss: -1503.708496\n",
      "Train Epoch: 986 [32768/54000 (61%)] Loss: -1499.620850\n",
      "    epoch          : 986\n",
      "    loss           : -1502.4750423791274\n",
      "    ess            : 3.7708307752069437\n",
      "    log_marginal   : 1502.6000884433963\n",
      "    val_loss       : -1501.818379720052\n",
      "    val_ess        : 3.7745935519536338\n",
      "    val_log_marginal: 1501.9436442057292\n",
      "Train Epoch: 987 [0/54000 (0%)] Loss: -1501.398682\n",
      "Train Epoch: 987 [32768/54000 (61%)] Loss: -1499.297363\n",
      "    epoch          : 987\n",
      "    loss           : -1502.4948431051002\n",
      "    ess            : 3.771563948325391\n",
      "    log_marginal   : 1502.6182815263855\n",
      "    val_loss       : -1501.9673868815105\n",
      "    val_ess        : 3.7769389152526855\n",
      "    val_log_marginal: 1502.0897827148438\n",
      "Train Epoch: 988 [0/54000 (0%)] Loss: -1503.433716\n",
      "Train Epoch: 988 [32768/54000 (61%)] Loss: -1502.790771\n",
      "    epoch          : 988\n",
      "    loss           : -1502.4596799454598\n",
      "    ess            : 3.7702538247378365\n",
      "    log_marginal   : 1502.5829709610848\n",
      "    val_loss       : -1502.3549397786458\n",
      "    val_ess        : 3.7801045974095664\n",
      "    val_log_marginal: 1502.4776814778645\n",
      "Train Epoch: 989 [0/54000 (0%)] Loss: -1502.472778\n",
      "Train Epoch: 989 [32768/54000 (61%)] Loss: -1499.880371\n",
      "    epoch          : 989\n",
      "    loss           : -1502.6395010318397\n",
      "    ess            : 3.772156980802428\n",
      "    log_marginal   : 1502.7631306198407\n",
      "    val_loss       : -1502.3081868489583\n",
      "    val_ess        : 3.771602153778076\n",
      "    val_log_marginal: 1502.435323079427\n",
      "Train Epoch: 990 [0/54000 (0%)] Loss: -1504.347656\n",
      "Train Epoch: 990 [32768/54000 (61%)] Loss: -1502.312988\n",
      "    epoch          : 990\n",
      "    loss           : -1502.764606979658\n",
      "    ess            : 3.769470084388301\n",
      "    log_marginal   : 1502.88916015625\n",
      "    val_loss       : -1502.0110677083333\n",
      "    val_ess        : 3.7745365301767984\n",
      "    val_log_marginal: 1502.1289876302083\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch990.pth ...\n",
      "Train Epoch: 991 [0/54000 (0%)] Loss: -1502.593140\n",
      "Train Epoch: 991 [32768/54000 (61%)] Loss: -1499.707031\n",
      "    epoch          : 991\n",
      "    loss           : -1502.8303130527713\n",
      "    ess            : 3.7670617733361587\n",
      "    log_marginal   : 1502.9580676960495\n",
      "    val_loss       : -1502.0418904622395\n",
      "    val_ess        : 3.765932480494181\n",
      "    val_log_marginal: 1502.164774576823\n",
      "Train Epoch: 992 [0/54000 (0%)] Loss: -1503.343262\n",
      "Train Epoch: 992 [32768/54000 (61%)] Loss: -1502.221924\n",
      "    epoch          : 992\n",
      "    loss           : -1502.9096149948407\n",
      "    ess            : 3.7751016391898102\n",
      "    log_marginal   : 1503.03480846477\n",
      "    val_loss       : -1502.1318766276042\n",
      "    val_ess        : 3.774792234102885\n",
      "    val_log_marginal: 1502.2451782226562\n",
      "Train Epoch: 993 [0/54000 (0%)] Loss: -1502.838501\n",
      "Train Epoch: 993 [32768/54000 (61%)] Loss: -1503.141602\n",
      "    epoch          : 993\n",
      "    loss           : -1503.0986420253537\n",
      "    ess            : 3.770762281597785\n",
      "    log_marginal   : 1503.2254477446934\n",
      "    val_loss       : -1502.7175699869792\n",
      "    val_ess        : 3.7905046542485556\n",
      "    val_log_marginal: 1502.8279825846355\n",
      "Train Epoch: 994 [0/54000 (0%)] Loss: -1500.382080\n",
      "Train Epoch: 994 [32768/54000 (61%)] Loss: -1501.798828\n",
      "    epoch          : 994\n",
      "    loss           : -1503.3321441074588\n",
      "    ess            : 3.7736521352012202\n",
      "    log_marginal   : 1503.4515173570164\n",
      "    val_loss       : -1502.7242431640625\n",
      "    val_ess        : 3.7791938384373984\n",
      "    val_log_marginal: 1502.8485514322917\n",
      "Train Epoch: 995 [0/54000 (0%)] Loss: -1505.082153\n",
      "Train Epoch: 995 [32768/54000 (61%)] Loss: -1504.763428\n",
      "    epoch          : 995\n",
      "    loss           : -1503.4672966723172\n",
      "    ess            : 3.77100030881054\n",
      "    log_marginal   : 1503.593390698703\n",
      "    val_loss       : -1503.1082356770833\n",
      "    val_ess        : 3.7830286423365274\n",
      "    val_log_marginal: 1503.2269897460938\n",
      "Train Epoch: 996 [0/54000 (0%)] Loss: -1500.524902\n",
      "Train Epoch: 996 [32768/54000 (61%)] Loss: -1506.160889\n",
      "    epoch          : 996\n",
      "    loss           : -1503.4900547243515\n",
      "    ess            : 3.765707492828369\n",
      "    log_marginal   : 1503.6197417637088\n",
      "    val_loss       : -1502.9921264648438\n",
      "    val_ess        : 3.76051131884257\n",
      "    val_log_marginal: 1503.1187947591145\n",
      "Train Epoch: 997 [0/54000 (0%)] Loss: -1501.474854\n",
      "Train Epoch: 997 [32768/54000 (61%)] Loss: -1502.082397\n",
      "    epoch          : 997\n",
      "    loss           : -1503.6743187094635\n",
      "    ess            : 3.767295239106664\n",
      "    log_marginal   : 1503.8003735812206\n",
      "    val_loss       : -1503.0873006184895\n",
      "    val_ess        : 3.7701846758524575\n",
      "    val_log_marginal: 1503.2098185221355\n",
      "Train Epoch: 998 [0/54000 (0%)] Loss: -1503.437744\n",
      "Train Epoch: 998 [32768/54000 (61%)] Loss: -1502.446045\n",
      "    epoch          : 998\n",
      "    loss           : -1503.8101023548054\n",
      "    ess            : 3.7701119746801988\n",
      "    log_marginal   : 1503.9370508733784\n",
      "    val_loss       : -1503.297139485677\n",
      "    val_ess        : 3.785351355870565\n",
      "    val_log_marginal: 1503.4022420247395\n",
      "Train Epoch: 999 [0/54000 (0%)] Loss: -1505.473145\n",
      "Train Epoch: 999 [32768/54000 (61%)] Loss: -1502.679932\n",
      "    epoch          : 999\n",
      "    loss           : -1503.9623631891216\n",
      "    ess            : 3.7730473257460684\n",
      "    log_marginal   : 1504.08587070681\n",
      "    val_loss       : -1503.5458984375\n",
      "    val_ess        : 3.7624013423919678\n",
      "    val_log_marginal: 1503.677469889323\n",
      "Train Epoch: 1000 [0/54000 (0%)] Loss: -1505.229492\n",
      "Train Epoch: 1000 [32768/54000 (61%)] Loss: -1501.397705\n",
      "    epoch          : 1000\n",
      "    loss           : -1504.076482808815\n",
      "    ess            : 3.7700282852604703\n",
      "    log_marginal   : 1504.2013653449292\n",
      "    val_loss       : -1503.101786295573\n",
      "    val_ess        : 3.7700498898824057\n",
      "    val_log_marginal: 1503.235819498698\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1000.pth ...\n",
      "Train Epoch: 1001 [0/54000 (0%)] Loss: -1504.303955\n",
      "Train Epoch: 1001 [32768/54000 (61%)] Loss: -1504.361084\n",
      "    epoch          : 1001\n",
      "    loss           : -1504.145772682046\n",
      "    ess            : 3.766312594683665\n",
      "    log_marginal   : 1504.2770143904777\n",
      "    val_loss       : -1503.2827758789062\n",
      "    val_ess        : 3.7735128005345664\n",
      "    val_log_marginal: 1503.414082845052\n",
      "Train Epoch: 1002 [0/54000 (0%)] Loss: -1501.742920\n",
      "Train Epoch: 1002 [32768/54000 (61%)] Loss: -1503.693604\n",
      "    epoch          : 1002\n",
      "    loss           : -1504.3729869914505\n",
      "    ess            : 3.773879973393566\n",
      "    log_marginal   : 1504.498555885171\n",
      "    val_loss       : -1503.6060994466145\n",
      "    val_ess        : 3.768946568171183\n",
      "    val_log_marginal: 1503.7304280598958\n",
      "Train Epoch: 1003 [0/54000 (0%)] Loss: -1502.570801\n",
      "Train Epoch: 1003 [32768/54000 (61%)] Loss: -1502.556885\n",
      "    epoch          : 1003\n",
      "    loss           : -1504.569580078125\n",
      "    ess            : 3.7669585605837264\n",
      "    log_marginal   : 1504.6964019199588\n",
      "    val_loss       : -1503.5509440104167\n",
      "    val_ess        : 3.759536941846212\n",
      "    val_log_marginal: 1503.677714029948\n",
      "Train Epoch: 1004 [0/54000 (0%)] Loss: -1504.750854\n",
      "Train Epoch: 1004 [32768/54000 (61%)] Loss: -1502.591553\n",
      "    epoch          : 1004\n",
      "    loss           : -1504.6010811283904\n",
      "    ess            : 3.765017918820651\n",
      "    log_marginal   : 1504.732790389151\n",
      "    val_loss       : -1503.7728474934895\n",
      "    val_ess        : 3.774183511734009\n",
      "    val_log_marginal: 1503.8985188802083\n",
      "Train Epoch: 1005 [0/54000 (0%)] Loss: -1505.112061\n",
      "Train Epoch: 1005 [32768/54000 (61%)] Loss: -1507.181885\n",
      "    epoch          : 1005\n",
      "    loss           : -1504.7458173643868\n",
      "    ess            : 3.7690634322616288\n",
      "    log_marginal   : 1504.8683920806309\n",
      "    val_loss       : -1503.9391682942708\n",
      "    val_ess        : 3.775011579195658\n",
      "    val_log_marginal: 1504.0612386067708\n",
      "Train Epoch: 1006 [0/54000 (0%)] Loss: -1503.051514\n",
      "Train Epoch: 1006 [32768/54000 (61%)] Loss: -1502.918701\n",
      "    epoch          : 1006\n",
      "    loss           : -1504.8310777196343\n",
      "    ess            : 3.772375502676334\n",
      "    log_marginal   : 1504.953790628685\n",
      "    val_loss       : -1504.0318806966145\n",
      "    val_ess        : 3.7707165479660034\n",
      "    val_log_marginal: 1504.150126139323\n",
      "Train Epoch: 1007 [0/54000 (0%)] Loss: -1501.983643\n",
      "Train Epoch: 1007 [32768/54000 (61%)] Loss: -1504.570435\n",
      "    epoch          : 1007\n",
      "    loss           : -1505.0219634433963\n",
      "    ess            : 3.769767981655193\n",
      "    log_marginal   : 1505.1467193027713\n",
      "    val_loss       : -1504.5322875976562\n",
      "    val_ess        : 3.7663894097010293\n",
      "    val_log_marginal: 1504.65869140625\n",
      "Train Epoch: 1008 [0/54000 (0%)] Loss: -1508.127075\n",
      "Train Epoch: 1008 [32768/54000 (61%)] Loss: -1504.050903\n",
      "    epoch          : 1008\n",
      "    loss           : -1505.211306014151\n",
      "    ess            : 3.772458607295774\n",
      "    log_marginal   : 1505.3346177586968\n",
      "    val_loss       : -1504.32421875\n",
      "    val_ess        : 3.7763548294703164\n",
      "    val_log_marginal: 1504.4478556315105\n",
      "Train Epoch: 1009 [0/54000 (0%)] Loss: -1504.738403\n",
      "Train Epoch: 1009 [32768/54000 (61%)] Loss: -1507.957764\n",
      "    epoch          : 1009\n",
      "    loss           : -1505.2800615418632\n",
      "    ess            : 3.773613268474363\n",
      "    log_marginal   : 1505.4041264372052\n",
      "    val_loss       : -1504.1840006510417\n",
      "    val_ess        : 3.763134161631266\n",
      "    val_log_marginal: 1504.3222249348958\n",
      "Train Epoch: 1010 [0/54000 (0%)] Loss: -1506.169189\n",
      "Train Epoch: 1010 [32768/54000 (61%)] Loss: -1505.832764\n",
      "    epoch          : 1010\n",
      "    loss           : -1505.33558971477\n",
      "    ess            : 3.7713330196884445\n",
      "    log_marginal   : 1505.460610443691\n",
      "    val_loss       : -1504.6593221028645\n",
      "    val_ess        : 3.770291010538737\n",
      "    val_log_marginal: 1504.7930501302083\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1010.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1011 [0/54000 (0%)] Loss: -1504.635864\n",
      "Train Epoch: 1011 [32768/54000 (61%)] Loss: -1507.832764\n",
      "    epoch          : 1011\n",
      "    loss           : -1505.61223789431\n",
      "    ess            : 3.774605134748063\n",
      "    log_marginal   : 1505.7322790757664\n",
      "    val_loss       : -1505.3230590820312\n",
      "    val_ess        : 3.767821987469991\n",
      "    val_log_marginal: 1505.4404296875\n",
      "Train Epoch: 1012 [0/54000 (0%)] Loss: -1504.716553\n",
      "Train Epoch: 1012 [32768/54000 (61%)] Loss: -1506.071411\n",
      "    epoch          : 1012\n",
      "    loss           : -1505.679567732901\n",
      "    ess            : 3.769732758683978\n",
      "    log_marginal   : 1505.8044825140034\n",
      "    val_loss       : -1505.0032145182292\n",
      "    val_ess        : 3.7678999106089273\n",
      "    val_log_marginal: 1505.127950032552\n",
      "Train Epoch: 1013 [0/54000 (0%)] Loss: -1508.418701\n",
      "Train Epoch: 1013 [32768/54000 (61%)] Loss: -1508.392578\n",
      "    epoch          : 1013\n",
      "    loss           : -1505.871015440743\n",
      "    ess            : 3.7680009581008047\n",
      "    log_marginal   : 1505.9994518352005\n",
      "    val_loss       : -1504.9744873046875\n",
      "    val_ess        : 3.775727073351542\n",
      "    val_log_marginal: 1505.0924275716145\n",
      "Train Epoch: 1014 [0/54000 (0%)] Loss: -1506.044067\n",
      "Train Epoch: 1014 [32768/54000 (61%)] Loss: -1506.543579\n",
      "    epoch          : 1014\n",
      "    loss           : -1505.8205750663326\n",
      "    ess            : 3.7740198441271513\n",
      "    log_marginal   : 1505.9469155365566\n",
      "    val_loss       : -1504.8765055338542\n",
      "    val_ess        : 3.784725030263265\n",
      "    val_log_marginal: 1504.9845581054688\n",
      "Train Epoch: 1015 [0/54000 (0%)] Loss: -1510.011353\n",
      "Train Epoch: 1015 [32768/54000 (61%)] Loss: -1511.298828\n",
      "    epoch          : 1015\n",
      "    loss           : -1506.0089065263855\n",
      "    ess            : 3.77406503569405\n",
      "    log_marginal   : 1506.1315019715507\n",
      "    val_loss       : -1505.2550862630208\n",
      "    val_ess        : 3.772900660832723\n",
      "    val_log_marginal: 1505.382344563802\n",
      "Train Epoch: 1016 [0/54000 (0%)] Loss: -1504.542480\n",
      "Train Epoch: 1016 [32768/54000 (61%)] Loss: -1503.545898\n",
      "    epoch          : 1016\n",
      "    loss           : -1505.9387299159787\n",
      "    ess            : 3.7704245639297196\n",
      "    log_marginal   : 1506.0634420142983\n",
      "    val_loss       : -1505.2304280598958\n",
      "    val_ess        : 3.774187684059143\n",
      "    val_log_marginal: 1505.3498128255208\n",
      "Train Epoch: 1017 [0/54000 (0%)] Loss: -1506.314697\n",
      "Train Epoch: 1017 [32768/54000 (61%)] Loss: -1505.289673\n",
      "    epoch          : 1017\n",
      "    loss           : -1506.1376768867924\n",
      "    ess            : 3.7732179344825023\n",
      "    log_marginal   : 1506.2596804061027\n",
      "    val_loss       : -1505.3189086914062\n",
      "    val_ess        : 3.7597827514012656\n",
      "    val_log_marginal: 1505.4488728841145\n",
      "Train Epoch: 1018 [0/54000 (0%)] Loss: -1505.318848\n",
      "Train Epoch: 1018 [32768/54000 (61%)] Loss: -1506.105225\n",
      "    epoch          : 1018\n",
      "    loss           : -1506.2683865529186\n",
      "    ess            : 3.768592407118599\n",
      "    log_marginal   : 1506.3929650648586\n",
      "    val_loss       : -1505.3198852539062\n",
      "    val_ess        : 3.7686845461527505\n",
      "    val_log_marginal: 1505.4457194010417\n",
      "Train Epoch: 1019 [0/54000 (0%)] Loss: -1506.918945\n",
      "Train Epoch: 1019 [32768/54000 (61%)] Loss: -1506.952637\n",
      "    epoch          : 1019\n",
      "    loss           : -1506.2499401164505\n",
      "    ess            : 3.7693780548167677\n",
      "    log_marginal   : 1506.3750184257076\n",
      "    val_loss       : -1505.6005859375\n",
      "    val_ess        : 3.7629740238189697\n",
      "    val_log_marginal: 1505.7394612630208\n",
      "Train Epoch: 1020 [0/54000 (0%)] Loss: -1507.615234\n",
      "Train Epoch: 1020 [32768/54000 (61%)] Loss: -1505.635132\n",
      "    epoch          : 1020\n",
      "    loss           : -1506.4056903191333\n",
      "    ess            : 3.773197425986236\n",
      "    log_marginal   : 1506.529234688237\n",
      "    val_loss       : -1505.7576904296875\n",
      "    val_ess        : 3.7709662914276123\n",
      "    val_log_marginal: 1505.8890991210938\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1020.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1021 [0/54000 (0%)] Loss: -1510.320557\n",
      "Train Epoch: 1021 [32768/54000 (61%)] Loss: -1503.930786\n",
      "    epoch          : 1021\n",
      "    loss           : -1506.5173362875885\n",
      "    ess            : 3.771100988927877\n",
      "    log_marginal   : 1506.640141325177\n",
      "    val_loss       : -1505.7356974283855\n",
      "    val_ess        : 3.7557860215504966\n",
      "    val_log_marginal: 1505.8705240885417\n",
      "Train Epoch: 1022 [0/54000 (0%)] Loss: -1505.415039\n",
      "Train Epoch: 1022 [32768/54000 (61%)] Loss: -1506.534790\n",
      "    epoch          : 1022\n",
      "    loss           : -1506.7508268536262\n",
      "    ess            : 3.7713432222042442\n",
      "    log_marginal   : 1506.875004606427\n",
      "    val_loss       : -1505.8347574869792\n",
      "    val_ess        : 3.7630492051442466\n",
      "    val_log_marginal: 1505.9620157877605\n",
      "Train Epoch: 1023 [0/54000 (0%)] Loss: -1506.150635\n",
      "Train Epoch: 1023 [32768/54000 (61%)] Loss: -1506.328857\n",
      "    epoch          : 1023\n",
      "    loss           : -1506.770830262382\n",
      "    ess            : 3.774588890795438\n",
      "    log_marginal   : 1506.8946648363797\n",
      "    val_loss       : -1506.0471801757812\n",
      "    val_ess        : 3.7603516578674316\n",
      "    val_log_marginal: 1506.1811116536458\n",
      "Train Epoch: 1024 [0/54000 (0%)] Loss: -1504.247314\n",
      "Train Epoch: 1024 [32768/54000 (61%)] Loss: -1505.594971\n",
      "    epoch          : 1024\n",
      "    loss           : -1507.0211964733196\n",
      "    ess            : 3.7709974927722283\n",
      "    log_marginal   : 1507.1450586858784\n",
      "    val_loss       : -1506.644551595052\n",
      "    val_ess        : 3.777778665224711\n",
      "    val_log_marginal: 1506.7663981119792\n",
      "Train Epoch: 1025 [0/54000 (0%)] Loss: -1504.179321\n",
      "Train Epoch: 1025 [32768/54000 (61%)] Loss: -1509.093018\n",
      "    epoch          : 1025\n",
      "    loss           : -1507.1037574624115\n",
      "    ess            : 3.7700916506209463\n",
      "    log_marginal   : 1507.228692972435\n",
      "    val_loss       : -1506.257832845052\n",
      "    val_ess        : 3.7802448670069375\n",
      "    val_log_marginal: 1506.3790486653645\n",
      "Train Epoch: 1026 [0/54000 (0%)] Loss: -1508.276367\n",
      "Train Epoch: 1026 [32768/54000 (61%)] Loss: -1504.536865\n",
      "    epoch          : 1026\n",
      "    loss           : -1507.2506840543927\n",
      "    ess            : 3.7667476051258593\n",
      "    log_marginal   : 1507.3792448223762\n",
      "    val_loss       : -1506.7660522460938\n",
      "    val_ess        : 3.7619656324386597\n",
      "    val_log_marginal: 1506.8976440429688\n",
      "Train Epoch: 1027 [0/54000 (0%)] Loss: -1508.829590\n",
      "Train Epoch: 1027 [32768/54000 (61%)] Loss: -1505.507202\n",
      "    epoch          : 1027\n",
      "    loss           : -1507.387617003243\n",
      "    ess            : 3.770572585879632\n",
      "    log_marginal   : 1507.5110876695164\n",
      "    val_loss       : -1507.036865234375\n",
      "    val_ess        : 3.7777651151021323\n",
      "    val_log_marginal: 1507.1527506510417\n",
      "Train Epoch: 1028 [0/54000 (0%)] Loss: -1509.617310\n",
      "Train Epoch: 1028 [32768/54000 (61%)] Loss: -1506.339844\n",
      "    epoch          : 1028\n",
      "    loss           : -1507.4233928176593\n",
      "    ess            : 3.7666152558236754\n",
      "    log_marginal   : 1507.5504150390625\n",
      "    val_loss       : -1506.6988525390625\n",
      "    val_ess        : 3.764118194580078\n",
      "    val_log_marginal: 1506.825927734375\n",
      "Train Epoch: 1029 [0/54000 (0%)] Loss: -1507.893799\n",
      "Train Epoch: 1029 [32768/54000 (61%)] Loss: -1509.043335\n",
      "    epoch          : 1029\n",
      "    loss           : -1507.6516573923939\n",
      "    ess            : 3.7672678974439515\n",
      "    log_marginal   : 1507.7779057340802\n",
      "    val_loss       : -1507.3065388997395\n",
      "    val_ess        : 3.7657504081726074\n",
      "    val_log_marginal: 1507.4307250976562\n",
      "Train Epoch: 1030 [0/54000 (0%)] Loss: -1506.794678\n",
      "Train Epoch: 1030 [32768/54000 (61%)] Loss: -1509.033447\n",
      "    epoch          : 1030\n",
      "    loss           : -1507.6471937647407\n",
      "    ess            : 3.7656301372456102\n",
      "    log_marginal   : 1507.7754988760319\n",
      "    val_loss       : -1507.3615112304688\n",
      "    val_ess        : 3.776818792025248\n",
      "    val_log_marginal: 1507.4792887369792\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1030.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1031 [0/54000 (0%)] Loss: -1506.261719\n",
      "Train Epoch: 1031 [32768/54000 (61%)] Loss: -1506.959229\n",
      "    epoch          : 1031\n",
      "    loss           : -1507.6560035561615\n",
      "    ess            : 3.768962509227249\n",
      "    log_marginal   : 1507.78090221477\n",
      "    val_loss       : -1507.5542602539062\n",
      "    val_ess        : 3.7659026384353638\n",
      "    val_log_marginal: 1507.6935221354167\n",
      "Train Epoch: 1032 [0/54000 (0%)] Loss: -1508.945312\n",
      "Train Epoch: 1032 [32768/54000 (61%)] Loss: -1508.781982\n",
      "    epoch          : 1032\n",
      "    loss           : -1507.8095311578716\n",
      "    ess            : 3.771485018280317\n",
      "    log_marginal   : 1507.932985701651\n",
      "    val_loss       : -1507.380859375\n",
      "    val_ess        : 3.7749032179514566\n",
      "    val_log_marginal: 1507.5019938151042\n",
      "Train Epoch: 1033 [0/54000 (0%)] Loss: -1506.935425\n",
      "Train Epoch: 1033 [32768/54000 (61%)] Loss: -1506.592651\n",
      "    epoch          : 1033\n",
      "    loss           : -1507.9058054798054\n",
      "    ess            : 3.7659820295729727\n",
      "    log_marginal   : 1508.0357343565743\n",
      "    val_loss       : -1507.5836995442708\n",
      "    val_ess        : 3.7654095888137817\n",
      "    val_log_marginal: 1507.698506673177\n",
      "Train Epoch: 1034 [0/54000 (0%)] Loss: -1507.504395\n",
      "Train Epoch: 1034 [32768/54000 (61%)] Loss: -1508.078369\n",
      "    epoch          : 1034\n",
      "    loss           : -1508.1129012197819\n",
      "    ess            : 3.768537386408392\n",
      "    log_marginal   : 1508.2390482200767\n",
      "    val_loss       : -1507.467753092448\n",
      "    val_ess        : 3.771734356880188\n",
      "    val_log_marginal: 1507.59765625\n",
      "Train Epoch: 1035 [0/54000 (0%)] Loss: -1505.555176\n",
      "Train Epoch: 1035 [32768/54000 (61%)] Loss: -1508.709839\n",
      "    epoch          : 1035\n",
      "    loss           : -1508.1161464475235\n",
      "    ess            : 3.769967205119583\n",
      "    log_marginal   : 1508.24267578125\n",
      "    val_loss       : -1507.1465250651042\n",
      "    val_ess        : 3.7612256606419883\n",
      "    val_log_marginal: 1507.2730712890625\n",
      "Train Epoch: 1036 [0/54000 (0%)] Loss: -1508.104004\n",
      "Train Epoch: 1036 [32768/54000 (61%)] Loss: -1505.506958\n",
      "    epoch          : 1036\n",
      "    loss           : -1508.3138796248527\n",
      "    ess            : 3.767497584504901\n",
      "    log_marginal   : 1508.443244214328\n",
      "    val_loss       : -1507.5214233398438\n",
      "    val_ess        : 3.775789658228556\n",
      "    val_log_marginal: 1507.645731608073\n",
      "Train Epoch: 1037 [0/54000 (0%)] Loss: -1506.726562\n",
      "Train Epoch: 1037 [32768/54000 (61%)] Loss: -1508.009277\n",
      "    epoch          : 1037\n",
      "    loss           : -1508.4439282687206\n",
      "    ess            : 3.772568167380567\n",
      "    log_marginal   : 1508.5673298385907\n",
      "    val_loss       : -1507.8081665039062\n",
      "    val_ess        : 3.7691914240519204\n",
      "    val_log_marginal: 1507.9297688802083\n",
      "Train Epoch: 1038 [0/54000 (0%)] Loss: -1511.378540\n",
      "Train Epoch: 1038 [32768/54000 (61%)] Loss: -1510.676025\n",
      "    epoch          : 1038\n",
      "    loss           : -1508.6385359854069\n",
      "    ess            : 3.774332473862846\n",
      "    log_marginal   : 1508.762570938974\n",
      "    val_loss       : -1507.530008951823\n",
      "    val_ess        : 3.7881001631418862\n",
      "    val_log_marginal: 1507.648213704427\n",
      "Train Epoch: 1039 [0/54000 (0%)] Loss: -1508.521973\n",
      "Train Epoch: 1039 [32768/54000 (61%)] Loss: -1511.847900\n",
      "    epoch          : 1039\n",
      "    loss           : -1508.8025132665093\n",
      "    ess            : 3.7712872658135757\n",
      "    log_marginal   : 1508.9258457399765\n",
      "    val_loss       : -1507.5682373046875\n",
      "    val_ess        : 3.7649381160736084\n",
      "    val_log_marginal: 1507.7012125651042\n",
      "Train Epoch: 1040 [0/54000 (0%)] Loss: -1506.285767\n",
      "Train Epoch: 1040 [32768/54000 (61%)] Loss: -1511.965210\n",
      "    epoch          : 1040\n",
      "    loss           : -1508.908140938237\n",
      "    ess            : 3.7763390990923034\n",
      "    log_marginal   : 1509.0283110996463\n",
      "    val_loss       : -1507.7683715820312\n",
      "    val_ess        : 3.7627855936686196\n",
      "    val_log_marginal: 1507.8883056640625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1040.pth ...\n",
      "Train Epoch: 1041 [0/54000 (0%)] Loss: -1509.247314\n",
      "Train Epoch: 1041 [32768/54000 (61%)] Loss: -1510.571533\n",
      "    epoch          : 1041\n",
      "    loss           : -1508.8909866045105\n",
      "    ess            : 3.769140607905838\n",
      "    log_marginal   : 1509.0183128500885\n",
      "    val_loss       : -1507.7914225260417\n",
      "    val_ess        : 3.767662525177002\n",
      "    val_log_marginal: 1507.9240112304688\n",
      "Train Epoch: 1042 [0/54000 (0%)] Loss: -1512.029175\n",
      "Train Epoch: 1042 [32768/54000 (61%)] Loss: -1508.730835\n",
      "    epoch          : 1042\n",
      "    loss           : -1509.1062518425708\n",
      "    ess            : 3.7738646606229387\n",
      "    log_marginal   : 1509.2285271410672\n",
      "    val_loss       : -1507.9149780273438\n",
      "    val_ess        : 3.7554208834966025\n",
      "    val_log_marginal: 1508.0481363932292\n",
      "Train Epoch: 1043 [0/54000 (0%)] Loss: -1513.612549\n",
      "Train Epoch: 1043 [32768/54000 (61%)] Loss: -1509.560181\n",
      "    epoch          : 1043\n",
      "    loss           : -1509.0682050596993\n",
      "    ess            : 3.7736495440860964\n",
      "    log_marginal   : 1509.1899275869694\n",
      "    val_loss       : -1507.8386840820312\n",
      "    val_ess        : 3.779220978418986\n",
      "    val_log_marginal: 1507.959940592448\n",
      "Train Epoch: 1044 [0/54000 (0%)] Loss: -1506.461304\n",
      "Train Epoch: 1044 [32768/54000 (61%)] Loss: -1509.540894\n",
      "    epoch          : 1044\n",
      "    loss           : -1509.2326475899174\n",
      "    ess            : 3.7726160670226476\n",
      "    log_marginal   : 1509.3567216981132\n",
      "    val_loss       : -1508.2389322916667\n",
      "    val_ess        : 3.7692664861679077\n",
      "    val_log_marginal: 1508.3644409179688\n",
      "Train Epoch: 1045 [0/54000 (0%)] Loss: -1507.581665\n",
      "Train Epoch: 1045 [32768/54000 (61%)] Loss: -1506.524170\n",
      "    epoch          : 1045\n",
      "    loss           : -1509.2426527491157\n",
      "    ess            : 3.7700301341290743\n",
      "    log_marginal   : 1509.3695022295105\n",
      "    val_loss       : -1508.521504720052\n",
      "    val_ess        : 3.776305874188741\n",
      "    val_log_marginal: 1508.6483154296875\n",
      "Train Epoch: 1046 [0/54000 (0%)] Loss: -1506.863037\n",
      "Train Epoch: 1046 [32768/54000 (61%)] Loss: -1508.536377\n",
      "    epoch          : 1046\n",
      "    loss           : -1509.308469376474\n",
      "    ess            : 3.769900088040334\n",
      "    log_marginal   : 1509.4322624926297\n",
      "    val_loss       : -1508.59326171875\n",
      "    val_ess        : 3.7759015560150146\n",
      "    val_log_marginal: 1508.722147623698\n",
      "Train Epoch: 1047 [0/54000 (0%)] Loss: -1512.795410\n",
      "Train Epoch: 1047 [32768/54000 (61%)] Loss: -1510.759277\n",
      "    epoch          : 1047\n",
      "    loss           : -1509.4362286261792\n",
      "    ess            : 3.7691992813686155\n",
      "    log_marginal   : 1509.564126068691\n",
      "    val_loss       : -1508.676513671875\n",
      "    val_ess        : 3.7671802043914795\n",
      "    val_log_marginal: 1508.8027750651042\n",
      "Train Epoch: 1048 [0/54000 (0%)] Loss: -1512.137329\n",
      "Train Epoch: 1048 [32768/54000 (61%)] Loss: -1507.566162\n",
      "    epoch          : 1048\n",
      "    loss           : -1509.754129661704\n",
      "    ess            : 3.7692218681551375\n",
      "    log_marginal   : 1509.8821054134728\n",
      "    val_loss       : -1508.9662679036458\n",
      "    val_ess        : 3.765118877092997\n",
      "    val_log_marginal: 1509.0946858723958\n",
      "Train Epoch: 1049 [0/54000 (0%)] Loss: -1506.611206\n",
      "Train Epoch: 1049 [32768/54000 (61%)] Loss: -1507.494873\n",
      "    epoch          : 1049\n",
      "    loss           : -1509.8755412551593\n",
      "    ess            : 3.767800164672564\n",
      "    log_marginal   : 1510.0043784087559\n",
      "    val_loss       : -1509.1310221354167\n",
      "    val_ess        : 3.7734305461247764\n",
      "    val_log_marginal: 1509.2552286783855\n",
      "Train Epoch: 1050 [0/54000 (0%)] Loss: -1510.319214\n",
      "Train Epoch: 1050 [32768/54000 (61%)] Loss: -1510.794922\n",
      "    epoch          : 1050\n",
      "    loss           : -1509.9196547022407\n",
      "    ess            : 3.771016665224759\n",
      "    log_marginal   : 1510.0453917305424\n",
      "    val_loss       : -1509.4769287109375\n",
      "    val_ess        : 3.7737395763397217\n",
      "    val_log_marginal: 1509.607930501302\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1050.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1051 [0/54000 (0%)] Loss: -1512.810303\n",
      "Train Epoch: 1051 [32768/54000 (61%)] Loss: -1510.486572\n",
      "    epoch          : 1051\n",
      "    loss           : -1510.0246973577534\n",
      "    ess            : 3.7680317365898275\n",
      "    log_marginal   : 1510.1530992040093\n",
      "    val_loss       : -1509.1885986328125\n",
      "    val_ess        : 3.767571489016215\n",
      "    val_log_marginal: 1509.3123779296875\n",
      "Train Epoch: 1052 [0/54000 (0%)] Loss: -1507.948242\n",
      "Train Epoch: 1052 [32768/54000 (61%)] Loss: -1508.033936\n",
      "    epoch          : 1052\n",
      "    loss           : -1510.1174707952534\n",
      "    ess            : 3.7692744237072064\n",
      "    log_marginal   : 1510.2461375110554\n",
      "    val_loss       : -1508.9830729166667\n",
      "    val_ess        : 3.7686120669047036\n",
      "    val_log_marginal: 1509.1087239583333\n",
      "Train Epoch: 1053 [0/54000 (0%)] Loss: -1509.916138\n",
      "Train Epoch: 1053 [32768/54000 (61%)] Loss: -1510.842285\n",
      "    epoch          : 1053\n",
      "    loss           : -1510.2106058372642\n",
      "    ess            : 3.7727871256054573\n",
      "    log_marginal   : 1510.3324297059257\n",
      "    val_loss       : -1509.2320556640625\n",
      "    val_ess        : 3.770461678504944\n",
      "    val_log_marginal: 1509.3601888020833\n",
      "Train Epoch: 1054 [0/54000 (0%)] Loss: -1510.022339\n",
      "Train Epoch: 1054 [32768/54000 (61%)] Loss: -1513.047363\n",
      "    epoch          : 1054\n",
      "    loss           : -1510.3291959942512\n",
      "    ess            : 3.772329762296857\n",
      "    log_marginal   : 1510.4546266951652\n",
      "    val_loss       : -1509.2280680338542\n",
      "    val_ess        : 3.7670392195383706\n",
      "    val_log_marginal: 1509.360331217448\n",
      "Train Epoch: 1055 [0/54000 (0%)] Loss: -1509.562988\n",
      "Train Epoch: 1055 [32768/54000 (61%)] Loss: -1508.635742\n",
      "    epoch          : 1055\n",
      "    loss           : -1510.5306626805718\n",
      "    ess            : 3.7697065416372046\n",
      "    log_marginal   : 1510.6560358011498\n",
      "    val_loss       : -1509.1974283854167\n",
      "    val_ess        : 3.774852434794108\n",
      "    val_log_marginal: 1509.324971516927\n",
      "Train Epoch: 1056 [0/54000 (0%)] Loss: -1511.308594\n",
      "Train Epoch: 1056 [32768/54000 (61%)] Loss: -1512.234253\n",
      "    epoch          : 1056\n",
      "    loss           : -1510.618081146816\n",
      "    ess            : 3.7744894252633148\n",
      "    log_marginal   : 1510.7422865381782\n",
      "    val_loss       : -1509.4822387695312\n",
      "    val_ess        : 3.764467716217041\n",
      "    val_log_marginal: 1509.614278157552\n",
      "Train Epoch: 1057 [0/54000 (0%)] Loss: -1507.879395\n",
      "Train Epoch: 1057 [32768/54000 (61%)] Loss: -1513.950195\n",
      "    epoch          : 1057\n",
      "    loss           : -1510.6412583836968\n",
      "    ess            : 3.7716892980179697\n",
      "    log_marginal   : 1510.7668848577534\n",
      "    val_loss       : -1509.4319458007812\n",
      "    val_ess        : 3.7745925188064575\n",
      "    val_log_marginal: 1509.5529174804688\n",
      "Train Epoch: 1058 [0/54000 (0%)] Loss: -1511.393555\n",
      "Train Epoch: 1058 [32768/54000 (61%)] Loss: -1509.218628\n",
      "    epoch          : 1058\n",
      "    loss           : -1510.826337706368\n",
      "    ess            : 3.7724896376987673\n",
      "    log_marginal   : 1510.952153043927\n",
      "    val_loss       : -1509.995137532552\n",
      "    val_ess        : 3.7817628383636475\n",
      "    val_log_marginal: 1510.1178792317708\n",
      "Train Epoch: 1059 [0/54000 (0%)] Loss: -1515.005371\n",
      "Train Epoch: 1059 [32768/54000 (61%)] Loss: -1511.592773\n",
      "    epoch          : 1059\n",
      "    loss           : -1510.8816171322228\n",
      "    ess            : 3.7686036757703096\n",
      "    log_marginal   : 1511.0123037662147\n",
      "    val_loss       : -1509.8612060546875\n",
      "    val_ess        : 3.7627488374710083\n",
      "    val_log_marginal: 1509.995340983073\n",
      "Train Epoch: 1060 [0/54000 (0%)] Loss: -1510.955078\n",
      "Train Epoch: 1060 [32768/54000 (61%)] Loss: -1510.569214\n",
      "    epoch          : 1060\n",
      "    loss           : -1511.0262612396816\n",
      "    ess            : 3.7696417997468195\n",
      "    log_marginal   : 1511.1522562278892\n",
      "    val_loss       : -1509.9205932617188\n",
      "    val_ess        : 3.758891463279724\n",
      "    val_log_marginal: 1510.0564982096355\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1060.pth ...\n",
      "Train Epoch: 1061 [0/54000 (0%)] Loss: -1510.387207\n",
      "Train Epoch: 1061 [32768/54000 (61%)] Loss: -1509.802490\n",
      "    epoch          : 1061\n",
      "    loss           : -1511.2353745946343\n",
      "    ess            : 3.7679508542114832\n",
      "    log_marginal   : 1511.3657341723172\n",
      "    val_loss       : -1510.1572265625\n",
      "    val_ess        : 3.771681825319926\n",
      "    val_log_marginal: 1510.2914428710938\n",
      "Train Epoch: 1062 [0/54000 (0%)] Loss: -1511.956055\n",
      "Train Epoch: 1062 [32768/54000 (61%)] Loss: -1512.231445\n",
      "    epoch          : 1062\n",
      "    loss           : -1511.211732108638\n",
      "    ess            : 3.770742007021634\n",
      "    log_marginal   : 1511.337029223172\n",
      "    val_loss       : -1510.0984497070312\n",
      "    val_ess        : 3.763383626937866\n",
      "    val_log_marginal: 1510.2239379882812\n",
      "Train Epoch: 1063 [0/54000 (0%)] Loss: -1512.999023\n",
      "Train Epoch: 1063 [32768/54000 (61%)] Loss: -1513.503540\n",
      "    epoch          : 1063\n",
      "    loss           : -1511.3012971698113\n",
      "    ess            : 3.770939386115884\n",
      "    log_marginal   : 1511.4274625958137\n",
      "    val_loss       : -1510.6478474934895\n",
      "    val_ess        : 3.7645347913106284\n",
      "    val_log_marginal: 1510.7807006835938\n",
      "Train Epoch: 1064 [0/54000 (0%)] Loss: -1509.786865\n",
      "Train Epoch: 1064 [32768/54000 (61%)] Loss: -1512.388428\n",
      "    epoch          : 1064\n",
      "    loss           : -1511.5826738465507\n",
      "    ess            : 3.7705014156845382\n",
      "    log_marginal   : 1511.7095049012382\n",
      "    val_loss       : -1510.4043375651042\n",
      "    val_ess        : 3.7650641997655234\n",
      "    val_log_marginal: 1510.5299479166667\n",
      "Train Epoch: 1065 [0/54000 (0%)] Loss: -1511.731689\n",
      "Train Epoch: 1065 [32768/54000 (61%)] Loss: -1514.054932\n",
      "    epoch          : 1065\n",
      "    loss           : -1511.5206989792157\n",
      "    ess            : 3.771323613400729\n",
      "    log_marginal   : 1511.6490616708431\n",
      "    val_loss       : -1510.7984008789062\n",
      "    val_ess        : 3.763927181561788\n",
      "    val_log_marginal: 1510.9281005859375\n",
      "Train Epoch: 1066 [0/54000 (0%)] Loss: -1513.422119\n",
      "Train Epoch: 1066 [32768/54000 (61%)] Loss: -1511.721313\n",
      "    epoch          : 1066\n",
      "    loss           : -1511.6293346477005\n",
      "    ess            : 3.7692522192901037\n",
      "    log_marginal   : 1511.7528214364681\n",
      "    val_loss       : -1510.258524576823\n",
      "    val_ess        : 3.7737462520599365\n",
      "    val_log_marginal: 1510.3941650390625\n",
      "Train Epoch: 1067 [0/54000 (0%)] Loss: -1511.847412\n",
      "Train Epoch: 1067 [32768/54000 (61%)] Loss: -1513.931885\n",
      "    epoch          : 1067\n",
      "    loss           : -1511.6963028817806\n",
      "    ess            : 3.7767099659397916\n",
      "    log_marginal   : 1511.8203217128537\n",
      "    val_loss       : -1510.256571451823\n",
      "    val_ess        : 3.7675618728001914\n",
      "    val_log_marginal: 1510.3812866210938\n",
      "Train Epoch: 1068 [0/54000 (0%)] Loss: -1512.463989\n",
      "Train Epoch: 1068 [32768/54000 (61%)] Loss: -1511.800537\n",
      "    epoch          : 1068\n",
      "    loss           : -1511.68310546875\n",
      "    ess            : 3.7695894511240833\n",
      "    log_marginal   : 1511.8093653265034\n",
      "    val_loss       : -1510.7369791666667\n",
      "    val_ess        : 3.77526863416036\n",
      "    val_log_marginal: 1510.8609008789062\n",
      "Train Epoch: 1069 [0/54000 (0%)] Loss: -1513.674194\n",
      "Train Epoch: 1069 [32768/54000 (61%)] Loss: -1511.342529\n",
      "    epoch          : 1069\n",
      "    loss           : -1511.8469353441922\n",
      "    ess            : 3.7728522228744796\n",
      "    log_marginal   : 1511.97509765625\n",
      "    val_loss       : -1510.75146484375\n",
      "    val_ess        : 3.7747710943222046\n",
      "    val_log_marginal: 1510.8832194010417\n",
      "Train Epoch: 1070 [0/54000 (0%)] Loss: -1509.119019\n",
      "Train Epoch: 1070 [32768/54000 (61%)] Loss: -1512.841187\n",
      "    epoch          : 1070\n",
      "    loss           : -1511.9132241303066\n",
      "    ess            : 3.7687578381232494\n",
      "    log_marginal   : 1512.0417457436615\n",
      "    val_loss       : -1511.177978515625\n",
      "    val_ess        : 3.768911918004354\n",
      "    val_log_marginal: 1511.301045735677\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1070.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1071 [0/54000 (0%)] Loss: -1512.960938\n",
      "Train Epoch: 1071 [32768/54000 (61%)] Loss: -1508.133423\n",
      "    epoch          : 1071\n",
      "    loss           : -1512.0897424086086\n",
      "    ess            : 3.7718104506438634\n",
      "    log_marginal   : 1512.2147101636203\n",
      "    val_loss       : -1511.1862386067708\n",
      "    val_ess        : 3.767290393511454\n",
      "    val_log_marginal: 1511.321512858073\n",
      "Train Epoch: 1072 [0/54000 (0%)] Loss: -1511.884033\n",
      "Train Epoch: 1072 [32768/54000 (61%)] Loss: -1511.923584\n",
      "    epoch          : 1072\n",
      "    loss           : -1512.3477668042453\n",
      "    ess            : 3.7692678919378317\n",
      "    log_marginal   : 1512.4753970739976\n",
      "    val_loss       : -1511.266866048177\n",
      "    val_ess        : 3.765523592631022\n",
      "    val_log_marginal: 1511.3950805664062\n",
      "Train Epoch: 1073 [0/54000 (0%)] Loss: -1514.279175\n",
      "Train Epoch: 1073 [32768/54000 (61%)] Loss: -1512.346191\n",
      "    epoch          : 1073\n",
      "    loss           : -1512.363930756191\n",
      "    ess            : 3.7704617212403497\n",
      "    log_marginal   : 1512.4908216944282\n",
      "    val_loss       : -1511.4828287760417\n",
      "    val_ess        : 3.777846932411194\n",
      "    val_log_marginal: 1511.5946248372395\n",
      "Train Epoch: 1074 [0/54000 (0%)] Loss: -1512.539307\n",
      "Train Epoch: 1074 [32768/54000 (61%)] Loss: -1515.703247\n",
      "    epoch          : 1074\n",
      "    loss           : -1512.498696381191\n",
      "    ess            : 3.7727555688822045\n",
      "    log_marginal   : 1512.6222960274174\n",
      "    val_loss       : -1511.5246988932292\n",
      "    val_ess        : 3.7720313469568887\n",
      "    val_log_marginal: 1511.6552124023438\n",
      "Train Epoch: 1075 [0/54000 (0%)] Loss: -1510.248535\n",
      "Train Epoch: 1075 [32768/54000 (61%)] Loss: -1512.950317\n",
      "    epoch          : 1075\n",
      "    loss           : -1512.6555429134728\n",
      "    ess            : 3.771389070546852\n",
      "    log_marginal   : 1512.7845412920105\n",
      "    val_loss       : -1511.85693359375\n",
      "    val_ess        : 3.7774494886398315\n",
      "    val_log_marginal: 1511.9744873046875\n",
      "Train Epoch: 1076 [0/54000 (0%)] Loss: -1514.133545\n",
      "Train Epoch: 1076 [32768/54000 (61%)] Loss: -1513.641602\n",
      "    epoch          : 1076\n",
      "    loss           : -1512.7085237323113\n",
      "    ess            : 3.7726372502884775\n",
      "    log_marginal   : 1512.833012418927\n",
      "    val_loss       : -1512.1690470377605\n",
      "    val_ess        : 3.7783451875050864\n",
      "    val_log_marginal: 1512.291280110677\n",
      "Train Epoch: 1077 [0/54000 (0%)] Loss: -1514.827637\n",
      "Train Epoch: 1077 [32768/54000 (61%)] Loss: -1512.147461\n",
      "    epoch          : 1077\n",
      "    loss           : -1512.8860807598762\n",
      "    ess            : 3.77580848279989\n",
      "    log_marginal   : 1513.009588277565\n",
      "    val_loss       : -1512.1541748046875\n",
      "    val_ess        : 3.7756093740463257\n",
      "    val_log_marginal: 1512.274434407552\n",
      "Train Epoch: 1078 [0/54000 (0%)] Loss: -1513.378174\n",
      "Train Epoch: 1078 [32768/54000 (61%)] Loss: -1513.996826\n",
      "    epoch          : 1078\n",
      "    loss           : -1512.8921704562206\n",
      "    ess            : 3.772239235212218\n",
      "    log_marginal   : 1513.0178591170402\n",
      "    val_loss       : -1512.181660970052\n",
      "    val_ess        : 3.7631485064824424\n",
      "    val_log_marginal: 1512.3157958984375\n",
      "Train Epoch: 1079 [0/54000 (0%)] Loss: -1516.483154\n",
      "Train Epoch: 1079 [32768/54000 (61%)] Loss: -1511.327637\n",
      "    epoch          : 1079\n",
      "    loss           : -1512.8893927808078\n",
      "    ess            : 3.7745384720136537\n",
      "    log_marginal   : 1513.0144365418632\n",
      "    val_loss       : -1512.3143717447917\n",
      "    val_ess        : 3.769393563270569\n",
      "    val_log_marginal: 1512.4434000651042\n",
      "Train Epoch: 1080 [0/54000 (0%)] Loss: -1514.545654\n",
      "Train Epoch: 1080 [32768/54000 (61%)] Loss: -1513.489502\n",
      "    epoch          : 1080\n",
      "    loss           : -1513.1403877690154\n",
      "    ess            : 3.77604915061087\n",
      "    log_marginal   : 1513.2624166236733\n",
      "    val_loss       : -1512.5841267903645\n",
      "    val_ess        : 3.767943104108175\n",
      "    val_log_marginal: 1512.7156982421875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1080.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1081 [0/54000 (0%)] Loss: -1515.190674\n",
      "Train Epoch: 1081 [32768/54000 (61%)] Loss: -1513.446777\n",
      "    epoch          : 1081\n",
      "    loss           : -1513.2232320533608\n",
      "    ess            : 3.776960309946312\n",
      "    log_marginal   : 1513.3478128685142\n",
      "    val_loss       : -1512.5718180338542\n",
      "    val_ess        : 3.766122063000997\n",
      "    val_log_marginal: 1512.7150472005208\n",
      "Train Epoch: 1082 [0/54000 (0%)] Loss: -1514.072510\n",
      "Train Epoch: 1082 [32768/54000 (61%)] Loss: -1512.778809\n",
      "    epoch          : 1082\n",
      "    loss           : -1513.3584007407135\n",
      "    ess            : 3.7772250220460712\n",
      "    log_marginal   : 1513.4795797096108\n",
      "    val_loss       : -1512.398457845052\n",
      "    val_ess        : 3.772324522336324\n",
      "    val_log_marginal: 1512.5254516601562\n",
      "Train Epoch: 1083 [0/54000 (0%)] Loss: -1513.967896\n",
      "Train Epoch: 1083 [32768/54000 (61%)] Loss: -1511.764893\n",
      "    epoch          : 1083\n",
      "    loss           : -1513.4350148326946\n",
      "    ess            : 3.7758833732245103\n",
      "    log_marginal   : 1513.5571772737323\n",
      "    val_loss       : -1512.3702392578125\n",
      "    val_ess        : 3.773595849672953\n",
      "    val_log_marginal: 1512.4922485351562\n",
      "Train Epoch: 1084 [0/54000 (0%)] Loss: -1514.144531\n",
      "Train Epoch: 1084 [32768/54000 (61%)] Loss: -1515.122070\n",
      "    epoch          : 1084\n",
      "    loss           : -1513.5904494951355\n",
      "    ess            : 3.7739635683455557\n",
      "    log_marginal   : 1513.7164076319282\n",
      "    val_loss       : -1512.4758911132812\n",
      "    val_ess        : 3.782625158627828\n",
      "    val_log_marginal: 1512.5997721354167\n",
      "Train Epoch: 1085 [0/54000 (0%)] Loss: -1517.998291\n",
      "Train Epoch: 1085 [32768/54000 (61%)] Loss: -1515.838867\n",
      "    epoch          : 1085\n",
      "    loss           : -1513.7011235075177\n",
      "    ess            : 3.779947375351528\n",
      "    log_marginal   : 1513.824442161704\n",
      "    val_loss       : -1512.844482421875\n",
      "    val_ess        : 3.778897762298584\n",
      "    val_log_marginal: 1512.9691772460938\n",
      "Train Epoch: 1086 [0/54000 (0%)] Loss: -1516.360596\n",
      "Train Epoch: 1086 [32768/54000 (61%)] Loss: -1513.812500\n",
      "    epoch          : 1086\n",
      "    loss           : -1513.7024824034493\n",
      "    ess            : 3.770387091726627\n",
      "    log_marginal   : 1513.8273557267098\n",
      "    val_loss       : -1512.5906575520833\n",
      "    val_ess        : 3.7642129262288413\n",
      "    val_log_marginal: 1512.7301025390625\n",
      "Train Epoch: 1087 [0/54000 (0%)] Loss: -1515.072510\n",
      "Train Epoch: 1087 [32768/54000 (61%)] Loss: -1514.985962\n",
      "    epoch          : 1087\n",
      "    loss           : -1513.759219763414\n",
      "    ess            : 3.7714178067333295\n",
      "    log_marginal   : 1513.8853299122936\n",
      "    val_loss       : -1512.980224609375\n",
      "    val_ess        : 3.7717464367548623\n",
      "    val_log_marginal: 1513.109395345052\n",
      "Train Epoch: 1088 [0/54000 (0%)] Loss: -1516.482788\n",
      "Train Epoch: 1088 [32768/54000 (61%)] Loss: -1513.398682\n",
      "    epoch          : 1088\n",
      "    loss           : -1513.8539900869694\n",
      "    ess            : 3.7707148452974715\n",
      "    log_marginal   : 1513.9803950471698\n",
      "    val_loss       : -1513.1363932291667\n",
      "    val_ess        : 3.786699374516805\n",
      "    val_log_marginal: 1513.2484334309895\n",
      "Train Epoch: 1089 [0/54000 (0%)] Loss: -1516.278442\n",
      "Train Epoch: 1089 [32768/54000 (61%)] Loss: -1511.463135\n",
      "    epoch          : 1089\n",
      "    loss           : -1513.9378546948703\n",
      "    ess            : 3.773671802484764\n",
      "    log_marginal   : 1514.0633452793338\n",
      "    val_loss       : -1513.1621907552083\n",
      "    val_ess        : 3.7800341049830117\n",
      "    val_log_marginal: 1513.2857462565105\n",
      "Train Epoch: 1090 [0/54000 (0%)] Loss: -1515.265381\n",
      "Train Epoch: 1090 [32768/54000 (61%)] Loss: -1513.537354\n",
      "    epoch          : 1090\n",
      "    loss           : -1513.9975816258843\n",
      "    ess            : 3.771299272213342\n",
      "    log_marginal   : 1514.125872917895\n",
      "    val_loss       : -1513.3196207682292\n",
      "    val_ess        : 3.7662747303644815\n",
      "    val_log_marginal: 1513.4540405273438\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1090.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1091 [0/54000 (0%)] Loss: -1513.933105\n",
      "Train Epoch: 1091 [32768/54000 (61%)] Loss: -1511.356445\n",
      "    epoch          : 1091\n",
      "    loss           : -1514.1672225088444\n",
      "    ess            : 3.772478499502506\n",
      "    log_marginal   : 1514.289285911704\n",
      "    val_loss       : -1513.5854085286458\n",
      "    val_ess        : 3.7726892630259194\n",
      "    val_log_marginal: 1513.7005615234375\n",
      "Train Epoch: 1092 [0/54000 (0%)] Loss: -1510.386597\n",
      "Train Epoch: 1092 [32768/54000 (61%)] Loss: -1515.387939\n",
      "    epoch          : 1092\n",
      "    loss           : -1514.2816254237912\n",
      "    ess            : 3.773963397403933\n",
      "    log_marginal   : 1514.4057755380306\n",
      "    val_loss       : -1514.1039428710938\n",
      "    val_ess        : 3.7889033953348794\n",
      "    val_log_marginal: 1514.2144775390625\n",
      "Train Epoch: 1093 [0/54000 (0%)] Loss: -1516.700439\n",
      "Train Epoch: 1093 [32768/54000 (61%)] Loss: -1515.846069\n",
      "    epoch          : 1093\n",
      "    loss           : -1514.4148432893573\n",
      "    ess            : 3.774943563173402\n",
      "    log_marginal   : 1514.5360475936027\n",
      "    val_loss       : -1513.8769124348958\n",
      "    val_ess        : 3.7826650142669678\n",
      "    val_log_marginal: 1513.9902954101562\n",
      "Train Epoch: 1094 [0/54000 (0%)] Loss: -1516.018433\n",
      "Train Epoch: 1094 [32768/54000 (61%)] Loss: -1511.754517\n",
      "    epoch          : 1094\n",
      "    loss           : -1514.4823735075177\n",
      "    ess            : 3.7748002646104344\n",
      "    log_marginal   : 1514.6044161814564\n",
      "    val_loss       : -1514.127909342448\n",
      "    val_ess        : 3.7794138193130493\n",
      "    val_log_marginal: 1514.2496541341145\n",
      "Train Epoch: 1095 [0/54000 (0%)] Loss: -1515.836670\n",
      "Train Epoch: 1095 [32768/54000 (61%)] Loss: -1516.248413\n",
      "    epoch          : 1095\n",
      "    loss           : -1514.4892923607017\n",
      "    ess            : 3.7694826980806746\n",
      "    log_marginal   : 1514.6159368551002\n",
      "    val_loss       : -1514.0\n",
      "    val_ess        : 3.7738435665766397\n",
      "    val_log_marginal: 1514.1314900716145\n",
      "Train Epoch: 1096 [0/54000 (0%)] Loss: -1515.779297\n",
      "Train Epoch: 1096 [32768/54000 (61%)] Loss: -1517.244507\n",
      "    epoch          : 1096\n",
      "    loss           : -1514.6321353552476\n",
      "    ess            : 3.7719943658360897\n",
      "    log_marginal   : 1514.76025390625\n",
      "    val_loss       : -1514.1825358072917\n",
      "    val_ess        : 3.770773450533549\n",
      "    val_log_marginal: 1514.318135579427\n",
      "Train Epoch: 1097 [0/54000 (0%)] Loss: -1516.712891\n",
      "Train Epoch: 1097 [32768/54000 (61%)] Loss: -1515.270630\n",
      "    epoch          : 1097\n",
      "    loss           : -1514.7227990492336\n",
      "    ess            : 3.7706051592556937\n",
      "    log_marginal   : 1514.8493099572524\n",
      "    val_loss       : -1514.0205485026042\n",
      "    val_ess        : 3.763222813606262\n",
      "    val_log_marginal: 1514.1413167317708\n",
      "Train Epoch: 1098 [0/54000 (0%)] Loss: -1514.354614\n",
      "Train Epoch: 1098 [32768/54000 (61%)] Loss: -1516.234619\n",
      "    epoch          : 1098\n",
      "    loss           : -1514.825377266362\n",
      "    ess            : 3.7744960470019646\n",
      "    log_marginal   : 1514.9478068801593\n",
      "    val_loss       : -1513.6381225585938\n",
      "    val_ess        : 3.7588655948638916\n",
      "    val_log_marginal: 1513.7755737304688\n",
      "Train Epoch: 1099 [0/54000 (0%)] Loss: -1514.135620\n",
      "Train Epoch: 1099 [32768/54000 (61%)] Loss: -1515.998535\n",
      "    epoch          : 1099\n",
      "    loss           : -1514.8701517357017\n",
      "    ess            : 3.7700827391642444\n",
      "    log_marginal   : 1514.9982887124115\n",
      "    val_loss       : -1514.2445271809895\n",
      "    val_ess        : 3.773432731628418\n",
      "    val_log_marginal: 1514.3691813151042\n",
      "Train Epoch: 1100 [0/54000 (0%)] Loss: -1516.615601\n",
      "Train Epoch: 1100 [32768/54000 (61%)] Loss: -1515.173462\n",
      "    epoch          : 1100\n",
      "    loss           : -1515.0239073555424\n",
      "    ess            : 3.7731655948566942\n",
      "    log_marginal   : 1515.1493703014446\n",
      "    val_loss       : -1514.4366861979167\n",
      "    val_ess        : 3.7793334325154624\n",
      "    val_log_marginal: 1514.5606486002605\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1100.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1101 [0/54000 (0%)] Loss: -1520.450195\n",
      "Train Epoch: 1101 [32768/54000 (61%)] Loss: -1512.167480\n",
      "    epoch          : 1101\n",
      "    loss           : -1515.0122669147995\n",
      "    ess            : 3.770085465233281\n",
      "    log_marginal   : 1515.13811680056\n",
      "    val_loss       : -1514.5486246744792\n",
      "    val_ess        : 3.778757929801941\n",
      "    val_log_marginal: 1514.678690592448\n",
      "Train Epoch: 1102 [0/54000 (0%)] Loss: -1514.409424\n",
      "Train Epoch: 1102 [32768/54000 (61%)] Loss: -1517.056396\n",
      "    epoch          : 1102\n",
      "    loss           : -1515.0618228552476\n",
      "    ess            : 3.7709872137825444\n",
      "    log_marginal   : 1515.1885686910377\n",
      "    val_loss       : -1514.4030354817708\n",
      "    val_ess        : 3.7739441792170205\n",
      "    val_log_marginal: 1514.5238037109375\n",
      "Train Epoch: 1103 [0/54000 (0%)] Loss: -1516.712891\n",
      "Train Epoch: 1103 [32768/54000 (61%)] Loss: -1518.704712\n",
      "    epoch          : 1103\n",
      "    loss           : -1515.29575794148\n",
      "    ess            : 3.770536832089694\n",
      "    log_marginal   : 1515.4226258475826\n",
      "    val_loss       : -1514.212381998698\n",
      "    val_ess        : 3.7702670097351074\n",
      "    val_log_marginal: 1514.3399047851562\n",
      "Train Epoch: 1104 [0/54000 (0%)] Loss: -1516.942261\n",
      "Train Epoch: 1104 [32768/54000 (61%)] Loss: -1516.149292\n",
      "    epoch          : 1104\n",
      "    loss           : -1515.4703138819282\n",
      "    ess            : 3.773330823430475\n",
      "    log_marginal   : 1515.5968340028007\n",
      "    val_loss       : -1514.3523559570312\n",
      "    val_ess        : 3.7856568098068237\n",
      "    val_log_marginal: 1514.4698689778645\n",
      "Train Epoch: 1105 [0/54000 (0%)] Loss: -1515.104370\n",
      "Train Epoch: 1105 [32768/54000 (61%)] Loss: -1512.595459\n",
      "    epoch          : 1105\n",
      "    loss           : -1515.4549560546875\n",
      "    ess            : 3.7728609498941674\n",
      "    log_marginal   : 1515.5822201135024\n",
      "    val_loss       : -1514.6110026041667\n",
      "    val_ess        : 3.771461089452108\n",
      "    val_log_marginal: 1514.7431030273438\n",
      "Train Epoch: 1106 [0/54000 (0%)] Loss: -1517.083252\n",
      "Train Epoch: 1106 [32768/54000 (61%)] Loss: -1513.841797\n",
      "    epoch          : 1106\n",
      "    loss           : -1515.6353920990566\n",
      "    ess            : 3.773330814433548\n",
      "    log_marginal   : 1515.7625156618515\n",
      "    val_loss       : -1514.9440307617188\n",
      "    val_ess        : 3.7683713833491006\n",
      "    val_log_marginal: 1515.0702107747395\n",
      "Train Epoch: 1107 [0/54000 (0%)] Loss: -1516.038452\n",
      "Train Epoch: 1107 [32768/54000 (61%)] Loss: -1515.444092\n",
      "    epoch          : 1107\n",
      "    loss           : -1515.6639150943397\n",
      "    ess            : 3.7689793334816986\n",
      "    log_marginal   : 1515.7938600936027\n",
      "    val_loss       : -1514.942606608073\n",
      "    val_ess        : 3.7872968514760337\n",
      "    val_log_marginal: 1515.0633138020833\n",
      "Train Epoch: 1108 [0/54000 (0%)] Loss: -1514.562012\n",
      "Train Epoch: 1108 [32768/54000 (61%)] Loss: -1513.000122\n",
      "    epoch          : 1108\n",
      "    loss           : -1515.8243062721108\n",
      "    ess            : 3.7704657518638753\n",
      "    log_marginal   : 1515.9541338074882\n",
      "    val_loss       : -1515.0525716145833\n",
      "    val_ess        : 3.7775718371073403\n",
      "    val_log_marginal: 1515.1786702473958\n",
      "Train Epoch: 1109 [0/54000 (0%)] Loss: -1518.872559\n",
      "Train Epoch: 1109 [32768/54000 (61%)] Loss: -1514.245728\n",
      "    epoch          : 1109\n",
      "    loss           : -1515.7774934588738\n",
      "    ess            : 3.770741300762824\n",
      "    log_marginal   : 1515.9046838148586\n",
      "    val_loss       : -1514.8111165364583\n",
      "    val_ess        : 3.788516084353129\n",
      "    val_log_marginal: 1514.9316813151042\n",
      "Train Epoch: 1110 [0/54000 (0%)] Loss: -1517.478516\n",
      "Train Epoch: 1110 [32768/54000 (61%)] Loss: -1516.259155\n",
      "    epoch          : 1110\n",
      "    loss           : -1515.8095680092865\n",
      "    ess            : 3.7692932542764916\n",
      "    log_marginal   : 1515.9388082252358\n",
      "    val_loss       : -1514.982666015625\n",
      "    val_ess        : 3.7720444202423096\n",
      "    val_log_marginal: 1515.1004842122395\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1110.pth ...\n",
      "Train Epoch: 1111 [0/54000 (0%)] Loss: -1517.828125\n",
      "Train Epoch: 1111 [32768/54000 (61%)] Loss: -1518.452271\n",
      "    epoch          : 1111\n",
      "    loss           : -1515.958380933078\n",
      "    ess            : 3.771126189321842\n",
      "    log_marginal   : 1516.0857163915093\n",
      "    val_loss       : -1515.424092610677\n",
      "    val_ess        : 3.78348700205485\n",
      "    val_log_marginal: 1515.5439860026042\n",
      "Train Epoch: 1112 [0/54000 (0%)] Loss: -1517.796387\n",
      "Train Epoch: 1112 [32768/54000 (61%)] Loss: -1518.977295\n",
      "    epoch          : 1112\n",
      "    loss           : -1516.0309828272407\n",
      "    ess            : 3.7688483966971345\n",
      "    log_marginal   : 1516.1600963664505\n",
      "    val_loss       : -1515.2637736002605\n",
      "    val_ess        : 3.772372762362162\n",
      "    val_log_marginal: 1515.3974609375\n",
      "Train Epoch: 1113 [0/54000 (0%)] Loss: -1515.046875\n",
      "Train Epoch: 1113 [32768/54000 (61%)] Loss: -1517.917236\n",
      "    epoch          : 1113\n",
      "    loss           : -1516.0773280881485\n",
      "    ess            : 3.7718510492792667\n",
      "    log_marginal   : 1516.2037675965507\n",
      "    val_loss       : -1515.0656127929688\n",
      "    val_ess        : 3.7619991302490234\n",
      "    val_log_marginal: 1515.2003580729167\n",
      "Train Epoch: 1114 [0/54000 (0%)] Loss: -1516.433105\n",
      "Train Epoch: 1114 [32768/54000 (61%)] Loss: -1515.345825\n",
      "    epoch          : 1114\n",
      "    loss           : -1516.0466055240272\n",
      "    ess            : 3.7738785293867005\n",
      "    log_marginal   : 1516.1710688752948\n",
      "    val_loss       : -1515.3562418619792\n",
      "    val_ess        : 3.7689884503682456\n",
      "    val_log_marginal: 1515.485616048177\n",
      "Train Epoch: 1115 [0/54000 (0%)] Loss: -1514.990723\n",
      "Train Epoch: 1115 [32768/54000 (61%)] Loss: -1518.015137\n",
      "    epoch          : 1115\n",
      "    loss           : -1516.2185496204304\n",
      "    ess            : 3.767532420608233\n",
      "    log_marginal   : 1516.3498419995578\n",
      "    val_loss       : -1515.3071899414062\n",
      "    val_ess        : 3.761806527773539\n",
      "    val_log_marginal: 1515.4466756184895\n",
      "Train Epoch: 1116 [0/54000 (0%)] Loss: -1516.100464\n",
      "Train Epoch: 1116 [32768/54000 (61%)] Loss: -1514.495605\n",
      "    epoch          : 1116\n",
      "    loss           : -1516.305254090507\n",
      "    ess            : 3.7697732313623966\n",
      "    log_marginal   : 1516.4350816258843\n",
      "    val_loss       : -1515.3738810221355\n",
      "    val_ess        : 3.773768941561381\n",
      "    val_log_marginal: 1515.5046997070312\n",
      "Train Epoch: 1117 [0/54000 (0%)] Loss: -1518.935059\n",
      "Train Epoch: 1117 [32768/54000 (61%)] Loss: -1517.604736\n",
      "    epoch          : 1117\n",
      "    loss           : -1516.3960099130306\n",
      "    ess            : 3.7756628765250153\n",
      "    log_marginal   : 1516.5194229989681\n",
      "    val_loss       : -1515.4990641276042\n",
      "    val_ess        : 3.7787152926127114\n",
      "    val_log_marginal: 1515.6222534179688\n",
      "Train Epoch: 1118 [0/54000 (0%)] Loss: -1516.736328\n",
      "Train Epoch: 1118 [32768/54000 (61%)] Loss: -1517.144043\n",
      "    epoch          : 1118\n",
      "    loss           : -1516.3858389224647\n",
      "    ess            : 3.7736831790996046\n",
      "    log_marginal   : 1516.5121793926887\n",
      "    val_loss       : -1515.917215983073\n",
      "    val_ess        : 3.772488077481588\n",
      "    val_log_marginal: 1516.0552775065105\n",
      "Train Epoch: 1119 [0/54000 (0%)] Loss: -1515.971802\n",
      "Train Epoch: 1119 [32768/54000 (61%)] Loss: -1516.440186\n",
      "    epoch          : 1119\n",
      "    loss           : -1516.6462563568691\n",
      "    ess            : 3.773704713245608\n",
      "    log_marginal   : 1516.7728616966392\n",
      "    val_loss       : -1516.1832885742188\n",
      "    val_ess        : 3.773520270983378\n",
      "    val_log_marginal: 1516.315185546875\n",
      "Train Epoch: 1120 [0/54000 (0%)] Loss: -1517.496704\n",
      "Train Epoch: 1120 [32768/54000 (61%)] Loss: -1519.583862\n",
      "    epoch          : 1120\n",
      "    loss           : -1516.867613594487\n",
      "    ess            : 3.7722414664502413\n",
      "    log_marginal   : 1516.9944446491745\n",
      "    val_loss       : -1515.9895629882812\n",
      "    val_ess        : 3.7648867766062417\n",
      "    val_log_marginal: 1516.1128540039062\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1120.pth ...\n",
      "Train Epoch: 1121 [0/54000 (0%)] Loss: -1516.192871\n",
      "Train Epoch: 1121 [32768/54000 (61%)] Loss: -1516.656982\n",
      "    epoch          : 1121\n",
      "    loss           : -1516.9541522331958\n",
      "    ess            : 3.7729590973764098\n",
      "    log_marginal   : 1517.081969063237\n",
      "    val_loss       : -1516.2201334635417\n",
      "    val_ess        : 3.7837679386138916\n",
      "    val_log_marginal: 1516.3372395833333\n",
      "Train Epoch: 1122 [0/54000 (0%)] Loss: -1518.403687\n",
      "Train Epoch: 1122 [32768/54000 (61%)] Loss: -1515.190186\n",
      "    epoch          : 1122\n",
      "    loss           : -1517.032599683078\n",
      "    ess            : 3.7692764165266506\n",
      "    log_marginal   : 1517.1593892799233\n",
      "    val_loss       : -1516.3519287109375\n",
      "    val_ess        : 3.7800625562667847\n",
      "    val_log_marginal: 1516.4733276367188\n",
      "Train Epoch: 1123 [0/54000 (0%)] Loss: -1517.658203\n",
      "Train Epoch: 1123 [32768/54000 (61%)] Loss: -1517.517212\n",
      "    epoch          : 1123\n",
      "    loss           : -1517.1642697892098\n",
      "    ess            : 3.772665167754551\n",
      "    log_marginal   : 1517.293825545401\n",
      "    val_loss       : -1516.583516438802\n",
      "    val_ess        : 3.770227233568827\n",
      "    val_log_marginal: 1516.7067464192708\n",
      "Train Epoch: 1124 [0/54000 (0%)] Loss: -1518.399902\n",
      "Train Epoch: 1124 [32768/54000 (61%)] Loss: -1514.575439\n",
      "    epoch          : 1124\n",
      "    loss           : -1517.1508420548348\n",
      "    ess            : 3.7725225304657557\n",
      "    log_marginal   : 1517.2753998378537\n",
      "    val_loss       : -1516.2161051432292\n",
      "    val_ess        : 3.7613609631856284\n",
      "    val_log_marginal: 1516.3472290039062\n",
      "Train Epoch: 1125 [0/54000 (0%)] Loss: -1518.245605\n",
      "Train Epoch: 1125 [32768/54000 (61%)] Loss: -1518.630127\n",
      "    epoch          : 1125\n",
      "    loss           : -1517.2329493108784\n",
      "    ess            : 3.7710946056078063\n",
      "    log_marginal   : 1517.362201042895\n",
      "    val_loss       : -1516.5048828125\n",
      "    val_ess        : 3.7700819969177246\n",
      "    val_log_marginal: 1516.6261596679688\n",
      "Train Epoch: 1126 [0/54000 (0%)] Loss: -1518.129028\n",
      "Train Epoch: 1126 [32768/54000 (61%)] Loss: -1514.392822\n",
      "    epoch          : 1126\n",
      "    loss           : -1517.4143711306015\n",
      "    ess            : 3.771259163910488\n",
      "    log_marginal   : 1517.5401265846108\n",
      "    val_loss       : -1516.2270914713542\n",
      "    val_ess        : 3.782644589742025\n",
      "    val_log_marginal: 1516.344706217448\n",
      "Train Epoch: 1127 [0/54000 (0%)] Loss: -1520.620972\n",
      "Train Epoch: 1127 [32768/54000 (61%)] Loss: -1516.470459\n",
      "    epoch          : 1127\n",
      "    loss           : -1517.5732675228478\n",
      "    ess            : 3.768692722860372\n",
      "    log_marginal   : 1517.6992579046284\n",
      "    val_loss       : -1516.9423014322917\n",
      "    val_ess        : 3.7754769722620645\n",
      "    val_log_marginal: 1517.0626017252605\n",
      "Train Epoch: 1128 [0/54000 (0%)] Loss: -1515.482788\n",
      "Train Epoch: 1128 [32768/54000 (61%)] Loss: -1518.912476\n",
      "    epoch          : 1128\n",
      "    loss           : -1517.6238599093456\n",
      "    ess            : 3.7694700798898375\n",
      "    log_marginal   : 1517.75209362102\n",
      "    val_loss       : -1516.7713623046875\n",
      "    val_ess        : 3.766184687614441\n",
      "    val_log_marginal: 1516.903096516927\n",
      "Train Epoch: 1129 [0/54000 (0%)] Loss: -1517.271118\n",
      "Train Epoch: 1129 [32768/54000 (61%)] Loss: -1521.130615\n",
      "    epoch          : 1129\n",
      "    loss           : -1517.7439402454304\n",
      "    ess            : 3.7666106448983245\n",
      "    log_marginal   : 1517.8728925596993\n",
      "    val_loss       : -1516.8547973632812\n",
      "    val_ess        : 3.7750899394353232\n",
      "    val_log_marginal: 1516.9829508463542\n",
      "Train Epoch: 1130 [0/54000 (0%)] Loss: -1518.311401\n",
      "Train Epoch: 1130 [32768/54000 (61%)] Loss: -1517.936279\n",
      "    epoch          : 1130\n",
      "    loss           : -1517.7760792858196\n",
      "    ess            : 3.770401180915113\n",
      "    log_marginal   : 1517.906759010171\n",
      "    val_loss       : -1516.7331949869792\n",
      "    val_ess        : 3.762965718905131\n",
      "    val_log_marginal: 1516.8699747721355\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1130.pth ...\n",
      "Train Epoch: 1131 [0/54000 (0%)] Loss: -1517.353271\n",
      "Train Epoch: 1131 [32768/54000 (61%)] Loss: -1521.461670\n",
      "    epoch          : 1131\n",
      "    loss           : -1517.922003979953\n",
      "    ess            : 3.7675059201582424\n",
      "    log_marginal   : 1518.0523313126473\n",
      "    val_loss       : -1517.322509765625\n",
      "    val_ess        : 3.770927985509237\n",
      "    val_log_marginal: 1517.4486694335938\n",
      "Train Epoch: 1132 [0/54000 (0%)] Loss: -1517.013306\n",
      "Train Epoch: 1132 [32768/54000 (61%)] Loss: -1515.665283\n",
      "    epoch          : 1132\n",
      "    loss           : -1517.9461623857605\n",
      "    ess            : 3.7671717202888346\n",
      "    log_marginal   : 1518.075907005454\n",
      "    val_loss       : -1516.9461466471355\n",
      "    val_ess        : 3.7814671993255615\n",
      "    val_log_marginal: 1517.0580444335938\n",
      "Train Epoch: 1133 [0/54000 (0%)] Loss: -1518.059326\n",
      "Train Epoch: 1133 [32768/54000 (61%)] Loss: -1515.339355\n",
      "    epoch          : 1133\n",
      "    loss           : -1518.1232633770637\n",
      "    ess            : 3.770836461265132\n",
      "    log_marginal   : 1518.2509258918042\n",
      "    val_loss       : -1517.1819661458333\n",
      "    val_ess        : 3.7794047196706138\n",
      "    val_log_marginal: 1517.3038126627605\n",
      "Train Epoch: 1134 [0/54000 (0%)] Loss: -1518.006958\n",
      "Train Epoch: 1134 [32768/54000 (61%)] Loss: -1518.500488\n",
      "    epoch          : 1134\n",
      "    loss           : -1518.1114824403007\n",
      "    ess            : 3.7722366710878767\n",
      "    log_marginal   : 1518.2385530291863\n",
      "    val_loss       : -1517.5611572265625\n",
      "    val_ess        : 3.7806528011957803\n",
      "    val_log_marginal: 1517.677754720052\n",
      "Train Epoch: 1135 [0/54000 (0%)] Loss: -1516.841675\n",
      "Train Epoch: 1135 [32768/54000 (61%)] Loss: -1519.908203\n",
      "    epoch          : 1135\n",
      "    loss           : -1518.282938255454\n",
      "    ess            : 3.772176962978435\n",
      "    log_marginal   : 1518.410623802329\n",
      "    val_loss       : -1517.659688313802\n",
      "    val_ess        : 3.783520778020223\n",
      "    val_log_marginal: 1517.7797241210938\n",
      "Train Epoch: 1136 [0/54000 (0%)] Loss: -1521.860107\n",
      "Train Epoch: 1136 [32768/54000 (61%)] Loss: -1521.168701\n",
      "    epoch          : 1136\n",
      "    loss           : -1518.2917388340213\n",
      "    ess            : 3.773602440672101\n",
      "    log_marginal   : 1518.4183004127358\n",
      "    val_loss       : -1517.4586385091145\n",
      "    val_ess        : 3.778477986653646\n",
      "    val_log_marginal: 1517.5881754557292\n",
      "Train Epoch: 1137 [0/54000 (0%)] Loss: -1516.713745\n",
      "Train Epoch: 1137 [32768/54000 (61%)] Loss: -1518.906494\n",
      "    epoch          : 1137\n",
      "    loss           : -1518.3540384544517\n",
      "    ess            : 3.767559478867729\n",
      "    log_marginal   : 1518.4823919332252\n",
      "    val_loss       : -1517.471211751302\n",
      "    val_ess        : 3.7764355341593423\n",
      "    val_log_marginal: 1517.6004638671875\n",
      "Train Epoch: 1138 [0/54000 (0%)] Loss: -1518.602295\n",
      "Train Epoch: 1138 [32768/54000 (61%)] Loss: -1519.375244\n",
      "    epoch          : 1138\n",
      "    loss           : -1518.4043890035377\n",
      "    ess            : 3.7782089395343132\n",
      "    log_marginal   : 1518.5277329930718\n",
      "    val_loss       : -1517.5963745117188\n",
      "    val_ess        : 3.7683260440826416\n",
      "    val_log_marginal: 1517.7222900390625\n",
      "Train Epoch: 1139 [0/54000 (0%)] Loss: -1518.441406\n",
      "Train Epoch: 1139 [32768/54000 (61%)] Loss: -1521.458252\n",
      "    epoch          : 1139\n",
      "    loss           : -1518.5494868440448\n",
      "    ess            : 3.770452989722198\n",
      "    log_marginal   : 1518.6783977004718\n",
      "    val_loss       : -1517.3602498372395\n",
      "    val_ess        : 3.77005926767985\n",
      "    val_log_marginal: 1517.4836832682292\n",
      "Train Epoch: 1140 [0/54000 (0%)] Loss: -1518.164551\n",
      "Train Epoch: 1140 [32768/54000 (61%)] Loss: -1518.545898\n",
      "    epoch          : 1140\n",
      "    loss           : -1518.5053158166274\n",
      "    ess            : 3.7737189373880065\n",
      "    log_marginal   : 1518.6302029591686\n",
      "    val_loss       : -1517.4560546875\n",
      "    val_ess        : 3.7806264559427896\n",
      "    val_log_marginal: 1517.576639811198\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1140.pth ...\n",
      "Train Epoch: 1141 [0/54000 (0%)] Loss: -1517.833496\n",
      "Train Epoch: 1141 [32768/54000 (61%)] Loss: -1516.734863\n",
      "    epoch          : 1141\n",
      "    loss           : -1518.6870600862323\n",
      "    ess            : 3.773098941119212\n",
      "    log_marginal   : 1518.8151394826061\n",
      "    val_loss       : -1518.0436604817708\n",
      "    val_ess        : 3.775270700454712\n",
      "    val_log_marginal: 1518.1734822591145\n",
      "Train Epoch: 1142 [0/54000 (0%)] Loss: -1520.282227\n",
      "Train Epoch: 1142 [32768/54000 (61%)] Loss: -1518.273926\n",
      "    epoch          : 1142\n",
      "    loss           : -1518.740837816922\n",
      "    ess            : 3.7681924487059972\n",
      "    log_marginal   : 1518.867125313237\n",
      "    val_loss       : -1517.9551188151042\n",
      "    val_ess        : 3.7623937129974365\n",
      "    val_log_marginal: 1518.0829060872395\n",
      "Train Epoch: 1143 [0/54000 (0%)] Loss: -1519.906494\n",
      "Train Epoch: 1143 [32768/54000 (61%)] Loss: -1516.622437\n",
      "    epoch          : 1143\n",
      "    loss           : -1518.9109623747052\n",
      "    ess            : 3.775055224040769\n",
      "    log_marginal   : 1519.0387262308373\n",
      "    val_loss       : -1517.9856567382812\n",
      "    val_ess        : 3.774432063102722\n",
      "    val_log_marginal: 1518.1180419921875\n",
      "Train Epoch: 1144 [0/54000 (0%)] Loss: -1520.437988\n",
      "Train Epoch: 1144 [32768/54000 (61%)] Loss: -1521.217041\n",
      "    epoch          : 1144\n",
      "    loss           : -1518.8891970076652\n",
      "    ess            : 3.770633675017447\n",
      "    log_marginal   : 1519.0145931603774\n",
      "    val_loss       : -1518.0343424479167\n",
      "    val_ess        : 3.774781266848246\n",
      "    val_log_marginal: 1518.1627807617188\n",
      "Train Epoch: 1145 [0/54000 (0%)] Loss: -1516.080322\n",
      "Train Epoch: 1145 [32768/54000 (61%)] Loss: -1517.853882\n",
      "    epoch          : 1145\n",
      "    loss           : -1519.0736936173348\n",
      "    ess            : 3.7719470644896886\n",
      "    log_marginal   : 1519.2009139150944\n",
      "    val_loss       : -1518.1328125\n",
      "    val_ess        : 3.7905619939168296\n",
      "    val_log_marginal: 1518.2431640625\n",
      "Train Epoch: 1146 [0/54000 (0%)] Loss: -1519.283203\n",
      "Train Epoch: 1146 [32768/54000 (61%)] Loss: -1518.240479\n",
      "    epoch          : 1146\n",
      "    loss           : -1519.1461181640625\n",
      "    ess            : 3.77110282430109\n",
      "    log_marginal   : 1519.2737806788032\n",
      "    val_loss       : -1518.0868326822917\n",
      "    val_ess        : 3.7706409295399985\n",
      "    val_log_marginal: 1518.2084350585938\n",
      "Train Epoch: 1147 [0/54000 (0%)] Loss: -1518.260376\n",
      "Train Epoch: 1147 [32768/54000 (61%)] Loss: -1519.593750\n",
      "    epoch          : 1147\n",
      "    loss           : -1519.2118173275353\n",
      "    ess            : 3.770758736808345\n",
      "    log_marginal   : 1519.3398068985848\n",
      "    val_loss       : -1517.952412923177\n",
      "    val_ess        : 3.764818469683329\n",
      "    val_log_marginal: 1518.085693359375\n",
      "Train Epoch: 1148 [0/54000 (0%)] Loss: -1519.194214\n",
      "Train Epoch: 1148 [32768/54000 (61%)] Loss: -1515.799561\n",
      "    epoch          : 1148\n",
      "    loss           : -1519.2467985333137\n",
      "    ess            : 3.773107110329394\n",
      "    log_marginal   : 1519.371759378685\n",
      "    val_loss       : -1518.4503987630208\n",
      "    val_ess        : 3.772578557332357\n",
      "    val_log_marginal: 1518.5694783528645\n",
      "Train Epoch: 1149 [0/54000 (0%)] Loss: -1519.390869\n",
      "Train Epoch: 1149 [32768/54000 (61%)] Loss: -1515.126221\n",
      "    epoch          : 1149\n",
      "    loss           : -1519.3451687794811\n",
      "    ess            : 3.7721680830109796\n",
      "    log_marginal   : 1519.4733978847287\n",
      "    val_loss       : -1518.522705078125\n",
      "    val_ess        : 3.7735349337259927\n",
      "    val_log_marginal: 1518.6451416015625\n",
      "Train Epoch: 1150 [0/54000 (0%)] Loss: -1518.334229\n",
      "Train Epoch: 1150 [32768/54000 (61%)] Loss: -1516.828369\n",
      "    epoch          : 1150\n",
      "    loss           : -1519.370096458579\n",
      "    ess            : 3.7668093780301652\n",
      "    log_marginal   : 1519.5016122494103\n",
      "    val_loss       : -1518.8657633463542\n",
      "    val_ess        : 3.774828473726908\n",
      "    val_log_marginal: 1518.9931233723958\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1150.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1151 [0/54000 (0%)] Loss: -1521.106567\n",
      "Train Epoch: 1151 [32768/54000 (61%)] Loss: -1521.626099\n",
      "    epoch          : 1151\n",
      "    loss           : -1519.5391500221108\n",
      "    ess            : 3.7737384742161013\n",
      "    log_marginal   : 1519.6643757370282\n",
      "    val_loss       : -1519.023905436198\n",
      "    val_ess        : 3.762064576148987\n",
      "    val_log_marginal: 1519.1602376302083\n",
      "Train Epoch: 1152 [0/54000 (0%)] Loss: -1522.807617\n",
      "Train Epoch: 1152 [32768/54000 (61%)] Loss: -1519.559937\n",
      "    epoch          : 1152\n",
      "    loss           : -1519.547139869546\n",
      "    ess            : 3.771971783548031\n",
      "    log_marginal   : 1519.6757467017983\n",
      "    val_loss       : -1518.5448404947917\n",
      "    val_ess        : 3.7707984844843545\n",
      "    val_log_marginal: 1518.669453938802\n",
      "Train Epoch: 1153 [0/54000 (0%)] Loss: -1520.217407\n",
      "Train Epoch: 1153 [32768/54000 (61%)] Loss: -1518.431152\n",
      "    epoch          : 1153\n",
      "    loss           : -1519.659340912441\n",
      "    ess            : 3.771125748472394\n",
      "    log_marginal   : 1519.786003832547\n",
      "    val_loss       : -1518.5667724609375\n",
      "    val_ess        : 3.7707075277964273\n",
      "    val_log_marginal: 1518.693359375\n",
      "Train Epoch: 1154 [0/54000 (0%)] Loss: -1521.044434\n",
      "Train Epoch: 1154 [32768/54000 (61%)] Loss: -1518.846436\n",
      "    epoch          : 1154\n",
      "    loss           : -1519.8363658977005\n",
      "    ess            : 3.772048869222965\n",
      "    log_marginal   : 1519.963072578862\n",
      "    val_loss       : -1518.7281290690105\n",
      "    val_ess        : 3.7667399644851685\n",
      "    val_log_marginal: 1518.8624064127605\n",
      "Train Epoch: 1155 [0/54000 (0%)] Loss: -1519.899902\n",
      "Train Epoch: 1155 [32768/54000 (61%)] Loss: -1520.460693\n",
      "    epoch          : 1155\n",
      "    loss           : -1519.8904061947228\n",
      "    ess            : 3.7717412237851127\n",
      "    log_marginal   : 1520.0179927034198\n",
      "    val_loss       : -1518.9044392903645\n",
      "    val_ess        : 3.7654558420181274\n",
      "    val_log_marginal: 1519.0465901692708\n",
      "Train Epoch: 1156 [0/54000 (0%)] Loss: -1521.603882\n",
      "Train Epoch: 1156 [32768/54000 (61%)] Loss: -1518.452881\n",
      "    epoch          : 1156\n",
      "    loss           : -1520.0374986180718\n",
      "    ess            : 3.7682043696349523\n",
      "    log_marginal   : 1520.166036353921\n",
      "    val_loss       : -1519.2153930664062\n",
      "    val_ess        : 3.7761897246042886\n",
      "    val_log_marginal: 1519.3382568359375\n",
      "Train Epoch: 1157 [0/54000 (0%)] Loss: -1520.881592\n",
      "Train Epoch: 1157 [32768/54000 (61%)] Loss: -1514.637939\n",
      "    epoch          : 1157\n",
      "    loss           : -1520.1003302808078\n",
      "    ess            : 3.7638960829320944\n",
      "    log_marginal   : 1520.2355220002948\n",
      "    val_loss       : -1519.6250406901042\n",
      "    val_ess        : 3.771182338396708\n",
      "    val_log_marginal: 1519.7462565104167\n",
      "Train Epoch: 1158 [0/54000 (0%)] Loss: -1524.185547\n",
      "Train Epoch: 1158 [32768/54000 (61%)] Loss: -1522.847900\n",
      "    epoch          : 1158\n",
      "    loss           : -1520.2427494840802\n",
      "    ess            : 3.76861480047118\n",
      "    log_marginal   : 1520.3715267541274\n",
      "    val_loss       : -1519.265604654948\n",
      "    val_ess        : 3.75955593585968\n",
      "    val_log_marginal: 1519.406005859375\n",
      "Train Epoch: 1159 [0/54000 (0%)] Loss: -1523.160400\n",
      "Train Epoch: 1159 [32768/54000 (61%)] Loss: -1522.941650\n",
      "    epoch          : 1159\n",
      "    loss           : -1520.3519194980838\n",
      "    ess            : 3.7738490644490943\n",
      "    log_marginal   : 1520.4783359743515\n",
      "    val_loss       : -1519.714864095052\n",
      "    val_ess        : 3.783354878425598\n",
      "    val_log_marginal: 1519.8423461914062\n",
      "Train Epoch: 1160 [0/54000 (0%)] Loss: -1518.263916\n",
      "Train Epoch: 1160 [32768/54000 (61%)] Loss: -1523.044556\n",
      "    epoch          : 1160\n",
      "    loss           : -1520.3723328788326\n",
      "    ess            : 3.769290568693629\n",
      "    log_marginal   : 1520.502259452388\n",
      "    val_loss       : -1519.7707926432292\n",
      "    val_ess        : 3.7552024920781455\n",
      "    val_log_marginal: 1519.9136149088542\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1160.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1161 [0/54000 (0%)] Loss: -1521.590210\n",
      "Train Epoch: 1161 [32768/54000 (61%)] Loss: -1520.460571\n",
      "    epoch          : 1161\n",
      "    loss           : -1520.4240561431309\n",
      "    ess            : 3.770514821106533\n",
      "    log_marginal   : 1520.5518890956662\n",
      "    val_loss       : -1519.9768880208333\n",
      "    val_ess        : 3.7746067444483438\n",
      "    val_log_marginal: 1520.1039632161458\n",
      "Train Epoch: 1162 [0/54000 (0%)] Loss: -1523.040283\n",
      "Train Epoch: 1162 [32768/54000 (61%)] Loss: -1520.400146\n",
      "    epoch          : 1162\n",
      "    loss           : -1520.4904531802772\n",
      "    ess            : 3.770306609711557\n",
      "    log_marginal   : 1520.6181571528596\n",
      "    val_loss       : -1520.0404256184895\n",
      "    val_ess        : 3.773846983909607\n",
      "    val_log_marginal: 1520.164082845052\n",
      "Train Epoch: 1163 [0/54000 (0%)] Loss: -1523.187988\n",
      "Train Epoch: 1163 [32768/54000 (61%)] Loss: -1520.112549\n",
      "    epoch          : 1163\n",
      "    loss           : -1520.6372415794517\n",
      "    ess            : 3.770434600002361\n",
      "    log_marginal   : 1520.7652795179836\n",
      "    val_loss       : -1520.0648803710938\n",
      "    val_ess        : 3.770629326502482\n",
      "    val_log_marginal: 1520.1939697265625\n",
      "Train Epoch: 1164 [0/54000 (0%)] Loss: -1520.579346\n",
      "Train Epoch: 1164 [32768/54000 (61%)] Loss: -1519.945923\n",
      "    epoch          : 1164\n",
      "    loss           : -1520.7517412293632\n",
      "    ess            : 3.770833730697632\n",
      "    log_marginal   : 1520.879514298349\n",
      "    val_loss       : -1520.142313639323\n",
      "    val_ess        : 3.767184535662333\n",
      "    val_log_marginal: 1520.2717895507812\n",
      "Train Epoch: 1165 [0/54000 (0%)] Loss: -1521.342896\n",
      "Train Epoch: 1165 [32768/54000 (61%)] Loss: -1521.497559\n",
      "    epoch          : 1165\n",
      "    loss           : -1520.9758899616745\n",
      "    ess            : 3.7731969716413967\n",
      "    log_marginal   : 1521.1038403780956\n",
      "    val_loss       : -1520.0144856770833\n",
      "    val_ess        : 3.7693063020706177\n",
      "    val_log_marginal: 1520.1392415364583\n",
      "Train Epoch: 1166 [0/54000 (0%)] Loss: -1520.536743\n",
      "Train Epoch: 1166 [32768/54000 (61%)] Loss: -1523.289062\n",
      "    epoch          : 1166\n",
      "    loss           : -1521.0088374299823\n",
      "    ess            : 3.768123784155216\n",
      "    log_marginal   : 1521.138858435289\n",
      "    val_loss       : -1520.5371704101562\n",
      "    val_ess        : 3.7762163082758584\n",
      "    val_log_marginal: 1520.6654663085938\n",
      "Train Epoch: 1167 [0/54000 (0%)] Loss: -1521.035767\n",
      "Train Epoch: 1167 [32768/54000 (61%)] Loss: -1520.772217\n",
      "    epoch          : 1167\n",
      "    loss           : -1520.9829631301593\n",
      "    ess            : 3.768276515996681\n",
      "    log_marginal   : 1521.1112797575177\n",
      "    val_loss       : -1520.5814412434895\n",
      "    val_ess        : 3.775465726852417\n",
      "    val_log_marginal: 1520.7067464192708\n",
      "Train Epoch: 1168 [0/54000 (0%)] Loss: -1522.885498\n",
      "Train Epoch: 1168 [32768/54000 (61%)] Loss: -1521.750000\n",
      "    epoch          : 1168\n",
      "    loss           : -1521.076047501474\n",
      "    ess            : 3.7703394709892994\n",
      "    log_marginal   : 1521.2061283903302\n",
      "    val_loss       : -1520.49267578125\n",
      "    val_ess        : 3.7637694279352822\n",
      "    val_log_marginal: 1520.6200561523438\n",
      "Train Epoch: 1169 [0/54000 (0%)] Loss: -1522.347534\n",
      "Train Epoch: 1169 [32768/54000 (61%)] Loss: -1521.471558\n",
      "    epoch          : 1169\n",
      "    loss           : -1521.1481035340507\n",
      "    ess            : 3.7721337912217625\n",
      "    log_marginal   : 1521.2738566848468\n",
      "    val_loss       : -1520.4299723307292\n",
      "    val_ess        : 3.7666324377059937\n",
      "    val_log_marginal: 1520.5599772135417\n",
      "Train Epoch: 1170 [0/54000 (0%)] Loss: -1521.287720\n",
      "Train Epoch: 1170 [32768/54000 (61%)] Loss: -1519.624390\n",
      "    epoch          : 1170\n",
      "    loss           : -1521.300408129422\n",
      "    ess            : 3.773566291017352\n",
      "    log_marginal   : 1521.4276330336086\n",
      "    val_loss       : -1520.5725708007812\n",
      "    val_ess        : 3.762325922648112\n",
      "    val_log_marginal: 1520.7080485026042\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1170.pth ...\n",
      "Train Epoch: 1171 [0/54000 (0%)] Loss: -1521.222412\n",
      "Train Epoch: 1171 [32768/54000 (61%)] Loss: -1520.747070\n",
      "    epoch          : 1171\n",
      "    loss           : -1521.3608490566037\n",
      "    ess            : 3.776023711798326\n",
      "    log_marginal   : 1521.485475936026\n",
      "    val_loss       : -1520.634989420573\n",
      "    val_ess        : 3.759740948677063\n",
      "    val_log_marginal: 1520.7738647460938\n",
      "Train Epoch: 1172 [0/54000 (0%)] Loss: -1520.023682\n",
      "Train Epoch: 1172 [32768/54000 (61%)] Loss: -1523.059570\n",
      "    epoch          : 1172\n",
      "    loss           : -1521.441302605395\n",
      "    ess            : 3.7713415892619007\n",
      "    log_marginal   : 1521.5672146779186\n",
      "    val_loss       : -1520.7924397786458\n",
      "    val_ess        : 3.7702993551890054\n",
      "    val_log_marginal: 1520.9225260416667\n",
      "Train Epoch: 1173 [0/54000 (0%)] Loss: -1522.769287\n",
      "Train Epoch: 1173 [32768/54000 (61%)] Loss: -1517.537720\n",
      "    epoch          : 1173\n",
      "    loss           : -1521.4559832878833\n",
      "    ess            : 3.767507220214268\n",
      "    log_marginal   : 1521.5913799933667\n",
      "    val_loss       : -1521.1350708007812\n",
      "    val_ess        : 3.7581297556559243\n",
      "    val_log_marginal: 1521.2732340494792\n",
      "Train Epoch: 1174 [0/54000 (0%)] Loss: -1521.879639\n",
      "Train Epoch: 1174 [32768/54000 (61%)] Loss: -1523.663574\n",
      "    epoch          : 1174\n",
      "    loss           : -1521.4467266730542\n",
      "    ess            : 3.772163728498063\n",
      "    log_marginal   : 1521.572733177329\n",
      "    val_loss       : -1521.4086100260417\n",
      "    val_ess        : 3.7742430766423545\n",
      "    val_log_marginal: 1521.545430501302\n",
      "Train Epoch: 1175 [0/54000 (0%)] Loss: -1521.365234\n",
      "Train Epoch: 1175 [32768/54000 (61%)] Loss: -1521.118408\n",
      "    epoch          : 1175\n",
      "    loss           : -1521.4555433741157\n",
      "    ess            : 3.768409823471645\n",
      "    log_marginal   : 1521.58726184773\n",
      "    val_loss       : -1521.145528157552\n",
      "    val_ess        : 3.7692530949910483\n",
      "    val_log_marginal: 1521.277323404948\n",
      "Train Epoch: 1176 [0/54000 (0%)] Loss: -1520.746094\n",
      "Train Epoch: 1176 [32768/54000 (61%)] Loss: -1521.815430\n",
      "    epoch          : 1176\n",
      "    loss           : -1521.618168668927\n",
      "    ess            : 3.7699660850021073\n",
      "    log_marginal   : 1521.7472499631485\n",
      "    val_loss       : -1521.1185302734375\n",
      "    val_ess        : 3.7633410692214966\n",
      "    val_log_marginal: 1521.256103515625\n",
      "Train Epoch: 1177 [0/54000 (0%)] Loss: -1524.191772\n",
      "Train Epoch: 1177 [32768/54000 (61%)] Loss: -1521.232666\n",
      "    epoch          : 1177\n",
      "    loss           : -1521.718038307046\n",
      "    ess            : 3.7709908035566224\n",
      "    log_marginal   : 1521.8449822191922\n",
      "    val_loss       : -1521.1915486653645\n",
      "    val_ess        : 3.7815582752227783\n",
      "    val_log_marginal: 1521.3188883463542\n",
      "Train Epoch: 1178 [0/54000 (0%)] Loss: -1523.797363\n",
      "Train Epoch: 1178 [32768/54000 (61%)] Loss: -1521.786255\n",
      "    epoch          : 1178\n",
      "    loss           : -1521.9665366118809\n",
      "    ess            : 3.7736611141348786\n",
      "    log_marginal   : 1522.0946413436027\n",
      "    val_loss       : -1521.21435546875\n",
      "    val_ess        : 3.783276359240214\n",
      "    val_log_marginal: 1521.336690266927\n",
      "Train Epoch: 1179 [0/54000 (0%)] Loss: -1523.878906\n",
      "Train Epoch: 1179 [32768/54000 (61%)] Loss: -1521.676147\n",
      "    epoch          : 1179\n",
      "    loss           : -1521.8452954562206\n",
      "    ess            : 3.768686496986533\n",
      "    log_marginal   : 1521.9720804466392\n",
      "    val_loss       : -1521.3350626627605\n",
      "    val_ess        : 3.776503841082255\n",
      "    val_log_marginal: 1521.4677124023438\n",
      "Train Epoch: 1180 [0/54000 (0%)] Loss: -1519.921509\n",
      "Train Epoch: 1180 [32768/54000 (61%)] Loss: -1522.162354\n",
      "    epoch          : 1180\n",
      "    loss           : -1521.9857016509434\n",
      "    ess            : 3.7716199497006975\n",
      "    log_marginal   : 1522.115946067954\n",
      "    val_loss       : -1521.4021809895833\n",
      "    val_ess        : 3.777141491572062\n",
      "    val_log_marginal: 1521.5353597005208\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1180.pth ...\n",
      "Train Epoch: 1181 [0/54000 (0%)] Loss: -1522.583008\n",
      "Train Epoch: 1181 [32768/54000 (61%)] Loss: -1523.497437\n",
      "    epoch          : 1181\n",
      "    loss           : -1522.0394194980838\n",
      "    ess            : 3.7729768033297555\n",
      "    log_marginal   : 1522.166545364092\n",
      "    val_loss       : -1521.260965983073\n",
      "    val_ess        : 3.7647618850072226\n",
      "    val_log_marginal: 1521.395487467448\n",
      "Train Epoch: 1182 [0/54000 (0%)] Loss: -1525.032593\n",
      "Train Epoch: 1182 [32768/54000 (61%)] Loss: -1522.517334\n",
      "    epoch          : 1182\n",
      "    loss           : -1522.0850691885319\n",
      "    ess            : 3.7705855279598595\n",
      "    log_marginal   : 1522.2150441295696\n",
      "    val_loss       : -1521.7069091796875\n",
      "    val_ess        : 3.778348128000895\n",
      "    val_log_marginal: 1521.8189697265625\n",
      "Train Epoch: 1183 [0/54000 (0%)] Loss: -1519.601318\n",
      "Train Epoch: 1183 [32768/54000 (61%)] Loss: -1518.887573\n",
      "    epoch          : 1183\n",
      "    loss           : -1522.3126888635024\n",
      "    ess            : 3.7663314477452694\n",
      "    log_marginal   : 1522.4442000479069\n",
      "    val_loss       : -1521.7375081380208\n",
      "    val_ess        : 3.7652875185012817\n",
      "    val_log_marginal: 1521.878641764323\n",
      "Train Epoch: 1184 [0/54000 (0%)] Loss: -1523.319580\n",
      "Train Epoch: 1184 [32768/54000 (61%)] Loss: -1523.334961\n",
      "    epoch          : 1184\n",
      "    loss           : -1522.378293595224\n",
      "    ess            : 3.770505707218962\n",
      "    log_marginal   : 1522.5062117666569\n",
      "    val_loss       : -1521.7574259440105\n",
      "    val_ess        : 3.774659355481466\n",
      "    val_log_marginal: 1521.8809204101562\n",
      "Train Epoch: 1185 [0/54000 (0%)] Loss: -1521.794922\n",
      "Train Epoch: 1185 [32768/54000 (61%)] Loss: -1521.210205\n",
      "    epoch          : 1185\n",
      "    loss           : -1522.4361871683373\n",
      "    ess            : 3.767664095140853\n",
      "    log_marginal   : 1522.5700130822524\n",
      "    val_loss       : -1521.4978637695312\n",
      "    val_ess        : 3.775269389152527\n",
      "    val_log_marginal: 1521.6190999348958\n",
      "Train Epoch: 1186 [0/54000 (0%)] Loss: -1521.529907\n",
      "Train Epoch: 1186 [32768/54000 (61%)] Loss: -1521.247559\n",
      "    epoch          : 1186\n",
      "    loss           : -1522.6325867850826\n",
      "    ess            : 3.7720172135335095\n",
      "    log_marginal   : 1522.7594155365566\n",
      "    val_loss       : -1521.9683227539062\n",
      "    val_ess        : 3.764772097269694\n",
      "    val_log_marginal: 1522.099833170573\n",
      "Train Epoch: 1187 [0/54000 (0%)] Loss: -1522.872803\n",
      "Train Epoch: 1187 [32768/54000 (61%)] Loss: -1525.665771\n",
      "    epoch          : 1187\n",
      "    loss           : -1522.5891965470223\n",
      "    ess            : 3.769218188411785\n",
      "    log_marginal   : 1522.7191277270047\n",
      "    val_loss       : -1522.0123087565105\n",
      "    val_ess        : 3.771587292353312\n",
      "    val_log_marginal: 1522.1396891276042\n",
      "Train Epoch: 1188 [0/54000 (0%)] Loss: -1522.878662\n",
      "Train Epoch: 1188 [32768/54000 (61%)] Loss: -1525.368408\n",
      "    epoch          : 1188\n",
      "    loss           : -1522.7075794147995\n",
      "    ess            : 3.767293021364032\n",
      "    log_marginal   : 1522.8369025464328\n",
      "    val_loss       : -1521.9799194335938\n",
      "    val_ess        : 3.7729031642278037\n",
      "    val_log_marginal: 1522.1075032552083\n",
      "Train Epoch: 1189 [0/54000 (0%)] Loss: -1522.863525\n",
      "Train Epoch: 1189 [32768/54000 (61%)] Loss: -1523.664795\n",
      "    epoch          : 1189\n",
      "    loss           : -1522.7083901459316\n",
      "    ess            : 3.7679953755072826\n",
      "    log_marginal   : 1522.842591483638\n",
      "    val_loss       : -1521.7488810221355\n",
      "    val_ess        : 3.770774245262146\n",
      "    val_log_marginal: 1521.8799438476562\n",
      "Train Epoch: 1190 [0/54000 (0%)] Loss: -1523.153564\n",
      "Train Epoch: 1190 [32768/54000 (61%)] Loss: -1522.908447\n",
      "    epoch          : 1190\n",
      "    loss           : -1522.811829764888\n",
      "    ess            : 3.7706176559880094\n",
      "    log_marginal   : 1522.941484559257\n",
      "    val_loss       : -1521.899922688802\n",
      "    val_ess        : 3.775288224220276\n",
      "    val_log_marginal: 1522.0277303059895\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1190.pth ...\n",
      "Train Epoch: 1191 [0/54000 (0%)] Loss: -1523.963989\n",
      "Train Epoch: 1191 [32768/54000 (61%)] Loss: -1524.601929\n",
      "    epoch          : 1191\n",
      "    loss           : -1522.8289794921875\n",
      "    ess            : 3.7764389110061356\n",
      "    log_marginal   : 1522.9525837448407\n",
      "    val_loss       : -1522.0842895507812\n",
      "    val_ess        : 3.769219994544983\n",
      "    val_log_marginal: 1522.2117919921875\n",
      "Train Epoch: 1192 [0/54000 (0%)] Loss: -1522.554077\n",
      "Train Epoch: 1192 [32768/54000 (61%)] Loss: -1520.197510\n",
      "    epoch          : 1192\n",
      "    loss           : -1523.0003823334316\n",
      "    ess            : 3.773059462601284\n",
      "    log_marginal   : 1523.1279204746463\n",
      "    val_loss       : -1522.158955891927\n",
      "    val_ess        : 3.7742099364598594\n",
      "    val_log_marginal: 1522.291971842448\n",
      "Train Epoch: 1193 [0/54000 (0%)] Loss: -1526.599854\n",
      "Train Epoch: 1193 [32768/54000 (61%)] Loss: -1523.379517\n",
      "    epoch          : 1193\n",
      "    loss           : -1523.250711692954\n",
      "    ess            : 3.77588733637108\n",
      "    log_marginal   : 1523.3746660340507\n",
      "    val_loss       : -1522.6758829752605\n",
      "    val_ess        : 3.7675296862920127\n",
      "    val_log_marginal: 1522.808573404948\n",
      "Train Epoch: 1194 [0/54000 (0%)] Loss: -1522.970459\n",
      "Train Epoch: 1194 [32768/54000 (61%)] Loss: -1522.716064\n",
      "    epoch          : 1194\n",
      "    loss           : -1523.2821620725235\n",
      "    ess            : 3.767806485014142\n",
      "    log_marginal   : 1523.4122890256485\n",
      "    val_loss       : -1522.4507853190105\n",
      "    val_ess        : 3.7821547985076904\n",
      "    val_log_marginal: 1522.5694376627605\n",
      "Train Epoch: 1195 [0/54000 (0%)] Loss: -1523.140381\n",
      "Train Epoch: 1195 [32768/54000 (61%)] Loss: -1524.041504\n",
      "    epoch          : 1195\n",
      "    loss           : -1523.3131817511792\n",
      "    ess            : 3.7705415194889285\n",
      "    log_marginal   : 1523.4423943285672\n",
      "    val_loss       : -1522.6288248697917\n",
      "    val_ess        : 3.783952554066976\n",
      "    val_log_marginal: 1522.742655436198\n",
      "Train Epoch: 1196 [0/54000 (0%)] Loss: -1519.563721\n",
      "Train Epoch: 1196 [32768/54000 (61%)] Loss: -1521.989990\n",
      "    epoch          : 1196\n",
      "    loss           : -1523.2990561431309\n",
      "    ess            : 3.7727591766501374\n",
      "    log_marginal   : 1523.4256822118218\n",
      "    val_loss       : -1522.7770589192708\n",
      "    val_ess        : 3.757157484690348\n",
      "    val_log_marginal: 1522.908203125\n",
      "Train Epoch: 1197 [0/54000 (0%)] Loss: -1524.847656\n",
      "Train Epoch: 1197 [32768/54000 (61%)] Loss: -1522.588135\n",
      "    epoch          : 1197\n",
      "    loss           : -1523.3326669369103\n",
      "    ess            : 3.769510750500661\n",
      "    log_marginal   : 1523.4654011276532\n",
      "    val_loss       : -1522.7616577148438\n",
      "    val_ess        : 3.7713791926701865\n",
      "    val_log_marginal: 1522.892822265625\n",
      "Train Epoch: 1198 [0/54000 (0%)] Loss: -1523.830078\n",
      "Train Epoch: 1198 [32768/54000 (61%)] Loss: -1523.024658\n",
      "    epoch          : 1198\n",
      "    loss           : -1523.313923385908\n",
      "    ess            : 3.768598839921771\n",
      "    log_marginal   : 1523.444704451651\n",
      "    val_loss       : -1522.7234903971355\n",
      "    val_ess        : 3.7756828467051187\n",
      "    val_log_marginal: 1522.8487345377605\n",
      "Train Epoch: 1199 [0/54000 (0%)] Loss: -1523.282349\n",
      "Train Epoch: 1199 [32768/54000 (61%)] Loss: -1521.641846\n",
      "    epoch          : 1199\n",
      "    loss           : -1523.5065388229657\n",
      "    ess            : 3.76853697704819\n",
      "    log_marginal   : 1523.6353552476414\n",
      "    val_loss       : -1522.519755045573\n",
      "    val_ess        : 3.7573976516723633\n",
      "    val_log_marginal: 1522.6587931315105\n",
      "Train Epoch: 1200 [0/54000 (0%)] Loss: -1522.071655\n",
      "Train Epoch: 1200 [32768/54000 (61%)] Loss: -1524.325439\n",
      "    epoch          : 1200\n",
      "    loss           : -1523.5932548091096\n",
      "    ess            : 3.7689025537023007\n",
      "    log_marginal   : 1523.7236719671284\n",
      "    val_loss       : -1522.2998046875\n",
      "    val_ess        : 3.7654378414154053\n",
      "    val_log_marginal: 1522.430155436198\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1200.pth ...\n",
      "Train Epoch: 1201 [0/54000 (0%)] Loss: -1520.684326\n",
      "Train Epoch: 1201 [32768/54000 (61%)] Loss: -1522.860718\n",
      "    epoch          : 1201\n",
      "    loss           : -1523.5548832731427\n",
      "    ess            : 3.7736691034065104\n",
      "    log_marginal   : 1523.679521668632\n",
      "    val_loss       : -1522.4850260416667\n",
      "    val_ess        : 3.777989943822225\n",
      "    val_log_marginal: 1522.6139322916667\n",
      "Train Epoch: 1202 [0/54000 (0%)] Loss: -1520.983521\n",
      "Train Epoch: 1202 [32768/54000 (61%)] Loss: -1521.832764\n",
      "    epoch          : 1202\n",
      "    loss           : -1523.624569299086\n",
      "    ess            : 3.770949089302207\n",
      "    log_marginal   : 1523.755801794664\n",
      "    val_loss       : -1522.8489786783855\n",
      "    val_ess        : 3.780252774556478\n",
      "    val_log_marginal: 1522.9659423828125\n",
      "Train Epoch: 1203 [0/54000 (0%)] Loss: -1528.137207\n",
      "Train Epoch: 1203 [32768/54000 (61%)] Loss: -1524.400391\n",
      "    epoch          : 1203\n",
      "    loss           : -1523.7914048680718\n",
      "    ess            : 3.773008904367123\n",
      "    log_marginal   : 1523.9142720924233\n",
      "    val_loss       : -1523.109395345052\n",
      "    val_ess        : 3.7779891093571982\n",
      "    val_log_marginal: 1523.228271484375\n",
      "Train Epoch: 1204 [0/54000 (0%)] Loss: -1523.574097\n",
      "Train Epoch: 1204 [32768/54000 (61%)] Loss: -1524.592163\n",
      "    epoch          : 1204\n",
      "    loss           : -1523.834965543927\n",
      "    ess            : 3.769772799509876\n",
      "    log_marginal   : 1523.9657281839623\n",
      "    val_loss       : -1522.989237467448\n",
      "    val_ess        : 3.782117327054342\n",
      "    val_log_marginal: 1523.1123046875\n",
      "Train Epoch: 1205 [0/54000 (0%)] Loss: -1524.315674\n",
      "Train Epoch: 1205 [32768/54000 (61%)] Loss: -1525.147217\n",
      "    epoch          : 1205\n",
      "    loss           : -1523.9546451208726\n",
      "    ess            : 3.7696454569978535\n",
      "    log_marginal   : 1524.0842216059846\n",
      "    val_loss       : -1523.0276896158855\n",
      "    val_ess        : 3.782055974006653\n",
      "    val_log_marginal: 1523.1472778320312\n",
      "Train Epoch: 1206 [0/54000 (0%)] Loss: -1528.182617\n",
      "Train Epoch: 1206 [32768/54000 (61%)] Loss: -1522.362793\n",
      "    epoch          : 1206\n",
      "    loss           : -1524.0310311947228\n",
      "    ess            : 3.7695290187619768\n",
      "    log_marginal   : 1524.161496720224\n",
      "    val_loss       : -1523.0652262369792\n",
      "    val_ess        : 3.7921972274780273\n",
      "    val_log_marginal: 1523.1734822591145\n",
      "Train Epoch: 1207 [0/54000 (0%)] Loss: -1525.840820\n",
      "Train Epoch: 1207 [32768/54000 (61%)] Loss: -1520.193237\n",
      "    epoch          : 1207\n",
      "    loss           : -1524.1204350309552\n",
      "    ess            : 3.7705461798973805\n",
      "    log_marginal   : 1524.2480238428657\n",
      "    val_loss       : -1523.1382649739583\n",
      "    val_ess        : 3.778662403424581\n",
      "    val_log_marginal: 1523.2614339192708\n",
      "Train Epoch: 1208 [0/54000 (0%)] Loss: -1524.652100\n",
      "Train Epoch: 1208 [32768/54000 (61%)] Loss: -1526.378052\n",
      "    epoch          : 1208\n",
      "    loss           : -1524.1060537662147\n",
      "    ess            : 3.7695933467936964\n",
      "    log_marginal   : 1524.2383987138855\n",
      "    val_loss       : -1523.0823771158855\n",
      "    val_ess        : 3.7566146850585938\n",
      "    val_log_marginal: 1523.2261555989583\n",
      "Train Epoch: 1209 [0/54000 (0%)] Loss: -1526.676025\n",
      "Train Epoch: 1209 [32768/54000 (61%)] Loss: -1524.903076\n",
      "    epoch          : 1209\n",
      "    loss           : -1524.0644692474941\n",
      "    ess            : 3.7755705095687\n",
      "    log_marginal   : 1524.1908580852005\n",
      "    val_loss       : -1522.9680989583333\n",
      "    val_ess        : 3.7680726448694863\n",
      "    val_log_marginal: 1523.100362141927\n",
      "Train Epoch: 1210 [0/54000 (0%)] Loss: -1522.690674\n",
      "Train Epoch: 1210 [32768/54000 (61%)] Loss: -1524.359741\n",
      "    epoch          : 1210\n",
      "    loss           : -1524.230712890625\n",
      "    ess            : 3.7736204255301997\n",
      "    log_marginal   : 1524.3569980837265\n",
      "    val_loss       : -1523.5950317382812\n",
      "    val_ess        : 3.776396155357361\n",
      "    val_log_marginal: 1523.7115885416667\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1210.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1211 [0/54000 (0%)] Loss: -1524.733398\n",
      "Train Epoch: 1211 [32768/54000 (61%)] Loss: -1525.577393\n",
      "    epoch          : 1211\n",
      "    loss           : -1524.4271954230542\n",
      "    ess            : 3.7751623144689597\n",
      "    log_marginal   : 1524.5528979031544\n",
      "    val_loss       : -1523.772684733073\n",
      "    val_ess        : 3.772618373235067\n",
      "    val_log_marginal: 1523.9001871744792\n",
      "Train Epoch: 1212 [0/54000 (0%)] Loss: -1527.340820\n",
      "Train Epoch: 1212 [32768/54000 (61%)] Loss: -1520.073242\n",
      "    epoch          : 1212\n",
      "    loss           : -1524.491865050118\n",
      "    ess            : 3.7685239449986874\n",
      "    log_marginal   : 1524.6217824108196\n",
      "    val_loss       : -1523.476318359375\n",
      "    val_ess        : 3.771704117457072\n",
      "    val_log_marginal: 1523.6003011067708\n",
      "Train Epoch: 1213 [0/54000 (0%)] Loss: -1522.954346\n",
      "Train Epoch: 1213 [32768/54000 (61%)] Loss: -1526.075684\n",
      "    epoch          : 1213\n",
      "    loss           : -1524.510134139151\n",
      "    ess            : 3.7724418685121357\n",
      "    log_marginal   : 1524.6382158387382\n",
      "    val_loss       : -1523.864237467448\n",
      "    val_ess        : 3.786135752995809\n",
      "    val_log_marginal: 1523.9864908854167\n",
      "Train Epoch: 1214 [0/54000 (0%)] Loss: -1527.879639\n",
      "Train Epoch: 1214 [32768/54000 (61%)] Loss: -1525.183594\n",
      "    epoch          : 1214\n",
      "    loss           : -1524.6417512713738\n",
      "    ess            : 3.7723834964464293\n",
      "    log_marginal   : 1524.7700563826652\n",
      "    val_loss       : -1523.819844563802\n",
      "    val_ess        : 3.7863791783650718\n",
      "    val_log_marginal: 1523.9442342122395\n",
      "Train Epoch: 1215 [0/54000 (0%)] Loss: -1524.067017\n",
      "Train Epoch: 1215 [32768/54000 (61%)] Loss: -1526.123047\n",
      "    epoch          : 1215\n",
      "    loss           : -1524.569414246757\n",
      "    ess            : 3.770631326819366\n",
      "    log_marginal   : 1524.6973370246167\n",
      "    val_loss       : -1523.731709798177\n",
      "    val_ess        : 3.767316301663717\n",
      "    val_log_marginal: 1523.863545735677\n",
      "Train Epoch: 1216 [0/54000 (0%)] Loss: -1523.037354\n",
      "Train Epoch: 1216 [32768/54000 (61%)] Loss: -1526.114258\n",
      "    epoch          : 1216\n",
      "    loss           : -1524.6182354621167\n",
      "    ess            : 3.7741154769681535\n",
      "    log_marginal   : 1524.7447855247642\n",
      "    val_loss       : -1523.874532063802\n",
      "    val_ess        : 3.7754015922546387\n",
      "    val_log_marginal: 1524.0115356445312\n",
      "Train Epoch: 1217 [0/54000 (0%)] Loss: -1526.031982\n",
      "Train Epoch: 1217 [32768/54000 (61%)] Loss: -1525.848389\n",
      "    epoch          : 1217\n",
      "    loss           : -1524.667853589328\n",
      "    ess            : 3.7720943127038344\n",
      "    log_marginal   : 1524.7974623194282\n",
      "    val_loss       : -1524.0828450520833\n",
      "    val_ess        : 3.7806370655695596\n",
      "    val_log_marginal: 1524.2075805664062\n",
      "Train Epoch: 1218 [0/54000 (0%)] Loss: -1525.669312\n",
      "Train Epoch: 1218 [32768/54000 (61%)] Loss: -1528.817017\n",
      "    epoch          : 1218\n",
      "    loss           : -1524.6541494693397\n",
      "    ess            : 3.770262898139234\n",
      "    log_marginal   : 1524.7843524285083\n",
      "    val_loss       : -1524.0916748046875\n",
      "    val_ess        : 3.773870865503947\n",
      "    val_log_marginal: 1524.21630859375\n",
      "Train Epoch: 1219 [0/54000 (0%)] Loss: -1526.424805\n",
      "Train Epoch: 1219 [32768/54000 (61%)] Loss: -1529.106934\n",
      "    epoch          : 1219\n",
      "    loss           : -1524.77936366819\n",
      "    ess            : 3.774547864805977\n",
      "    log_marginal   : 1524.904665389151\n",
      "    val_loss       : -1524.1543986002605\n",
      "    val_ess        : 3.7702735662460327\n",
      "    val_log_marginal: 1524.2759399414062\n",
      "Train Epoch: 1220 [0/54000 (0%)] Loss: -1528.377930\n",
      "Train Epoch: 1220 [32768/54000 (61%)] Loss: -1526.880493\n",
      "    epoch          : 1220\n",
      "    loss           : -1524.8860577277417\n",
      "    ess            : 3.769818706332513\n",
      "    log_marginal   : 1525.0137156360554\n",
      "    val_loss       : -1524.1230061848958\n",
      "    val_ess        : 3.7822617292404175\n",
      "    val_log_marginal: 1524.2513224283855\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1220.pth ...\n",
      "Train Epoch: 1221 [0/54000 (0%)] Loss: -1528.175781\n",
      "Train Epoch: 1221 [32768/54000 (61%)] Loss: -1525.256348\n",
      "    epoch          : 1221\n",
      "    loss           : -1524.9193598909198\n",
      "    ess            : 3.775469384103451\n",
      "    log_marginal   : 1525.0461656102593\n",
      "    val_loss       : -1524.0574747721355\n",
      "    val_ess        : 3.763022025426229\n",
      "    val_log_marginal: 1524.1883748372395\n",
      "Train Epoch: 1222 [0/54000 (0%)] Loss: -1527.188477\n",
      "Train Epoch: 1222 [32768/54000 (61%)] Loss: -1525.901733\n",
      "    epoch          : 1222\n",
      "    loss           : -1525.0083652712265\n",
      "    ess            : 3.7701122760772705\n",
      "    log_marginal   : 1525.136350235849\n",
      "    val_loss       : -1524.1660563151042\n",
      "    val_ess        : 3.783527374267578\n",
      "    val_log_marginal: 1524.2844645182292\n",
      "Train Epoch: 1223 [0/54000 (0%)] Loss: -1521.484863\n",
      "Train Epoch: 1223 [32768/54000 (61%)] Loss: -1526.589111\n",
      "    epoch          : 1223\n",
      "    loss           : -1525.1262736770343\n",
      "    ess            : 3.7706634953336895\n",
      "    log_marginal   : 1525.254997973172\n",
      "    val_loss       : -1524.0015258789062\n",
      "    val_ess        : 3.7705642779668174\n",
      "    val_log_marginal: 1524.133544921875\n",
      "Train Epoch: 1224 [0/54000 (0%)] Loss: -1527.466309\n",
      "Train Epoch: 1224 [32768/54000 (61%)] Loss: -1523.616211\n",
      "    epoch          : 1224\n",
      "    loss           : -1525.179328198703\n",
      "    ess            : 3.770445522272362\n",
      "    log_marginal   : 1525.3094827903892\n",
      "    val_loss       : -1524.0364990234375\n",
      "    val_ess        : 3.7737358808517456\n",
      "    val_log_marginal: 1524.163818359375\n",
      "Train Epoch: 1225 [0/54000 (0%)] Loss: -1526.762085\n",
      "Train Epoch: 1225 [32768/54000 (61%)] Loss: -1523.549072\n",
      "    epoch          : 1225\n",
      "    loss           : -1525.2024110038326\n",
      "    ess            : 3.7691092356195988\n",
      "    log_marginal   : 1525.329958357901\n",
      "    val_loss       : -1524.1109008789062\n",
      "    val_ess        : 3.7711966832478843\n",
      "    val_log_marginal: 1524.240478515625\n",
      "Train Epoch: 1226 [0/54000 (0%)] Loss: -1525.923828\n",
      "Train Epoch: 1226 [32768/54000 (61%)] Loss: -1519.936401\n",
      "    epoch          : 1226\n",
      "    loss           : -1525.2913449845223\n",
      "    ess            : 3.770194516991669\n",
      "    log_marginal   : 1525.4202466280956\n",
      "    val_loss       : -1524.2440999348958\n",
      "    val_ess        : 3.769199768702189\n",
      "    val_log_marginal: 1524.36376953125\n",
      "Train Epoch: 1227 [0/54000 (0%)] Loss: -1525.972168\n",
      "Train Epoch: 1227 [32768/54000 (61%)] Loss: -1521.251587\n",
      "    epoch          : 1227\n",
      "    loss           : -1525.428337816922\n",
      "    ess            : 3.7722843862929434\n",
      "    log_marginal   : 1525.5558483195755\n",
      "    val_loss       : -1524.442647298177\n",
      "    val_ess        : 3.779362599054972\n",
      "    val_log_marginal: 1524.567403157552\n",
      "Train Epoch: 1228 [0/54000 (0%)] Loss: -1525.130371\n",
      "Train Epoch: 1228 [32768/54000 (61%)] Loss: -1525.676758\n",
      "    epoch          : 1228\n",
      "    loss           : -1525.6030204341096\n",
      "    ess            : 3.769248998390054\n",
      "    log_marginal   : 1525.7332095739976\n",
      "    val_loss       : -1524.3658040364583\n",
      "    val_ess        : 3.7721078395843506\n",
      "    val_log_marginal: 1524.4939575195312\n",
      "Train Epoch: 1229 [0/54000 (0%)] Loss: -1527.389893\n",
      "Train Epoch: 1229 [32768/54000 (61%)] Loss: -1526.984619\n",
      "    epoch          : 1229\n",
      "    loss           : -1525.7063310731132\n",
      "    ess            : 3.7711616282193168\n",
      "    log_marginal   : 1525.8354561283904\n",
      "    val_loss       : -1524.5267130533855\n",
      "    val_ess        : 3.7677685022354126\n",
      "    val_log_marginal: 1524.6592814127605\n",
      "Train Epoch: 1230 [0/54000 (0%)] Loss: -1526.749756\n",
      "Train Epoch: 1230 [32768/54000 (61%)] Loss: -1525.027344\n",
      "    epoch          : 1230\n",
      "    loss           : -1525.6520189969044\n",
      "    ess            : 3.7737407009556607\n",
      "    log_marginal   : 1525.7833482274468\n",
      "    val_loss       : -1525.073465983073\n",
      "    val_ess        : 3.777106444040934\n",
      "    val_log_marginal: 1525.198506673177\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1230.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1231 [0/54000 (0%)] Loss: -1524.902222\n",
      "Train Epoch: 1231 [32768/54000 (61%)] Loss: -1528.194336\n",
      "    epoch          : 1231\n",
      "    loss           : -1525.8231523621757\n",
      "    ess            : 3.7731732422450803\n",
      "    log_marginal   : 1525.9484679024174\n",
      "    val_loss       : -1525.2701619466145\n",
      "    val_ess        : 3.7711703777313232\n",
      "    val_log_marginal: 1525.3943888346355\n",
      "Train Epoch: 1232 [0/54000 (0%)] Loss: -1526.768311\n",
      "Train Epoch: 1232 [32768/54000 (61%)] Loss: -1524.658325\n",
      "    epoch          : 1232\n",
      "    loss           : -1525.8826558814858\n",
      "    ess            : 3.7713869157827125\n",
      "    log_marginal   : 1526.0128519310142\n",
      "    val_loss       : -1524.9992268880208\n",
      "    val_ess        : 3.7712262868881226\n",
      "    val_log_marginal: 1525.1284993489583\n",
      "Train Epoch: 1233 [0/54000 (0%)] Loss: -1525.578369\n",
      "Train Epoch: 1233 [32768/54000 (61%)] Loss: -1530.181152\n",
      "    epoch          : 1233\n",
      "    loss           : -1525.9432649432488\n",
      "    ess            : 3.7693181757657035\n",
      "    log_marginal   : 1526.0749258365272\n",
      "    val_loss       : -1524.886942545573\n",
      "    val_ess        : 3.762478748957316\n",
      "    val_log_marginal: 1525.012939453125\n",
      "Train Epoch: 1234 [0/54000 (0%)] Loss: -1522.739136\n",
      "Train Epoch: 1234 [32768/54000 (61%)] Loss: -1527.107178\n",
      "    epoch          : 1234\n",
      "    loss           : -1525.9660345113502\n",
      "    ess            : 3.771185339621778\n",
      "    log_marginal   : 1526.096559920401\n",
      "    val_loss       : -1525.2588297526042\n",
      "    val_ess        : 3.7774800062179565\n",
      "    val_log_marginal: 1525.3836059570312\n",
      "Train Epoch: 1235 [0/54000 (0%)] Loss: -1530.920288\n",
      "Train Epoch: 1235 [32768/54000 (61%)] Loss: -1523.705933\n",
      "    epoch          : 1235\n",
      "    loss           : -1526.1405996646522\n",
      "    ess            : 3.76907180390268\n",
      "    log_marginal   : 1526.2709223909198\n",
      "    val_loss       : -1525.3795979817708\n",
      "    val_ess        : 3.7716197570165\n",
      "    val_log_marginal: 1525.512959798177\n",
      "Train Epoch: 1236 [0/54000 (0%)] Loss: -1527.523560\n",
      "Train Epoch: 1236 [32768/54000 (61%)] Loss: -1528.971313\n",
      "    epoch          : 1236\n",
      "    loss           : -1526.2657056124706\n",
      "    ess            : 3.771104889095954\n",
      "    log_marginal   : 1526.396198776533\n",
      "    val_loss       : -1525.2292887369792\n",
      "    val_ess        : 3.7747132778167725\n",
      "    val_log_marginal: 1525.3601684570312\n",
      "Train Epoch: 1237 [0/54000 (0%)] Loss: -1526.467773\n",
      "Train Epoch: 1237 [32768/54000 (61%)] Loss: -1526.074707\n",
      "    epoch          : 1237\n",
      "    loss           : -1526.1851299933667\n",
      "    ess            : 3.7686843872070312\n",
      "    log_marginal   : 1526.3165375331662\n",
      "    val_loss       : -1525.7035725911458\n",
      "    val_ess        : 3.775785764058431\n",
      "    val_log_marginal: 1525.8353881835938\n",
      "Train Epoch: 1238 [0/54000 (0%)] Loss: -1528.062500\n",
      "Train Epoch: 1238 [32768/54000 (61%)] Loss: -1525.035156\n",
      "    epoch          : 1238\n",
      "    loss           : -1526.3174081478478\n",
      "    ess            : 3.7686653991915144\n",
      "    log_marginal   : 1526.4461808114681\n",
      "    val_loss       : -1525.607666015625\n",
      "    val_ess        : 3.776126583417257\n",
      "    val_log_marginal: 1525.7393798828125\n",
      "Train Epoch: 1239 [0/54000 (0%)] Loss: -1529.370850\n",
      "Train Epoch: 1239 [32768/54000 (61%)] Loss: -1525.089844\n",
      "    epoch          : 1239\n",
      "    loss           : -1526.4427973909198\n",
      "    ess            : 3.772834152545569\n",
      "    log_marginal   : 1526.5754049049233\n",
      "    val_loss       : -1525.7129720052083\n",
      "    val_ess        : 3.7682073513666787\n",
      "    val_log_marginal: 1525.8466796875\n",
      "Train Epoch: 1240 [0/54000 (0%)] Loss: -1527.634766\n",
      "Train Epoch: 1240 [32768/54000 (61%)] Loss: -1525.875488\n",
      "    epoch          : 1240\n",
      "    loss           : -1526.4406208542157\n",
      "    ess            : 3.772604798370937\n",
      "    log_marginal   : 1526.5703769899765\n",
      "    val_loss       : -1525.7194417317708\n",
      "    val_ess        : 3.770063559214274\n",
      "    val_log_marginal: 1525.8509928385417\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1240.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1241 [0/54000 (0%)] Loss: -1526.136230\n",
      "Train Epoch: 1241 [32768/54000 (61%)] Loss: -1525.065796\n",
      "    epoch          : 1241\n",
      "    loss           : -1526.4703046690743\n",
      "    ess            : 3.774586763022081\n",
      "    log_marginal   : 1526.5974765993515\n",
      "    val_loss       : -1526.2449747721355\n",
      "    val_ess        : 3.7787159283955893\n",
      "    val_log_marginal: 1526.3649495442708\n",
      "Train Epoch: 1242 [0/54000 (0%)] Loss: -1528.485352\n",
      "Train Epoch: 1242 [32768/54000 (61%)] Loss: -1522.613770\n",
      "    epoch          : 1242\n",
      "    loss           : -1526.6135990934552\n",
      "    ess            : 3.7721227744840227\n",
      "    log_marginal   : 1526.7421483453716\n",
      "    val_loss       : -1525.9577229817708\n",
      "    val_ess        : 3.7650267680486045\n",
      "    val_log_marginal: 1526.0879516601562\n",
      "Train Epoch: 1243 [0/54000 (0%)] Loss: -1528.516357\n",
      "Train Epoch: 1243 [32768/54000 (61%)] Loss: -1526.796997\n",
      "    epoch          : 1243\n",
      "    loss           : -1526.7497282208137\n",
      "    ess            : 3.766764267435614\n",
      "    log_marginal   : 1526.8835840765034\n",
      "    val_loss       : -1525.7240397135417\n",
      "    val_ess        : 3.7751051982243857\n",
      "    val_log_marginal: 1525.851094563802\n",
      "Train Epoch: 1244 [0/54000 (0%)] Loss: -1532.004761\n",
      "Train Epoch: 1244 [32768/54000 (61%)] Loss: -1522.287109\n",
      "    epoch          : 1244\n",
      "    loss           : -1526.7863285856427\n",
      "    ess            : 3.767912392346364\n",
      "    log_marginal   : 1526.9143803434552\n",
      "    val_loss       : -1526.0635579427083\n",
      "    val_ess        : 3.767580588658651\n",
      "    val_log_marginal: 1526.197530110677\n",
      "Train Epoch: 1245 [0/54000 (0%)] Loss: -1529.118164\n",
      "Train Epoch: 1245 [32768/54000 (61%)] Loss: -1523.621826\n",
      "    epoch          : 1245\n",
      "    loss           : -1526.7206086932488\n",
      "    ess            : 3.7721781235820844\n",
      "    log_marginal   : 1526.8503302808078\n",
      "    val_loss       : -1526.0367024739583\n",
      "    val_ess        : 3.7778757413228354\n",
      "    val_log_marginal: 1526.168721516927\n",
      "Train Epoch: 1246 [0/54000 (0%)] Loss: -1526.716064\n",
      "Train Epoch: 1246 [32768/54000 (61%)] Loss: -1526.294678\n",
      "    epoch          : 1246\n",
      "    loss           : -1526.8256905033904\n",
      "    ess            : 3.7722479757272973\n",
      "    log_marginal   : 1526.9514897184552\n",
      "    val_loss       : -1525.6473999023438\n",
      "    val_ess        : 3.768316626548767\n",
      "    val_log_marginal: 1525.773173014323\n",
      "Train Epoch: 1247 [0/54000 (0%)] Loss: -1526.745972\n",
      "Train Epoch: 1247 [32768/54000 (61%)] Loss: -1530.760498\n",
      "    epoch          : 1247\n",
      "    loss           : -1526.954767191185\n",
      "    ess            : 3.7754942246203154\n",
      "    log_marginal   : 1527.079179871757\n",
      "    val_loss       : -1526.3618570963542\n",
      "    val_ess        : 3.770713210105896\n",
      "    val_log_marginal: 1526.4972330729167\n",
      "Train Epoch: 1248 [0/54000 (0%)] Loss: -1528.923584\n",
      "Train Epoch: 1248 [32768/54000 (61%)] Loss: -1525.817871\n",
      "    epoch          : 1248\n",
      "    loss           : -1526.9987677808078\n",
      "    ess            : 3.7715056617304965\n",
      "    log_marginal   : 1527.131571067954\n",
      "    val_loss       : -1526.282002766927\n",
      "    val_ess        : 3.780323108037313\n",
      "    val_log_marginal: 1526.4014485677083\n",
      "Train Epoch: 1249 [0/54000 (0%)] Loss: -1527.871826\n",
      "Train Epoch: 1249 [32768/54000 (61%)] Loss: -1527.619263\n",
      "    epoch          : 1249\n",
      "    loss           : -1527.049783958579\n",
      "    ess            : 3.7758114068013318\n",
      "    log_marginal   : 1527.1732431087853\n",
      "    val_loss       : -1526.2820638020833\n",
      "    val_ess        : 3.766400178273519\n",
      "    val_log_marginal: 1526.4173787434895\n",
      "Train Epoch: 1250 [0/54000 (0%)] Loss: -1527.712036\n",
      "Train Epoch: 1250 [32768/54000 (61%)] Loss: -1527.628906\n",
      "    epoch          : 1250\n",
      "    loss           : -1527.0433211416569\n",
      "    ess            : 3.77526859067521\n",
      "    log_marginal   : 1527.166814840065\n",
      "    val_loss       : -1526.3363850911458\n",
      "    val_ess        : 3.7678802410761514\n",
      "    val_log_marginal: 1526.4644775390625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1250.pth ...\n",
      "Train Epoch: 1251 [0/54000 (0%)] Loss: -1529.207031\n",
      "Train Epoch: 1251 [32768/54000 (61%)] Loss: -1527.052246\n",
      "    epoch          : 1251\n",
      "    loss           : -1527.2402597103478\n",
      "    ess            : 3.7711296306466155\n",
      "    log_marginal   : 1527.3719367261203\n",
      "    val_loss       : -1526.103739420573\n",
      "    val_ess        : 3.7614639600118003\n",
      "    val_log_marginal: 1526.2329508463542\n",
      "Train Epoch: 1252 [0/54000 (0%)] Loss: -1529.698975\n",
      "Train Epoch: 1252 [32768/54000 (61%)] Loss: -1526.087036\n",
      "    epoch          : 1252\n",
      "    loss           : -1527.1870508733784\n",
      "    ess            : 3.7708716527471005\n",
      "    log_marginal   : 1527.3158442659198\n",
      "    val_loss       : -1526.4423421223958\n",
      "    val_ess        : 3.7719784577687583\n",
      "    val_log_marginal: 1526.5670776367188\n",
      "Train Epoch: 1253 [0/54000 (0%)] Loss: -1528.026855\n",
      "Train Epoch: 1253 [32768/54000 (61%)] Loss: -1525.631470\n",
      "    epoch          : 1253\n",
      "    loss           : -1527.2258231684846\n",
      "    ess            : 3.774426226345998\n",
      "    log_marginal   : 1527.3563992482311\n",
      "    val_loss       : -1526.5534261067708\n",
      "    val_ess        : 3.767334739367167\n",
      "    val_log_marginal: 1526.6820882161458\n",
      "Train Epoch: 1254 [0/54000 (0%)] Loss: -1527.463135\n",
      "Train Epoch: 1254 [32768/54000 (61%)] Loss: -1525.918213\n",
      "    epoch          : 1254\n",
      "    loss           : -1527.2058450950767\n",
      "    ess            : 3.767190177485628\n",
      "    log_marginal   : 1527.3375566590507\n",
      "    val_loss       : -1526.5640869140625\n",
      "    val_ess        : 3.7623750368754068\n",
      "    val_log_marginal: 1526.7029418945312\n",
      "Train Epoch: 1255 [0/54000 (0%)] Loss: -1527.218750\n",
      "Train Epoch: 1255 [32768/54000 (61%)] Loss: -1526.444092\n",
      "    epoch          : 1255\n",
      "    loss           : -1527.3126059478184\n",
      "    ess            : 3.7700096886113004\n",
      "    log_marginal   : 1527.442974738355\n",
      "    val_loss       : -1526.8155517578125\n",
      "    val_ess        : 3.7766361236572266\n",
      "    val_log_marginal: 1526.9434204101562\n",
      "Train Epoch: 1256 [0/54000 (0%)] Loss: -1526.281250\n",
      "Train Epoch: 1256 [32768/54000 (61%)] Loss: -1529.779785\n",
      "    epoch          : 1256\n",
      "    loss           : -1527.3178872162441\n",
      "    ess            : 3.7743166977504514\n",
      "    log_marginal   : 1527.4458238133843\n",
      "    val_loss       : -1526.3259684244792\n",
      "    val_ess        : 3.766937017440796\n",
      "    val_log_marginal: 1526.4531656901042\n",
      "Train Epoch: 1257 [0/54000 (0%)] Loss: -1527.428101\n",
      "Train Epoch: 1257 [32768/54000 (61%)] Loss: -1526.718262\n",
      "    epoch          : 1257\n",
      "    loss           : -1527.189084610849\n",
      "    ess            : 3.7714273524734208\n",
      "    log_marginal   : 1527.3166895452534\n",
      "    val_loss       : -1526.2705688476562\n",
      "    val_ess        : 3.767338832219442\n",
      "    val_log_marginal: 1526.410135904948\n",
      "Train Epoch: 1258 [0/54000 (0%)] Loss: -1527.302734\n",
      "Train Epoch: 1258 [32768/54000 (61%)] Loss: -1526.436523\n",
      "    epoch          : 1258\n",
      "    loss           : -1527.3162749668338\n",
      "    ess            : 3.774291695288892\n",
      "    log_marginal   : 1527.4421087301002\n",
      "    val_loss       : -1526.4864705403645\n",
      "    val_ess        : 3.7687260707219443\n",
      "    val_log_marginal: 1526.6246337890625\n",
      "Train Epoch: 1259 [0/54000 (0%)] Loss: -1531.516357\n",
      "Train Epoch: 1259 [32768/54000 (61%)] Loss: -1526.395020\n",
      "    epoch          : 1259\n",
      "    loss           : -1527.4220454377948\n",
      "    ess            : 3.77289845808497\n",
      "    log_marginal   : 1527.5507835532135\n",
      "    val_loss       : -1526.4435424804688\n",
      "    val_ess        : 3.7805546124776206\n",
      "    val_log_marginal: 1526.5692952473958\n",
      "Train Epoch: 1260 [0/54000 (0%)] Loss: -1531.648438\n",
      "Train Epoch: 1260 [32768/54000 (61%)] Loss: -1525.341309\n",
      "    epoch          : 1260\n",
      "    loss           : -1527.5385005159198\n",
      "    ess            : 3.773544671400538\n",
      "    log_marginal   : 1527.6649054761203\n",
      "    val_loss       : -1526.5392252604167\n",
      "    val_ess        : 3.7507201035817466\n",
      "    val_log_marginal: 1526.6818440755208\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1260.pth ...\n",
      "Train Epoch: 1261 [0/54000 (0%)] Loss: -1527.260742\n",
      "Train Epoch: 1261 [32768/54000 (61%)] Loss: -1528.126465\n",
      "    epoch          : 1261\n",
      "    loss           : -1527.6106118256191\n",
      "    ess            : 3.7669227213229775\n",
      "    log_marginal   : 1527.742431640625\n",
      "    val_loss       : -1526.6583862304688\n",
      "    val_ess        : 3.769816279411316\n",
      "    val_log_marginal: 1526.7927652994792\n",
      "Train Epoch: 1262 [0/54000 (0%)] Loss: -1531.589111\n",
      "Train Epoch: 1262 [32768/54000 (61%)] Loss: -1524.363159\n",
      "    epoch          : 1262\n",
      "    loss           : -1527.4662164652123\n",
      "    ess            : 3.7712851470371462\n",
      "    log_marginal   : 1527.5958251953125\n",
      "    val_loss       : -1526.5228271484375\n",
      "    val_ess        : 3.762864589691162\n",
      "    val_log_marginal: 1526.652323404948\n",
      "Train Epoch: 1263 [0/54000 (0%)] Loss: -1531.179443\n",
      "Train Epoch: 1263 [32768/54000 (61%)] Loss: -1525.697632\n",
      "    epoch          : 1263\n",
      "    loss           : -1527.5648423680718\n",
      "    ess            : 3.7731767690406657\n",
      "    log_marginal   : 1527.6927121720223\n",
      "    val_loss       : -1526.801737467448\n",
      "    val_ess        : 3.7803730567296348\n",
      "    val_log_marginal: 1526.9189453125\n",
      "Train Epoch: 1264 [0/54000 (0%)] Loss: -1530.656738\n",
      "Train Epoch: 1264 [32768/54000 (61%)] Loss: -1527.388916\n",
      "    epoch          : 1264\n",
      "    loss           : -1527.720587964328\n",
      "    ess            : 3.772100997420977\n",
      "    log_marginal   : 1527.8478842681309\n",
      "    val_loss       : -1526.9123128255208\n",
      "    val_ess        : 3.774397134780884\n",
      "    val_log_marginal: 1527.036885579427\n",
      "Train Epoch: 1265 [0/54000 (0%)] Loss: -1528.191406\n",
      "Train Epoch: 1265 [32768/54000 (61%)] Loss: -1525.367920\n",
      "    epoch          : 1265\n",
      "    loss           : -1527.7330667747642\n",
      "    ess            : 3.768827537320695\n",
      "    log_marginal   : 1527.861873986586\n",
      "    val_loss       : -1527.1617431640625\n",
      "    val_ess        : 3.7923393646876016\n",
      "    val_log_marginal: 1527.2792561848958\n",
      "Train Epoch: 1266 [0/54000 (0%)] Loss: -1525.289551\n",
      "Train Epoch: 1266 [32768/54000 (61%)] Loss: -1530.397949\n",
      "    epoch          : 1266\n",
      "    loss           : -1527.8212959721404\n",
      "    ess            : 3.767558660147325\n",
      "    log_marginal   : 1527.9521254053657\n",
      "    val_loss       : -1526.8590494791667\n",
      "    val_ess        : 3.769053896268209\n",
      "    val_log_marginal: 1526.9791666666667\n",
      "Train Epoch: 1267 [0/54000 (0%)] Loss: -1531.060425\n",
      "Train Epoch: 1267 [32768/54000 (61%)] Loss: -1528.157715\n",
      "    epoch          : 1267\n",
      "    loss           : -1528.023983361586\n",
      "    ess            : 3.7734301270179027\n",
      "    log_marginal   : 1528.1539997604657\n",
      "    val_loss       : -1527.258056640625\n",
      "    val_ess        : 3.760732968648275\n",
      "    val_log_marginal: 1527.3881022135417\n",
      "Train Epoch: 1268 [0/54000 (0%)] Loss: -1529.448364\n",
      "Train Epoch: 1268 [32768/54000 (61%)] Loss: -1527.127441\n",
      "    epoch          : 1268\n",
      "    loss           : -1528.1115331109966\n",
      "    ess            : 3.7698954591211282\n",
      "    log_marginal   : 1528.2404485738502\n",
      "    val_loss       : -1527.2091878255208\n",
      "    val_ess        : 3.7710524002710977\n",
      "    val_log_marginal: 1527.3408610026042\n",
      "Train Epoch: 1269 [0/54000 (0%)] Loss: -1527.236816\n",
      "Train Epoch: 1269 [32768/54000 (61%)] Loss: -1531.346069\n",
      "    epoch          : 1269\n",
      "    loss           : -1528.1411869840802\n",
      "    ess            : 3.772530641195909\n",
      "    log_marginal   : 1528.2689554466392\n",
      "    val_loss       : -1527.7154134114583\n",
      "    val_ess        : 3.7722216844558716\n",
      "    val_log_marginal: 1527.8462931315105\n",
      "Train Epoch: 1270 [0/54000 (0%)] Loss: -1528.461914\n",
      "Train Epoch: 1270 [32768/54000 (61%)] Loss: -1526.259521\n",
      "    epoch          : 1270\n",
      "    loss           : -1528.2078143425708\n",
      "    ess            : 3.7741286574669606\n",
      "    log_marginal   : 1528.3368449660968\n",
      "    val_loss       : -1527.5388590494792\n",
      "    val_ess        : 3.7703690926233926\n",
      "    val_log_marginal: 1527.670918782552\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1270.pth ...\n",
      "Train Epoch: 1271 [0/54000 (0%)] Loss: -1526.222168\n",
      "Train Epoch: 1271 [32768/54000 (61%)] Loss: -1526.592529\n",
      "    epoch          : 1271\n",
      "    loss           : -1528.2368878058667\n",
      "    ess            : 3.774283373130942\n",
      "    log_marginal   : 1528.3632789467865\n",
      "    val_loss       : -1527.8025309244792\n",
      "    val_ess        : 3.772826353708903\n",
      "    val_log_marginal: 1527.9253540039062\n",
      "Train Epoch: 1272 [0/54000 (0%)] Loss: -1526.459351\n",
      "Train Epoch: 1272 [32768/54000 (61%)] Loss: -1524.873657\n",
      "    epoch          : 1272\n",
      "    loss           : -1528.3581266583137\n",
      "    ess            : 3.775358690405792\n",
      "    log_marginal   : 1528.4836103331368\n",
      "    val_loss       : -1527.7786661783855\n",
      "    val_ess        : 3.7766767342885337\n",
      "    val_log_marginal: 1527.8995564778645\n",
      "Train Epoch: 1273 [0/54000 (0%)] Loss: -1528.568848\n",
      "Train Epoch: 1273 [32768/54000 (61%)] Loss: -1530.487305\n",
      "    epoch          : 1273\n",
      "    loss           : -1528.4021733122052\n",
      "    ess            : 3.772892911479158\n",
      "    log_marginal   : 1528.52727695681\n",
      "    val_loss       : -1527.6058959960938\n",
      "    val_ess        : 3.7714116175969443\n",
      "    val_log_marginal: 1527.7330322265625\n",
      "Train Epoch: 1274 [0/54000 (0%)] Loss: -1524.647949\n",
      "Train Epoch: 1274 [32768/54000 (61%)] Loss: -1531.247070\n",
      "    epoch          : 1274\n",
      "    loss           : -1528.3962287183078\n",
      "    ess            : 3.7677852927513844\n",
      "    log_marginal   : 1528.5283479510613\n",
      "    val_loss       : -1527.6904907226562\n",
      "    val_ess        : 3.771746873855591\n",
      "    val_log_marginal: 1527.8281860351562\n",
      "Train Epoch: 1275 [0/54000 (0%)] Loss: -1532.400024\n",
      "Train Epoch: 1275 [32768/54000 (61%)] Loss: -1528.334961\n",
      "    epoch          : 1275\n",
      "    loss           : -1528.4091198039505\n",
      "    ess            : 3.772815043071531\n",
      "    log_marginal   : 1528.536798441185\n",
      "    val_loss       : -1528.1356201171875\n",
      "    val_ess        : 3.771065831184387\n",
      "    val_log_marginal: 1528.260274251302\n",
      "Train Epoch: 1276 [0/54000 (0%)] Loss: -1529.012329\n",
      "Train Epoch: 1276 [32768/54000 (61%)] Loss: -1526.375854\n",
      "    epoch          : 1276\n",
      "    loss           : -1528.5627671727593\n",
      "    ess            : 3.7749959522823118\n",
      "    log_marginal   : 1528.6889487212559\n",
      "    val_loss       : -1527.6642659505208\n",
      "    val_ess        : 3.779425064722697\n",
      "    val_log_marginal: 1527.7943725585938\n",
      "Train Epoch: 1277 [0/54000 (0%)] Loss: -1528.496582\n",
      "Train Epoch: 1277 [32768/54000 (61%)] Loss: -1531.296875\n",
      "    epoch          : 1277\n",
      "    loss           : -1528.5769849093456\n",
      "    ess            : 3.7750422099851213\n",
      "    log_marginal   : 1528.705483490566\n",
      "    val_loss       : -1527.7981567382812\n",
      "    val_ess        : 3.7754427591959634\n",
      "    val_log_marginal: 1527.923848470052\n",
      "Train Epoch: 1278 [0/54000 (0%)] Loss: -1528.378662\n",
      "Train Epoch: 1278 [32768/54000 (61%)] Loss: -1527.837646\n",
      "    epoch          : 1278\n",
      "    loss           : -1528.6298989349941\n",
      "    ess            : 3.774104694150529\n",
      "    log_marginal   : 1528.7582316848468\n",
      "    val_loss       : -1528.1913248697917\n",
      "    val_ess        : 3.7748677333196006\n",
      "    val_log_marginal: 1528.3211466471355\n",
      "Train Epoch: 1279 [0/54000 (0%)] Loss: -1527.909424\n",
      "Train Epoch: 1279 [32768/54000 (61%)] Loss: -1529.020020\n",
      "    epoch          : 1279\n",
      "    loss           : -1528.697634139151\n",
      "    ess            : 3.776215449819025\n",
      "    log_marginal   : 1528.8258402122642\n",
      "    val_loss       : -1527.9391479492188\n",
      "    val_ess        : 3.7759938637415567\n",
      "    val_log_marginal: 1528.0767008463542\n",
      "Train Epoch: 1280 [0/54000 (0%)] Loss: -1529.671387\n",
      "Train Epoch: 1280 [32768/54000 (61%)] Loss: -1528.933838\n",
      "    epoch          : 1280\n",
      "    loss           : -1528.706013229658\n",
      "    ess            : 3.7748399320638404\n",
      "    log_marginal   : 1528.8337793890034\n",
      "    val_loss       : -1528.2859497070312\n",
      "    val_ess        : 3.766738176345825\n",
      "    val_log_marginal: 1528.4061279296875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1280.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1281 [0/54000 (0%)] Loss: -1530.238281\n",
      "Train Epoch: 1281 [32768/54000 (61%)] Loss: -1525.444092\n",
      "    epoch          : 1281\n",
      "    loss           : -1528.7620573223762\n",
      "    ess            : 3.772930046297469\n",
      "    log_marginal   : 1528.8878956920696\n",
      "    val_loss       : -1528.24560546875\n",
      "    val_ess        : 3.76362144947052\n",
      "    val_log_marginal: 1528.380391438802\n",
      "Train Epoch: 1282 [0/54000 (0%)] Loss: -1530.089111\n",
      "Train Epoch: 1282 [32768/54000 (61%)] Loss: -1529.752319\n",
      "    epoch          : 1282\n",
      "    loss           : -1528.9262833505306\n",
      "    ess            : 3.7726498234946773\n",
      "    log_marginal   : 1529.0521746941333\n",
      "    val_loss       : -1528.5267130533855\n",
      "    val_ess        : 3.7706764141718545\n",
      "    val_log_marginal: 1528.659688313802\n",
      "Train Epoch: 1283 [0/54000 (0%)] Loss: -1528.918945\n",
      "Train Epoch: 1283 [32768/54000 (61%)] Loss: -1528.390625\n",
      "    epoch          : 1283\n",
      "    loss           : -1528.8695966612618\n",
      "    ess            : 3.769975338342055\n",
      "    log_marginal   : 1529.000566590507\n",
      "    val_loss       : -1528.466532389323\n",
      "    val_ess        : 3.7823917071024575\n",
      "    val_log_marginal: 1528.5907796223958\n",
      "Train Epoch: 1284 [0/54000 (0%)] Loss: -1532.222046\n",
      "Train Epoch: 1284 [32768/54000 (61%)] Loss: -1527.994873\n",
      "    epoch          : 1284\n",
      "    loss           : -1528.9227179761203\n",
      "    ess            : 3.773963595336338\n",
      "    log_marginal   : 1529.0491574845223\n",
      "    val_loss       : -1527.9345296223958\n",
      "    val_ess        : 3.777542471885681\n",
      "    val_log_marginal: 1528.0572509765625\n",
      "Train Epoch: 1285 [0/54000 (0%)] Loss: -1526.870728\n",
      "Train Epoch: 1285 [32768/54000 (61%)] Loss: -1529.034912\n",
      "    epoch          : 1285\n",
      "    loss           : -1528.9087628058667\n",
      "    ess            : 3.7759986733490565\n",
      "    log_marginal   : 1529.0367086158608\n",
      "    val_loss       : -1528.343485514323\n",
      "    val_ess        : 3.770214796066284\n",
      "    val_log_marginal: 1528.4776204427083\n",
      "Train Epoch: 1286 [0/54000 (0%)] Loss: -1530.803955\n",
      "Train Epoch: 1286 [32768/54000 (61%)] Loss: -1526.064819\n",
      "    epoch          : 1286\n",
      "    loss           : -1528.9504786077534\n",
      "    ess            : 3.7708746622193536\n",
      "    log_marginal   : 1529.0805502837559\n",
      "    val_loss       : -1528.381815592448\n",
      "    val_ess        : 3.773103912671407\n",
      "    val_log_marginal: 1528.5107014973958\n",
      "Train Epoch: 1287 [0/54000 (0%)] Loss: -1531.649414\n",
      "Train Epoch: 1287 [32768/54000 (61%)] Loss: -1527.245117\n",
      "    epoch          : 1287\n",
      "    loss           : -1528.9512709131782\n",
      "    ess            : 3.7708043107446634\n",
      "    log_marginal   : 1529.0768167747642\n",
      "    val_loss       : -1528.456522623698\n",
      "    val_ess        : 3.7755813598632812\n",
      "    val_log_marginal: 1528.5768432617188\n",
      "Train Epoch: 1288 [0/54000 (0%)] Loss: -1531.497559\n",
      "Train Epoch: 1288 [32768/54000 (61%)] Loss: -1530.042480\n",
      "    epoch          : 1288\n",
      "    loss           : -1528.9372858011498\n",
      "    ess            : 3.770374397061906\n",
      "    log_marginal   : 1529.0701328493515\n",
      "    val_loss       : -1528.8804117838542\n",
      "    val_ess        : 3.767900506655375\n",
      "    val_log_marginal: 1529.0076497395833\n",
      "Train Epoch: 1289 [0/54000 (0%)] Loss: -1530.688965\n",
      "Train Epoch: 1289 [32768/54000 (61%)] Loss: -1526.399658\n",
      "    epoch          : 1289\n",
      "    loss           : -1529.2911515145931\n",
      "    ess            : 3.774007464354893\n",
      "    log_marginal   : 1529.4194589290978\n",
      "    val_loss       : -1528.5137736002605\n",
      "    val_ess        : 3.761469523111979\n",
      "    val_log_marginal: 1528.6573282877605\n",
      "Train Epoch: 1290 [0/54000 (0%)] Loss: -1532.377930\n",
      "Train Epoch: 1290 [32768/54000 (61%)] Loss: -1526.720215\n",
      "    epoch          : 1290\n",
      "    loss           : -1529.280144457547\n",
      "    ess            : 3.774009925014568\n",
      "    log_marginal   : 1529.4065655402417\n",
      "    val_loss       : -1528.6698811848958\n",
      "    val_ess        : 3.786262353261312\n",
      "    val_log_marginal: 1528.7906901041667\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1290.pth ...\n",
      "Train Epoch: 1291 [0/54000 (0%)] Loss: -1532.606689\n",
      "Train Epoch: 1291 [32768/54000 (61%)] Loss: -1527.531982\n",
      "    epoch          : 1291\n",
      "    loss           : -1529.4176255711968\n",
      "    ess            : 3.772519251085677\n",
      "    log_marginal   : 1529.5460205078125\n",
      "    val_loss       : -1528.5565592447917\n",
      "    val_ess        : 3.7701554695765176\n",
      "    val_log_marginal: 1528.6875406901042\n",
      "Train Epoch: 1292 [0/54000 (0%)] Loss: -1530.078735\n",
      "Train Epoch: 1292 [32768/54000 (61%)] Loss: -1528.214600\n",
      "    epoch          : 1292\n",
      "    loss           : -1529.345786040684\n",
      "    ess            : 3.771360401837331\n",
      "    log_marginal   : 1529.4742892283314\n",
      "    val_loss       : -1528.7222900390625\n",
      "    val_ess        : 3.771609663963318\n",
      "    val_log_marginal: 1528.8458862304688\n",
      "Train Epoch: 1293 [0/54000 (0%)] Loss: -1526.397095\n",
      "Train Epoch: 1293 [32768/54000 (61%)] Loss: -1531.449951\n",
      "    epoch          : 1293\n",
      "    loss           : -1529.49371913694\n",
      "    ess            : 3.7727093966502063\n",
      "    log_marginal   : 1529.624044166421\n",
      "    val_loss       : -1528.693623860677\n",
      "    val_ess        : 3.778820832570394\n",
      "    val_log_marginal: 1528.8138427734375\n",
      "Train Epoch: 1294 [0/54000 (0%)] Loss: -1534.045288\n",
      "Train Epoch: 1294 [32768/54000 (61%)] Loss: -1532.209717\n",
      "    epoch          : 1294\n",
      "    loss           : -1529.5964908239976\n",
      "    ess            : 3.7697407434571466\n",
      "    log_marginal   : 1529.7291374926297\n",
      "    val_loss       : -1528.894022623698\n",
      "    val_ess        : 3.7626907428105674\n",
      "    val_log_marginal: 1529.029805501302\n",
      "Train Epoch: 1295 [0/54000 (0%)] Loss: -1534.359375\n",
      "Train Epoch: 1295 [32768/54000 (61%)] Loss: -1521.874023\n",
      "    epoch          : 1295\n",
      "    loss           : -1529.5755407945164\n",
      "    ess            : 3.7707674008495404\n",
      "    log_marginal   : 1529.7073007259728\n",
      "    val_loss       : -1528.7533569335938\n",
      "    val_ess        : 3.7768192291259766\n",
      "    val_log_marginal: 1528.8737386067708\n",
      "Train Epoch: 1296 [0/54000 (0%)] Loss: -1532.539307\n",
      "Train Epoch: 1296 [32768/54000 (61%)] Loss: -1531.428101\n",
      "    epoch          : 1296\n",
      "    loss           : -1529.6263750184257\n",
      "    ess            : 3.775665706058718\n",
      "    log_marginal   : 1529.752991874263\n",
      "    val_loss       : -1528.8538208007812\n",
      "    val_ess        : 3.7829729318618774\n",
      "    val_log_marginal: 1528.98046875\n",
      "Train Epoch: 1297 [0/54000 (0%)] Loss: -1530.087524\n",
      "Train Epoch: 1297 [32768/54000 (61%)] Loss: -1528.756348\n",
      "    epoch          : 1297\n",
      "    loss           : -1529.748783903302\n",
      "    ess            : 3.7703561782836914\n",
      "    log_marginal   : 1529.8797331036262\n",
      "    val_loss       : -1528.9920654296875\n",
      "    val_ess        : 3.7912093003590903\n",
      "    val_log_marginal: 1529.1082560221355\n",
      "Train Epoch: 1298 [0/54000 (0%)] Loss: -1526.640625\n",
      "Train Epoch: 1298 [32768/54000 (61%)] Loss: -1528.895752\n",
      "    epoch          : 1298\n",
      "    loss           : -1529.8538058298939\n",
      "    ess            : 3.772799716805512\n",
      "    log_marginal   : 1529.9809132701946\n",
      "    val_loss       : -1528.9298502604167\n",
      "    val_ess        : 3.773063898086548\n",
      "    val_log_marginal: 1529.0623779296875\n",
      "Train Epoch: 1299 [0/54000 (0%)] Loss: -1531.953857\n",
      "Train Epoch: 1299 [32768/54000 (61%)] Loss: -1529.232666\n",
      "    epoch          : 1299\n",
      "    loss           : -1529.929646042158\n",
      "    ess            : 3.767237960167651\n",
      "    log_marginal   : 1530.0649045548348\n",
      "    val_loss       : -1529.0301310221355\n",
      "    val_ess        : 3.7779011726379395\n",
      "    val_log_marginal: 1529.1519165039062\n",
      "Train Epoch: 1300 [0/54000 (0%)] Loss: -1529.625244\n",
      "Train Epoch: 1300 [32768/54000 (61%)] Loss: -1530.715820\n",
      "    epoch          : 1300\n",
      "    loss           : -1529.9768043374115\n",
      "    ess            : 3.776164189824518\n",
      "    log_marginal   : 1530.1032599683078\n",
      "    val_loss       : -1528.7210286458333\n",
      "    val_ess        : 3.782054821650187\n",
      "    val_log_marginal: 1528.8394775390625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1300.pth ...\n",
      "Train Epoch: 1301 [0/54000 (0%)] Loss: -1530.278320\n",
      "Train Epoch: 1301 [32768/54000 (61%)] Loss: -1531.528198\n",
      "    epoch          : 1301\n",
      "    loss           : -1530.031068046138\n",
      "    ess            : 3.7701574496503145\n",
      "    log_marginal   : 1530.1593363060142\n",
      "    val_loss       : -1529.1177978515625\n",
      "    val_ess        : 3.7789849042892456\n",
      "    val_log_marginal: 1529.2396647135417\n",
      "Train Epoch: 1302 [0/54000 (0%)] Loss: -1532.897705\n",
      "Train Epoch: 1302 [32768/54000 (61%)] Loss: -1528.773560\n",
      "    epoch          : 1302\n",
      "    loss           : -1529.9872977778596\n",
      "    ess            : 3.775634185323175\n",
      "    log_marginal   : 1530.1133618624706\n",
      "    val_loss       : -1529.0543009440105\n",
      "    val_ess        : 3.7775781949361167\n",
      "    val_log_marginal: 1529.1881510416667\n",
      "Train Epoch: 1303 [0/54000 (0%)] Loss: -1532.574707\n",
      "Train Epoch: 1303 [32768/54000 (61%)] Loss: -1529.889404\n",
      "    epoch          : 1303\n",
      "    loss           : -1530.1683188384434\n",
      "    ess            : 3.776255985475936\n",
      "    log_marginal   : 1530.292075103184\n",
      "    val_loss       : -1529.509256998698\n",
      "    val_ess        : 3.7827043930689492\n",
      "    val_log_marginal: 1529.6287434895833\n",
      "Train Epoch: 1304 [0/54000 (0%)] Loss: -1535.266113\n",
      "Train Epoch: 1304 [32768/54000 (61%)] Loss: -1533.388794\n",
      "    epoch          : 1304\n",
      "    loss           : -1530.2945095997936\n",
      "    ess            : 3.772600920695179\n",
      "    log_marginal   : 1530.4232661409198\n",
      "    val_loss       : -1529.1395060221355\n",
      "    val_ess        : 3.7856555779774985\n",
      "    val_log_marginal: 1529.26416015625\n",
      "Train Epoch: 1305 [0/54000 (0%)] Loss: -1530.530518\n",
      "Train Epoch: 1305 [32768/54000 (61%)] Loss: -1529.541504\n",
      "    epoch          : 1305\n",
      "    loss           : -1530.1757374889446\n",
      "    ess            : 3.7731731792665877\n",
      "    log_marginal   : 1530.3024879311615\n",
      "    val_loss       : -1529.212178548177\n",
      "    val_ess        : 3.7708537578582764\n",
      "    val_log_marginal: 1529.3495686848958\n",
      "Train Epoch: 1306 [0/54000 (0%)] Loss: -1534.359375\n",
      "Train Epoch: 1306 [32768/54000 (61%)] Loss: -1530.552734\n",
      "    epoch          : 1306\n",
      "    loss           : -1530.2608366192512\n",
      "    ess            : 3.7706924384494998\n",
      "    log_marginal   : 1530.3932575729657\n",
      "    val_loss       : -1529.355244954427\n",
      "    val_ess        : 3.7572274605433145\n",
      "    val_log_marginal: 1529.4915364583333\n",
      "Train Epoch: 1307 [0/54000 (0%)] Loss: -1531.775879\n",
      "Train Epoch: 1307 [32768/54000 (61%)] Loss: -1529.520996\n",
      "    epoch          : 1307\n",
      "    loss           : -1530.3324941959022\n",
      "    ess            : 3.7726113121464566\n",
      "    log_marginal   : 1530.4595670880012\n",
      "    val_loss       : -1529.779296875\n",
      "    val_ess        : 3.7604614893595376\n",
      "    val_log_marginal: 1529.9146728515625\n",
      "Train Epoch: 1308 [0/54000 (0%)] Loss: -1529.203857\n",
      "Train Epoch: 1308 [32768/54000 (61%)] Loss: -1531.366211\n",
      "    epoch          : 1308\n",
      "    loss           : -1530.5023861291274\n",
      "    ess            : 3.7764059507621908\n",
      "    log_marginal   : 1530.6281623120578\n",
      "    val_loss       : -1529.7088419596355\n",
      "    val_ess        : 3.768067638079325\n",
      "    val_log_marginal: 1529.8438110351562\n",
      "Train Epoch: 1309 [0/54000 (0%)] Loss: -1534.034302\n",
      "Train Epoch: 1309 [32768/54000 (61%)] Loss: -1529.337646\n",
      "    epoch          : 1309\n",
      "    loss           : -1530.5974673864976\n",
      "    ess            : 3.777910736371886\n",
      "    log_marginal   : 1530.7252312426297\n",
      "    val_loss       : -1529.4921264648438\n",
      "    val_ess        : 3.7803673346837363\n",
      "    val_log_marginal: 1529.609151204427\n",
      "Train Epoch: 1310 [0/54000 (0%)] Loss: -1528.251587\n",
      "Train Epoch: 1310 [32768/54000 (61%)] Loss: -1529.178223\n",
      "    epoch          : 1310\n",
      "    loss           : -1530.5043761055424\n",
      "    ess            : 3.7701076606534563\n",
      "    log_marginal   : 1530.6360623341686\n",
      "    val_loss       : -1529.669901529948\n",
      "    val_ess        : 3.7710154056549072\n",
      "    val_log_marginal: 1529.8036092122395\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1310.pth ...\n",
      "Train Epoch: 1311 [0/54000 (0%)] Loss: -1532.196045\n",
      "Train Epoch: 1311 [32768/54000 (61%)] Loss: -1529.977173\n",
      "    epoch          : 1311\n",
      "    loss           : -1530.4787528559846\n",
      "    ess            : 3.77336604640169\n",
      "    log_marginal   : 1530.6082924896816\n",
      "    val_loss       : -1530.2360229492188\n",
      "    val_ess        : 3.7775067488352456\n",
      "    val_log_marginal: 1530.3515014648438\n",
      "Train Epoch: 1312 [0/54000 (0%)] Loss: -1532.915405\n",
      "Train Epoch: 1312 [32768/54000 (61%)] Loss: -1532.202393\n",
      "    epoch          : 1312\n",
      "    loss           : -1530.6162385760613\n",
      "    ess            : 3.772157592593499\n",
      "    log_marginal   : 1530.7459025832843\n",
      "    val_loss       : -1529.6478068033855\n",
      "    val_ess        : 3.780036966005961\n",
      "    val_log_marginal: 1529.7733357747395\n",
      "Train Epoch: 1313 [0/54000 (0%)] Loss: -1532.743896\n",
      "Train Epoch: 1313 [32768/54000 (61%)] Loss: -1528.308594\n",
      "    epoch          : 1313\n",
      "    loss           : -1530.5647295106132\n",
      "    ess            : 3.7745704291001805\n",
      "    log_marginal   : 1530.6892988096993\n",
      "    val_loss       : -1529.7816365559895\n",
      "    val_ess        : 3.7832137743631997\n",
      "    val_log_marginal: 1529.9101155598958\n",
      "Train Epoch: 1314 [0/54000 (0%)] Loss: -1529.300415\n",
      "Train Epoch: 1314 [32768/54000 (61%)] Loss: -1533.126465\n",
      "    epoch          : 1314\n",
      "    loss           : -1530.5610121241157\n",
      "    ess            : 3.771179545600459\n",
      "    log_marginal   : 1530.6908212337853\n",
      "    val_loss       : -1529.978006998698\n",
      "    val_ess        : 3.7705583969751992\n",
      "    val_log_marginal: 1530.1067708333333\n",
      "Train Epoch: 1315 [0/54000 (0%)] Loss: -1531.051270\n",
      "Train Epoch: 1315 [32768/54000 (61%)] Loss: -1531.337646\n",
      "    epoch          : 1315\n",
      "    loss           : -1530.588494066922\n",
      "    ess            : 3.7708128173396274\n",
      "    log_marginal   : 1530.7169557967277\n",
      "    val_loss       : -1530.1383260091145\n",
      "    val_ess        : 3.766221046447754\n",
      "    val_log_marginal: 1530.2713216145833\n",
      "Train Epoch: 1316 [0/54000 (0%)] Loss: -1531.859985\n",
      "Train Epoch: 1316 [32768/54000 (61%)] Loss: -1530.283203\n",
      "    epoch          : 1316\n",
      "    loss           : -1530.5714019199588\n",
      "    ess            : 3.773308902416589\n",
      "    log_marginal   : 1530.70005481648\n",
      "    val_loss       : -1530.1080729166667\n",
      "    val_ess        : 3.77696692943573\n",
      "    val_log_marginal: 1530.233154296875\n",
      "Train Epoch: 1317 [0/54000 (0%)] Loss: -1528.462646\n",
      "Train Epoch: 1317 [32768/54000 (61%)] Loss: -1529.276611\n",
      "    epoch          : 1317\n",
      "    loss           : -1530.602898363797\n",
      "    ess            : 3.770528406467078\n",
      "    log_marginal   : 1530.733112839033\n",
      "    val_loss       : -1530.3276774088542\n",
      "    val_ess        : 3.7712385257085166\n",
      "    val_log_marginal: 1530.4513142903645\n",
      "Train Epoch: 1318 [0/54000 (0%)] Loss: -1531.341064\n",
      "Train Epoch: 1318 [32768/54000 (61%)] Loss: -1526.220703\n",
      "    epoch          : 1318\n",
      "    loss           : -1530.692788178066\n",
      "    ess            : 3.7691578100312433\n",
      "    log_marginal   : 1530.8220859743515\n",
      "    val_loss       : -1530.1529337565105\n",
      "    val_ess        : 3.7670332193374634\n",
      "    val_log_marginal: 1530.2846069335938\n",
      "Train Epoch: 1319 [0/54000 (0%)] Loss: -1530.950317\n",
      "Train Epoch: 1319 [32768/54000 (61%)] Loss: -1534.040039\n",
      "    epoch          : 1319\n",
      "    loss           : -1530.730063384434\n",
      "    ess            : 3.7748557036777712\n",
      "    log_marginal   : 1530.8574702424823\n",
      "    val_loss       : -1530.478006998698\n",
      "    val_ess        : 3.7617408831914267\n",
      "    val_log_marginal: 1530.622538248698\n",
      "Train Epoch: 1320 [0/54000 (0%)] Loss: -1532.090088\n",
      "Train Epoch: 1320 [32768/54000 (61%)] Loss: -1534.082764\n",
      "    epoch          : 1320\n",
      "    loss           : -1530.792314637382\n",
      "    ess            : 3.7747438133887523\n",
      "    log_marginal   : 1530.9210988170696\n",
      "    val_loss       : -1530.3047688802083\n",
      "    val_ess        : 3.789663553237915\n",
      "    val_log_marginal: 1530.4258422851562\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1320.pth ...\n",
      "Train Epoch: 1321 [0/54000 (0%)] Loss: -1535.795898\n",
      "Train Epoch: 1321 [32768/54000 (61%)] Loss: -1530.537720\n",
      "    epoch          : 1321\n",
      "    loss           : -1530.8918433999115\n",
      "    ess            : 3.771278975144872\n",
      "    log_marginal   : 1531.016596956073\n",
      "    val_loss       : -1530.2871704101562\n",
      "    val_ess        : 3.7736313740412393\n",
      "    val_log_marginal: 1530.4112345377605\n",
      "Train Epoch: 1322 [0/54000 (0%)] Loss: -1531.994385\n",
      "Train Epoch: 1322 [32768/54000 (61%)] Loss: -1530.489258\n",
      "    epoch          : 1322\n",
      "    loss           : -1530.9526390219635\n",
      "    ess            : 3.774748586258798\n",
      "    log_marginal   : 1531.0797441590507\n",
      "    val_loss       : -1530.3966878255208\n",
      "    val_ess        : 3.7770506540934243\n",
      "    val_log_marginal: 1530.528076171875\n",
      "Train Epoch: 1323 [0/54000 (0%)] Loss: -1532.876221\n",
      "Train Epoch: 1323 [32768/54000 (61%)] Loss: -1528.151367\n",
      "    epoch          : 1323\n",
      "    loss           : -1531.0011400906544\n",
      "    ess            : 3.7764759603536353\n",
      "    log_marginal   : 1531.1254606426887\n",
      "    val_loss       : -1530.5052490234375\n",
      "    val_ess        : 3.762231429417928\n",
      "    val_log_marginal: 1530.6436971028645\n",
      "Train Epoch: 1324 [0/54000 (0%)] Loss: -1533.014648\n",
      "Train Epoch: 1324 [32768/54000 (61%)] Loss: -1530.323730\n",
      "    epoch          : 1324\n",
      "    loss           : -1531.0490860849056\n",
      "    ess            : 3.7755925340472527\n",
      "    log_marginal   : 1531.1759793263561\n",
      "    val_loss       : -1530.124735514323\n",
      "    val_ess        : 3.77434504032135\n",
      "    val_log_marginal: 1530.2611287434895\n",
      "Train Epoch: 1325 [0/54000 (0%)] Loss: -1531.679199\n",
      "Train Epoch: 1325 [32768/54000 (61%)] Loss: -1528.161011\n",
      "    epoch          : 1325\n",
      "    loss           : -1531.041388745578\n",
      "    ess            : 3.7748842194395245\n",
      "    log_marginal   : 1531.1679595371463\n",
      "    val_loss       : -1530.4190673828125\n",
      "    val_ess        : 3.7761340141296387\n",
      "    val_log_marginal: 1530.5513305664062\n",
      "Train Epoch: 1326 [0/54000 (0%)] Loss: -1533.648560\n",
      "Train Epoch: 1326 [32768/54000 (61%)] Loss: -1528.745117\n",
      "    epoch          : 1326\n",
      "    loss           : -1530.9940669221698\n",
      "    ess            : 3.7725320312212096\n",
      "    log_marginal   : 1531.1260065042748\n",
      "    val_loss       : -1530.215352376302\n",
      "    val_ess        : 3.7809971968332925\n",
      "    val_log_marginal: 1530.3409830729167\n",
      "Train Epoch: 1327 [0/54000 (0%)] Loss: -1527.244385\n",
      "Train Epoch: 1327 [32768/54000 (61%)] Loss: -1526.030151\n",
      "    epoch          : 1327\n",
      "    loss           : -1531.126054871757\n",
      "    ess            : 3.7699290401530714\n",
      "    log_marginal   : 1531.2570524395637\n",
      "    val_loss       : -1530.193379720052\n",
      "    val_ess        : 3.783005873362223\n",
      "    val_log_marginal: 1530.3248494466145\n",
      "Train Epoch: 1328 [0/54000 (0%)] Loss: -1530.836304\n",
      "Train Epoch: 1328 [32768/54000 (61%)] Loss: -1533.264648\n",
      "    epoch          : 1328\n",
      "    loss           : -1531.1881448997642\n",
      "    ess            : 3.775000662173865\n",
      "    log_marginal   : 1531.312032447671\n",
      "    val_loss       : -1530.556131998698\n",
      "    val_ess        : 3.7845776875813804\n",
      "    val_log_marginal: 1530.6761067708333\n",
      "Train Epoch: 1329 [0/54000 (0%)] Loss: -1533.445068\n",
      "Train Epoch: 1329 [32768/54000 (61%)] Loss: -1529.493896\n",
      "    epoch          : 1329\n",
      "    loss           : -1531.220099683078\n",
      "    ess            : 3.7721978853333673\n",
      "    log_marginal   : 1531.3498558188385\n",
      "    val_loss       : -1530.3418986002605\n",
      "    val_ess        : 3.771050055821737\n",
      "    val_log_marginal: 1530.473368326823\n",
      "Train Epoch: 1330 [0/54000 (0%)] Loss: -1528.991577\n",
      "Train Epoch: 1330 [32768/54000 (61%)] Loss: -1532.453125\n",
      "    epoch          : 1330\n",
      "    loss           : -1531.3153444686027\n",
      "    ess            : 3.7752894860393598\n",
      "    log_marginal   : 1531.4427835716392\n",
      "    val_loss       : -1530.6956176757812\n",
      "    val_ess        : 3.782305598258972\n",
      "    val_log_marginal: 1530.8294474283855\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1330.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1331 [0/54000 (0%)] Loss: -1532.786255\n",
      "Train Epoch: 1331 [32768/54000 (61%)] Loss: -1531.167114\n",
      "    epoch          : 1331\n",
      "    loss           : -1531.3286317069576\n",
      "    ess            : 3.7775912284851074\n",
      "    log_marginal   : 1531.4571694428066\n",
      "    val_loss       : -1530.9090372721355\n",
      "    val_ess        : 3.7672165632247925\n",
      "    val_log_marginal: 1531.0405883789062\n",
      "Train Epoch: 1332 [0/54000 (0%)] Loss: -1533.066406\n",
      "Train Epoch: 1332 [32768/54000 (61%)] Loss: -1530.448486\n",
      "    epoch          : 1332\n",
      "    loss           : -1531.4532608895931\n",
      "    ess            : 3.775556078496969\n",
      "    log_marginal   : 1531.5833509913032\n",
      "    val_loss       : -1530.3022867838542\n",
      "    val_ess        : 3.768530488014221\n",
      "    val_log_marginal: 1530.4395955403645\n",
      "Train Epoch: 1333 [0/54000 (0%)] Loss: -1531.596680\n",
      "Train Epoch: 1333 [32768/54000 (61%)] Loss: -1529.229858\n",
      "    epoch          : 1333\n",
      "    loss           : -1531.5978911777713\n",
      "    ess            : 3.7750198076356134\n",
      "    log_marginal   : 1531.7263575140034\n",
      "    val_loss       : -1530.7815551757812\n",
      "    val_ess        : 3.791593631108602\n",
      "    val_log_marginal: 1530.8907470703125\n",
      "Train Epoch: 1334 [0/54000 (0%)] Loss: -1528.441528\n",
      "Train Epoch: 1334 [32768/54000 (61%)] Loss: -1534.844971\n",
      "    epoch          : 1334\n",
      "    loss           : -1531.5112281655365\n",
      "    ess            : 3.7757286710559197\n",
      "    log_marginal   : 1531.6379233306309\n",
      "    val_loss       : -1530.4954833984375\n",
      "    val_ess        : 3.7757612069447837\n",
      "    val_log_marginal: 1530.6220296223958\n",
      "Train Epoch: 1335 [0/54000 (0%)] Loss: -1534.748169\n",
      "Train Epoch: 1335 [32768/54000 (61%)] Loss: -1532.889648\n",
      "    epoch          : 1335\n",
      "    loss           : -1531.5879896631782\n",
      "    ess            : 3.7714163042464346\n",
      "    log_marginal   : 1531.7209933298939\n",
      "    val_loss       : -1530.8927408854167\n",
      "    val_ess        : 3.7664669354756675\n",
      "    val_log_marginal: 1531.0245361328125\n",
      "Train Epoch: 1336 [0/54000 (0%)] Loss: -1529.757568\n",
      "Train Epoch: 1336 [32768/54000 (61%)] Loss: -1531.231201\n",
      "    epoch          : 1336\n",
      "    loss           : -1531.653377892836\n",
      "    ess            : 3.77284836769104\n",
      "    log_marginal   : 1531.7830073518573\n",
      "    val_loss       : -1530.902608235677\n",
      "    val_ess        : 3.783334255218506\n",
      "    val_log_marginal: 1531.0267333984375\n",
      "Train Epoch: 1337 [0/54000 (0%)] Loss: -1532.300903\n",
      "Train Epoch: 1337 [32768/54000 (61%)] Loss: -1534.005249\n",
      "    epoch          : 1337\n",
      "    loss           : -1531.7254016804245\n",
      "    ess            : 3.774741622636903\n",
      "    log_marginal   : 1531.8553466796875\n",
      "    val_loss       : -1531.329833984375\n",
      "    val_ess        : 3.77605938911438\n",
      "    val_log_marginal: 1531.4481404622395\n",
      "Train Epoch: 1338 [0/54000 (0%)] Loss: -1530.345093\n",
      "Train Epoch: 1338 [32768/54000 (61%)] Loss: -1533.939941\n",
      "    epoch          : 1338\n",
      "    loss           : -1531.820966612618\n",
      "    ess            : 3.7756849774774515\n",
      "    log_marginal   : 1531.947998046875\n",
      "    val_loss       : -1531.1532389322917\n",
      "    val_ess        : 3.7681144078572593\n",
      "    val_log_marginal: 1531.2835489908855\n",
      "Train Epoch: 1339 [0/54000 (0%)] Loss: -1529.949219\n",
      "Train Epoch: 1339 [32768/54000 (61%)] Loss: -1530.421875\n",
      "    epoch          : 1339\n",
      "    loss           : -1531.9594611401828\n",
      "    ess            : 3.7740098620360754\n",
      "    log_marginal   : 1532.0857785782723\n",
      "    val_loss       : -1531.1410115559895\n",
      "    val_ess        : 3.7709930340449014\n",
      "    val_log_marginal: 1531.2692057291667\n",
      "Train Epoch: 1340 [0/54000 (0%)] Loss: -1532.381958\n",
      "Train Epoch: 1340 [32768/54000 (61%)] Loss: -1531.979004\n",
      "    epoch          : 1340\n",
      "    loss           : -1532.0098093860554\n",
      "    ess            : 3.7686057315682464\n",
      "    log_marginal   : 1532.142251068691\n",
      "    val_loss       : -1531.0250854492188\n",
      "    val_ess        : 3.7697739203770957\n",
      "    val_log_marginal: 1531.1629638671875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1340.pth ...\n",
      "Train Epoch: 1341 [0/54000 (0%)] Loss: -1532.999634\n",
      "Train Epoch: 1341 [32768/54000 (61%)] Loss: -1534.734497\n",
      "    epoch          : 1341\n",
      "    loss           : -1531.986894715507\n",
      "    ess            : 3.7674430316349246\n",
      "    log_marginal   : 1532.1229409271816\n",
      "    val_loss       : -1531.5724690755208\n",
      "    val_ess        : 3.7646615902582803\n",
      "    val_log_marginal: 1531.7076009114583\n",
      "Train Epoch: 1342 [0/54000 (0%)] Loss: -1534.256104\n",
      "Train Epoch: 1342 [32768/54000 (61%)] Loss: -1530.704834\n",
      "    epoch          : 1342\n",
      "    loss           : -1532.1426909824588\n",
      "    ess            : 3.7705176146525257\n",
      "    log_marginal   : 1532.2748931308963\n",
      "    val_loss       : -1531.5673421223958\n",
      "    val_ess        : 3.7767709493637085\n",
      "    val_log_marginal: 1531.697041829427\n",
      "Train Epoch: 1343 [0/54000 (0%)] Loss: -1530.779663\n",
      "Train Epoch: 1343 [32768/54000 (61%)] Loss: -1528.756348\n",
      "    epoch          : 1343\n",
      "    loss           : -1532.1094809478184\n",
      "    ess            : 3.776563289030543\n",
      "    log_marginal   : 1532.2361116229363\n",
      "    val_loss       : -1531.42236328125\n",
      "    val_ess        : 3.7642794847488403\n",
      "    val_log_marginal: 1531.5652262369792\n",
      "Train Epoch: 1344 [0/54000 (0%)] Loss: -1536.399170\n",
      "Train Epoch: 1344 [32768/54000 (61%)] Loss: -1531.130371\n",
      "    epoch          : 1344\n",
      "    loss           : -1532.0323186910377\n",
      "    ess            : 3.773171015505521\n",
      "    log_marginal   : 1532.1637446565448\n",
      "    val_loss       : -1531.5527954101562\n",
      "    val_ess        : 3.77567728360494\n",
      "    val_log_marginal: 1531.6761474609375\n",
      "Train Epoch: 1345 [0/54000 (0%)] Loss: -1531.871338\n",
      "Train Epoch: 1345 [32768/54000 (61%)] Loss: -1530.462646\n",
      "    epoch          : 1345\n",
      "    loss           : -1532.2001768867924\n",
      "    ess            : 3.774346783476056\n",
      "    log_marginal   : 1532.327475493809\n",
      "    val_loss       : -1531.667012532552\n",
      "    val_ess        : 3.7790479262669883\n",
      "    val_log_marginal: 1531.7852783203125\n",
      "Train Epoch: 1346 [0/54000 (0%)] Loss: -1532.516724\n",
      "Train Epoch: 1346 [32768/54000 (61%)] Loss: -1531.949097\n",
      "    epoch          : 1346\n",
      "    loss           : -1532.44189453125\n",
      "    ess            : 3.773726368850132\n",
      "    log_marginal   : 1532.5704138413914\n",
      "    val_loss       : -1531.8272705078125\n",
      "    val_ess        : 3.771730581919352\n",
      "    val_log_marginal: 1531.951436360677\n",
      "Train Epoch: 1347 [0/54000 (0%)] Loss: -1535.746582\n",
      "Train Epoch: 1347 [32768/54000 (61%)] Loss: -1533.436523\n",
      "    epoch          : 1347\n",
      "    loss           : -1532.4551264924823\n",
      "    ess            : 3.7745847027256803\n",
      "    log_marginal   : 1532.580805940448\n",
      "    val_loss       : -1531.7805582682292\n",
      "    val_ess        : 3.767438054084778\n",
      "    val_log_marginal: 1531.905517578125\n",
      "Train Epoch: 1348 [0/54000 (0%)] Loss: -1534.355957\n",
      "Train Epoch: 1348 [32768/54000 (61%)] Loss: -1532.198120\n",
      "    epoch          : 1348\n",
      "    loss           : -1532.4652145673645\n",
      "    ess            : 3.775626348999311\n",
      "    log_marginal   : 1532.592711250737\n",
      "    val_loss       : -1531.8709513346355\n",
      "    val_ess        : 3.779964288075765\n",
      "    val_log_marginal: 1531.994873046875\n",
      "Train Epoch: 1349 [0/54000 (0%)] Loss: -1533.579346\n",
      "Train Epoch: 1349 [32768/54000 (61%)] Loss: -1535.868896\n",
      "    epoch          : 1349\n",
      "    loss           : -1532.5123406176297\n",
      "    ess            : 3.7730304745008363\n",
      "    log_marginal   : 1532.6443861475532\n",
      "    val_loss       : -1531.7677612304688\n",
      "    val_ess        : 3.7864689429601035\n",
      "    val_log_marginal: 1531.8941040039062\n",
      "Train Epoch: 1350 [0/54000 (0%)] Loss: -1534.571899\n",
      "Train Epoch: 1350 [32768/54000 (61%)] Loss: -1534.348999\n",
      "    epoch          : 1350\n",
      "    loss           : -1532.5449103589328\n",
      "    ess            : 3.7692636453880453\n",
      "    log_marginal   : 1532.677329009434\n",
      "    val_loss       : -1531.8729451497395\n",
      "    val_ess        : 3.7743524312973022\n",
      "    val_log_marginal: 1532.001241048177\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1350.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1351 [0/54000 (0%)] Loss: -1534.208252\n",
      "Train Epoch: 1351 [32768/54000 (61%)] Loss: -1535.334839\n",
      "    epoch          : 1351\n",
      "    loss           : -1532.712704064711\n",
      "    ess            : 3.7732623703074903\n",
      "    log_marginal   : 1532.841313200177\n",
      "    val_loss       : -1531.947285970052\n",
      "    val_ess        : 3.7826955715815225\n",
      "    val_log_marginal: 1532.0685628255208\n",
      "Train Epoch: 1352 [0/54000 (0%)] Loss: -1533.463379\n",
      "Train Epoch: 1352 [32768/54000 (61%)] Loss: -1531.602051\n",
      "    epoch          : 1352\n",
      "    loss           : -1532.8539555387677\n",
      "    ess            : 3.7730765882528052\n",
      "    log_marginal   : 1532.9841377690154\n",
      "    val_loss       : -1531.9435628255208\n",
      "    val_ess        : 3.7647154728571572\n",
      "    val_log_marginal: 1532.0800170898438\n",
      "Train Epoch: 1353 [0/54000 (0%)] Loss: -1532.741821\n",
      "Train Epoch: 1353 [32768/54000 (61%)] Loss: -1533.782959\n",
      "    epoch          : 1353\n",
      "    loss           : -1532.7635290757664\n",
      "    ess            : 3.7724737221339963\n",
      "    log_marginal   : 1532.8944414246757\n",
      "    val_loss       : -1531.5598958333333\n",
      "    val_ess        : 3.765317916870117\n",
      "    val_log_marginal: 1531.6856079101562\n",
      "Train Epoch: 1354 [0/54000 (0%)] Loss: -1534.263794\n",
      "Train Epoch: 1354 [32768/54000 (61%)] Loss: -1532.732544\n",
      "    epoch          : 1354\n",
      "    loss           : -1532.871519844487\n",
      "    ess            : 3.7731673987406604\n",
      "    log_marginal   : 1533.0001957731427\n",
      "    val_loss       : -1531.8287556966145\n",
      "    val_ess        : 3.770107944806417\n",
      "    val_log_marginal: 1531.962381998698\n",
      "Train Epoch: 1355 [0/54000 (0%)] Loss: -1534.500977\n",
      "Train Epoch: 1355 [32768/54000 (61%)] Loss: -1535.318604\n",
      "    epoch          : 1355\n",
      "    loss           : -1532.9556746572819\n",
      "    ess            : 3.774824650782459\n",
      "    log_marginal   : 1533.0836642283314\n",
      "    val_loss       : -1532.268575032552\n",
      "    val_ess        : 3.7738474210103354\n",
      "    val_log_marginal: 1532.3970133463542\n",
      "Train Epoch: 1356 [0/54000 (0%)] Loss: -1534.346436\n",
      "Train Epoch: 1356 [32768/54000 (61%)] Loss: -1533.760742\n",
      "    epoch          : 1356\n",
      "    loss           : -1532.9402293079304\n",
      "    ess            : 3.769192691119212\n",
      "    log_marginal   : 1533.0759116118809\n",
      "    val_loss       : -1532.2220458984375\n",
      "    val_ess        : 3.7671976884206138\n",
      "    val_log_marginal: 1532.3560384114583\n",
      "Train Epoch: 1357 [0/54000 (0%)] Loss: -1532.403564\n",
      "Train Epoch: 1357 [32768/54000 (61%)] Loss: -1537.347778\n",
      "    epoch          : 1357\n",
      "    loss           : -1533.0769779997052\n",
      "    ess            : 3.7748424512035443\n",
      "    log_marginal   : 1533.206911482901\n",
      "    val_loss       : -1531.6628824869792\n",
      "    val_ess        : 3.771008054415385\n",
      "    val_log_marginal: 1531.7908935546875\n",
      "Train Epoch: 1358 [0/54000 (0%)] Loss: -1533.615601\n",
      "Train Epoch: 1358 [32768/54000 (61%)] Loss: -1533.422119\n",
      "    epoch          : 1358\n",
      "    loss           : -1533.191021613355\n",
      "    ess            : 3.776803529487466\n",
      "    log_marginal   : 1533.315408958579\n",
      "    val_loss       : -1532.4112345377605\n",
      "    val_ess        : 3.7777041594187417\n",
      "    val_log_marginal: 1532.5393880208333\n",
      "Train Epoch: 1359 [0/54000 (0%)] Loss: -1532.733521\n",
      "Train Epoch: 1359 [32768/54000 (61%)] Loss: -1533.802734\n",
      "    epoch          : 1359\n",
      "    loss           : -1533.2411648732311\n",
      "    ess            : 3.7728718361764586\n",
      "    log_marginal   : 1533.3708933704304\n",
      "    val_loss       : -1532.9944254557292\n",
      "    val_ess        : 3.7799498240152993\n",
      "    val_log_marginal: 1533.1165364583333\n",
      "Train Epoch: 1360 [0/54000 (0%)] Loss: -1534.969238\n",
      "Train Epoch: 1360 [32768/54000 (61%)] Loss: -1532.401611\n",
      "    epoch          : 1360\n",
      "    loss           : -1533.2388962079895\n",
      "    ess            : 3.7752797468653263\n",
      "    log_marginal   : 1533.3681410303657\n",
      "    val_loss       : -1532.666524251302\n",
      "    val_ess        : 3.7759321133295694\n",
      "    val_log_marginal: 1532.8012288411458\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1360.pth ...\n",
      "Train Epoch: 1361 [0/54000 (0%)] Loss: -1535.264893\n",
      "Train Epoch: 1361 [32768/54000 (61%)] Loss: -1530.560303\n",
      "    epoch          : 1361\n",
      "    loss           : -1533.2442857274468\n",
      "    ess            : 3.775396909353868\n",
      "    log_marginal   : 1533.37151523806\n",
      "    val_loss       : -1532.46044921875\n",
      "    val_ess        : 3.7732434272766113\n",
      "    val_log_marginal: 1532.5909423828125\n",
      "Train Epoch: 1362 [0/54000 (0%)] Loss: -1533.053955\n",
      "Train Epoch: 1362 [32768/54000 (61%)] Loss: -1534.620850\n",
      "    epoch          : 1362\n",
      "    loss           : -1533.36865234375\n",
      "    ess            : 3.772059445111257\n",
      "    log_marginal   : 1533.5003569980838\n",
      "    val_loss       : -1532.8262939453125\n",
      "    val_ess        : 3.7671573162078857\n",
      "    val_log_marginal: 1532.9656168619792\n",
      "Train Epoch: 1363 [0/54000 (0%)] Loss: -1533.234863\n",
      "Train Epoch: 1363 [32768/54000 (61%)] Loss: -1532.692017\n",
      "    epoch          : 1363\n",
      "    loss           : -1533.5380997567806\n",
      "    ess            : 3.773546088416621\n",
      "    log_marginal   : 1533.6664578419811\n",
      "    val_loss       : -1532.4620361328125\n",
      "    val_ess        : 3.7814029455184937\n",
      "    val_log_marginal: 1532.5850016276042\n",
      "Train Epoch: 1364 [0/54000 (0%)] Loss: -1535.536865\n",
      "Train Epoch: 1364 [32768/54000 (61%)] Loss: -1530.298828\n",
      "    epoch          : 1364\n",
      "    loss           : -1533.5234628353478\n",
      "    ess            : 3.7767909832720488\n",
      "    log_marginal   : 1533.6502639482605\n",
      "    val_loss       : -1532.4337565104167\n",
      "    val_ess        : 3.7786960999170938\n",
      "    val_log_marginal: 1532.5627848307292\n",
      "Train Epoch: 1365 [0/54000 (0%)] Loss: -1533.196655\n",
      "Train Epoch: 1365 [32768/54000 (61%)] Loss: -1534.228149\n",
      "    epoch          : 1365\n",
      "    loss           : -1533.5160649137677\n",
      "    ess            : 3.7694522434810422\n",
      "    log_marginal   : 1533.6510677697524\n",
      "    val_loss       : -1532.4061482747395\n",
      "    val_ess        : 3.768132209777832\n",
      "    val_log_marginal: 1532.529541015625\n",
      "Train Epoch: 1366 [0/54000 (0%)] Loss: -1532.674072\n",
      "Train Epoch: 1366 [32768/54000 (61%)] Loss: -1533.447388\n",
      "    epoch          : 1366\n",
      "    loss           : -1533.589641067217\n",
      "    ess            : 3.773760273771466\n",
      "    log_marginal   : 1533.719685104658\n",
      "    val_loss       : -1532.7218017578125\n",
      "    val_ess        : 3.77763831615448\n",
      "    val_log_marginal: 1532.8511352539062\n",
      "Train Epoch: 1367 [0/54000 (0%)] Loss: -1530.456665\n",
      "Train Epoch: 1367 [32768/54000 (61%)] Loss: -1534.564331\n",
      "    epoch          : 1367\n",
      "    loss           : -1533.7033714438385\n",
      "    ess            : 3.7724176037986323\n",
      "    log_marginal   : 1533.8350346403302\n",
      "    val_loss       : -1532.8414103190105\n",
      "    val_ess        : 3.775675376256307\n",
      "    val_log_marginal: 1532.9701334635417\n",
      "Train Epoch: 1368 [0/54000 (0%)] Loss: -1534.401855\n",
      "Train Epoch: 1368 [32768/54000 (61%)] Loss: -1533.128784\n",
      "    epoch          : 1368\n",
      "    loss           : -1533.7211568580483\n",
      "    ess            : 3.7778484686365665\n",
      "    log_marginal   : 1533.8480524027123\n",
      "    val_loss       : -1532.609619140625\n",
      "    val_ess        : 3.770772178967794\n",
      "    val_log_marginal: 1532.7415771484375\n",
      "Train Epoch: 1369 [0/54000 (0%)] Loss: -1533.604980\n",
      "Train Epoch: 1369 [32768/54000 (61%)] Loss: -1535.635742\n",
      "    epoch          : 1369\n",
      "    loss           : -1533.6594491634728\n",
      "    ess            : 3.776505749180632\n",
      "    log_marginal   : 1533.7876322044517\n",
      "    val_loss       : -1532.6512247721355\n",
      "    val_ess        : 3.7757680416107178\n",
      "    val_log_marginal: 1532.7793782552083\n",
      "Train Epoch: 1370 [0/54000 (0%)] Loss: -1535.712158\n",
      "Train Epoch: 1370 [32768/54000 (61%)] Loss: -1533.890625\n",
      "    epoch          : 1370\n",
      "    loss           : -1533.7391979289505\n",
      "    ess            : 3.774271362232712\n",
      "    log_marginal   : 1533.8686177955483\n",
      "    val_loss       : -1533.001729329427\n",
      "    val_ess        : 3.7763336102167764\n",
      "    val_log_marginal: 1533.1334635416667\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1370.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1371 [0/54000 (0%)] Loss: -1533.892090\n",
      "Train Epoch: 1371 [32768/54000 (61%)] Loss: -1531.914551\n",
      "    epoch          : 1371\n",
      "    loss           : -1533.8619499926297\n",
      "    ess            : 3.7784720231901923\n",
      "    log_marginal   : 1533.9869476894162\n",
      "    val_loss       : -1533.123758951823\n",
      "    val_ess        : 3.772536555926005\n",
      "    val_log_marginal: 1533.2545166015625\n",
      "Train Epoch: 1372 [0/54000 (0%)] Loss: -1537.052368\n",
      "Train Epoch: 1372 [32768/54000 (61%)] Loss: -1531.961182\n",
      "    epoch          : 1372\n",
      "    loss           : -1533.7439402454304\n",
      "    ess            : 3.7722712057941363\n",
      "    log_marginal   : 1533.8742906102593\n",
      "    val_loss       : -1532.777364095052\n",
      "    val_ess        : 3.7674026489257812\n",
      "    val_log_marginal: 1532.920918782552\n",
      "Train Epoch: 1373 [0/54000 (0%)] Loss: -1536.014404\n",
      "Train Epoch: 1373 [32768/54000 (61%)] Loss: -1532.592285\n",
      "    epoch          : 1373\n",
      "    loss           : -1533.9265873747052\n",
      "    ess            : 3.7723790474657743\n",
      "    log_marginal   : 1534.0540656323703\n",
      "    val_loss       : -1532.8009033203125\n",
      "    val_ess        : 3.770848194758097\n",
      "    val_log_marginal: 1532.9172973632812\n",
      "Train Epoch: 1374 [0/54000 (0%)] Loss: -1533.718994\n",
      "Train Epoch: 1374 [32768/54000 (61%)] Loss: -1530.439941\n",
      "    epoch          : 1374\n",
      "    loss           : -1533.7551522884728\n",
      "    ess            : 3.7697166766760484\n",
      "    log_marginal   : 1533.885539504717\n",
      "    val_loss       : -1532.91357421875\n",
      "    val_ess        : 3.7787615060806274\n",
      "    val_log_marginal: 1533.0350138346355\n",
      "Train Epoch: 1375 [0/54000 (0%)] Loss: -1533.773193\n",
      "Train Epoch: 1375 [32768/54000 (61%)] Loss: -1534.317017\n",
      "    epoch          : 1375\n",
      "    loss           : -1533.7967298975532\n",
      "    ess            : 3.7724606765891022\n",
      "    log_marginal   : 1533.9268061799823\n",
      "    val_loss       : -1532.7457885742188\n",
      "    val_ess        : 3.7599716186523438\n",
      "    val_log_marginal: 1532.885274251302\n",
      "Train Epoch: 1376 [0/54000 (0%)] Loss: -1536.097900\n",
      "Train Epoch: 1376 [32768/54000 (61%)] Loss: -1537.558105\n",
      "    epoch          : 1376\n",
      "    loss           : -1533.9102092239093\n",
      "    ess            : 3.774597707784401\n",
      "    log_marginal   : 1534.0375492887677\n",
      "    val_loss       : -1533.027119954427\n",
      "    val_ess        : 3.782698710759481\n",
      "    val_log_marginal: 1533.1477457682292\n",
      "Train Epoch: 1377 [0/54000 (0%)] Loss: -1536.314209\n",
      "Train Epoch: 1377 [32768/54000 (61%)] Loss: -1532.062866\n",
      "    epoch          : 1377\n",
      "    loss           : -1533.8657295658904\n",
      "    ess            : 3.770695169017\n",
      "    log_marginal   : 1533.9963401938385\n",
      "    val_loss       : -1533.3029378255208\n",
      "    val_ess        : 3.758490244547526\n",
      "    val_log_marginal: 1533.4361979166667\n",
      "Train Epoch: 1378 [0/54000 (0%)] Loss: -1532.715942\n",
      "Train Epoch: 1378 [32768/54000 (61%)] Loss: -1531.645996\n",
      "    epoch          : 1378\n",
      "    loss           : -1533.8736295880012\n",
      "    ess            : 3.7711018481344545\n",
      "    log_marginal   : 1534.0043553766216\n",
      "    val_loss       : -1532.9615885416667\n",
      "    val_ess        : 3.776718775431315\n",
      "    val_log_marginal: 1533.087381998698\n",
      "Train Epoch: 1379 [0/54000 (0%)] Loss: -1533.900513\n",
      "Train Epoch: 1379 [32768/54000 (61%)] Loss: -1532.684448\n",
      "    epoch          : 1379\n",
      "    loss           : -1534.0039707399765\n",
      "    ess            : 3.7694410018201143\n",
      "    log_marginal   : 1534.1337568175118\n",
      "    val_loss       : -1533.1070760091145\n",
      "    val_ess        : 3.785161018371582\n",
      "    val_log_marginal: 1533.2220052083333\n",
      "Train Epoch: 1380 [0/54000 (0%)] Loss: -1534.822266\n",
      "Train Epoch: 1380 [32768/54000 (61%)] Loss: -1536.719971\n",
      "    epoch          : 1380\n",
      "    loss           : -1534.0018609964623\n",
      "    ess            : 3.7726809708577282\n",
      "    log_marginal   : 1534.1346297354069\n",
      "    val_loss       : -1533.1327718098958\n",
      "    val_ess        : 3.7797324657440186\n",
      "    val_log_marginal: 1533.2657470703125\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1380.pth ...\n",
      "Train Epoch: 1381 [0/54000 (0%)] Loss: -1535.382080\n",
      "Train Epoch: 1381 [32768/54000 (61%)] Loss: -1537.545776\n",
      "    epoch          : 1381\n",
      "    loss           : -1534.061845887382\n",
      "    ess            : 3.7749791190309345\n",
      "    log_marginal   : 1534.1920511497642\n",
      "    val_loss       : -1533.2237141927083\n",
      "    val_ess        : 3.7672389348347983\n",
      "    val_log_marginal: 1533.3560384114583\n",
      "Train Epoch: 1382 [0/54000 (0%)] Loss: -1530.457031\n",
      "Train Epoch: 1382 [32768/54000 (61%)] Loss: -1537.157959\n",
      "    epoch          : 1382\n",
      "    loss           : -1534.1093381485848\n",
      "    ess            : 3.7773461071950085\n",
      "    log_marginal   : 1534.2361277454304\n",
      "    val_loss       : -1533.4241739908855\n",
      "    val_ess        : 3.7667167584101358\n",
      "    val_log_marginal: 1533.5604858398438\n",
      "Train Epoch: 1383 [0/54000 (0%)] Loss: -1535.265259\n",
      "Train Epoch: 1383 [32768/54000 (61%)] Loss: -1537.139893\n",
      "    epoch          : 1383\n",
      "    loss           : -1534.2611913141216\n",
      "    ess            : 3.772039926277017\n",
      "    log_marginal   : 1534.391596956073\n",
      "    val_loss       : -1533.3541666666667\n",
      "    val_ess        : 3.7689934968948364\n",
      "    val_log_marginal: 1533.484110514323\n",
      "Train Epoch: 1384 [0/54000 (0%)] Loss: -1535.170166\n",
      "Train Epoch: 1384 [32768/54000 (61%)] Loss: -1532.578491\n",
      "    epoch          : 1384\n",
      "    loss           : -1534.1952940742924\n",
      "    ess            : 3.7708717607102304\n",
      "    log_marginal   : 1534.3270931603774\n",
      "    val_loss       : -1533.4062906901042\n",
      "    val_ess        : 3.7746415932973227\n",
      "    val_log_marginal: 1533.531514485677\n",
      "Train Epoch: 1385 [0/54000 (0%)] Loss: -1536.500610\n",
      "Train Epoch: 1385 [32768/54000 (61%)] Loss: -1532.223633\n",
      "    epoch          : 1385\n",
      "    loss           : -1534.3796271558078\n",
      "    ess            : 3.7766974017305195\n",
      "    log_marginal   : 1534.5062209795105\n",
      "    val_loss       : -1533.5621541341145\n",
      "    val_ess        : 3.756485382715861\n",
      "    val_log_marginal: 1533.7034301757812\n",
      "Train Epoch: 1386 [0/54000 (0%)] Loss: -1535.276855\n",
      "Train Epoch: 1386 [32768/54000 (61%)] Loss: -1533.963867\n",
      "    epoch          : 1386\n",
      "    loss           : -1534.3734084795105\n",
      "    ess            : 3.7725328859293237\n",
      "    log_marginal   : 1534.5062117666569\n",
      "    val_loss       : -1533.7952677408855\n",
      "    val_ess        : 3.77440353234609\n",
      "    val_log_marginal: 1533.9266560872395\n",
      "Train Epoch: 1387 [0/54000 (0%)] Loss: -1536.557129\n",
      "Train Epoch: 1387 [32768/54000 (61%)] Loss: -1538.720947\n",
      "    epoch          : 1387\n",
      "    loss           : -1534.2424661888267\n",
      "    ess            : 3.7719587694923833\n",
      "    log_marginal   : 1534.370584739829\n",
      "    val_loss       : -1533.6243693033855\n",
      "    val_ess        : 3.7742968797683716\n",
      "    val_log_marginal: 1533.7523396809895\n",
      "Train Epoch: 1388 [0/54000 (0%)] Loss: -1533.769287\n",
      "Train Epoch: 1388 [32768/54000 (61%)] Loss: -1534.140869\n",
      "    epoch          : 1388\n",
      "    loss           : -1534.3415020636792\n",
      "    ess            : 3.7703423859938137\n",
      "    log_marginal   : 1534.4739529591686\n",
      "    val_loss       : -1533.8067423502605\n",
      "    val_ess        : 3.7765182654062905\n",
      "    val_log_marginal: 1533.9412638346355\n",
      "Train Epoch: 1389 [0/54000 (0%)] Loss: -1534.978516\n",
      "Train Epoch: 1389 [32768/54000 (61%)] Loss: -1534.753296\n",
      "    epoch          : 1389\n",
      "    loss           : -1534.3450006448998\n",
      "    ess            : 3.7696597126294984\n",
      "    log_marginal   : 1534.475507628243\n",
      "    val_loss       : -1533.730733235677\n",
      "    val_ess        : 3.778756062189738\n",
      "    val_log_marginal: 1533.856709798177\n",
      "Train Epoch: 1390 [0/54000 (0%)] Loss: -1534.028442\n",
      "Train Epoch: 1390 [32768/54000 (61%)] Loss: -1534.549805\n",
      "    epoch          : 1390\n",
      "    loss           : -1534.4779927955483\n",
      "    ess            : 3.775588737343842\n",
      "    log_marginal   : 1534.6057635613208\n",
      "    val_loss       : -1533.2981363932292\n",
      "    val_ess        : 3.7970039447148642\n",
      "    val_log_marginal: 1533.4146321614583\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1390.pth ...\n",
      "Train Epoch: 1391 [0/54000 (0%)] Loss: -1536.656372\n",
      "Train Epoch: 1391 [32768/54000 (61%)] Loss: -1533.827881\n",
      "    epoch          : 1391\n",
      "    loss           : -1534.4469961490272\n",
      "    ess            : 3.7749917237263806\n",
      "    log_marginal   : 1534.574702424823\n",
      "    val_loss       : -1533.8287353515625\n",
      "    val_ess        : 3.767683744430542\n",
      "    val_log_marginal: 1533.9554850260417\n",
      "Train Epoch: 1392 [0/54000 (0%)] Loss: -1533.813599\n",
      "Train Epoch: 1392 [32768/54000 (61%)] Loss: -1536.359619\n",
      "    epoch          : 1392\n",
      "    loss           : -1534.602274192954\n",
      "    ess            : 3.7732917947589226\n",
      "    log_marginal   : 1534.7332418189858\n",
      "    val_loss       : -1533.619405110677\n",
      "    val_ess        : 3.76760200659434\n",
      "    val_log_marginal: 1533.749267578125\n",
      "Train Epoch: 1393 [0/54000 (0%)] Loss: -1535.706299\n",
      "Train Epoch: 1393 [32768/54000 (61%)] Loss: -1534.780029\n",
      "    epoch          : 1393\n",
      "    loss           : -1534.6598729547466\n",
      "    ess            : 3.7748000666780293\n",
      "    log_marginal   : 1534.7889243071934\n",
      "    val_loss       : -1533.565450032552\n",
      "    val_ess        : 3.772605538368225\n",
      "    val_log_marginal: 1533.6988321940105\n",
      "Train Epoch: 1394 [0/54000 (0%)] Loss: -1533.172119\n",
      "Train Epoch: 1394 [32768/54000 (61%)] Loss: -1533.781982\n",
      "    epoch          : 1394\n",
      "    loss           : -1534.642458357901\n",
      "    ess            : 3.775007913697441\n",
      "    log_marginal   : 1534.7733062168338\n",
      "    val_loss       : -1533.7935384114583\n",
      "    val_ess        : 3.7587325970331826\n",
      "    val_log_marginal: 1533.929178873698\n",
      "Train Epoch: 1395 [0/54000 (0%)] Loss: -1536.224243\n",
      "Train Epoch: 1395 [32768/54000 (61%)] Loss: -1533.103638\n",
      "    epoch          : 1395\n",
      "    loss           : -1534.6898677034198\n",
      "    ess            : 3.780689005581838\n",
      "    log_marginal   : 1534.8153905328716\n",
      "    val_loss       : -1534.1268310546875\n",
      "    val_ess        : 3.7781494855880737\n",
      "    val_log_marginal: 1534.2483520507812\n",
      "Train Epoch: 1396 [0/54000 (0%)] Loss: -1534.744751\n",
      "Train Epoch: 1396 [32768/54000 (61%)] Loss: -1533.370605\n",
      "    epoch          : 1396\n",
      "    loss           : -1534.7331151422466\n",
      "    ess            : 3.7726236334386862\n",
      "    log_marginal   : 1534.8630209868809\n",
      "    val_loss       : -1533.752950032552\n",
      "    val_ess        : 3.779659390449524\n",
      "    val_log_marginal: 1533.8821411132812\n",
      "Train Epoch: 1397 [0/54000 (0%)] Loss: -1536.930420\n",
      "Train Epoch: 1397 [32768/54000 (61%)] Loss: -1535.553223\n",
      "    epoch          : 1397\n",
      "    loss           : -1534.7828622494103\n",
      "    ess            : 3.7736835524720966\n",
      "    log_marginal   : 1534.9162620688385\n",
      "    val_loss       : -1533.9154866536458\n",
      "    val_ess        : 3.7722498575846353\n",
      "    val_log_marginal: 1534.044453938802\n",
      "Train Epoch: 1398 [0/54000 (0%)] Loss: -1532.619141\n",
      "Train Epoch: 1398 [32768/54000 (61%)] Loss: -1540.077881\n",
      "    epoch          : 1398\n",
      "    loss           : -1534.848876953125\n",
      "    ess            : 3.775034148738069\n",
      "    log_marginal   : 1534.978333671138\n",
      "    val_loss       : -1533.9329630533855\n",
      "    val_ess        : 3.7888712088267007\n",
      "    val_log_marginal: 1534.0482381184895\n",
      "Train Epoch: 1399 [0/54000 (0%)] Loss: -1535.809326\n",
      "Train Epoch: 1399 [32768/54000 (61%)] Loss: -1535.342773\n",
      "    epoch          : 1399\n",
      "    loss           : -1534.8608052955483\n",
      "    ess            : 3.769245781988468\n",
      "    log_marginal   : 1534.9956814747936\n",
      "    val_loss       : -1533.9774780273438\n",
      "    val_ess        : 3.775485952695211\n",
      "    val_log_marginal: 1534.110127766927\n",
      "Train Epoch: 1400 [0/54000 (0%)] Loss: -1535.714233\n",
      "Train Epoch: 1400 [32768/54000 (61%)] Loss: -1536.386963\n",
      "    epoch          : 1400\n",
      "    loss           : -1534.9631094302772\n",
      "    ess            : 3.7705602600889385\n",
      "    log_marginal   : 1535.0924486844044\n",
      "    val_loss       : -1533.4743041992188\n",
      "    val_ess        : 3.75789213180542\n",
      "    val_log_marginal: 1533.6102701822917\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1400.pth ...\n",
      "Train Epoch: 1401 [0/54000 (0%)] Loss: -1534.789062\n",
      "Train Epoch: 1401 [32768/54000 (61%)] Loss: -1534.406982\n",
      "    epoch          : 1401\n",
      "    loss           : -1534.999979271079\n",
      "    ess            : 3.7747140155648284\n",
      "    log_marginal   : 1535.1277500368515\n",
      "    val_loss       : -1533.8541870117188\n",
      "    val_ess        : 3.788255055745443\n",
      "    val_log_marginal: 1533.9777425130208\n",
      "Train Epoch: 1402 [0/54000 (0%)] Loss: -1537.525635\n",
      "Train Epoch: 1402 [32768/54000 (61%)] Loss: -1532.632690\n",
      "    epoch          : 1402\n",
      "    loss           : -1535.2115017872936\n",
      "    ess            : 3.7773785816048675\n",
      "    log_marginal   : 1535.341193433078\n",
      "    val_loss       : -1534.1194458007812\n",
      "    val_ess        : 3.777642011642456\n",
      "    val_log_marginal: 1534.2497965494792\n",
      "Train Epoch: 1403 [0/54000 (0%)] Loss: -1534.983643\n",
      "Train Epoch: 1403 [32768/54000 (61%)] Loss: -1535.988770\n",
      "    epoch          : 1403\n",
      "    loss           : -1535.1273976451946\n",
      "    ess            : 3.775428439086338\n",
      "    log_marginal   : 1535.253438697671\n",
      "    val_loss       : -1534.019755045573\n",
      "    val_ess        : 3.764573017756144\n",
      "    val_log_marginal: 1534.1553344726562\n",
      "Train Epoch: 1404 [0/54000 (0%)] Loss: -1538.119385\n",
      "Train Epoch: 1404 [32768/54000 (61%)] Loss: -1533.757080\n",
      "    epoch          : 1404\n",
      "    loss           : -1535.1376814932194\n",
      "    ess            : 3.774288496881161\n",
      "    log_marginal   : 1535.2675712153596\n",
      "    val_loss       : -1534.1083170572917\n",
      "    val_ess        : 3.775005340576172\n",
      "    val_log_marginal: 1534.2347208658855\n",
      "Train Epoch: 1405 [0/54000 (0%)] Loss: -1537.101440\n",
      "Train Epoch: 1405 [32768/54000 (61%)] Loss: -1536.101074\n",
      "    epoch          : 1405\n",
      "    loss           : -1535.1927536298645\n",
      "    ess            : 3.7760693397162095\n",
      "    log_marginal   : 1535.3193082989387\n",
      "    val_loss       : -1534.611104329427\n",
      "    val_ess        : 3.7732433478037515\n",
      "    val_log_marginal: 1534.7444458007812\n",
      "Train Epoch: 1406 [0/54000 (0%)] Loss: -1538.307617\n",
      "Train Epoch: 1406 [32768/54000 (61%)] Loss: -1539.646729\n",
      "    epoch          : 1406\n",
      "    loss           : -1535.4373894457547\n",
      "    ess            : 3.7749635993309743\n",
      "    log_marginal   : 1535.5654458099941\n",
      "    val_loss       : -1534.4045817057292\n",
      "    val_ess        : 3.787000139554342\n",
      "    val_log_marginal: 1534.5318603515625\n",
      "Train Epoch: 1407 [0/54000 (0%)] Loss: -1537.109009\n",
      "Train Epoch: 1407 [32768/54000 (61%)] Loss: -1538.875488\n",
      "    epoch          : 1407\n",
      "    loss           : -1535.3840585384728\n",
      "    ess            : 3.7759461402893066\n",
      "    log_marginal   : 1535.5085909861439\n",
      "    val_loss       : -1534.2887776692708\n",
      "    val_ess        : 3.764137069384257\n",
      "    val_log_marginal: 1534.4344685872395\n",
      "Train Epoch: 1408 [0/54000 (0%)] Loss: -1534.353516\n",
      "Train Epoch: 1408 [32768/54000 (61%)] Loss: -1534.115234\n",
      "    epoch          : 1408\n",
      "    loss           : -1535.4242979805424\n",
      "    ess            : 3.7716986368287286\n",
      "    log_marginal   : 1535.5531835016216\n",
      "    val_loss       : -1533.9837036132812\n",
      "    val_ess        : 3.7732592026392617\n",
      "    val_log_marginal: 1534.1114298502605\n",
      "Train Epoch: 1409 [0/54000 (0%)] Loss: -1535.857666\n",
      "Train Epoch: 1409 [32768/54000 (61%)] Loss: -1536.107910\n",
      "    epoch          : 1409\n",
      "    loss           : -1535.5278873083726\n",
      "    ess            : 3.77360020043715\n",
      "    log_marginal   : 1535.6607044147995\n",
      "    val_loss       : -1534.4311930338542\n",
      "    val_ess        : 3.777844945589701\n",
      "    val_log_marginal: 1534.5657755533855\n",
      "Train Epoch: 1410 [0/54000 (0%)] Loss: -1534.091187\n",
      "Train Epoch: 1410 [32768/54000 (61%)] Loss: -1533.055298\n",
      "    epoch          : 1410\n",
      "    loss           : -1535.612995651533\n",
      "    ess            : 3.773091473669376\n",
      "    log_marginal   : 1535.7432584942512\n",
      "    val_loss       : -1534.5232747395833\n",
      "    val_ess        : 3.7817980448404946\n",
      "    val_log_marginal: 1534.655741373698\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1410.pth ...\n",
      "Train Epoch: 1411 [0/54000 (0%)] Loss: -1536.564941\n",
      "Train Epoch: 1411 [32768/54000 (61%)] Loss: -1535.366089\n",
      "    epoch          : 1411\n",
      "    loss           : -1535.5268738944576\n",
      "    ess            : 3.769736685842838\n",
      "    log_marginal   : 1535.6602000110554\n",
      "    val_loss       : -1534.5284830729167\n",
      "    val_ess        : 3.7900055249532065\n",
      "    val_log_marginal: 1534.6405843098958\n",
      "Train Epoch: 1412 [0/54000 (0%)] Loss: -1540.444824\n",
      "Train Epoch: 1412 [32768/54000 (61%)] Loss: -1536.989502\n",
      "    epoch          : 1412\n",
      "    loss           : -1535.571533203125\n",
      "    ess            : 3.7723956063108623\n",
      "    log_marginal   : 1535.7037883254718\n",
      "    val_loss       : -1534.6639811197917\n",
      "    val_ess        : 3.770105322202047\n",
      "    val_log_marginal: 1534.7938639322917\n",
      "Train Epoch: 1413 [0/54000 (0%)] Loss: -1538.029785\n",
      "Train Epoch: 1413 [32768/54000 (61%)] Loss: -1535.485962\n",
      "    epoch          : 1413\n",
      "    loss           : -1535.6532143646816\n",
      "    ess            : 3.777904173113265\n",
      "    log_marginal   : 1535.7804646042157\n",
      "    val_loss       : -1534.486572265625\n",
      "    val_ess        : 3.776249130566915\n",
      "    val_log_marginal: 1534.6177978515625\n",
      "Train Epoch: 1414 [0/54000 (0%)] Loss: -1536.634644\n",
      "Train Epoch: 1414 [32768/54000 (61%)] Loss: -1537.656494\n",
      "    epoch          : 1414\n",
      "    loss           : -1535.7385415131191\n",
      "    ess            : 3.7733536981186777\n",
      "    log_marginal   : 1535.8649579893868\n",
      "    val_loss       : -1534.7254435221355\n",
      "    val_ess        : 3.78587539990743\n",
      "    val_log_marginal: 1534.8402709960938\n",
      "Train Epoch: 1415 [0/54000 (0%)] Loss: -1538.236572\n",
      "Train Epoch: 1415 [32768/54000 (61%)] Loss: -1537.311035\n",
      "    epoch          : 1415\n",
      "    loss           : -1535.7369960568985\n",
      "    ess            : 3.7720412668192163\n",
      "    log_marginal   : 1535.8691291089328\n",
      "    val_loss       : -1534.8280843098958\n",
      "    val_ess        : 3.789448698361715\n",
      "    val_log_marginal: 1534.9473876953125\n",
      "Train Epoch: 1416 [0/54000 (0%)] Loss: -1537.239990\n",
      "Train Epoch: 1416 [32768/54000 (61%)] Loss: -1532.662964\n",
      "    epoch          : 1416\n",
      "    loss           : -1535.6087139777417\n",
      "    ess            : 3.7751353461787387\n",
      "    log_marginal   : 1535.7387557119694\n",
      "    val_loss       : -1534.6322224934895\n",
      "    val_ess        : 3.773438652356466\n",
      "    val_log_marginal: 1534.7667032877605\n",
      "Train Epoch: 1417 [0/54000 (0%)] Loss: -1535.325928\n",
      "Train Epoch: 1417 [32768/54000 (61%)] Loss: -1533.870361\n",
      "    epoch          : 1417\n",
      "    loss           : -1535.6784299454598\n",
      "    ess            : 3.7682718690836206\n",
      "    log_marginal   : 1535.8116961785083\n",
      "    val_loss       : -1534.8907267252605\n",
      "    val_ess        : 3.7728719313939414\n",
      "    val_log_marginal: 1535.021504720052\n",
      "Train Epoch: 1418 [0/54000 (0%)] Loss: -1539.020020\n",
      "Train Epoch: 1418 [32768/54000 (61%)] Loss: -1535.476318\n",
      "    epoch          : 1418\n",
      "    loss           : -1535.669304613797\n",
      "    ess            : 3.772872560429123\n",
      "    log_marginal   : 1535.7982085605838\n",
      "    val_loss       : -1534.6026407877605\n",
      "    val_ess        : 3.7673765420913696\n",
      "    val_log_marginal: 1534.7373453776042\n",
      "Train Epoch: 1419 [0/54000 (0%)] Loss: -1536.678589\n",
      "Train Epoch: 1419 [32768/54000 (61%)] Loss: -1533.507568\n",
      "    epoch          : 1419\n",
      "    loss           : -1535.5836181640625\n",
      "    ess            : 3.769696550549201\n",
      "    log_marginal   : 1535.7179715138561\n",
      "    val_loss       : -1535.0818277994792\n",
      "    val_ess        : 3.772883971532186\n",
      "    val_log_marginal: 1535.2056884765625\n",
      "Train Epoch: 1420 [0/54000 (0%)] Loss: -1537.186401\n",
      "Train Epoch: 1420 [32768/54000 (61%)] Loss: -1537.896729\n",
      "    epoch          : 1420\n",
      "    loss           : -1535.828410598467\n",
      "    ess            : 3.7705309570960277\n",
      "    log_marginal   : 1535.9613866266216\n",
      "    val_loss       : -1534.734883626302\n",
      "    val_ess        : 3.773217519124349\n",
      "    val_log_marginal: 1534.864501953125\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1420.pth ...\n",
      "Train Epoch: 1421 [0/54000 (0%)] Loss: -1537.171631\n",
      "Train Epoch: 1421 [32768/54000 (61%)] Loss: -1537.394897\n",
      "    epoch          : 1421\n",
      "    loss           : -1535.8539578419811\n",
      "    ess            : 3.776915874121324\n",
      "    log_marginal   : 1535.982972343013\n",
      "    val_loss       : -1535.0300903320312\n",
      "    val_ess        : 3.7733048597971597\n",
      "    val_log_marginal: 1535.1573079427083\n",
      "Train Epoch: 1422 [0/54000 (0%)] Loss: -1535.466553\n",
      "Train Epoch: 1422 [32768/54000 (61%)] Loss: -1538.287476\n",
      "    epoch          : 1422\n",
      "    loss           : -1535.7530655770931\n",
      "    ess            : 3.7701629422745615\n",
      "    log_marginal   : 1535.8862604105248\n",
      "    val_loss       : -1534.9202677408855\n",
      "    val_ess        : 3.7652282317479453\n",
      "    val_log_marginal: 1535.0601603190105\n",
      "Train Epoch: 1423 [0/54000 (0%)] Loss: -1536.907471\n",
      "Train Epoch: 1423 [32768/54000 (61%)] Loss: -1537.525757\n",
      "    epoch          : 1423\n",
      "    loss           : -1535.7913910487912\n",
      "    ess            : 3.7686922235308953\n",
      "    log_marginal   : 1535.92592174602\n",
      "    val_loss       : -1534.915547688802\n",
      "    val_ess        : 3.7641438643137612\n",
      "    val_log_marginal: 1535.050557454427\n",
      "Train Epoch: 1424 [0/54000 (0%)] Loss: -1537.312500\n",
      "Train Epoch: 1424 [32768/54000 (61%)] Loss: -1536.928345\n",
      "    epoch          : 1424\n",
      "    loss           : -1535.8111341944282\n",
      "    ess            : 3.772138348165548\n",
      "    log_marginal   : 1535.9421110333137\n",
      "    val_loss       : -1535.1642456054688\n",
      "    val_ess        : 3.7751633723576865\n",
      "    val_log_marginal: 1535.2918294270833\n",
      "Train Epoch: 1425 [0/54000 (0%)] Loss: -1535.554810\n",
      "Train Epoch: 1425 [32768/54000 (61%)] Loss: -1534.636719\n",
      "    epoch          : 1425\n",
      "    loss           : -1535.9270388045402\n",
      "    ess            : 3.770990146780914\n",
      "    log_marginal   : 1536.0577807156544\n",
      "    val_loss       : -1535.3100179036458\n",
      "    val_ess        : 3.7741138537724814\n",
      "    val_log_marginal: 1535.4449259440105\n",
      "Train Epoch: 1426 [0/54000 (0%)] Loss: -1536.255371\n",
      "Train Epoch: 1426 [32768/54000 (61%)] Loss: -1537.565186\n",
      "    epoch          : 1426\n",
      "    loss           : -1535.9074315484966\n",
      "    ess            : 3.769815980263476\n",
      "    log_marginal   : 1536.0384843934257\n",
      "    val_loss       : -1535.2196858723958\n",
      "    val_ess        : 3.7770365873972573\n",
      "    val_log_marginal: 1535.3467610677083\n",
      "Train Epoch: 1427 [0/54000 (0%)] Loss: -1537.646973\n",
      "Train Epoch: 1427 [32768/54000 (61%)] Loss: -1535.809448\n",
      "    epoch          : 1427\n",
      "    loss           : -1536.0366602483784\n",
      "    ess            : 3.7715410601417974\n",
      "    log_marginal   : 1536.1684293926887\n",
      "    val_loss       : -1535.0531819661458\n",
      "    val_ess        : 3.7642711798350015\n",
      "    val_log_marginal: 1535.1912638346355\n",
      "Train Epoch: 1428 [0/54000 (0%)] Loss: -1532.081299\n",
      "Train Epoch: 1428 [32768/54000 (61%)] Loss: -1536.216064\n",
      "    epoch          : 1428\n",
      "    loss           : -1536.0835398548054\n",
      "    ess            : 3.773485521100602\n",
      "    log_marginal   : 1536.2133696933963\n",
      "    val_loss       : -1535.4514973958333\n",
      "    val_ess        : 3.782782793045044\n",
      "    val_log_marginal: 1535.5795288085938\n",
      "Train Epoch: 1429 [0/54000 (0%)] Loss: -1534.253174\n",
      "Train Epoch: 1429 [32768/54000 (61%)] Loss: -1535.213623\n",
      "    epoch          : 1429\n",
      "    loss           : -1536.1895406471108\n",
      "    ess            : 3.7722136029657327\n",
      "    log_marginal   : 1536.3209228515625\n",
      "    val_loss       : -1535.418680826823\n",
      "    val_ess        : 3.7762794494628906\n",
      "    val_log_marginal: 1535.540506998698\n",
      "Train Epoch: 1430 [0/54000 (0%)] Loss: -1535.462280\n",
      "Train Epoch: 1430 [32768/54000 (61%)] Loss: -1532.273315\n",
      "    epoch          : 1430\n",
      "    loss           : -1536.1721698113208\n",
      "    ess            : 3.767107473229462\n",
      "    log_marginal   : 1536.3040057488208\n",
      "    val_loss       : -1535.6312459309895\n",
      "    val_ess        : 3.7898383935292563\n",
      "    val_log_marginal: 1535.754903157552\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1430.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1431 [0/54000 (0%)] Loss: -1537.906372\n",
      "Train Epoch: 1431 [32768/54000 (61%)] Loss: -1536.532471\n",
      "    epoch          : 1431\n",
      "    loss           : -1536.2136506854363\n",
      "    ess            : 3.770920398100367\n",
      "    log_marginal   : 1536.3460025427476\n",
      "    val_loss       : -1535.446309407552\n",
      "    val_ess        : 3.774238705635071\n",
      "    val_log_marginal: 1535.577860514323\n",
      "Train Epoch: 1432 [0/54000 (0%)] Loss: -1536.237793\n",
      "Train Epoch: 1432 [32768/54000 (61%)] Loss: -1539.183594\n",
      "    epoch          : 1432\n",
      "    loss           : -1536.2627920474647\n",
      "    ess            : 3.774209607322261\n",
      "    log_marginal   : 1536.3925067253833\n",
      "    val_loss       : -1535.8290405273438\n",
      "    val_ess        : 3.7689479192097983\n",
      "    val_log_marginal: 1535.9605509440105\n",
      "Train Epoch: 1433 [0/54000 (0%)] Loss: -1539.413208\n",
      "Train Epoch: 1433 [32768/54000 (61%)] Loss: -1535.424805\n",
      "    epoch          : 1433\n",
      "    loss           : -1536.2451033682194\n",
      "    ess            : 3.774427153029532\n",
      "    log_marginal   : 1536.3736065558667\n",
      "    val_loss       : -1535.3192138671875\n",
      "    val_ess        : 3.781973401705424\n",
      "    val_log_marginal: 1535.4507446289062\n",
      "Train Epoch: 1434 [0/54000 (0%)] Loss: -1540.252441\n",
      "Train Epoch: 1434 [32768/54000 (61%)] Loss: -1535.364136\n",
      "    epoch          : 1434\n",
      "    loss           : -1536.4177591575767\n",
      "    ess            : 3.7735967186262025\n",
      "    log_marginal   : 1536.5441802402713\n",
      "    val_loss       : -1535.702901204427\n",
      "    val_ess        : 3.7651003996531167\n",
      "    val_log_marginal: 1535.8422241210938\n",
      "Train Epoch: 1435 [0/54000 (0%)] Loss: -1533.033203\n",
      "Train Epoch: 1435 [32768/54000 (61%)] Loss: -1534.012207\n",
      "    epoch          : 1435\n",
      "    loss           : -1536.3640528265034\n",
      "    ess            : 3.7687375995348082\n",
      "    log_marginal   : 1536.496768591539\n",
      "    val_loss       : -1535.8357340494792\n",
      "    val_ess        : 3.7772624492645264\n",
      "    val_log_marginal: 1535.9613240559895\n",
      "Train Epoch: 1436 [0/54000 (0%)] Loss: -1538.256348\n",
      "Train Epoch: 1436 [32768/54000 (61%)] Loss: -1539.185791\n",
      "    epoch          : 1436\n",
      "    loss           : -1536.570780052329\n",
      "    ess            : 3.772108703289392\n",
      "    log_marginal   : 1536.7012179392689\n",
      "    val_loss       : -1535.574971516927\n",
      "    val_ess        : 3.7766199509302774\n",
      "    val_log_marginal: 1535.703104654948\n",
      "Train Epoch: 1437 [0/54000 (0%)] Loss: -1535.961060\n",
      "Train Epoch: 1437 [32768/54000 (61%)] Loss: -1535.245972\n",
      "    epoch          : 1437\n",
      "    loss           : -1536.4513031581662\n",
      "    ess            : 3.7725131106826493\n",
      "    log_marginal   : 1536.5832957141804\n",
      "    val_loss       : -1535.5950113932292\n",
      "    val_ess        : 3.760316252708435\n",
      "    val_log_marginal: 1535.7421468098958\n",
      "Train Epoch: 1438 [0/54000 (0%)] Loss: -1535.945557\n",
      "Train Epoch: 1438 [32768/54000 (61%)] Loss: -1536.579712\n",
      "    epoch          : 1438\n",
      "    loss           : -1536.5768029554836\n",
      "    ess            : 3.773798254300963\n",
      "    log_marginal   : 1536.7077705815154\n",
      "    val_loss       : -1535.9279378255208\n",
      "    val_ess        : 3.7854400475819907\n",
      "    val_log_marginal: 1536.045186360677\n",
      "Train Epoch: 1439 [0/54000 (0%)] Loss: -1535.463989\n",
      "Train Epoch: 1439 [32768/54000 (61%)] Loss: -1536.755615\n",
      "    epoch          : 1439\n",
      "    loss           : -1536.4087420769458\n",
      "    ess            : 3.7740884906840773\n",
      "    log_marginal   : 1536.5362387603184\n",
      "    val_loss       : -1535.9768473307292\n",
      "    val_ess        : 3.772070566813151\n",
      "    val_log_marginal: 1536.1050415039062\n",
      "Train Epoch: 1440 [0/54000 (0%)] Loss: -1533.605347\n",
      "Train Epoch: 1440 [32768/54000 (61%)] Loss: -1538.211060\n",
      "    epoch          : 1440\n",
      "    loss           : -1536.4739230173939\n",
      "    ess            : 3.7737993024430185\n",
      "    log_marginal   : 1536.6024906950177\n",
      "    val_loss       : -1535.5991617838542\n",
      "    val_ess        : 3.760879635810852\n",
      "    val_log_marginal: 1535.7423706054688\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1440.pth ...\n",
      "Train Epoch: 1441 [0/54000 (0%)] Loss: -1539.829468\n",
      "Train Epoch: 1441 [32768/54000 (61%)] Loss: -1532.628296\n",
      "    epoch          : 1441\n",
      "    loss           : -1536.5216225678066\n",
      "    ess            : 3.7716585645135843\n",
      "    log_marginal   : 1536.6540688568691\n",
      "    val_loss       : -1535.6491088867188\n",
      "    val_ess        : 3.7647057374318442\n",
      "    val_log_marginal: 1535.795186360677\n",
      "Train Epoch: 1442 [0/54000 (0%)] Loss: -1537.250977\n",
      "Train Epoch: 1442 [32768/54000 (61%)] Loss: -1537.144043\n",
      "    epoch          : 1442\n",
      "    loss           : -1536.6465212264152\n",
      "    ess            : 3.775547576400469\n",
      "    log_marginal   : 1536.7753560767983\n",
      "    val_loss       : -1536.1223958333333\n",
      "    val_ess        : 3.778232534726461\n",
      "    val_log_marginal: 1536.2529703776042\n",
      "Train Epoch: 1443 [0/54000 (0%)] Loss: -1537.453125\n",
      "Train Epoch: 1443 [32768/54000 (61%)] Loss: -1535.790771\n",
      "    epoch          : 1443\n",
      "    loss           : -1536.6608702461674\n",
      "    ess            : 3.7719710772892214\n",
      "    log_marginal   : 1536.79241367556\n",
      "    val_loss       : -1536.1071166992188\n",
      "    val_ess        : 3.76091992855072\n",
      "    val_log_marginal: 1536.2462565104167\n",
      "Train Epoch: 1444 [0/54000 (0%)] Loss: -1536.089355\n",
      "Train Epoch: 1444 [32768/54000 (61%)] Loss: -1538.760376\n",
      "    epoch          : 1444\n",
      "    loss           : -1536.7890256485848\n",
      "    ess            : 3.773884260429526\n",
      "    log_marginal   : 1536.9219717349647\n",
      "    val_loss       : -1535.9567464192708\n",
      "    val_ess        : 3.764505902926127\n",
      "    val_log_marginal: 1536.0942789713542\n",
      "Train Epoch: 1445 [0/54000 (0%)] Loss: -1538.626831\n",
      "Train Epoch: 1445 [32768/54000 (61%)] Loss: -1533.228271\n",
      "    epoch          : 1445\n",
      "    loss           : -1536.8449522774174\n",
      "    ess            : 3.773911287199776\n",
      "    log_marginal   : 1536.9761801665684\n",
      "    val_loss       : -1536.0221557617188\n",
      "    val_ess        : 3.7603584130605063\n",
      "    val_log_marginal: 1536.1559651692708\n",
      "Train Epoch: 1446 [0/54000 (0%)] Loss: -1538.147461\n",
      "Train Epoch: 1446 [32768/54000 (61%)] Loss: -1537.195923\n",
      "    epoch          : 1446\n",
      "    loss           : -1536.9066069980838\n",
      "    ess            : 3.7693805559626163\n",
      "    log_marginal   : 1537.0367961379718\n",
      "    val_loss       : -1535.8015543619792\n",
      "    val_ess        : 3.766204039255778\n",
      "    val_log_marginal: 1535.9257405598958\n",
      "Train Epoch: 1447 [0/54000 (0%)] Loss: -1537.257324\n",
      "Train Epoch: 1447 [32768/54000 (61%)] Loss: -1539.974365\n",
      "    epoch          : 1447\n",
      "    loss           : -1536.8378353478774\n",
      "    ess            : 3.772069701608622\n",
      "    log_marginal   : 1536.971435546875\n",
      "    val_loss       : -1535.8138224283855\n",
      "    val_ess        : 3.7801600297292075\n",
      "    val_log_marginal: 1535.9430135091145\n",
      "Train Epoch: 1448 [0/54000 (0%)] Loss: -1537.457520\n",
      "Train Epoch: 1448 [32768/54000 (61%)] Loss: -1536.821777\n",
      "    epoch          : 1448\n",
      "    loss           : -1536.9048335237323\n",
      "    ess            : 3.7726771156742887\n",
      "    log_marginal   : 1537.0339747015034\n",
      "    val_loss       : -1536.011962890625\n",
      "    val_ess        : 3.7727798223495483\n",
      "    val_log_marginal: 1536.1387939453125\n",
      "Train Epoch: 1449 [0/54000 (0%)] Loss: -1537.480225\n",
      "Train Epoch: 1449 [32768/54000 (61%)] Loss: -1539.035156\n",
      "    epoch          : 1449\n",
      "    loss           : -1536.86272617556\n",
      "    ess            : 3.7736535342234485\n",
      "    log_marginal   : 1536.9897829451652\n",
      "    val_loss       : -1536.3255615234375\n",
      "    val_ess        : 3.782634894053141\n",
      "    val_log_marginal: 1536.4496459960938\n",
      "Train Epoch: 1450 [0/54000 (0%)] Loss: -1535.693604\n",
      "Train Epoch: 1450 [32768/54000 (61%)] Loss: -1538.770996\n",
      "    epoch          : 1450\n",
      "    loss           : -1536.9580446639152\n",
      "    ess            : 3.775663803208549\n",
      "    log_marginal   : 1537.0870038878243\n",
      "    val_loss       : -1535.6771036783855\n",
      "    val_ess        : 3.790861487388611\n",
      "    val_log_marginal: 1535.792500813802\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1450.pth ...\n",
      "Train Epoch: 1451 [0/54000 (0%)] Loss: -1532.400635\n",
      "Train Epoch: 1451 [32768/54000 (61%)] Loss: -1532.634155\n",
      "    epoch          : 1451\n",
      "    loss           : -1536.955020544664\n",
      "    ess            : 3.7701038099684805\n",
      "    log_marginal   : 1537.0878721992924\n",
      "    val_loss       : -1536.1571248372395\n",
      "    val_ess        : 3.772021452585856\n",
      "    val_log_marginal: 1536.2874145507812\n",
      "Train Epoch: 1452 [0/54000 (0%)] Loss: -1534.955322\n",
      "Train Epoch: 1452 [32768/54000 (61%)] Loss: -1538.831421\n",
      "    epoch          : 1452\n",
      "    loss           : -1537.0316484559257\n",
      "    ess            : 3.7726153877546205\n",
      "    log_marginal   : 1537.162899377211\n",
      "    val_loss       : -1536.0953776041667\n",
      "    val_ess        : 3.7640018463134766\n",
      "    val_log_marginal: 1536.232666015625\n",
      "Train Epoch: 1453 [0/54000 (0%)] Loss: -1540.300781\n",
      "Train Epoch: 1453 [32768/54000 (61%)] Loss: -1535.541260\n",
      "    epoch          : 1453\n",
      "    loss           : -1537.1669622457252\n",
      "    ess            : 3.7764976384504787\n",
      "    log_marginal   : 1537.2930194206958\n",
      "    val_loss       : -1536.208028157552\n",
      "    val_ess        : 3.7760847012201944\n",
      "    val_log_marginal: 1536.33349609375\n",
      "Train Epoch: 1454 [0/54000 (0%)] Loss: -1535.892822\n",
      "Train Epoch: 1454 [32768/54000 (61%)] Loss: -1536.131836\n",
      "    epoch          : 1454\n",
      "    loss           : -1537.0852350198998\n",
      "    ess            : 3.771802303926\n",
      "    log_marginal   : 1537.2183354215802\n",
      "    val_loss       : -1536.19921875\n",
      "    val_ess        : 3.774770736694336\n",
      "    val_log_marginal: 1536.3269653320312\n",
      "Train Epoch: 1455 [0/54000 (0%)] Loss: -1538.370850\n",
      "Train Epoch: 1455 [32768/54000 (61%)] Loss: -1535.170044\n",
      "    epoch          : 1455\n",
      "    loss           : -1537.1729943617336\n",
      "    ess            : 3.7734406399277023\n",
      "    log_marginal   : 1537.3022000294811\n",
      "    val_loss       : -1535.9127604166667\n",
      "    val_ess        : 3.7725380261739097\n",
      "    val_log_marginal: 1536.0533243815105\n",
      "Train Epoch: 1456 [0/54000 (0%)] Loss: -1536.697754\n",
      "Train Epoch: 1456 [32768/54000 (61%)] Loss: -1537.892334\n",
      "    epoch          : 1456\n",
      "    loss           : -1537.1860282466096\n",
      "    ess            : 3.7736583520781317\n",
      "    log_marginal   : 1537.31598476194\n",
      "    val_loss       : -1536.2673950195312\n",
      "    val_ess        : 3.7948251167933145\n",
      "    val_log_marginal: 1536.3812662760417\n",
      "Train Epoch: 1457 [0/54000 (0%)] Loss: -1538.111084\n",
      "Train Epoch: 1457 [32768/54000 (61%)] Loss: -1533.855713\n",
      "    epoch          : 1457\n",
      "    loss           : -1537.2060431714328\n",
      "    ess            : 3.7764794466630467\n",
      "    log_marginal   : 1537.3333371720223\n",
      "    val_loss       : -1536.3658854166667\n",
      "    val_ess        : 3.7782783110936484\n",
      "    val_log_marginal: 1536.4891560872395\n",
      "Train Epoch: 1458 [0/54000 (0%)] Loss: -1539.184082\n",
      "Train Epoch: 1458 [32768/54000 (61%)] Loss: -1538.490967\n",
      "    epoch          : 1458\n",
      "    loss           : -1537.122724425118\n",
      "    ess            : 3.769310033546304\n",
      "    log_marginal   : 1537.2563038951946\n",
      "    val_loss       : -1536.317626953125\n",
      "    val_ess        : 3.7836565574010215\n",
      "    val_log_marginal: 1536.4348754882812\n",
      "Train Epoch: 1459 [0/54000 (0%)] Loss: -1539.614502\n",
      "Train Epoch: 1459 [32768/54000 (61%)] Loss: -1539.889893\n",
      "    epoch          : 1459\n",
      "    loss           : -1537.209306824882\n",
      "    ess            : 3.7755229293175465\n",
      "    log_marginal   : 1537.3375612654777\n",
      "    val_loss       : -1536.4420572916667\n",
      "    val_ess        : 3.788151979446411\n",
      "    val_log_marginal: 1536.561543782552\n",
      "Train Epoch: 1460 [0/54000 (0%)] Loss: -1538.839111\n",
      "Train Epoch: 1460 [32768/54000 (61%)] Loss: -1540.090454\n",
      "    epoch          : 1460\n",
      "    loss           : -1537.1967335826946\n",
      "    ess            : 3.7725279691084377\n",
      "    log_marginal   : 1537.3255845555718\n",
      "    val_loss       : -1536.0433756510417\n",
      "    val_ess        : 3.774117112159729\n",
      "    val_log_marginal: 1536.1775919596355\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1460.pth ...\n",
      "Train Epoch: 1461 [0/54000 (0%)] Loss: -1538.639771\n",
      "Train Epoch: 1461 [32768/54000 (61%)] Loss: -1537.792480\n",
      "    epoch          : 1461\n",
      "    loss           : -1537.3134765625\n",
      "    ess            : 3.774896756658014\n",
      "    log_marginal   : 1537.4403398621757\n",
      "    val_loss       : -1536.5815836588542\n",
      "    val_ess        : 3.7871743043263755\n",
      "    val_log_marginal: 1536.7066040039062\n",
      "Train Epoch: 1462 [0/54000 (0%)] Loss: -1535.361328\n",
      "Train Epoch: 1462 [32768/54000 (61%)] Loss: -1540.703125\n",
      "    epoch          : 1462\n",
      "    loss           : -1537.2407387787441\n",
      "    ess            : 3.7723226772164398\n",
      "    log_marginal   : 1537.372963959316\n",
      "    val_loss       : -1536.5185139973958\n",
      "    val_ess        : 3.777664621671041\n",
      "    val_log_marginal: 1536.6400553385417\n",
      "Train Epoch: 1463 [0/54000 (0%)] Loss: -1539.911743\n",
      "Train Epoch: 1463 [32768/54000 (61%)] Loss: -1533.173340\n",
      "    epoch          : 1463\n",
      "    loss           : -1537.4304475604363\n",
      "    ess            : 3.776469788461361\n",
      "    log_marginal   : 1537.5578590249115\n",
      "    val_loss       : -1536.2338256835938\n",
      "    val_ess        : 3.7702041467030845\n",
      "    val_log_marginal: 1536.3700561523438\n",
      "Train Epoch: 1464 [0/54000 (0%)] Loss: -1538.600586\n",
      "Train Epoch: 1464 [32768/54000 (61%)] Loss: -1537.156006\n",
      "    epoch          : 1464\n",
      "    loss           : -1537.3974632407135\n",
      "    ess            : 3.7733834824472106\n",
      "    log_marginal   : 1537.5266021152713\n",
      "    val_loss       : -1536.412353515625\n",
      "    val_ess        : 3.7732561429341636\n",
      "    val_log_marginal: 1536.5467122395833\n",
      "Train Epoch: 1465 [0/54000 (0%)] Loss: -1537.552002\n",
      "Train Epoch: 1465 [32768/54000 (61%)] Loss: -1533.129639\n",
      "    epoch          : 1465\n",
      "    loss           : -1537.4261635834316\n",
      "    ess            : 3.7763951634461024\n",
      "    log_marginal   : 1537.5539942327534\n",
      "    val_loss       : -1536.5453287760417\n",
      "    val_ess        : 3.7750394344329834\n",
      "    val_log_marginal: 1536.6722005208333\n",
      "Train Epoch: 1466 [0/54000 (0%)] Loss: -1537.630981\n",
      "Train Epoch: 1466 [32768/54000 (61%)] Loss: -1532.985352\n",
      "    epoch          : 1466\n",
      "    loss           : -1537.399471642836\n",
      "    ess            : 3.7745998625485404\n",
      "    log_marginal   : 1537.5303171985554\n",
      "    val_loss       : -1536.855692545573\n",
      "    val_ess        : 3.77998415629069\n",
      "    val_log_marginal: 1536.9777425130208\n",
      "Train Epoch: 1467 [0/54000 (0%)] Loss: -1539.336670\n",
      "Train Epoch: 1467 [32768/54000 (61%)] Loss: -1534.558105\n",
      "    epoch          : 1467\n",
      "    loss           : -1537.3268144715507\n",
      "    ess            : 3.7706843097254916\n",
      "    log_marginal   : 1537.4602281102593\n",
      "    val_loss       : -1536.6932169596355\n",
      "    val_ess        : 3.769585649172465\n",
      "    val_log_marginal: 1536.8285319010417\n",
      "Train Epoch: 1468 [0/54000 (0%)] Loss: -1537.505737\n",
      "Train Epoch: 1468 [32768/54000 (61%)] Loss: -1536.328369\n",
      "    epoch          : 1468\n",
      "    loss           : -1537.3813752948113\n",
      "    ess            : 3.774344876127423\n",
      "    log_marginal   : 1537.5106062979069\n",
      "    val_loss       : -1537.0510660807292\n",
      "    val_ess        : 3.7905553181966147\n",
      "    val_log_marginal: 1537.1747029622395\n",
      "Train Epoch: 1469 [0/54000 (0%)] Loss: -1536.627441\n",
      "Train Epoch: 1469 [32768/54000 (61%)] Loss: -1533.927856\n",
      "    epoch          : 1469\n",
      "    loss           : -1537.461061873526\n",
      "    ess            : 3.7727162388135804\n",
      "    log_marginal   : 1537.5929461785083\n",
      "    val_loss       : -1536.2644653320312\n",
      "    val_ess        : 3.783524990081787\n",
      "    val_log_marginal: 1536.3794962565105\n",
      "Train Epoch: 1470 [0/54000 (0%)] Loss: -1538.735107\n",
      "Train Epoch: 1470 [32768/54000 (61%)] Loss: -1537.143311\n",
      "    epoch          : 1470\n",
      "    loss           : -1537.434102760171\n",
      "    ess            : 3.7765071616982513\n",
      "    log_marginal   : 1537.561896558078\n",
      "    val_loss       : -1536.620849609375\n",
      "    val_ess        : 3.78471831480662\n",
      "    val_log_marginal: 1536.7378336588542\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1470.pth ...\n",
      "Train Epoch: 1471 [0/54000 (0%)] Loss: -1536.835938\n",
      "Train Epoch: 1471 [32768/54000 (61%)] Loss: -1534.852295\n",
      "    epoch          : 1471\n",
      "    loss           : -1537.4766016546284\n",
      "    ess            : 3.771330770456566\n",
      "    log_marginal   : 1537.6104436910377\n",
      "    val_loss       : -1536.552958170573\n",
      "    val_ess        : 3.7766509850819907\n",
      "    val_log_marginal: 1536.6801350911458\n",
      "Train Epoch: 1472 [0/54000 (0%)] Loss: -1536.737061\n",
      "Train Epoch: 1472 [32768/54000 (61%)] Loss: -1538.356323\n",
      "    epoch          : 1472\n",
      "    loss           : -1537.5150284677181\n",
      "    ess            : 3.7739344272973403\n",
      "    log_marginal   : 1537.6478547869988\n",
      "    val_loss       : -1536.4202677408855\n",
      "    val_ess        : 3.7770708401997886\n",
      "    val_log_marginal: 1536.5475260416667\n",
      "Train Epoch: 1473 [0/54000 (0%)] Loss: -1536.116943\n",
      "Train Epoch: 1473 [32768/54000 (61%)] Loss: -1538.284180\n",
      "    epoch          : 1473\n",
      "    loss           : -1537.7218524285083\n",
      "    ess            : 3.771503803864965\n",
      "    log_marginal   : 1537.8528592091686\n",
      "    val_loss       : -1536.533467610677\n",
      "    val_ess        : 3.7656230131785073\n",
      "    val_log_marginal: 1536.659444173177\n",
      "Train Epoch: 1474 [0/54000 (0%)] Loss: -1539.733643\n",
      "Train Epoch: 1474 [32768/54000 (61%)] Loss: -1535.800171\n",
      "    epoch          : 1474\n",
      "    loss           : -1537.6586430387677\n",
      "    ess            : 3.773883099825877\n",
      "    log_marginal   : 1537.7865450877064\n",
      "    val_loss       : -1536.742655436198\n",
      "    val_ess        : 3.7796059449513755\n",
      "    val_log_marginal: 1536.8754475911458\n",
      "Train Epoch: 1475 [0/54000 (0%)] Loss: -1535.781006\n",
      "Train Epoch: 1475 [32768/54000 (61%)] Loss: -1536.750366\n",
      "    epoch          : 1475\n",
      "    loss           : -1537.8985641767395\n",
      "    ess            : 3.776824843208745\n",
      "    log_marginal   : 1538.026263542895\n",
      "    val_loss       : -1536.9289143880208\n",
      "    val_ess        : 3.786300857861837\n",
      "    val_log_marginal: 1537.047831217448\n",
      "Train Epoch: 1476 [0/54000 (0%)] Loss: -1541.755249\n",
      "Train Epoch: 1476 [32768/54000 (61%)] Loss: -1535.165771\n",
      "    epoch          : 1476\n",
      "    loss           : -1537.8328972582547\n",
      "    ess            : 3.774806458995027\n",
      "    log_marginal   : 1537.9619232753537\n",
      "    val_loss       : -1536.8935953776042\n",
      "    val_ess        : 3.7671146392822266\n",
      "    val_log_marginal: 1537.025899251302\n",
      "Train Epoch: 1477 [0/54000 (0%)] Loss: -1536.802246\n",
      "Train Epoch: 1477 [32768/54000 (61%)] Loss: -1536.690430\n",
      "    epoch          : 1477\n",
      "    loss           : -1537.8388487617924\n",
      "    ess            : 3.7720363814875766\n",
      "    log_marginal   : 1537.9698854842277\n",
      "    val_loss       : -1537.1783854166667\n",
      "    val_ess        : 3.762180209159851\n",
      "    val_log_marginal: 1537.3179931640625\n",
      "Train Epoch: 1478 [0/54000 (0%)] Loss: -1536.765137\n",
      "Train Epoch: 1478 [32768/54000 (61%)] Loss: -1538.776123\n",
      "    epoch          : 1478\n",
      "    loss           : -1537.9528992850826\n",
      "    ess            : 3.7736244741475806\n",
      "    log_marginal   : 1538.0861655181309\n",
      "    val_loss       : -1537.3133138020833\n",
      "    val_ess        : 3.7733925183614097\n",
      "    val_log_marginal: 1537.4288330078125\n",
      "Train Epoch: 1479 [0/54000 (0%)] Loss: -1535.265381\n",
      "Train Epoch: 1479 [32768/54000 (61%)] Loss: -1539.395752\n",
      "    epoch          : 1479\n",
      "    loss           : -1537.9151404038914\n",
      "    ess            : 3.7788350042307153\n",
      "    log_marginal   : 1538.0433602962853\n",
      "    val_loss       : -1537.3530883789062\n",
      "    val_ess        : 3.7844900290171304\n",
      "    val_log_marginal: 1537.47265625\n",
      "Train Epoch: 1480 [0/54000 (0%)] Loss: -1542.524414\n",
      "Train Epoch: 1480 [32768/54000 (61%)] Loss: -1535.911133\n",
      "    epoch          : 1480\n",
      "    loss           : -1537.9809132701946\n",
      "    ess            : 3.7777207662474432\n",
      "    log_marginal   : 1538.1109296690743\n",
      "    val_loss       : -1537.257568359375\n",
      "    val_ess        : 3.785759210586548\n",
      "    val_log_marginal: 1537.3670857747395\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1480.pth ...\n",
      "Train Epoch: 1481 [0/54000 (0%)] Loss: -1538.773438\n",
      "Train Epoch: 1481 [32768/54000 (61%)] Loss: -1538.357910\n",
      "    epoch          : 1481\n",
      "    loss           : -1538.0686841280956\n",
      "    ess            : 3.772557294593667\n",
      "    log_marginal   : 1538.2009139150944\n",
      "    val_loss       : -1537.0762329101562\n",
      "    val_ess        : 3.7695804437001548\n",
      "    val_log_marginal: 1537.1984049479167\n",
      "Train Epoch: 1482 [0/54000 (0%)] Loss: -1537.185791\n",
      "Train Epoch: 1482 [32768/54000 (61%)] Loss: -1536.997192\n",
      "    epoch          : 1482\n",
      "    loss           : -1538.1333606647995\n",
      "    ess            : 3.7721115418200224\n",
      "    log_marginal   : 1538.2640012345223\n",
      "    val_loss       : -1537.4471028645833\n",
      "    val_ess        : 3.7785611947377524\n",
      "    val_log_marginal: 1537.5663655598958\n",
      "Train Epoch: 1483 [0/54000 (0%)] Loss: -1540.997070\n",
      "Train Epoch: 1483 [32768/54000 (61%)] Loss: -1535.295166\n",
      "    epoch          : 1483\n",
      "    loss           : -1538.126787293632\n",
      "    ess            : 3.7719935516141496\n",
      "    log_marginal   : 1538.2605233822228\n",
      "    val_loss       : -1537.344482421875\n",
      "    val_ess        : 3.7762693564097085\n",
      "    val_log_marginal: 1537.46923828125\n",
      "Train Epoch: 1484 [0/54000 (0%)] Loss: -1540.420654\n",
      "Train Epoch: 1484 [32768/54000 (61%)] Loss: -1537.279907\n",
      "    epoch          : 1484\n",
      "    loss           : -1538.1673791273586\n",
      "    ess            : 3.772696904416354\n",
      "    log_marginal   : 1538.2961587006191\n",
      "    val_loss       : -1537.1469116210938\n",
      "    val_ess        : 3.784550189971924\n",
      "    val_log_marginal: 1537.27490234375\n",
      "Train Epoch: 1485 [0/54000 (0%)] Loss: -1536.315308\n",
      "Train Epoch: 1485 [32768/54000 (61%)] Loss: -1535.620361\n",
      "    epoch          : 1485\n",
      "    loss           : -1538.1591428360848\n",
      "    ess            : 3.774895780491379\n",
      "    log_marginal   : 1538.2885673091096\n",
      "    val_loss       : -1537.2170003255208\n",
      "    val_ess        : 3.7812956174214682\n",
      "    val_log_marginal: 1537.3346150716145\n",
      "Train Epoch: 1486 [0/54000 (0%)] Loss: -1541.254761\n",
      "Train Epoch: 1486 [32768/54000 (61%)] Loss: -1536.368530\n",
      "    epoch          : 1486\n",
      "    loss           : -1538.1961001989976\n",
      "    ess            : 3.7803568255226567\n",
      "    log_marginal   : 1538.3218832915684\n",
      "    val_loss       : -1537.3287963867188\n",
      "    val_ess        : 3.7739731470743814\n",
      "    val_log_marginal: 1537.446756998698\n",
      "Train Epoch: 1487 [0/54000 (0%)] Loss: -1539.687012\n",
      "Train Epoch: 1487 [32768/54000 (61%)] Loss: -1539.975830\n",
      "    epoch          : 1487\n",
      "    loss           : -1538.2013446160083\n",
      "    ess            : 3.776824600291702\n",
      "    log_marginal   : 1538.3280075361145\n",
      "    val_loss       : -1537.5369669596355\n",
      "    val_ess        : 3.7772799332936606\n",
      "    val_log_marginal: 1537.6652018229167\n",
      "Train Epoch: 1488 [0/54000 (0%)] Loss: -1540.827148\n",
      "Train Epoch: 1488 [32768/54000 (61%)] Loss: -1538.485107\n",
      "    epoch          : 1488\n",
      "    loss           : -1538.0845256301593\n",
      "    ess            : 3.7775294105961637\n",
      "    log_marginal   : 1538.2114073555424\n",
      "    val_loss       : -1536.7986246744792\n",
      "    val_ess        : 3.779082099596659\n",
      "    val_log_marginal: 1536.9334716796875\n",
      "Train Epoch: 1489 [0/54000 (0%)] Loss: -1537.564331\n",
      "Train Epoch: 1489 [32768/54000 (61%)] Loss: -1539.291748\n",
      "    epoch          : 1489\n",
      "    loss           : -1538.1213217681309\n",
      "    ess            : 3.772511950079\n",
      "    log_marginal   : 1538.2524091612618\n",
      "    val_loss       : -1537.2148844401042\n",
      "    val_ess        : 3.7623414198557534\n",
      "    val_log_marginal: 1537.355000813802\n",
      "Train Epoch: 1490 [0/54000 (0%)] Loss: -1538.747803\n",
      "Train Epoch: 1490 [32768/54000 (61%)] Loss: -1540.617920\n",
      "    epoch          : 1490\n",
      "    loss           : -1538.2081091538914\n",
      "    ess            : 3.7721291218163833\n",
      "    log_marginal   : 1538.3417738428657\n",
      "    val_loss       : -1537.1362711588542\n",
      "    val_ess        : 3.769852876663208\n",
      "    val_log_marginal: 1537.2694702148438\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1490.pth ...\n",
      "Train Epoch: 1491 [0/54000 (0%)] Loss: -1540.375977\n",
      "Train Epoch: 1491 [32768/54000 (61%)] Loss: -1538.097168\n",
      "    epoch          : 1491\n",
      "    loss           : -1538.2443732495578\n",
      "    ess            : 3.7762129621685676\n",
      "    log_marginal   : 1538.372314453125\n",
      "    val_loss       : -1537.0149332682292\n",
      "    val_ess        : 3.7684483528137207\n",
      "    val_log_marginal: 1537.1469319661458\n",
      "Train Epoch: 1492 [0/54000 (0%)] Loss: -1541.077637\n",
      "Train Epoch: 1492 [32768/54000 (61%)] Loss: -1538.518066\n",
      "    epoch          : 1492\n",
      "    loss           : -1538.321086379717\n",
      "    ess            : 3.77198466714823\n",
      "    log_marginal   : 1538.45473033977\n",
      "    val_loss       : -1537.104024251302\n",
      "    val_ess        : 3.767068107922872\n",
      "    val_log_marginal: 1537.250020345052\n",
      "Train Epoch: 1493 [0/54000 (0%)] Loss: -1535.632324\n",
      "Train Epoch: 1493 [32768/54000 (61%)] Loss: -1537.349976\n",
      "    epoch          : 1493\n",
      "    loss           : -1538.3617404002064\n",
      "    ess            : 3.777921586666467\n",
      "    log_marginal   : 1538.488401017099\n",
      "    val_loss       : -1537.3431803385417\n",
      "    val_ess        : 3.7669384876887\n",
      "    val_log_marginal: 1537.4716389973958\n",
      "Train Epoch: 1494 [0/54000 (0%)] Loss: -1538.593262\n",
      "Train Epoch: 1494 [32768/54000 (61%)] Loss: -1538.364014\n",
      "    epoch          : 1494\n",
      "    loss           : -1538.3019950434846\n",
      "    ess            : 3.7710984697881735\n",
      "    log_marginal   : 1538.4362516583137\n",
      "    val_loss       : -1537.3705240885417\n",
      "    val_ess        : 3.7792476415634155\n",
      "    val_log_marginal: 1537.4996134440105\n",
      "Train Epoch: 1495 [0/54000 (0%)] Loss: -1536.347656\n",
      "Train Epoch: 1495 [32768/54000 (61%)] Loss: -1539.104004\n",
      "    epoch          : 1495\n",
      "    loss           : -1538.4625773879718\n",
      "    ess            : 3.7725642042339973\n",
      "    log_marginal   : 1538.5899796395931\n",
      "    val_loss       : -1537.4073486328125\n",
      "    val_ess        : 3.7726343472798667\n",
      "    val_log_marginal: 1537.540059407552\n",
      "Train Epoch: 1496 [0/54000 (0%)] Loss: -1539.769897\n",
      "Train Epoch: 1496 [32768/54000 (61%)] Loss: -1540.265137\n",
      "    epoch          : 1496\n",
      "    loss           : -1538.5325052513267\n",
      "    ess            : 3.773823040836262\n",
      "    log_marginal   : 1538.6633738391804\n",
      "    val_loss       : -1537.5546875\n",
      "    val_ess        : 3.777840336163839\n",
      "    val_log_marginal: 1537.6878255208333\n",
      "Train Epoch: 1497 [0/54000 (0%)] Loss: -1540.793823\n",
      "Train Epoch: 1497 [32768/54000 (61%)] Loss: -1538.545166\n",
      "    epoch          : 1497\n",
      "    loss           : -1538.593911224941\n",
      "    ess            : 3.776755944737848\n",
      "    log_marginal   : 1538.7206570607311\n",
      "    val_loss       : -1537.6563924153645\n",
      "    val_ess        : 3.7668329874674478\n",
      "    val_log_marginal: 1537.7970174153645\n",
      "Train Epoch: 1498 [0/54000 (0%)] Loss: -1540.159424\n",
      "Train Epoch: 1498 [32768/54000 (61%)] Loss: -1538.030518\n",
      "    epoch          : 1498\n",
      "    loss           : -1538.5373350899174\n",
      "    ess            : 3.769716109869615\n",
      "    log_marginal   : 1538.6708477668042\n",
      "    val_loss       : -1538.2688598632812\n",
      "    val_ess        : 3.7849863370259604\n",
      "    val_log_marginal: 1538.3893636067708\n",
      "Train Epoch: 1499 [0/54000 (0%)] Loss: -1537.042236\n",
      "Train Epoch: 1499 [32768/54000 (61%)] Loss: -1537.093506\n",
      "    epoch          : 1499\n",
      "    loss           : -1538.6200319686027\n",
      "    ess            : 3.7742770662847556\n",
      "    log_marginal   : 1538.749138598172\n",
      "    val_loss       : -1538.1286214192708\n",
      "    val_ess        : 3.7813072204589844\n",
      "    val_log_marginal: 1538.2581990559895\n",
      "Train Epoch: 1500 [0/54000 (0%)] Loss: -1540.003296\n",
      "Train Epoch: 1500 [32768/54000 (61%)] Loss: -1540.588867\n",
      "    epoch          : 1500\n",
      "    loss           : -1538.5767614976414\n",
      "    ess            : 3.7743115919940875\n",
      "    log_marginal   : 1538.7066535229953\n",
      "    val_loss       : -1538.4178670247395\n",
      "    val_ess        : 3.7640504837036133\n",
      "    val_log_marginal: 1538.5614420572917\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1500.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1501 [0/54000 (0%)] Loss: -1536.724609\n",
      "Train Epoch: 1501 [32768/54000 (61%)] Loss: -1537.045898\n",
      "    epoch          : 1501\n",
      "    loss           : -1538.5311486586086\n",
      "    ess            : 3.7745441400779867\n",
      "    log_marginal   : 1538.6612272442512\n",
      "    val_loss       : -1537.9740804036458\n",
      "    val_ess        : 3.7658646504084268\n",
      "    val_log_marginal: 1538.11279296875\n",
      "Train Epoch: 1502 [0/54000 (0%)] Loss: -1538.510498\n",
      "Train Epoch: 1502 [32768/54000 (61%)] Loss: -1539.553223\n",
      "    epoch          : 1502\n",
      "    loss           : -1538.6883706146816\n",
      "    ess            : 3.776934547244378\n",
      "    log_marginal   : 1538.8172331036262\n",
      "    val_loss       : -1538.0276692708333\n",
      "    val_ess        : 3.766349196434021\n",
      "    val_log_marginal: 1538.1574300130208\n",
      "Train Epoch: 1503 [0/54000 (0%)] Loss: -1537.370361\n",
      "Train Epoch: 1503 [32768/54000 (61%)] Loss: -1538.773193\n",
      "    epoch          : 1503\n",
      "    loss           : -1538.7530102999706\n",
      "    ess            : 3.7738426676336325\n",
      "    log_marginal   : 1538.8833537551593\n",
      "    val_loss       : -1538.101338704427\n",
      "    val_ess        : 3.7858737309773765\n",
      "    val_log_marginal: 1538.2266438802083\n",
      "Train Epoch: 1504 [0/54000 (0%)] Loss: -1542.037231\n",
      "Train Epoch: 1504 [32768/54000 (61%)] Loss: -1540.841797\n",
      "    epoch          : 1504\n",
      "    loss           : -1538.7110227188973\n",
      "    ess            : 3.7752040152279838\n",
      "    log_marginal   : 1538.839786169664\n",
      "    val_loss       : -1537.9053955078125\n",
      "    val_ess        : 3.7844552596410117\n",
      "    val_log_marginal: 1538.0289713541667\n",
      "Train Epoch: 1505 [0/54000 (0%)] Loss: -1538.378418\n",
      "Train Epoch: 1505 [32768/54000 (61%)] Loss: -1537.640259\n",
      "    epoch          : 1505\n",
      "    loss           : -1538.9241943359375\n",
      "    ess            : 3.7833418981084286\n",
      "    log_marginal   : 1539.048157889888\n",
      "    val_loss       : -1537.7568766276042\n",
      "    val_ess        : 3.7795932292938232\n",
      "    val_log_marginal: 1537.8816731770833\n",
      "Train Epoch: 1506 [0/54000 (0%)] Loss: -1536.792480\n",
      "Train Epoch: 1506 [32768/54000 (61%)] Loss: -1539.956055\n",
      "    epoch          : 1506\n",
      "    loss           : -1538.9151150685436\n",
      "    ess            : 3.774485893969266\n",
      "    log_marginal   : 1539.0470868956368\n",
      "    val_loss       : -1537.748067220052\n",
      "    val_ess        : 3.7772627671559653\n",
      "    val_log_marginal: 1537.8758748372395\n",
      "Train Epoch: 1507 [0/54000 (0%)] Loss: -1539.569824\n",
      "Train Epoch: 1507 [32768/54000 (61%)] Loss: -1539.374023\n",
      "    epoch          : 1507\n",
      "    loss           : -1538.8612406028892\n",
      "    ess            : 3.774756040213243\n",
      "    log_marginal   : 1538.9902113428657\n",
      "    val_loss       : -1537.9038492838542\n",
      "    val_ess        : 3.774594704310099\n",
      "    val_log_marginal: 1538.0274251302083\n",
      "Train Epoch: 1508 [0/54000 (0%)] Loss: -1541.479004\n",
      "Train Epoch: 1508 [32768/54000 (61%)] Loss: -1539.376709\n",
      "    epoch          : 1508\n",
      "    loss           : -1538.8526772553066\n",
      "    ess            : 3.769990619623436\n",
      "    log_marginal   : 1538.9850360222583\n",
      "    val_loss       : -1538.3082071940105\n",
      "    val_ess        : 3.782844384511312\n",
      "    val_log_marginal: 1538.4372965494792\n",
      "Train Epoch: 1509 [0/54000 (0%)] Loss: -1538.999756\n",
      "Train Epoch: 1509 [32768/54000 (61%)] Loss: -1538.881592\n",
      "    epoch          : 1509\n",
      "    loss           : -1538.952901588296\n",
      "    ess            : 3.7766828581971943\n",
      "    log_marginal   : 1539.0772221403302\n",
      "    val_loss       : -1538.03271484375\n",
      "    val_ess        : 3.7767959435780845\n",
      "    val_log_marginal: 1538.162862141927\n",
      "Train Epoch: 1510 [0/54000 (0%)] Loss: -1538.760010\n",
      "Train Epoch: 1510 [32768/54000 (61%)] Loss: -1537.469360\n",
      "    epoch          : 1510\n",
      "    loss           : -1538.8057331589032\n",
      "    ess            : 3.772017663379885\n",
      "    log_marginal   : 1538.9395959242336\n",
      "    val_loss       : -1538.515380859375\n",
      "    val_ess        : 3.7785724401474\n",
      "    val_log_marginal: 1538.6422526041667\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1510.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1511 [0/54000 (0%)] Loss: -1542.881348\n",
      "Train Epoch: 1511 [32768/54000 (61%)] Loss: -1539.253052\n",
      "    epoch          : 1511\n",
      "    loss           : -1538.8582141804245\n",
      "    ess            : 3.771179568092778\n",
      "    log_marginal   : 1538.9879657097583\n",
      "    val_loss       : -1538.1971435546875\n",
      "    val_ess        : 3.7816138664881387\n",
      "    val_log_marginal: 1538.313456217448\n",
      "Train Epoch: 1512 [0/54000 (0%)] Loss: -1538.367920\n",
      "Train Epoch: 1512 [32768/54000 (61%)] Loss: -1538.565430\n",
      "    epoch          : 1512\n",
      "    loss           : -1538.9057548091096\n",
      "    ess            : 3.775598597976397\n",
      "    log_marginal   : 1539.036989607901\n",
      "    val_loss       : -1538.7938842773438\n",
      "    val_ess        : 3.7810162703196206\n",
      "    val_log_marginal: 1538.929443359375\n",
      "Train Epoch: 1513 [0/54000 (0%)] Loss: -1538.822632\n",
      "Train Epoch: 1513 [32768/54000 (61%)] Loss: -1538.822754\n",
      "    epoch          : 1513\n",
      "    loss           : -1538.8517145120873\n",
      "    ess            : 3.7693392150806933\n",
      "    log_marginal   : 1538.98479648806\n",
      "    val_loss       : -1538.2525838216145\n",
      "    val_ess        : 3.7738226652145386\n",
      "    val_log_marginal: 1538.383056640625\n",
      "Train Epoch: 1514 [0/54000 (0%)] Loss: -1538.149902\n",
      "Train Epoch: 1514 [32768/54000 (61%)] Loss: -1538.020142\n",
      "    epoch          : 1514\n",
      "    loss           : -1538.9247954746463\n",
      "    ess            : 3.7753233279822007\n",
      "    log_marginal   : 1539.0542890440743\n",
      "    val_loss       : -1538.1852620442708\n",
      "    val_ess        : 3.7678194840749106\n",
      "    val_log_marginal: 1538.3243815104167\n",
      "Train Epoch: 1515 [0/54000 (0%)] Loss: -1542.552856\n",
      "Train Epoch: 1515 [32768/54000 (61%)] Loss: -1541.011230\n",
      "    epoch          : 1515\n",
      "    loss           : -1538.9564301112912\n",
      "    ess            : 3.7736075329330734\n",
      "    log_marginal   : 1539.0858476746757\n",
      "    val_loss       : -1538.2549235026042\n",
      "    val_ess        : 3.7667423486709595\n",
      "    val_log_marginal: 1538.3837076822917\n",
      "Train Epoch: 1516 [0/54000 (0%)] Loss: -1536.480347\n",
      "Train Epoch: 1516 [32768/54000 (61%)] Loss: -1534.949341\n",
      "    epoch          : 1516\n",
      "    loss           : -1539.0249207694576\n",
      "    ess            : 3.7723379495008937\n",
      "    log_marginal   : 1539.1560910782723\n",
      "    val_loss       : -1538.1942952473958\n",
      "    val_ess        : 3.7912681897481284\n",
      "    val_log_marginal: 1538.3108520507812\n",
      "Train Epoch: 1517 [0/54000 (0%)] Loss: -1540.730103\n",
      "Train Epoch: 1517 [32768/54000 (61%)] Loss: -1540.667114\n",
      "    epoch          : 1517\n",
      "    loss           : -1538.9857016509434\n",
      "    ess            : 3.7713384268418797\n",
      "    log_marginal   : 1539.1202185288914\n",
      "    val_loss       : -1537.928243001302\n",
      "    val_ess        : 3.77489443620046\n",
      "    val_log_marginal: 1538.0664672851562\n",
      "Train Epoch: 1518 [0/54000 (0%)] Loss: -1537.885742\n",
      "Train Epoch: 1518 [32768/54000 (61%)] Loss: -1542.710693\n",
      "    epoch          : 1518\n",
      "    loss           : -1538.9775713074882\n",
      "    ess            : 3.7728108729956285\n",
      "    log_marginal   : 1539.1105980063385\n",
      "    val_loss       : -1538.1815795898438\n",
      "    val_ess        : 3.770312190055847\n",
      "    val_log_marginal: 1538.326171875\n",
      "Train Epoch: 1519 [0/54000 (0%)] Loss: -1542.578125\n",
      "Train Epoch: 1519 [32768/54000 (61%)] Loss: -1541.173584\n",
      "    epoch          : 1519\n",
      "    loss           : -1539.0451130417157\n",
      "    ess            : 3.774302586069647\n",
      "    log_marginal   : 1539.176737083579\n",
      "    val_loss       : -1538.5674438476562\n",
      "    val_ess        : 3.7680213848749795\n",
      "    val_log_marginal: 1538.698994954427\n",
      "Train Epoch: 1520 [0/54000 (0%)] Loss: -1539.984619\n",
      "Train Epoch: 1520 [32768/54000 (61%)] Loss: -1539.419312\n",
      "    epoch          : 1520\n",
      "    loss           : -1539.059061302329\n",
      "    ess            : 3.7719675280013174\n",
      "    log_marginal   : 1539.1933731942806\n",
      "    val_loss       : -1538.3465169270833\n",
      "    val_ess        : 3.7554157972335815\n",
      "    val_log_marginal: 1538.4935913085938\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1520.pth ...\n",
      "Train Epoch: 1521 [0/54000 (0%)] Loss: -1543.910400\n",
      "Train Epoch: 1521 [32768/54000 (61%)] Loss: -1540.561890\n",
      "    epoch          : 1521\n",
      "    loss           : -1539.0082938716096\n",
      "    ess            : 3.776972865158657\n",
      "    log_marginal   : 1539.1344477815448\n",
      "    val_loss       : -1538.2710978190105\n",
      "    val_ess        : 3.774492700894674\n",
      "    val_log_marginal: 1538.40283203125\n",
      "Train Epoch: 1522 [0/54000 (0%)] Loss: -1537.944336\n",
      "Train Epoch: 1522 [32768/54000 (61%)] Loss: -1540.505615\n",
      "    epoch          : 1522\n",
      "    loss           : -1539.241388284935\n",
      "    ess            : 3.772957554403341\n",
      "    log_marginal   : 1539.3722752984966\n",
      "    val_loss       : -1538.219014485677\n",
      "    val_ess        : 3.767451445261637\n",
      "    val_log_marginal: 1538.3635864257812\n",
      "Train Epoch: 1523 [0/54000 (0%)] Loss: -1538.300293\n",
      "Train Epoch: 1523 [32768/54000 (61%)] Loss: -1538.836304\n",
      "    epoch          : 1523\n",
      "    loss           : -1539.218448279039\n",
      "    ess            : 3.773440572450746\n",
      "    log_marginal   : 1539.3477829267395\n",
      "    val_loss       : -1538.020039876302\n",
      "    val_ess        : 3.7817874749501548\n",
      "    val_log_marginal: 1538.133280436198\n",
      "Train Epoch: 1524 [0/54000 (0%)] Loss: -1539.061523\n",
      "Train Epoch: 1524 [32768/54000 (61%)] Loss: -1535.127075\n",
      "    epoch          : 1524\n",
      "    loss           : -1539.135861954599\n",
      "    ess            : 3.77619254814004\n",
      "    log_marginal   : 1539.2652933372642\n",
      "    val_loss       : -1538.1640625\n",
      "    val_ess        : 3.7809492349624634\n",
      "    val_log_marginal: 1538.28515625\n",
      "Train Epoch: 1525 [0/54000 (0%)] Loss: -1540.332764\n",
      "Train Epoch: 1525 [32768/54000 (61%)] Loss: -1538.024658\n",
      "    epoch          : 1525\n",
      "    loss           : -1539.294880417158\n",
      "    ess            : 3.7737790233684034\n",
      "    log_marginal   : 1539.4231509802476\n",
      "    val_loss       : -1538.4713948567708\n",
      "    val_ess        : 3.7631298700968423\n",
      "    val_log_marginal: 1538.6211954752605\n",
      "Train Epoch: 1526 [0/54000 (0%)] Loss: -1541.512207\n",
      "Train Epoch: 1526 [32768/54000 (61%)] Loss: -1538.842529\n",
      "    epoch          : 1526\n",
      "    loss           : -1539.1750119767098\n",
      "    ess            : 3.771580862549116\n",
      "    log_marginal   : 1539.3104524432488\n",
      "    val_loss       : -1538.305440266927\n",
      "    val_ess        : 3.778603951136271\n",
      "    val_log_marginal: 1538.4322306315105\n",
      "Train Epoch: 1527 [0/54000 (0%)] Loss: -1541.346680\n",
      "Train Epoch: 1527 [32768/54000 (61%)] Loss: -1538.952881\n",
      "    epoch          : 1527\n",
      "    loss           : -1539.1981155107605\n",
      "    ess            : 3.7736872547077684\n",
      "    log_marginal   : 1539.3269365418632\n",
      "    val_loss       : -1538.3631795247395\n",
      "    val_ess        : 3.7821789185206094\n",
      "    val_log_marginal: 1538.4789428710938\n",
      "Train Epoch: 1528 [0/54000 (0%)] Loss: -1541.789673\n",
      "Train Epoch: 1528 [32768/54000 (61%)] Loss: -1541.043701\n",
      "    epoch          : 1528\n",
      "    loss           : -1539.2302637640034\n",
      "    ess            : 3.7750554984470583\n",
      "    log_marginal   : 1539.3623046875\n",
      "    val_loss       : -1538.6975708007812\n",
      "    val_ess        : 3.7762926816940308\n",
      "    val_log_marginal: 1538.8318684895833\n",
      "Train Epoch: 1529 [0/54000 (0%)] Loss: -1538.063232\n",
      "Train Epoch: 1529 [32768/54000 (61%)] Loss: -1541.496582\n",
      "    epoch          : 1529\n",
      "    loss           : -1539.3379988760319\n",
      "    ess            : 3.7748011283154757\n",
      "    log_marginal   : 1539.466792268573\n",
      "    val_loss       : -1538.6073811848958\n",
      "    val_ess        : 3.770140369733175\n",
      "    val_log_marginal: 1538.7372233072917\n",
      "Train Epoch: 1530 [0/54000 (0%)] Loss: -1538.527222\n",
      "Train Epoch: 1530 [32768/54000 (61%)] Loss: -1540.795654\n",
      "    epoch          : 1530\n",
      "    loss           : -1539.479024635171\n",
      "    ess            : 3.7764453797970177\n",
      "    log_marginal   : 1539.6069934772995\n",
      "    val_loss       : -1538.55908203125\n",
      "    val_ess        : 3.7843955357869468\n",
      "    val_log_marginal: 1538.6802164713542\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1530.pth ...\n",
      "Train Epoch: 1531 [0/54000 (0%)] Loss: -1539.809692\n",
      "Train Epoch: 1531 [32768/54000 (61%)] Loss: -1538.551025\n",
      "    epoch          : 1531\n",
      "    loss           : -1539.3537758881191\n",
      "    ess            : 3.7768895221206376\n",
      "    log_marginal   : 1539.485107421875\n",
      "    val_loss       : -1538.4573567708333\n",
      "    val_ess        : 3.7846554120381675\n",
      "    val_log_marginal: 1538.5814005533855\n",
      "Train Epoch: 1532 [0/54000 (0%)] Loss: -1541.013428\n",
      "Train Epoch: 1532 [32768/54000 (61%)] Loss: -1539.779663\n",
      "    epoch          : 1532\n",
      "    loss           : -1539.515079138414\n",
      "    ess            : 3.7766091193792954\n",
      "    log_marginal   : 1539.644448334316\n",
      "    val_loss       : -1538.5985717773438\n",
      "    val_ess        : 3.7706175645192466\n",
      "    val_log_marginal: 1538.7371826171875\n",
      "Train Epoch: 1533 [0/54000 (0%)] Loss: -1539.768066\n",
      "Train Epoch: 1533 [32768/54000 (61%)] Loss: -1541.073975\n",
      "    epoch          : 1533\n",
      "    loss           : -1539.4403582878833\n",
      "    ess            : 3.7786618178745486\n",
      "    log_marginal   : 1539.5683616782135\n",
      "    val_loss       : -1538.67333984375\n",
      "    val_ess        : 3.7747073968251548\n",
      "    val_log_marginal: 1538.8121337890625\n",
      "Train Epoch: 1534 [0/54000 (0%)] Loss: -1538.798950\n",
      "Train Epoch: 1534 [32768/54000 (61%)] Loss: -1538.377930\n",
      "    epoch          : 1534\n",
      "    loss           : -1539.5654780549823\n",
      "    ess            : 3.7758176461705624\n",
      "    log_marginal   : 1539.6942921764446\n",
      "    val_loss       : -1538.875223795573\n",
      "    val_ess        : 3.7847325801849365\n",
      "    val_log_marginal: 1538.9933268229167\n",
      "Train Epoch: 1535 [0/54000 (0%)] Loss: -1539.542603\n",
      "Train Epoch: 1535 [32768/54000 (61%)] Loss: -1539.565430\n",
      "    epoch          : 1535\n",
      "    loss           : -1539.5068520599941\n",
      "    ess            : 3.774481310034698\n",
      "    log_marginal   : 1539.636698021079\n",
      "    val_loss       : -1538.5821126302083\n",
      "    val_ess        : 3.787002921104431\n",
      "    val_log_marginal: 1538.6968994140625\n",
      "Train Epoch: 1536 [0/54000 (0%)] Loss: -1540.803955\n",
      "Train Epoch: 1536 [32768/54000 (61%)] Loss: -1539.337402\n",
      "    epoch          : 1536\n",
      "    loss           : -1539.5824826798348\n",
      "    ess            : 3.7739880669791743\n",
      "    log_marginal   : 1539.7158110996463\n",
      "    val_loss       : -1538.4242757161458\n",
      "    val_ess        : 3.771962602933248\n",
      "    val_log_marginal: 1538.5581461588542\n",
      "Train Epoch: 1537 [0/54000 (0%)] Loss: -1540.098389\n",
      "Train Epoch: 1537 [32768/54000 (61%)] Loss: -1538.296143\n",
      "    epoch          : 1537\n",
      "    loss           : -1539.651309607164\n",
      "    ess            : 3.7676923634871\n",
      "    log_marginal   : 1539.7886294958726\n",
      "    val_loss       : -1538.9417928059895\n",
      "    val_ess        : 3.774478634198507\n",
      "    val_log_marginal: 1539.075439453125\n",
      "Train Epoch: 1538 [0/54000 (0%)] Loss: -1539.454712\n",
      "Train Epoch: 1538 [32768/54000 (61%)] Loss: -1536.057373\n",
      "    epoch          : 1538\n",
      "    loss           : -1539.7633402122642\n",
      "    ess            : 3.7726492836790264\n",
      "    log_marginal   : 1539.8943055350826\n",
      "    val_loss       : -1538.916971842448\n",
      "    val_ess        : 3.7743828694025674\n",
      "    val_log_marginal: 1539.0453287760417\n",
      "Train Epoch: 1539 [0/54000 (0%)] Loss: -1540.355469\n",
      "Train Epoch: 1539 [32768/54000 (61%)] Loss: -1539.815308\n",
      "    epoch          : 1539\n",
      "    loss           : -1539.802916328862\n",
      "    ess            : 3.77424193778128\n",
      "    log_marginal   : 1539.9335131375294\n",
      "    val_loss       : -1538.7022094726562\n",
      "    val_ess        : 3.7726434071858725\n",
      "    val_log_marginal: 1538.8338012695312\n",
      "Train Epoch: 1540 [0/54000 (0%)] Loss: -1538.325439\n",
      "Train Epoch: 1540 [32768/54000 (61%)] Loss: -1538.183594\n",
      "    epoch          : 1540\n",
      "    loss           : -1539.7745499520931\n",
      "    ess            : 3.7749400858609183\n",
      "    log_marginal   : 1539.9050684515034\n",
      "    val_loss       : -1538.9306233723958\n",
      "    val_ess        : 3.790760119756063\n",
      "    val_log_marginal: 1539.047139485677\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1540.pth ...\n",
      "Train Epoch: 1541 [0/54000 (0%)] Loss: -1539.465942\n",
      "Train Epoch: 1541 [32768/54000 (61%)] Loss: -1538.552124\n",
      "    epoch          : 1541\n",
      "    loss           : -1539.6946606905956\n",
      "    ess            : 3.77713790479696\n",
      "    log_marginal   : 1539.8237442880306\n",
      "    val_loss       : -1538.993896484375\n",
      "    val_ess        : 3.781092961629232\n",
      "    val_log_marginal: 1539.1107991536458\n",
      "Train Epoch: 1542 [0/54000 (0%)] Loss: -1539.753296\n",
      "Train Epoch: 1542 [32768/54000 (61%)] Loss: -1539.711060\n",
      "    epoch          : 1542\n",
      "    loss           : -1539.8335237323113\n",
      "    ess            : 3.7781340626050843\n",
      "    log_marginal   : 1539.9650118845814\n",
      "    val_loss       : -1538.8401896158855\n",
      "    val_ess        : 3.7662786642710366\n",
      "    val_log_marginal: 1538.9804280598958\n",
      "Train Epoch: 1543 [0/54000 (0%)] Loss: -1540.989746\n",
      "Train Epoch: 1543 [32768/54000 (61%)] Loss: -1543.122925\n",
      "    epoch          : 1543\n",
      "    loss           : -1539.8244997420402\n",
      "    ess            : 3.7732255638770336\n",
      "    log_marginal   : 1539.9550666089328\n",
      "    val_loss       : -1539.3634033203125\n",
      "    val_ess        : 3.7812222242355347\n",
      "    val_log_marginal: 1539.4891560872395\n",
      "Train Epoch: 1544 [0/54000 (0%)] Loss: -1541.329468\n",
      "Train Epoch: 1544 [32768/54000 (61%)] Loss: -1540.222534\n",
      "    epoch          : 1544\n",
      "    loss           : -1539.927610001474\n",
      "    ess            : 3.7769394460714087\n",
      "    log_marginal   : 1540.0590659087559\n",
      "    val_loss       : -1539.1846313476562\n",
      "    val_ess        : 3.77825657526652\n",
      "    val_log_marginal: 1539.3116658528645\n",
      "Train Epoch: 1545 [0/54000 (0%)] Loss: -1540.333252\n",
      "Train Epoch: 1545 [32768/54000 (61%)] Loss: -1540.029297\n",
      "    epoch          : 1545\n",
      "    loss           : -1540.0271917379127\n",
      "    ess            : 3.773421692398359\n",
      "    log_marginal   : 1540.1571551628833\n",
      "    val_loss       : -1538.5177815755208\n",
      "    val_ess        : 3.76495361328125\n",
      "    val_log_marginal: 1538.6565551757812\n",
      "Train Epoch: 1546 [0/54000 (0%)] Loss: -1545.454224\n",
      "Train Epoch: 1546 [32768/54000 (61%)] Loss: -1539.961304\n",
      "    epoch          : 1546\n",
      "    loss           : -1540.0351861917748\n",
      "    ess            : 3.777167855568652\n",
      "    log_marginal   : 1540.1665499705189\n",
      "    val_loss       : -1538.8038533528645\n",
      "    val_ess        : 3.7729658683141074\n",
      "    val_log_marginal: 1538.9410807291667\n",
      "Train Epoch: 1547 [0/54000 (0%)] Loss: -1544.196655\n",
      "Train Epoch: 1547 [32768/54000 (61%)] Loss: -1539.809082\n",
      "    epoch          : 1547\n",
      "    loss           : -1540.0521977262677\n",
      "    ess            : 3.773214209754512\n",
      "    log_marginal   : 1540.1839714770047\n",
      "    val_loss       : -1538.8575642903645\n",
      "    val_ess        : 3.7789644400278726\n",
      "    val_log_marginal: 1538.9904174804688\n",
      "Train Epoch: 1548 [0/54000 (0%)] Loss: -1538.721436\n",
      "Train Epoch: 1548 [32768/54000 (61%)] Loss: -1538.270996\n",
      "    epoch          : 1548\n",
      "    loss           : -1539.985049841539\n",
      "    ess            : 3.7751065650076234\n",
      "    log_marginal   : 1540.115909216539\n",
      "    val_loss       : -1539.17626953125\n",
      "    val_ess        : 3.7740302085876465\n",
      "    val_log_marginal: 1539.3045857747395\n",
      "Train Epoch: 1549 [0/54000 (0%)] Loss: -1537.967651\n",
      "Train Epoch: 1549 [32768/54000 (61%)] Loss: -1540.315918\n",
      "    epoch          : 1549\n",
      "    loss           : -1540.0505486254422\n",
      "    ess            : 3.7702467126666375\n",
      "    log_marginal   : 1540.1849250073703\n",
      "    val_loss       : -1539.2384440104167\n",
      "    val_ess        : 3.7919547160466514\n",
      "    val_log_marginal: 1539.3631184895833\n",
      "Train Epoch: 1550 [0/54000 (0%)] Loss: -1542.925781\n",
      "Train Epoch: 1550 [32768/54000 (61%)] Loss: -1539.939697\n",
      "    epoch          : 1550\n",
      "    loss           : -1540.24658203125\n",
      "    ess            : 3.774541481485907\n",
      "    log_marginal   : 1540.3766007333431\n",
      "    val_loss       : -1539.3917846679688\n",
      "    val_ess        : 3.771525740623474\n",
      "    val_log_marginal: 1539.514139811198\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1550.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1551 [0/54000 (0%)] Loss: -1539.117798\n",
      "Train Epoch: 1551 [32768/54000 (61%)] Loss: -1541.445801\n",
      "    epoch          : 1551\n",
      "    loss           : -1540.2701899690448\n",
      "    ess            : 3.7753047943115234\n",
      "    log_marginal   : 1540.4005288178066\n",
      "    val_loss       : -1539.4373779296875\n",
      "    val_ess        : 3.7706114053726196\n",
      "    val_log_marginal: 1539.5740356445312\n",
      "Train Epoch: 1552 [0/54000 (0%)] Loss: -1541.494263\n",
      "Train Epoch: 1552 [32768/54000 (61%)] Loss: -1538.945557\n",
      "    epoch          : 1552\n",
      "    loss           : -1540.3941397037147\n",
      "    ess            : 3.778323137535239\n",
      "    log_marginal   : 1540.5241054318985\n",
      "    val_loss       : -1539.9491780598958\n",
      "    val_ess        : 3.7792488733927407\n",
      "    val_log_marginal: 1540.0795288085938\n",
      "Train Epoch: 1553 [0/54000 (0%)] Loss: -1542.733887\n",
      "Train Epoch: 1553 [32768/54000 (61%)] Loss: -1539.185303\n",
      "    epoch          : 1553\n",
      "    loss           : -1540.358771558078\n",
      "    ess            : 3.775873899459839\n",
      "    log_marginal   : 1540.4916900058963\n",
      "    val_loss       : -1539.6448771158855\n",
      "    val_ess        : 3.7738088369369507\n",
      "    val_log_marginal: 1539.7783610026042\n",
      "Train Epoch: 1554 [0/54000 (0%)] Loss: -1541.254639\n",
      "Train Epoch: 1554 [32768/54000 (61%)] Loss: -1542.188110\n",
      "    epoch          : 1554\n",
      "    loss           : -1540.280070754717\n",
      "    ess            : 3.7731149961363593\n",
      "    log_marginal   : 1540.4149423275353\n",
      "    val_loss       : -1539.534444173177\n",
      "    val_ess        : 3.775635997454325\n",
      "    val_log_marginal: 1539.655782063802\n",
      "Train Epoch: 1555 [0/54000 (0%)] Loss: -1540.963013\n",
      "Train Epoch: 1555 [32768/54000 (61%)] Loss: -1541.991455\n",
      "    epoch          : 1555\n",
      "    loss           : -1540.3570303287147\n",
      "    ess            : 3.779631934075985\n",
      "    log_marginal   : 1540.4867450066333\n",
      "    val_loss       : -1540.0389607747395\n",
      "    val_ess        : 3.777488589286804\n",
      "    val_log_marginal: 1540.1693929036458\n",
      "Train Epoch: 1556 [0/54000 (0%)] Loss: -1540.711426\n",
      "Train Epoch: 1556 [32768/54000 (61%)] Loss: -1540.893311\n",
      "    epoch          : 1556\n",
      "    loss           : -1540.4166674344044\n",
      "    ess            : 3.776345324966143\n",
      "    log_marginal   : 1540.5475314158314\n",
      "    val_loss       : -1539.6440022786458\n",
      "    val_ess        : 3.7848729689915976\n",
      "    val_log_marginal: 1539.7684529622395\n",
      "Train Epoch: 1557 [0/54000 (0%)] Loss: -1542.129639\n",
      "Train Epoch: 1557 [32768/54000 (61%)] Loss: -1539.211182\n",
      "    epoch          : 1557\n",
      "    loss           : -1540.4019913583431\n",
      "    ess            : 3.7751345499506535\n",
      "    log_marginal   : 1540.532003150796\n",
      "    val_loss       : -1539.8920491536458\n",
      "    val_ess        : 3.7670845190684\n",
      "    val_log_marginal: 1540.0333048502605\n",
      "Train Epoch: 1558 [0/54000 (0%)] Loss: -1540.007446\n",
      "Train Epoch: 1558 [32768/54000 (61%)] Loss: -1542.233521\n",
      "    epoch          : 1558\n",
      "    loss           : -1540.570879090507\n",
      "    ess            : 3.777767284861151\n",
      "    log_marginal   : 1540.699686302329\n",
      "    val_loss       : -1539.4359741210938\n",
      "    val_ess        : 3.781497359275818\n",
      "    val_log_marginal: 1539.549336751302\n",
      "Train Epoch: 1559 [0/54000 (0%)] Loss: -1542.776489\n",
      "Train Epoch: 1559 [32768/54000 (61%)] Loss: -1539.817993\n",
      "    epoch          : 1559\n",
      "    loss           : -1540.4946611512382\n",
      "    ess            : 3.7802124113406776\n",
      "    log_marginal   : 1540.6240142246463\n",
      "    val_loss       : -1539.1621907552083\n",
      "    val_ess        : 3.786375880241394\n",
      "    val_log_marginal: 1539.2855834960938\n",
      "Train Epoch: 1560 [0/54000 (0%)] Loss: -1542.600098\n",
      "Train Epoch: 1560 [32768/54000 (61%)] Loss: -1539.036987\n",
      "    epoch          : 1560\n",
      "    loss           : -1540.5805802255306\n",
      "    ess            : 3.773790696881852\n",
      "    log_marginal   : 1540.7109858674823\n",
      "    val_loss       : -1539.691650390625\n",
      "    val_ess        : 3.7779664993286133\n",
      "    val_log_marginal: 1539.815165201823\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1560.pth ...\n",
      "Train Epoch: 1561 [0/54000 (0%)] Loss: -1540.981934\n",
      "Train Epoch: 1561 [32768/54000 (61%)] Loss: -1541.867676\n",
      "    epoch          : 1561\n",
      "    loss           : -1540.5988539209907\n",
      "    ess            : 3.7763180417834588\n",
      "    log_marginal   : 1540.7283981611145\n",
      "    val_loss       : -1539.7185668945312\n",
      "    val_ess        : 3.7713640133539834\n",
      "    val_log_marginal: 1539.8557942708333\n",
      "Train Epoch: 1562 [0/54000 (0%)] Loss: -1540.519653\n",
      "Train Epoch: 1562 [32768/54000 (61%)] Loss: -1544.211670\n",
      "    epoch          : 1562\n",
      "    loss           : -1540.6343418337265\n",
      "    ess            : 3.778199276834164\n",
      "    log_marginal   : 1540.7623981979657\n",
      "    val_loss       : -1539.5755818684895\n",
      "    val_ess        : 3.7809417645136514\n",
      "    val_log_marginal: 1539.705342610677\n",
      "Train Epoch: 1563 [0/54000 (0%)] Loss: -1541.628052\n",
      "Train Epoch: 1563 [32768/54000 (61%)] Loss: -1540.195801\n",
      "    epoch          : 1563\n",
      "    loss           : -1540.727762474204\n",
      "    ess            : 3.7763681861589538\n",
      "    log_marginal   : 1540.855795806309\n",
      "    val_loss       : -1539.7154337565105\n",
      "    val_ess        : 3.777358651161194\n",
      "    val_log_marginal: 1539.8460286458333\n",
      "Train Epoch: 1564 [0/54000 (0%)] Loss: -1544.425293\n",
      "Train Epoch: 1564 [32768/54000 (61%)] Loss: -1541.965820\n",
      "    epoch          : 1564\n",
      "    loss           : -1540.7040301628833\n",
      "    ess            : 3.7724733307676495\n",
      "    log_marginal   : 1540.8372503316627\n",
      "    val_loss       : -1539.7494710286458\n",
      "    val_ess        : 3.7796146074930825\n",
      "    val_log_marginal: 1539.877421061198\n",
      "Train Epoch: 1565 [0/54000 (0%)] Loss: -1540.984619\n",
      "Train Epoch: 1565 [32768/54000 (61%)] Loss: -1540.380493\n",
      "    epoch          : 1565\n",
      "    loss           : -1540.7545488465507\n",
      "    ess            : 3.774434615980904\n",
      "    log_marginal   : 1540.8856569686027\n",
      "    val_loss       : -1539.7757568359375\n",
      "    val_ess        : 3.7776029109954834\n",
      "    val_log_marginal: 1539.9097290039062\n",
      "Train Epoch: 1566 [0/54000 (0%)] Loss: -1540.675049\n",
      "Train Epoch: 1566 [32768/54000 (61%)] Loss: -1541.430176\n",
      "    epoch          : 1566\n",
      "    loss           : -1540.7572551223468\n",
      "    ess            : 3.7775005934373387\n",
      "    log_marginal   : 1540.885498046875\n",
      "    val_loss       : -1539.743143717448\n",
      "    val_ess        : 3.7730671564737954\n",
      "    val_log_marginal: 1539.8807576497395\n",
      "Train Epoch: 1567 [0/54000 (0%)] Loss: -1539.330200\n",
      "Train Epoch: 1567 [32768/54000 (61%)] Loss: -1539.979736\n",
      "    epoch          : 1567\n",
      "    loss           : -1540.8097868145637\n",
      "    ess            : 3.772269851756546\n",
      "    log_marginal   : 1540.941972840507\n",
      "    val_loss       : -1540.2937825520833\n",
      "    val_ess        : 3.7763657172520957\n",
      "    val_log_marginal: 1540.4207153320312\n",
      "Train Epoch: 1568 [0/54000 (0%)] Loss: -1541.921631\n",
      "Train Epoch: 1568 [32768/54000 (61%)] Loss: -1542.110352\n",
      "    epoch          : 1568\n",
      "    loss           : -1540.8192184736145\n",
      "    ess            : 3.7729773386469425\n",
      "    log_marginal   : 1540.95075038694\n",
      "    val_loss       : -1540.0383707682292\n",
      "    val_ess        : 3.780194083849589\n",
      "    val_log_marginal: 1540.1586303710938\n",
      "Train Epoch: 1569 [0/54000 (0%)] Loss: -1541.625244\n",
      "Train Epoch: 1569 [32768/54000 (61%)] Loss: -1543.764404\n",
      "    epoch          : 1569\n",
      "    loss           : -1540.8595845924233\n",
      "    ess            : 3.7771242789502413\n",
      "    log_marginal   : 1540.9888409308667\n",
      "    val_loss       : -1539.9908650716145\n",
      "    val_ess        : 3.7728262742360434\n",
      "    val_log_marginal: 1540.1257731119792\n",
      "Train Epoch: 1570 [0/54000 (0%)] Loss: -1540.267334\n",
      "Train Epoch: 1570 [32768/54000 (61%)] Loss: -1539.019043\n",
      "    epoch          : 1570\n",
      "    loss           : -1540.8160054908608\n",
      "    ess            : 3.7756027590553716\n",
      "    log_marginal   : 1540.9466898216392\n",
      "    val_loss       : -1540.303955078125\n",
      "    val_ess        : 3.7690616448720298\n",
      "    val_log_marginal: 1540.448221842448\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1570.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1571 [0/54000 (0%)] Loss: -1542.500122\n",
      "Train Epoch: 1571 [32768/54000 (61%)] Loss: -1541.321411\n",
      "    epoch          : 1571\n",
      "    loss           : -1540.7888782429245\n",
      "    ess            : 3.7742423876276554\n",
      "    log_marginal   : 1540.9198504753833\n",
      "    val_loss       : -1540.7960815429688\n",
      "    val_ess        : 3.782850662867228\n",
      "    val_log_marginal: 1540.9169311523438\n",
      "Train Epoch: 1572 [0/54000 (0%)] Loss: -1540.951538\n",
      "Train Epoch: 1572 [32768/54000 (61%)] Loss: -1540.300781\n",
      "    epoch          : 1572\n",
      "    loss           : -1540.8423335237323\n",
      "    ess            : 3.7741959949709334\n",
      "    log_marginal   : 1540.9754316221993\n",
      "    val_loss       : -1540.3385416666667\n",
      "    val_ess        : 3.779414931933085\n",
      "    val_log_marginal: 1540.4657592773438\n",
      "Train Epoch: 1573 [0/54000 (0%)] Loss: -1541.100586\n",
      "Train Epoch: 1573 [32768/54000 (61%)] Loss: -1541.411377\n",
      "    epoch          : 1573\n",
      "    loss           : -1540.8022483969635\n",
      "    ess            : 3.7764640169323616\n",
      "    log_marginal   : 1540.9326102778596\n",
      "    val_loss       : -1540.4544881184895\n",
      "    val_ess        : 3.7887970209121704\n",
      "    val_log_marginal: 1540.5696818033855\n",
      "Train Epoch: 1574 [0/54000 (0%)] Loss: -1541.996094\n",
      "Train Epoch: 1574 [32768/54000 (61%)] Loss: -1542.140137\n",
      "    epoch          : 1574\n",
      "    loss           : -1540.9186666236733\n",
      "    ess            : 3.7712478592710674\n",
      "    log_marginal   : 1541.051596587559\n",
      "    val_loss       : -1540.2796834309895\n",
      "    val_ess        : 3.7839208443959556\n",
      "    val_log_marginal: 1540.4041748046875\n",
      "Train Epoch: 1575 [0/54000 (0%)] Loss: -1539.081543\n",
      "Train Epoch: 1575 [32768/54000 (61%)] Loss: -1539.670654\n",
      "    epoch          : 1575\n",
      "    loss           : -1540.881020599941\n",
      "    ess            : 3.774921439728647\n",
      "    log_marginal   : 1541.0094155365566\n",
      "    val_loss       : -1540.3509928385417\n",
      "    val_ess        : 3.775144894917806\n",
      "    val_log_marginal: 1540.4842325846355\n",
      "Train Epoch: 1576 [0/54000 (0%)] Loss: -1544.148438\n",
      "Train Epoch: 1576 [32768/54000 (61%)] Loss: -1542.776855\n",
      "    epoch          : 1576\n",
      "    loss           : -1540.9167019826061\n",
      "    ess            : 3.7733896858287306\n",
      "    log_marginal   : 1541.0468266325177\n",
      "    val_loss       : -1540.3428344726562\n",
      "    val_ess        : 3.7780110836029053\n",
      "    val_log_marginal: 1540.4674275716145\n",
      "Train Epoch: 1577 [0/54000 (0%)] Loss: -1545.587402\n",
      "Train Epoch: 1577 [32768/54000 (61%)] Loss: -1540.272949\n",
      "    epoch          : 1577\n",
      "    loss           : -1541.0271502800708\n",
      "    ess            : 3.7756340143815526\n",
      "    log_marginal   : 1541.156613907724\n",
      "    val_loss       : -1540.1137084960938\n",
      "    val_ess        : 3.7706578572591147\n",
      "    val_log_marginal: 1540.2459920247395\n",
      "Train Epoch: 1578 [0/54000 (0%)] Loss: -1545.548706\n",
      "Train Epoch: 1578 [32768/54000 (61%)] Loss: -1543.532471\n",
      "    epoch          : 1578\n",
      "    loss           : -1541.0185431714328\n",
      "    ess            : 3.775010941163549\n",
      "    log_marginal   : 1541.1473549896816\n",
      "    val_loss       : -1540.4442952473958\n",
      "    val_ess        : 3.782822926839193\n",
      "    val_log_marginal: 1540.5669759114583\n",
      "Train Epoch: 1579 [0/54000 (0%)] Loss: -1541.738770\n",
      "Train Epoch: 1579 [32768/54000 (61%)] Loss: -1539.582275\n",
      "    epoch          : 1579\n",
      "    loss           : -1541.0504035229953\n",
      "    ess            : 3.7752471959815836\n",
      "    log_marginal   : 1541.177411925118\n",
      "    val_loss       : -1540.3851318359375\n",
      "    val_ess        : 3.770572384198507\n",
      "    val_log_marginal: 1540.5146484375\n",
      "Train Epoch: 1580 [0/54000 (0%)] Loss: -1543.845093\n",
      "Train Epoch: 1580 [32768/54000 (61%)] Loss: -1542.003418\n",
      "    epoch          : 1580\n",
      "    loss           : -1541.0071399616745\n",
      "    ess            : 3.766728954495124\n",
      "    log_marginal   : 1541.144853699882\n",
      "    val_loss       : -1540.1858317057292\n",
      "    val_ess        : 3.7784607807795205\n",
      "    val_log_marginal: 1540.3191935221355\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1580.pth ...\n",
      "Train Epoch: 1581 [0/54000 (0%)] Loss: -1542.360962\n",
      "Train Epoch: 1581 [32768/54000 (61%)] Loss: -1539.962036\n",
      "    epoch          : 1581\n",
      "    loss           : -1541.0688315337559\n",
      "    ess            : 3.7730596830260077\n",
      "    log_marginal   : 1541.198917029039\n",
      "    val_loss       : -1540.3108927408855\n",
      "    val_ess        : 3.781429131825765\n",
      "    val_log_marginal: 1540.4326578776042\n",
      "Train Epoch: 1582 [0/54000 (0%)] Loss: -1543.179443\n",
      "Train Epoch: 1582 [32768/54000 (61%)] Loss: -1538.837646\n",
      "    epoch          : 1582\n",
      "    loss           : -1541.0473540683963\n",
      "    ess            : 3.7748642012758076\n",
      "    log_marginal   : 1541.1770388045402\n",
      "    val_loss       : -1540.061258951823\n",
      "    val_ess        : 3.7841989994049072\n",
      "    val_log_marginal: 1540.179707845052\n",
      "Train Epoch: 1583 [0/54000 (0%)] Loss: -1541.501587\n",
      "Train Epoch: 1583 [32768/54000 (61%)] Loss: -1542.403687\n",
      "    epoch          : 1583\n",
      "    loss           : -1541.172478441922\n",
      "    ess            : 3.773410977057691\n",
      "    log_marginal   : 1541.306942345961\n",
      "    val_loss       : -1540.2891031901042\n",
      "    val_ess        : 3.782468795776367\n",
      "    val_log_marginal: 1540.4217122395833\n",
      "Train Epoch: 1584 [0/54000 (0%)] Loss: -1543.736328\n",
      "Train Epoch: 1584 [32768/54000 (61%)] Loss: -1541.146729\n",
      "    epoch          : 1584\n",
      "    loss           : -1541.0985245614681\n",
      "    ess            : 3.7744667485075176\n",
      "    log_marginal   : 1541.234884010171\n",
      "    val_loss       : -1540.440205891927\n",
      "    val_ess        : 3.768406391143799\n",
      "    val_log_marginal: 1540.5758056640625\n",
      "Train Epoch: 1585 [0/54000 (0%)] Loss: -1539.762207\n",
      "Train Epoch: 1585 [32768/54000 (61%)] Loss: -1538.893555\n",
      "    epoch          : 1585\n",
      "    loss           : -1540.994686486586\n",
      "    ess            : 3.772630556574408\n",
      "    log_marginal   : 1541.1290743845814\n",
      "    val_loss       : -1540.2405598958333\n",
      "    val_ess        : 3.7767693201700845\n",
      "    val_log_marginal: 1540.3752034505208\n",
      "Train Epoch: 1586 [0/54000 (0%)] Loss: -1545.930908\n",
      "Train Epoch: 1586 [32768/54000 (61%)] Loss: -1539.894531\n",
      "    epoch          : 1586\n",
      "    loss           : -1541.023359190743\n",
      "    ess            : 3.773976537416566\n",
      "    log_marginal   : 1541.152219376474\n",
      "    val_loss       : -1540.2549641927083\n",
      "    val_ess        : 3.773911992708842\n",
      "    val_log_marginal: 1540.3894856770833\n",
      "Train Epoch: 1587 [0/54000 (0%)] Loss: -1544.776611\n",
      "Train Epoch: 1587 [32768/54000 (61%)] Loss: -1541.734131\n",
      "    epoch          : 1587\n",
      "    loss           : -1541.0608209573998\n",
      "    ess            : 3.772848169758635\n",
      "    log_marginal   : 1541.1916480874115\n",
      "    val_loss       : -1540.5787353515625\n",
      "    val_ess        : 3.774075905481974\n",
      "    val_log_marginal: 1540.7117919921875\n",
      "Train Epoch: 1588 [0/54000 (0%)] Loss: -1542.458496\n",
      "Train Epoch: 1588 [32768/54000 (61%)] Loss: -1545.289795\n",
      "    epoch          : 1588\n",
      "    loss           : -1541.1508719966096\n",
      "    ess            : 3.775820943544496\n",
      "    log_marginal   : 1541.279780549823\n",
      "    val_loss       : -1540.3263142903645\n",
      "    val_ess        : 3.7724177837371826\n",
      "    val_log_marginal: 1540.4578043619792\n",
      "Train Epoch: 1589 [0/54000 (0%)] Loss: -1540.787354\n",
      "Train Epoch: 1589 [32768/54000 (61%)] Loss: -1539.174072\n",
      "    epoch          : 1589\n",
      "    loss           : -1541.0590797280365\n",
      "    ess            : 3.7715777091260225\n",
      "    log_marginal   : 1541.1917471255897\n",
      "    val_loss       : -1540.844502766927\n",
      "    val_ess        : 3.772568464279175\n",
      "    val_log_marginal: 1540.975077311198\n",
      "Train Epoch: 1590 [0/54000 (0%)] Loss: -1546.492676\n",
      "Train Epoch: 1590 [32768/54000 (61%)] Loss: -1544.141357\n",
      "    epoch          : 1590\n",
      "    loss           : -1541.0458846182194\n",
      "    ess            : 3.774974134733092\n",
      "    log_marginal   : 1541.1749682156544\n",
      "    val_loss       : -1540.4117431640625\n",
      "    val_ess        : 3.7770562966664634\n",
      "    val_log_marginal: 1540.539794921875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1590.pth ...\n",
      "Train Epoch: 1591 [0/54000 (0%)] Loss: -1542.354736\n",
      "Train Epoch: 1591 [32768/54000 (61%)] Loss: -1542.332275\n",
      "    epoch          : 1591\n",
      "    loss           : -1541.1451669369103\n",
      "    ess            : 3.7744116333295716\n",
      "    log_marginal   : 1541.2776040131191\n",
      "    val_loss       : -1540.3973185221355\n",
      "    val_ess        : 3.7765905459721885\n",
      "    val_log_marginal: 1540.5196126302083\n",
      "Train Epoch: 1592 [0/54000 (0%)] Loss: -1541.485352\n",
      "Train Epoch: 1592 [32768/54000 (61%)] Loss: -1543.606812\n",
      "    epoch          : 1592\n",
      "    loss           : -1541.2535930129718\n",
      "    ess            : 3.7748787987906978\n",
      "    log_marginal   : 1541.384380988355\n",
      "    val_loss       : -1541.040506998698\n",
      "    val_ess        : 3.778180400530497\n",
      "    val_log_marginal: 1541.1714884440105\n",
      "Train Epoch: 1593 [0/54000 (0%)] Loss: -1539.620850\n",
      "Train Epoch: 1593 [32768/54000 (61%)] Loss: -1540.057617\n",
      "    epoch          : 1593\n",
      "    loss           : -1541.23988658977\n",
      "    ess            : 3.772678735121241\n",
      "    log_marginal   : 1541.370365934552\n",
      "    val_loss       : -1540.7586873372395\n",
      "    val_ess        : 3.7792349259058633\n",
      "    val_log_marginal: 1540.8853759765625\n",
      "Train Epoch: 1594 [0/54000 (0%)] Loss: -1539.897461\n",
      "Train Epoch: 1594 [32768/54000 (61%)] Loss: -1543.155273\n",
      "    epoch          : 1594\n",
      "    loss           : -1541.317647682046\n",
      "    ess            : 3.776276228562841\n",
      "    log_marginal   : 1541.4471090064858\n",
      "    val_loss       : -1540.6715291341145\n",
      "    val_ess        : 3.754872719446818\n",
      "    val_log_marginal: 1540.8158162434895\n",
      "Train Epoch: 1595 [0/54000 (0%)] Loss: -1540.369385\n",
      "Train Epoch: 1595 [32768/54000 (61%)] Loss: -1540.628906\n",
      "    epoch          : 1595\n",
      "    loss           : -1541.4623839180424\n",
      "    ess            : 3.770921180833061\n",
      "    log_marginal   : 1541.5949384581368\n",
      "    val_loss       : -1540.8250325520833\n",
      "    val_ess        : 3.7816867431004844\n",
      "    val_log_marginal: 1540.9480590820312\n",
      "Train Epoch: 1596 [0/54000 (0%)] Loss: -1541.812988\n",
      "Train Epoch: 1596 [32768/54000 (61%)] Loss: -1537.176758\n",
      "    epoch          : 1596\n",
      "    loss           : -1541.3882480837265\n",
      "    ess            : 3.7712857678251446\n",
      "    log_marginal   : 1541.5215949292453\n",
      "    val_loss       : -1540.388448079427\n",
      "    val_ess        : 3.775747060775757\n",
      "    val_log_marginal: 1540.5193481445312\n",
      "Train Epoch: 1597 [0/54000 (0%)] Loss: -1541.184082\n",
      "Train Epoch: 1597 [32768/54000 (61%)] Loss: -1542.372559\n",
      "    epoch          : 1597\n",
      "    loss           : -1541.3210771668632\n",
      "    ess            : 3.7759441609652535\n",
      "    log_marginal   : 1541.4513423127948\n",
      "    val_loss       : -1540.7533772786458\n",
      "    val_ess        : 3.7792550325393677\n",
      "    val_log_marginal: 1540.886250813802\n",
      "Train Epoch: 1598 [0/54000 (0%)] Loss: -1542.180176\n",
      "Train Epoch: 1598 [32768/54000 (61%)] Loss: -1538.213135\n",
      "    epoch          : 1598\n",
      "    loss           : -1541.350528357164\n",
      "    ess            : 3.773176422658956\n",
      "    log_marginal   : 1541.4820418447819\n",
      "    val_loss       : -1540.7435099283855\n",
      "    val_ess        : 3.783639113108317\n",
      "    val_log_marginal: 1540.8619995117188\n",
      "Train Epoch: 1599 [0/54000 (0%)] Loss: -1541.096680\n",
      "Train Epoch: 1599 [32768/54000 (61%)] Loss: -1536.992432\n",
      "    epoch          : 1599\n",
      "    loss           : -1541.2849996314858\n",
      "    ess            : 3.778983323079235\n",
      "    log_marginal   : 1541.4099190190154\n",
      "    val_loss       : -1540.9703776041667\n",
      "    val_ess        : 3.772847294807434\n",
      "    val_log_marginal: 1541.105204264323\n",
      "Train Epoch: 1600 [0/54000 (0%)] Loss: -1540.276611\n",
      "Train Epoch: 1600 [32768/54000 (61%)] Loss: -1541.832031\n",
      "    epoch          : 1600\n",
      "    loss           : -1541.3666531544811\n",
      "    ess            : 3.776245616516977\n",
      "    log_marginal   : 1541.494831589033\n",
      "    val_loss       : -1540.6159261067708\n",
      "    val_ess        : 3.7750882307688394\n",
      "    val_log_marginal: 1540.7445882161458\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1600.pth ...\n",
      "Train Epoch: 1601 [0/54000 (0%)] Loss: -1540.546387\n",
      "Train Epoch: 1601 [32768/54000 (61%)] Loss: -1541.430664\n",
      "    epoch          : 1601\n",
      "    loss           : -1541.3545474646226\n",
      "    ess            : 3.772910329530824\n",
      "    log_marginal   : 1541.4901790978774\n",
      "    val_loss       : -1540.5909830729167\n",
      "    val_ess        : 3.7699689467748008\n",
      "    val_log_marginal: 1540.7129923502605\n",
      "Train Epoch: 1602 [0/54000 (0%)] Loss: -1540.222412\n",
      "Train Epoch: 1602 [32768/54000 (61%)] Loss: -1537.279419\n",
      "    epoch          : 1602\n",
      "    loss           : -1541.3419880417157\n",
      "    ess            : 3.7740738346891582\n",
      "    log_marginal   : 1541.4723199808373\n",
      "    val_loss       : -1541.0648396809895\n",
      "    val_ess        : 3.7899048725763955\n",
      "    val_log_marginal: 1541.188700358073\n",
      "Train Epoch: 1603 [0/54000 (0%)] Loss: -1547.153564\n",
      "Train Epoch: 1603 [32768/54000 (61%)] Loss: -1541.132568\n",
      "    epoch          : 1603\n",
      "    loss           : -1541.2617026275059\n",
      "    ess            : 3.7811406198537574\n",
      "    log_marginal   : 1541.3889643831073\n",
      "    val_loss       : -1540.5741373697917\n",
      "    val_ess        : 3.7651988665262857\n",
      "    val_log_marginal: 1540.7147827148438\n",
      "Train Epoch: 1604 [0/54000 (0%)] Loss: -1539.810791\n",
      "Train Epoch: 1604 [32768/54000 (61%)] Loss: -1541.197266\n",
      "    epoch          : 1604\n",
      "    loss           : -1541.3144277896522\n",
      "    ess            : 3.7728456731112496\n",
      "    log_marginal   : 1541.447832215507\n",
      "    val_loss       : -1540.7040608723958\n",
      "    val_ess        : 3.7771934270858765\n",
      "    val_log_marginal: 1540.837381998698\n",
      "Train Epoch: 1605 [0/54000 (0%)] Loss: -1542.477051\n",
      "Train Epoch: 1605 [32768/54000 (61%)] Loss: -1540.673340\n",
      "    epoch          : 1605\n",
      "    loss           : -1541.509012474204\n",
      "    ess            : 3.7746273301682383\n",
      "    log_marginal   : 1541.6405950582252\n",
      "    val_loss       : -1540.8864339192708\n",
      "    val_ess        : 3.7697771787643433\n",
      "    val_log_marginal: 1541.0135701497395\n",
      "Train Epoch: 1606 [0/54000 (0%)] Loss: -1539.348145\n",
      "Train Epoch: 1606 [32768/54000 (61%)] Loss: -1542.909180\n",
      "    epoch          : 1606\n",
      "    loss           : -1541.5189784787735\n",
      "    ess            : 3.7753667336589887\n",
      "    log_marginal   : 1541.6462793890034\n",
      "    val_loss       : -1540.8638305664062\n",
      "    val_ess        : 3.7845048904418945\n",
      "    val_log_marginal: 1540.9920247395833\n",
      "Train Epoch: 1607 [0/54000 (0%)] Loss: -1542.097412\n",
      "Train Epoch: 1607 [32768/54000 (61%)] Loss: -1545.356567\n",
      "    epoch          : 1607\n",
      "    loss           : -1541.487507370283\n",
      "    ess            : 3.7759993976017214\n",
      "    log_marginal   : 1541.6184450545402\n",
      "    val_loss       : -1540.9185791015625\n",
      "    val_ess        : 3.788088043530782\n",
      "    val_log_marginal: 1541.036885579427\n",
      "Train Epoch: 1608 [0/54000 (0%)] Loss: -1542.370117\n",
      "Train Epoch: 1608 [32768/54000 (61%)] Loss: -1538.216187\n",
      "    epoch          : 1608\n",
      "    loss           : -1541.4150574882076\n",
      "    ess            : 3.774083155506062\n",
      "    log_marginal   : 1541.5483145084022\n",
      "    val_loss       : -1540.857157389323\n",
      "    val_ess        : 3.7745055754979453\n",
      "    val_log_marginal: 1540.9939575195312\n",
      "Train Epoch: 1609 [0/54000 (0%)] Loss: -1540.889648\n",
      "Train Epoch: 1609 [32768/54000 (61%)] Loss: -1536.390381\n",
      "    epoch          : 1609\n",
      "    loss           : -1541.449826798349\n",
      "    ess            : 3.775424008099538\n",
      "    log_marginal   : 1541.57777721477\n",
      "    val_loss       : -1541.0248413085938\n",
      "    val_ess        : 3.770694891611735\n",
      "    val_log_marginal: 1541.1572672526042\n",
      "Train Epoch: 1610 [0/54000 (0%)] Loss: -1542.058105\n",
      "Train Epoch: 1610 [32768/54000 (61%)] Loss: -1539.895264\n",
      "    epoch          : 1610\n",
      "    loss           : -1541.6400031323703\n",
      "    ess            : 3.7761605100811653\n",
      "    log_marginal   : 1541.7685546875\n",
      "    val_loss       : -1540.6930135091145\n",
      "    val_ess        : 3.789276361465454\n",
      "    val_log_marginal: 1540.8119506835938\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1610.pth ...\n",
      "Train Epoch: 1611 [0/54000 (0%)] Loss: -1542.201660\n",
      "Train Epoch: 1611 [32768/54000 (61%)] Loss: -1538.759766\n",
      "    epoch          : 1611\n",
      "    loss           : -1541.5927734375\n",
      "    ess            : 3.778217023273684\n",
      "    log_marginal   : 1541.7186578714623\n",
      "    val_loss       : -1540.652567545573\n",
      "    val_ess        : 3.7850263913472495\n",
      "    val_log_marginal: 1540.7850952148438\n",
      "Train Epoch: 1612 [0/54000 (0%)] Loss: -1542.493774\n",
      "Train Epoch: 1612 [32768/54000 (61%)] Loss: -1541.015259\n",
      "    epoch          : 1612\n",
      "    loss           : -1541.6151445496757\n",
      "    ess            : 3.775190240931961\n",
      "    log_marginal   : 1541.7455824366157\n",
      "    val_loss       : -1540.6197713216145\n",
      "    val_ess        : 3.7824467420578003\n",
      "    val_log_marginal: 1540.7449747721355\n",
      "Train Epoch: 1613 [0/54000 (0%)] Loss: -1544.303711\n",
      "Train Epoch: 1613 [32768/54000 (61%)] Loss: -1542.106445\n",
      "    epoch          : 1613\n",
      "    loss           : -1541.8538311652417\n",
      "    ess            : 3.7789046494465954\n",
      "    log_marginal   : 1541.9805424528302\n",
      "    val_loss       : -1540.9863891601562\n",
      "    val_ess        : 3.774925390879313\n",
      "    val_log_marginal: 1541.116923014323\n",
      "Train Epoch: 1614 [0/54000 (0%)] Loss: -1542.457764\n",
      "Train Epoch: 1614 [32768/54000 (61%)] Loss: -1539.386230\n",
      "    epoch          : 1614\n",
      "    loss           : -1541.7409230358196\n",
      "    ess            : 3.773494149154087\n",
      "    log_marginal   : 1541.8716672501473\n",
      "    val_loss       : -1540.7926839192708\n",
      "    val_ess        : 3.774529298146566\n",
      "    val_log_marginal: 1540.9161783854167\n",
      "Train Epoch: 1615 [0/54000 (0%)] Loss: -1540.290527\n",
      "Train Epoch: 1615 [32768/54000 (61%)] Loss: -1542.021851\n",
      "    epoch          : 1615\n",
      "    loss           : -1541.7751695165093\n",
      "    ess            : 3.774340571097608\n",
      "    log_marginal   : 1541.907247291421\n",
      "    val_loss       : -1540.8357543945312\n",
      "    val_ess        : 3.7673344214757285\n",
      "    val_log_marginal: 1540.978271484375\n",
      "Train Epoch: 1616 [0/54000 (0%)] Loss: -1542.630249\n",
      "Train Epoch: 1616 [32768/54000 (61%)] Loss: -1543.142700\n",
      "    epoch          : 1616\n",
      "    loss           : -1541.7069967017983\n",
      "    ess            : 3.77198721777718\n",
      "    log_marginal   : 1541.83935546875\n",
      "    val_loss       : -1540.9132486979167\n",
      "    val_ess        : 3.7665755351384482\n",
      "    val_log_marginal: 1541.0462239583333\n",
      "Train Epoch: 1617 [0/54000 (0%)] Loss: -1543.179565\n",
      "Train Epoch: 1617 [32768/54000 (61%)] Loss: -1541.529053\n",
      "    epoch          : 1617\n",
      "    loss           : -1541.7332303029186\n",
      "    ess            : 3.7725022244003585\n",
      "    log_marginal   : 1541.8625119767098\n",
      "    val_loss       : -1541.0905354817708\n",
      "    val_ess        : 3.7798388401667276\n",
      "    val_log_marginal: 1541.2134399414062\n",
      "Train Epoch: 1618 [0/54000 (0%)] Loss: -1544.716919\n",
      "Train Epoch: 1618 [32768/54000 (61%)] Loss: -1541.961548\n",
      "    epoch          : 1618\n",
      "    loss           : -1541.8134512271522\n",
      "    ess            : 3.7746906955287143\n",
      "    log_marginal   : 1541.9423828125\n",
      "    val_loss       : -1541.0779825846355\n",
      "    val_ess        : 3.7792017062505088\n",
      "    val_log_marginal: 1541.2102457682292\n",
      "Train Epoch: 1619 [0/54000 (0%)] Loss: -1539.802368\n",
      "Train Epoch: 1619 [32768/54000 (61%)] Loss: -1543.385010\n",
      "    epoch          : 1619\n",
      "    loss           : -1541.7724724535672\n",
      "    ess            : 3.775055300514653\n",
      "    log_marginal   : 1541.9050154775944\n",
      "    val_loss       : -1541.0408528645833\n",
      "    val_ess        : 3.77373739083608\n",
      "    val_log_marginal: 1541.1680704752605\n",
      "Train Epoch: 1620 [0/54000 (0%)] Loss: -1544.290771\n",
      "Train Epoch: 1620 [32768/54000 (61%)] Loss: -1536.958618\n",
      "    epoch          : 1620\n",
      "    loss           : -1541.860040628685\n",
      "    ess            : 3.774292122642949\n",
      "    log_marginal   : 1541.9892416900059\n",
      "    val_loss       : -1541.2668863932292\n",
      "    val_ess        : 3.783223350842794\n",
      "    val_log_marginal: 1541.39111328125\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1620.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1621 [0/54000 (0%)] Loss: -1541.625732\n",
      "Train Epoch: 1621 [32768/54000 (61%)] Loss: -1539.287964\n",
      "    epoch          : 1621\n",
      "    loss           : -1541.9052642246463\n",
      "    ess            : 3.7753415242680965\n",
      "    log_marginal   : 1542.0385350641216\n",
      "    val_loss       : -1541.0352986653645\n",
      "    val_ess        : 3.769232193628947\n",
      "    val_log_marginal: 1541.1711832682292\n",
      "Train Epoch: 1622 [0/54000 (0%)] Loss: -1543.919922\n",
      "Train Epoch: 1622 [32768/54000 (61%)] Loss: -1541.460938\n",
      "    epoch          : 1622\n",
      "    loss           : -1541.9272023326946\n",
      "    ess            : 3.7727227166013897\n",
      "    log_marginal   : 1542.0582782097583\n",
      "    val_loss       : -1540.9378865559895\n",
      "    val_ess        : 3.7646755377451577\n",
      "    val_log_marginal: 1541.0771484375\n",
      "Train Epoch: 1623 [0/54000 (0%)] Loss: -1538.862671\n",
      "Train Epoch: 1623 [32768/54000 (61%)] Loss: -1540.012573\n",
      "    epoch          : 1623\n",
      "    loss           : -1541.963192345961\n",
      "    ess            : 3.7770034232229555\n",
      "    log_marginal   : 1542.0929208431603\n",
      "    val_loss       : -1541.0023193359375\n",
      "    val_ess        : 3.7738104263941445\n",
      "    val_log_marginal: 1541.135762532552\n",
      "Train Epoch: 1624 [0/54000 (0%)] Loss: -1542.074219\n",
      "Train Epoch: 1624 [32768/54000 (61%)] Loss: -1540.567383\n",
      "    epoch          : 1624\n",
      "    loss           : -1541.9981228810436\n",
      "    ess            : 3.7745059886068666\n",
      "    log_marginal   : 1542.1333860001473\n",
      "    val_loss       : -1541.125264485677\n",
      "    val_ess        : 3.796283006668091\n",
      "    val_log_marginal: 1541.2440388997395\n",
      "Train Epoch: 1625 [0/54000 (0%)] Loss: -1544.252563\n",
      "Train Epoch: 1625 [32768/54000 (61%)] Loss: -1543.137451\n",
      "    epoch          : 1625\n",
      "    loss           : -1542.0905738686615\n",
      "    ess            : 3.7743730050212934\n",
      "    log_marginal   : 1542.2216474425118\n",
      "    val_loss       : -1540.9600219726562\n",
      "    val_ess        : 3.7623751958211265\n",
      "    val_log_marginal: 1541.1018676757812\n",
      "Train Epoch: 1626 [0/54000 (0%)] Loss: -1541.703125\n",
      "Train Epoch: 1626 [32768/54000 (61%)] Loss: -1541.130859\n",
      "    epoch          : 1626\n",
      "    loss           : -1542.019411482901\n",
      "    ess            : 3.7730460076961876\n",
      "    log_marginal   : 1542.1534930535083\n",
      "    val_loss       : -1541.0718587239583\n",
      "    val_ess        : 3.7767693201700845\n",
      "    val_log_marginal: 1541.2033284505208\n",
      "Train Epoch: 1627 [0/54000 (0%)] Loss: -1544.420898\n",
      "Train Epoch: 1627 [32768/54000 (61%)] Loss: -1539.961182\n",
      "    epoch          : 1627\n",
      "    loss           : -1541.9239617113797\n",
      "    ess            : 3.777508443256594\n",
      "    log_marginal   : 1542.0542591022995\n",
      "    val_loss       : -1541.0628255208333\n",
      "    val_ess        : 3.7684494654337564\n",
      "    val_log_marginal: 1541.198710123698\n",
      "Train Epoch: 1628 [0/54000 (0%)] Loss: -1543.051880\n",
      "Train Epoch: 1628 [32768/54000 (61%)] Loss: -1543.117432\n",
      "    epoch          : 1628\n",
      "    loss           : -1541.941426978921\n",
      "    ess            : 3.7726387167876623\n",
      "    log_marginal   : 1542.0759599793632\n",
      "    val_loss       : -1541.0407307942708\n",
      "    val_ess        : 3.7766640186309814\n",
      "    val_log_marginal: 1541.1748046875\n",
      "Train Epoch: 1629 [0/54000 (0%)] Loss: -1543.745972\n",
      "Train Epoch: 1629 [32768/54000 (61%)] Loss: -1543.809814\n",
      "    epoch          : 1629\n",
      "    loss           : -1541.9119642725532\n",
      "    ess            : 3.7741542762180544\n",
      "    log_marginal   : 1542.0435307340802\n",
      "    val_loss       : -1540.8753051757812\n",
      "    val_ess        : 3.782433112462362\n",
      "    val_log_marginal: 1540.9913940429688\n",
      "Train Epoch: 1630 [0/54000 (0%)] Loss: -1541.020020\n",
      "Train Epoch: 1630 [32768/54000 (61%)] Loss: -1545.425781\n",
      "    epoch          : 1630\n",
      "    loss           : -1542.0626312831662\n",
      "    ess            : 3.7750627004875326\n",
      "    log_marginal   : 1542.1941678029186\n",
      "    val_loss       : -1541.0078938802083\n",
      "    val_ess        : 3.774615923563639\n",
      "    val_log_marginal: 1541.1413981119792\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1630.pth ...\n",
      "Train Epoch: 1631 [0/54000 (0%)] Loss: -1540.638062\n",
      "Train Epoch: 1631 [32768/54000 (61%)] Loss: -1542.621094\n",
      "    epoch          : 1631\n",
      "    loss           : -1542.0263948260613\n",
      "    ess            : 3.774038274333162\n",
      "    log_marginal   : 1542.1565747530956\n",
      "    val_loss       : -1541.3425903320312\n",
      "    val_ess        : 3.78446892897288\n",
      "    val_log_marginal: 1541.468770345052\n",
      "Train Epoch: 1632 [0/54000 (0%)] Loss: -1544.203857\n",
      "Train Epoch: 1632 [32768/54000 (61%)] Loss: -1540.656738\n",
      "    epoch          : 1632\n",
      "    loss           : -1541.989543410967\n",
      "    ess            : 3.7804591070930913\n",
      "    log_marginal   : 1542.1181778817806\n",
      "    val_loss       : -1541.0546264648438\n",
      "    val_ess        : 3.7789376974105835\n",
      "    val_log_marginal: 1541.1815592447917\n",
      "Train Epoch: 1633 [0/54000 (0%)] Loss: -1544.516846\n",
      "Train Epoch: 1633 [32768/54000 (61%)] Loss: -1543.027100\n",
      "    epoch          : 1633\n",
      "    loss           : -1542.031494140625\n",
      "    ess            : 3.7753911378248683\n",
      "    log_marginal   : 1542.162775003685\n",
      "    val_loss       : -1541.2724609375\n",
      "    val_ess        : 3.769496043523153\n",
      "    val_log_marginal: 1541.4130249023438\n",
      "Train Epoch: 1634 [0/54000 (0%)] Loss: -1543.979004\n",
      "Train Epoch: 1634 [32768/54000 (61%)] Loss: -1541.712524\n",
      "    epoch          : 1634\n",
      "    loss           : -1542.005007186026\n",
      "    ess            : 3.774771474442392\n",
      "    log_marginal   : 1542.1329967570755\n",
      "    val_loss       : -1541.5084228515625\n",
      "    val_ess        : 3.777957638104757\n",
      "    val_log_marginal: 1541.6324666341145\n",
      "Train Epoch: 1635 [0/54000 (0%)] Loss: -1542.305664\n",
      "Train Epoch: 1635 [32768/54000 (61%)] Loss: -1540.674805\n",
      "    epoch          : 1635\n",
      "    loss           : -1542.103630785672\n",
      "    ess            : 3.7743820514319077\n",
      "    log_marginal   : 1542.2359043337265\n",
      "    val_loss       : -1541.4657185872395\n",
      "    val_ess        : 3.78813103834788\n",
      "    val_log_marginal: 1541.5785319010417\n",
      "Train Epoch: 1636 [0/54000 (0%)] Loss: -1541.968384\n",
      "Train Epoch: 1636 [32768/54000 (61%)] Loss: -1544.247070\n",
      "    epoch          : 1636\n",
      "    loss           : -1542.033364349941\n",
      "    ess            : 3.7762828592984183\n",
      "    log_marginal   : 1542.163272497789\n",
      "    val_loss       : -1540.877705891927\n",
      "    val_ess        : 3.7766922314961753\n",
      "    val_log_marginal: 1541.004903157552\n",
      "Train Epoch: 1637 [0/54000 (0%)] Loss: -1543.182129\n",
      "Train Epoch: 1637 [32768/54000 (61%)] Loss: -1543.687256\n",
      "    epoch          : 1637\n",
      "    loss           : -1542.1533272221404\n",
      "    ess            : 3.7759594692374177\n",
      "    log_marginal   : 1542.2830948739681\n",
      "    val_loss       : -1541.5366821289062\n",
      "    val_ess        : 3.7780752579371133\n",
      "    val_log_marginal: 1541.668721516927\n",
      "Train Epoch: 1638 [0/54000 (0%)] Loss: -1541.180176\n",
      "Train Epoch: 1638 [32768/54000 (61%)] Loss: -1540.890381\n",
      "    epoch          : 1638\n",
      "    loss           : -1542.1289523142689\n",
      "    ess            : 3.7760708556984954\n",
      "    log_marginal   : 1542.259599793632\n",
      "    val_loss       : -1541.5198567708333\n",
      "    val_ess        : 3.780933380126953\n",
      "    val_log_marginal: 1541.64306640625\n",
      "Train Epoch: 1639 [0/54000 (0%)] Loss: -1540.199707\n",
      "Train Epoch: 1639 [32768/54000 (61%)] Loss: -1541.324341\n",
      "    epoch          : 1639\n",
      "    loss           : -1542.0948970002948\n",
      "    ess            : 3.7751488550653995\n",
      "    log_marginal   : 1542.2262308372642\n",
      "    val_loss       : -1541.7377319335938\n",
      "    val_ess        : 3.791629513104757\n",
      "    val_log_marginal: 1541.860595703125\n",
      "Train Epoch: 1640 [0/54000 (0%)] Loss: -1540.912354\n",
      "Train Epoch: 1640 [32768/54000 (61%)] Loss: -1541.710815\n",
      "    epoch          : 1640\n",
      "    loss           : -1542.0784543595223\n",
      "    ess            : 3.776326255978278\n",
      "    log_marginal   : 1542.2108614939564\n",
      "    val_loss       : -1541.3072509765625\n",
      "    val_ess        : 3.775945464769999\n",
      "    val_log_marginal: 1541.433837890625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1640.pth ...\n",
      "Train Epoch: 1641 [0/54000 (0%)] Loss: -1541.565308\n",
      "Train Epoch: 1641 [32768/54000 (61%)] Loss: -1542.965210\n",
      "    epoch          : 1641\n",
      "    loss           : -1542.1707303029186\n",
      "    ess            : 3.772001855778244\n",
      "    log_marginal   : 1542.3060625184257\n",
      "    val_loss       : -1541.680399576823\n",
      "    val_ess        : 3.7713290055592856\n",
      "    val_log_marginal: 1541.8186645507812\n",
      "Train Epoch: 1642 [0/54000 (0%)] Loss: -1540.508057\n",
      "Train Epoch: 1642 [32768/54000 (61%)] Loss: -1542.639648\n",
      "    epoch          : 1642\n",
      "    loss           : -1542.184346900796\n",
      "    ess            : 3.7749325014510244\n",
      "    log_marginal   : 1542.3146535045696\n",
      "    val_loss       : -1541.3358968098958\n",
      "    val_ess        : 3.7811120748519897\n",
      "    val_log_marginal: 1541.456563313802\n",
      "Train Epoch: 1643 [0/54000 (0%)] Loss: -1541.817383\n",
      "Train Epoch: 1643 [32768/54000 (61%)] Loss: -1543.452759\n",
      "    epoch          : 1643\n",
      "    loss           : -1542.2190701466686\n",
      "    ess            : 3.7789666607694805\n",
      "    log_marginal   : 1542.3448946970814\n",
      "    val_loss       : -1541.2979939778645\n",
      "    val_ess        : 3.7695587873458862\n",
      "    val_log_marginal: 1541.4265543619792\n",
      "Train Epoch: 1644 [0/54000 (0%)] Loss: -1543.517212\n",
      "Train Epoch: 1644 [32768/54000 (61%)] Loss: -1539.739136\n",
      "    epoch          : 1644\n",
      "    loss           : -1542.2481965838738\n",
      "    ess            : 3.777909368838904\n",
      "    log_marginal   : 1542.3779849646226\n",
      "    val_loss       : -1541.619873046875\n",
      "    val_ess        : 3.784599939982096\n",
      "    val_log_marginal: 1541.7384033203125\n",
      "Train Epoch: 1645 [0/54000 (0%)] Loss: -1544.611694\n",
      "Train Epoch: 1645 [32768/54000 (61%)] Loss: -1540.386230\n",
      "    epoch          : 1645\n",
      "    loss           : -1542.3183363428657\n",
      "    ess            : 3.7728818857444906\n",
      "    log_marginal   : 1542.4506858969635\n",
      "    val_loss       : -1542.0559692382812\n",
      "    val_ess        : 3.774018923441569\n",
      "    val_log_marginal: 1542.186055501302\n",
      "Train Epoch: 1646 [0/54000 (0%)] Loss: -1540.977539\n",
      "Train Epoch: 1646 [32768/54000 (61%)] Loss: -1543.005371\n",
      "    epoch          : 1646\n",
      "    loss           : -1542.2468699329304\n",
      "    ess            : 3.7762765839414776\n",
      "    log_marginal   : 1542.3755044037441\n",
      "    val_loss       : -1541.6965942382812\n",
      "    val_ess        : 3.7767961819966636\n",
      "    val_log_marginal: 1541.824442545573\n",
      "Train Epoch: 1647 [0/54000 (0%)] Loss: -1545.537964\n",
      "Train Epoch: 1647 [32768/54000 (61%)] Loss: -1543.058594\n",
      "    epoch          : 1647\n",
      "    loss           : -1542.4012773621757\n",
      "    ess            : 3.7710334399961076\n",
      "    log_marginal   : 1542.5361696639152\n",
      "    val_loss       : -1541.6846923828125\n",
      "    val_ess        : 3.779812534650167\n",
      "    val_log_marginal: 1541.8067423502605\n",
      "Train Epoch: 1648 [0/54000 (0%)] Loss: -1544.643066\n",
      "Train Epoch: 1648 [32768/54000 (61%)] Loss: -1542.070190\n",
      "    epoch          : 1648\n",
      "    loss           : -1542.3394545069282\n",
      "    ess            : 3.776988929172732\n",
      "    log_marginal   : 1542.4680037588444\n",
      "    val_loss       : -1541.7203979492188\n",
      "    val_ess        : 3.7764182090759277\n",
      "    val_log_marginal: 1541.8592325846355\n",
      "Train Epoch: 1649 [0/54000 (0%)] Loss: -1544.515869\n",
      "Train Epoch: 1649 [32768/54000 (61%)] Loss: -1540.451416\n",
      "    epoch          : 1649\n",
      "    loss           : -1542.4228884139152\n",
      "    ess            : 3.7746918021507985\n",
      "    log_marginal   : 1542.5499175449588\n",
      "    val_loss       : -1542.0745849609375\n",
      "    val_ess        : 3.7861937284469604\n",
      "    val_log_marginal: 1542.1929117838542\n",
      "Train Epoch: 1650 [0/54000 (0%)] Loss: -1547.017578\n",
      "Train Epoch: 1650 [32768/54000 (61%)] Loss: -1541.734619\n",
      "    epoch          : 1650\n",
      "    loss           : -1542.3764164762677\n",
      "    ess            : 3.773793836809554\n",
      "    log_marginal   : 1542.5090239902713\n",
      "    val_loss       : -1541.513692220052\n",
      "    val_ess        : 3.757295807202657\n",
      "    val_log_marginal: 1541.6671549479167\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1650.pth ...\n",
      "Train Epoch: 1651 [0/54000 (0%)] Loss: -1545.372559\n",
      "Train Epoch: 1651 [32768/54000 (61%)] Loss: -1543.652100\n",
      "    epoch          : 1651\n",
      "    loss           : -1542.37437122273\n",
      "    ess            : 3.776539532643444\n",
      "    log_marginal   : 1542.5013059220223\n",
      "    val_loss       : -1541.4739786783855\n",
      "    val_ess        : 3.7655756870905557\n",
      "    val_log_marginal: 1541.615478515625\n",
      "Train Epoch: 1652 [0/54000 (0%)] Loss: -1543.131226\n",
      "Train Epoch: 1652 [32768/54000 (61%)] Loss: -1539.685913\n",
      "    epoch          : 1652\n",
      "    loss           : -1542.3355758954895\n",
      "    ess            : 3.7763149738311768\n",
      "    log_marginal   : 1542.466739294664\n",
      "    val_loss       : -1541.452168782552\n",
      "    val_ess        : 3.7697816292444863\n",
      "    val_log_marginal: 1541.585469563802\n",
      "Train Epoch: 1653 [0/54000 (0%)] Loss: -1544.851318\n",
      "Train Epoch: 1653 [32768/54000 (61%)] Loss: -1544.045654\n",
      "    epoch          : 1653\n",
      "    loss           : -1542.3976682267098\n",
      "    ess            : 3.7721700803288876\n",
      "    log_marginal   : 1542.5333620467277\n",
      "    val_loss       : -1541.6634928385417\n",
      "    val_ess        : 3.779939333597819\n",
      "    val_log_marginal: 1541.8038126627605\n",
      "Train Epoch: 1654 [0/54000 (0%)] Loss: -1545.678711\n",
      "Train Epoch: 1654 [32768/54000 (61%)] Loss: -1539.882080\n",
      "    epoch          : 1654\n",
      "    loss           : -1542.527095002948\n",
      "    ess            : 3.777276354015998\n",
      "    log_marginal   : 1542.654416642099\n",
      "    val_loss       : -1541.8436686197917\n",
      "    val_ess        : 3.7900540431340537\n",
      "    val_log_marginal: 1541.9706624348958\n",
      "Train Epoch: 1655 [0/54000 (0%)] Loss: -1543.745361\n",
      "Train Epoch: 1655 [32768/54000 (61%)] Loss: -1544.344116\n",
      "    epoch          : 1655\n",
      "    loss           : -1542.5441019310142\n",
      "    ess            : 3.7759925329460287\n",
      "    log_marginal   : 1542.6772138487618\n",
      "    val_loss       : -1541.6278686523438\n",
      "    val_ess        : 3.767321070035299\n",
      "    val_log_marginal: 1541.7671508789062\n",
      "Train Epoch: 1656 [0/54000 (0%)] Loss: -1543.234863\n",
      "Train Epoch: 1656 [32768/54000 (61%)] Loss: -1543.443359\n",
      "    epoch          : 1656\n",
      "    loss           : -1542.6714258733784\n",
      "    ess            : 3.774827975147175\n",
      "    log_marginal   : 1542.806131614829\n",
      "    val_loss       : -1542.0345052083333\n",
      "    val_ess        : 3.7895463705062866\n",
      "    val_log_marginal: 1542.1539916992188\n",
      "Train Epoch: 1657 [0/54000 (0%)] Loss: -1539.995361\n",
      "Train Epoch: 1657 [32768/54000 (61%)] Loss: -1546.244385\n",
      "    epoch          : 1657\n",
      "    loss           : -1542.661782318691\n",
      "    ess            : 3.7759356408748985\n",
      "    log_marginal   : 1542.7906148658608\n",
      "    val_loss       : -1541.7438354492188\n",
      "    val_ess        : 3.7701347271601358\n",
      "    val_log_marginal: 1541.8724975585938\n",
      "Train Epoch: 1658 [0/54000 (0%)] Loss: -1542.822266\n",
      "Train Epoch: 1658 [32768/54000 (61%)] Loss: -1542.351074\n",
      "    epoch          : 1658\n",
      "    loss           : -1542.8427411925118\n",
      "    ess            : 3.7791835586979703\n",
      "    log_marginal   : 1542.971076245578\n",
      "    val_loss       : -1542.2649739583333\n",
      "    val_ess        : 3.7769373655319214\n",
      "    val_log_marginal: 1542.4016520182292\n",
      "Train Epoch: 1659 [0/54000 (0%)] Loss: -1540.351562\n",
      "Train Epoch: 1659 [32768/54000 (61%)] Loss: -1540.207275\n",
      "    epoch          : 1659\n",
      "    loss           : -1542.7413076724647\n",
      "    ess            : 3.7777548646027186\n",
      "    log_marginal   : 1542.8722015956662\n",
      "    val_loss       : -1542.0045166015625\n",
      "    val_ess        : 3.772374749183655\n",
      "    val_log_marginal: 1542.131327311198\n",
      "Train Epoch: 1660 [0/54000 (0%)] Loss: -1546.313721\n",
      "Train Epoch: 1660 [32768/54000 (61%)] Loss: -1542.814697\n",
      "    epoch          : 1660\n",
      "    loss           : -1542.686585624263\n",
      "    ess            : 3.7729762905048876\n",
      "    log_marginal   : 1542.8193428471404\n",
      "    val_loss       : -1541.9605509440105\n",
      "    val_ess        : 3.7761552333831787\n",
      "    val_log_marginal: 1542.0855102539062\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1660.pth ...\n",
      "Train Epoch: 1661 [0/54000 (0%)] Loss: -1541.555664\n",
      "Train Epoch: 1661 [32768/54000 (61%)] Loss: -1541.562256\n",
      "    epoch          : 1661\n",
      "    loss           : -1542.7473236659787\n",
      "    ess            : 3.7762946092857503\n",
      "    log_marginal   : 1542.878500884434\n",
      "    val_loss       : -1542.115234375\n",
      "    val_ess        : 3.7758565743764243\n",
      "    val_log_marginal: 1542.2446899414062\n",
      "Train Epoch: 1662 [0/54000 (0%)] Loss: -1540.331055\n",
      "Train Epoch: 1662 [32768/54000 (61%)] Loss: -1543.569336\n",
      "    epoch          : 1662\n",
      "    loss           : -1542.7994269604953\n",
      "    ess            : 3.770082172357811\n",
      "    log_marginal   : 1542.9321818801593\n",
      "    val_loss       : -1541.8973592122395\n",
      "    val_ess        : 3.792749842007955\n",
      "    val_log_marginal: 1542.0079142252605\n",
      "Train Epoch: 1663 [0/54000 (0%)] Loss: -1542.338623\n",
      "Train Epoch: 1663 [32768/54000 (61%)] Loss: -1545.921875\n",
      "    epoch          : 1663\n",
      "    loss           : -1542.851177863355\n",
      "    ess            : 3.773777223982901\n",
      "    log_marginal   : 1542.9825485517395\n",
      "    val_loss       : -1542.040771484375\n",
      "    val_ess        : 3.7782180309295654\n",
      "    val_log_marginal: 1542.1705118815105\n",
      "Train Epoch: 1664 [0/54000 (0%)] Loss: -1541.566895\n",
      "Train Epoch: 1664 [32768/54000 (61%)] Loss: -1543.084229\n",
      "    epoch          : 1664\n",
      "    loss           : -1542.782346329599\n",
      "    ess            : 3.7755913689451397\n",
      "    log_marginal   : 1542.9115151459316\n",
      "    val_loss       : -1542.0925903320312\n",
      "    val_ess        : 3.781424959500631\n",
      "    val_log_marginal: 1542.2174275716145\n",
      "Train Epoch: 1665 [0/54000 (0%)] Loss: -1545.832520\n",
      "Train Epoch: 1665 [32768/54000 (61%)] Loss: -1544.662842\n",
      "    epoch          : 1665\n",
      "    loss           : -1542.9496886055424\n",
      "    ess            : 3.782353122279329\n",
      "    log_marginal   : 1543.0770609153892\n",
      "    val_loss       : -1542.131591796875\n",
      "    val_ess        : 3.7685168186823526\n",
      "    val_log_marginal: 1542.2609456380208\n",
      "Train Epoch: 1666 [0/54000 (0%)] Loss: -1542.116333\n",
      "Train Epoch: 1666 [32768/54000 (61%)] Loss: -1541.397339\n",
      "    epoch          : 1666\n",
      "    loss           : -1542.9750585016216\n",
      "    ess            : 3.779816344099225\n",
      "    log_marginal   : 1543.1040730026532\n",
      "    val_loss       : -1541.8310546875\n",
      "    val_ess        : 3.76894478003184\n",
      "    val_log_marginal: 1541.975341796875\n",
      "Train Epoch: 1667 [0/54000 (0%)] Loss: -1547.038574\n",
      "Train Epoch: 1667 [32768/54000 (61%)] Loss: -1542.990967\n",
      "    epoch          : 1667\n",
      "    loss           : -1542.8611392614976\n",
      "    ess            : 3.775762274580182\n",
      "    log_marginal   : 1542.99225429319\n",
      "    val_loss       : -1541.8553059895833\n",
      "    val_ess        : 3.786611557006836\n",
      "    val_log_marginal: 1541.9776407877605\n",
      "Train Epoch: 1668 [0/54000 (0%)] Loss: -1543.124390\n",
      "Train Epoch: 1668 [32768/54000 (61%)] Loss: -1542.209717\n",
      "    epoch          : 1668\n",
      "    loss           : -1542.9569667600235\n",
      "    ess            : 3.7743041875227443\n",
      "    log_marginal   : 1543.0884065448113\n",
      "    val_loss       : -1542.2657267252605\n",
      "    val_ess        : 3.778791586558024\n",
      "    val_log_marginal: 1542.398946126302\n",
      "Train Epoch: 1669 [0/54000 (0%)] Loss: -1542.163086\n",
      "Train Epoch: 1669 [32768/54000 (61%)] Loss: -1542.953369\n",
      "    epoch          : 1669\n",
      "    loss           : -1543.0153094597583\n",
      "    ess            : 3.775342585905543\n",
      "    log_marginal   : 1543.1446279849647\n",
      "    val_loss       : -1542.2932942708333\n",
      "    val_ess        : 3.7832042376200357\n",
      "    val_log_marginal: 1542.4110310872395\n",
      "Train Epoch: 1670 [0/54000 (0%)] Loss: -1542.343872\n",
      "Train Epoch: 1670 [32768/54000 (61%)] Loss: -1544.344360\n",
      "    epoch          : 1670\n",
      "    loss           : -1542.8597366045105\n",
      "    ess            : 3.7712949716819906\n",
      "    log_marginal   : 1542.9913007628243\n",
      "    val_loss       : -1542.457784016927\n",
      "    val_ess        : 3.778401533762614\n",
      "    val_log_marginal: 1542.5832926432292\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1670.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1671 [0/54000 (0%)] Loss: -1542.029907\n",
      "Train Epoch: 1671 [32768/54000 (61%)] Loss: -1544.711914\n",
      "    epoch          : 1671\n",
      "    loss           : -1542.869083044664\n",
      "    ess            : 3.770228570362307\n",
      "    log_marginal   : 1543.00299648069\n",
      "    val_loss       : -1542.223164876302\n",
      "    val_ess        : 3.786484956741333\n",
      "    val_log_marginal: 1542.347391764323\n",
      "Train Epoch: 1672 [0/54000 (0%)] Loss: -1547.277588\n",
      "Train Epoch: 1672 [32768/54000 (61%)] Loss: -1541.019531\n",
      "    epoch          : 1672\n",
      "    loss           : -1542.9983831441627\n",
      "    ess            : 3.778657130475314\n",
      "    log_marginal   : 1543.127545050855\n",
      "    val_loss       : -1542.3895670572917\n",
      "    val_ess        : 3.7691012620925903\n",
      "    val_log_marginal: 1542.5276489257812\n",
      "Train Epoch: 1673 [0/54000 (0%)] Loss: -1542.901733\n",
      "Train Epoch: 1673 [32768/54000 (61%)] Loss: -1544.871948\n",
      "    epoch          : 1673\n",
      "    loss           : -1542.9595072044517\n",
      "    ess            : 3.7791045521790125\n",
      "    log_marginal   : 1543.0908640735554\n",
      "    val_loss       : -1542.2139078776042\n",
      "    val_ess        : 3.7832367420196533\n",
      "    val_log_marginal: 1542.340799967448\n",
      "Train Epoch: 1674 [0/54000 (0%)] Loss: -1543.898193\n",
      "Train Epoch: 1674 [32768/54000 (61%)] Loss: -1541.626465\n",
      "    epoch          : 1674\n",
      "    loss           : -1543.0488396410672\n",
      "    ess            : 3.7762507897502973\n",
      "    log_marginal   : 1543.1779923349056\n",
      "    val_loss       : -1542.0921020507812\n",
      "    val_ess        : 3.776942412058512\n",
      "    val_log_marginal: 1542.2161661783855\n",
      "Train Epoch: 1675 [0/54000 (0%)] Loss: -1542.363525\n",
      "Train Epoch: 1675 [32768/54000 (61%)] Loss: -1544.420166\n",
      "    epoch          : 1675\n",
      "    loss           : -1542.9662095555718\n",
      "    ess            : 3.774917908434598\n",
      "    log_marginal   : 1543.0979994288032\n",
      "    val_loss       : -1541.7762247721355\n",
      "    val_ess        : 3.772850672403971\n",
      "    val_log_marginal: 1541.896240234375\n",
      "Train Epoch: 1676 [0/54000 (0%)] Loss: -1542.209961\n",
      "Train Epoch: 1676 [32768/54000 (61%)] Loss: -1539.316406\n",
      "    epoch          : 1676\n",
      "    loss           : -1543.0628892430718\n",
      "    ess            : 3.7749965820672378\n",
      "    log_marginal   : 1543.1967289762677\n",
      "    val_loss       : -1542.2007446289062\n",
      "    val_ess        : 3.7779422998428345\n",
      "    val_log_marginal: 1542.3232421875\n",
      "Train Epoch: 1677 [0/54000 (0%)] Loss: -1542.825684\n",
      "Train Epoch: 1677 [32768/54000 (61%)] Loss: -1543.874023\n",
      "    epoch          : 1677\n",
      "    loss           : -1542.9918742629718\n",
      "    ess            : 3.7775659741095775\n",
      "    log_marginal   : 1543.1237078972583\n",
      "    val_loss       : -1542.4231567382812\n",
      "    val_ess        : 3.7756837606430054\n",
      "    val_log_marginal: 1542.548828125\n",
      "Train Epoch: 1678 [0/54000 (0%)] Loss: -1542.421875\n",
      "Train Epoch: 1678 [32768/54000 (61%)] Loss: -1542.391479\n",
      "    epoch          : 1678\n",
      "    loss           : -1543.0801840728184\n",
      "    ess            : 3.7776088264753236\n",
      "    log_marginal   : 1543.2098296543338\n",
      "    val_loss       : -1542.3690795898438\n",
      "    val_ess        : 3.7765760819117227\n",
      "    val_log_marginal: 1542.4991251627605\n",
      "Train Epoch: 1679 [0/54000 (0%)] Loss: -1544.552734\n",
      "Train Epoch: 1679 [32768/54000 (61%)] Loss: -1543.183594\n",
      "    epoch          : 1679\n",
      "    loss           : -1543.082648511203\n",
      "    ess            : 3.7723997673898375\n",
      "    log_marginal   : 1543.2137359043338\n",
      "    val_loss       : -1542.291768391927\n",
      "    val_ess        : 3.780159870783488\n",
      "    val_log_marginal: 1542.4193522135417\n",
      "Train Epoch: 1680 [0/54000 (0%)] Loss: -1541.899658\n",
      "Train Epoch: 1680 [32768/54000 (61%)] Loss: -1544.960693\n",
      "    epoch          : 1680\n",
      "    loss           : -1543.317502579599\n",
      "    ess            : 3.7783671640000254\n",
      "    log_marginal   : 1543.4448472508843\n",
      "    val_loss       : -1542.6522013346355\n",
      "    val_ess        : 3.7771430810292563\n",
      "    val_log_marginal: 1542.790995279948\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1680.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1681 [0/54000 (0%)] Loss: -1544.659790\n",
      "Train Epoch: 1681 [32768/54000 (61%)] Loss: -1544.203125\n",
      "    epoch          : 1681\n",
      "    loss           : -1543.418332657724\n",
      "    ess            : 3.775133780713351\n",
      "    log_marginal   : 1543.5490215949292\n",
      "    val_loss       : -1542.5174967447917\n",
      "    val_ess        : 3.7808895111083984\n",
      "    val_log_marginal: 1542.6507568359375\n",
      "Train Epoch: 1682 [0/54000 (0%)] Loss: -1547.277100\n",
      "Train Epoch: 1682 [32768/54000 (61%)] Loss: -1544.828613\n",
      "    epoch          : 1682\n",
      "    loss           : -1543.3923593197228\n",
      "    ess            : 3.774272990676592\n",
      "    log_marginal   : 1543.5237507370282\n",
      "    val_loss       : -1542.4441731770833\n",
      "    val_ess        : 3.7805030743281045\n",
      "    val_log_marginal: 1542.570780436198\n",
      "Train Epoch: 1683 [0/54000 (0%)] Loss: -1541.942627\n",
      "Train Epoch: 1683 [32768/54000 (61%)] Loss: -1543.531006\n",
      "    epoch          : 1683\n",
      "    loss           : -1543.2901104621167\n",
      "    ess            : 3.7746234749847987\n",
      "    log_marginal   : 1543.420281176297\n",
      "    val_loss       : -1542.485107421875\n",
      "    val_ess        : 3.772836764653524\n",
      "    val_log_marginal: 1542.6146036783855\n",
      "Train Epoch: 1684 [0/54000 (0%)] Loss: -1543.653198\n",
      "Train Epoch: 1684 [32768/54000 (61%)] Loss: -1539.521484\n",
      "    epoch          : 1684\n",
      "    loss           : -1543.2875170437794\n",
      "    ess            : 3.770231732782328\n",
      "    log_marginal   : 1543.4195925154777\n",
      "    val_loss       : -1542.4961954752605\n",
      "    val_ess        : 3.7682154973347983\n",
      "    val_log_marginal: 1542.639912923177\n",
      "Train Epoch: 1685 [0/54000 (0%)] Loss: -1543.118896\n",
      "Train Epoch: 1685 [32768/54000 (61%)] Loss: -1539.551758\n",
      "    epoch          : 1685\n",
      "    loss           : -1543.2787786519752\n",
      "    ess            : 3.778911163222115\n",
      "    log_marginal   : 1543.410706718013\n",
      "    val_loss       : -1542.5713297526042\n",
      "    val_ess        : 3.7879074017206826\n",
      "    val_log_marginal: 1542.6925048828125\n",
      "Train Epoch: 1686 [0/54000 (0%)] Loss: -1545.947998\n",
      "Train Epoch: 1686 [32768/54000 (61%)] Loss: -1543.862793\n",
      "    epoch          : 1686\n",
      "    loss           : -1543.5230367408608\n",
      "    ess            : 3.7746159580518617\n",
      "    log_marginal   : 1543.6558515440743\n",
      "    val_loss       : -1542.4280395507812\n",
      "    val_ess        : 3.7757103045781455\n",
      "    val_log_marginal: 1542.5567016601562\n",
      "Train Epoch: 1687 [0/54000 (0%)] Loss: -1544.576294\n",
      "Train Epoch: 1687 [32768/54000 (61%)] Loss: -1542.257202\n",
      "    epoch          : 1687\n",
      "    loss           : -1543.4087259544517\n",
      "    ess            : 3.7735110633778124\n",
      "    log_marginal   : 1543.5422271152713\n",
      "    val_loss       : -1542.767333984375\n",
      "    val_ess        : 3.7707587480545044\n",
      "    val_log_marginal: 1542.8950805664062\n",
      "Train Epoch: 1688 [0/54000 (0%)] Loss: -1541.748291\n",
      "Train Epoch: 1688 [32768/54000 (61%)] Loss: -1545.789673\n",
      "    epoch          : 1688\n",
      "    loss           : -1543.5016214622642\n",
      "    ess            : 3.774000586203809\n",
      "    log_marginal   : 1543.6329852410083\n",
      "    val_loss       : -1542.883809407552\n",
      "    val_ess        : 3.7756221294403076\n",
      "    val_log_marginal: 1543.0042317708333\n",
      "Train Epoch: 1689 [0/54000 (0%)] Loss: -1540.714233\n",
      "Train Epoch: 1689 [32768/54000 (61%)] Loss: -1543.273926\n",
      "    epoch          : 1689\n",
      "    loss           : -1543.5410593860554\n",
      "    ess            : 3.7750108062096364\n",
      "    log_marginal   : 1543.6722458173645\n",
      "    val_loss       : -1542.9618530273438\n",
      "    val_ess        : 3.7892871697743735\n",
      "    val_log_marginal: 1543.0763549804688\n",
      "Train Epoch: 1690 [0/54000 (0%)] Loss: -1541.449707\n",
      "Train Epoch: 1690 [32768/54000 (61%)] Loss: -1543.123535\n",
      "    epoch          : 1690\n",
      "    loss           : -1543.447551223467\n",
      "    ess            : 3.770327095715505\n",
      "    log_marginal   : 1543.582026643573\n",
      "    val_loss       : -1542.8241577148438\n",
      "    val_ess        : 3.7749569416046143\n",
      "    val_log_marginal: 1542.9546508789062\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1690.pth ...\n",
      "Train Epoch: 1691 [0/54000 (0%)] Loss: -1543.003662\n",
      "Train Epoch: 1691 [32768/54000 (61%)] Loss: -1542.488770\n",
      "    epoch          : 1691\n",
      "    loss           : -1543.368408203125\n",
      "    ess            : 3.7715070292634785\n",
      "    log_marginal   : 1543.501349683078\n",
      "    val_loss       : -1543.06494140625\n",
      "    val_ess        : 3.7803609371185303\n",
      "    val_log_marginal: 1543.1965942382812\n",
      "Train Epoch: 1692 [0/54000 (0%)] Loss: -1541.761230\n",
      "Train Epoch: 1692 [32768/54000 (61%)] Loss: -1541.118042\n",
      "    epoch          : 1692\n",
      "    loss           : -1543.3430866745282\n",
      "    ess            : 3.7767501147288196\n",
      "    log_marginal   : 1543.4709495688385\n",
      "    val_loss       : -1543.0730387369792\n",
      "    val_ess        : 3.7824507554372153\n",
      "    val_log_marginal: 1543.1944783528645\n",
      "Train Epoch: 1693 [0/54000 (0%)] Loss: -1544.595459\n",
      "Train Epoch: 1693 [32768/54000 (61%)] Loss: -1543.598511\n",
      "    epoch          : 1693\n",
      "    loss           : -1543.5319225383255\n",
      "    ess            : 3.7763124591899366\n",
      "    log_marginal   : 1543.6617109190743\n",
      "    val_loss       : -1543.0749918619792\n",
      "    val_ess        : 3.7731398344039917\n",
      "    val_log_marginal: 1543.2014973958333\n",
      "Train Epoch: 1694 [0/54000 (0%)] Loss: -1544.518311\n",
      "Train Epoch: 1694 [32768/54000 (61%)] Loss: -1543.491821\n",
      "    epoch          : 1694\n",
      "    loss           : -1543.420840857164\n",
      "    ess            : 3.774657609327784\n",
      "    log_marginal   : 1543.5526952203716\n",
      "    val_loss       : -1543.210673014323\n",
      "    val_ess        : 3.769778768221537\n",
      "    val_log_marginal: 1543.3558349609375\n",
      "Train Epoch: 1695 [0/54000 (0%)] Loss: -1542.755615\n",
      "Train Epoch: 1695 [32768/54000 (61%)] Loss: -1543.352295\n",
      "    epoch          : 1695\n",
      "    loss           : -1543.3674869177476\n",
      "    ess            : 3.7749870633179285\n",
      "    log_marginal   : 1543.4985489755306\n",
      "    val_loss       : -1542.576924641927\n",
      "    val_ess        : 3.775613864262899\n",
      "    val_log_marginal: 1542.7147420247395\n",
      "Train Epoch: 1696 [0/54000 (0%)] Loss: -1546.761353\n",
      "Train Epoch: 1696 [32768/54000 (61%)] Loss: -1538.564209\n",
      "    epoch          : 1696\n",
      "    loss           : -1543.3479096034787\n",
      "    ess            : 3.7717932755092405\n",
      "    log_marginal   : 1543.4829400980248\n",
      "    val_loss       : -1542.902323404948\n",
      "    val_ess        : 3.777856389681498\n",
      "    val_log_marginal: 1543.019287109375\n",
      "Train Epoch: 1697 [0/54000 (0%)] Loss: -1544.991455\n",
      "Train Epoch: 1697 [32768/54000 (61%)] Loss: -1540.945923\n",
      "    epoch          : 1697\n",
      "    loss           : -1543.2871439232017\n",
      "    ess            : 3.7762004519408605\n",
      "    log_marginal   : 1543.4157484522407\n",
      "    val_loss       : -1543.0145467122395\n",
      "    val_ess        : 3.782272140185038\n",
      "    val_log_marginal: 1543.1366170247395\n",
      "Train Epoch: 1698 [0/54000 (0%)] Loss: -1544.691162\n",
      "Train Epoch: 1698 [32768/54000 (61%)] Loss: -1540.986694\n",
      "    epoch          : 1698\n",
      "    loss           : -1543.3243753685142\n",
      "    ess            : 3.7772762010682306\n",
      "    log_marginal   : 1543.4513054613797\n",
      "    val_loss       : -1543.0691528320312\n",
      "    val_ess        : 3.7722246646881104\n",
      "    val_log_marginal: 1543.2116292317708\n",
      "Train Epoch: 1699 [0/54000 (0%)] Loss: -1542.181152\n",
      "Train Epoch: 1699 [32768/54000 (61%)] Loss: -1540.900513\n",
      "    epoch          : 1699\n",
      "    loss           : -1543.5964447597287\n",
      "    ess            : 3.7728971985151185\n",
      "    log_marginal   : 1543.730385834316\n",
      "    val_loss       : -1542.9508666992188\n",
      "    val_ess        : 3.7807185649871826\n",
      "    val_log_marginal: 1543.0860595703125\n",
      "Train Epoch: 1700 [0/54000 (0%)] Loss: -1545.025879\n",
      "Train Epoch: 1700 [32768/54000 (61%)] Loss: -1543.674561\n",
      "    epoch          : 1700\n",
      "    loss           : -1543.5811283903302\n",
      "    ess            : 3.776637518180991\n",
      "    log_marginal   : 1543.711098724941\n",
      "    val_loss       : -1542.6937866210938\n",
      "    val_ess        : 3.767641544342041\n",
      "    val_log_marginal: 1542.8324381510417\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1700.pth ...\n",
      "Train Epoch: 1701 [0/54000 (0%)] Loss: -1543.653442\n",
      "Train Epoch: 1701 [32768/54000 (61%)] Loss: -1544.210205\n",
      "    epoch          : 1701\n",
      "    loss           : -1543.5630205262382\n",
      "    ess            : 3.777274343202699\n",
      "    log_marginal   : 1543.6948127026828\n",
      "    val_loss       : -1542.572021484375\n",
      "    val_ess        : 3.7747989495595298\n",
      "    val_log_marginal: 1542.7062581380208\n",
      "Train Epoch: 1702 [0/54000 (0%)] Loss: -1542.719727\n",
      "Train Epoch: 1702 [32768/54000 (61%)] Loss: -1542.187866\n",
      "    epoch          : 1702\n",
      "    loss           : -1543.6178761608196\n",
      "    ess            : 3.777855288307622\n",
      "    log_marginal   : 1543.7459555571934\n",
      "    val_loss       : -1542.7564086914062\n",
      "    val_ess        : 3.775939623514811\n",
      "    val_log_marginal: 1542.8848063151042\n",
      "Train Epoch: 1703 [0/54000 (0%)] Loss: -1546.259277\n",
      "Train Epoch: 1703 [32768/54000 (61%)] Loss: -1542.213135\n",
      "    epoch          : 1703\n",
      "    loss           : -1543.5963664504718\n",
      "    ess            : 3.7749393256205432\n",
      "    log_marginal   : 1543.73004726194\n",
      "    val_loss       : -1542.4618530273438\n",
      "    val_ess        : 3.780242443084717\n",
      "    val_log_marginal: 1542.6009928385417\n",
      "Train Epoch: 1704 [0/54000 (0%)] Loss: -1544.172974\n",
      "Train Epoch: 1704 [32768/54000 (61%)] Loss: -1546.473999\n",
      "    epoch          : 1704\n",
      "    loss           : -1543.5850691885319\n",
      "    ess            : 3.777428091696973\n",
      "    log_marginal   : 1543.7164444833431\n",
      "    val_loss       : -1542.6776733398438\n",
      "    val_ess        : 3.7827528715133667\n",
      "    val_log_marginal: 1542.8062540690105\n",
      "Train Epoch: 1705 [0/54000 (0%)] Loss: -1545.753174\n",
      "Train Epoch: 1705 [32768/54000 (61%)] Loss: -1542.248535\n",
      "    epoch          : 1705\n",
      "    loss           : -1543.450798754422\n",
      "    ess            : 3.772399717906736\n",
      "    log_marginal   : 1543.5842123931309\n",
      "    val_loss       : -1542.9798787434895\n",
      "    val_ess        : 3.7747023502985635\n",
      "    val_log_marginal: 1543.1073811848958\n",
      "Train Epoch: 1706 [0/54000 (0%)] Loss: -1544.479370\n",
      "Train Epoch: 1706 [32768/54000 (61%)] Loss: -1542.389648\n",
      "    epoch          : 1706\n",
      "    loss           : -1543.4114138045402\n",
      "    ess            : 3.7740415941994145\n",
      "    log_marginal   : 1543.5404513377064\n",
      "    val_loss       : -1542.8383382161458\n",
      "    val_ess        : 3.7816787163416543\n",
      "    val_log_marginal: 1542.9715169270833\n",
      "Train Epoch: 1707 [0/54000 (0%)] Loss: -1544.219604\n",
      "Train Epoch: 1707 [32768/54000 (61%)] Loss: -1542.939453\n",
      "    epoch          : 1707\n",
      "    loss           : -1543.4937214401532\n",
      "    ess            : 3.77195728050088\n",
      "    log_marginal   : 1543.6286851415093\n",
      "    val_loss       : -1542.909891764323\n",
      "    val_ess        : 3.762573003768921\n",
      "    val_log_marginal: 1543.0521443684895\n",
      "Train Epoch: 1708 [0/54000 (0%)] Loss: -1545.052734\n",
      "Train Epoch: 1708 [32768/54000 (61%)] Loss: -1540.310059\n",
      "    epoch          : 1708\n",
      "    loss           : -1543.5704921506485\n",
      "    ess            : 3.778580557625249\n",
      "    log_marginal   : 1543.696648363797\n",
      "    val_loss       : -1542.719482421875\n",
      "    val_ess        : 3.7727692127227783\n",
      "    val_log_marginal: 1542.8539021809895\n",
      "Train Epoch: 1709 [0/54000 (0%)] Loss: -1545.648193\n",
      "Train Epoch: 1709 [32768/54000 (61%)] Loss: -1544.843628\n",
      "    epoch          : 1709\n",
      "    loss           : -1543.4311661630306\n",
      "    ess            : 3.775132957494484\n",
      "    log_marginal   : 1543.5635686910377\n",
      "    val_loss       : -1542.5308024088542\n",
      "    val_ess        : 3.7764087518056235\n",
      "    val_log_marginal: 1542.6723225911458\n",
      "Train Epoch: 1710 [0/54000 (0%)] Loss: -1544.635620\n",
      "Train Epoch: 1710 [32768/54000 (61%)] Loss: -1544.252197\n",
      "    epoch          : 1710\n",
      "    loss           : -1543.510502653302\n",
      "    ess            : 3.7771013772712565\n",
      "    log_marginal   : 1543.6403716465213\n",
      "    val_loss       : -1542.4944458007812\n",
      "    val_ess        : 3.774457852045695\n",
      "    val_log_marginal: 1542.6321207682292\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1710.pth ...\n",
      "Train Epoch: 1711 [0/54000 (0%)] Loss: -1544.481201\n",
      "Train Epoch: 1711 [32768/54000 (61%)] Loss: -1541.410156\n",
      "    epoch          : 1711\n",
      "    loss           : -1543.6014104879127\n",
      "    ess            : 3.775510549545288\n",
      "    log_marginal   : 1543.7311090433373\n",
      "    val_loss       : -1542.6130777994792\n",
      "    val_ess        : 3.780330181121826\n",
      "    val_log_marginal: 1542.7383422851562\n",
      "Train Epoch: 1712 [0/54000 (0%)] Loss: -1545.904297\n",
      "Train Epoch: 1712 [32768/54000 (61%)] Loss: -1543.805176\n",
      "    epoch          : 1712\n",
      "    loss           : -1543.5255288178066\n",
      "    ess            : 3.770727908836221\n",
      "    log_marginal   : 1543.6589516693691\n",
      "    val_loss       : -1542.698994954427\n",
      "    val_ess        : 3.7680055697758994\n",
      "    val_log_marginal: 1542.832784016927\n",
      "Train Epoch: 1713 [0/54000 (0%)] Loss: -1544.000244\n",
      "Train Epoch: 1713 [32768/54000 (61%)] Loss: -1543.379761\n",
      "    epoch          : 1713\n",
      "    loss           : -1543.5529693027713\n",
      "    ess            : 3.7726776914776496\n",
      "    log_marginal   : 1543.683407189711\n",
      "    val_loss       : -1542.416483561198\n",
      "    val_ess        : 3.7689406871795654\n",
      "    val_log_marginal: 1542.5433959960938\n",
      "Train Epoch: 1714 [0/54000 (0%)] Loss: -1545.463867\n",
      "Train Epoch: 1714 [32768/54000 (61%)] Loss: -1545.522705\n",
      "    epoch          : 1714\n",
      "    loss           : -1543.75844127727\n",
      "    ess            : 3.781016192346249\n",
      "    log_marginal   : 1543.8841460605838\n",
      "    val_loss       : -1543.030008951823\n",
      "    val_ess        : 3.767331878344218\n",
      "    val_log_marginal: 1543.1581217447917\n",
      "Train Epoch: 1715 [0/54000 (0%)] Loss: -1544.483398\n",
      "Train Epoch: 1715 [32768/54000 (61%)] Loss: -1545.584961\n",
      "    epoch          : 1715\n",
      "    loss           : -1543.7550302181603\n",
      "    ess            : 3.7797510983808986\n",
      "    log_marginal   : 1543.8797653486145\n",
      "    val_loss       : -1543.271708170573\n",
      "    val_ess        : 3.793973763783773\n",
      "    val_log_marginal: 1543.3875935872395\n",
      "Train Epoch: 1716 [0/54000 (0%)] Loss: -1543.621704\n",
      "Train Epoch: 1716 [32768/54000 (61%)] Loss: -1541.801270\n",
      "    epoch          : 1716\n",
      "    loss           : -1543.7979390846108\n",
      "    ess            : 3.7783502677701555\n",
      "    log_marginal   : 1543.9239985627948\n",
      "    val_loss       : -1542.8701985677083\n",
      "    val_ess        : 3.7671091556549072\n",
      "    val_log_marginal: 1543.0056762695312\n",
      "Train Epoch: 1717 [0/54000 (0%)] Loss: -1542.019775\n",
      "Train Epoch: 1717 [32768/54000 (61%)] Loss: -1543.025146\n",
      "    epoch          : 1717\n",
      "    loss           : -1543.7278476931015\n",
      "    ess            : 3.777606037427794\n",
      "    log_marginal   : 1543.8554940853478\n",
      "    val_loss       : -1543.0291748046875\n",
      "    val_ess        : 3.7642183701197305\n",
      "    val_log_marginal: 1543.1694946289062\n",
      "Train Epoch: 1718 [0/54000 (0%)] Loss: -1546.772217\n",
      "Train Epoch: 1718 [32768/54000 (61%)] Loss: -1542.555786\n",
      "    epoch          : 1718\n",
      "    loss           : -1543.7276357974647\n",
      "    ess            : 3.772854638549517\n",
      "    log_marginal   : 1543.8581681161556\n",
      "    val_loss       : -1543.27685546875\n",
      "    val_ess        : 3.7744354804356894\n",
      "    val_log_marginal: 1543.415018717448\n",
      "Train Epoch: 1719 [0/54000 (0%)] Loss: -1547.004883\n",
      "Train Epoch: 1719 [32768/54000 (61%)] Loss: -1538.524536\n",
      "    epoch          : 1719\n",
      "    loss           : -1543.7486664394162\n",
      "    ess            : 3.775192544145404\n",
      "    log_marginal   : 1543.878947707842\n",
      "    val_loss       : -1542.8400268554688\n",
      "    val_ess        : 3.775188366572062\n",
      "    val_log_marginal: 1542.9762166341145\n",
      "Train Epoch: 1720 [0/54000 (0%)] Loss: -1544.542725\n",
      "Train Epoch: 1720 [32768/54000 (61%)] Loss: -1544.939453\n",
      "    epoch          : 1720\n",
      "    loss           : -1543.5950720445164\n",
      "    ess            : 3.776480751217536\n",
      "    log_marginal   : 1543.7238884691922\n",
      "    val_loss       : -1543.135986328125\n",
      "    val_ess        : 3.788674076398214\n",
      "    val_log_marginal: 1543.2595825195312\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1720.pth ...\n",
      "Train Epoch: 1721 [0/54000 (0%)] Loss: -1542.760986\n",
      "Train Epoch: 1721 [32768/54000 (61%)] Loss: -1541.907349\n",
      "    epoch          : 1721\n",
      "    loss           : -1543.7325600678066\n",
      "    ess            : 3.7713410764370323\n",
      "    log_marginal   : 1543.8653725678066\n",
      "    val_loss       : -1542.9436645507812\n",
      "    val_ess        : 3.787027676900228\n",
      "    val_log_marginal: 1543.064473470052\n",
      "Train Epoch: 1722 [0/54000 (0%)] Loss: -1548.527100\n",
      "Train Epoch: 1722 [32768/54000 (61%)] Loss: -1545.304199\n",
      "    epoch          : 1722\n",
      "    loss           : -1543.709534843013\n",
      "    ess            : 3.768368990916126\n",
      "    log_marginal   : 1543.8445192732902\n",
      "    val_loss       : -1543.1827799479167\n",
      "    val_ess        : 3.7701083024342856\n",
      "    val_log_marginal: 1543.3186442057292\n",
      "Train Epoch: 1723 [0/54000 (0%)] Loss: -1544.991699\n",
      "Train Epoch: 1723 [32768/54000 (61%)] Loss: -1541.770020\n",
      "    epoch          : 1723\n",
      "    loss           : -1543.745055000737\n",
      "    ess            : 3.7787547336434417\n",
      "    log_marginal   : 1543.871987396816\n",
      "    val_loss       : -1543.0321248372395\n",
      "    val_ess        : 3.7804743448893228\n",
      "    val_log_marginal: 1543.1536051432292\n",
      "Train Epoch: 1724 [0/54000 (0%)] Loss: -1544.492798\n",
      "Train Epoch: 1724 [32768/54000 (61%)] Loss: -1542.070801\n",
      "    epoch          : 1724\n",
      "    loss           : -1543.8244721034787\n",
      "    ess            : 3.774807538626329\n",
      "    log_marginal   : 1543.9552140145931\n",
      "    val_loss       : -1543.0061645507812\n",
      "    val_ess        : 3.768163045247396\n",
      "    val_log_marginal: 1543.1458333333333\n",
      "Train Epoch: 1725 [0/54000 (0%)] Loss: -1542.604614\n",
      "Train Epoch: 1725 [32768/54000 (61%)] Loss: -1543.062378\n",
      "    epoch          : 1725\n",
      "    loss           : -1543.8691014703716\n",
      "    ess            : 3.7729259571939147\n",
      "    log_marginal   : 1544.000082915684\n",
      "    val_loss       : -1542.994608561198\n",
      "    val_ess        : 3.778034528096517\n",
      "    val_log_marginal: 1543.1217041015625\n",
      "Train Epoch: 1726 [0/54000 (0%)] Loss: -1546.825073\n",
      "Train Epoch: 1726 [32768/54000 (61%)] Loss: -1542.542480\n",
      "    epoch          : 1726\n",
      "    loss           : -1543.88218372273\n",
      "    ess            : 3.7717619212168567\n",
      "    log_marginal   : 1544.0149893130897\n",
      "    val_loss       : -1542.893086751302\n",
      "    val_ess        : 3.781657894452413\n",
      "    val_log_marginal: 1543.0181681315105\n",
      "Train Epoch: 1727 [0/54000 (0%)] Loss: -1545.318970\n",
      "Train Epoch: 1727 [32768/54000 (61%)] Loss: -1544.516113\n",
      "    epoch          : 1727\n",
      "    loss           : -1543.8030775538032\n",
      "    ess            : 3.773318596605985\n",
      "    log_marginal   : 1543.9360029112618\n",
      "    val_loss       : -1543.2578938802083\n",
      "    val_ess        : 3.7717384099960327\n",
      "    val_log_marginal: 1543.397440592448\n",
      "Train Epoch: 1728 [0/54000 (0%)] Loss: -1540.345581\n",
      "Train Epoch: 1728 [32768/54000 (61%)] Loss: -1544.276611\n",
      "    epoch          : 1728\n",
      "    loss           : -1543.9515542084316\n",
      "    ess            : 3.774547608393543\n",
      "    log_marginal   : 1544.0846315779777\n",
      "    val_loss       : -1543.11669921875\n",
      "    val_ess        : 3.7679033279418945\n",
      "    val_log_marginal: 1543.2530924479167\n",
      "Train Epoch: 1729 [0/54000 (0%)] Loss: -1543.050659\n",
      "Train Epoch: 1729 [32768/54000 (61%)] Loss: -1543.670654\n",
      "    epoch          : 1729\n",
      "    loss           : -1543.747782005454\n",
      "    ess            : 3.7793453279531226\n",
      "    log_marginal   : 1543.8724987102005\n",
      "    val_loss       : -1543.037821451823\n",
      "    val_ess        : 3.762608011563619\n",
      "    val_log_marginal: 1543.1756184895833\n",
      "Train Epoch: 1730 [0/54000 (0%)] Loss: -1544.922119\n",
      "Train Epoch: 1730 [32768/54000 (61%)] Loss: -1540.611328\n",
      "    epoch          : 1730\n",
      "    loss           : -1543.858907447671\n",
      "    ess            : 3.7770199100926236\n",
      "    log_marginal   : 1543.992109190743\n",
      "    val_loss       : -1542.5240885416667\n",
      "    val_ess        : 3.7634130716323853\n",
      "    val_log_marginal: 1542.662333170573\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1730.pth ...\n",
      "Train Epoch: 1731 [0/54000 (0%)] Loss: -1546.217041\n",
      "Train Epoch: 1731 [32768/54000 (61%)] Loss: -1542.843994\n",
      "    epoch          : 1731\n",
      "    loss           : -1543.9003376510907\n",
      "    ess            : 3.782824804198067\n",
      "    log_marginal   : 1544.027281563237\n",
      "    val_loss       : -1543.202901204427\n",
      "    val_ess        : 3.7738686005274453\n",
      "    val_log_marginal: 1543.339864095052\n",
      "Train Epoch: 1732 [0/54000 (0%)] Loss: -1543.271973\n",
      "Train Epoch: 1732 [32768/54000 (61%)] Loss: -1544.147217\n",
      "    epoch          : 1732\n",
      "    loss           : -1544.1011732569282\n",
      "    ess            : 3.776007094473209\n",
      "    log_marginal   : 1544.2332141804245\n",
      "    val_loss       : -1543.2277425130208\n",
      "    val_ess        : 3.7688093185424805\n",
      "    val_log_marginal: 1543.3651326497395\n",
      "Train Epoch: 1733 [0/54000 (0%)] Loss: -1543.078125\n",
      "Train Epoch: 1733 [32768/54000 (61%)] Loss: -1544.157227\n",
      "    epoch          : 1733\n",
      "    loss           : -1544.0680507443985\n",
      "    ess            : 3.77572988114267\n",
      "    log_marginal   : 1544.2008471219044\n",
      "    val_loss       : -1543.1324055989583\n",
      "    val_ess        : 3.7821677923202515\n",
      "    val_log_marginal: 1543.2601725260417\n",
      "Train Epoch: 1734 [0/54000 (0%)] Loss: -1544.081055\n",
      "Train Epoch: 1734 [32768/54000 (61%)] Loss: -1543.868652\n",
      "    epoch          : 1734\n",
      "    loss           : -1544.147456331073\n",
      "    ess            : 3.778007390364161\n",
      "    log_marginal   : 1544.2774450913914\n",
      "    val_loss       : -1543.2009684244792\n",
      "    val_ess        : 3.771974563598633\n",
      "    val_log_marginal: 1543.3365681966145\n",
      "Train Epoch: 1735 [0/54000 (0%)] Loss: -1546.468018\n",
      "Train Epoch: 1735 [32768/54000 (61%)] Loss: -1542.231689\n",
      "    epoch          : 1735\n",
      "    loss           : -1544.133975622789\n",
      "    ess            : 3.772845016335541\n",
      "    log_marginal   : 1544.2691374005012\n",
      "    val_loss       : -1543.3218180338542\n",
      "    val_ess        : 3.7817736069361367\n",
      "    val_log_marginal: 1543.4484049479167\n",
      "Train Epoch: 1736 [0/54000 (0%)] Loss: -1546.910400\n",
      "Train Epoch: 1736 [32768/54000 (61%)] Loss: -1541.448242\n",
      "    epoch          : 1736\n",
      "    loss           : -1544.0986604510613\n",
      "    ess            : 3.777779754602684\n",
      "    log_marginal   : 1544.229128279776\n",
      "    val_loss       : -1543.5032348632812\n",
      "    val_ess        : 3.777262886365255\n",
      "    val_log_marginal: 1543.6306966145833\n",
      "Train Epoch: 1737 [0/54000 (0%)] Loss: -1543.972778\n",
      "Train Epoch: 1737 [32768/54000 (61%)] Loss: -1543.840820\n",
      "    epoch          : 1737\n",
      "    loss           : -1544.0424781655365\n",
      "    ess            : 3.7773330571516506\n",
      "    log_marginal   : 1544.1737544221698\n",
      "    val_loss       : -1543.239481608073\n",
      "    val_ess        : 3.7764318386713662\n",
      "    val_log_marginal: 1543.3722127278645\n",
      "Train Epoch: 1738 [0/54000 (0%)] Loss: -1543.250977\n",
      "Train Epoch: 1738 [32768/54000 (61%)] Loss: -1545.999023\n",
      "    epoch          : 1738\n",
      "    loss           : -1544.0547635060436\n",
      "    ess            : 3.781984473174473\n",
      "    log_marginal   : 1544.1802771226414\n",
      "    val_loss       : -1543.4835001627605\n",
      "    val_ess        : 3.7770759661992392\n",
      "    val_log_marginal: 1543.613057454427\n",
      "Train Epoch: 1739 [0/54000 (0%)] Loss: -1542.052734\n",
      "Train Epoch: 1739 [32768/54000 (61%)] Loss: -1547.770874\n",
      "    epoch          : 1739\n",
      "    loss           : -1544.0532295658904\n",
      "    ess            : 3.775034211716562\n",
      "    log_marginal   : 1544.1847683888561\n",
      "    val_loss       : -1543.709493001302\n",
      "    val_ess        : 3.7821884552637735\n",
      "    val_log_marginal: 1543.8324381510417\n",
      "Train Epoch: 1740 [0/54000 (0%)] Loss: -1547.969604\n",
      "Train Epoch: 1740 [32768/54000 (61%)] Loss: -1547.944824\n",
      "    epoch          : 1740\n",
      "    loss           : -1544.223103073408\n",
      "    ess            : 3.7759120959155963\n",
      "    log_marginal   : 1544.3563647000294\n",
      "    val_loss       : -1543.457743326823\n",
      "    val_ess        : 3.7806721131006875\n",
      "    val_log_marginal: 1543.5873616536458\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1740.pth ...\n",
      "Train Epoch: 1741 [0/54000 (0%)] Loss: -1547.929688\n",
      "Train Epoch: 1741 [32768/54000 (61%)] Loss: -1540.142578\n",
      "    epoch          : 1741\n",
      "    loss           : -1544.198002653302\n",
      "    ess            : 3.7760710896186107\n",
      "    log_marginal   : 1544.327459371315\n",
      "    val_loss       : -1543.6412150065105\n",
      "    val_ess        : 3.777774135271708\n",
      "    val_log_marginal: 1543.7692260742188\n",
      "Train Epoch: 1742 [0/54000 (0%)] Loss: -1547.571777\n",
      "Train Epoch: 1742 [32768/54000 (61%)] Loss: -1541.539551\n",
      "    epoch          : 1742\n",
      "    loss           : -1544.1417581810142\n",
      "    ess            : 3.7714754725402257\n",
      "    log_marginal   : 1544.2755702756485\n",
      "    val_loss       : -1543.481689453125\n",
      "    val_ess        : 3.788360913594564\n",
      "    val_log_marginal: 1543.597432454427\n",
      "Train Epoch: 1743 [0/54000 (0%)] Loss: -1548.716797\n",
      "Train Epoch: 1743 [32768/54000 (61%)] Loss: -1544.174072\n",
      "    epoch          : 1743\n",
      "    loss           : -1544.0681336600826\n",
      "    ess            : 3.77012817814665\n",
      "    log_marginal   : 1544.2040785303657\n",
      "    val_loss       : -1543.6212972005208\n",
      "    val_ess        : 3.770200490951538\n",
      "    val_log_marginal: 1543.751729329427\n",
      "Train Epoch: 1744 [0/54000 (0%)] Loss: -1545.916992\n",
      "Train Epoch: 1744 [32768/54000 (61%)] Loss: -1546.334717\n",
      "    epoch          : 1744\n",
      "    loss           : -1544.2165780697228\n",
      "    ess            : 3.779235048114129\n",
      "    log_marginal   : 1544.34312122273\n",
      "    val_loss       : -1543.389628092448\n",
      "    val_ess        : 3.7851961851119995\n",
      "    val_log_marginal: 1543.518290201823\n",
      "Train Epoch: 1745 [0/54000 (0%)] Loss: -1544.071655\n",
      "Train Epoch: 1745 [32768/54000 (61%)] Loss: -1539.365479\n",
      "    epoch          : 1745\n",
      "    loss           : -1544.2702176076061\n",
      "    ess            : 3.7730427912946016\n",
      "    log_marginal   : 1544.404541015625\n",
      "    val_loss       : -1543.4327392578125\n",
      "    val_ess        : 3.7755287488301597\n",
      "    val_log_marginal: 1543.5726928710938\n",
      "Train Epoch: 1746 [0/54000 (0%)] Loss: -1542.613770\n",
      "Train Epoch: 1746 [32768/54000 (61%)] Loss: -1543.739746\n",
      "    epoch          : 1746\n",
      "    loss           : -1544.1893011129127\n",
      "    ess            : 3.777278873155702\n",
      "    log_marginal   : 1544.3179793447819\n",
      "    val_loss       : -1543.7451171875\n",
      "    val_ess        : 3.786565820376078\n",
      "    val_log_marginal: 1543.8660481770833\n",
      "Train Epoch: 1747 [0/54000 (0%)] Loss: -1545.558105\n",
      "Train Epoch: 1747 [32768/54000 (61%)] Loss: -1544.129761\n",
      "    epoch          : 1747\n",
      "    loss           : -1544.2346283534787\n",
      "    ess            : 3.7754828839931847\n",
      "    log_marginal   : 1544.365800965507\n",
      "    val_loss       : -1543.3369750976562\n",
      "    val_ess        : 3.7794390122095742\n",
      "    val_log_marginal: 1543.4693806966145\n",
      "Train Epoch: 1748 [0/54000 (0%)] Loss: -1543.138916\n",
      "Train Epoch: 1748 [32768/54000 (61%)] Loss: -1543.095215\n",
      "    epoch          : 1748\n",
      "    loss           : -1544.2873304834907\n",
      "    ess            : 3.776973728863698\n",
      "    log_marginal   : 1544.4162436431309\n",
      "    val_loss       : -1543.6083984375\n",
      "    val_ess        : 3.784177780151367\n",
      "    val_log_marginal: 1543.732889811198\n",
      "Train Epoch: 1749 [0/54000 (0%)] Loss: -1546.797485\n",
      "Train Epoch: 1749 [32768/54000 (61%)] Loss: -1544.219849\n",
      "    epoch          : 1749\n",
      "    loss           : -1544.2407387787441\n",
      "    ess            : 3.776976167031054\n",
      "    log_marginal   : 1544.3691774764152\n",
      "    val_loss       : -1543.5843912760417\n",
      "    val_ess        : 3.7734469970067344\n",
      "    val_log_marginal: 1543.7122802734375\n",
      "Train Epoch: 1750 [0/54000 (0%)] Loss: -1544.513916\n",
      "Train Epoch: 1750 [32768/54000 (61%)] Loss: -1545.357788\n",
      "    epoch          : 1750\n",
      "    loss           : -1544.2649317327534\n",
      "    ess            : 3.7755856738900238\n",
      "    log_marginal   : 1544.3990386387088\n",
      "    val_loss       : -1543.53515625\n",
      "    val_ess        : 3.7751092116038003\n",
      "    val_log_marginal: 1543.6632486979167\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1750.pth ...\n",
      "Train Epoch: 1751 [0/54000 (0%)] Loss: -1543.654297\n",
      "Train Epoch: 1751 [32768/54000 (61%)] Loss: -1545.203247\n",
      "    epoch          : 1751\n",
      "    loss           : -1544.3386161372346\n",
      "    ess            : 3.7762423236415072\n",
      "    log_marginal   : 1544.4708413178066\n",
      "    val_loss       : -1543.912353515625\n",
      "    val_ess        : 3.775776982307434\n",
      "    val_log_marginal: 1544.0418497721355\n",
      "Train Epoch: 1752 [0/54000 (0%)] Loss: -1545.906250\n",
      "Train Epoch: 1752 [32768/54000 (61%)] Loss: -1543.608887\n",
      "    epoch          : 1752\n",
      "    loss           : -1544.34375\n",
      "    ess            : 3.76945572529199\n",
      "    log_marginal   : 1544.4802361254422\n",
      "    val_loss       : -1543.7268880208333\n",
      "    val_ess        : 3.7730892101923623\n",
      "    val_log_marginal: 1543.8682657877605\n",
      "Train Epoch: 1753 [0/54000 (0%)] Loss: -1545.859497\n",
      "Train Epoch: 1753 [32768/54000 (61%)] Loss: -1543.012573\n",
      "    epoch          : 1753\n",
      "    loss           : -1544.4055475198998\n",
      "    ess            : 3.7771460650102147\n",
      "    log_marginal   : 1544.5383116524174\n",
      "    val_loss       : -1543.809834798177\n",
      "    val_ess        : 3.773909250895182\n",
      "    val_log_marginal: 1543.9413248697917\n",
      "Train Epoch: 1754 [0/54000 (0%)] Loss: -1546.002197\n",
      "Train Epoch: 1754 [32768/54000 (61%)] Loss: -1544.861816\n",
      "    epoch          : 1754\n",
      "    loss           : -1544.3951416015625\n",
      "    ess            : 3.7783206318909266\n",
      "    log_marginal   : 1544.5239165683963\n",
      "    val_loss       : -1543.8959147135417\n",
      "    val_ess        : 3.776347001393636\n",
      "    val_log_marginal: 1544.0297444661458\n",
      "Train Epoch: 1755 [0/54000 (0%)] Loss: -1547.393677\n",
      "Train Epoch: 1755 [32768/54000 (61%)] Loss: -1543.753662\n",
      "    epoch          : 1755\n",
      "    loss           : -1544.5717266730542\n",
      "    ess            : 3.7746973982397116\n",
      "    log_marginal   : 1544.7000571196934\n",
      "    val_loss       : -1543.8395385742188\n",
      "    val_ess        : 3.76783279577891\n",
      "    val_log_marginal: 1543.9833577473958\n",
      "Train Epoch: 1756 [0/54000 (0%)] Loss: -1547.456543\n",
      "Train Epoch: 1756 [32768/54000 (61%)] Loss: -1543.758057\n",
      "    epoch          : 1756\n",
      "    loss           : -1544.5409603478774\n",
      "    ess            : 3.773358129105478\n",
      "    log_marginal   : 1544.6758802881782\n",
      "    val_loss       : -1543.6237182617188\n",
      "    val_ess        : 3.7605775197347007\n",
      "    val_log_marginal: 1543.7808024088542\n",
      "Train Epoch: 1757 [0/54000 (0%)] Loss: -1546.938965\n",
      "Train Epoch: 1757 [32768/54000 (61%)] Loss: -1542.733643\n",
      "    epoch          : 1757\n",
      "    loss           : -1544.5356261055424\n",
      "    ess            : 3.781068446501246\n",
      "    log_marginal   : 1544.663553489829\n",
      "    val_loss       : -1543.6718343098958\n",
      "    val_ess        : 3.780066212018331\n",
      "    val_log_marginal: 1543.7964274088542\n",
      "Train Epoch: 1758 [0/54000 (0%)] Loss: -1545.332520\n",
      "Train Epoch: 1758 [32768/54000 (61%)] Loss: -1543.614624\n",
      "    epoch          : 1758\n",
      "    loss           : -1544.535276017099\n",
      "    ess            : 3.7770531132536114\n",
      "    log_marginal   : 1544.669553360849\n",
      "    val_loss       : -1543.8744710286458\n",
      "    val_ess        : 3.770672082901001\n",
      "    val_log_marginal: 1544.0089721679688\n",
      "Train Epoch: 1759 [0/54000 (0%)] Loss: -1543.385132\n",
      "Train Epoch: 1759 [32768/54000 (61%)] Loss: -1545.942383\n",
      "    epoch          : 1759\n",
      "    loss           : -1544.4760212448407\n",
      "    ess            : 3.7757965663693986\n",
      "    log_marginal   : 1544.6069497162441\n",
      "    val_loss       : -1543.654805501302\n",
      "    val_ess        : 3.7710469166437783\n",
      "    val_log_marginal: 1543.7859497070312\n",
      "Train Epoch: 1760 [0/54000 (0%)] Loss: -1547.421143\n",
      "Train Epoch: 1760 [32768/54000 (61%)] Loss: -1544.195312\n",
      "    epoch          : 1760\n",
      "    loss           : -1544.4294779075767\n",
      "    ess            : 3.778336560951089\n",
      "    log_marginal   : 1544.5564218197228\n",
      "    val_loss       : -1543.5475260416667\n",
      "    val_ess        : 3.779898722966512\n",
      "    val_log_marginal: 1543.6808268229167\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1760.pth ...\n",
      "Train Epoch: 1761 [0/54000 (0%)] Loss: -1545.288818\n",
      "Train Epoch: 1761 [32768/54000 (61%)] Loss: -1545.906494\n",
      "    epoch          : 1761\n",
      "    loss           : -1544.4737387603184\n",
      "    ess            : 3.7741299890122324\n",
      "    log_marginal   : 1544.6107891730542\n",
      "    val_loss       : -1543.6302897135417\n",
      "    val_ess        : 3.7682026624679565\n",
      "    val_log_marginal: 1543.7597249348958\n",
      "Train Epoch: 1762 [0/54000 (0%)] Loss: -1546.589722\n",
      "Train Epoch: 1762 [32768/54000 (61%)] Loss: -1545.906982\n",
      "    epoch          : 1762\n",
      "    loss           : -1544.5315102631191\n",
      "    ess            : 3.7833523390428074\n",
      "    log_marginal   : 1544.6585440005897\n",
      "    val_loss       : -1543.5479736328125\n",
      "    val_ess        : 3.7573560078938804\n",
      "    val_log_marginal: 1543.694112141927\n",
      "Train Epoch: 1763 [0/54000 (0%)] Loss: -1542.632812\n",
      "Train Epoch: 1763 [32768/54000 (61%)] Loss: -1543.561035\n",
      "    epoch          : 1763\n",
      "    loss           : -1544.5871927513267\n",
      "    ess            : 3.77953750682327\n",
      "    log_marginal   : 1544.716978828862\n",
      "    val_loss       : -1543.4164225260417\n",
      "    val_ess        : 3.7808501720428467\n",
      "    val_log_marginal: 1543.5413411458333\n",
      "Train Epoch: 1764 [0/54000 (0%)] Loss: -1545.881958\n",
      "Train Epoch: 1764 [32768/54000 (61%)] Loss: -1544.844482\n",
      "    epoch          : 1764\n",
      "    loss           : -1544.616579451651\n",
      "    ess            : 3.7783756076164967\n",
      "    log_marginal   : 1544.7493113391804\n",
      "    val_loss       : -1543.468973795573\n",
      "    val_ess        : 3.7863882780075073\n",
      "    val_log_marginal: 1543.5908813476562\n",
      "Train Epoch: 1765 [0/54000 (0%)] Loss: -1544.956909\n",
      "Train Epoch: 1765 [32768/54000 (61%)] Loss: -1542.255127\n",
      "    epoch          : 1765\n",
      "    loss           : -1544.6137580151828\n",
      "    ess            : 3.776504431130751\n",
      "    log_marginal   : 1544.7452438642395\n",
      "    val_loss       : -1543.4284261067708\n",
      "    val_ess        : 3.784109592437744\n",
      "    val_log_marginal: 1543.5553181966145\n",
      "Train Epoch: 1766 [0/54000 (0%)] Loss: -1541.538086\n",
      "Train Epoch: 1766 [32768/54000 (61%)] Loss: -1546.039307\n",
      "    epoch          : 1766\n",
      "    loss           : -1544.661807654039\n",
      "    ess            : 3.779258228697867\n",
      "    log_marginal   : 1544.7904052734375\n",
      "    val_loss       : -1543.5409342447917\n",
      "    val_ess        : 3.7771670818328857\n",
      "    val_log_marginal: 1543.6628011067708\n",
      "Train Epoch: 1767 [0/54000 (0%)] Loss: -1545.246338\n",
      "Train Epoch: 1767 [32768/54000 (61%)] Loss: -1548.179077\n",
      "    epoch          : 1767\n",
      "    loss           : -1544.5802762013561\n",
      "    ess            : 3.778656820081315\n",
      "    log_marginal   : 1544.7074274027123\n",
      "    val_loss       : -1543.3397623697917\n",
      "    val_ess        : 3.787383755048116\n",
      "    val_log_marginal: 1543.4654744466145\n",
      "Train Epoch: 1768 [0/54000 (0%)] Loss: -1548.086914\n",
      "Train Epoch: 1768 [32768/54000 (61%)] Loss: -1542.608643\n",
      "    epoch          : 1768\n",
      "    loss           : -1544.6493910303657\n",
      "    ess            : 3.7800439798607015\n",
      "    log_marginal   : 1544.776284271816\n",
      "    val_loss       : -1543.6873779296875\n",
      "    val_ess        : 3.767670194307963\n",
      "    val_log_marginal: 1543.8230387369792\n",
      "Train Epoch: 1769 [0/54000 (0%)] Loss: -1549.524414\n",
      "Train Epoch: 1769 [32768/54000 (61%)] Loss: -1544.409302\n",
      "    epoch          : 1769\n",
      "    loss           : -1544.7018950840213\n",
      "    ess            : 3.7784836337251484\n",
      "    log_marginal   : 1544.8321579267395\n",
      "    val_loss       : -1543.7118530273438\n",
      "    val_ess        : 3.7795862754185996\n",
      "    val_log_marginal: 1543.8429158528645\n",
      "Train Epoch: 1770 [0/54000 (0%)] Loss: -1544.519287\n",
      "Train Epoch: 1770 [32768/54000 (61%)] Loss: -1543.763794\n",
      "    epoch          : 1770\n",
      "    loss           : -1544.7155324108196\n",
      "    ess            : 3.7769449656864382\n",
      "    log_marginal   : 1544.8445307893573\n",
      "    val_loss       : -1543.8360595703125\n",
      "    val_ess        : 3.780203700065613\n",
      "    val_log_marginal: 1543.9595540364583\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1770.pth ...\n",
      "Train Epoch: 1771 [0/54000 (0%)] Loss: -1546.589966\n",
      "Train Epoch: 1771 [32768/54000 (61%)] Loss: -1544.603516\n",
      "    epoch          : 1771\n",
      "    loss           : -1544.7432723135319\n",
      "    ess            : 3.7718030686648385\n",
      "    log_marginal   : 1544.881244011645\n",
      "    val_loss       : -1543.7510375976562\n",
      "    val_ess        : 3.7734946807225547\n",
      "    val_log_marginal: 1543.8843587239583\n",
      "Train Epoch: 1772 [0/54000 (0%)] Loss: -1545.539062\n",
      "Train Epoch: 1772 [32768/54000 (61%)] Loss: -1547.455811\n",
      "    epoch          : 1772\n",
      "    loss           : -1544.748493698408\n",
      "    ess            : 3.7747919469509483\n",
      "    log_marginal   : 1544.8795903043927\n",
      "    val_loss       : -1543.8339029947917\n",
      "    val_ess        : 3.767414649327596\n",
      "    val_log_marginal: 1543.9753824869792\n",
      "Train Epoch: 1773 [0/54000 (0%)] Loss: -1547.593018\n",
      "Train Epoch: 1773 [32768/54000 (61%)] Loss: -1544.344360\n",
      "    epoch          : 1773\n",
      "    loss           : -1544.8505974535672\n",
      "    ess            : 3.7793714730244763\n",
      "    log_marginal   : 1544.9808395673645\n",
      "    val_loss       : -1544.1396077473958\n",
      "    val_ess        : 3.7915292183558145\n",
      "    val_log_marginal: 1544.255615234375\n",
      "Train Epoch: 1774 [0/54000 (0%)] Loss: -1544.689819\n",
      "Train Epoch: 1774 [32768/54000 (61%)] Loss: -1547.136230\n",
      "    epoch          : 1774\n",
      "    loss           : -1544.8007467017983\n",
      "    ess            : 3.782327562008264\n",
      "    log_marginal   : 1544.9258065853478\n",
      "    val_loss       : -1544.0454508463542\n",
      "    val_ess        : 3.7768741448720298\n",
      "    val_log_marginal: 1544.1759643554688\n",
      "Train Epoch: 1775 [0/54000 (0%)] Loss: -1545.117920\n",
      "Train Epoch: 1775 [32768/54000 (61%)] Loss: -1546.231445\n",
      "    epoch          : 1775\n",
      "    loss           : -1544.8067673017395\n",
      "    ess            : 3.7793621207183263\n",
      "    log_marginal   : 1544.9368666163032\n",
      "    val_loss       : -1544.0911865234375\n",
      "    val_ess        : 3.785647432009379\n",
      "    val_log_marginal: 1544.213846842448\n",
      "Train Epoch: 1776 [0/54000 (0%)] Loss: -1542.044067\n",
      "Train Epoch: 1776 [32768/54000 (61%)] Loss: -1544.758789\n",
      "    epoch          : 1776\n",
      "    loss           : -1544.8409101378243\n",
      "    ess            : 3.776977795474934\n",
      "    log_marginal   : 1544.9736834831958\n",
      "    val_loss       : -1543.9641520182292\n",
      "    val_ess        : 3.7778574228286743\n",
      "    val_log_marginal: 1544.0943196614583\n",
      "Train Epoch: 1777 [0/54000 (0%)] Loss: -1544.987793\n",
      "Train Epoch: 1777 [32768/54000 (61%)] Loss: -1543.895020\n",
      "    epoch          : 1777\n",
      "    loss           : -1544.9414200692806\n",
      "    ess            : 3.7802877561101376\n",
      "    log_marginal   : 1545.0695432267098\n",
      "    val_loss       : -1543.9442138671875\n",
      "    val_ess        : 3.768194874127706\n",
      "    val_log_marginal: 1544.0895589192708\n",
      "Train Epoch: 1778 [0/54000 (0%)] Loss: -1543.135986\n",
      "Train Epoch: 1778 [32768/54000 (61%)] Loss: -1545.879395\n",
      "    epoch          : 1778\n",
      "    loss           : -1544.9933437131485\n",
      "    ess            : 3.7770514488220215\n",
      "    log_marginal   : 1545.1219943064564\n",
      "    val_loss       : -1543.5482381184895\n",
      "    val_ess        : 3.777810573577881\n",
      "    val_log_marginal: 1543.6759847005208\n",
      "Train Epoch: 1779 [0/54000 (0%)] Loss: -1546.741943\n",
      "Train Epoch: 1779 [32768/54000 (61%)] Loss: -1544.005371\n",
      "    epoch          : 1779\n",
      "    loss           : -1544.9542512713738\n",
      "    ess            : 3.7748746647025055\n",
      "    log_marginal   : 1545.0859490160672\n",
      "    val_loss       : -1543.7228190104167\n",
      "    val_ess        : 3.793747345606486\n",
      "    val_log_marginal: 1543.8443196614583\n",
      "Train Epoch: 1780 [0/54000 (0%)] Loss: -1544.459473\n",
      "Train Epoch: 1780 [32768/54000 (61%)] Loss: -1546.318359\n",
      "    epoch          : 1780\n",
      "    loss           : -1544.8154227778596\n",
      "    ess            : 3.777831774837566\n",
      "    log_marginal   : 1544.9458146005306\n",
      "    val_loss       : -1543.8059488932292\n",
      "    val_ess        : 3.7830063501993814\n",
      "    val_log_marginal: 1543.929423014323\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1780.pth ...\n",
      "Train Epoch: 1781 [0/54000 (0%)] Loss: -1546.712280\n",
      "Train Epoch: 1781 [32768/54000 (61%)] Loss: -1545.045654\n",
      "    epoch          : 1781\n",
      "    loss           : -1544.911803047612\n",
      "    ess            : 3.7782269333893397\n",
      "    log_marginal   : 1545.0386847729953\n",
      "    val_loss       : -1543.869160970052\n",
      "    val_ess        : 3.7781095107396445\n",
      "    val_log_marginal: 1543.999491373698\n",
      "Train Epoch: 1782 [0/54000 (0%)] Loss: -1547.810669\n",
      "Train Epoch: 1782 [32768/54000 (61%)] Loss: -1544.627808\n",
      "    epoch          : 1782\n",
      "    loss           : -1544.8266877948113\n",
      "    ess            : 3.778740055156204\n",
      "    log_marginal   : 1544.9540900464328\n",
      "    val_loss       : -1543.5359700520833\n",
      "    val_ess        : 3.7898173332214355\n",
      "    val_log_marginal: 1543.6585693359375\n",
      "Train Epoch: 1783 [0/54000 (0%)] Loss: -1546.422119\n",
      "Train Epoch: 1783 [32768/54000 (61%)] Loss: -1545.741455\n",
      "    epoch          : 1783\n",
      "    loss           : -1544.7374636092277\n",
      "    ess            : 3.775551274137677\n",
      "    log_marginal   : 1544.8688458136792\n",
      "    val_loss       : -1543.924560546875\n",
      "    val_ess        : 3.7797316710154214\n",
      "    val_log_marginal: 1544.0493977864583\n",
      "Train Epoch: 1784 [0/54000 (0%)] Loss: -1548.227295\n",
      "Train Epoch: 1784 [32768/54000 (61%)] Loss: -1546.890625\n",
      "    epoch          : 1784\n",
      "    loss           : -1544.9241160266804\n",
      "    ess            : 3.77196263367275\n",
      "    log_marginal   : 1545.057414504717\n",
      "    val_loss       : -1544.3145345052083\n",
      "    val_ess        : 3.7956677277882895\n",
      "    val_log_marginal: 1544.4312744140625\n",
      "Train Epoch: 1785 [0/54000 (0%)] Loss: -1544.280518\n",
      "Train Epoch: 1785 [32768/54000 (61%)] Loss: -1547.368774\n",
      "    epoch          : 1785\n",
      "    loss           : -1544.8380011792453\n",
      "    ess            : 3.7721914300378763\n",
      "    log_marginal   : 1544.971804061026\n",
      "    val_loss       : -1544.1065266927083\n",
      "    val_ess        : 3.780216932296753\n",
      "    val_log_marginal: 1544.2396443684895\n",
      "Train Epoch: 1786 [0/54000 (0%)] Loss: -1544.296509\n",
      "Train Epoch: 1786 [32768/54000 (61%)] Loss: -1550.956543\n",
      "    epoch          : 1786\n",
      "    loss           : -1545.0055184994103\n",
      "    ess            : 3.773979645855022\n",
      "    log_marginal   : 1545.1375456036262\n",
      "    val_loss       : -1543.990966796875\n",
      "    val_ess        : 3.7723573048909507\n",
      "    val_log_marginal: 1544.1256103515625\n",
      "Train Epoch: 1787 [0/54000 (0%)] Loss: -1545.640869\n",
      "Train Epoch: 1787 [32768/54000 (61%)] Loss: -1544.103760\n",
      "    epoch          : 1787\n",
      "    loss           : -1544.8729823850235\n",
      "    ess            : 3.77675628212263\n",
      "    log_marginal   : 1545.0030770931603\n",
      "    val_loss       : -1544.076904296875\n",
      "    val_ess        : 3.765500783920288\n",
      "    val_log_marginal: 1544.2122395833333\n",
      "Train Epoch: 1788 [0/54000 (0%)] Loss: -1547.952515\n",
      "Train Epoch: 1788 [32768/54000 (61%)] Loss: -1543.209717\n",
      "    epoch          : 1788\n",
      "    loss           : -1544.9699200324292\n",
      "    ess            : 3.7813640585485495\n",
      "    log_marginal   : 1545.0983126658314\n",
      "    val_loss       : -1544.1719360351562\n",
      "    val_ess        : 3.777347207069397\n",
      "    val_log_marginal: 1544.3126220703125\n",
      "Train Epoch: 1789 [0/54000 (0%)] Loss: -1548.734741\n",
      "Train Epoch: 1789 [32768/54000 (61%)] Loss: -1543.076904\n",
      "    epoch          : 1789\n",
      "    loss           : -1544.9305143536262\n",
      "    ess            : 3.7767150132161267\n",
      "    log_marginal   : 1545.0619172869988\n",
      "    val_loss       : -1544.219462076823\n",
      "    val_ess        : 3.782404820124308\n",
      "    val_log_marginal: 1544.3472086588542\n",
      "Train Epoch: 1790 [0/54000 (0%)] Loss: -1543.708740\n",
      "Train Epoch: 1790 [32768/54000 (61%)] Loss: -1546.827148\n",
      "    epoch          : 1790\n",
      "    loss           : -1545.0438531839623\n",
      "    ess            : 3.7785549253787636\n",
      "    log_marginal   : 1545.171750626474\n",
      "    val_loss       : -1544.104227701823\n",
      "    val_ess        : 3.769524852434794\n",
      "    val_log_marginal: 1544.245361328125\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1790.pth ...\n",
      "Train Epoch: 1791 [0/54000 (0%)] Loss: -1545.147339\n",
      "Train Epoch: 1791 [32768/54000 (61%)] Loss: -1549.779785\n",
      "    epoch          : 1791\n",
      "    loss           : -1545.053830704599\n",
      "    ess            : 3.7808585706746802\n",
      "    log_marginal   : 1545.1818340949292\n",
      "    val_loss       : -1543.8657633463542\n",
      "    val_ess        : 3.772320588429769\n",
      "    val_log_marginal: 1544.0001220703125\n",
      "Train Epoch: 1792 [0/54000 (0%)] Loss: -1549.408203\n",
      "Train Epoch: 1792 [32768/54000 (61%)] Loss: -1545.605713\n",
      "    epoch          : 1792\n",
      "    loss           : -1545.053595776828\n",
      "    ess            : 3.7793475142065085\n",
      "    log_marginal   : 1545.1816705667748\n",
      "    val_loss       : -1543.773417154948\n",
      "    val_ess        : 3.7778181234995523\n",
      "    val_log_marginal: 1543.907246907552\n",
      "Train Epoch: 1793 [0/54000 (0%)] Loss: -1546.066040\n",
      "Train Epoch: 1793 [32768/54000 (61%)] Loss: -1546.428101\n",
      "    epoch          : 1793\n",
      "    loss           : -1545.1142094450177\n",
      "    ess            : 3.7728791011954255\n",
      "    log_marginal   : 1545.2460499889446\n",
      "    val_loss       : -1544.0107014973958\n",
      "    val_ess        : 3.772753953933716\n",
      "    val_log_marginal: 1544.1483764648438\n",
      "Train Epoch: 1794 [0/54000 (0%)] Loss: -1547.573730\n",
      "Train Epoch: 1794 [32768/54000 (61%)] Loss: -1544.057617\n",
      "    epoch          : 1794\n",
      "    loss           : -1545.1432345408314\n",
      "    ess            : 3.775239404642357\n",
      "    log_marginal   : 1545.2721430940448\n",
      "    val_loss       : -1544.0218505859375\n",
      "    val_ess        : 3.7815729777018228\n",
      "    val_log_marginal: 1544.152852376302\n",
      "Train Epoch: 1795 [0/54000 (0%)] Loss: -1546.380371\n",
      "Train Epoch: 1795 [32768/54000 (61%)] Loss: -1543.974854\n",
      "    epoch          : 1795\n",
      "    loss           : -1545.1185095445164\n",
      "    ess            : 3.776522690395139\n",
      "    log_marginal   : 1545.2481021521226\n",
      "    val_loss       : -1544.0291951497395\n",
      "    val_ess        : 3.79013454914093\n",
      "    val_log_marginal: 1544.1516927083333\n",
      "Train Epoch: 1796 [0/54000 (0%)] Loss: -1546.397461\n",
      "Train Epoch: 1796 [32768/54000 (61%)] Loss: -1543.107056\n",
      "    epoch          : 1796\n",
      "    loss           : -1545.066853073408\n",
      "    ess            : 3.775009479162828\n",
      "    log_marginal   : 1545.1993868845814\n",
      "    val_loss       : -1544.3055419921875\n",
      "    val_ess        : 3.768306334813436\n",
      "    val_log_marginal: 1544.4527791341145\n",
      "Train Epoch: 1797 [0/54000 (0%)] Loss: -1548.609741\n",
      "Train Epoch: 1797 [32768/54000 (61%)] Loss: -1548.331787\n",
      "    epoch          : 1797\n",
      "    loss           : -1545.1769766177772\n",
      "    ess            : 3.7782198393119955\n",
      "    log_marginal   : 1545.3072302476414\n",
      "    val_loss       : -1544.4886474609375\n",
      "    val_ess        : 3.7677272160847983\n",
      "    val_log_marginal: 1544.6292317708333\n",
      "Train Epoch: 1798 [0/54000 (0%)] Loss: -1546.224609\n",
      "Train Epoch: 1798 [32768/54000 (61%)] Loss: -1541.636963\n",
      "    epoch          : 1798\n",
      "    loss           : -1545.0399077793338\n",
      "    ess            : 3.775275279890816\n",
      "    log_marginal   : 1545.1690535635319\n",
      "    val_loss       : -1544.161112467448\n",
      "    val_ess        : 3.7660415967305503\n",
      "    val_log_marginal: 1544.300557454427\n",
      "Train Epoch: 1799 [0/54000 (0%)] Loss: -1542.380127\n",
      "Train Epoch: 1799 [32768/54000 (61%)] Loss: -1545.356201\n",
      "    epoch          : 1799\n",
      "    loss           : -1545.012128721993\n",
      "    ess            : 3.778959517209035\n",
      "    log_marginal   : 1545.139155549823\n",
      "    val_loss       : -1544.339111328125\n",
      "    val_ess        : 3.7716087897618613\n",
      "    val_log_marginal: 1544.4831949869792\n",
      "Train Epoch: 1800 [0/54000 (0%)] Loss: -1542.952271\n",
      "Train Epoch: 1800 [32768/54000 (61%)] Loss: -1544.967407\n",
      "    epoch          : 1800\n",
      "    loss           : -1545.1065950213738\n",
      "    ess            : 3.779461847161347\n",
      "    log_marginal   : 1545.2350060804836\n",
      "    val_loss       : -1544.1406656901042\n",
      "    val_ess        : 3.7638196547826133\n",
      "    val_log_marginal: 1544.2788696289062\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1800.pth ...\n",
      "Train Epoch: 1801 [0/54000 (0%)] Loss: -1544.578125\n",
      "Train Epoch: 1801 [32768/54000 (61%)] Loss: -1541.945190\n",
      "    epoch          : 1801\n",
      "    loss           : -1545.055535082547\n",
      "    ess            : 3.781122661986441\n",
      "    log_marginal   : 1545.1821749705189\n",
      "    val_loss       : -1544.3556518554688\n",
      "    val_ess        : 3.7795085509618125\n",
      "    val_log_marginal: 1544.4836832682292\n",
      "Train Epoch: 1802 [0/54000 (0%)] Loss: -1546.499512\n",
      "Train Epoch: 1802 [32768/54000 (61%)] Loss: -1545.891235\n",
      "    epoch          : 1802\n",
      "    loss           : -1545.0841962706368\n",
      "    ess            : 3.778459481473239\n",
      "    log_marginal   : 1545.212381614829\n",
      "    val_loss       : -1544.3323771158855\n",
      "    val_ess        : 3.776683529218038\n",
      "    val_log_marginal: 1544.4655354817708\n",
      "Train Epoch: 1803 [0/54000 (0%)] Loss: -1549.493164\n",
      "Train Epoch: 1803 [32768/54000 (61%)] Loss: -1545.216431\n",
      "    epoch          : 1803\n",
      "    loss           : -1545.1518071012677\n",
      "    ess            : 3.7764916150075085\n",
      "    log_marginal   : 1545.28306262898\n",
      "    val_loss       : -1544.5142211914062\n",
      "    val_ess        : 3.778364976247152\n",
      "    val_log_marginal: 1544.651631673177\n",
      "Train Epoch: 1804 [0/54000 (0%)] Loss: -1546.934692\n",
      "Train Epoch: 1804 [32768/54000 (61%)] Loss: -1546.283936\n",
      "    epoch          : 1804\n",
      "    loss           : -1545.1158309072819\n",
      "    ess            : 3.7784637235245615\n",
      "    log_marginal   : 1545.245382057046\n",
      "    val_loss       : -1544.5871988932292\n",
      "    val_ess        : 3.7756275733311973\n",
      "    val_log_marginal: 1544.7192993164062\n",
      "Train Epoch: 1805 [0/54000 (0%)] Loss: -1543.484375\n",
      "Train Epoch: 1805 [32768/54000 (61%)] Loss: -1544.728271\n",
      "    epoch          : 1805\n",
      "    loss           : -1545.2680986512382\n",
      "    ess            : 3.7799483650135546\n",
      "    log_marginal   : 1545.3985342349647\n",
      "    val_loss       : -1544.3473307291667\n",
      "    val_ess        : 3.7881726026535034\n",
      "    val_log_marginal: 1544.4705607096355\n",
      "Train Epoch: 1806 [0/54000 (0%)] Loss: -1547.392334\n",
      "Train Epoch: 1806 [32768/54000 (61%)] Loss: -1546.211182\n",
      "    epoch          : 1806\n",
      "    loss           : -1545.3048924859966\n",
      "    ess            : 3.7777557373046875\n",
      "    log_marginal   : 1545.4334002800708\n",
      "    val_loss       : -1544.4423217773438\n",
      "    val_ess        : 3.783846894900004\n",
      "    val_log_marginal: 1544.56591796875\n",
      "Train Epoch: 1807 [0/54000 (0%)] Loss: -1549.092529\n",
      "Train Epoch: 1807 [32768/54000 (61%)] Loss: -1543.669922\n",
      "    epoch          : 1807\n",
      "    loss           : -1545.320089088296\n",
      "    ess            : 3.7787368072653718\n",
      "    log_marginal   : 1545.4487604105248\n",
      "    val_loss       : -1544.5265096028645\n",
      "    val_ess        : 3.7593480348587036\n",
      "    val_log_marginal: 1544.676513671875\n",
      "Train Epoch: 1808 [0/54000 (0%)] Loss: -1547.925293\n",
      "Train Epoch: 1808 [32768/54000 (61%)] Loss: -1544.145020\n",
      "    epoch          : 1808\n",
      "    loss           : -1545.2335573592277\n",
      "    ess            : 3.7788653688610725\n",
      "    log_marginal   : 1545.359619140625\n",
      "    val_loss       : -1544.5788167317708\n",
      "    val_ess        : 3.789433797200521\n",
      "    val_log_marginal: 1544.6935628255208\n",
      "Train Epoch: 1809 [0/54000 (0%)] Loss: -1546.272705\n",
      "Train Epoch: 1809 [32768/54000 (61%)] Loss: -1544.847778\n",
      "    epoch          : 1809\n",
      "    loss           : -1545.2187592128537\n",
      "    ess            : 3.7778150225585363\n",
      "    log_marginal   : 1545.349729142099\n",
      "    val_loss       : -1544.437276204427\n",
      "    val_ess        : 3.779285987218221\n",
      "    val_log_marginal: 1544.5641682942708\n",
      "Train Epoch: 1810 [0/54000 (0%)] Loss: -1546.799561\n",
      "Train Epoch: 1810 [32768/54000 (61%)] Loss: -1546.366333\n",
      "    epoch          : 1810\n",
      "    loss           : -1545.1824720850532\n",
      "    ess            : 3.780986731907107\n",
      "    log_marginal   : 1545.3125368514152\n",
      "    val_loss       : -1544.4508463541667\n",
      "    val_ess        : 3.7901408274968467\n",
      "    val_log_marginal: 1544.5767618815105\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1810.pth ...\n",
      "Train Epoch: 1811 [0/54000 (0%)] Loss: -1545.480469\n",
      "Train Epoch: 1811 [32768/54000 (61%)] Loss: -1546.222412\n",
      "    epoch          : 1811\n",
      "    loss           : -1545.1853142504422\n",
      "    ess            : 3.7758783619358853\n",
      "    log_marginal   : 1545.3176522884728\n",
      "    val_loss       : -1544.2861735026042\n",
      "    val_ess        : 3.76270067691803\n",
      "    val_log_marginal: 1544.427490234375\n",
      "Train Epoch: 1812 [0/54000 (0%)] Loss: -1548.627197\n",
      "Train Epoch: 1812 [32768/54000 (61%)] Loss: -1546.147949\n",
      "    epoch          : 1812\n",
      "    loss           : -1545.2724678471404\n",
      "    ess            : 3.7780999147667074\n",
      "    log_marginal   : 1545.4003791089328\n",
      "    val_loss       : -1544.4654337565105\n",
      "    val_ess        : 3.785309672355652\n",
      "    val_log_marginal: 1544.5916544596355\n",
      "Train Epoch: 1813 [0/54000 (0%)] Loss: -1546.706787\n",
      "Train Epoch: 1813 [32768/54000 (61%)] Loss: -1544.873291\n",
      "    epoch          : 1813\n",
      "    loss           : -1545.3454267393868\n",
      "    ess            : 3.775443931795516\n",
      "    log_marginal   : 1545.4776334942512\n",
      "    val_loss       : -1544.5411783854167\n",
      "    val_ess        : 3.7753811279932656\n",
      "    val_log_marginal: 1544.6786499023438\n",
      "Train Epoch: 1814 [0/54000 (0%)] Loss: -1546.812622\n",
      "Train Epoch: 1814 [32768/54000 (61%)] Loss: -1542.964600\n",
      "    epoch          : 1814\n",
      "    loss           : -1545.3041900058963\n",
      "    ess            : 3.775370458386979\n",
      "    log_marginal   : 1545.4355215396522\n",
      "    val_loss       : -1544.3342895507812\n",
      "    val_ess        : 3.770862658818563\n",
      "    val_log_marginal: 1544.4767252604167\n",
      "Train Epoch: 1815 [0/54000 (0%)] Loss: -1546.159668\n",
      "Train Epoch: 1815 [32768/54000 (61%)] Loss: -1544.360229\n",
      "    epoch          : 1815\n",
      "    loss           : -1545.412784216539\n",
      "    ess            : 3.779943200777162\n",
      "    log_marginal   : 1545.5410662956958\n",
      "    val_loss       : -1544.8426106770833\n",
      "    val_ess        : 3.784826477368673\n",
      "    val_log_marginal: 1544.9652913411458\n",
      "Train Epoch: 1816 [0/54000 (0%)] Loss: -1546.207031\n",
      "Train Epoch: 1816 [32768/54000 (61%)] Loss: -1545.563232\n",
      "    epoch          : 1816\n",
      "    loss           : -1545.2985770747346\n",
      "    ess            : 3.7809072305571356\n",
      "    log_marginal   : 1545.4290725420105\n",
      "    val_loss       : -1544.621602376302\n",
      "    val_ess        : 3.788253744443258\n",
      "    val_log_marginal: 1544.7498168945312\n",
      "Train Epoch: 1817 [0/54000 (0%)] Loss: -1548.364136\n",
      "Train Epoch: 1817 [32768/54000 (61%)] Loss: -1548.071289\n",
      "    epoch          : 1817\n",
      "    loss           : -1545.3318354768573\n",
      "    ess            : 3.7772683872366852\n",
      "    log_marginal   : 1545.4617436247052\n",
      "    val_loss       : -1545.15185546875\n",
      "    val_ess        : 3.778638998667399\n",
      "    val_log_marginal: 1545.2804565429688\n",
      "Train Epoch: 1818 [0/54000 (0%)] Loss: -1547.131104\n",
      "Train Epoch: 1818 [32768/54000 (61%)] Loss: -1544.773193\n",
      "    epoch          : 1818\n",
      "    loss           : -1545.294127266362\n",
      "    ess            : 3.7793714640275486\n",
      "    log_marginal   : 1545.424602004717\n",
      "    val_loss       : -1544.5116170247395\n",
      "    val_ess        : 3.771709402402242\n",
      "    val_log_marginal: 1544.65087890625\n",
      "Train Epoch: 1819 [0/54000 (0%)] Loss: -1546.569824\n",
      "Train Epoch: 1819 [32768/54000 (61%)] Loss: -1546.836670\n",
      "    epoch          : 1819\n",
      "    loss           : -1545.3044088111733\n",
      "    ess            : 3.7796959787044884\n",
      "    log_marginal   : 1545.4344390293338\n",
      "    val_loss       : -1544.7650756835938\n",
      "    val_ess        : 3.7665000756581626\n",
      "    val_log_marginal: 1544.9073079427083\n",
      "Train Epoch: 1820 [0/54000 (0%)] Loss: -1546.054688\n",
      "Train Epoch: 1820 [32768/54000 (61%)] Loss: -1544.804199\n",
      "    epoch          : 1820\n",
      "    loss           : -1545.2337485259434\n",
      "    ess            : 3.7811291037865407\n",
      "    log_marginal   : 1545.3613672796284\n",
      "    val_loss       : -1544.8900146484375\n",
      "    val_ess        : 3.786929210027059\n",
      "    val_log_marginal: 1545.016133626302\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1820.pth ...\n",
      "Train Epoch: 1821 [0/54000 (0%)] Loss: -1543.979736\n",
      "Train Epoch: 1821 [32768/54000 (61%)] Loss: -1545.573486\n",
      "    epoch          : 1821\n",
      "    loss           : -1545.2525381412147\n",
      "    ess            : 3.779273563960813\n",
      "    log_marginal   : 1545.379638671875\n",
      "    val_loss       : -1544.5813802083333\n",
      "    val_ess        : 3.7841429313023887\n",
      "    val_log_marginal: 1544.7086791992188\n",
      "Train Epoch: 1822 [0/54000 (0%)] Loss: -1546.745605\n",
      "Train Epoch: 1822 [32768/54000 (61%)] Loss: -1546.032715\n",
      "    epoch          : 1822\n",
      "    loss           : -1545.1641753574588\n",
      "    ess            : 3.776323727841647\n",
      "    log_marginal   : 1545.292397553066\n",
      "    val_loss       : -1544.5765380859375\n",
      "    val_ess        : 3.7683540185292563\n",
      "    val_log_marginal: 1544.710957845052\n",
      "Train Epoch: 1823 [0/54000 (0%)] Loss: -1547.597168\n",
      "Train Epoch: 1823 [32768/54000 (61%)] Loss: -1546.538574\n",
      "    epoch          : 1823\n",
      "    loss           : -1545.2126165426002\n",
      "    ess            : 3.7768721535520733\n",
      "    log_marginal   : 1545.3472025169517\n",
      "    val_loss       : -1544.7562866210938\n",
      "    val_ess        : 3.7750757535298667\n",
      "    val_log_marginal: 1544.8958333333333\n",
      "Train Epoch: 1824 [0/54000 (0%)] Loss: -1545.542236\n",
      "Train Epoch: 1824 [32768/54000 (61%)] Loss: -1547.658325\n",
      "    epoch          : 1824\n",
      "    loss           : -1545.2600696491745\n",
      "    ess            : 3.77870356361821\n",
      "    log_marginal   : 1545.3911224941037\n",
      "    val_loss       : -1544.3558349609375\n",
      "    val_ess        : 3.7738524675369263\n",
      "    val_log_marginal: 1544.4905395507812\n",
      "Train Epoch: 1825 [0/54000 (0%)] Loss: -1544.219971\n",
      "Train Epoch: 1825 [32768/54000 (61%)] Loss: -1545.436035\n",
      "    epoch          : 1825\n",
      "    loss           : -1545.240338019605\n",
      "    ess            : 3.7786383223983475\n",
      "    log_marginal   : 1545.3693387013561\n",
      "    val_loss       : -1544.6322631835938\n",
      "    val_ess        : 3.770201086997986\n",
      "    val_log_marginal: 1544.7645670572917\n",
      "Train Epoch: 1826 [0/54000 (0%)] Loss: -1548.700562\n",
      "Train Epoch: 1826 [32768/54000 (61%)] Loss: -1545.335693\n",
      "    epoch          : 1826\n",
      "    loss           : -1545.255863981427\n",
      "    ess            : 3.7729774511085368\n",
      "    log_marginal   : 1545.389445754717\n",
      "    val_loss       : -1544.36865234375\n",
      "    val_ess        : 3.7820725440979004\n",
      "    val_log_marginal: 1544.4972534179688\n",
      "Train Epoch: 1827 [0/54000 (0%)] Loss: -1549.411377\n",
      "Train Epoch: 1827 [32768/54000 (61%)] Loss: -1545.983398\n",
      "    epoch          : 1827\n",
      "    loss           : -1545.2016279112618\n",
      "    ess            : 3.777608228179644\n",
      "    log_marginal   : 1545.3325448665978\n",
      "    val_loss       : -1544.3437906901042\n",
      "    val_ess        : 3.779035131136576\n",
      "    val_log_marginal: 1544.4768473307292\n",
      "Train Epoch: 1828 [0/54000 (0%)] Loss: -1547.920654\n",
      "Train Epoch: 1828 [32768/54000 (61%)] Loss: -1546.434448\n",
      "    epoch          : 1828\n",
      "    loss           : -1545.3612981832252\n",
      "    ess            : 3.7815311045016884\n",
      "    log_marginal   : 1545.4873185067806\n",
      "    val_loss       : -1544.5868733723958\n",
      "    val_ess        : 3.7848366101582847\n",
      "    val_log_marginal: 1544.7120971679688\n",
      "Train Epoch: 1829 [0/54000 (0%)] Loss: -1545.925781\n",
      "Train Epoch: 1829 [32768/54000 (61%)] Loss: -1546.119385\n",
      "    epoch          : 1829\n",
      "    loss           : -1545.287171561763\n",
      "    ess            : 3.776365653523859\n",
      "    log_marginal   : 1545.420467736586\n",
      "    val_loss       : -1544.5677490234375\n",
      "    val_ess        : 3.7870895862579346\n",
      "    val_log_marginal: 1544.6853434244792\n",
      "Train Epoch: 1830 [0/54000 (0%)] Loss: -1549.280518\n",
      "Train Epoch: 1830 [32768/54000 (61%)] Loss: -1545.335449\n",
      "    epoch          : 1830\n",
      "    loss           : -1545.299684920401\n",
      "    ess            : 3.7803799701186844\n",
      "    log_marginal   : 1545.428731666421\n",
      "    val_loss       : -1544.6129353841145\n",
      "    val_ess        : 3.7874584197998047\n",
      "    val_log_marginal: 1544.7312418619792\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1830.pth ...\n",
      "Train Epoch: 1831 [0/54000 (0%)] Loss: -1545.502563\n",
      "Train Epoch: 1831 [32768/54000 (61%)] Loss: -1542.556152\n",
      "    epoch          : 1831\n",
      "    loss           : -1545.276143775796\n",
      "    ess            : 3.775538880870027\n",
      "    log_marginal   : 1545.4082906471108\n",
      "    val_loss       : -1544.3775024414062\n",
      "    val_ess        : 3.7604528268178306\n",
      "    val_log_marginal: 1544.5185953776042\n",
      "Train Epoch: 1832 [0/54000 (0%)] Loss: -1544.791016\n",
      "Train Epoch: 1832 [32768/54000 (61%)] Loss: -1543.256348\n",
      "    epoch          : 1832\n",
      "    loss           : -1545.416321952388\n",
      "    ess            : 3.7772455035515553\n",
      "    log_marginal   : 1545.545046248526\n",
      "    val_loss       : -1544.6338297526042\n",
      "    val_ess        : 3.779749115308126\n",
      "    val_log_marginal: 1544.7628377278645\n",
      "Train Epoch: 1833 [0/54000 (0%)] Loss: -1547.184814\n",
      "Train Epoch: 1833 [32768/54000 (61%)] Loss: -1543.458130\n",
      "    epoch          : 1833\n",
      "    loss           : -1545.3889275316922\n",
      "    ess            : 3.7788543881110424\n",
      "    log_marginal   : 1545.5166959942512\n",
      "    val_loss       : -1545.2858072916667\n",
      "    val_ess        : 3.783388535181681\n",
      "    val_log_marginal: 1545.4070638020833\n",
      "Train Epoch: 1834 [0/54000 (0%)] Loss: -1543.735352\n",
      "Train Epoch: 1834 [32768/54000 (61%)] Loss: -1543.013794\n",
      "    epoch          : 1834\n",
      "    loss           : -1545.4664767283314\n",
      "    ess            : 3.7791483627175384\n",
      "    log_marginal   : 1545.5971587558963\n",
      "    val_loss       : -1544.556864420573\n",
      "    val_ess        : 3.7847514947255454\n",
      "    val_log_marginal: 1544.6875813802083\n",
      "Train Epoch: 1835 [0/54000 (0%)] Loss: -1543.854126\n",
      "Train Epoch: 1835 [32768/54000 (61%)] Loss: -1544.403076\n",
      "    epoch          : 1835\n",
      "    loss           : -1545.522087816922\n",
      "    ess            : 3.780891850309552\n",
      "    log_marginal   : 1545.6489557230248\n",
      "    val_loss       : -1544.9285888671875\n",
      "    val_ess        : 3.785769462585449\n",
      "    val_log_marginal: 1545.0489705403645\n",
      "Train Epoch: 1836 [0/54000 (0%)] Loss: -1544.233643\n",
      "Train Epoch: 1836 [32768/54000 (61%)] Loss: -1546.145386\n",
      "    epoch          : 1836\n",
      "    loss           : -1545.6117311873527\n",
      "    ess            : 3.7833129010110533\n",
      "    log_marginal   : 1545.7377008402123\n",
      "    val_loss       : -1544.7778727213542\n",
      "    val_ess        : 3.7720636129379272\n",
      "    val_log_marginal: 1544.911356608073\n",
      "Train Epoch: 1837 [0/54000 (0%)] Loss: -1548.391724\n",
      "Train Epoch: 1837 [32768/54000 (61%)] Loss: -1544.515381\n",
      "    epoch          : 1837\n",
      "    loss           : -1545.6973738760319\n",
      "    ess            : 3.7791184569304845\n",
      "    log_marginal   : 1545.8275676223468\n",
      "    val_loss       : -1544.6758422851562\n",
      "    val_ess        : 3.7607423861821494\n",
      "    val_log_marginal: 1544.82470703125\n",
      "Train Epoch: 1838 [0/54000 (0%)] Loss: -1543.411377\n",
      "Train Epoch: 1838 [32768/54000 (61%)] Loss: -1544.202148\n",
      "    epoch          : 1838\n",
      "    loss           : -1545.639408903302\n",
      "    ess            : 3.7758749341065028\n",
      "    log_marginal   : 1545.7699734669811\n",
      "    val_loss       : -1544.5305786132812\n",
      "    val_ess        : 3.779228925704956\n",
      "    val_log_marginal: 1544.6600341796875\n",
      "Train Epoch: 1839 [0/54000 (0%)] Loss: -1544.060547\n",
      "Train Epoch: 1839 [32768/54000 (61%)] Loss: -1545.740234\n",
      "    epoch          : 1839\n",
      "    loss           : -1545.5748498304836\n",
      "    ess            : 3.7792329428330906\n",
      "    log_marginal   : 1545.703327682783\n",
      "    val_loss       : -1544.9229939778645\n",
      "    val_ess        : 3.7787425915400186\n",
      "    val_log_marginal: 1545.0507202148438\n",
      "Train Epoch: 1840 [0/54000 (0%)] Loss: -1548.922974\n",
      "Train Epoch: 1840 [32768/54000 (61%)] Loss: -1545.492188\n",
      "    epoch          : 1840\n",
      "    loss           : -1545.602435417895\n",
      "    ess            : 3.7732233191436193\n",
      "    log_marginal   : 1545.7371734043338\n",
      "    val_loss       : -1544.6729939778645\n",
      "    val_ess        : 3.7896023193995156\n",
      "    val_log_marginal: 1544.7882283528645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1840.pth ...\n",
      "Train Epoch: 1841 [0/54000 (0%)] Loss: -1546.813965\n",
      "Train Epoch: 1841 [32768/54000 (61%)] Loss: -1542.703857\n",
      "    epoch          : 1841\n",
      "    loss           : -1545.646016822671\n",
      "    ess            : 3.7748901529132195\n",
      "    log_marginal   : 1545.7775072781544\n",
      "    val_loss       : -1544.9077555338542\n",
      "    val_ess        : 3.781927307446798\n",
      "    val_log_marginal: 1545.0352783203125\n",
      "Train Epoch: 1842 [0/54000 (0%)] Loss: -1548.467529\n",
      "Train Epoch: 1842 [32768/54000 (61%)] Loss: -1546.443604\n",
      "    epoch          : 1842\n",
      "    loss           : -1545.6575444059552\n",
      "    ess            : 3.777832625047216\n",
      "    log_marginal   : 1545.7874847987912\n",
      "    val_loss       : -1545.282979329427\n",
      "    val_ess        : 3.777478257815043\n",
      "    val_log_marginal: 1545.4098307291667\n",
      "Train Epoch: 1843 [0/54000 (0%)] Loss: -1547.286621\n",
      "Train Epoch: 1843 [32768/54000 (61%)] Loss: -1544.669312\n",
      "    epoch          : 1843\n",
      "    loss           : -1545.5912233748527\n",
      "    ess            : 3.77525735801121\n",
      "    log_marginal   : 1545.7214263340213\n",
      "    val_loss       : -1544.523457845052\n",
      "    val_ess        : 3.783715605735779\n",
      "    val_log_marginal: 1544.6554361979167\n",
      "Train Epoch: 1844 [0/54000 (0%)] Loss: -1544.947876\n",
      "Train Epoch: 1844 [32768/54000 (61%)] Loss: -1548.390869\n",
      "    epoch          : 1844\n",
      "    loss           : -1545.633544921875\n",
      "    ess            : 3.7740239737168797\n",
      "    log_marginal   : 1545.7651712669517\n",
      "    val_loss       : -1544.6620076497395\n",
      "    val_ess        : 3.784249226252238\n",
      "    val_log_marginal: 1544.7789713541667\n",
      "Train Epoch: 1845 [0/54000 (0%)] Loss: -1545.425537\n",
      "Train Epoch: 1845 [32768/54000 (61%)] Loss: -1545.591797\n",
      "    epoch          : 1845\n",
      "    loss           : -1545.658281434257\n",
      "    ess            : 3.7792693039156355\n",
      "    log_marginal   : 1545.7876506301593\n",
      "    val_loss       : -1544.917989095052\n",
      "    val_ess        : 3.79068660736084\n",
      "    val_log_marginal: 1545.0387166341145\n",
      "Train Epoch: 1846 [0/54000 (0%)] Loss: -1545.076172\n",
      "Train Epoch: 1846 [32768/54000 (61%)] Loss: -1542.841187\n",
      "    epoch          : 1846\n",
      "    loss           : -1545.6253201466686\n",
      "    ess            : 3.771588775346864\n",
      "    log_marginal   : 1545.7602907576652\n",
      "    val_loss       : -1544.8750406901042\n",
      "    val_ess        : 3.7913784186045327\n",
      "    val_log_marginal: 1544.9906412760417\n",
      "Train Epoch: 1847 [0/54000 (0%)] Loss: -1546.805420\n",
      "Train Epoch: 1847 [32768/54000 (61%)] Loss: -1543.905762\n",
      "    epoch          : 1847\n",
      "    loss           : -1545.6661515145931\n",
      "    ess            : 3.7779853703840724\n",
      "    log_marginal   : 1545.7958731021522\n",
      "    val_loss       : -1545.0423990885417\n",
      "    val_ess        : 3.7745376427968345\n",
      "    val_log_marginal: 1545.1776326497395\n",
      "Train Epoch: 1848 [0/54000 (0%)] Loss: -1552.332031\n",
      "Train Epoch: 1848 [32768/54000 (61%)] Loss: -1546.478760\n",
      "    epoch          : 1848\n",
      "    loss           : -1545.6538938126473\n",
      "    ess            : 3.7756762549562275\n",
      "    log_marginal   : 1545.7842165389152\n",
      "    val_loss       : -1544.663106282552\n",
      "    val_ess        : 3.7609872023264566\n",
      "    val_log_marginal: 1544.8038940429688\n",
      "Train Epoch: 1849 [0/54000 (0%)] Loss: -1546.957520\n",
      "Train Epoch: 1849 [32768/54000 (61%)] Loss: -1542.135986\n",
      "    epoch          : 1849\n",
      "    loss           : -1545.716912035672\n",
      "    ess            : 3.780955328131622\n",
      "    log_marginal   : 1545.843625626474\n",
      "    val_loss       : -1544.7503051757812\n",
      "    val_ess        : 3.766991297403971\n",
      "    val_log_marginal: 1544.8866373697917\n",
      "Train Epoch: 1850 [0/54000 (0%)] Loss: -1547.073242\n",
      "Train Epoch: 1850 [32768/54000 (61%)] Loss: -1541.449951\n",
      "    epoch          : 1850\n",
      "    loss           : -1545.6536519752358\n",
      "    ess            : 3.7788858593634838\n",
      "    log_marginal   : 1545.7832998599647\n",
      "    val_loss       : -1544.673583984375\n",
      "    val_ess        : 3.7745333115259805\n",
      "    val_log_marginal: 1544.8094889322917\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1850.pth ...\n",
      "Train Epoch: 1851 [0/54000 (0%)] Loss: -1549.758545\n",
      "Train Epoch: 1851 [32768/54000 (61%)] Loss: -1546.111084\n",
      "    epoch          : 1851\n",
      "    loss           : -1545.6553678692512\n",
      "    ess            : 3.7776479541130787\n",
      "    log_marginal   : 1545.7884774837853\n",
      "    val_loss       : -1545.3084513346355\n",
      "    val_ess        : 3.7756344079971313\n",
      "    val_log_marginal: 1545.4439697265625\n",
      "Train Epoch: 1852 [0/54000 (0%)] Loss: -1550.240479\n",
      "Train Epoch: 1852 [32768/54000 (61%)] Loss: -1546.861816\n",
      "    epoch          : 1852\n",
      "    loss           : -1545.6289361917748\n",
      "    ess            : 3.774948282061883\n",
      "    log_marginal   : 1545.760382886203\n",
      "    val_loss       : -1545.34423828125\n",
      "    val_ess        : 3.774917483329773\n",
      "    val_log_marginal: 1545.4777425130208\n",
      "Train Epoch: 1853 [0/54000 (0%)] Loss: -1547.677490\n",
      "Train Epoch: 1853 [32768/54000 (61%)] Loss: -1543.737915\n",
      "    epoch          : 1853\n",
      "    loss           : -1545.6534285635319\n",
      "    ess            : 3.776928852189262\n",
      "    log_marginal   : 1545.7850871535968\n",
      "    val_loss       : -1545.4195760091145\n",
      "    val_ess        : 3.7807263135910034\n",
      "    val_log_marginal: 1545.5450236002605\n",
      "Train Epoch: 1854 [0/54000 (0%)] Loss: -1547.220459\n",
      "Train Epoch: 1854 [32768/54000 (61%)] Loss: -1546.864746\n",
      "    epoch          : 1854\n",
      "    loss           : -1545.756964917453\n",
      "    ess            : 3.7746332141588317\n",
      "    log_marginal   : 1545.8893352004718\n",
      "    val_loss       : -1544.8816324869792\n",
      "    val_ess        : 3.776323994000753\n",
      "    val_log_marginal: 1545.0101725260417\n",
      "Train Epoch: 1855 [0/54000 (0%)] Loss: -1546.427490\n",
      "Train Epoch: 1855 [32768/54000 (61%)] Loss: -1543.959351\n",
      "    epoch          : 1855\n",
      "    loss           : -1545.751527030513\n",
      "    ess            : 3.7770763163296683\n",
      "    log_marginal   : 1545.8829069317512\n",
      "    val_loss       : -1545.072245279948\n",
      "    val_ess        : 3.7655798196792603\n",
      "    val_log_marginal: 1545.2034098307292\n",
      "Train Epoch: 1856 [0/54000 (0%)] Loss: -1545.319458\n",
      "Train Epoch: 1856 [32768/54000 (61%)] Loss: -1548.919067\n",
      "    epoch          : 1856\n",
      "    loss           : -1545.8886810878537\n",
      "    ess            : 3.77876342467542\n",
      "    log_marginal   : 1546.0187136092277\n",
      "    val_loss       : -1544.9871215820312\n",
      "    val_ess        : 3.793821175893148\n",
      "    val_log_marginal: 1545.106953938802\n",
      "Train Epoch: 1857 [0/54000 (0%)] Loss: -1549.482178\n",
      "Train Epoch: 1857 [32768/54000 (61%)] Loss: -1543.813965\n",
      "    epoch          : 1857\n",
      "    loss           : -1545.8453484301297\n",
      "    ess            : 3.780232272058163\n",
      "    log_marginal   : 1545.9736466317806\n",
      "    val_loss       : -1545.0520629882812\n",
      "    val_ess        : 3.7857977946599326\n",
      "    val_log_marginal: 1545.1783650716145\n",
      "Train Epoch: 1858 [0/54000 (0%)] Loss: -1545.770020\n",
      "Train Epoch: 1858 [32768/54000 (61%)] Loss: -1546.908081\n",
      "    epoch          : 1858\n",
      "    loss           : -1545.7699020673645\n",
      "    ess            : 3.7724538659149744\n",
      "    log_marginal   : 1545.9019084426593\n",
      "    val_loss       : -1544.9044392903645\n",
      "    val_ess        : 3.7955887715021768\n",
      "    val_log_marginal: 1545.019551595052\n",
      "Train Epoch: 1859 [0/54000 (0%)] Loss: -1544.497559\n",
      "Train Epoch: 1859 [32768/54000 (61%)] Loss: -1545.512695\n",
      "    epoch          : 1859\n",
      "    loss           : -1545.8064817032723\n",
      "    ess            : 3.774283098724653\n",
      "    log_marginal   : 1545.9396995688385\n",
      "    val_loss       : -1544.9631754557292\n",
      "    val_ess        : 3.790812333424886\n",
      "    val_log_marginal: 1545.077880859375\n",
      "Train Epoch: 1860 [0/54000 (0%)] Loss: -1543.677002\n",
      "Train Epoch: 1860 [32768/54000 (61%)] Loss: -1543.783691\n",
      "    epoch          : 1860\n",
      "    loss           : -1545.7848222840507\n",
      "    ess            : 3.7768496747286813\n",
      "    log_marginal   : 1545.9128855579304\n",
      "    val_loss       : -1545.1938883463542\n",
      "    val_ess        : 3.7880818843841553\n",
      "    val_log_marginal: 1545.3166097005208\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1860.pth ...\n",
      "Train Epoch: 1861 [0/54000 (0%)] Loss: -1544.471436\n",
      "Train Epoch: 1861 [32768/54000 (61%)] Loss: -1543.943359\n",
      "    epoch          : 1861\n",
      "    loss           : -1545.7768900169517\n",
      "    ess            : 3.7764686773408136\n",
      "    log_marginal   : 1545.9043083910672\n",
      "    val_loss       : -1544.7980346679688\n",
      "    val_ess        : 3.778445323308309\n",
      "    val_log_marginal: 1544.9302775065105\n",
      "Train Epoch: 1862 [0/54000 (0%)] Loss: -1550.135254\n",
      "Train Epoch: 1862 [32768/54000 (61%)] Loss: -1547.075684\n",
      "    epoch          : 1862\n",
      "    loss           : -1545.8117583652713\n",
      "    ess            : 3.778963655795691\n",
      "    log_marginal   : 1545.9421709168632\n",
      "    val_loss       : -1545.099609375\n",
      "    val_ess        : 3.7831687927246094\n",
      "    val_log_marginal: 1545.2252400716145\n",
      "Train Epoch: 1863 [0/54000 (0%)] Loss: -1547.258301\n",
      "Train Epoch: 1863 [32768/54000 (61%)] Loss: -1545.346558\n",
      "    epoch          : 1863\n",
      "    loss           : -1545.8072164283608\n",
      "    ess            : 3.7805127287810705\n",
      "    log_marginal   : 1545.9360835237323\n",
      "    val_loss       : -1545.2296956380208\n",
      "    val_ess        : 3.768764098485311\n",
      "    val_log_marginal: 1545.3727620442708\n",
      "Train Epoch: 1864 [0/54000 (0%)] Loss: -1545.274292\n",
      "Train Epoch: 1864 [32768/54000 (61%)] Loss: -1546.357178\n",
      "    epoch          : 1864\n",
      "    loss           : -1545.8437753353478\n",
      "    ess            : 3.779292533982475\n",
      "    log_marginal   : 1545.9754753832547\n",
      "    val_loss       : -1545.1337890625\n",
      "    val_ess        : 3.782549420992533\n",
      "    val_log_marginal: 1545.259765625\n",
      "Train Epoch: 1865 [0/54000 (0%)] Loss: -1547.843872\n",
      "Train Epoch: 1865 [32768/54000 (61%)] Loss: -1545.295166\n",
      "    epoch          : 1865\n",
      "    loss           : -1545.930357735112\n",
      "    ess            : 3.777883961515607\n",
      "    log_marginal   : 1546.0620669958726\n",
      "    val_loss       : -1545.1413981119792\n",
      "    val_ess        : 3.777968486150106\n",
      "    val_log_marginal: 1545.268046061198\n",
      "Train Epoch: 1866 [0/54000 (0%)] Loss: -1546.095215\n",
      "Train Epoch: 1866 [32768/54000 (61%)] Loss: -1545.009399\n",
      "    epoch          : 1866\n",
      "    loss           : -1545.9230104842277\n",
      "    ess            : 3.7786934825609313\n",
      "    log_marginal   : 1546.0533930940448\n",
      "    val_loss       : -1544.8600463867188\n",
      "    val_ess        : 3.780200640360514\n",
      "    val_log_marginal: 1544.984842936198\n",
      "Train Epoch: 1867 [0/54000 (0%)] Loss: -1547.398682\n",
      "Train Epoch: 1867 [32768/54000 (61%)] Loss: -1542.426514\n",
      "    epoch          : 1867\n",
      "    loss           : -1545.8588798091096\n",
      "    ess            : 3.77660183186801\n",
      "    log_marginal   : 1545.9918374115566\n",
      "    val_loss       : -1544.9294840494792\n",
      "    val_ess        : 3.780509869257609\n",
      "    val_log_marginal: 1545.0635986328125\n",
      "Train Epoch: 1868 [0/54000 (0%)] Loss: -1546.827148\n",
      "Train Epoch: 1868 [32768/54000 (61%)] Loss: -1545.605957\n",
      "    epoch          : 1868\n",
      "    loss           : -1545.8145130085495\n",
      "    ess            : 3.776523032278385\n",
      "    log_marginal   : 1545.9460149801002\n",
      "    val_loss       : -1544.8226114908855\n",
      "    val_ess        : 3.775479316711426\n",
      "    val_log_marginal: 1544.9530436197917\n",
      "Train Epoch: 1869 [0/54000 (0%)] Loss: -1544.366333\n",
      "Train Epoch: 1869 [32768/54000 (61%)] Loss: -1547.772827\n",
      "    epoch          : 1869\n",
      "    loss           : -1545.7021207989387\n",
      "    ess            : 3.7783377575424484\n",
      "    log_marginal   : 1545.8309464364681\n",
      "    val_loss       : -1544.586893717448\n",
      "    val_ess        : 3.765886108080546\n",
      "    val_log_marginal: 1544.7266642252605\n",
      "Train Epoch: 1870 [0/54000 (0%)] Loss: -1546.623535\n",
      "Train Epoch: 1870 [32768/54000 (61%)] Loss: -1547.028809\n",
      "    epoch          : 1870\n",
      "    loss           : -1545.9877077498527\n",
      "    ess            : 3.7816851049099327\n",
      "    log_marginal   : 1546.117800154776\n",
      "    val_loss       : -1545.1311848958333\n",
      "    val_ess        : 3.7702552874883017\n",
      "    val_log_marginal: 1545.2713623046875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1870.pth ...\n",
      "Train Epoch: 1871 [0/54000 (0%)] Loss: -1548.610107\n",
      "Train Epoch: 1871 [32768/54000 (61%)] Loss: -1547.967041\n",
      "    epoch          : 1871\n",
      "    loss           : -1546.1108306308963\n",
      "    ess            : 3.779603958129883\n",
      "    log_marginal   : 1546.2406305277123\n",
      "    val_loss       : -1545.0525512695312\n",
      "    val_ess        : 3.780541976292928\n",
      "    val_log_marginal: 1545.181660970052\n",
      "Train Epoch: 1872 [0/54000 (0%)] Loss: -1548.128906\n",
      "Train Epoch: 1872 [32768/54000 (61%)] Loss: -1546.417480\n",
      "    epoch          : 1872\n",
      "    loss           : -1546.1413896668632\n",
      "    ess            : 3.777690680521839\n",
      "    log_marginal   : 1546.2714337043042\n",
      "    val_loss       : -1545.5005696614583\n",
      "    val_ess        : 3.7838302850723267\n",
      "    val_log_marginal: 1545.633056640625\n",
      "Train Epoch: 1873 [0/54000 (0%)] Loss: -1544.324951\n",
      "Train Epoch: 1873 [32768/54000 (61%)] Loss: -1544.286255\n",
      "    epoch          : 1873\n",
      "    loss           : -1546.0653352557488\n",
      "    ess            : 3.7827912366615153\n",
      "    log_marginal   : 1546.1894991892689\n",
      "    val_loss       : -1545.1888834635417\n",
      "    val_ess        : 3.773190220197042\n",
      "    val_log_marginal: 1545.3271484375\n",
      "Train Epoch: 1874 [0/54000 (0%)] Loss: -1544.380005\n",
      "Train Epoch: 1874 [32768/54000 (61%)] Loss: -1545.967285\n",
      "    epoch          : 1874\n",
      "    loss           : -1546.0509770231427\n",
      "    ess            : 3.7780967343528316\n",
      "    log_marginal   : 1546.1795769457547\n",
      "    val_loss       : -1545.0814005533855\n",
      "    val_ess        : 3.7816532055536904\n",
      "    val_log_marginal: 1545.2074788411458\n",
      "Train Epoch: 1875 [0/54000 (0%)] Loss: -1548.467773\n",
      "Train Epoch: 1875 [32768/54000 (61%)] Loss: -1543.288330\n",
      "    epoch          : 1875\n",
      "    loss           : -1546.0824964991157\n",
      "    ess            : 3.777105929716578\n",
      "    log_marginal   : 1546.2132844744988\n",
      "    val_loss       : -1545.089599609375\n",
      "    val_ess        : 3.7811623414357505\n",
      "    val_log_marginal: 1545.211690266927\n",
      "Train Epoch: 1876 [0/54000 (0%)] Loss: -1547.436279\n",
      "Train Epoch: 1876 [32768/54000 (61%)] Loss: -1545.607666\n",
      "    epoch          : 1876\n",
      "    loss           : -1546.104798514888\n",
      "    ess            : 3.7778355175594114\n",
      "    log_marginal   : 1546.23423450398\n",
      "    val_loss       : -1545.4248860677083\n",
      "    val_ess        : 3.7823458512624106\n",
      "    val_log_marginal: 1545.5590209960938\n",
      "Train Epoch: 1877 [0/54000 (0%)] Loss: -1550.278442\n",
      "Train Epoch: 1877 [32768/54000 (61%)] Loss: -1548.681885\n",
      "    epoch          : 1877\n",
      "    loss           : -1546.1779416642098\n",
      "    ess            : 3.778105231950868\n",
      "    log_marginal   : 1546.3078060510024\n",
      "    val_loss       : -1545.6615600585938\n",
      "    val_ess        : 3.7823503414789834\n",
      "    val_log_marginal: 1545.7938232421875\n",
      "Train Epoch: 1878 [0/54000 (0%)] Loss: -1544.864014\n",
      "Train Epoch: 1878 [32768/54000 (61%)] Loss: -1544.844727\n",
      "    epoch          : 1878\n",
      "    loss           : -1546.1644448334316\n",
      "    ess            : 3.773570618539486\n",
      "    log_marginal   : 1546.2988787956958\n",
      "    val_loss       : -1545.1698201497395\n",
      "    val_ess        : 3.7686574856440225\n",
      "    val_log_marginal: 1545.3053181966145\n",
      "Train Epoch: 1879 [0/54000 (0%)] Loss: -1546.695557\n",
      "Train Epoch: 1879 [32768/54000 (61%)] Loss: -1549.541748\n",
      "    epoch          : 1879\n",
      "    loss           : -1546.0718464401532\n",
      "    ess            : 3.7776906760233753\n",
      "    log_marginal   : 1546.2017937426297\n",
      "    val_loss       : -1545.056640625\n",
      "    val_ess        : 3.7780916690826416\n",
      "    val_log_marginal: 1545.19287109375\n",
      "Train Epoch: 1880 [0/54000 (0%)] Loss: -1547.788330\n",
      "Train Epoch: 1880 [32768/54000 (61%)] Loss: -1546.241333\n",
      "    epoch          : 1880\n",
      "    loss           : -1546.2873051481427\n",
      "    ess            : 3.7790746283981034\n",
      "    log_marginal   : 1546.415771484375\n",
      "    val_loss       : -1545.354268391927\n",
      "    val_ess        : 3.773127555847168\n",
      "    val_log_marginal: 1545.4934488932292\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1880.pth ...\n",
      "Train Epoch: 1881 [0/54000 (0%)] Loss: -1547.205322\n",
      "Train Epoch: 1881 [32768/54000 (61%)] Loss: -1547.664307\n",
      "    epoch          : 1881\n",
      "    loss           : -1546.3139210826946\n",
      "    ess            : 3.776492847586578\n",
      "    log_marginal   : 1546.4436749152417\n",
      "    val_loss       : -1545.7936197916667\n",
      "    val_ess        : 3.787163774172465\n",
      "    val_log_marginal: 1545.926025390625\n",
      "Train Epoch: 1882 [0/54000 (0%)] Loss: -1550.103638\n",
      "Train Epoch: 1882 [32768/54000 (61%)] Loss: -1545.178467\n",
      "    epoch          : 1882\n",
      "    loss           : -1546.2385276938385\n",
      "    ess            : 3.777331824572581\n",
      "    log_marginal   : 1546.36802356648\n",
      "    val_loss       : -1545.2770182291667\n",
      "    val_ess        : 3.770080248514811\n",
      "    val_log_marginal: 1545.4117431640625\n",
      "Train Epoch: 1883 [0/54000 (0%)] Loss: -1546.139648\n",
      "Train Epoch: 1883 [32768/54000 (61%)] Loss: -1543.772095\n",
      "    epoch          : 1883\n",
      "    loss           : -1546.2408792747642\n",
      "    ess            : 3.7831365162471555\n",
      "    log_marginal   : 1546.368449660967\n",
      "    val_loss       : -1545.1836344401042\n",
      "    val_ess        : 3.7824808756510415\n",
      "    val_log_marginal: 1545.3137817382812\n",
      "Train Epoch: 1884 [0/54000 (0%)] Loss: -1545.005371\n",
      "Train Epoch: 1884 [32768/54000 (61%)] Loss: -1547.407715\n",
      "    epoch          : 1884\n",
      "    loss           : -1546.2730390440743\n",
      "    ess            : 3.7791589925873956\n",
      "    log_marginal   : 1546.4043268167748\n",
      "    val_loss       : -1545.4883626302083\n",
      "    val_ess        : 3.787300944328308\n",
      "    val_log_marginal: 1545.606465657552\n",
      "Train Epoch: 1885 [0/54000 (0%)] Loss: -1545.419312\n",
      "Train Epoch: 1885 [32768/54000 (61%)] Loss: -1543.454102\n",
      "    epoch          : 1885\n",
      "    loss           : -1546.3082943322524\n",
      "    ess            : 3.7786398968606627\n",
      "    log_marginal   : 1546.4395245246167\n",
      "    val_loss       : -1545.4462890625\n",
      "    val_ess        : 3.794267018636068\n",
      "    val_log_marginal: 1545.556620279948\n",
      "Train Epoch: 1886 [0/54000 (0%)] Loss: -1546.129150\n",
      "Train Epoch: 1886 [32768/54000 (61%)] Loss: -1548.838013\n",
      "    epoch          : 1886\n",
      "    loss           : -1546.321127837559\n",
      "    ess            : 3.781090461982871\n",
      "    log_marginal   : 1546.4505407945164\n",
      "    val_loss       : -1545.1591796875\n",
      "    val_ess        : 3.7635563611984253\n",
      "    val_log_marginal: 1545.306905110677\n",
      "Train Epoch: 1887 [0/54000 (0%)] Loss: -1548.149658\n",
      "Train Epoch: 1887 [32768/54000 (61%)] Loss: -1545.226929\n",
      "    epoch          : 1887\n",
      "    loss           : -1546.3595385281544\n",
      "    ess            : 3.7768318428183503\n",
      "    log_marginal   : 1546.48870273806\n",
      "    val_loss       : -1545.3416748046875\n",
      "    val_ess        : 3.782030979792277\n",
      "    val_log_marginal: 1545.4626871744792\n",
      "Train Epoch: 1888 [0/54000 (0%)] Loss: -1544.166016\n",
      "Train Epoch: 1888 [32768/54000 (61%)] Loss: -1549.018311\n",
      "    epoch          : 1888\n",
      "    loss           : -1546.282938255454\n",
      "    ess            : 3.781786950129383\n",
      "    log_marginal   : 1546.411434533461\n",
      "    val_loss       : -1545.1551920572917\n",
      "    val_ess        : 3.7752379179000854\n",
      "    val_log_marginal: 1545.2886962890625\n",
      "Train Epoch: 1889 [0/54000 (0%)] Loss: -1547.422485\n",
      "Train Epoch: 1889 [32768/54000 (61%)] Loss: -1545.956299\n",
      "    epoch          : 1889\n",
      "    loss           : -1546.3957542563385\n",
      "    ess            : 3.7763978085427916\n",
      "    log_marginal   : 1546.5273460532135\n",
      "    val_loss       : -1545.1260579427083\n",
      "    val_ess        : 3.7813321352005005\n",
      "    val_log_marginal: 1545.2536214192708\n",
      "Train Epoch: 1890 [0/54000 (0%)] Loss: -1549.515991\n",
      "Train Epoch: 1890 [32768/54000 (61%)] Loss: -1549.070557\n",
      "    epoch          : 1890\n",
      "    loss           : -1546.4881085089917\n",
      "    ess            : 3.779299947450746\n",
      "    log_marginal   : 1546.6170930682488\n",
      "    val_loss       : -1545.2717692057292\n",
      "    val_ess        : 3.792689005533854\n",
      "    val_log_marginal: 1545.3866170247395\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1890.pth ...\n",
      "Train Epoch: 1891 [0/54000 (0%)] Loss: -1547.802002\n",
      "Train Epoch: 1891 [32768/54000 (61%)] Loss: -1548.592041\n",
      "    epoch          : 1891\n",
      "    loss           : -1546.4240400206368\n",
      "    ess            : 3.7771442071446835\n",
      "    log_marginal   : 1546.5553554318985\n",
      "    val_loss       : -1545.7046915690105\n",
      "    val_ess        : 3.7795862356821694\n",
      "    val_log_marginal: 1545.8330891927083\n",
      "Train Epoch: 1892 [0/54000 (0%)] Loss: -1545.081055\n",
      "Train Epoch: 1892 [32768/54000 (61%)] Loss: -1547.608887\n",
      "    epoch          : 1892\n",
      "    loss           : -1546.4862267836086\n",
      "    ess            : 3.7798142883012877\n",
      "    log_marginal   : 1546.616397497789\n",
      "    val_loss       : -1545.5675252278645\n",
      "    val_ess        : 3.7879320780436196\n",
      "    val_log_marginal: 1545.6956176757812\n",
      "Train Epoch: 1893 [0/54000 (0%)] Loss: -1548.558716\n",
      "Train Epoch: 1893 [32768/54000 (61%)] Loss: -1547.341064\n",
      "    epoch          : 1893\n",
      "    loss           : -1546.41022304319\n",
      "    ess            : 3.7767554634022265\n",
      "    log_marginal   : 1546.540485885908\n",
      "    val_loss       : -1545.3087361653645\n",
      "    val_ess        : 3.7863391637802124\n",
      "    val_log_marginal: 1545.4381713867188\n",
      "Train Epoch: 1894 [0/54000 (0%)] Loss: -1547.841309\n",
      "Train Epoch: 1894 [32768/54000 (61%)] Loss: -1548.515137\n",
      "    epoch          : 1894\n",
      "    loss           : -1546.3751750442218\n",
      "    ess            : 3.778216780356641\n",
      "    log_marginal   : 1546.504030623526\n",
      "    val_loss       : -1545.3877563476562\n",
      "    val_ess        : 3.7715024948120117\n",
      "    val_log_marginal: 1545.5321044921875\n",
      "Train Epoch: 1895 [0/54000 (0%)] Loss: -1547.204712\n",
      "Train Epoch: 1895 [32768/54000 (61%)] Loss: -1546.411133\n",
      "    epoch          : 1895\n",
      "    loss           : -1546.3233158903302\n",
      "    ess            : 3.7744722546271556\n",
      "    log_marginal   : 1546.4545184441333\n",
      "    val_loss       : -1545.4981486002605\n",
      "    val_ess        : 3.7880868911743164\n",
      "    val_log_marginal: 1545.6140747070312\n",
      "Train Epoch: 1896 [0/54000 (0%)] Loss: -1548.733643\n",
      "Train Epoch: 1896 [32768/54000 (61%)] Loss: -1550.271851\n",
      "    epoch          : 1896\n",
      "    loss           : -1546.3452217533904\n",
      "    ess            : 3.775284573716937\n",
      "    log_marginal   : 1546.4779812794811\n",
      "    val_loss       : -1545.4288533528645\n",
      "    val_ess        : 3.785554806391398\n",
      "    val_log_marginal: 1545.5628051757812\n",
      "Train Epoch: 1897 [0/54000 (0%)] Loss: -1545.196655\n",
      "Train Epoch: 1897 [32768/54000 (61%)] Loss: -1545.977295\n",
      "    epoch          : 1897\n",
      "    loss           : -1546.3309648621757\n",
      "    ess            : 3.7730814106059523\n",
      "    log_marginal   : 1546.4661957362912\n",
      "    val_loss       : -1545.305155436198\n",
      "    val_ess        : 3.7739237546920776\n",
      "    val_log_marginal: 1545.4353434244792\n",
      "Train Epoch: 1898 [0/54000 (0%)] Loss: -1545.833984\n",
      "Train Epoch: 1898 [32768/54000 (61%)] Loss: -1541.867188\n",
      "    epoch          : 1898\n",
      "    loss           : -1546.3430452166863\n",
      "    ess            : 3.779458756716746\n",
      "    log_marginal   : 1546.4687661224941\n",
      "    val_loss       : -1545.357686360677\n",
      "    val_ess        : 3.7669223149617515\n",
      "    val_log_marginal: 1545.4942830403645\n",
      "Train Epoch: 1899 [0/54000 (0%)] Loss: -1543.771973\n",
      "Train Epoch: 1899 [32768/54000 (61%)] Loss: -1544.870117\n",
      "    epoch          : 1899\n",
      "    loss           : -1546.23834804319\n",
      "    ess            : 3.775276053626582\n",
      "    log_marginal   : 1546.3713033424233\n",
      "    val_loss       : -1545.758768717448\n",
      "    val_ess        : 3.7759742736816406\n",
      "    val_log_marginal: 1545.8834635416667\n",
      "Train Epoch: 1900 [0/54000 (0%)] Loss: -1547.008057\n",
      "Train Epoch: 1900 [32768/54000 (61%)] Loss: -1548.714355\n",
      "    epoch          : 1900\n",
      "    loss           : -1546.3162565411262\n",
      "    ess            : 3.779201885439315\n",
      "    log_marginal   : 1546.4460702572228\n",
      "    val_loss       : -1545.5707600911458\n",
      "    val_ess        : 3.786130746205648\n",
      "    val_log_marginal: 1545.6968790690105\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1900.pth ...\n",
      "Train Epoch: 1901 [0/54000 (0%)] Loss: -1551.002441\n",
      "Train Epoch: 1901 [32768/54000 (61%)] Loss: -1545.644409\n",
      "    epoch          : 1901\n",
      "    loss           : -1546.215336637677\n",
      "    ess            : 3.7791604096034788\n",
      "    log_marginal   : 1546.3434206404777\n",
      "    val_loss       : -1545.6924845377605\n",
      "    val_ess        : 3.7791401942571006\n",
      "    val_log_marginal: 1545.81982421875\n",
      "Train Epoch: 1902 [0/54000 (0%)] Loss: -1546.029297\n",
      "Train Epoch: 1902 [32768/54000 (61%)] Loss: -1547.315918\n",
      "    epoch          : 1902\n",
      "    loss           : -1546.3356910561615\n",
      "    ess            : 3.7793958501995735\n",
      "    log_marginal   : 1546.460573592276\n",
      "    val_loss       : -1545.7287190755208\n",
      "    val_ess        : 3.7764904499053955\n",
      "    val_log_marginal: 1545.8562418619792\n",
      "Train Epoch: 1903 [0/54000 (0%)] Loss: -1546.471436\n",
      "Train Epoch: 1903 [32768/54000 (61%)] Loss: -1547.879150\n",
      "    epoch          : 1903\n",
      "    loss           : -1546.286261792453\n",
      "    ess            : 3.780129504653643\n",
      "    log_marginal   : 1546.413839088296\n",
      "    val_loss       : -1545.5289103190105\n",
      "    val_ess        : 3.7747697035471597\n",
      "    val_log_marginal: 1545.6612752278645\n",
      "Train Epoch: 1904 [0/54000 (0%)] Loss: -1548.163574\n",
      "Train Epoch: 1904 [32768/54000 (61%)] Loss: -1547.112061\n",
      "    epoch          : 1904\n",
      "    loss           : -1546.337287183078\n",
      "    ess            : 3.780808943622517\n",
      "    log_marginal   : 1546.4653043926887\n",
      "    val_loss       : -1545.286865234375\n",
      "    val_ess        : 3.7775621016820273\n",
      "    val_log_marginal: 1545.4111328125\n",
      "Train Epoch: 1905 [0/54000 (0%)] Loss: -1543.723267\n",
      "Train Epoch: 1905 [32768/54000 (61%)] Loss: -1549.622803\n",
      "    epoch          : 1905\n",
      "    loss           : -1546.3703475088444\n",
      "    ess            : 3.77509405927838\n",
      "    log_marginal   : 1546.5032106795402\n",
      "    val_loss       : -1545.544942220052\n",
      "    val_ess        : 3.764574726422628\n",
      "    val_log_marginal: 1545.6902669270833\n",
      "Train Epoch: 1906 [0/54000 (0%)] Loss: -1545.154541\n",
      "Train Epoch: 1906 [32768/54000 (61%)] Loss: -1544.496338\n",
      "    epoch          : 1906\n",
      "    loss           : -1546.3876630675118\n",
      "    ess            : 3.7805013386708386\n",
      "    log_marginal   : 1546.5207197081368\n",
      "    val_loss       : -1545.8113810221355\n",
      "    val_ess        : 3.770569165547689\n",
      "    val_log_marginal: 1545.9517008463542\n",
      "Train Epoch: 1907 [0/54000 (0%)] Loss: -1545.133179\n",
      "Train Epoch: 1907 [32768/54000 (61%)] Loss: -1544.746582\n",
      "    epoch          : 1907\n",
      "    loss           : -1546.3362092791863\n",
      "    ess            : 3.7746745730346105\n",
      "    log_marginal   : 1546.4717142357017\n",
      "    val_loss       : -1545.6839803059895\n",
      "    val_ess        : 3.783157547314962\n",
      "    val_log_marginal: 1545.8081461588542\n",
      "Train Epoch: 1908 [0/54000 (0%)] Loss: -1548.965820\n",
      "Train Epoch: 1908 [32768/54000 (61%)] Loss: -1546.843994\n",
      "    epoch          : 1908\n",
      "    loss           : -1546.4217851746757\n",
      "    ess            : 3.7813381204065286\n",
      "    log_marginal   : 1546.5470270120873\n",
      "    val_loss       : -1545.759012858073\n",
      "    val_ess        : 3.7786001761754355\n",
      "    val_log_marginal: 1545.888651529948\n",
      "Train Epoch: 1909 [0/54000 (0%)] Loss: -1547.899048\n",
      "Train Epoch: 1909 [32768/54000 (61%)] Loss: -1544.170044\n",
      "    epoch          : 1909\n",
      "    loss           : -1546.455868127211\n",
      "    ess            : 3.773887863698995\n",
      "    log_marginal   : 1546.5891550891804\n",
      "    val_loss       : -1545.462890625\n",
      "    val_ess        : 3.7902222871780396\n",
      "    val_log_marginal: 1545.5797119140625\n",
      "Train Epoch: 1910 [0/54000 (0%)] Loss: -1546.135010\n",
      "Train Epoch: 1910 [32768/54000 (61%)] Loss: -1541.536621\n",
      "    epoch          : 1910\n",
      "    loss           : -1546.2893250663326\n",
      "    ess            : 3.7789004523799106\n",
      "    log_marginal   : 1546.4208546764446\n",
      "    val_loss       : -1545.3355305989583\n",
      "    val_ess        : 3.7630163431167603\n",
      "    val_log_marginal: 1545.4778442382812\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1910.pth ...\n",
      "Train Epoch: 1911 [0/54000 (0%)] Loss: -1544.758057\n",
      "Train Epoch: 1911 [32768/54000 (61%)] Loss: -1546.891479\n",
      "    epoch          : 1911\n",
      "    loss           : -1546.3637971698113\n",
      "    ess            : 3.7810510059572615\n",
      "    log_marginal   : 1546.489584868809\n",
      "    val_loss       : -1545.5092163085938\n",
      "    val_ess        : 3.7789144118626914\n",
      "    val_log_marginal: 1545.6297810872395\n",
      "Train Epoch: 1912 [0/54000 (0%)] Loss: -1547.352905\n",
      "Train Epoch: 1912 [32768/54000 (61%)] Loss: -1545.330566\n",
      "    epoch          : 1912\n",
      "    loss           : -1546.3201121204304\n",
      "    ess            : 3.777987097794155\n",
      "    log_marginal   : 1546.453290831368\n",
      "    val_loss       : -1545.443379720052\n",
      "    val_ess        : 3.7704139947891235\n",
      "    val_log_marginal: 1545.5860392252605\n",
      "Train Epoch: 1913 [0/54000 (0%)] Loss: -1549.379761\n",
      "Train Epoch: 1913 [32768/54000 (61%)] Loss: -1545.612061\n",
      "    epoch          : 1913\n",
      "    loss           : -1546.436346090065\n",
      "    ess            : 3.779613692805452\n",
      "    log_marginal   : 1546.5661436836674\n",
      "    val_loss       : -1545.4667358398438\n",
      "    val_ess        : 3.7743184566497803\n",
      "    val_log_marginal: 1545.59765625\n",
      "Train Epoch: 1914 [0/54000 (0%)] Loss: -1544.393799\n",
      "Train Epoch: 1914 [32768/54000 (61%)] Loss: -1547.103027\n",
      "    epoch          : 1914\n",
      "    loss           : -1546.3738506964917\n",
      "    ess            : 3.7752092964244337\n",
      "    log_marginal   : 1546.5089203456662\n",
      "    val_loss       : -1545.5216471354167\n",
      "    val_ess        : 3.792443792025248\n",
      "    val_log_marginal: 1545.645975748698\n",
      "Train Epoch: 1915 [0/54000 (0%)] Loss: -1545.560791\n",
      "Train Epoch: 1915 [32768/54000 (61%)] Loss: -1546.158203\n",
      "    epoch          : 1915\n",
      "    loss           : -1546.3835426186615\n",
      "    ess            : 3.7810782216629892\n",
      "    log_marginal   : 1546.5097564121463\n",
      "    val_loss       : -1545.436279296875\n",
      "    val_ess        : 3.7892339626948037\n",
      "    val_log_marginal: 1545.5504760742188\n",
      "Train Epoch: 1916 [0/54000 (0%)] Loss: -1547.994141\n",
      "Train Epoch: 1916 [32768/54000 (61%)] Loss: -1547.611572\n",
      "    epoch          : 1916\n",
      "    loss           : -1546.3932253279777\n",
      "    ess            : 3.778072037786808\n",
      "    log_marginal   : 1546.5255288178066\n",
      "    val_loss       : -1545.7657674153645\n",
      "    val_ess        : 3.800921638806661\n",
      "    val_log_marginal: 1545.8720296223958\n",
      "Train Epoch: 1917 [0/54000 (0%)] Loss: -1543.172607\n",
      "Train Epoch: 1917 [32768/54000 (61%)] Loss: -1547.507935\n",
      "    epoch          : 1917\n",
      "    loss           : -1546.3658585458431\n",
      "    ess            : 3.776047891041018\n",
      "    log_marginal   : 1546.4962780070755\n",
      "    val_loss       : -1545.481221516927\n",
      "    val_ess        : 3.7823530435562134\n",
      "    val_log_marginal: 1545.6125081380208\n",
      "Train Epoch: 1918 [0/54000 (0%)] Loss: -1546.853638\n",
      "Train Epoch: 1918 [32768/54000 (61%)] Loss: -1549.300659\n",
      "    epoch          : 1918\n",
      "    loss           : -1546.4158175486439\n",
      "    ess            : 3.7761331054399596\n",
      "    log_marginal   : 1546.5465433372642\n",
      "    val_loss       : -1545.6854654947917\n",
      "    val_ess        : 3.7785523335138955\n",
      "    val_log_marginal: 1545.8116455078125\n",
      "Train Epoch: 1919 [0/54000 (0%)] Loss: -1545.847290\n",
      "Train Epoch: 1919 [32768/54000 (61%)] Loss: -1548.070801\n",
      "    epoch          : 1919\n",
      "    loss           : -1546.5834592423348\n",
      "    ess            : 3.7771428126209186\n",
      "    log_marginal   : 1546.7147585311027\n",
      "    val_loss       : -1545.4429117838542\n",
      "    val_ess        : 3.7792977492014566\n",
      "    val_log_marginal: 1545.5747680664062\n",
      "Train Epoch: 1920 [0/54000 (0%)] Loss: -1548.607422\n",
      "Train Epoch: 1920 [32768/54000 (61%)] Loss: -1547.822754\n",
      "    epoch          : 1920\n",
      "    loss           : -1546.5927711342865\n",
      "    ess            : 3.778008222579956\n",
      "    log_marginal   : 1546.7211821933963\n",
      "    val_loss       : -1545.830790201823\n",
      "    val_ess        : 3.770117004712423\n",
      "    val_log_marginal: 1545.9718831380208\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1920.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 1921 [0/54000 (0%)] Loss: -1546.148926\n",
      "Train Epoch: 1921 [32768/54000 (61%)] Loss: -1547.213379\n",
      "    epoch          : 1921\n",
      "    loss           : -1546.6054802660672\n",
      "    ess            : 3.774579399036911\n",
      "    log_marginal   : 1546.7405130638267\n",
      "    val_loss       : -1545.4266560872395\n",
      "    val_ess        : 3.7815223137537637\n",
      "    val_log_marginal: 1545.548319498698\n",
      "Train Epoch: 1922 [0/54000 (0%)] Loss: -1548.159180\n",
      "Train Epoch: 1922 [32768/54000 (61%)] Loss: -1547.195190\n",
      "    epoch          : 1922\n",
      "    loss           : -1546.6144720113502\n",
      "    ess            : 3.7777449634839906\n",
      "    log_marginal   : 1546.7463724388267\n",
      "    val_loss       : -1545.6344807942708\n",
      "    val_ess        : 3.7685150305430093\n",
      "    val_log_marginal: 1545.7830607096355\n",
      "Train Epoch: 1923 [0/54000 (0%)] Loss: -1547.950439\n",
      "Train Epoch: 1923 [32768/54000 (61%)] Loss: -1547.599121\n",
      "    epoch          : 1923\n",
      "    loss           : -1546.578836692954\n",
      "    ess            : 3.7800971112161315\n",
      "    log_marginal   : 1546.7068469929245\n",
      "    val_loss       : -1544.8464965820312\n",
      "    val_ess        : 3.781825065612793\n",
      "    val_log_marginal: 1544.9698282877605\n",
      "Train Epoch: 1924 [0/54000 (0%)] Loss: -1549.967651\n",
      "Train Epoch: 1924 [32768/54000 (61%)] Loss: -1546.537354\n",
      "    epoch          : 1924\n",
      "    loss           : -1546.6317415057488\n",
      "    ess            : 3.778836776625435\n",
      "    log_marginal   : 1546.7637524874706\n",
      "    val_loss       : -1545.4656982421875\n",
      "    val_ess        : 3.778512159983317\n",
      "    val_log_marginal: 1545.5927327473958\n",
      "Train Epoch: 1925 [0/54000 (0%)] Loss: -1546.822632\n",
      "Train Epoch: 1925 [32768/54000 (61%)] Loss: -1549.067871\n",
      "    epoch          : 1925\n",
      "    loss           : -1546.6420460826946\n",
      "    ess            : 3.778087058157291\n",
      "    log_marginal   : 1546.772403357164\n",
      "    val_loss       : -1545.8031209309895\n",
      "    val_ess        : 3.79028590520223\n",
      "    val_log_marginal: 1545.9200642903645\n",
      "Train Epoch: 1926 [0/54000 (0%)] Loss: -1549.026489\n",
      "Train Epoch: 1926 [32768/54000 (61%)] Loss: -1547.137817\n",
      "    epoch          : 1926\n",
      "    loss           : -1546.6054157760907\n",
      "    ess            : 3.7786924659081227\n",
      "    log_marginal   : 1546.7334491081958\n",
      "    val_loss       : -1545.8264770507812\n",
      "    val_ess        : 3.7826143900553384\n",
      "    val_log_marginal: 1545.9523315429688\n",
      "Train Epoch: 1927 [0/54000 (0%)] Loss: -1549.230347\n",
      "Train Epoch: 1927 [32768/54000 (61%)] Loss: -1547.270874\n",
      "    epoch          : 1927\n",
      "    loss           : -1546.535768904776\n",
      "    ess            : 3.7806064182857297\n",
      "    log_marginal   : 1546.6648686247052\n",
      "    val_loss       : -1545.6687418619792\n",
      "    val_ess        : 3.7714800039927163\n",
      "    val_log_marginal: 1545.8055623372395\n",
      "Train Epoch: 1928 [0/54000 (0%)] Loss: -1545.254028\n",
      "Train Epoch: 1928 [32768/54000 (61%)] Loss: -1546.953979\n",
      "    epoch          : 1928\n",
      "    loss           : -1546.512617003243\n",
      "    ess            : 3.779827158406096\n",
      "    log_marginal   : 1546.6413274801002\n",
      "    val_loss       : -1546.1590779622395\n",
      "    val_ess        : 3.7865313291549683\n",
      "    val_log_marginal: 1546.2853190104167\n",
      "Train Epoch: 1929 [0/54000 (0%)] Loss: -1548.698730\n",
      "Train Epoch: 1929 [32768/54000 (61%)] Loss: -1547.140259\n",
      "    epoch          : 1929\n",
      "    loss           : -1546.5129763045402\n",
      "    ess            : 3.7826260170846617\n",
      "    log_marginal   : 1546.6395309736145\n",
      "    val_loss       : -1546.1399332682292\n",
      "    val_ess        : 3.785161773363749\n",
      "    val_log_marginal: 1546.266337076823\n",
      "Train Epoch: 1930 [0/54000 (0%)] Loss: -1546.956665\n",
      "Train Epoch: 1930 [32768/54000 (61%)] Loss: -1545.602661\n",
      "    epoch          : 1930\n",
      "    loss           : -1546.5551158977005\n",
      "    ess            : 3.771552180344204\n",
      "    log_marginal   : 1546.6889556308963\n",
      "    val_loss       : -1545.6802978515625\n",
      "    val_ess        : 3.7712332010269165\n",
      "    val_log_marginal: 1545.8134155273438\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1930.pth ...\n",
      "Train Epoch: 1931 [0/54000 (0%)] Loss: -1550.351196\n",
      "Train Epoch: 1931 [32768/54000 (61%)] Loss: -1546.181152\n",
      "    epoch          : 1931\n",
      "    loss           : -1546.5695662588444\n",
      "    ess            : 3.7751649235779383\n",
      "    log_marginal   : 1546.7008194833431\n",
      "    val_loss       : -1545.975362141927\n",
      "    val_ess        : 3.772865613301595\n",
      "    val_log_marginal: 1546.1168212890625\n",
      "Train Epoch: 1932 [0/54000 (0%)] Loss: -1548.024414\n",
      "Train Epoch: 1932 [32768/54000 (61%)] Loss: -1545.208130\n",
      "    epoch          : 1932\n",
      "    loss           : -1546.5558851709907\n",
      "    ess            : 3.777128615469303\n",
      "    log_marginal   : 1546.6870485701652\n",
      "    val_loss       : -1545.394063313802\n",
      "    val_ess        : 3.781554659207662\n",
      "    val_log_marginal: 1545.5177205403645\n",
      "Train Epoch: 1933 [0/54000 (0%)] Loss: -1546.241577\n",
      "Train Epoch: 1933 [32768/54000 (61%)] Loss: -1546.481934\n",
      "    epoch          : 1933\n",
      "    loss           : -1546.5810984485554\n",
      "    ess            : 3.7775668827992566\n",
      "    log_marginal   : 1546.7089659492924\n",
      "    val_loss       : -1545.8482666015625\n",
      "    val_ess        : 3.774950305620829\n",
      "    val_log_marginal: 1545.9882202148438\n",
      "Train Epoch: 1934 [0/54000 (0%)] Loss: -1547.422852\n",
      "Train Epoch: 1934 [32768/54000 (61%)] Loss: -1549.147949\n",
      "    epoch          : 1934\n",
      "    loss           : -1546.6786510539505\n",
      "    ess            : 3.780055450943281\n",
      "    log_marginal   : 1546.8073431051002\n",
      "    val_loss       : -1545.5628255208333\n",
      "    val_ess        : 3.780174175898234\n",
      "    val_log_marginal: 1545.6917114257812\n",
      "Train Epoch: 1935 [0/54000 (0%)] Loss: -1545.458984\n",
      "Train Epoch: 1935 [32768/54000 (61%)] Loss: -1548.981079\n",
      "    epoch          : 1935\n",
      "    loss           : -1546.625665628685\n",
      "    ess            : 3.7830152601565956\n",
      "    log_marginal   : 1546.7522156913326\n",
      "    val_loss       : -1545.372049967448\n",
      "    val_ess        : 3.7671876748402915\n",
      "    val_log_marginal: 1545.5050862630208\n",
      "Train Epoch: 1936 [0/54000 (0%)] Loss: -1549.190674\n",
      "Train Epoch: 1936 [32768/54000 (61%)] Loss: -1546.766357\n",
      "    epoch          : 1936\n",
      "    loss           : -1546.6895890145931\n",
      "    ess            : 3.7758938726389184\n",
      "    log_marginal   : 1546.8224199403007\n",
      "    val_loss       : -1545.643290201823\n",
      "    val_ess        : 3.781603137652079\n",
      "    val_log_marginal: 1545.7735799153645\n",
      "Train Epoch: 1937 [0/54000 (0%)] Loss: -1547.691040\n",
      "Train Epoch: 1937 [32768/54000 (61%)] Loss: -1548.786865\n",
      "    epoch          : 1937\n",
      "    loss           : -1546.5638588959316\n",
      "    ess            : 3.779166684960419\n",
      "    log_marginal   : 1546.6948610701652\n",
      "    val_loss       : -1545.8639729817708\n",
      "    val_ess        : 3.789596954981486\n",
      "    val_log_marginal: 1545.9845377604167\n",
      "Train Epoch: 1938 [0/54000 (0%)] Loss: -1547.126953\n",
      "Train Epoch: 1938 [32768/54000 (61%)] Loss: -1547.583740\n",
      "    epoch          : 1938\n",
      "    loss           : -1546.7196620725235\n",
      "    ess            : 3.7757047212348795\n",
      "    log_marginal   : 1546.85414440227\n",
      "    val_loss       : -1545.9293009440105\n",
      "    val_ess        : 3.786548376083374\n",
      "    val_log_marginal: 1546.0423583984375\n",
      "Train Epoch: 1939 [0/54000 (0%)] Loss: -1548.782593\n",
      "Train Epoch: 1939 [32768/54000 (61%)] Loss: -1547.631592\n",
      "    epoch          : 1939\n",
      "    loss           : -1546.9084357495578\n",
      "    ess            : 3.7830431146441765\n",
      "    log_marginal   : 1547.0393665241745\n",
      "    val_loss       : -1545.895772298177\n",
      "    val_ess        : 3.7758016188939414\n",
      "    val_log_marginal: 1546.0347086588542\n",
      "Train Epoch: 1940 [0/54000 (0%)] Loss: -1544.992554\n",
      "Train Epoch: 1940 [32768/54000 (61%)] Loss: -1547.115967\n",
      "    epoch          : 1940\n",
      "    loss           : -1546.9591824513561\n",
      "    ess            : 3.781985102959399\n",
      "    log_marginal   : 1547.0852212006191\n",
      "    val_loss       : -1545.893330891927\n",
      "    val_ess        : 3.780909260114034\n",
      "    val_log_marginal: 1546.019999186198\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1940.pth ...\n",
      "Train Epoch: 1941 [0/54000 (0%)] Loss: -1546.846436\n",
      "Train Epoch: 1941 [32768/54000 (61%)] Loss: -1547.410522\n",
      "    epoch          : 1941\n",
      "    loss           : -1546.9558543079304\n",
      "    ess            : 3.7757001912818766\n",
      "    log_marginal   : 1547.090737396816\n",
      "    val_loss       : -1545.7882283528645\n",
      "    val_ess        : 3.780607581138611\n",
      "    val_log_marginal: 1545.9246622721355\n",
      "Train Epoch: 1942 [0/54000 (0%)] Loss: -1544.734497\n",
      "Train Epoch: 1942 [32768/54000 (61%)] Loss: -1546.465454\n",
      "    epoch          : 1942\n",
      "    loss           : -1547.0218183409493\n",
      "    ess            : 3.7821902284082376\n",
      "    log_marginal   : 1547.148806014151\n",
      "    val_loss       : -1546.151143391927\n",
      "    val_ess        : 3.7815428972244263\n",
      "    val_log_marginal: 1546.2752685546875\n",
      "Train Epoch: 1943 [0/54000 (0%)] Loss: -1547.135498\n",
      "Train Epoch: 1943 [32768/54000 (61%)] Loss: -1546.275513\n",
      "    epoch          : 1943\n",
      "    loss           : -1546.8773400648586\n",
      "    ess            : 3.7835004374666035\n",
      "    log_marginal   : 1547.0037795732605\n",
      "    val_loss       : -1546.0238647460938\n",
      "    val_ess        : 3.7903405825297036\n",
      "    val_log_marginal: 1546.1410319010417\n",
      "Train Epoch: 1944 [0/54000 (0%)] Loss: -1548.175781\n",
      "Train Epoch: 1944 [32768/54000 (61%)] Loss: -1545.923828\n",
      "    epoch          : 1944\n",
      "    loss           : -1546.939084610849\n",
      "    ess            : 3.7779524686201564\n",
      "    log_marginal   : 1547.069709058078\n",
      "    val_loss       : -1546.1349487304688\n",
      "    val_ess        : 3.7792540788650513\n",
      "    val_log_marginal: 1546.2728474934895\n",
      "Train Epoch: 1945 [0/54000 (0%)] Loss: -1543.239014\n",
      "Train Epoch: 1945 [32768/54000 (61%)] Loss: -1547.044800\n",
      "    epoch          : 1945\n",
      "    loss           : -1546.8640044590213\n",
      "    ess            : 3.777418222067491\n",
      "    log_marginal   : 1546.99644153523\n",
      "    val_loss       : -1545.935791015625\n",
      "    val_ess        : 3.7776323159535727\n",
      "    val_log_marginal: 1546.0716349283855\n",
      "Train Epoch: 1946 [0/54000 (0%)] Loss: -1549.764282\n",
      "Train Epoch: 1946 [32768/54000 (61%)] Loss: -1548.975464\n",
      "    epoch          : 1946\n",
      "    loss           : -1546.8487710053066\n",
      "    ess            : 3.7775107869562112\n",
      "    log_marginal   : 1546.9809754569576\n",
      "    val_loss       : -1546.380147298177\n",
      "    val_ess        : 3.7978129386901855\n",
      "    val_log_marginal: 1546.4982503255208\n",
      "Train Epoch: 1947 [0/54000 (0%)] Loss: -1546.431885\n",
      "Train Epoch: 1947 [32768/54000 (61%)] Loss: -1549.604858\n",
      "    epoch          : 1947\n",
      "    loss           : -1547.0655287256782\n",
      "    ess            : 3.7810038845494107\n",
      "    log_marginal   : 1547.1908235369988\n",
      "    val_loss       : -1546.0830688476562\n",
      "    val_ess        : 3.77835476398468\n",
      "    val_log_marginal: 1546.21240234375\n",
      "Train Epoch: 1948 [0/54000 (0%)] Loss: -1547.930054\n",
      "Train Epoch: 1948 [32768/54000 (61%)] Loss: -1549.435547\n",
      "    epoch          : 1948\n",
      "    loss           : -1546.9040803729363\n",
      "    ess            : 3.7759729601302237\n",
      "    log_marginal   : 1547.0365450877064\n",
      "    val_loss       : -1546.220458984375\n",
      "    val_ess        : 3.76792041460673\n",
      "    val_log_marginal: 1546.3515014648438\n",
      "Train Epoch: 1949 [0/54000 (0%)] Loss: -1542.648560\n",
      "Train Epoch: 1949 [32768/54000 (61%)] Loss: -1545.188232\n",
      "    epoch          : 1949\n",
      "    loss           : -1546.8840216870578\n",
      "    ess            : 3.7768749111103563\n",
      "    log_marginal   : 1547.0157816185142\n",
      "    val_loss       : -1546.1553548177083\n",
      "    val_ess        : 3.7783881425857544\n",
      "    val_log_marginal: 1546.2862141927083\n",
      "Train Epoch: 1950 [0/54000 (0%)] Loss: -1548.307129\n",
      "Train Epoch: 1950 [32768/54000 (61%)] Loss: -1546.710449\n",
      "    epoch          : 1950\n",
      "    loss           : -1546.925615418632\n",
      "    ess            : 3.7839129465930865\n",
      "    log_marginal   : 1547.0532341723172\n",
      "    val_loss       : -1545.864522298177\n",
      "    val_ess        : 3.779735724131266\n",
      "    val_log_marginal: 1545.9903971354167\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1950.pth ...\n",
      "Train Epoch: 1951 [0/54000 (0%)] Loss: -1548.131348\n",
      "Train Epoch: 1951 [32768/54000 (61%)] Loss: -1549.781494\n",
      "    epoch          : 1951\n",
      "    loss           : -1547.0544779075767\n",
      "    ess            : 3.780306685645625\n",
      "    log_marginal   : 1547.1817281471108\n",
      "    val_loss       : -1545.858133951823\n",
      "    val_ess        : 3.7843153874079385\n",
      "    val_log_marginal: 1545.98193359375\n",
      "Train Epoch: 1952 [0/54000 (0%)] Loss: -1549.026123\n",
      "Train Epoch: 1952 [32768/54000 (61%)] Loss: -1548.091675\n",
      "    epoch          : 1952\n",
      "    loss           : -1546.97907069944\n",
      "    ess            : 3.782193696723794\n",
      "    log_marginal   : 1547.1086448813385\n",
      "    val_loss       : -1545.6774495442708\n",
      "    val_ess        : 3.775877594947815\n",
      "    val_log_marginal: 1545.8146362304688\n",
      "Train Epoch: 1953 [0/54000 (0%)] Loss: -1543.449463\n",
      "Train Epoch: 1953 [32768/54000 (61%)] Loss: -1547.104614\n",
      "    epoch          : 1953\n",
      "    loss           : -1547.046697652565\n",
      "    ess            : 3.78190186788451\n",
      "    log_marginal   : 1547.1733720887382\n",
      "    val_loss       : -1546.0826416015625\n",
      "    val_ess        : 3.7720171213150024\n",
      "    val_log_marginal: 1546.2326253255208\n",
      "Train Epoch: 1954 [0/54000 (0%)] Loss: -1545.834961\n",
      "Train Epoch: 1954 [32768/54000 (61%)] Loss: -1547.808594\n",
      "    epoch          : 1954\n",
      "    loss           : -1546.987797575177\n",
      "    ess            : 3.781782829536582\n",
      "    log_marginal   : 1547.117592865566\n",
      "    val_loss       : -1545.6413167317708\n",
      "    val_ess        : 3.7790739933649697\n",
      "    val_log_marginal: 1545.7645263671875\n",
      "Train Epoch: 1955 [0/54000 (0%)] Loss: -1548.355957\n",
      "Train Epoch: 1955 [32768/54000 (61%)] Loss: -1547.850098\n",
      "    epoch          : 1955\n",
      "    loss           : -1547.086550154776\n",
      "    ess            : 3.778492527187995\n",
      "    log_marginal   : 1547.2187822449882\n",
      "    val_loss       : -1545.8114624023438\n",
      "    val_ess        : 3.774944265683492\n",
      "    val_log_marginal: 1545.944600423177\n",
      "Train Epoch: 1956 [0/54000 (0%)] Loss: -1546.142334\n",
      "Train Epoch: 1956 [32768/54000 (61%)] Loss: -1549.531250\n",
      "    epoch          : 1956\n",
      "    loss           : -1547.075257499263\n",
      "    ess            : 3.7741683069265113\n",
      "    log_marginal   : 1547.2092100899174\n",
      "    val_loss       : -1545.7921346028645\n",
      "    val_ess        : 3.764603018760681\n",
      "    val_log_marginal: 1545.9262084960938\n",
      "Train Epoch: 1957 [0/54000 (0%)] Loss: -1547.705322\n",
      "Train Epoch: 1957 [32768/54000 (61%)] Loss: -1546.852295\n",
      "    epoch          : 1957\n",
      "    loss           : -1547.0740022479363\n",
      "    ess            : 3.7768007854245744\n",
      "    log_marginal   : 1547.2067525611733\n",
      "    val_loss       : -1546.020039876302\n",
      "    val_ess        : 3.790168841679891\n",
      "    val_log_marginal: 1546.145772298177\n",
      "Train Epoch: 1958 [0/54000 (0%)] Loss: -1548.509644\n",
      "Train Epoch: 1958 [32768/54000 (61%)] Loss: -1548.474121\n",
      "    epoch          : 1958\n",
      "    loss           : -1547.0984439489976\n",
      "    ess            : 3.775485358148251\n",
      "    log_marginal   : 1547.2315927181603\n",
      "    val_loss       : -1546.1173909505208\n",
      "    val_ess        : 3.7837388118108115\n",
      "    val_log_marginal: 1546.2432250976562\n",
      "Train Epoch: 1959 [0/54000 (0%)] Loss: -1548.132324\n",
      "Train Epoch: 1959 [32768/54000 (61%)] Loss: -1549.658936\n",
      "    epoch          : 1959\n",
      "    loss           : -1547.1251520120873\n",
      "    ess            : 3.784534364376428\n",
      "    log_marginal   : 1547.2547331036262\n",
      "    val_loss       : -1546.592549641927\n",
      "    val_ess        : 3.773491621017456\n",
      "    val_log_marginal: 1546.7251383463542\n",
      "Train Epoch: 1960 [0/54000 (0%)] Loss: -1548.484741\n",
      "Train Epoch: 1960 [32768/54000 (61%)] Loss: -1545.641479\n",
      "    epoch          : 1960\n",
      "    loss           : -1547.0011907613502\n",
      "    ess            : 3.7803645808741733\n",
      "    log_marginal   : 1547.129150390625\n",
      "    val_loss       : -1546.4846801757812\n",
      "    val_ess        : 3.7787054777145386\n",
      "    val_log_marginal: 1546.6200561523438\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1960.pth ...\n",
      "Train Epoch: 1961 [0/54000 (0%)] Loss: -1548.371948\n",
      "Train Epoch: 1961 [32768/54000 (61%)] Loss: -1546.106812\n",
      "    epoch          : 1961\n",
      "    loss           : -1547.0245937131485\n",
      "    ess            : 3.773522934823666\n",
      "    log_marginal   : 1547.1585370909493\n",
      "    val_loss       : -1545.8731689453125\n",
      "    val_ess        : 3.782217820485433\n",
      "    val_log_marginal: 1546.005594889323\n",
      "Train Epoch: 1962 [0/54000 (0%)] Loss: -1543.794189\n",
      "Train Epoch: 1962 [32768/54000 (61%)] Loss: -1544.705078\n",
      "    epoch          : 1962\n",
      "    loss           : -1546.890053803066\n",
      "    ess            : 3.778022419731572\n",
      "    log_marginal   : 1547.021666328862\n",
      "    val_loss       : -1546.2027791341145\n",
      "    val_ess        : 3.779667297999064\n",
      "    val_log_marginal: 1546.3370971679688\n",
      "Train Epoch: 1963 [0/54000 (0%)] Loss: -1548.915771\n",
      "Train Epoch: 1963 [32768/54000 (61%)] Loss: -1549.249634\n",
      "    epoch          : 1963\n",
      "    loss           : -1546.9057594155365\n",
      "    ess            : 3.779728466609739\n",
      "    log_marginal   : 1547.0344353441922\n",
      "    val_loss       : -1546.2046712239583\n",
      "    val_ess        : 3.787748177846273\n",
      "    val_log_marginal: 1546.3255004882812\n",
      "Train Epoch: 1964 [0/54000 (0%)] Loss: -1545.988525\n",
      "Train Epoch: 1964 [32768/54000 (61%)] Loss: -1549.839722\n",
      "    epoch          : 1964\n",
      "    loss           : -1547.0217630638267\n",
      "    ess            : 3.780027744905004\n",
      "    log_marginal   : 1547.1498079119988\n",
      "    val_loss       : -1546.481953938802\n",
      "    val_ess        : 3.7844040791193643\n",
      "    val_log_marginal: 1546.609883626302\n",
      "Train Epoch: 1965 [0/54000 (0%)] Loss: -1550.454590\n",
      "Train Epoch: 1965 [32768/54000 (61%)] Loss: -1545.269775\n",
      "    epoch          : 1965\n",
      "    loss           : -1547.0058916199882\n",
      "    ess            : 3.7772442439817033\n",
      "    log_marginal   : 1547.1377851378243\n",
      "    val_loss       : -1546.5011189778645\n",
      "    val_ess        : 3.7764366467793784\n",
      "    val_log_marginal: 1546.6370849609375\n",
      "Train Epoch: 1966 [0/54000 (0%)] Loss: -1545.317383\n",
      "Train Epoch: 1966 [32768/54000 (61%)] Loss: -1550.797119\n",
      "    epoch          : 1966\n",
      "    loss           : -1546.985902030513\n",
      "    ess            : 3.774673691335714\n",
      "    log_marginal   : 1547.1196542415978\n",
      "    val_loss       : -1546.2148030598958\n",
      "    val_ess        : 3.781354864438375\n",
      "    val_log_marginal: 1546.3421020507812\n",
      "Train Epoch: 1967 [0/54000 (0%)] Loss: -1549.161743\n",
      "Train Epoch: 1967 [32768/54000 (61%)] Loss: -1549.608032\n",
      "    epoch          : 1967\n",
      "    loss           : -1547.113276643573\n",
      "    ess            : 3.7807652050594114\n",
      "    log_marginal   : 1547.2404186320755\n",
      "    val_loss       : -1546.0465291341145\n",
      "    val_ess        : 3.773205876350403\n",
      "    val_log_marginal: 1546.1872965494792\n",
      "Train Epoch: 1968 [0/54000 (0%)] Loss: -1548.219604\n",
      "Train Epoch: 1968 [32768/54000 (61%)] Loss: -1548.354980\n",
      "    epoch          : 1968\n",
      "    loss           : -1547.10498046875\n",
      "    ess            : 3.778819201127538\n",
      "    log_marginal   : 1547.235591096698\n",
      "    val_loss       : -1546.4393513997395\n",
      "    val_ess        : 3.789300719896952\n",
      "    val_log_marginal: 1546.5591430664062\n",
      "Train Epoch: 1969 [0/54000 (0%)] Loss: -1550.616333\n",
      "Train Epoch: 1969 [32768/54000 (61%)] Loss: -1546.215698\n",
      "    epoch          : 1969\n",
      "    loss           : -1547.0959081109966\n",
      "    ess            : 3.7809403797365584\n",
      "    log_marginal   : 1547.2210578198703\n",
      "    val_loss       : -1546.1837158203125\n",
      "    val_ess        : 3.782490889231364\n",
      "    val_log_marginal: 1546.307637532552\n",
      "Train Epoch: 1970 [0/54000 (0%)] Loss: -1547.836060\n",
      "Train Epoch: 1970 [32768/54000 (61%)] Loss: -1547.823242\n",
      "    epoch          : 1970\n",
      "    loss           : -1547.1919037441037\n",
      "    ess            : 3.774549290818988\n",
      "    log_marginal   : 1547.3264068027713\n",
      "    val_loss       : -1546.4355061848958\n",
      "    val_ess        : 3.7879576285680137\n",
      "    val_log_marginal: 1546.5515950520833\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1970.pth ...\n",
      "Train Epoch: 1971 [0/54000 (0%)] Loss: -1547.708984\n",
      "Train Epoch: 1971 [32768/54000 (61%)] Loss: -1545.408447\n",
      "    epoch          : 1971\n",
      "    loss           : -1547.0113732679836\n",
      "    ess            : 3.775140775824493\n",
      "    log_marginal   : 1547.1444874889446\n",
      "    val_loss       : -1546.2953694661458\n",
      "    val_ess        : 3.771710236867269\n",
      "    val_log_marginal: 1546.4246215820312\n",
      "Train Epoch: 1972 [0/54000 (0%)] Loss: -1547.306152\n",
      "Train Epoch: 1972 [32768/54000 (61%)] Loss: -1549.261963\n",
      "    epoch          : 1972\n",
      "    loss           : -1547.0660054908608\n",
      "    ess            : 3.7796372602570734\n",
      "    log_marginal   : 1547.1989976415093\n",
      "    val_loss       : -1546.3660278320312\n",
      "    val_ess        : 3.7879285415013633\n",
      "    val_log_marginal: 1546.4881591796875\n",
      "Train Epoch: 1973 [0/54000 (0%)] Loss: -1547.526611\n",
      "Train Epoch: 1973 [32768/54000 (61%)] Loss: -1545.508911\n",
      "    epoch          : 1973\n",
      "    loss           : -1546.9929544700767\n",
      "    ess            : 3.7776934290831945\n",
      "    log_marginal   : 1547.1281484927772\n",
      "    val_loss       : -1546.1986287434895\n",
      "    val_ess        : 3.7868031660715737\n",
      "    val_log_marginal: 1546.3211263020833\n",
      "Train Epoch: 1974 [0/54000 (0%)] Loss: -1546.065430\n",
      "Train Epoch: 1974 [32768/54000 (61%)] Loss: -1547.229980\n",
      "    epoch          : 1974\n",
      "    loss           : -1547.1098609780365\n",
      "    ess            : 3.774156777363903\n",
      "    log_marginal   : 1547.2425813494988\n",
      "    val_loss       : -1546.2212524414062\n",
      "    val_ess        : 3.7731325229008994\n",
      "    val_log_marginal: 1546.35302734375\n",
      "Train Epoch: 1975 [0/54000 (0%)] Loss: -1545.629639\n",
      "Train Epoch: 1975 [32768/54000 (61%)] Loss: -1545.742920\n",
      "    epoch          : 1975\n",
      "    loss           : -1547.1953977188973\n",
      "    ess            : 3.777771387460097\n",
      "    log_marginal   : 1547.3250363907723\n",
      "    val_loss       : -1545.7923787434895\n",
      "    val_ess        : 3.7799963553746543\n",
      "    val_log_marginal: 1545.9335327148438\n",
      "Train Epoch: 1976 [0/54000 (0%)] Loss: -1546.407837\n",
      "Train Epoch: 1976 [32768/54000 (61%)] Loss: -1547.594971\n",
      "    epoch          : 1976\n",
      "    loss           : -1547.114386792453\n",
      "    ess            : 3.7742648484571926\n",
      "    log_marginal   : 1547.2494863834022\n",
      "    val_loss       : -1546.0623168945312\n",
      "    val_ess        : 3.7673502763112388\n",
      "    val_log_marginal: 1546.1989339192708\n",
      "Train Epoch: 1977 [0/54000 (0%)] Loss: -1547.242432\n",
      "Train Epoch: 1977 [32768/54000 (61%)] Loss: -1551.337646\n",
      "    epoch          : 1977\n",
      "    loss           : -1547.1044668521522\n",
      "    ess            : 3.7765890562309408\n",
      "    log_marginal   : 1547.2347458173645\n",
      "    val_loss       : -1546.0736287434895\n",
      "    val_ess        : 3.7758339643478394\n",
      "    val_log_marginal: 1546.207010904948\n",
      "Train Epoch: 1978 [0/54000 (0%)] Loss: -1546.412842\n",
      "Train Epoch: 1978 [32768/54000 (61%)] Loss: -1549.929443\n",
      "    epoch          : 1978\n",
      "    loss           : -1546.995854215802\n",
      "    ess            : 3.776505060915677\n",
      "    log_marginal   : 1547.1295995172466\n",
      "    val_loss       : -1546.1354370117188\n",
      "    val_ess        : 3.7693329652150473\n",
      "    val_log_marginal: 1546.2805582682292\n",
      "Train Epoch: 1979 [0/54000 (0%)] Loss: -1548.065918\n",
      "Train Epoch: 1979 [32768/54000 (61%)] Loss: -1546.677979\n",
      "    epoch          : 1979\n",
      "    loss           : -1546.997028854658\n",
      "    ess            : 3.7784877183302394\n",
      "    log_marginal   : 1547.12939453125\n",
      "    val_loss       : -1546.000732421875\n",
      "    val_ess        : 3.7875208059946694\n",
      "    val_log_marginal: 1546.1226806640625\n",
      "Train Epoch: 1980 [0/54000 (0%)] Loss: -1548.983154\n",
      "Train Epoch: 1980 [32768/54000 (61%)] Loss: -1544.307373\n",
      "    epoch          : 1980\n",
      "    loss           : -1547.0791176849941\n",
      "    ess            : 3.778871531756419\n",
      "    log_marginal   : 1547.2090765035377\n",
      "    val_loss       : -1546.299784342448\n",
      "    val_ess        : 3.788276751836141\n",
      "    val_log_marginal: 1546.4324951171875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1980.pth ...\n",
      "Train Epoch: 1981 [0/54000 (0%)] Loss: -1548.080078\n",
      "Train Epoch: 1981 [32768/54000 (61%)] Loss: -1547.124878\n",
      "    epoch          : 1981\n",
      "    loss           : -1547.1327272811027\n",
      "    ess            : 3.779061204982254\n",
      "    log_marginal   : 1547.2636119914505\n",
      "    val_loss       : -1546.0704549153645\n",
      "    val_ess        : 3.7780739068984985\n",
      "    val_log_marginal: 1546.1977132161458\n",
      "Train Epoch: 1982 [0/54000 (0%)] Loss: -1548.635010\n",
      "Train Epoch: 1982 [32768/54000 (61%)] Loss: -1547.545044\n",
      "    epoch          : 1982\n",
      "    loss           : -1547.092596090065\n",
      "    ess            : 3.7764844129670343\n",
      "    log_marginal   : 1547.2232366597877\n",
      "    val_loss       : -1546.4871012369792\n",
      "    val_ess        : 3.7717082103093467\n",
      "    val_log_marginal: 1546.6280924479167\n",
      "Train Epoch: 1983 [0/54000 (0%)] Loss: -1544.601318\n",
      "Train Epoch: 1983 [32768/54000 (61%)] Loss: -1550.023193\n",
      "    epoch          : 1983\n",
      "    loss           : -1547.1663772295105\n",
      "    ess            : 3.773519961339123\n",
      "    log_marginal   : 1547.3008134949882\n",
      "    val_loss       : -1546.3871053059895\n",
      "    val_ess        : 3.7819659312566123\n",
      "    val_log_marginal: 1546.518575032552\n",
      "Train Epoch: 1984 [0/54000 (0%)] Loss: -1549.417114\n",
      "Train Epoch: 1984 [32768/54000 (61%)] Loss: -1544.738403\n",
      "    epoch          : 1984\n",
      "    loss           : -1547.0817134065448\n",
      "    ess            : 3.7740409599160247\n",
      "    log_marginal   : 1547.2128560767983\n",
      "    val_loss       : -1546.0833333333333\n",
      "    val_ess        : 3.757984002431234\n",
      "    val_log_marginal: 1546.2315266927083\n",
      "Train Epoch: 1985 [0/54000 (0%)] Loss: -1546.974854\n",
      "Train Epoch: 1985 [32768/54000 (61%)] Loss: -1546.717285\n",
      "    epoch          : 1985\n",
      "    loss           : -1547.038933520047\n",
      "    ess            : 3.7805177940512604\n",
      "    log_marginal   : 1547.1678190411262\n",
      "    val_loss       : -1546.2519938151042\n",
      "    val_ess        : 3.7718570629755654\n",
      "    val_log_marginal: 1546.389424641927\n",
      "Train Epoch: 1986 [0/54000 (0%)] Loss: -1548.031982\n",
      "Train Epoch: 1986 [32768/54000 (61%)] Loss: -1549.050659\n",
      "    epoch          : 1986\n",
      "    loss           : -1547.0216340838738\n",
      "    ess            : 3.7799844381944188\n",
      "    log_marginal   : 1547.15053112102\n",
      "    val_loss       : -1546.197530110677\n",
      "    val_ess        : 3.7902797857920327\n",
      "    val_log_marginal: 1546.3135172526042\n",
      "Train Epoch: 1987 [0/54000 (0%)] Loss: -1545.384766\n",
      "Train Epoch: 1987 [32768/54000 (61%)] Loss: -1544.990479\n",
      "    epoch          : 1987\n",
      "    loss           : -1546.9758853552476\n",
      "    ess            : 3.781885668916522\n",
      "    log_marginal   : 1547.1055217239093\n",
      "    val_loss       : -1546.550069173177\n",
      "    val_ess        : 3.7762096325556436\n",
      "    val_log_marginal: 1546.6736450195312\n",
      "Train Epoch: 1988 [0/54000 (0%)] Loss: -1550.544678\n",
      "Train Epoch: 1988 [32768/54000 (61%)] Loss: -1545.207520\n",
      "    epoch          : 1988\n",
      "    loss           : -1547.1649308114681\n",
      "    ess            : 3.774657024527496\n",
      "    log_marginal   : 1547.2975129901238\n",
      "    val_loss       : -1546.6810709635417\n",
      "    val_ess        : 3.7713390986124673\n",
      "    val_log_marginal: 1546.8143310546875\n",
      "Train Epoch: 1989 [0/54000 (0%)] Loss: -1547.504272\n",
      "Train Epoch: 1989 [32768/54000 (61%)] Loss: -1543.934082\n",
      "    epoch          : 1989\n",
      "    loss           : -1547.1382549933667\n",
      "    ess            : 3.7738554792584114\n",
      "    log_marginal   : 1547.2735595703125\n",
      "    val_loss       : -1546.8617757161458\n",
      "    val_ess        : 3.8003252347310386\n",
      "    val_log_marginal: 1546.976094563802\n",
      "Train Epoch: 1990 [0/54000 (0%)] Loss: -1549.597290\n",
      "Train Epoch: 1990 [32768/54000 (61%)] Loss: -1549.240234\n",
      "    epoch          : 1990\n",
      "    loss           : -1547.2200835605838\n",
      "    ess            : 3.7818739639138275\n",
      "    log_marginal   : 1547.3498719413326\n",
      "    val_loss       : -1546.5921427408855\n",
      "    val_ess        : 3.7887086073557534\n",
      "    val_log_marginal: 1546.717061360677\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch1990.pth ...\n",
      "Train Epoch: 1991 [0/54000 (0%)] Loss: -1548.479004\n",
      "Train Epoch: 1991 [32768/54000 (61%)] Loss: -1547.154785\n",
      "    epoch          : 1991\n",
      "    loss           : -1547.2432584942512\n",
      "    ess            : 3.7769787356538593\n",
      "    log_marginal   : 1547.374672943691\n",
      "    val_loss       : -1546.8707478841145\n",
      "    val_ess        : 3.7710452874501548\n",
      "    val_log_marginal: 1547.006327311198\n",
      "Train Epoch: 1992 [0/54000 (0%)] Loss: -1547.079834\n",
      "Train Epoch: 1992 [32768/54000 (61%)] Loss: -1545.176514\n",
      "    epoch          : 1992\n",
      "    loss           : -1547.1949831404777\n",
      "    ess            : 3.777068538485833\n",
      "    log_marginal   : 1547.325434846698\n",
      "    val_loss       : -1546.650655110677\n",
      "    val_ess        : 3.7733266750971475\n",
      "    val_log_marginal: 1546.7808634440105\n",
      "Train Epoch: 1993 [0/54000 (0%)] Loss: -1547.266602\n",
      "Train Epoch: 1993 [32768/54000 (61%)] Loss: -1547.091309\n",
      "    epoch          : 1993\n",
      "    loss           : -1547.152302292158\n",
      "    ess            : 3.7798923051582194\n",
      "    log_marginal   : 1547.283161667158\n",
      "    val_loss       : -1546.5054524739583\n",
      "    val_ess        : 3.7839552561442056\n",
      "    val_log_marginal: 1546.634541829427\n",
      "Train Epoch: 1994 [0/54000 (0%)] Loss: -1550.888428\n",
      "Train Epoch: 1994 [32768/54000 (61%)] Loss: -1547.201050\n",
      "    epoch          : 1994\n",
      "    loss           : -1547.210697965802\n",
      "    ess            : 3.7793801190718166\n",
      "    log_marginal   : 1547.3412095555718\n",
      "    val_loss       : -1546.777811686198\n",
      "    val_ess        : 3.772516886393229\n",
      "    val_log_marginal: 1546.9130859375\n",
      "Train Epoch: 1995 [0/54000 (0%)] Loss: -1550.244507\n",
      "Train Epoch: 1995 [32768/54000 (61%)] Loss: -1545.551392\n",
      "    epoch          : 1995\n",
      "    loss           : -1547.3424947486733\n",
      "    ess            : 3.780937284793494\n",
      "    log_marginal   : 1547.4716036814564\n",
      "    val_loss       : -1546.550028483073\n",
      "    val_ess        : 3.7756781578063965\n",
      "    val_log_marginal: 1546.6852010091145\n",
      "Train Epoch: 1996 [0/54000 (0%)] Loss: -1548.959229\n",
      "Train Epoch: 1996 [32768/54000 (61%)] Loss: -1550.560791\n",
      "    epoch          : 1996\n",
      "    loss           : -1547.3893282908314\n",
      "    ess            : 3.778773492237307\n",
      "    log_marginal   : 1547.5179028780956\n",
      "    val_loss       : -1546.5340576171875\n",
      "    val_ess        : 3.780593673388163\n",
      "    val_log_marginal: 1546.6631673177083\n",
      "Train Epoch: 1997 [0/54000 (0%)] Loss: -1547.400269\n",
      "Train Epoch: 1997 [32768/54000 (61%)] Loss: -1546.396362\n",
      "    epoch          : 1997\n",
      "    loss           : -1547.3418129974941\n",
      "    ess            : 3.7775830997610993\n",
      "    log_marginal   : 1547.4711269162735\n",
      "    val_loss       : -1546.5368041992188\n",
      "    val_ess        : 3.773091475168864\n",
      "    val_log_marginal: 1546.669413248698\n",
      "Train Epoch: 1998 [0/54000 (0%)] Loss: -1545.516357\n",
      "Train Epoch: 1998 [32768/54000 (61%)] Loss: -1546.909912\n",
      "    epoch          : 1998\n",
      "    loss           : -1547.2433897774174\n",
      "    ess            : 3.774307903253807\n",
      "    log_marginal   : 1547.3761124520931\n",
      "    val_loss       : -1546.7764689127605\n",
      "    val_ess        : 3.7792828480402627\n",
      "    val_log_marginal: 1546.9007364908855\n",
      "Train Epoch: 1999 [0/54000 (0%)] Loss: -1548.010498\n",
      "Train Epoch: 1999 [32768/54000 (61%)] Loss: -1547.490234\n",
      "    epoch          : 1999\n",
      "    loss           : -1547.2446173901828\n",
      "    ess            : 3.779535599474637\n",
      "    log_marginal   : 1547.3761976709907\n",
      "    val_loss       : -1546.9415079752605\n",
      "    val_ess        : 3.7817891041437783\n",
      "    val_log_marginal: 1547.0675048828125\n",
      "Train Epoch: 2000 [0/54000 (0%)] Loss: -1550.380615\n",
      "Train Epoch: 2000 [32768/54000 (61%)] Loss: -1545.922852\n",
      "    epoch          : 2000\n",
      "    loss           : -1547.269411482901\n",
      "    ess            : 3.7771620255596234\n",
      "    log_marginal   : 1547.400713074882\n",
      "    val_loss       : -1547.00048828125\n",
      "    val_ess        : 3.7856932481129966\n",
      "    val_log_marginal: 1547.1408081054688\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0416_172629/checkpoint-epoch2000.pth ...\n",
      "Saving current best: model_best.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa5b900-0121-4cf6-91b6-2c9b0b12716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParticleDict(\n",
       "    (z1): Parameter containing: [torch.FloatTensor of size 4x6000x20]\n",
       "    (z2): Parameter containing: [torch.FloatTensor of size 4x6000x128]\n",
       "    (z3): Parameter containing: [torch.FloatTensor of size 4x6000x256]\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.eval()\n",
    "trainer.model.cpu()\n",
    "trainer.cpu()\n",
    "trainer.train_particles.cpu()\n",
    "trainer.valid_particles.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d528cb-d45e-4a37-be86-9622aec9ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.graph.clear()\n",
    "trainer._load_particles(range(trainer.data_loader.batch_size), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e26726a6-74e5-4e0f-81d5-746dba00f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in trainer.model.graph.nodes:\n",
    "    trainer.model.graph.nodes[site]['is_observed'] = trainer.model.graph.nodes[site]['value'] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb94c06-7112-4c5e-b781-0ac215a7e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a2eeb8-32e3-467e-9e9a-0ac1e2af9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate_stack(\"forward\", (trainer.num_particles, trainer.data_loader.batch_size)):\n",
    "    model = pyro.condition(trainer.model, data={k: v['value'] for k, v in trainer.model.graph.nodes.items()})\n",
    "    xs = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6e9ba59-7b26-4ef3-9bfd-23f7c8a26464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1509d2-9afc-444e-821f-b7ccda42aa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(xs.mean(dim=0)[i].squeeze().detach().cpu().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2029315-afe9-4ae8-9f64-c342ef8b830b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34a71d-84a2-48f0-8150-3607e77ed6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
