{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ef93e3-8eb5-4883-8265-5fbe97d06e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/ppc_experiments\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94520ed3-45be-4735-a0f2-b8f380838c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import pyro\n",
    "import torch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "import trainer.trainer as module_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac4be4-19eb-4713-a88d-9bec118c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75ea7b9-6fe5-4f8a-a825-3572e421242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1445d1-45bb-43f9-893d-7a2b2bad1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "\n",
    "config = read_json(\"experiments/ppc_mnist_config.json\")\n",
    "config = ConfigParser(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca35026-5f64-47f8-98c7-a5e228013d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistPpc(\n",
      "  (prior): GaussianPrior()\n",
      "  (decoder): ConditionalGaussian(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=400, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (likelihood): MlpBernoulliLikelihood(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=400, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=400, out_features=784, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (graph): GraphicalModel()\n",
      ")\n",
      "Trainable parameters: 438196\n",
      "Initialize particles: train batch 0\n",
      "Initialize particles: train batch 1\n",
      "Initialize particles: train batch 2\n",
      "Initialize particles: train batch 3\n",
      "Initialize particles: train batch 4\n",
      "Initialize particles: train batch 5\n",
      "Initialize particles: train batch 6\n",
      "Initialize particles: train batch 7\n",
      "Initialize particles: train batch 8\n",
      "Initialize particles: train batch 9\n",
      "Initialize particles: train batch 10\n",
      "Initialize particles: train batch 11\n",
      "Initialize particles: train batch 12\n",
      "Initialize particles: train batch 13\n",
      "Initialize particles: train batch 14\n",
      "Initialize particles: train batch 15\n",
      "Initialize particles: train batch 16\n",
      "Initialize particles: train batch 17\n",
      "Initialize particles: train batch 18\n",
      "Initialize particles: train batch 19\n",
      "Initialize particles: train batch 20\n",
      "Initialize particles: train batch 21\n",
      "Initialize particles: train batch 22\n",
      "Initialize particles: train batch 23\n",
      "Initialize particles: train batch 24\n",
      "Initialize particles: train batch 25\n",
      "Initialize particles: train batch 26\n",
      "Initialize particles: train batch 27\n",
      "Initialize particles: train batch 28\n",
      "Initialize particles: train batch 29\n",
      "Initialize particles: train batch 30\n",
      "Initialize particles: train batch 31\n",
      "Initialize particles: train batch 32\n",
      "Initialize particles: train batch 33\n",
      "Initialize particles: train batch 34\n",
      "Initialize particles: train batch 35\n",
      "Initialize particles: train batch 36\n",
      "Initialize particles: train batch 37\n",
      "Initialize particles: train batch 38\n",
      "Initialize particles: train batch 39\n",
      "Initialize particles: train batch 40\n",
      "Initialize particles: train batch 41\n",
      "Initialize particles: train batch 42\n",
      "Initialize particles: train batch 43\n",
      "Initialize particles: train batch 44\n",
      "Initialize particles: train batch 45\n",
      "Initialize particles: train batch 46\n",
      "Initialize particles: train batch 47\n",
      "Initialize particles: train batch 48\n",
      "Initialize particles: train batch 49\n",
      "Initialize particles: train batch 50\n",
      "Initialize particles: train batch 51\n",
      "Initialize particles: train batch 52\n",
      "Initialize particles: train batch 53\n",
      "Initialize particles: train batch 54\n",
      "Initialize particles: train batch 55\n",
      "Initialize particles: train batch 56\n",
      "Initialize particles: train batch 57\n",
      "Initialize particles: train batch 58\n",
      "Initialize particles: train batch 59\n",
      "Initialize particles: train batch 60\n",
      "Initialize particles: train batch 61\n",
      "Initialize particles: train batch 62\n",
      "Initialize particles: train batch 63\n",
      "Initialize particles: train batch 64\n",
      "Initialize particles: train batch 65\n",
      "Initialize particles: train batch 66\n",
      "Initialize particles: train batch 67\n",
      "Initialize particles: train batch 68\n",
      "Initialize particles: train batch 69\n",
      "Initialize particles: train batch 70\n",
      "Initialize particles: train batch 71\n",
      "Initialize particles: train batch 72\n",
      "Initialize particles: train batch 73\n",
      "Initialize particles: train batch 74\n",
      "Initialize particles: train batch 75\n",
      "Initialize particles: train batch 76\n",
      "Initialize particles: train batch 77\n",
      "Initialize particles: train batch 78\n",
      "Initialize particles: train batch 79\n",
      "Initialize particles: train batch 80\n",
      "Initialize particles: train batch 81\n",
      "Initialize particles: train batch 82\n",
      "Initialize particles: train batch 83\n",
      "Initialize particles: train batch 84\n",
      "Initialize particles: train batch 85\n",
      "Initialize particles: train batch 86\n",
      "Initialize particles: train batch 87\n",
      "Initialize particles: train batch 88\n",
      "Initialize particles: train batch 89\n",
      "Initialize particles: train batch 90\n",
      "Initialize particles: train batch 91\n",
      "Initialize particles: train batch 92\n",
      "Initialize particles: train batch 93\n",
      "Initialize particles: train batch 94\n",
      "Initialize particles: train batch 95\n",
      "Initialize particles: train batch 96\n",
      "Initialize particles: train batch 97\n",
      "Initialize particles: train batch 98\n",
      "Initialize particles: train batch 99\n",
      "Initialize particles: train batch 100\n",
      "Initialize particles: train batch 101\n",
      "Initialize particles: train batch 102\n",
      "Initialize particles: train batch 103\n",
      "Initialize particles: train batch 104\n",
      "Initialize particles: train batch 105\n",
      "Initialize particles: valid batch 0\n",
      "Initialize particles: valid batch 1\n",
      "Initialize particles: valid batch 2\n",
      "Initialize particles: valid batch 3\n",
      "Initialize particles: valid batch 4\n",
      "Initialize particles: valid batch 5\n",
      "Initialize particles: valid batch 6\n",
      "Initialize particles: valid batch 7\n",
      "Initialize particles: valid batch 8\n",
      "Initialize particles: valid batch 9\n",
      "Initialize particles: valid batch 10\n",
      "Initialize particles: valid batch 11\n"
     ]
    }
   ],
   "source": [
    "logger = config.get_logger('train')\n",
    "\n",
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()\n",
    "\n",
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)\n",
    "logger.info(model)\n",
    "\n",
    "# get function handles of metrics\n",
    "metrics = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# build optimizer.\n",
    "if \"lr_scheduler\" in config:\n",
    "    lr_scheduler = getattr(pyro.optim, config[\"lr_scheduler\"][\"type\"])\n",
    "    lr_scheduler = optimizer = lr_scheduler({\n",
    "        \"optimizer\": getattr(torch.optim, config[\"optimizer\"][\"type\"]),\n",
    "        \"optim_args\": config[\"optimizer\"][\"args\"][\"optim_args\"],\n",
    "        **config[\"lr_scheduler\"][\"args\"]\n",
    "    })\n",
    "else:\n",
    "    optimizer = config.init_obj('optimizer', pyro.optim)\n",
    "    lr_scheduler = None\n",
    "\n",
    "# build trainer\n",
    "# kwargs = config['trainer'].pop('args')\n",
    "trainer = config.init_obj('trainer', module_trainer, model, metrics, optimizer,\n",
    "                          config=config, data_loader=data_loader,\n",
    "                          valid_data_loader=valid_data_loader,\n",
    "                          lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5cdd31-7fae-4e6f-8fe2-ef5c023919de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved/log/Mnist_Ppc/0321_141154\n"
     ]
    }
   ],
   "source": [
    "logger.info(trainer.config.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9820b982-1a39-4bde-850e-1a1d9a92557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/54000 (0%)] Loss: 250.595062\n",
      "Train Epoch: 1 [11264/54000 (21%)] Loss: -1061.825439\n",
      "Train Epoch: 1 [22528/54000 (42%)] Loss: -1220.863770\n",
      "Train Epoch: 1 [33792/54000 (63%)] Loss: -1327.508667\n",
      "Train Epoch: 1 [45056/54000 (83%)] Loss: -1369.150635\n",
      "    epoch          : 1\n",
      "    loss           : -1199.1422267769867\n",
      "    ess            : 19.040313648727704\n",
      "    log_marginal   : 1200.551682994051\n",
      "    val_loss       : -1400.4387105305989\n",
      "    val_ess        : 19.221043745676678\n",
      "    val_log_marginal: 1401.8160502115886\n",
      "Train Epoch: 2 [0/54000 (0%)] Loss: -1390.848022\n",
      "Train Epoch: 2 [11264/54000 (21%)] Loss: -1402.648438\n",
      "Train Epoch: 2 [22528/54000 (42%)] Loss: -1419.545166\n",
      "Train Epoch: 2 [33792/54000 (63%)] Loss: -1424.437988\n",
      "Train Epoch: 2 [45056/54000 (83%)] Loss: -1428.116455\n",
      "    epoch          : 2\n",
      "    loss           : -1414.7426769328567\n",
      "    ess            : 30.84123170600747\n",
      "    log_marginal   : 1414.8635656968602\n",
      "    val_loss       : -1470.939717610677\n",
      "    val_ess        : 31.09743897120158\n",
      "    val_log_marginal: 1471.0322265625\n",
      "Train Epoch: 3 [0/54000 (0%)] Loss: -1464.339966\n",
      "Train Epoch: 3 [11264/54000 (21%)] Loss: -1477.602539\n",
      "Train Epoch: 3 [22528/54000 (42%)] Loss: -1417.724121\n",
      "Train Epoch: 3 [33792/54000 (63%)] Loss: -1452.354492\n",
      "Train Epoch: 3 [45056/54000 (83%)] Loss: -1396.746338\n",
      "    epoch          : 3\n",
      "    loss           : -1439.2201261700325\n",
      "    ess            : 29.450006395016075\n",
      "    log_marginal   : 1439.3319506375294\n",
      "    val_loss       : -1408.6606852213542\n",
      "    val_ess        : 29.107582410176594\n",
      "    val_log_marginal: 1408.7866821289062\n",
      "Train Epoch: 4 [0/54000 (0%)] Loss: -1388.248779\n",
      "Train Epoch: 4 [11264/54000 (21%)] Loss: -1424.671875\n",
      "Train Epoch: 4 [22528/54000 (42%)] Loss: -1443.183838\n",
      "Train Epoch: 4 [33792/54000 (63%)] Loss: -1465.375488\n",
      "Train Epoch: 4 [45056/54000 (83%)] Loss: -1461.811523\n",
      "    epoch          : 4\n",
      "    loss           : -1442.8187255859375\n",
      "    ess            : 29.42092377284788\n",
      "    log_marginal   : 1442.936738787957\n",
      "    val_loss       : -1486.3805745442708\n",
      "    val_ess        : 29.536948680877686\n",
      "    val_log_marginal: 1486.4963887532551\n",
      "Train Epoch: 5 [0/54000 (0%)] Loss: -1502.645020\n",
      "Train Epoch: 5 [11264/54000 (21%)] Loss: -1532.658203\n",
      "Train Epoch: 5 [22528/54000 (42%)] Loss: -1503.999756\n",
      "Train Epoch: 5 [33792/54000 (63%)] Loss: -1521.957886\n",
      "Train Epoch: 5 [45056/54000 (83%)] Loss: -1525.763184\n",
      "    epoch          : 5\n",
      "    loss           : -1517.1577413307045\n",
      "    ess            : 29.583471945996553\n",
      "    log_marginal   : 1517.2663516638413\n",
      "    val_loss       : -1539.0047912597656\n",
      "    val_ess        : 29.189006805419922\n",
      "    val_log_marginal: 1539.1339009602864\n",
      "Train Epoch: 6 [0/54000 (0%)] Loss: -1547.999512\n",
      "Train Epoch: 6 [11264/54000 (21%)] Loss: -1557.979126\n",
      "Train Epoch: 6 [22528/54000 (42%)] Loss: -1536.637817\n",
      "Train Epoch: 6 [33792/54000 (63%)] Loss: -1558.282593\n",
      "Train Epoch: 6 [45056/54000 (83%)] Loss: -1556.106934\n",
      "    epoch          : 6\n",
      "    loss           : -1551.7359999170844\n",
      "    ess            : 29.130366487323112\n",
      "    log_marginal   : 1551.86788652528\n",
      "    val_loss       : -1565.6476542154949\n",
      "    val_ess        : 28.95291582743327\n",
      "    val_log_marginal: 1565.7854105631511\n",
      "Train Epoch: 7 [0/54000 (0%)] Loss: -1585.426880\n",
      "Train Epoch: 7 [11264/54000 (21%)] Loss: -1585.703979\n",
      "Train Epoch: 7 [22528/54000 (42%)] Loss: -1583.191162\n",
      "Train Epoch: 7 [33792/54000 (63%)] Loss: -1565.802002\n",
      "Train Epoch: 7 [45056/54000 (83%)] Loss: -1513.154297\n",
      "    epoch          : 7\n",
      "    loss           : -1560.874961996978\n",
      "    ess            : 28.900785446166992\n",
      "    log_marginal   : 1561.0185328069722\n",
      "    val_loss       : -1543.0480855305989\n",
      "    val_ess        : 28.833099524180096\n",
      "    val_log_marginal: 1543.2027994791667\n",
      "Train Epoch: 8 [0/54000 (0%)] Loss: -1554.598267\n",
      "Train Epoch: 8 [11264/54000 (21%)] Loss: -1576.752075\n",
      "Train Epoch: 8 [22528/54000 (42%)] Loss: -1576.583618\n",
      "Train Epoch: 8 [33792/54000 (63%)] Loss: -1571.294434\n",
      "Train Epoch: 8 [45056/54000 (83%)] Loss: -1566.887939\n",
      "    epoch          : 8\n",
      "    loss           : -1571.4185341889004\n",
      "    ess            : 28.936545857843363\n",
      "    log_marginal   : 1571.5658373562794\n",
      "    val_loss       : -1560.0419413248699\n",
      "    val_ess        : 29.168620109558105\n",
      "    val_log_marginal: 1560.1856079101562\n",
      "Train Epoch: 9 [0/54000 (0%)] Loss: -1596.105957\n",
      "Train Epoch: 9 [11264/54000 (21%)] Loss: -1586.819580\n",
      "Train Epoch: 9 [22528/54000 (42%)] Loss: -1584.549316\n",
      "Train Epoch: 9 [33792/54000 (63%)] Loss: -1586.805664\n",
      "Train Epoch: 9 [45056/54000 (83%)] Loss: -1594.535889\n",
      "    epoch          : 9\n",
      "    loss           : -1588.3307472085053\n",
      "    ess            : 28.98295708422391\n",
      "    log_marginal   : 1588.4767479086822\n",
      "    val_loss       : -1596.9703979492188\n",
      "    val_ess        : 29.12003231048584\n",
      "    val_log_marginal: 1597.1006978352864\n",
      "Train Epoch: 10 [0/54000 (0%)] Loss: -1601.886841\n",
      "Train Epoch: 10 [11264/54000 (21%)] Loss: -1619.691650\n",
      "Train Epoch: 10 [22528/54000 (42%)] Loss: -1613.197266\n",
      "Train Epoch: 10 [33792/54000 (63%)] Loss: -1621.022705\n",
      "Train Epoch: 10 [45056/54000 (83%)] Loss: -1619.077148\n",
      "    epoch          : 10\n",
      "    loss           : -1614.8486305092865\n",
      "    ess            : 28.930919485272103\n",
      "    log_marginal   : 1614.9928427642246\n",
      "    val_loss       : -1617.9165649414062\n",
      "    val_ess        : 28.826999187469482\n",
      "    val_log_marginal: 1618.0573832194011\n",
      "Train Epoch: 11 [0/54000 (0%)] Loss: -1628.528931\n",
      "Train Epoch: 11 [11264/54000 (21%)] Loss: -1637.659790\n",
      "Train Epoch: 11 [22528/54000 (42%)] Loss: -1631.004517\n",
      "Train Epoch: 11 [33792/54000 (63%)] Loss: -1635.495117\n",
      "Train Epoch: 11 [45056/54000 (83%)] Loss: -1627.265381\n",
      "    epoch          : 11\n",
      "    loss           : -1629.4661047593602\n",
      "    ess            : 28.60880013231961\n",
      "    log_marginal   : 1629.6253201466686\n",
      "    val_loss       : -1623.9068400065105\n",
      "    val_ess        : 28.495579878489178\n",
      "    val_log_marginal: 1624.0744527180989\n",
      "Train Epoch: 12 [0/54000 (0%)] Loss: -1626.011841\n",
      "Train Epoch: 12 [11264/54000 (21%)] Loss: -1639.771606\n",
      "Train Epoch: 12 [22528/54000 (42%)] Loss: -1622.297241\n",
      "Train Epoch: 12 [33792/54000 (63%)] Loss: -1628.172974\n",
      "Train Epoch: 12 [45056/54000 (83%)] Loss: -1627.875000\n",
      "    epoch          : 12\n",
      "    loss           : -1629.9245202406398\n",
      "    ess            : 28.495483236492806\n",
      "    log_marginal   : 1630.091230284493\n",
      "    val_loss       : -1629.8444722493489\n",
      "    val_ess        : 28.50070333480835\n",
      "    val_log_marginal: 1630.0052185058594\n",
      "Train Epoch: 13 [0/54000 (0%)] Loss: -1636.375610\n",
      "Train Epoch: 13 [11264/54000 (21%)] Loss: -1650.154907\n",
      "Train Epoch: 13 [22528/54000 (42%)] Loss: -1632.559570\n",
      "Train Epoch: 13 [33792/54000 (63%)] Loss: -1627.349487\n",
      "Train Epoch: 13 [45056/54000 (83%)] Loss: -1631.241943\n",
      "    epoch          : 13\n",
      "    loss           : -1636.1734204562206\n",
      "    ess            : 28.617364577527315\n",
      "    log_marginal   : 1636.3351440429688\n",
      "    val_loss       : -1626.7435404459636\n",
      "    val_ess        : 28.681644916534424\n",
      "    val_log_marginal: 1626.9007568359375\n",
      "Train Epoch: 14 [0/54000 (0%)] Loss: -1641.896484\n",
      "Train Epoch: 14 [11264/54000 (21%)] Loss: -1652.407715\n",
      "Train Epoch: 14 [22528/54000 (42%)] Loss: -1650.284912\n",
      "Train Epoch: 14 [33792/54000 (63%)] Loss: -1653.829468\n",
      "Train Epoch: 14 [45056/54000 (83%)] Loss: -1644.515137\n",
      "    epoch          : 14\n",
      "    loss           : -1647.684383752211\n",
      "    ess            : 28.58513130331939\n",
      "    log_marginal   : 1647.8453023658608\n",
      "    val_loss       : -1636.5258687337239\n",
      "    val_ess        : 28.725371678670246\n",
      "    val_log_marginal: 1636.6831563313801\n",
      "Train Epoch: 15 [0/54000 (0%)] Loss: -1647.489258\n",
      "Train Epoch: 15 [11264/54000 (21%)] Loss: -1646.534912\n",
      "Train Epoch: 15 [22528/54000 (42%)] Loss: -1659.166870\n",
      "Train Epoch: 15 [33792/54000 (63%)] Loss: -1661.738892\n",
      "Train Epoch: 15 [45056/54000 (83%)] Loss: -1663.121338\n",
      "    epoch          : 15\n",
      "    loss           : -1656.4617459279186\n",
      "    ess            : 28.32700759959671\n",
      "    log_marginal   : 1656.633262778228\n",
      "    val_loss       : -1648.861836751302\n",
      "    val_ess        : 28.64465093612671\n",
      "    val_log_marginal: 1649.0223185221355\n",
      "Train Epoch: 16 [0/54000 (0%)] Loss: -1670.160889\n",
      "Train Epoch: 16 [11264/54000 (21%)] Loss: -1665.334473\n",
      "Train Epoch: 16 [22528/54000 (42%)] Loss: -1666.457275\n",
      "Train Epoch: 16 [33792/54000 (63%)] Loss: -1666.198364\n",
      "Train Epoch: 16 [45056/54000 (83%)] Loss: -1665.398804\n",
      "    epoch          : 16\n",
      "    loss           : -1666.6648559570312\n",
      "    ess            : 28.043347610617584\n",
      "    log_marginal   : 1666.8487007572967\n",
      "    val_loss       : -1666.646708170573\n",
      "    val_ess        : 28.39974037806193\n",
      "    val_log_marginal: 1666.8152872721355\n",
      "Train Epoch: 17 [0/54000 (0%)] Loss: -1678.494385\n",
      "Train Epoch: 17 [11264/54000 (21%)] Loss: -1677.773682\n",
      "Train Epoch: 17 [22528/54000 (42%)] Loss: -1674.625732\n",
      "Train Epoch: 17 [33792/54000 (63%)] Loss: -1615.701172\n",
      "Train Epoch: 17 [45056/54000 (83%)] Loss: -1649.931152\n",
      "    epoch          : 17\n",
      "    loss           : -1652.1635028191333\n",
      "    ess            : 27.280015999416136\n",
      "    log_marginal   : 1652.3711087208874\n",
      "    val_loss       : -1523.1853434244792\n",
      "    val_ess        : 27.481982072194416\n",
      "    val_log_marginal: 1523.3800964355469\n",
      "Train Epoch: 18 [0/54000 (0%)] Loss: -1517.767334\n",
      "Train Epoch: 18 [11264/54000 (21%)] Loss: -1596.979980\n",
      "Train Epoch: 18 [22528/54000 (42%)] Loss: -1619.205566\n",
      "Train Epoch: 18 [33792/54000 (63%)] Loss: -1637.688477\n",
      "Train Epoch: 18 [45056/54000 (83%)] Loss: -1626.432251\n",
      "    epoch          : 18\n",
      "    loss           : -1613.0741012861145\n",
      "    ess            : 27.279740783403504\n",
      "    log_marginal   : 1613.2750670235112\n",
      "    val_loss       : -1563.3544413248699\n",
      "    val_ess        : 29.240277131398518\n",
      "    val_log_marginal: 1563.4668884277344\n",
      "Train Epoch: 19 [0/54000 (0%)] Loss: -1622.296509\n",
      "Train Epoch: 19 [11264/54000 (21%)] Loss: -1655.346436\n",
      "Train Epoch: 19 [22528/54000 (42%)] Loss: -1656.741211\n",
      "Train Epoch: 19 [33792/54000 (63%)] Loss: -1659.727539\n",
      "Train Epoch: 19 [45056/54000 (83%)] Loss: -1655.313965\n",
      "    epoch          : 19\n",
      "    loss           : -1653.1950706625885\n",
      "    ess            : 27.99368953704834\n",
      "    log_marginal   : 1653.3599174067658\n",
      "    val_loss       : -1649.3445332845051\n",
      "    val_ess        : 28.50200080871582\n",
      "    val_log_marginal: 1649.4834391276042\n",
      "Train Epoch: 20 [0/54000 (0%)] Loss: -1673.042114\n",
      "Train Epoch: 20 [11264/54000 (21%)] Loss: -1670.937256\n",
      "Train Epoch: 20 [22528/54000 (42%)] Loss: -1667.616943\n",
      "Train Epoch: 20 [33792/54000 (63%)] Loss: -1649.817871\n",
      "Train Epoch: 20 [45056/54000 (83%)] Loss: -1657.380737\n",
      "    epoch          : 20\n",
      "    loss           : -1664.0121920603626\n",
      "    ess            : 27.227007380071676\n",
      "    log_marginal   : 1664.2088623046875\n",
      "    val_loss       : -1659.0760599772136\n",
      "    val_ess        : 27.33762836456299\n",
      "    val_log_marginal: 1659.2698465983074\n",
      "Train Epoch: 21 [0/54000 (0%)] Loss: -1667.678711\n",
      "Train Epoch: 21 [11264/54000 (21%)] Loss: -1671.001465\n",
      "Train Epoch: 21 [22528/54000 (42%)] Loss: -1677.220703\n",
      "Train Epoch: 21 [33792/54000 (63%)] Loss: -1666.064941\n",
      "Train Epoch: 21 [45056/54000 (83%)] Loss: -1667.349487\n",
      "    epoch          : 21\n",
      "    loss           : -1669.7790101249263\n",
      "    ess            : 27.006015003852124\n",
      "    log_marginal   : 1669.9843312389446\n",
      "    val_loss       : -1668.8128458658855\n",
      "    val_ess        : 27.22724994023641\n",
      "    val_log_marginal: 1669.012919108073\n",
      "Train Epoch: 22 [0/54000 (0%)] Loss: -1679.005981\n",
      "Train Epoch: 22 [11264/54000 (21%)] Loss: -1674.856689\n",
      "Train Epoch: 22 [22528/54000 (42%)] Loss: -1674.667236\n",
      "Train Epoch: 22 [33792/54000 (63%)] Loss: -1671.930420\n",
      "Train Epoch: 22 [45056/54000 (83%)] Loss: -1661.202148\n",
      "    epoch          : 22\n",
      "    loss           : -1670.409841861365\n",
      "    ess            : 26.89640590379823\n",
      "    log_marginal   : 1670.622794673128\n",
      "    val_loss       : -1633.2352701822917\n",
      "    val_ess        : 26.98975944519043\n",
      "    val_log_marginal: 1633.4407653808594\n",
      "Train Epoch: 23 [0/54000 (0%)] Loss: -1649.335571\n",
      "Train Epoch: 23 [11264/54000 (21%)] Loss: -1653.943481\n",
      "Train Epoch: 23 [22528/54000 (42%)] Loss: -1666.063232\n",
      "Train Epoch: 23 [33792/54000 (63%)] Loss: -1672.628174\n",
      "Train Epoch: 23 [45056/54000 (83%)] Loss: -1681.204956\n",
      "    epoch          : 23\n",
      "    loss           : -1665.7210854584316\n",
      "    ess            : 27.05828141266445\n",
      "    log_marginal   : 1665.9322164283608\n",
      "    val_loss       : -1639.0834248860676\n",
      "    val_ess        : 27.980305353800457\n",
      "    val_log_marginal: 1639.253641764323\n",
      "Train Epoch: 24 [0/54000 (0%)] Loss: -1669.475098\n",
      "Train Epoch: 24 [11264/54000 (21%)] Loss: -1680.662598\n",
      "Train Epoch: 24 [22528/54000 (42%)] Loss: -1677.168945\n",
      "Train Epoch: 24 [33792/54000 (63%)] Loss: -1676.040283\n",
      "Train Epoch: 24 [45056/54000 (83%)] Loss: -1668.406494\n",
      "    epoch          : 24\n",
      "    loss           : -1676.1575513155956\n",
      "    ess            : 27.14832791742289\n",
      "    log_marginal   : 1676.3604598135319\n",
      "    val_loss       : -1659.3226114908855\n",
      "    val_ess        : 27.667368412017822\n",
      "    val_log_marginal: 1659.5139567057292\n",
      "Train Epoch: 25 [0/54000 (0%)] Loss: -1678.643188\n",
      "Train Epoch: 25 [11264/54000 (21%)] Loss: -1667.710449\n",
      "Train Epoch: 25 [22528/54000 (42%)] Loss: -1675.717041\n",
      "Train Epoch: 25 [33792/54000 (63%)] Loss: -1675.040405\n",
      "Train Epoch: 25 [45056/54000 (83%)] Loss: -1688.854126\n",
      "    epoch          : 25\n",
      "    loss           : -1675.8464919756043\n",
      "    ess            : 26.893846709773225\n",
      "    log_marginal   : 1676.0656968602593\n",
      "    val_loss       : -1672.5244445800781\n",
      "    val_ess        : 27.301221529642742\n",
      "    val_log_marginal: 1672.720723470052\n",
      "Train Epoch: 26 [0/54000 (0%)] Loss: -1683.545410\n",
      "Train Epoch: 26 [11264/54000 (21%)] Loss: -1687.002686\n",
      "Train Epoch: 26 [22528/54000 (42%)] Loss: -1692.684326\n",
      "Train Epoch: 26 [33792/54000 (63%)] Loss: -1686.166992\n",
      "Train Epoch: 26 [45056/54000 (83%)] Loss: -1686.073120\n",
      "    epoch          : 26\n",
      "    loss           : -1686.625745089549\n",
      "    ess            : 27.021127664817953\n",
      "    log_marginal   : 1686.8359674417748\n",
      "    val_loss       : -1683.9114685058594\n",
      "    val_ess        : 26.78679370880127\n",
      "    val_log_marginal: 1684.1357828776042\n",
      "Train Epoch: 27 [0/54000 (0%)] Loss: -1696.479004\n",
      "Train Epoch: 27 [11264/54000 (21%)] Loss: -1690.685303\n",
      "Train Epoch: 27 [22528/54000 (42%)] Loss: -1690.255981\n",
      "Train Epoch: 27 [33792/54000 (63%)] Loss: -1693.433594\n",
      "Train Epoch: 27 [45056/54000 (83%)] Loss: -1689.431274\n",
      "    epoch          : 27\n",
      "    loss           : -1692.221622107164\n",
      "    ess            : 26.6266597711815\n",
      "    log_marginal   : 1692.4511108398438\n",
      "    val_loss       : -1686.9427388509114\n",
      "    val_ess        : 26.61912965774536\n",
      "    val_log_marginal: 1687.1717020670574\n",
      "Train Epoch: 28 [0/54000 (0%)] Loss: -1695.507568\n",
      "Train Epoch: 28 [11264/54000 (21%)] Loss: -1622.141357\n",
      "Train Epoch: 28 [22528/54000 (42%)] Loss: -1662.798828\n",
      "Train Epoch: 28 [33792/54000 (63%)] Loss: -1643.081055\n",
      "Train Epoch: 28 [45056/54000 (83%)] Loss: -1648.046387\n",
      "    epoch          : 28\n",
      "    loss           : -1652.8564545253537\n",
      "    ess            : 26.40243102019688\n",
      "    log_marginal   : 1653.0941162109375\n",
      "    val_loss       : -1669.1210123697917\n",
      "    val_ess        : 26.67492898305257\n",
      "    val_log_marginal: 1669.3631490071614\n",
      "Train Epoch: 29 [0/54000 (0%)] Loss: -1673.587646\n",
      "Train Epoch: 29 [11264/54000 (21%)] Loss: -1681.516113\n",
      "Train Epoch: 29 [22528/54000 (42%)] Loss: -1672.406982\n",
      "Train Epoch: 29 [33792/54000 (63%)] Loss: -1675.473755\n",
      "Train Epoch: 29 [45056/54000 (83%)] Loss: -1682.334351\n",
      "    epoch          : 29\n",
      "    loss           : -1677.65289882444\n",
      "    ess            : 27.565952750871766\n",
      "    log_marginal   : 1677.8426882186027\n",
      "    val_loss       : -1683.0738016764324\n",
      "    val_ess        : 27.08276065190633\n",
      "    val_log_marginal: 1683.2758687337239\n",
      "Train Epoch: 30 [0/54000 (0%)] Loss: -1688.881348\n",
      "Train Epoch: 30 [11264/54000 (21%)] Loss: -1695.326416\n",
      "Train Epoch: 30 [22528/54000 (42%)] Loss: -1691.105103\n",
      "Train Epoch: 30 [33792/54000 (63%)] Loss: -1688.668457\n",
      "Train Epoch: 30 [45056/54000 (83%)] Loss: -1689.007080\n",
      "    epoch          : 30\n",
      "    loss           : -1689.6615865455483\n",
      "    ess            : 26.836996276423616\n",
      "    log_marginal   : 1689.8794475051593\n",
      "    val_loss       : -1689.6910298665364\n",
      "    val_ess        : 26.417065779368084\n",
      "    val_log_marginal: 1689.9294738769531\n",
      "Train Epoch: 31 [0/54000 (0%)] Loss: -1700.323975\n",
      "Train Epoch: 31 [11264/54000 (21%)] Loss: -1696.756470\n",
      "Train Epoch: 31 [22528/54000 (42%)] Loss: -1691.292725\n",
      "Train Epoch: 31 [33792/54000 (63%)] Loss: -1695.776367\n",
      "Train Epoch: 31 [45056/54000 (83%)] Loss: -1689.578491\n",
      "    epoch          : 31\n",
      "    loss           : -1694.206092690522\n",
      "    ess            : 26.39779780045995\n",
      "    log_marginal   : 1694.4449670179836\n",
      "    val_loss       : -1693.7128601074219\n",
      "    val_ess        : 26.233269532521565\n",
      "    val_log_marginal: 1693.9666137695312\n",
      "Train Epoch: 32 [0/54000 (0%)] Loss: -1701.657593\n",
      "Train Epoch: 32 [11264/54000 (21%)] Loss: -1695.035645\n",
      "Train Epoch: 32 [22528/54000 (42%)] Loss: -1701.411255\n",
      "Train Epoch: 32 [33792/54000 (63%)] Loss: -1698.606689\n",
      "Train Epoch: 32 [45056/54000 (83%)] Loss: -1702.389648\n",
      "    epoch          : 32\n",
      "    loss           : -1696.9703380656692\n",
      "    ess            : 26.30909549065356\n",
      "    log_marginal   : 1697.2129205667748\n",
      "    val_loss       : -1695.7390441894531\n",
      "    val_ess        : 26.265775680541992\n",
      "    val_log_marginal: 1695.9842325846355\n",
      "Train Epoch: 33 [0/54000 (0%)] Loss: -1699.079590\n",
      "Train Epoch: 33 [11264/54000 (21%)] Loss: -1697.955444\n",
      "Train Epoch: 33 [22528/54000 (42%)] Loss: -1704.208496\n",
      "Train Epoch: 33 [33792/54000 (63%)] Loss: -1694.071045\n",
      "Train Epoch: 33 [45056/54000 (83%)] Loss: -1700.254150\n",
      "    epoch          : 33\n",
      "    loss           : -1699.1024031729069\n",
      "    ess            : 26.362155320509423\n",
      "    log_marginal   : 1699.3465725880749\n",
      "    val_loss       : -1697.7612202962239\n",
      "    val_ess        : 26.304773648579914\n",
      "    val_log_marginal: 1698.0093892415364\n",
      "Train Epoch: 34 [0/54000 (0%)] Loss: -1697.737793\n",
      "Train Epoch: 34 [11264/54000 (21%)] Loss: -1702.642578\n",
      "Train Epoch: 34 [22528/54000 (42%)] Loss: -1704.644897\n",
      "Train Epoch: 34 [33792/54000 (63%)] Loss: -1700.230469\n",
      "Train Epoch: 34 [45056/54000 (83%)] Loss: -1699.903564\n",
      "    epoch          : 34\n",
      "    loss           : -1700.1487622530956\n",
      "    ess            : 26.267219867346423\n",
      "    log_marginal   : 1700.3986090894016\n",
      "    val_loss       : -1689.7469889322917\n",
      "    val_ess        : 26.244712670644123\n",
      "    val_log_marginal: 1689.9938557942708\n",
      "Train Epoch: 35 [0/54000 (0%)] Loss: -1703.197266\n",
      "Train Epoch: 35 [11264/54000 (21%)] Loss: -1667.313232\n",
      "Train Epoch: 35 [22528/54000 (42%)] Loss: -1695.518188\n",
      "Train Epoch: 35 [33792/54000 (63%)] Loss: -1658.614990\n",
      "Train Epoch: 35 [45056/54000 (83%)] Loss: -1691.040283\n",
      "    epoch          : 35\n",
      "    loss           : -1677.3414548478036\n",
      "    ess            : 26.34998380912925\n",
      "    log_marginal   : 1677.5863728073407\n",
      "    val_loss       : -1676.2718607584636\n",
      "    val_ess        : 26.87871487935384\n",
      "    val_log_marginal: 1676.4992370605469\n",
      "Train Epoch: 36 [0/54000 (0%)] Loss: -1678.170898\n",
      "Train Epoch: 36 [11264/54000 (21%)] Loss: -1689.250488\n",
      "Train Epoch: 36 [22528/54000 (42%)] Loss: -1691.823730\n",
      "Train Epoch: 36 [33792/54000 (63%)] Loss: -1694.148926\n",
      "Train Epoch: 36 [45056/54000 (83%)] Loss: -1692.959717\n",
      "    epoch          : 36\n",
      "    loss           : -1691.5127828346108\n",
      "    ess            : 27.127747391754728\n",
      "    log_marginal   : 1691.7236639058815\n",
      "    val_loss       : -1687.1615905761719\n",
      "    val_ess        : 27.295323212941486\n",
      "    val_log_marginal: 1687.3587341308594\n",
      "Train Epoch: 37 [0/54000 (0%)] Loss: -1697.972900\n",
      "Train Epoch: 37 [11264/54000 (21%)] Loss: -1700.442627\n",
      "Train Epoch: 37 [22528/54000 (42%)] Loss: -1694.764648\n",
      "Train Epoch: 37 [33792/54000 (63%)] Loss: -1695.429443\n",
      "Train Epoch: 37 [45056/54000 (83%)] Loss: -1700.868164\n",
      "    epoch          : 37\n",
      "    loss           : -1699.5757780255012\n",
      "    ess            : 26.69744095712338\n",
      "    log_marginal   : 1699.8042498894458\n",
      "    val_loss       : -1697.6554565429688\n",
      "    val_ess        : 26.709216753641766\n",
      "    val_log_marginal: 1697.8834431966145\n",
      "Train Epoch: 38 [0/54000 (0%)] Loss: -1706.038330\n",
      "Train Epoch: 38 [11264/54000 (21%)] Loss: -1703.980713\n",
      "Train Epoch: 38 [22528/54000 (42%)] Loss: -1703.073486\n",
      "Train Epoch: 38 [33792/54000 (63%)] Loss: -1703.250000\n",
      "Train Epoch: 38 [45056/54000 (83%)] Loss: -1704.185547\n",
      "    epoch          : 38\n",
      "    loss           : -1702.9394634894604\n",
      "    ess            : 26.43012541644978\n",
      "    log_marginal   : 1703.179481362397\n",
      "    val_loss       : -1700.7344767252605\n",
      "    val_ess        : 26.423347632090252\n",
      "    val_log_marginal: 1700.9678039550781\n",
      "Train Epoch: 39 [0/54000 (0%)] Loss: -1704.032715\n",
      "Train Epoch: 39 [11264/54000 (21%)] Loss: -1704.371460\n",
      "Train Epoch: 39 [22528/54000 (42%)] Loss: -1704.609619\n",
      "Train Epoch: 39 [33792/54000 (63%)] Loss: -1705.026123\n",
      "Train Epoch: 39 [45056/54000 (83%)] Loss: -1708.182495\n",
      "    epoch          : 39\n",
      "    loss           : -1704.843290508918\n",
      "    ess            : 26.252960600942934\n",
      "    log_marginal   : 1705.0950593768425\n",
      "    val_loss       : -1702.9130554199219\n",
      "    val_ess        : 26.310789744059246\n",
      "    val_log_marginal: 1703.1595357259114\n",
      "Train Epoch: 40 [0/54000 (0%)] Loss: -1710.546387\n",
      "Train Epoch: 40 [11264/54000 (21%)] Loss: -1707.294800\n",
      "Train Epoch: 40 [22528/54000 (42%)] Loss: -1706.746094\n",
      "Train Epoch: 40 [33792/54000 (63%)] Loss: -1707.917480\n",
      "Train Epoch: 40 [45056/54000 (83%)] Loss: -1703.153198\n",
      "    epoch          : 40\n",
      "    loss           : -1706.4361065558667\n",
      "    ess            : 26.264153804419177\n",
      "    log_marginal   : 1706.6875437610554\n",
      "    val_loss       : -1704.4546305338542\n",
      "    val_ess        : 26.10690927505493\n",
      "    val_log_marginal: 1704.70263671875\n",
      "Train Epoch: 41 [0/54000 (0%)] Loss: -1704.708008\n",
      "Train Epoch: 41 [11264/54000 (21%)] Loss: -1707.135742\n",
      "Train Epoch: 41 [22528/54000 (42%)] Loss: -1707.587158\n",
      "Train Epoch: 41 [33792/54000 (63%)] Loss: -1710.357178\n",
      "Train Epoch: 41 [45056/54000 (83%)] Loss: -1707.509277\n",
      "    epoch          : 41\n",
      "    loss           : -1707.2832917987175\n",
      "    ess            : 26.24994211376838\n",
      "    log_marginal   : 1707.5355051868366\n",
      "    val_loss       : -1699.4883117675781\n",
      "    val_ess        : 26.227964719136555\n",
      "    val_log_marginal: 1699.7486572265625\n",
      "Train Epoch: 42 [0/54000 (0%)] Loss: -1709.055542\n",
      "Train Epoch: 42 [11264/54000 (21%)] Loss: -1631.930176\n",
      "Train Epoch: 42 [22528/54000 (42%)] Loss: -1634.052002\n",
      "Train Epoch: 42 [33792/54000 (63%)] Loss: -1633.772095\n",
      "Train Epoch: 42 [45056/54000 (83%)] Loss: -1645.200684\n",
      "    epoch          : 42\n",
      "    loss           : -1646.180304761203\n",
      "    ess            : 26.28223172673639\n",
      "    log_marginal   : 1646.4341787662147\n",
      "    val_loss       : -1650.40283203125\n",
      "    val_ess        : 26.47368319829305\n",
      "    val_log_marginal: 1650.6664225260417\n",
      "Train Epoch: 43 [0/54000 (0%)] Loss: -1667.911865\n",
      "Train Epoch: 43 [11264/54000 (21%)] Loss: -1672.028809\n",
      "Train Epoch: 43 [22528/54000 (42%)] Loss: -1674.521606\n",
      "Train Epoch: 43 [33792/54000 (63%)] Loss: -1676.405640\n",
      "Train Epoch: 43 [45056/54000 (83%)] Loss: -1667.384277\n",
      "    epoch          : 43\n",
      "    loss           : -1670.9056120098762\n",
      "    ess            : 27.855442712891776\n",
      "    log_marginal   : 1671.0894556585347\n",
      "    val_loss       : -1683.0509948730469\n",
      "    val_ess        : 28.172878742218018\n",
      "    val_log_marginal: 1683.2146402994792\n",
      "Train Epoch: 44 [0/54000 (0%)] Loss: -1693.411011\n",
      "Train Epoch: 44 [11264/54000 (21%)] Loss: -1695.037842\n",
      "Train Epoch: 44 [22528/54000 (42%)] Loss: -1695.949951\n",
      "Train Epoch: 44 [33792/54000 (63%)] Loss: -1701.581787\n",
      "Train Epoch: 44 [45056/54000 (83%)] Loss: -1696.922607\n",
      "    epoch          : 44\n",
      "    loss           : -1694.9097197910526\n",
      "    ess            : 27.23098380610628\n",
      "    log_marginal   : 1695.1171230100235\n",
      "    val_loss       : -1697.4783426920574\n",
      "    val_ess        : 26.925504366556805\n",
      "    val_log_marginal: 1697.7023518880208\n",
      "Train Epoch: 45 [0/54000 (0%)] Loss: -1703.876953\n",
      "Train Epoch: 45 [11264/54000 (21%)] Loss: -1710.115479\n",
      "Train Epoch: 45 [22528/54000 (42%)] Loss: -1701.613525\n",
      "Train Epoch: 45 [33792/54000 (63%)] Loss: -1694.998535\n",
      "Train Epoch: 45 [45056/54000 (83%)] Loss: -1697.178589\n",
      "    epoch          : 45\n",
      "    loss           : -1702.2349519549675\n",
      "    ess            : 26.530821080477732\n",
      "    log_marginal   : 1702.4731007701946\n",
      "    val_loss       : -1702.813212076823\n",
      "    val_ess        : 26.35360352198283\n",
      "    val_log_marginal: 1703.0641174316406\n",
      "Train Epoch: 46 [0/54000 (0%)] Loss: -1705.499756\n",
      "Train Epoch: 46 [11264/54000 (21%)] Loss: -1706.954346\n",
      "Train Epoch: 46 [22528/54000 (42%)] Loss: -1704.548340\n",
      "Train Epoch: 46 [33792/54000 (63%)] Loss: -1705.646606\n",
      "Train Epoch: 46 [45056/54000 (83%)] Loss: -1708.802979\n",
      "    epoch          : 46\n",
      "    loss           : -1706.015232302108\n",
      "    ess            : 26.292056425562446\n",
      "    log_marginal   : 1706.268741247789\n",
      "    val_loss       : -1705.275634765625\n",
      "    val_ess        : 26.246002515157063\n",
      "    val_log_marginal: 1705.5427347819011\n",
      "Train Epoch: 47 [0/54000 (0%)] Loss: -1712.865723\n",
      "Train Epoch: 47 [11264/54000 (21%)] Loss: -1708.604980\n",
      "Train Epoch: 47 [22528/54000 (42%)] Loss: -1710.207642\n",
      "Train Epoch: 47 [33792/54000 (63%)] Loss: -1707.615845\n",
      "Train Epoch: 47 [45056/54000 (83%)] Loss: -1707.554565\n",
      "    epoch          : 47\n",
      "    loss           : -1708.4440468842129\n",
      "    ess            : 26.22535833322777\n",
      "    log_marginal   : 1708.7017948942364\n",
      "    val_loss       : -1707.6145324707031\n",
      "    val_ess        : 26.296139240264893\n",
      "    val_log_marginal: 1707.8670756022136\n",
      "Train Epoch: 48 [0/54000 (0%)] Loss: -1706.470947\n",
      "Train Epoch: 48 [11264/54000 (21%)] Loss: -1718.755005\n",
      "Train Epoch: 48 [22528/54000 (42%)] Loss: -1705.726196\n",
      "Train Epoch: 48 [33792/54000 (63%)] Loss: -1709.218628\n",
      "Train Epoch: 48 [45056/54000 (83%)] Loss: -1712.201050\n",
      "    epoch          : 48\n",
      "    loss           : -1709.8651986751916\n",
      "    ess            : 26.23493694809248\n",
      "    log_marginal   : 1710.1224710716392\n",
      "    val_loss       : -1707.9671732584636\n",
      "    val_ess        : 26.403371969858807\n",
      "    val_log_marginal: 1708.2151285807292\n",
      "Train Epoch: 49 [0/54000 (0%)] Loss: -1708.605591\n",
      "Train Epoch: 49 [11264/54000 (21%)] Loss: -1704.491211\n",
      "Train Epoch: 49 [22528/54000 (42%)] Loss: -1670.936157\n",
      "Train Epoch: 49 [33792/54000 (63%)] Loss: -1700.576538\n",
      "Train Epoch: 49 [45056/54000 (83%)] Loss: -1689.312256\n",
      "    epoch          : 49\n",
      "    loss           : -1695.8767228036556\n",
      "    ess            : 26.33735014357657\n",
      "    log_marginal   : 1696.1325464788472\n",
      "    val_loss       : -1696.6681111653645\n",
      "    val_ess        : 26.312754313151043\n",
      "    val_log_marginal: 1696.9258931477864\n",
      "Train Epoch: 50 [0/54000 (0%)] Loss: -1693.962524\n",
      "Train Epoch: 50 [11264/54000 (21%)] Loss: -1705.503174\n",
      "Train Epoch: 50 [22528/54000 (42%)] Loss: -1698.545044\n",
      "Train Epoch: 50 [33792/54000 (63%)] Loss: -1704.458252\n",
      "Train Epoch: 50 [45056/54000 (83%)] Loss: -1707.809082\n",
      "    epoch          : 50\n",
      "    loss           : -1704.4238096992924\n",
      "    ess            : 26.87658752585357\n",
      "    log_marginal   : 1704.6531832713001\n",
      "    val_loss       : -1706.4710184733074\n",
      "    val_ess        : 26.759300231933594\n",
      "    val_log_marginal: 1706.7037048339844\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch50.pth ...\n",
      "Train Epoch: 51 [0/54000 (0%)] Loss: -1713.349609\n",
      "Train Epoch: 51 [11264/54000 (21%)] Loss: -1708.587158\n",
      "Train Epoch: 51 [22528/54000 (42%)] Loss: -1709.245850\n",
      "Train Epoch: 51 [33792/54000 (63%)] Loss: -1711.380371\n",
      "Train Epoch: 51 [45056/54000 (83%)] Loss: -1702.135986\n",
      "    epoch          : 51\n",
      "    loss           : -1710.5367339512088\n",
      "    ess            : 26.48993346376239\n",
      "    log_marginal   : 1710.7807214125148\n",
      "    val_loss       : -1710.5745951334636\n",
      "    val_ess        : 26.272272904713947\n",
      "    val_log_marginal: 1710.8316548665364\n",
      "Train Epoch: 52 [0/54000 (0%)] Loss: -1714.174805\n",
      "Train Epoch: 52 [11264/54000 (21%)] Loss: -1711.211060\n",
      "Train Epoch: 52 [22528/54000 (42%)] Loss: -1718.107422\n",
      "Train Epoch: 52 [33792/54000 (63%)] Loss: -1714.990967\n",
      "Train Epoch: 52 [45056/54000 (83%)] Loss: -1711.143311\n",
      "    epoch          : 52\n",
      "    loss           : -1712.86181640625\n",
      "    ess            : 26.263414041051323\n",
      "    log_marginal   : 1713.1198338922466\n",
      "    val_loss       : -1712.5646158854167\n",
      "    val_ess        : 26.08665148417155\n",
      "    val_log_marginal: 1712.8274027506511\n",
      "Train Epoch: 53 [0/54000 (0%)] Loss: -1715.078491\n",
      "Train Epoch: 53 [11264/54000 (21%)] Loss: -1712.352051\n",
      "Train Epoch: 53 [22528/54000 (42%)] Loss: -1711.249878\n",
      "Train Epoch: 53 [33792/54000 (63%)] Loss: -1709.633301\n",
      "Train Epoch: 53 [45056/54000 (83%)] Loss: -1655.243408\n",
      "    epoch          : 53\n",
      "    loss           : -1698.580309597951\n",
      "    ess            : 26.275435357723595\n",
      "    log_marginal   : 1698.8362530402417\n",
      "    val_loss       : -1697.8074340820312\n",
      "    val_ess        : 26.28755458196004\n",
      "    val_log_marginal: 1698.0552978515625\n",
      "Train Epoch: 54 [0/54000 (0%)] Loss: -1683.727783\n",
      "Train Epoch: 54 [11264/54000 (21%)] Loss: -1698.797485\n",
      "Train Epoch: 54 [22528/54000 (42%)] Loss: -1701.576904\n",
      "Train Epoch: 54 [33792/54000 (63%)] Loss: -1662.764893\n",
      "Train Epoch: 54 [45056/54000 (83%)] Loss: -1684.008057\n",
      "    epoch          : 54\n",
      "    loss           : -1689.0886691111439\n",
      "    ess            : 26.73604270647157\n",
      "    log_marginal   : 1689.324103589328\n",
      "    val_loss       : -1688.4730326334636\n",
      "    val_ess        : 26.64048957824707\n",
      "    val_log_marginal: 1688.7074076334636\n",
      "Train Epoch: 55 [0/54000 (0%)] Loss: -1699.529541\n",
      "Train Epoch: 55 [11264/54000 (21%)] Loss: -1696.528320\n",
      "Train Epoch: 55 [22528/54000 (42%)] Loss: -1702.720703\n",
      "Train Epoch: 55 [33792/54000 (63%)] Loss: -1703.751221\n",
      "Train Epoch: 55 [45056/54000 (83%)] Loss: -1706.790039\n",
      "    epoch          : 55\n",
      "    loss           : -1702.0745170161408\n",
      "    ess            : 27.12842473443949\n",
      "    log_marginal   : 1702.290771484375\n",
      "    val_loss       : -1703.2403767903645\n",
      "    val_ess        : 27.35781701405843\n",
      "    val_log_marginal: 1703.4418131510417\n",
      "Train Epoch: 56 [0/54000 (0%)] Loss: -1711.294800\n",
      "Train Epoch: 56 [11264/54000 (21%)] Loss: -1710.435791\n",
      "Train Epoch: 56 [22528/54000 (42%)] Loss: -1711.249756\n",
      "Train Epoch: 56 [33792/54000 (63%)] Loss: -1707.743042\n",
      "Train Epoch: 56 [45056/54000 (83%)] Loss: -1712.966919\n",
      "    epoch          : 56\n",
      "    loss           : -1710.1476947136646\n",
      "    ess            : 26.628506750430702\n",
      "    log_marginal   : 1710.388448463296\n",
      "    val_loss       : -1711.0818990071614\n",
      "    val_ess        : 26.455567359924316\n",
      "    val_log_marginal: 1711.3293762207031\n",
      "Train Epoch: 57 [0/54000 (0%)] Loss: -1715.215332\n",
      "Train Epoch: 57 [11264/54000 (21%)] Loss: -1715.287842\n",
      "Train Epoch: 57 [22528/54000 (42%)] Loss: -1719.829590\n",
      "Train Epoch: 57 [33792/54000 (63%)] Loss: -1716.057495\n",
      "Train Epoch: 57 [45056/54000 (83%)] Loss: -1712.246704\n",
      "    epoch          : 57\n",
      "    loss           : -1713.4693948997642\n",
      "    ess            : 26.241655565657705\n",
      "    log_marginal   : 1713.7293021723908\n",
      "    val_loss       : -1713.7095336914062\n",
      "    val_ess        : 26.127882957458496\n",
      "    val_log_marginal: 1713.9732157389324\n",
      "Train Epoch: 58 [0/54000 (0%)] Loss: -1715.940063\n",
      "Train Epoch: 58 [11264/54000 (21%)] Loss: -1716.799683\n",
      "Train Epoch: 58 [22528/54000 (42%)] Loss: -1717.104004\n",
      "Train Epoch: 58 [33792/54000 (63%)] Loss: -1710.508423\n",
      "Train Epoch: 58 [45056/54000 (83%)] Loss: -1708.615967\n",
      "    epoch          : 58\n",
      "    loss           : -1715.4180286335495\n",
      "    ess            : 26.26729339023806\n",
      "    log_marginal   : 1715.6777539523143\n",
      "    val_loss       : -1715.2967834472656\n",
      "    val_ess        : 26.16600815455119\n",
      "    val_log_marginal: 1715.5555521647136\n",
      "Train Epoch: 59 [0/54000 (0%)] Loss: -1714.588745\n",
      "Train Epoch: 59 [11264/54000 (21%)] Loss: -1713.688965\n",
      "Train Epoch: 59 [22528/54000 (42%)] Loss: -1715.307495\n",
      "Train Epoch: 59 [33792/54000 (63%)] Loss: -1715.833008\n",
      "Train Epoch: 59 [45056/54000 (83%)] Loss: -1710.938721\n",
      "    epoch          : 59\n",
      "    loss           : -1716.0114285451061\n",
      "    ess            : 26.123766917102742\n",
      "    log_marginal   : 1716.2785713627654\n",
      "    val_loss       : -1712.3748474121094\n",
      "    val_ess        : 26.2163880666097\n",
      "    val_log_marginal: 1712.6392822265625\n",
      "Train Epoch: 60 [0/54000 (0%)] Loss: -1711.708862\n",
      "Train Epoch: 60 [11264/54000 (21%)] Loss: -1666.583740\n",
      "Train Epoch: 60 [22528/54000 (42%)] Loss: -1668.570923\n",
      "Train Epoch: 60 [33792/54000 (63%)] Loss: -1687.218018\n",
      "Train Epoch: 60 [45056/54000 (83%)] Loss: -1686.237793\n",
      "    epoch          : 60\n",
      "    loss           : -1679.5532456883843\n",
      "    ess            : 26.26828159476226\n",
      "    log_marginal   : 1679.8170465433373\n",
      "    val_loss       : -1695.456787109375\n",
      "    val_ess        : 26.338003794352215\n",
      "    val_log_marginal: 1695.7271830240886\n",
      "Train Epoch: 61 [0/54000 (0%)] Loss: -1689.970459\n",
      "Train Epoch: 61 [11264/54000 (21%)] Loss: -1701.626953\n",
      "Train Epoch: 61 [22528/54000 (42%)] Loss: -1696.514282\n",
      "Train Epoch: 61 [33792/54000 (63%)] Loss: -1703.169678\n",
      "Train Epoch: 61 [45056/54000 (83%)] Loss: -1707.661377\n",
      "    epoch          : 61\n",
      "    loss           : -1702.450592616819\n",
      "    ess            : 27.500004066611236\n",
      "    log_marginal   : 1702.6566956718013\n",
      "    val_loss       : -1710.5321146647136\n",
      "    val_ess        : 27.125786781311035\n",
      "    val_log_marginal: 1710.7508850097656\n",
      "Train Epoch: 62 [0/54000 (0%)] Loss: -1712.042725\n",
      "Train Epoch: 62 [11264/54000 (21%)] Loss: -1712.250488\n",
      "Train Epoch: 62 [22528/54000 (42%)] Loss: -1710.595581\n",
      "Train Epoch: 62 [33792/54000 (63%)] Loss: -1715.013916\n",
      "Train Epoch: 62 [45056/54000 (83%)] Loss: -1710.923340\n",
      "    epoch          : 62\n",
      "    loss           : -1713.135105348983\n",
      "    ess            : 26.721744465378094\n",
      "    log_marginal   : 1713.3760571749706\n",
      "    val_loss       : -1716.2192993164062\n",
      "    val_ess        : 26.37463076909383\n",
      "    val_log_marginal: 1716.472900390625\n",
      "Train Epoch: 63 [0/54000 (0%)] Loss: -1722.205566\n",
      "Train Epoch: 63 [11264/54000 (21%)] Loss: -1714.831421\n",
      "Train Epoch: 63 [22528/54000 (42%)] Loss: -1715.763916\n",
      "Train Epoch: 63 [33792/54000 (63%)] Loss: -1719.345093\n",
      "Train Epoch: 63 [45056/54000 (83%)] Loss: -1716.915039\n",
      "    epoch          : 63\n",
      "    loss           : -1716.7875320146668\n",
      "    ess            : 26.24187361519292\n",
      "    log_marginal   : 1717.054927034198\n",
      "    val_loss       : -1718.4754536946614\n",
      "    val_ess        : 26.51909637451172\n",
      "    val_log_marginal: 1718.7202860514324\n",
      "Train Epoch: 64 [0/54000 (0%)] Loss: -1718.417725\n",
      "Train Epoch: 64 [11264/54000 (21%)] Loss: -1719.871826\n",
      "Train Epoch: 64 [22528/54000 (42%)] Loss: -1722.259277\n",
      "Train Epoch: 64 [33792/54000 (63%)] Loss: -1719.071289\n",
      "Train Epoch: 64 [45056/54000 (83%)] Loss: -1722.448242\n",
      "    epoch          : 64\n",
      "    loss           : -1718.7576075140034\n",
      "    ess            : 26.208197521713544\n",
      "    log_marginal   : 1719.024248231132\n",
      "    val_loss       : -1720.078592936198\n",
      "    val_ess        : 26.523527304331463\n",
      "    val_log_marginal: 1720.332743326823\n",
      "Train Epoch: 65 [0/54000 (0%)] Loss: -1719.605957\n",
      "Train Epoch: 65 [11264/54000 (21%)] Loss: -1723.452148\n",
      "Train Epoch: 65 [22528/54000 (42%)] Loss: -1722.717041\n",
      "Train Epoch: 65 [33792/54000 (63%)] Loss: -1718.583008\n",
      "Train Epoch: 65 [45056/54000 (83%)] Loss: -1724.964722\n",
      "    epoch          : 65\n",
      "    loss           : -1720.2935917692364\n",
      "    ess            : 26.137671092771136\n",
      "    log_marginal   : 1720.566087254938\n",
      "    val_loss       : -1720.9583740234375\n",
      "    val_ess        : 26.162860870361328\n",
      "    val_log_marginal: 1721.2276306152344\n",
      "Train Epoch: 66 [0/54000 (0%)] Loss: -1726.378174\n",
      "Train Epoch: 66 [11264/54000 (21%)] Loss: -1718.576416\n",
      "Train Epoch: 66 [22528/54000 (42%)] Loss: -1720.804810\n",
      "Train Epoch: 66 [33792/54000 (63%)] Loss: -1690.151367\n",
      "Train Epoch: 66 [45056/54000 (83%)] Loss: -1708.403564\n",
      "    epoch          : 66\n",
      "    loss           : -1711.6038115879276\n",
      "    ess            : 26.235746185734587\n",
      "    log_marginal   : 1711.8709371314858\n",
      "    val_loss       : -1713.0671488444011\n",
      "    val_ess        : 26.14852253595988\n",
      "    val_log_marginal: 1713.3404337565105\n",
      "Train Epoch: 67 [0/54000 (0%)] Loss: -1712.100952\n",
      "Train Epoch: 67 [11264/54000 (21%)] Loss: -1715.363403\n",
      "Train Epoch: 67 [22528/54000 (42%)] Loss: -1715.055420\n",
      "Train Epoch: 67 [33792/54000 (63%)] Loss: -1713.722656\n",
      "Train Epoch: 67 [45056/54000 (83%)] Loss: -1709.531738\n",
      "    epoch          : 67\n",
      "    loss           : -1713.1029375184257\n",
      "    ess            : 26.50827787507255\n",
      "    log_marginal   : 1713.361576872052\n",
      "    val_loss       : -1716.2989908854167\n",
      "    val_ess        : 26.65002139409383\n",
      "    val_log_marginal: 1716.5415140787761\n",
      "Train Epoch: 68 [0/54000 (0%)] Loss: -1718.682983\n",
      "Train Epoch: 68 [11264/54000 (21%)] Loss: -1717.047852\n",
      "Train Epoch: 68 [22528/54000 (42%)] Loss: -1720.180054\n",
      "Train Epoch: 68 [33792/54000 (63%)] Loss: -1718.300781\n",
      "Train Epoch: 68 [45056/54000 (83%)] Loss: -1721.248779\n",
      "    epoch          : 68\n",
      "    loss           : -1719.7152191737912\n",
      "    ess            : 26.545913390393526\n",
      "    log_marginal   : 1719.9669131872788\n",
      "    val_loss       : -1720.184061686198\n",
      "    val_ess        : 26.285191853841145\n",
      "    val_log_marginal: 1720.447285970052\n",
      "Train Epoch: 69 [0/54000 (0%)] Loss: -1719.175049\n",
      "Train Epoch: 69 [11264/54000 (21%)] Loss: -1719.665771\n",
      "Train Epoch: 69 [22528/54000 (42%)] Loss: -1725.269775\n",
      "Train Epoch: 69 [33792/54000 (63%)] Loss: -1719.097290\n",
      "Train Epoch: 69 [45056/54000 (83%)] Loss: -1720.770264\n",
      "    epoch          : 69\n",
      "    loss           : -1722.3095737673202\n",
      "    ess            : 26.248901889009296\n",
      "    log_marginal   : 1722.575659410009\n",
      "    val_loss       : -1723.0440266927083\n",
      "    val_ess        : 26.462358156840008\n",
      "    val_log_marginal: 1723.2967834472656\n",
      "Train Epoch: 70 [0/54000 (0%)] Loss: -1725.172363\n",
      "Train Epoch: 70 [11264/54000 (21%)] Loss: -1722.266113\n",
      "Train Epoch: 70 [22528/54000 (42%)] Loss: -1723.107666\n",
      "Train Epoch: 70 [33792/54000 (63%)] Loss: -1727.598145\n",
      "Train Epoch: 70 [45056/54000 (83%)] Loss: -1723.336914\n",
      "    epoch          : 70\n",
      "    loss           : -1723.6773842865566\n",
      "    ess            : 26.174027388950563\n",
      "    log_marginal   : 1723.9524536132812\n",
      "    val_loss       : -1724.259785970052\n",
      "    val_ess        : 26.302086512247723\n",
      "    val_log_marginal: 1724.5194702148438\n",
      "Train Epoch: 71 [0/54000 (0%)] Loss: -1724.094482\n",
      "Train Epoch: 71 [11264/54000 (21%)] Loss: -1726.411133\n",
      "Train Epoch: 71 [22528/54000 (42%)] Loss: -1724.305786\n",
      "Train Epoch: 71 [33792/54000 (63%)] Loss: -1720.720337\n",
      "Train Epoch: 71 [45056/54000 (83%)] Loss: -1727.787842\n",
      "    epoch          : 71\n",
      "    loss           : -1724.7430005343456\n",
      "    ess            : 26.220331641862977\n",
      "    log_marginal   : 1725.0189162920105\n",
      "    val_loss       : -1725.03125\n",
      "    val_ess        : 26.23157564798991\n",
      "    val_log_marginal: 1725.2913106282551\n",
      "Train Epoch: 72 [0/54000 (0%)] Loss: -1727.184570\n",
      "Train Epoch: 72 [11264/54000 (21%)] Loss: -1729.131104\n",
      "Train Epoch: 72 [22528/54000 (42%)] Loss: -1721.974976\n",
      "Train Epoch: 72 [33792/54000 (63%)] Loss: -1726.819824\n",
      "Train Epoch: 72 [45056/54000 (83%)] Loss: -1712.012451\n",
      "    epoch          : 72\n",
      "    loss           : -1719.3835218897407\n",
      "    ess            : 26.17069890364161\n",
      "    log_marginal   : 1719.6575685896964\n",
      "    val_loss       : -1668.537353515625\n",
      "    val_ess        : 26.190884113311768\n",
      "    val_log_marginal: 1668.8110758463542\n",
      "Train Epoch: 73 [0/54000 (0%)] Loss: -1669.610107\n",
      "Train Epoch: 73 [11264/54000 (21%)] Loss: -1693.503418\n",
      "Train Epoch: 73 [22528/54000 (42%)] Loss: -1694.843994\n",
      "Train Epoch: 73 [33792/54000 (63%)] Loss: -1696.878418\n",
      "Train Epoch: 73 [45056/54000 (83%)] Loss: -1703.107178\n",
      "    epoch          : 73\n",
      "    loss           : -1692.2998311744545\n",
      "    ess            : 26.477115703078937\n",
      "    log_marginal   : 1692.5717658276828\n",
      "    val_loss       : -1669.5359700520833\n",
      "    val_ess        : 27.947497844696045\n",
      "    val_log_marginal: 1669.737548828125\n",
      "Train Epoch: 74 [0/54000 (0%)] Loss: -1706.495117\n",
      "Train Epoch: 74 [11264/54000 (21%)] Loss: -1712.772217\n",
      "Train Epoch: 74 [22528/54000 (42%)] Loss: -1712.139404\n",
      "Train Epoch: 74 [33792/54000 (63%)] Loss: -1715.500977\n",
      "Train Epoch: 74 [45056/54000 (83%)] Loss: -1716.730713\n",
      "    epoch          : 74\n",
      "    loss           : -1714.1670371001621\n",
      "    ess            : 27.50967083337172\n",
      "    log_marginal   : 1714.3805875958137\n",
      "    val_loss       : -1710.0560913085938\n",
      "    val_ess        : 27.856436252593994\n",
      "    val_log_marginal: 1710.2540893554688\n",
      "Train Epoch: 75 [0/54000 (0%)] Loss: -1719.416992\n",
      "Train Epoch: 75 [11264/54000 (21%)] Loss: -1719.532959\n",
      "Train Epoch: 75 [22528/54000 (42%)] Loss: -1724.038940\n",
      "Train Epoch: 75 [33792/54000 (63%)] Loss: -1723.313843\n",
      "Train Epoch: 75 [45056/54000 (83%)] Loss: -1721.874268\n",
      "    epoch          : 75\n",
      "    loss           : -1722.9991604786999\n",
      "    ess            : 26.64350504245398\n",
      "    log_marginal   : 1723.2533074145047\n",
      "    val_loss       : -1718.2406717936199\n",
      "    val_ess        : 26.470835367838543\n",
      "    val_log_marginal: 1718.5111287434895\n",
      "Train Epoch: 76 [0/54000 (0%)] Loss: -1725.739136\n",
      "Train Epoch: 76 [11264/54000 (21%)] Loss: -1726.458862\n",
      "Train Epoch: 76 [22528/54000 (42%)] Loss: -1727.824707\n",
      "Train Epoch: 76 [33792/54000 (63%)] Loss: -1722.982056\n",
      "Train Epoch: 76 [45056/54000 (83%)] Loss: -1726.401489\n",
      "    epoch          : 76\n",
      "    loss           : -1726.0804927034198\n",
      "    ess            : 26.327262248633044\n",
      "    log_marginal   : 1726.3539117777123\n",
      "    val_loss       : -1721.7652282714844\n",
      "    val_ess        : 26.164191563924152\n",
      "    val_log_marginal: 1722.0409647623699\n",
      "Train Epoch: 77 [0/54000 (0%)] Loss: -1728.382202\n",
      "Train Epoch: 77 [11264/54000 (21%)] Loss: -1726.745728\n",
      "Train Epoch: 77 [22528/54000 (42%)] Loss: -1730.494141\n",
      "Train Epoch: 77 [33792/54000 (63%)] Loss: -1735.472534\n",
      "Train Epoch: 77 [45056/54000 (83%)] Loss: -1727.757324\n",
      "    epoch          : 77\n",
      "    loss           : -1727.84214466023\n",
      "    ess            : 26.24141523972997\n",
      "    log_marginal   : 1728.1189183649028\n",
      "    val_loss       : -1724.026123046875\n",
      "    val_ess        : 26.289116382598877\n",
      "    val_log_marginal: 1724.3125813802083\n",
      "Train Epoch: 78 [0/54000 (0%)] Loss: -1733.109497\n",
      "Train Epoch: 78 [11264/54000 (21%)] Loss: -1732.933105\n",
      "Train Epoch: 78 [22528/54000 (42%)] Loss: -1733.561523\n",
      "Train Epoch: 78 [33792/54000 (63%)] Loss: -1726.810913\n",
      "Train Epoch: 78 [45056/54000 (83%)] Loss: -1728.444824\n",
      "    epoch          : 78\n",
      "    loss           : -1729.2491777528007\n",
      "    ess            : 26.20927709903357\n",
      "    log_marginal   : 1729.5305452166863\n",
      "    val_loss       : -1725.8340250651042\n",
      "    val_ess        : 26.20394213994344\n",
      "    val_log_marginal: 1726.1262817382812\n",
      "Train Epoch: 79 [0/54000 (0%)] Loss: -1735.839600\n",
      "Train Epoch: 79 [11264/54000 (21%)] Loss: -1733.941284\n",
      "Train Epoch: 79 [22528/54000 (42%)] Loss: -1724.514893\n",
      "Train Epoch: 79 [33792/54000 (63%)] Loss: -1726.422729\n",
      "Train Epoch: 79 [45056/54000 (83%)] Loss: -1734.312744\n",
      "    epoch          : 79\n",
      "    loss           : -1730.331592487839\n",
      "    ess            : 26.090524331578667\n",
      "    log_marginal   : 1730.6177195423054\n",
      "    val_loss       : -1727.2955423990886\n",
      "    val_ess        : 26.15734052658081\n",
      "    val_log_marginal: 1727.5798238118489\n",
      "Train Epoch: 80 [0/54000 (0%)] Loss: -1733.784180\n",
      "Train Epoch: 80 [11264/54000 (21%)] Loss: -1729.995728\n",
      "Train Epoch: 80 [22528/54000 (42%)] Loss: -1713.179321\n",
      "Train Epoch: 80 [33792/54000 (63%)] Loss: -1720.583740\n",
      "Train Epoch: 80 [45056/54000 (83%)] Loss: -1726.450562\n",
      "    epoch          : 80\n",
      "    loss           : -1723.7476921801297\n",
      "    ess            : 26.214633779705697\n",
      "    log_marginal   : 1724.0284930535083\n",
      "    val_loss       : -1714.1711934407551\n",
      "    val_ess        : 26.17956558863322\n",
      "    val_log_marginal: 1714.4521077473958\n",
      "Train Epoch: 81 [0/54000 (0%)] Loss: -1720.309814\n",
      "Train Epoch: 81 [11264/54000 (21%)] Loss: -1682.833984\n",
      "Train Epoch: 81 [22528/54000 (42%)] Loss: -1717.288818\n",
      "Train Epoch: 81 [33792/54000 (63%)] Loss: -1671.608398\n",
      "Train Epoch: 81 [45056/54000 (83%)] Loss: -1707.570557\n",
      "    epoch          : 81\n",
      "    loss           : -1699.3206464659493\n",
      "    ess            : 26.532575049490298\n",
      "    log_marginal   : 1699.5784486014888\n",
      "    val_loss       : -1690.864237467448\n",
      "    val_ess        : 26.92325242360433\n",
      "    val_log_marginal: 1691.1011149088542\n",
      "Train Epoch: 82 [0/54000 (0%)] Loss: -1701.686768\n",
      "Train Epoch: 82 [11264/54000 (21%)] Loss: -1710.425293\n",
      "Train Epoch: 82 [22528/54000 (42%)] Loss: -1717.496094\n",
      "Train Epoch: 82 [33792/54000 (63%)] Loss: -1720.846680\n",
      "Train Epoch: 82 [45056/54000 (83%)] Loss: -1714.706055\n",
      "    epoch          : 82\n",
      "    loss           : -1713.9408592368072\n",
      "    ess            : 27.21846078476816\n",
      "    log_marginal   : 1714.1691698758107\n",
      "    val_loss       : -1708.4479675292969\n",
      "    val_ess        : 27.526748498280842\n",
      "    val_log_marginal: 1708.6722920735676\n",
      "Train Epoch: 83 [0/54000 (0%)] Loss: -1720.894531\n",
      "Train Epoch: 83 [11264/54000 (21%)] Loss: -1722.584106\n",
      "Train Epoch: 83 [22528/54000 (42%)] Loss: -1723.268066\n",
      "Train Epoch: 83 [33792/54000 (63%)] Loss: -1725.050293\n",
      "Train Epoch: 83 [45056/54000 (83%)] Loss: -1725.429199\n",
      "    epoch          : 83\n",
      "    loss           : -1723.3252678637234\n",
      "    ess            : 26.63799204916324\n",
      "    log_marginal   : 1723.5830596348026\n",
      "    val_loss       : -1720.7244466145833\n",
      "    val_ess        : 26.678568522135418\n",
      "    val_log_marginal: 1720.9769592285156\n",
      "Train Epoch: 84 [0/54000 (0%)] Loss: -1731.956177\n",
      "Train Epoch: 84 [11264/54000 (21%)] Loss: -1724.014526\n",
      "Train Epoch: 84 [22528/54000 (42%)] Loss: -1724.676147\n",
      "Train Epoch: 84 [33792/54000 (63%)] Loss: -1728.846436\n",
      "Train Epoch: 84 [45056/54000 (83%)] Loss: -1725.264038\n",
      "    epoch          : 84\n",
      "    loss           : -1727.3230256854363\n",
      "    ess            : 26.32930275179305\n",
      "    log_marginal   : 1727.5973579838592\n",
      "    val_loss       : -1724.630839029948\n",
      "    val_ess        : 26.44066572189331\n",
      "    val_log_marginal: 1724.9006856282551\n",
      "Train Epoch: 85 [0/54000 (0%)] Loss: -1731.549561\n",
      "Train Epoch: 85 [11264/54000 (21%)] Loss: -1727.825195\n",
      "Train Epoch: 85 [22528/54000 (42%)] Loss: -1726.508667\n",
      "Train Epoch: 85 [33792/54000 (63%)] Loss: -1734.593384\n",
      "Train Epoch: 85 [45056/54000 (83%)] Loss: -1723.726074\n",
      "    epoch          : 85\n",
      "    loss           : -1729.2597391380455\n",
      "    ess            : 26.223653811328816\n",
      "    log_marginal   : 1729.5404789762677\n",
      "    val_loss       : -1726.3657735188801\n",
      "    val_ess        : 26.254369894663494\n",
      "    val_log_marginal: 1726.6453857421875\n",
      "Train Epoch: 86 [0/54000 (0%)] Loss: -1733.287109\n",
      "Train Epoch: 86 [11264/54000 (21%)] Loss: -1727.113403\n",
      "Train Epoch: 86 [22528/54000 (42%)] Loss: -1733.379395\n",
      "Train Epoch: 86 [33792/54000 (63%)] Loss: -1729.531006\n",
      "Train Epoch: 86 [45056/54000 (83%)] Loss: -1729.678467\n",
      "    epoch          : 86\n",
      "    loss           : -1730.802337070681\n",
      "    ess            : 26.04227992723573\n",
      "    log_marginal   : 1731.0933077830189\n",
      "    val_loss       : -1728.1712036132812\n",
      "    val_ess        : 26.170901775360107\n",
      "    val_log_marginal: 1728.4473470052083\n",
      "Train Epoch: 87 [0/54000 (0%)] Loss: -1729.102539\n",
      "Train Epoch: 87 [11264/54000 (21%)] Loss: -1732.541626\n",
      "Train Epoch: 87 [22528/54000 (42%)] Loss: -1733.876099\n",
      "Train Epoch: 87 [33792/54000 (63%)] Loss: -1732.891846\n",
      "Train Epoch: 87 [45056/54000 (83%)] Loss: -1732.354736\n",
      "    epoch          : 87\n",
      "    loss           : -1731.9609144678657\n",
      "    ess            : 26.145315458189767\n",
      "    log_marginal   : 1732.2485996462265\n",
      "    val_loss       : -1729.1741638183594\n",
      "    val_ess        : 26.170008182525635\n",
      "    val_log_marginal: 1729.4608357747395\n",
      "Train Epoch: 88 [0/54000 (0%)] Loss: -1738.477051\n",
      "Train Epoch: 88 [11264/54000 (21%)] Loss: -1737.107666\n",
      "Train Epoch: 88 [22528/54000 (42%)] Loss: -1730.712891\n",
      "Train Epoch: 88 [33792/54000 (63%)] Loss: -1732.891724\n",
      "Train Epoch: 88 [45056/54000 (83%)] Loss: -1732.119873\n",
      "    epoch          : 88\n",
      "    loss           : -1727.2313934901974\n",
      "    ess            : 26.21636583220284\n",
      "    log_marginal   : 1727.5156940964032\n",
      "    val_loss       : -1630.5472310384114\n",
      "    val_ess        : 26.496399402618408\n",
      "    val_log_marginal: 1630.8071187337239\n",
      "Train Epoch: 89 [0/54000 (0%)] Loss: -1639.404297\n",
      "Train Epoch: 89 [11264/54000 (21%)] Loss: -1700.543457\n",
      "Train Epoch: 89 [22528/54000 (42%)] Loss: -1706.131958\n",
      "Train Epoch: 89 [33792/54000 (63%)] Loss: -1702.112305\n",
      "Train Epoch: 89 [45056/54000 (83%)] Loss: -1719.393555\n",
      "    epoch          : 89\n",
      "    loss           : -1701.7160748175854\n",
      "    ess            : 26.42211755716576\n",
      "    log_marginal   : 1701.9858052955483\n",
      "    val_loss       : -1657.1958109537761\n",
      "    val_ess        : 28.442187150319416\n",
      "    val_log_marginal: 1657.375996907552\n",
      "Train Epoch: 90 [0/54000 (0%)] Loss: -1713.439819\n",
      "Train Epoch: 90 [11264/54000 (21%)] Loss: -1723.166870\n",
      "Train Epoch: 90 [22528/54000 (42%)] Loss: -1717.247559\n",
      "Train Epoch: 90 [33792/54000 (63%)] Loss: -1719.535645\n",
      "Train Epoch: 90 [45056/54000 (83%)] Loss: -1720.970703\n",
      "    epoch          : 90\n",
      "    loss           : -1720.4914366524174\n",
      "    ess            : 27.038298372952443\n",
      "    log_marginal   : 1720.735827176076\n",
      "    val_loss       : -1706.448710123698\n",
      "    val_ess        : 27.605094750722248\n",
      "    val_log_marginal: 1706.661356608073\n",
      "Train Epoch: 91 [0/54000 (0%)] Loss: -1730.985718\n",
      "Train Epoch: 91 [11264/54000 (21%)] Loss: -1725.755981\n",
      "Train Epoch: 91 [22528/54000 (42%)] Loss: -1726.872925\n",
      "Train Epoch: 91 [33792/54000 (63%)] Loss: -1730.437012\n",
      "Train Epoch: 91 [45056/54000 (83%)] Loss: -1725.293213\n",
      "    epoch          : 91\n",
      "    loss           : -1728.2331312647407\n",
      "    ess            : 26.47760983233182\n",
      "    log_marginal   : 1728.5034709426593\n",
      "    val_loss       : -1714.5553588867188\n",
      "    val_ess        : 26.656570434570312\n",
      "    val_log_marginal: 1714.8194681803386\n",
      "Train Epoch: 92 [0/54000 (0%)] Loss: -1730.327881\n",
      "Train Epoch: 92 [11264/54000 (21%)] Loss: -1733.650879\n",
      "Train Epoch: 92 [22528/54000 (42%)] Loss: -1729.752563\n",
      "Train Epoch: 92 [33792/54000 (63%)] Loss: -1734.507080\n",
      "Train Epoch: 92 [45056/54000 (83%)] Loss: -1731.999756\n",
      "    epoch          : 92\n",
      "    loss           : -1730.9926458394752\n",
      "    ess            : 26.224875792017524\n",
      "    log_marginal   : 1731.2810001013413\n",
      "    val_loss       : -1718.9052022298176\n",
      "    val_ess        : 26.48617172241211\n",
      "    val_log_marginal: 1719.178202311198\n",
      "Train Epoch: 93 [0/54000 (0%)] Loss: -1729.681885\n",
      "Train Epoch: 93 [11264/54000 (21%)] Loss: -1733.871582\n",
      "Train Epoch: 93 [22528/54000 (42%)] Loss: -1734.527344\n",
      "Train Epoch: 93 [33792/54000 (63%)] Loss: -1736.326294\n",
      "Train Epoch: 93 [45056/54000 (83%)] Loss: -1727.557861\n",
      "    epoch          : 93\n",
      "    loss           : -1732.713544737618\n",
      "    ess            : 26.289130750692117\n",
      "    log_marginal   : 1732.9965808796433\n",
      "    val_loss       : -1721.4332885742188\n",
      "    val_ess        : 26.259575525919598\n",
      "    val_log_marginal: 1721.7176106770833\n",
      "Train Epoch: 94 [0/54000 (0%)] Loss: -1735.237793\n",
      "Train Epoch: 94 [11264/54000 (21%)] Loss: -1733.163452\n",
      "Train Epoch: 94 [22528/54000 (42%)] Loss: -1732.349121\n",
      "Train Epoch: 94 [33792/54000 (63%)] Loss: -1740.495117\n",
      "Train Epoch: 94 [45056/54000 (83%)] Loss: -1732.902344\n",
      "    epoch          : 94\n",
      "    loss           : -1734.0706280402417\n",
      "    ess            : 26.112807525778717\n",
      "    log_marginal   : 1734.3668431695903\n",
      "    val_loss       : -1724.1775309244792\n",
      "    val_ess        : 26.11118205388387\n",
      "    val_log_marginal: 1724.4800618489583\n",
      "Train Epoch: 95 [0/54000 (0%)] Loss: -1739.614258\n",
      "Train Epoch: 95 [11264/54000 (21%)] Loss: -1734.202881\n",
      "Train Epoch: 95 [22528/54000 (42%)] Loss: -1735.834961\n",
      "Train Epoch: 95 [33792/54000 (63%)] Loss: -1727.250977\n",
      "Train Epoch: 95 [45056/54000 (83%)] Loss: -1737.836670\n",
      "    epoch          : 95\n",
      "    loss           : -1734.6153149874706\n",
      "    ess            : 26.152604049106813\n",
      "    log_marginal   : 1734.911003832547\n",
      "    val_loss       : -1723.4581197102864\n",
      "    val_ess        : 26.235799471537273\n",
      "    val_log_marginal: 1723.7549235026042\n",
      "Train Epoch: 96 [0/54000 (0%)] Loss: -1731.943115\n",
      "Train Epoch: 96 [11264/54000 (21%)] Loss: -1706.499146\n",
      "Train Epoch: 96 [22528/54000 (42%)] Loss: -1733.137207\n",
      "Train Epoch: 96 [33792/54000 (63%)] Loss: -1731.047363\n",
      "Train Epoch: 96 [45056/54000 (83%)] Loss: -1686.622314\n",
      "    epoch          : 96\n",
      "    loss           : -1717.02176191222\n",
      "    ess            : 26.293696133595592\n",
      "    log_marginal   : 1717.3063423588592\n",
      "    val_loss       : -1716.809326171875\n",
      "    val_ess        : 26.484980424245197\n",
      "    val_log_marginal: 1717.0899353027344\n",
      "Train Epoch: 97 [0/54000 (0%)] Loss: -1719.904785\n",
      "Train Epoch: 97 [11264/54000 (21%)] Loss: -1725.096924\n",
      "Train Epoch: 97 [22528/54000 (42%)] Loss: -1719.789185\n",
      "Train Epoch: 97 [33792/54000 (63%)] Loss: -1724.447510\n",
      "Train Epoch: 97 [45056/54000 (83%)] Loss: -1722.208496\n",
      "    epoch          : 97\n",
      "    loss           : -1722.9334935602153\n",
      "    ess            : 26.84953248725747\n",
      "    log_marginal   : 1723.1930634120724\n",
      "    val_loss       : -1722.0648396809895\n",
      "    val_ess        : 26.608556429545086\n",
      "    val_log_marginal: 1722.3403930664062\n",
      "Train Epoch: 98 [0/54000 (0%)] Loss: -1732.066406\n",
      "Train Epoch: 98 [11264/54000 (21%)] Loss: -1731.185303\n",
      "Train Epoch: 98 [22528/54000 (42%)] Loss: -1721.844971\n",
      "Train Epoch: 98 [33792/54000 (63%)] Loss: -1701.541992\n",
      "Train Epoch: 98 [45056/54000 (83%)] Loss: -1720.260986\n",
      "    epoch          : 98\n",
      "    loss           : -1720.070689075398\n",
      "    ess            : 26.659711225977485\n",
      "    log_marginal   : 1720.34221836306\n",
      "    val_loss       : -1720.7236836751301\n",
      "    val_ess        : 26.532243569691975\n",
      "    val_log_marginal: 1721.0037129720051\n",
      "Train Epoch: 99 [0/54000 (0%)] Loss: -1724.578369\n",
      "Train Epoch: 99 [11264/54000 (21%)] Loss: -1727.950562\n",
      "Train Epoch: 99 [22528/54000 (42%)] Loss: -1725.640747\n",
      "Train Epoch: 99 [33792/54000 (63%)] Loss: -1727.336182\n",
      "Train Epoch: 99 [45056/54000 (83%)] Loss: -1727.938477\n",
      "    epoch          : 99\n",
      "    loss           : -1727.6873975070018\n",
      "    ess            : 26.875458105555122\n",
      "    log_marginal   : 1727.9441090709759\n",
      "    val_loss       : -1728.241455078125\n",
      "    val_ess        : 26.676758607228596\n",
      "    val_log_marginal: 1728.515645345052\n",
      "Train Epoch: 100 [0/54000 (0%)] Loss: -1737.276123\n",
      "Train Epoch: 100 [11264/54000 (21%)] Loss: -1735.908203\n",
      "Train Epoch: 100 [22528/54000 (42%)] Loss: -1736.281494\n",
      "Train Epoch: 100 [33792/54000 (63%)] Loss: -1730.830566\n",
      "Train Epoch: 100 [45056/54000 (83%)] Loss: -1729.506348\n",
      "    epoch          : 100\n",
      "    loss           : -1733.869815466539\n",
      "    ess            : 26.51800315784958\n",
      "    log_marginal   : 1734.150275464328\n",
      "    val_loss       : -1731.6310221354167\n",
      "    val_ess        : 26.20437224706014\n",
      "    val_log_marginal: 1731.9281819661458\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch100.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 101 [0/54000 (0%)] Loss: -1738.597412\n",
      "Train Epoch: 101 [11264/54000 (21%)] Loss: -1733.100708\n",
      "Train Epoch: 101 [22528/54000 (42%)] Loss: -1735.810059\n",
      "Train Epoch: 101 [33792/54000 (63%)] Loss: -1737.816040\n",
      "Train Epoch: 101 [45056/54000 (83%)] Loss: -1735.869263\n",
      "    epoch          : 101\n",
      "    loss           : -1736.2588696749706\n",
      "    ess            : 26.234219155221616\n",
      "    log_marginal   : 1736.5547024708874\n",
      "    val_loss       : -1733.4877624511719\n",
      "    val_ess        : 26.249408721923828\n",
      "    val_log_marginal: 1733.779276529948\n",
      "Train Epoch: 102 [0/54000 (0%)] Loss: -1735.380615\n",
      "Train Epoch: 102 [11264/54000 (21%)] Loss: -1736.089600\n",
      "Train Epoch: 102 [22528/54000 (42%)] Loss: -1736.303101\n",
      "Train Epoch: 102 [33792/54000 (63%)] Loss: -1739.843140\n",
      "Train Epoch: 102 [45056/54000 (83%)] Loss: -1731.268066\n",
      "    epoch          : 102\n",
      "    loss           : -1737.743259645858\n",
      "    ess            : 26.234165857423026\n",
      "    log_marginal   : 1738.0381020599941\n",
      "    val_loss       : -1734.2772115071614\n",
      "    val_ess        : 26.23605712254842\n",
      "    val_log_marginal: 1734.5747477213542\n",
      "Train Epoch: 103 [0/54000 (0%)] Loss: -1739.817383\n",
      "Train Epoch: 103 [11264/54000 (21%)] Loss: -1744.592529\n",
      "Train Epoch: 103 [22528/54000 (42%)] Loss: -1735.467651\n",
      "Train Epoch: 103 [33792/54000 (63%)] Loss: -1734.286743\n",
      "Train Epoch: 103 [45056/54000 (83%)] Loss: -1741.988403\n",
      "    epoch          : 103\n",
      "    loss           : -1739.0032129827534\n",
      "    ess            : 26.168933400567973\n",
      "    log_marginal   : 1739.3047888413914\n",
      "    val_loss       : -1735.6536966959636\n",
      "    val_ess        : 26.163252353668213\n",
      "    val_log_marginal: 1735.9564107259114\n",
      "Train Epoch: 104 [0/54000 (0%)] Loss: -1742.359619\n",
      "Train Epoch: 104 [11264/54000 (21%)] Loss: -1737.094482\n",
      "Train Epoch: 104 [22528/54000 (42%)] Loss: -1747.829468\n",
      "Train Epoch: 104 [33792/54000 (63%)] Loss: -1740.995361\n",
      "Train Epoch: 104 [45056/54000 (83%)] Loss: -1722.599609\n",
      "    epoch          : 104\n",
      "    loss           : -1732.836405052329\n",
      "    ess            : 26.15604445619403\n",
      "    log_marginal   : 1733.1377713185436\n",
      "    val_loss       : -1705.2973327636719\n",
      "    val_ess        : 26.159977277119953\n",
      "    val_log_marginal: 1705.5736694335938\n",
      "Train Epoch: 105 [0/54000 (0%)] Loss: -1712.609985\n",
      "Train Epoch: 105 [11264/54000 (21%)] Loss: -1731.764160\n",
      "Train Epoch: 105 [22528/54000 (42%)] Loss: -1731.481689\n",
      "Train Epoch: 105 [33792/54000 (63%)] Loss: -1740.026367\n",
      "Train Epoch: 105 [45056/54000 (83%)] Loss: -1730.832886\n",
      "    epoch          : 105\n",
      "    loss           : -1730.7605544756043\n",
      "    ess            : 26.40155813828954\n",
      "    log_marginal   : 1731.051906369767\n",
      "    val_loss       : -1723.8848063151042\n",
      "    val_ess        : 26.981454213460285\n",
      "    val_log_marginal: 1724.1449686686199\n",
      "Train Epoch: 106 [0/54000 (0%)] Loss: -1737.367188\n",
      "Train Epoch: 106 [11264/54000 (21%)] Loss: -1736.459961\n",
      "Train Epoch: 106 [22528/54000 (42%)] Loss: -1738.531494\n",
      "Train Epoch: 106 [33792/54000 (63%)] Loss: -1738.668701\n",
      "Train Epoch: 106 [45056/54000 (83%)] Loss: -1738.974976\n",
      "    epoch          : 106\n",
      "    loss           : -1738.0184579525353\n",
      "    ess            : 26.511942737507372\n",
      "    log_marginal   : 1738.3037420308815\n",
      "    val_loss       : -1731.7520039876301\n",
      "    val_ess        : 26.582005818684895\n",
      "    val_log_marginal: 1732.0258687337239\n",
      "Train Epoch: 107 [0/54000 (0%)] Loss: -1739.524658\n",
      "Train Epoch: 107 [11264/54000 (21%)] Loss: -1744.088867\n",
      "Train Epoch: 107 [22528/54000 (42%)] Loss: -1736.598633\n",
      "Train Epoch: 107 [33792/54000 (63%)] Loss: -1736.730469\n",
      "Train Epoch: 107 [45056/54000 (83%)] Loss: -1735.205444\n",
      "    epoch          : 107\n",
      "    loss           : -1740.3889851120282\n",
      "    ess            : 26.25557670953139\n",
      "    log_marginal   : 1740.6826862839032\n",
      "    val_loss       : -1734.4022521972656\n",
      "    val_ess        : 26.553327878316242\n",
      "    val_log_marginal: 1734.6831868489583\n",
      "Train Epoch: 108 [0/54000 (0%)] Loss: -1736.449097\n",
      "Train Epoch: 108 [11264/54000 (21%)] Loss: -1739.253662\n",
      "Train Epoch: 108 [22528/54000 (42%)] Loss: -1739.406982\n",
      "Train Epoch: 108 [33792/54000 (63%)] Loss: -1743.986206\n",
      "Train Epoch: 108 [45056/54000 (83%)] Loss: -1746.625000\n",
      "    epoch          : 108\n",
      "    loss           : -1741.6848697302476\n",
      "    ess            : 26.23888429605736\n",
      "    log_marginal   : 1741.9798572468308\n",
      "    val_loss       : -1736.3230692545574\n",
      "    val_ess        : 26.30759048461914\n",
      "    val_log_marginal: 1736.6239827473958\n",
      "Train Epoch: 109 [0/54000 (0%)] Loss: -1747.024170\n",
      "Train Epoch: 109 [11264/54000 (21%)] Loss: -1745.226074\n",
      "Train Epoch: 109 [22528/54000 (42%)] Loss: -1744.054199\n",
      "Train Epoch: 109 [33792/54000 (63%)] Loss: -1740.032471\n",
      "Train Epoch: 109 [45056/54000 (83%)] Loss: -1745.063477\n",
      "    epoch          : 109\n",
      "    loss           : -1742.8016656839623\n",
      "    ess            : 26.217545059492004\n",
      "    log_marginal   : 1743.105547059257\n",
      "    val_loss       : -1737.5176086425781\n",
      "    val_ess        : 26.39349937438965\n",
      "    val_log_marginal: 1737.8171081542969\n",
      "Train Epoch: 110 [0/54000 (0%)] Loss: -1745.717529\n",
      "Train Epoch: 110 [11264/54000 (21%)] Loss: -1741.358521\n",
      "Train Epoch: 110 [22528/54000 (42%)] Loss: -1744.349365\n",
      "Train Epoch: 110 [33792/54000 (63%)] Loss: -1741.464844\n",
      "Train Epoch: 110 [45056/54000 (83%)] Loss: -1744.759521\n",
      "    epoch          : 110\n",
      "    loss           : -1743.5878733508991\n",
      "    ess            : 26.251654031141747\n",
      "    log_marginal   : 1743.8915854400059\n",
      "    val_loss       : -1737.4070332845051\n",
      "    val_ess        : 26.248531341552734\n",
      "    val_log_marginal: 1737.7169698079426\n",
      "Train Epoch: 111 [0/54000 (0%)] Loss: -1746.574951\n",
      "Train Epoch: 111 [11264/54000 (21%)] Loss: -1742.185059\n",
      "Train Epoch: 111 [22528/54000 (42%)] Loss: -1715.846924\n",
      "Train Epoch: 111 [33792/54000 (63%)] Loss: -1736.924316\n",
      "Train Epoch: 111 [45056/54000 (83%)] Loss: -1732.084595\n",
      "    epoch          : 111\n",
      "    loss           : -1729.5221903099205\n",
      "    ess            : 26.287455774703115\n",
      "    log_marginal   : 1729.819034216539\n",
      "    val_loss       : -1726.9836527506511\n",
      "    val_ess        : 26.23959795633952\n",
      "    val_log_marginal: 1727.2939554850261\n",
      "Train Epoch: 112 [0/54000 (0%)] Loss: -1731.142578\n",
      "Train Epoch: 112 [11264/54000 (21%)] Loss: -1734.060547\n",
      "Train Epoch: 112 [22528/54000 (42%)] Loss: -1690.569946\n",
      "Train Epoch: 112 [33792/54000 (63%)] Loss: -1727.899536\n",
      "Train Epoch: 112 [45056/54000 (83%)] Loss: -1732.611450\n",
      "    epoch          : 112\n",
      "    loss           : -1725.0593273234817\n",
      "    ess            : 26.805088241145295\n",
      "    log_marginal   : 1725.328377201872\n",
      "    val_loss       : -1721.0348815917969\n",
      "    val_ess        : 26.872657299041748\n",
      "    val_log_marginal: 1721.3004964192708\n",
      "Train Epoch: 113 [0/54000 (0%)] Loss: -1722.854980\n",
      "Train Epoch: 113 [11264/54000 (21%)] Loss: -1714.147339\n",
      "Train Epoch: 113 [22528/54000 (42%)] Loss: -1725.567505\n",
      "Train Epoch: 113 [33792/54000 (63%)] Loss: -1729.943115\n",
      "Train Epoch: 113 [45056/54000 (83%)] Loss: -1731.300049\n",
      "    epoch          : 113\n",
      "    loss           : -1727.6160140127506\n",
      "    ess            : 26.868049819514436\n",
      "    log_marginal   : 1727.8800739792157\n",
      "    val_loss       : -1733.2849019368489\n",
      "    val_ess        : 27.283804893493652\n",
      "    val_log_marginal: 1733.5285542805989\n",
      "Train Epoch: 114 [0/54000 (0%)] Loss: -1734.719604\n",
      "Train Epoch: 114 [11264/54000 (21%)] Loss: -1741.085205\n",
      "Train Epoch: 114 [22528/54000 (42%)] Loss: -1728.892944\n",
      "Train Epoch: 114 [33792/54000 (63%)] Loss: -1739.436646\n",
      "Train Epoch: 114 [45056/54000 (83%)] Loss: -1735.224487\n",
      "    epoch          : 114\n",
      "    loss           : -1737.197323205336\n",
      "    ess            : 26.747861106440705\n",
      "    log_marginal   : 1737.4734163104363\n",
      "    val_loss       : -1738.1584065755208\n",
      "    val_ess        : 26.446348349253338\n",
      "    val_log_marginal: 1738.4430745442708\n",
      "Train Epoch: 115 [0/54000 (0%)] Loss: -1743.841797\n",
      "Train Epoch: 115 [11264/54000 (21%)] Loss: -1738.535645\n",
      "Train Epoch: 115 [22528/54000 (42%)] Loss: -1743.107422\n",
      "Train Epoch: 115 [33792/54000 (63%)] Loss: -1741.278198\n",
      "Train Epoch: 115 [45056/54000 (83%)] Loss: -1742.290039\n",
      "    epoch          : 115\n",
      "    loss           : -1741.5625426094487\n",
      "    ess            : 26.34316573952729\n",
      "    log_marginal   : 1741.857235314711\n",
      "    val_loss       : -1740.946797688802\n",
      "    val_ess        : 26.19684950510661\n",
      "    val_log_marginal: 1741.2506408691406\n",
      "Train Epoch: 116 [0/54000 (0%)] Loss: -1746.546265\n",
      "Train Epoch: 116 [11264/54000 (21%)] Loss: -1747.299072\n",
      "Train Epoch: 116 [22528/54000 (42%)] Loss: -1744.852539\n",
      "Train Epoch: 116 [33792/54000 (63%)] Loss: -1746.299927\n",
      "Train Epoch: 116 [45056/54000 (83%)] Loss: -1743.727295\n",
      "    epoch          : 116\n",
      "    loss           : -1743.648268213812\n",
      "    ess            : 26.26537927591576\n",
      "    log_marginal   : 1743.952831340286\n",
      "    val_loss       : -1742.0665283203125\n",
      "    val_ess        : 26.330406030019123\n",
      "    val_log_marginal: 1742.3749084472656\n",
      "Train Epoch: 117 [0/54000 (0%)] Loss: -1744.482422\n",
      "Train Epoch: 117 [11264/54000 (21%)] Loss: -1743.867798\n",
      "Train Epoch: 117 [22528/54000 (42%)] Loss: -1750.973633\n",
      "Train Epoch: 117 [33792/54000 (63%)] Loss: -1745.520142\n",
      "Train Epoch: 117 [45056/54000 (83%)] Loss: -1745.878296\n",
      "    epoch          : 117\n",
      "    loss           : -1745.1047731795402\n",
      "    ess            : 26.279303766646475\n",
      "    log_marginal   : 1745.4084645397259\n",
      "    val_loss       : -1743.3612569173176\n",
      "    val_ess        : 26.300563017527264\n",
      "    val_log_marginal: 1743.6601867675781\n",
      "Train Epoch: 118 [0/54000 (0%)] Loss: -1747.180908\n",
      "Train Epoch: 118 [11264/54000 (21%)] Loss: -1744.747925\n",
      "Train Epoch: 118 [22528/54000 (42%)] Loss: -1742.684570\n",
      "Train Epoch: 118 [33792/54000 (63%)] Loss: -1747.561035\n",
      "Train Epoch: 118 [45056/54000 (83%)] Loss: -1748.080566\n",
      "    epoch          : 118\n",
      "    loss           : -1746.1805799952094\n",
      "    ess            : 26.329140105337466\n",
      "    log_marginal   : 1746.4824046008991\n",
      "    val_loss       : -1744.2864074707031\n",
      "    val_ess        : 26.067314783732098\n",
      "    val_log_marginal: 1744.6037902832031\n",
      "Train Epoch: 119 [0/54000 (0%)] Loss: -1747.108887\n",
      "Train Epoch: 119 [11264/54000 (21%)] Loss: -1748.273438\n",
      "Train Epoch: 119 [22528/54000 (42%)] Loss: -1748.661377\n",
      "Train Epoch: 119 [33792/54000 (63%)] Loss: -1746.072021\n",
      "Train Epoch: 119 [45056/54000 (83%)] Loss: -1744.959473\n",
      "    epoch          : 119\n",
      "    loss           : -1746.9006094302772\n",
      "    ess            : 26.26222345963964\n",
      "    log_marginal   : 1747.2093045216686\n",
      "    val_loss       : -1743.5365804036458\n",
      "    val_ess        : 26.41163396835327\n",
      "    val_log_marginal: 1743.8322041829426\n",
      "Train Epoch: 120 [0/54000 (0%)] Loss: -1746.682617\n",
      "Train Epoch: 120 [11264/54000 (21%)] Loss: -1725.733398\n",
      "Train Epoch: 120 [22528/54000 (42%)] Loss: -1652.590332\n",
      "Train Epoch: 120 [33792/54000 (63%)] Loss: -1678.062988\n",
      "Train Epoch: 120 [45056/54000 (83%)] Loss: -1708.471680\n",
      "    epoch          : 120\n",
      "    loss           : -1695.0478918687352\n",
      "    ess            : 26.238659930679034\n",
      "    log_marginal   : 1695.3473487710053\n",
      "    val_loss       : -1676.4336853027344\n",
      "    val_ess        : 26.43315331141154\n",
      "    val_log_marginal: 1676.7000325520833\n",
      "Train Epoch: 121 [0/54000 (0%)] Loss: -1662.320068\n",
      "Train Epoch: 121 [11264/54000 (21%)] Loss: -1710.648560\n",
      "Train Epoch: 121 [22528/54000 (42%)] Loss: -1719.404541\n",
      "Train Epoch: 121 [33792/54000 (63%)] Loss: -1714.734131\n",
      "Train Epoch: 121 [45056/54000 (83%)] Loss: -1722.396484\n",
      "    epoch          : 121\n",
      "    loss           : -1713.6581501510907\n",
      "    ess            : 27.547221993500333\n",
      "    log_marginal   : 1713.8874085624263\n",
      "    val_loss       : -1704.9584350585938\n",
      "    val_ess        : 27.966615200042725\n",
      "    val_log_marginal: 1705.1774495442708\n",
      "Train Epoch: 122 [0/54000 (0%)] Loss: -1728.789673\n",
      "Train Epoch: 122 [11264/54000 (21%)] Loss: -1732.138916\n",
      "Train Epoch: 122 [22528/54000 (42%)] Loss: -1729.032471\n",
      "Train Epoch: 122 [33792/54000 (63%)] Loss: -1733.357178\n",
      "Train Epoch: 122 [45056/54000 (83%)] Loss: -1731.732788\n",
      "    epoch          : 122\n",
      "    loss           : -1731.910122853405\n",
      "    ess            : 26.877431401666605\n",
      "    log_marginal   : 1732.178702876253\n",
      "    val_loss       : -1723.0863952636719\n",
      "    val_ess        : 27.088486194610596\n",
      "    val_log_marginal: 1723.3585713704426\n",
      "Train Epoch: 123 [0/54000 (0%)] Loss: -1737.270996\n",
      "Train Epoch: 123 [11264/54000 (21%)] Loss: -1738.414307\n",
      "Train Epoch: 123 [22528/54000 (42%)] Loss: -1737.697021\n",
      "Train Epoch: 123 [33792/54000 (63%)] Loss: -1736.247681\n",
      "Train Epoch: 123 [45056/54000 (83%)] Loss: -1740.062500\n",
      "    epoch          : 123\n",
      "    loss           : -1737.365631679319\n",
      "    ess            : 26.416561090721274\n",
      "    log_marginal   : 1737.6598902288472\n",
      "    val_loss       : -1728.630615234375\n",
      "    val_ess        : 26.627617518107098\n",
      "    val_log_marginal: 1728.9129028320312\n",
      "Train Epoch: 124 [0/54000 (0%)] Loss: -1742.833008\n",
      "Train Epoch: 124 [11264/54000 (21%)] Loss: -1736.062378\n",
      "Train Epoch: 124 [22528/54000 (42%)] Loss: -1739.419189\n",
      "Train Epoch: 124 [33792/54000 (63%)] Loss: -1741.704102\n",
      "Train Epoch: 124 [45056/54000 (83%)] Loss: -1739.318115\n",
      "    epoch          : 124\n",
      "    loss           : -1740.16196887898\n",
      "    ess            : 26.306750351527953\n",
      "    log_marginal   : 1740.464243762898\n",
      "    val_loss       : -1732.1950276692708\n",
      "    val_ess        : 26.515693346659344\n",
      "    val_log_marginal: 1732.4763692220051\n",
      "Train Epoch: 125 [0/54000 (0%)] Loss: -1741.037109\n",
      "Train Epoch: 125 [11264/54000 (21%)] Loss: -1747.246460\n",
      "Train Epoch: 125 [22528/54000 (42%)] Loss: -1744.059326\n",
      "Train Epoch: 125 [33792/54000 (63%)] Loss: -1745.476074\n",
      "Train Epoch: 125 [45056/54000 (83%)] Loss: -1740.228149\n",
      "    epoch          : 125\n",
      "    loss           : -1742.0297989755306\n",
      "    ess            : 26.234028096468943\n",
      "    log_marginal   : 1742.3385908018868\n",
      "    val_loss       : -1734.8311360677083\n",
      "    val_ess        : 25.978006680806477\n",
      "    val_log_marginal: 1735.1514892578125\n",
      "Train Epoch: 126 [0/54000 (0%)] Loss: -1747.830322\n",
      "Train Epoch: 126 [11264/54000 (21%)] Loss: -1743.025513\n",
      "Train Epoch: 126 [22528/54000 (42%)] Loss: -1742.631592\n",
      "Train Epoch: 126 [33792/54000 (63%)] Loss: -1742.989014\n",
      "Train Epoch: 126 [45056/54000 (83%)] Loss: -1743.895630\n",
      "    epoch          : 126\n",
      "    loss           : -1743.5541543060879\n",
      "    ess            : 26.27387881728838\n",
      "    log_marginal   : 1743.8570706349499\n",
      "    val_loss       : -1736.8790181477864\n",
      "    val_ess        : 26.407389005025227\n",
      "    val_log_marginal: 1737.1732279459636\n",
      "Train Epoch: 127 [0/54000 (0%)] Loss: -1749.136719\n",
      "Train Epoch: 127 [11264/54000 (21%)] Loss: -1741.225586\n",
      "Train Epoch: 127 [22528/54000 (42%)] Loss: -1746.843384\n",
      "Train Epoch: 127 [33792/54000 (63%)] Loss: -1744.449829\n",
      "Train Epoch: 127 [45056/54000 (83%)] Loss: -1741.987549\n",
      "    epoch          : 127\n",
      "    loss           : -1744.0763469192218\n",
      "    ess            : 26.218143031282246\n",
      "    log_marginal   : 1744.3835967441776\n",
      "    val_loss       : -1736.2936299641926\n",
      "    val_ess        : 26.48608112335205\n",
      "    val_log_marginal: 1736.5814514160156\n",
      "Train Epoch: 128 [0/54000 (0%)] Loss: -1746.168945\n",
      "Train Epoch: 128 [11264/54000 (21%)] Loss: -1685.780518\n",
      "Train Epoch: 128 [22528/54000 (42%)] Loss: -1735.023682\n",
      "Train Epoch: 128 [33792/54000 (63%)] Loss: -1715.051025\n",
      "Train Epoch: 128 [45056/54000 (83%)] Loss: -1724.957764\n",
      "    epoch          : 128\n",
      "    loss           : -1720.8048084187058\n",
      "    ess            : 26.305522216940826\n",
      "    log_marginal   : 1721.107785782724\n",
      "    val_loss       : -1731.6493835449219\n",
      "    val_ess        : 26.76052172978719\n",
      "    val_log_marginal: 1731.9213765462239\n",
      "Train Epoch: 129 [0/54000 (0%)] Loss: -1727.009766\n",
      "Train Epoch: 129 [11264/54000 (21%)] Loss: -1734.757080\n",
      "Train Epoch: 129 [22528/54000 (42%)] Loss: -1738.955322\n",
      "Train Epoch: 129 [33792/54000 (63%)] Loss: -1731.021729\n",
      "Train Epoch: 129 [45056/54000 (83%)] Loss: -1733.557617\n",
      "    epoch          : 129\n",
      "    loss           : -1734.8138934441333\n",
      "    ess            : 27.1930048060867\n",
      "    log_marginal   : 1735.067883761424\n",
      "    val_loss       : -1734.6343587239583\n",
      "    val_ess        : 26.40836000442505\n",
      "    val_log_marginal: 1734.9278259277344\n",
      "Train Epoch: 130 [0/54000 (0%)] Loss: -1745.070801\n",
      "Train Epoch: 130 [11264/54000 (21%)] Loss: -1736.501953\n",
      "Train Epoch: 130 [22528/54000 (42%)] Loss: -1745.590698\n",
      "Train Epoch: 130 [33792/54000 (63%)] Loss: -1738.461060\n",
      "Train Epoch: 130 [45056/54000 (83%)] Loss: -1740.852905\n",
      "    epoch          : 130\n",
      "    loss           : -1739.6605167029038\n",
      "    ess            : 26.601216640112536\n",
      "    log_marginal   : 1739.9509645857902\n",
      "    val_loss       : -1740.5842997233074\n",
      "    val_ess        : 26.57237497965495\n",
      "    val_log_marginal: 1740.8742167154949\n",
      "Train Epoch: 131 [0/54000 (0%)] Loss: -1747.395752\n",
      "Train Epoch: 131 [11264/54000 (21%)] Loss: -1744.465576\n",
      "Train Epoch: 131 [22528/54000 (42%)] Loss: -1743.187744\n",
      "Train Epoch: 131 [33792/54000 (63%)] Loss: -1744.898560\n",
      "Train Epoch: 131 [45056/54000 (83%)] Loss: -1744.193848\n",
      "    epoch          : 131\n",
      "    loss           : -1743.6430986512382\n",
      "    ess            : 26.4757783457918\n",
      "    log_marginal   : 1743.9384546819722\n",
      "    val_loss       : -1742.5755106608074\n",
      "    val_ess        : 26.732817490895588\n",
      "    val_log_marginal: 1742.8594563802083\n",
      "Train Epoch: 132 [0/54000 (0%)] Loss: -1744.726074\n",
      "Train Epoch: 132 [11264/54000 (21%)] Loss: -1746.481445\n",
      "Train Epoch: 132 [22528/54000 (42%)] Loss: -1748.060669\n",
      "Train Epoch: 132 [33792/54000 (63%)] Loss: -1742.222046\n",
      "Train Epoch: 132 [45056/54000 (83%)] Loss: -1747.378662\n",
      "    epoch          : 132\n",
      "    loss           : -1745.8429196915536\n",
      "    ess            : 26.30890464782715\n",
      "    log_marginal   : 1746.1512128721993\n",
      "    val_loss       : -1744.2618509928386\n",
      "    val_ess        : 26.01607656478882\n",
      "    val_log_marginal: 1744.5937906901042\n",
      "Train Epoch: 133 [0/54000 (0%)] Loss: -1751.693604\n",
      "Train Epoch: 133 [11264/54000 (21%)] Loss: -1752.150391\n",
      "Train Epoch: 133 [22528/54000 (42%)] Loss: -1741.155029\n",
      "Train Epoch: 133 [33792/54000 (63%)] Loss: -1746.322754\n",
      "Train Epoch: 133 [45056/54000 (83%)] Loss: -1746.495361\n",
      "    epoch          : 133\n",
      "    loss           : -1747.3775231703273\n",
      "    ess            : 26.333456975109172\n",
      "    log_marginal   : 1747.6899874705189\n",
      "    val_loss       : -1745.1693522135417\n",
      "    val_ess        : 26.112040042877197\n",
      "    val_log_marginal: 1745.493143717448\n",
      "Train Epoch: 134 [0/54000 (0%)] Loss: -1751.651855\n",
      "Train Epoch: 134 [11264/54000 (21%)] Loss: -1748.010864\n",
      "Train Epoch: 134 [22528/54000 (42%)] Loss: -1746.147095\n",
      "Train Epoch: 134 [33792/54000 (63%)] Loss: -1747.567017\n",
      "Train Epoch: 134 [45056/54000 (83%)] Loss: -1747.536377\n",
      "    epoch          : 134\n",
      "    loss           : -1748.2756911943543\n",
      "    ess            : 26.29884570499636\n",
      "    log_marginal   : 1748.590687877727\n",
      "    val_loss       : -1745.2167561848958\n",
      "    val_ess        : 26.077677090962727\n",
      "    val_log_marginal: 1745.5405375162761\n",
      "Train Epoch: 135 [0/54000 (0%)] Loss: -1748.906616\n",
      "Train Epoch: 135 [11264/54000 (21%)] Loss: -1745.089844\n",
      "Train Epoch: 135 [22528/54000 (42%)] Loss: -1699.448486\n",
      "Train Epoch: 135 [33792/54000 (63%)] Loss: -1728.234741\n",
      "Train Epoch: 135 [45056/54000 (83%)] Loss: -1740.304688\n",
      "    epoch          : 135\n",
      "    loss           : -1733.171428176592\n",
      "    ess            : 26.25424854710417\n",
      "    log_marginal   : 1733.483977695681\n",
      "    val_loss       : -1722.7181193033855\n",
      "    val_ess        : 26.348797639211018\n",
      "    val_log_marginal: 1723.02294921875\n",
      "Train Epoch: 136 [0/54000 (0%)] Loss: -1735.762817\n",
      "Train Epoch: 136 [11264/54000 (21%)] Loss: -1745.158081\n",
      "Train Epoch: 136 [22528/54000 (42%)] Loss: -1744.309570\n",
      "Train Epoch: 136 [33792/54000 (63%)] Loss: -1740.919067\n",
      "Train Epoch: 136 [45056/54000 (83%)] Loss: -1745.689209\n",
      "    epoch          : 136\n",
      "    loss           : -1740.6076487415241\n",
      "    ess            : 26.90244581114571\n",
      "    log_marginal   : 1740.8874200784935\n",
      "    val_loss       : -1734.3221638997395\n",
      "    val_ess        : 27.314780394236248\n",
      "    val_log_marginal: 1734.5718485514324\n",
      "Train Epoch: 137 [0/54000 (0%)] Loss: -1739.914917\n",
      "Train Epoch: 137 [11264/54000 (21%)] Loss: -1751.953857\n",
      "Train Epoch: 137 [22528/54000 (42%)] Loss: -1747.116699\n",
      "Train Epoch: 137 [33792/54000 (63%)] Loss: -1748.004272\n",
      "Train Epoch: 137 [45056/54000 (83%)] Loss: -1746.494507\n",
      "    epoch          : 137\n",
      "    loss           : -1746.458898004496\n",
      "    ess            : 26.67172683859771\n",
      "    log_marginal   : 1746.7522686652417\n",
      "    val_loss       : -1741.9066060384114\n",
      "    val_ess        : 26.393767992655437\n",
      "    val_log_marginal: 1742.2299906412761\n",
      "Train Epoch: 138 [0/54000 (0%)] Loss: -1745.686768\n",
      "Train Epoch: 138 [11264/54000 (21%)] Loss: -1749.757568\n",
      "Train Epoch: 138 [22528/54000 (42%)] Loss: -1747.890381\n",
      "Train Epoch: 138 [33792/54000 (63%)] Loss: -1743.300781\n",
      "Train Epoch: 138 [45056/54000 (83%)] Loss: -1753.357788\n",
      "    epoch          : 138\n",
      "    loss           : -1748.8414801831516\n",
      "    ess            : 26.354337818217726\n",
      "    log_marginal   : 1749.150510392099\n",
      "    val_loss       : -1744.3451741536458\n",
      "    val_ess        : 26.406127452850342\n",
      "    val_log_marginal: 1744.6529846191406\n",
      "Train Epoch: 139 [0/54000 (0%)] Loss: -1748.378906\n",
      "Train Epoch: 139 [11264/54000 (21%)] Loss: -1747.885376\n",
      "Train Epoch: 139 [22528/54000 (42%)] Loss: -1751.194092\n",
      "Train Epoch: 139 [33792/54000 (63%)] Loss: -1745.693237\n",
      "Train Epoch: 139 [45056/54000 (83%)] Loss: -1754.667480\n",
      "    epoch          : 139\n",
      "    loss           : -1750.2889772811027\n",
      "    ess            : 26.269065982890577\n",
      "    log_marginal   : 1750.606523621757\n",
      "    val_loss       : -1746.0840352376301\n",
      "    val_ess        : 26.435649077097576\n",
      "    val_log_marginal: 1746.3924357096355\n",
      "Train Epoch: 140 [0/54000 (0%)] Loss: -1749.570068\n",
      "Train Epoch: 140 [11264/54000 (21%)] Loss: -1745.379028\n",
      "Train Epoch: 140 [22528/54000 (42%)] Loss: -1753.961182\n",
      "Train Epoch: 140 [33792/54000 (63%)] Loss: -1754.158081\n",
      "Train Epoch: 140 [45056/54000 (83%)] Loss: -1753.363770\n",
      "    epoch          : 140\n",
      "    loss           : -1751.544114598688\n",
      "    ess            : 26.383760236344248\n",
      "    log_marginal   : 1751.852952489313\n",
      "    val_loss       : -1747.5315958658855\n",
      "    val_ess        : 26.376917997996014\n",
      "    val_log_marginal: 1747.8473307291667\n",
      "Train Epoch: 141 [0/54000 (0%)] Loss: -1760.336914\n",
      "Train Epoch: 141 [11264/54000 (21%)] Loss: -1752.660278\n",
      "Train Epoch: 141 [22528/54000 (42%)] Loss: -1753.898193\n",
      "Train Epoch: 141 [33792/54000 (63%)] Loss: -1755.291504\n",
      "Train Epoch: 141 [45056/54000 (83%)] Loss: -1754.716797\n",
      "    epoch          : 141\n",
      "    loss           : -1751.7487447486733\n",
      "    ess            : 26.384057314890736\n",
      "    log_marginal   : 1752.063936053582\n",
      "    val_loss       : -1743.919413248698\n",
      "    val_ess        : 26.19847361246745\n",
      "    val_log_marginal: 1744.243428548177\n",
      "Train Epoch: 142 [0/54000 (0%)] Loss: -1741.363892\n",
      "Train Epoch: 142 [11264/54000 (21%)] Loss: -1707.128174\n",
      "Train Epoch: 142 [22528/54000 (42%)] Loss: -1734.994385\n",
      "Train Epoch: 142 [33792/54000 (63%)] Loss: -1745.817139\n",
      "Train Epoch: 142 [45056/54000 (83%)] Loss: -1737.365845\n",
      "    epoch          : 142\n",
      "    loss           : -1734.0743984006485\n",
      "    ess            : 26.426047145195728\n",
      "    log_marginal   : 1734.3772444815006\n",
      "    val_loss       : -1734.9363911946614\n",
      "    val_ess        : 26.6863431930542\n",
      "    val_log_marginal: 1735.2405293782551\n",
      "Train Epoch: 143 [0/54000 (0%)] Loss: -1736.237549\n",
      "Train Epoch: 143 [11264/54000 (21%)] Loss: -1740.076294\n",
      "Train Epoch: 143 [22528/54000 (42%)] Loss: -1740.213989\n",
      "Train Epoch: 143 [33792/54000 (63%)] Loss: -1742.545898\n",
      "Train Epoch: 143 [45056/54000 (83%)] Loss: -1741.035156\n",
      "    epoch          : 143\n",
      "    loss           : -1743.1781132536114\n",
      "    ess            : 27.1351801674321\n",
      "    log_marginal   : 1743.4513342515477\n",
      "    val_loss       : -1743.7563985188801\n",
      "    val_ess        : 26.942129770914715\n",
      "    val_log_marginal: 1744.0426025390625\n",
      "Train Epoch: 144 [0/54000 (0%)] Loss: -1748.027832\n",
      "Train Epoch: 144 [11264/54000 (21%)] Loss: -1744.697998\n",
      "Train Epoch: 144 [22528/54000 (42%)] Loss: -1753.364990\n",
      "Train Epoch: 144 [33792/54000 (63%)] Loss: -1748.445801\n",
      "Train Epoch: 144 [45056/54000 (83%)] Loss: -1750.472168\n",
      "    epoch          : 144\n",
      "    loss           : -1748.878186495799\n",
      "    ess            : 26.659377835831553\n",
      "    log_marginal   : 1749.1737601802033\n",
      "    val_loss       : -1744.9414367675781\n",
      "    val_ess        : 26.37507692972819\n",
      "    val_log_marginal: 1745.2650146484375\n",
      "Train Epoch: 145 [0/54000 (0%)] Loss: -1750.615723\n",
      "Train Epoch: 145 [11264/54000 (21%)] Loss: -1749.920532\n",
      "Train Epoch: 145 [22528/54000 (42%)] Loss: -1746.383911\n",
      "Train Epoch: 145 [33792/54000 (63%)] Loss: -1751.697876\n",
      "Train Epoch: 145 [45056/54000 (83%)] Loss: -1750.472900\n",
      "    epoch          : 145\n",
      "    loss           : -1748.5598605173939\n",
      "    ess            : 26.510918977125634\n",
      "    log_marginal   : 1748.868676527491\n",
      "    val_loss       : -1749.2347310384114\n",
      "    val_ess        : 26.419549306233723\n",
      "    val_log_marginal: 1749.5542399088542\n",
      "Train Epoch: 146 [0/54000 (0%)] Loss: -1750.376953\n",
      "Train Epoch: 146 [11264/54000 (21%)] Loss: -1752.043823\n",
      "Train Epoch: 146 [22528/54000 (42%)] Loss: -1756.066406\n",
      "Train Epoch: 146 [33792/54000 (63%)] Loss: -1751.362061\n",
      "Train Epoch: 146 [45056/54000 (83%)] Loss: -1751.102661\n",
      "    epoch          : 146\n",
      "    loss           : -1752.6852106058373\n",
      "    ess            : 26.668265342712402\n",
      "    log_marginal   : 1752.9832107256043\n",
      "    val_loss       : -1751.1641642252605\n",
      "    val_ess        : 26.50521167119344\n",
      "    val_log_marginal: 1751.4740091959636\n",
      "Train Epoch: 147 [0/54000 (0%)] Loss: -1755.702637\n",
      "Train Epoch: 147 [11264/54000 (21%)] Loss: -1756.251831\n",
      "Train Epoch: 147 [22528/54000 (42%)] Loss: -1756.252930\n",
      "Train Epoch: 147 [33792/54000 (63%)] Loss: -1754.398682\n",
      "Train Epoch: 147 [45056/54000 (83%)] Loss: -1754.526611\n",
      "    epoch          : 147\n",
      "    loss           : -1754.5755027914947\n",
      "    ess            : 26.429095430194206\n",
      "    log_marginal   : 1754.8886995135613\n",
      "    val_loss       : -1752.8502604166667\n",
      "    val_ess        : 26.17373530069987\n",
      "    val_log_marginal: 1753.1687927246094\n",
      "Train Epoch: 148 [0/54000 (0%)] Loss: -1756.230957\n",
      "Train Epoch: 148 [11264/54000 (21%)] Loss: -1753.480957\n",
      "Train Epoch: 148 [22528/54000 (42%)] Loss: -1746.870605\n",
      "Train Epoch: 148 [33792/54000 (63%)] Loss: -1762.510864\n",
      "Train Epoch: 148 [45056/54000 (83%)] Loss: -1757.846191\n",
      "    epoch          : 148\n",
      "    loss           : -1755.8230487175708\n",
      "    ess            : 26.485679752421827\n",
      "    log_marginal   : 1756.1358504385319\n",
      "    val_loss       : -1753.8299763997395\n",
      "    val_ess        : 26.45159371693929\n",
      "    val_log_marginal: 1754.158935546875\n",
      "Train Epoch: 149 [0/54000 (0%)] Loss: -1754.792480\n",
      "Train Epoch: 149 [11264/54000 (21%)] Loss: -1753.390625\n",
      "Train Epoch: 149 [22528/54000 (42%)] Loss: -1754.315063\n",
      "Train Epoch: 149 [33792/54000 (63%)] Loss: -1755.041016\n",
      "Train Epoch: 149 [45056/54000 (83%)] Loss: -1754.763916\n",
      "    epoch          : 149\n",
      "    loss           : -1756.8597861235996\n",
      "    ess            : 26.385906147507\n",
      "    log_marginal   : 1757.1830133402123\n",
      "    val_loss       : -1754.5244242350261\n",
      "    val_ess        : 26.348844528198242\n",
      "    val_log_marginal: 1754.8561096191406\n",
      "Train Epoch: 150 [0/54000 (0%)] Loss: -1762.937622\n",
      "Train Epoch: 150 [11264/54000 (21%)] Loss: -1755.437744\n",
      "Train Epoch: 150 [22528/54000 (42%)] Loss: -1760.650879\n",
      "Train Epoch: 150 [33792/54000 (63%)] Loss: -1753.872803\n",
      "Train Epoch: 150 [45056/54000 (83%)] Loss: -1756.371094\n",
      "    epoch          : 150\n",
      "    loss           : -1756.6496777804393\n",
      "    ess            : 26.44508703699652\n",
      "    log_marginal   : 1756.9685024045548\n",
      "    val_loss       : -1750.0087178548176\n",
      "    val_ess        : 26.29539203643799\n",
      "    val_log_marginal: 1750.3304341634114\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch150.pth ...\n",
      "Train Epoch: 151 [0/54000 (0%)] Loss: -1750.897949\n",
      "Train Epoch: 151 [11264/54000 (21%)] Loss: -1699.436279\n",
      "Train Epoch: 151 [22528/54000 (42%)] Loss: -1740.086060\n",
      "Train Epoch: 151 [33792/54000 (63%)] Loss: -1734.529419\n",
      "Train Epoch: 151 [45056/54000 (83%)] Loss: -1751.575562\n",
      "    epoch          : 151\n",
      "    loss           : -1736.6508432064416\n",
      "    ess            : 26.39572213730722\n",
      "    log_marginal   : 1736.9623390053803\n",
      "    val_loss       : -1741.7715555826824\n",
      "    val_ess        : 27.01410500208537\n",
      "    val_log_marginal: 1742.0495300292969\n",
      "Train Epoch: 152 [0/54000 (0%)] Loss: -1746.015259\n",
      "Train Epoch: 152 [11264/54000 (21%)] Loss: -1748.626221\n",
      "Train Epoch: 152 [22528/54000 (42%)] Loss: -1750.040405\n",
      "Train Epoch: 152 [33792/54000 (63%)] Loss: -1744.993042\n",
      "Train Epoch: 152 [45056/54000 (83%)] Loss: -1748.821899\n",
      "    epoch          : 152\n",
      "    loss           : -1745.3937596734966\n",
      "    ess            : 27.122613636952526\n",
      "    log_marginal   : 1745.6667227115272\n",
      "    val_loss       : -1738.7207641601562\n",
      "    val_ess        : 27.115090529123943\n",
      "    val_log_marginal: 1738.9891560872395\n",
      "Train Epoch: 153 [0/54000 (0%)] Loss: -1737.584961\n",
      "Train Epoch: 153 [11264/54000 (21%)] Loss: -1733.247559\n",
      "Train Epoch: 153 [22528/54000 (42%)] Loss: -1751.985107\n",
      "Train Epoch: 153 [33792/54000 (63%)] Loss: -1737.484619\n",
      "Train Epoch: 153 [45056/54000 (83%)] Loss: -1728.024658\n",
      "    epoch          : 153\n",
      "    loss           : -1738.5736936173348\n",
      "    ess            : 26.858440399169922\n",
      "    log_marginal   : 1738.8576959573998\n",
      "    val_loss       : -1736.0033060709636\n",
      "    val_ess        : 26.961151599884033\n",
      "    val_log_marginal: 1736.2899068196614\n",
      "Train Epoch: 154 [0/54000 (0%)] Loss: -1739.619995\n",
      "Train Epoch: 154 [11264/54000 (21%)] Loss: -1747.659302\n",
      "Train Epoch: 154 [22528/54000 (42%)] Loss: -1744.431885\n",
      "Train Epoch: 154 [33792/54000 (63%)] Loss: -1749.330811\n",
      "Train Epoch: 154 [45056/54000 (83%)] Loss: -1749.833496\n",
      "    epoch          : 154\n",
      "    loss           : -1746.366053167379\n",
      "    ess            : 27.00764560699463\n",
      "    log_marginal   : 1746.6454076227153\n",
      "    val_loss       : -1748.6394958496094\n",
      "    val_ess        : 26.982107162475586\n",
      "    val_log_marginal: 1748.9230143229167\n",
      "Train Epoch: 155 [0/54000 (0%)] Loss: -1753.377441\n",
      "Train Epoch: 155 [11264/54000 (21%)] Loss: -1748.914062\n",
      "Train Epoch: 155 [22528/54000 (42%)] Loss: -1757.354248\n",
      "Train Epoch: 155 [33792/54000 (63%)] Loss: -1753.684326\n",
      "Train Epoch: 155 [45056/54000 (83%)] Loss: -1754.405518\n",
      "    epoch          : 155\n",
      "    loss           : -1752.13923040426\n",
      "    ess            : 26.542637663067513\n",
      "    log_marginal   : 1752.4450464788472\n",
      "    val_loss       : -1752.2001851399739\n",
      "    val_ess        : 26.517781893412273\n",
      "    val_log_marginal: 1752.5045776367188\n",
      "Train Epoch: 156 [0/54000 (0%)] Loss: -1758.295410\n",
      "Train Epoch: 156 [11264/54000 (21%)] Loss: -1754.090820\n",
      "Train Epoch: 156 [22528/54000 (42%)] Loss: -1755.284546\n",
      "Train Epoch: 156 [33792/54000 (63%)] Loss: -1759.573486\n",
      "Train Epoch: 156 [45056/54000 (83%)] Loss: -1757.670654\n",
      "    epoch          : 156\n",
      "    loss           : -1754.4368838904038\n",
      "    ess            : 26.498533518809193\n",
      "    log_marginal   : 1754.7490764114093\n",
      "    val_loss       : -1753.9425862630208\n",
      "    val_ess        : 26.562937259674072\n",
      "    val_log_marginal: 1754.2522684733074\n",
      "Train Epoch: 157 [0/54000 (0%)] Loss: -1755.561035\n",
      "Train Epoch: 157 [11264/54000 (21%)] Loss: -1752.482178\n",
      "Train Epoch: 157 [22528/54000 (42%)] Loss: -1753.818970\n",
      "Train Epoch: 157 [33792/54000 (63%)] Loss: -1757.551270\n",
      "Train Epoch: 157 [45056/54000 (83%)] Loss: -1756.368652\n",
      "    epoch          : 157\n",
      "    loss           : -1756.0103103349793\n",
      "    ess            : 26.460493213725538\n",
      "    log_marginal   : 1756.3246759378685\n",
      "    val_loss       : -1755.3321024576824\n",
      "    val_ess        : 26.453123569488525\n",
      "    val_log_marginal: 1755.6502278645833\n",
      "Train Epoch: 158 [0/54000 (0%)] Loss: -1757.052490\n",
      "Train Epoch: 158 [11264/54000 (21%)] Loss: -1757.617798\n",
      "Train Epoch: 158 [22528/54000 (42%)] Loss: -1757.885010\n",
      "Train Epoch: 158 [33792/54000 (63%)] Loss: -1761.611450\n",
      "Train Epoch: 158 [45056/54000 (83%)] Loss: -1754.831543\n",
      "    epoch          : 158\n",
      "    loss           : -1757.202400639372\n",
      "    ess            : 26.42951155608555\n",
      "    log_marginal   : 1757.5203719229069\n",
      "    val_loss       : -1755.9786275227864\n",
      "    val_ess        : 26.19724973042806\n",
      "    val_log_marginal: 1756.3221537272136\n",
      "Train Epoch: 159 [0/54000 (0%)] Loss: -1754.807373\n",
      "Train Epoch: 159 [11264/54000 (21%)] Loss: -1757.961060\n",
      "Train Epoch: 159 [22528/54000 (42%)] Loss: -1761.493774\n",
      "Train Epoch: 159 [33792/54000 (63%)] Loss: -1758.384521\n",
      "Train Epoch: 159 [45056/54000 (83%)] Loss: -1754.729492\n",
      "    epoch          : 159\n",
      "    loss           : -1758.3050318304097\n",
      "    ess            : 26.433836505098164\n",
      "    log_marginal   : 1758.6229455336086\n",
      "    val_loss       : -1757.0721944173176\n",
      "    val_ess        : 26.474945386250813\n",
      "    val_log_marginal: 1757.389628092448\n",
      "Train Epoch: 160 [0/54000 (0%)] Loss: -1758.195312\n",
      "Train Epoch: 160 [11264/54000 (21%)] Loss: -1758.196533\n",
      "Train Epoch: 160 [22528/54000 (42%)] Loss: -1758.245850\n",
      "Train Epoch: 160 [33792/54000 (63%)] Loss: -1758.067871\n",
      "Train Epoch: 160 [45056/54000 (83%)] Loss: -1757.972168\n",
      "    epoch          : 160\n",
      "    loss           : -1759.308875893647\n",
      "    ess            : 26.398328115355294\n",
      "    log_marginal   : 1759.635485379201\n",
      "    val_loss       : -1758.2781778971355\n",
      "    val_ess        : 26.618144671122234\n",
      "    val_log_marginal: 1758.5887044270833\n",
      "Train Epoch: 161 [0/54000 (0%)] Loss: -1762.546143\n",
      "Train Epoch: 161 [11264/54000 (21%)] Loss: -1763.468140\n",
      "Train Epoch: 161 [22528/54000 (42%)] Loss: -1758.437500\n",
      "Train Epoch: 161 [33792/54000 (63%)] Loss: -1759.011353\n",
      "Train Epoch: 161 [45056/54000 (83%)] Loss: -1758.712280\n",
      "    epoch          : 161\n",
      "    loss           : -1759.3160054908608\n",
      "    ess            : 26.490166088320173\n",
      "    log_marginal   : 1759.6394019936615\n",
      "    val_loss       : -1755.2529907226562\n",
      "    val_ess        : 26.40908447901408\n",
      "    val_log_marginal: 1755.5756530761719\n",
      "Train Epoch: 162 [0/54000 (0%)] Loss: -1760.106445\n",
      "Train Epoch: 162 [11264/54000 (21%)] Loss: -1716.489624\n",
      "Train Epoch: 162 [22528/54000 (42%)] Loss: -1714.156250\n",
      "Train Epoch: 162 [33792/54000 (63%)] Loss: -1679.816406\n",
      "Train Epoch: 162 [45056/54000 (83%)] Loss: -1709.217896\n",
      "    epoch          : 162\n",
      "    loss           : -1713.7493746775501\n",
      "    ess            : 26.389402191593962\n",
      "    log_marginal   : 1714.0557769199588\n",
      "    val_loss       : -1730.4890848795574\n",
      "    val_ess        : 26.475931644439697\n",
      "    val_log_marginal: 1730.7987772623699\n",
      "Train Epoch: 163 [0/54000 (0%)] Loss: -1725.080566\n",
      "Train Epoch: 163 [11264/54000 (21%)] Loss: -1734.869141\n",
      "Train Epoch: 163 [22528/54000 (42%)] Loss: -1732.856079\n",
      "Train Epoch: 163 [33792/54000 (63%)] Loss: -1738.660767\n",
      "Train Epoch: 163 [45056/54000 (83%)] Loss: -1740.510742\n",
      "    epoch          : 163\n",
      "    loss           : -1735.8957035856427\n",
      "    ess            : 27.702135104053426\n",
      "    log_marginal   : 1736.135680000737\n",
      "    val_loss       : -1746.0465291341145\n",
      "    val_ess        : 27.18259572982788\n",
      "    val_log_marginal: 1746.3059997558594\n",
      "Train Epoch: 164 [0/54000 (0%)] Loss: -1747.752075\n",
      "Train Epoch: 164 [11264/54000 (21%)] Loss: -1749.249512\n",
      "Train Epoch: 164 [22528/54000 (42%)] Loss: -1743.629272\n",
      "Train Epoch: 164 [33792/54000 (63%)] Loss: -1748.602539\n",
      "Train Epoch: 164 [45056/54000 (83%)] Loss: -1752.729126\n",
      "    epoch          : 164\n",
      "    loss           : -1747.4813865805572\n",
      "    ess            : 26.91631461089512\n",
      "    log_marginal   : 1747.766788122789\n",
      "    val_loss       : -1752.0744018554688\n",
      "    val_ess        : 26.603554884592693\n",
      "    val_log_marginal: 1752.3679606119792\n",
      "Train Epoch: 165 [0/54000 (0%)] Loss: -1746.836060\n",
      "Train Epoch: 165 [11264/54000 (21%)] Loss: -1749.006958\n",
      "Train Epoch: 165 [22528/54000 (42%)] Loss: -1749.902222\n",
      "Train Epoch: 165 [33792/54000 (63%)] Loss: -1750.688354\n",
      "Train Epoch: 165 [45056/54000 (83%)] Loss: -1756.381836\n",
      "    epoch          : 165\n",
      "    loss           : -1751.524409456073\n",
      "    ess            : 26.485383933445192\n",
      "    log_marginal   : 1751.8396836766656\n",
      "    val_loss       : -1754.1512145996094\n",
      "    val_ess        : 26.30670404434204\n",
      "    val_log_marginal: 1754.4841206868489\n",
      "Train Epoch: 166 [0/54000 (0%)] Loss: -1754.175781\n",
      "Train Epoch: 166 [11264/54000 (21%)] Loss: -1754.544678\n",
      "Train Epoch: 166 [22528/54000 (42%)] Loss: -1752.983154\n",
      "Train Epoch: 166 [33792/54000 (63%)] Loss: -1754.065918\n",
      "Train Epoch: 166 [45056/54000 (83%)] Loss: -1753.090332\n",
      "    epoch          : 166\n",
      "    loss           : -1753.6912058704304\n",
      "    ess            : 26.413358886286897\n",
      "    log_marginal   : 1754.0098105376621\n",
      "    val_loss       : -1755.661844889323\n",
      "    val_ess        : 26.4764404296875\n",
      "    val_log_marginal: 1755.9774881998699\n",
      "Train Epoch: 167 [0/54000 (0%)] Loss: -1759.141602\n",
      "Train Epoch: 167 [11264/54000 (21%)] Loss: -1756.852783\n",
      "Train Epoch: 167 [22528/54000 (42%)] Loss: -1754.390869\n",
      "Train Epoch: 167 [33792/54000 (63%)] Loss: -1753.210327\n",
      "Train Epoch: 167 [45056/54000 (83%)] Loss: -1758.542847\n",
      "    epoch          : 167\n",
      "    loss           : -1755.2596562223614\n",
      "    ess            : 26.46217162654085\n",
      "    log_marginal   : 1755.5750386939858\n",
      "    val_loss       : -1756.6563212076824\n",
      "    val_ess        : 26.223505814870197\n",
      "    val_log_marginal: 1756.9957377115886\n",
      "Train Epoch: 168 [0/54000 (0%)] Loss: -1763.314453\n",
      "Train Epoch: 168 [11264/54000 (21%)] Loss: -1754.016846\n",
      "Train Epoch: 168 [22528/54000 (42%)] Loss: -1753.380859\n",
      "Train Epoch: 168 [33792/54000 (63%)] Loss: -1757.153809\n",
      "Train Epoch: 168 [45056/54000 (83%)] Loss: -1757.232422\n",
      "    epoch          : 168\n",
      "    loss           : -1756.5162503224499\n",
      "    ess            : 26.455805796497273\n",
      "    log_marginal   : 1756.8364706939121\n",
      "    val_loss       : -1757.2603963216145\n",
      "    val_ess        : 26.499752044677734\n",
      "    val_log_marginal: 1757.5667317708333\n",
      "Train Epoch: 169 [0/54000 (0%)] Loss: -1756.113037\n",
      "Train Epoch: 169 [11264/54000 (21%)] Loss: -1728.819092\n",
      "Train Epoch: 169 [22528/54000 (42%)] Loss: -1735.340820\n",
      "Train Epoch: 169 [33792/54000 (63%)] Loss: -1741.806030\n",
      "Train Epoch: 169 [45056/54000 (83%)] Loss: -1730.547607\n",
      "    epoch          : 169\n",
      "    loss           : -1736.6680447560436\n",
      "    ess            : 26.37733898522719\n",
      "    log_marginal   : 1736.9836932488208\n",
      "    val_loss       : -1740.0474243164062\n",
      "    val_ess        : 26.38144000371297\n",
      "    val_log_marginal: 1740.3605041503906\n",
      "Train Epoch: 170 [0/54000 (0%)] Loss: -1744.361694\n",
      "Train Epoch: 170 [11264/54000 (21%)] Loss: -1751.102051\n",
      "Train Epoch: 170 [22528/54000 (42%)] Loss: -1751.036255\n",
      "Train Epoch: 170 [33792/54000 (63%)] Loss: -1745.566040\n",
      "Train Epoch: 170 [45056/54000 (83%)] Loss: -1743.858643\n",
      "    epoch          : 170\n",
      "    loss           : -1747.6299887603184\n",
      "    ess            : 27.145410339787322\n",
      "    log_marginal   : 1747.9044200969192\n",
      "    val_loss       : -1749.8953247070312\n",
      "    val_ess        : 27.251938501993816\n",
      "    val_log_marginal: 1750.1606547037761\n",
      "Train Epoch: 171 [0/54000 (0%)] Loss: -1752.600952\n",
      "Train Epoch: 171 [11264/54000 (21%)] Loss: -1756.914917\n",
      "Train Epoch: 171 [22528/54000 (42%)] Loss: -1747.451172\n",
      "Train Epoch: 171 [33792/54000 (63%)] Loss: -1750.075684\n",
      "Train Epoch: 171 [45056/54000 (83%)] Loss: -1751.762329\n",
      "    epoch          : 171\n",
      "    loss           : -1752.3320139758991\n",
      "    ess            : 26.761982018092894\n",
      "    log_marginal   : 1752.6302812684257\n",
      "    val_loss       : -1753.590067545573\n",
      "    val_ess        : 26.59623670578003\n",
      "    val_log_marginal: 1753.8953653971355\n",
      "Train Epoch: 172 [0/54000 (0%)] Loss: -1758.754395\n",
      "Train Epoch: 172 [11264/54000 (21%)] Loss: -1752.790039\n",
      "Train Epoch: 172 [22528/54000 (42%)] Loss: -1750.892578\n",
      "Train Epoch: 172 [33792/54000 (63%)] Loss: -1754.324707\n",
      "Train Epoch: 172 [45056/54000 (83%)] Loss: -1753.196289\n",
      "    epoch          : 172\n",
      "    loss           : -1754.701875506707\n",
      "    ess            : 26.50413975625668\n",
      "    log_marginal   : 1755.0183761884582\n",
      "    val_loss       : -1755.068583170573\n",
      "    val_ess        : 26.61915636062622\n",
      "    val_log_marginal: 1755.3702799479167\n",
      "Train Epoch: 173 [0/54000 (0%)] Loss: -1755.459229\n",
      "Train Epoch: 173 [11264/54000 (21%)] Loss: -1755.220459\n",
      "Train Epoch: 173 [22528/54000 (42%)] Loss: -1757.887207\n",
      "Train Epoch: 173 [33792/54000 (63%)] Loss: -1752.166870\n",
      "Train Epoch: 173 [45056/54000 (83%)] Loss: -1721.844482\n",
      "    epoch          : 173\n",
      "    loss           : -1748.6300590083283\n",
      "    ess            : 26.350180014124458\n",
      "    log_marginal   : 1748.9529775943397\n",
      "    val_loss       : -1745.5891215006511\n",
      "    val_ess        : 26.446986039479572\n",
      "    val_log_marginal: 1745.8946329752605\n",
      "Train Epoch: 174 [0/54000 (0%)] Loss: -1743.564209\n",
      "Train Epoch: 174 [11264/54000 (21%)] Loss: -1751.348389\n",
      "Train Epoch: 174 [22528/54000 (42%)] Loss: -1751.425293\n",
      "Train Epoch: 174 [33792/54000 (63%)] Loss: -1750.749390\n",
      "Train Epoch: 174 [45056/54000 (83%)] Loss: -1754.784424\n",
      "    epoch          : 174\n",
      "    loss           : -1750.0291160727447\n",
      "    ess            : 26.6907047955495\n",
      "    log_marginal   : 1750.3332945625737\n",
      "    val_loss       : -1754.3151143391926\n",
      "    val_ess        : 26.647579193115234\n",
      "    val_log_marginal: 1754.612772623698\n",
      "Train Epoch: 175 [0/54000 (0%)] Loss: -1756.625610\n",
      "Train Epoch: 175 [11264/54000 (21%)] Loss: -1750.070312\n",
      "Train Epoch: 175 [22528/54000 (42%)] Loss: -1759.770996\n",
      "Train Epoch: 175 [33792/54000 (63%)] Loss: -1754.525146\n",
      "Train Epoch: 175 [45056/54000 (83%)] Loss: -1754.957764\n",
      "    epoch          : 175\n",
      "    loss           : -1755.221076245578\n",
      "    ess            : 26.611266999874474\n",
      "    log_marginal   : 1755.5310150722287\n",
      "    val_loss       : -1756.7268371582031\n",
      "    val_ess        : 26.714189370473225\n",
      "    val_log_marginal: 1757.0186971028645\n",
      "Train Epoch: 176 [0/54000 (0%)] Loss: -1754.045288\n",
      "Train Epoch: 176 [11264/54000 (21%)] Loss: -1754.316406\n",
      "Train Epoch: 176 [22528/54000 (42%)] Loss: -1751.217041\n",
      "Train Epoch: 176 [33792/54000 (63%)] Loss: -1758.701660\n",
      "Train Epoch: 176 [45056/54000 (83%)] Loss: -1752.182007\n",
      "    epoch          : 176\n",
      "    loss           : -1757.1133353755158\n",
      "    ess            : 26.49096454764312\n",
      "    log_marginal   : 1757.4330214014594\n",
      "    val_loss       : -1758.1612447102864\n",
      "    val_ess        : 26.619404157002766\n",
      "    val_log_marginal: 1758.4681803385417\n",
      "Train Epoch: 177 [0/54000 (0%)] Loss: -1760.731934\n",
      "Train Epoch: 177 [11264/54000 (21%)] Loss: -1759.197144\n",
      "Train Epoch: 177 [22528/54000 (42%)] Loss: -1760.309326\n",
      "Train Epoch: 177 [33792/54000 (63%)] Loss: -1764.047119\n",
      "Train Epoch: 177 [45056/54000 (83%)] Loss: -1758.813477\n",
      "    epoch          : 177\n",
      "    loss           : -1758.4945828419811\n",
      "    ess            : 26.481337259400565\n",
      "    log_marginal   : 1758.8149229805424\n",
      "    val_loss       : -1759.3751729329426\n",
      "    val_ess        : 26.53772846857707\n",
      "    val_log_marginal: 1759.6927388509114\n",
      "Train Epoch: 178 [0/54000 (0%)] Loss: -1757.316162\n",
      "Train Epoch: 178 [11264/54000 (21%)] Loss: -1764.782471\n",
      "Train Epoch: 178 [22528/54000 (42%)] Loss: -1765.184570\n",
      "Train Epoch: 178 [33792/54000 (63%)] Loss: -1763.806152\n",
      "Train Epoch: 178 [45056/54000 (83%)] Loss: -1760.996826\n",
      "    epoch          : 178\n",
      "    loss           : -1759.4909679484817\n",
      "    ess            : 26.441984338580436\n",
      "    log_marginal   : 1759.8140097564121\n",
      "    val_loss       : -1759.3368631998699\n",
      "    val_ess        : 26.36513074239095\n",
      "    val_log_marginal: 1759.6548461914062\n",
      "Train Epoch: 179 [0/54000 (0%)] Loss: -1759.037354\n",
      "Train Epoch: 179 [11264/54000 (21%)] Loss: -1758.307617\n",
      "Train Epoch: 179 [22528/54000 (42%)] Loss: -1760.011108\n",
      "Train Epoch: 179 [33792/54000 (63%)] Loss: -1754.552490\n",
      "Train Epoch: 179 [45056/54000 (83%)] Loss: -1695.031616\n",
      "    epoch          : 179\n",
      "    loss           : -1747.3171985554245\n",
      "    ess            : 26.459335776994813\n",
      "    log_marginal   : 1747.6318048441185\n",
      "    val_loss       : -1743.4864298502605\n",
      "    val_ess        : 26.40174945195516\n",
      "    val_log_marginal: 1743.799072265625\n",
      "Train Epoch: 180 [0/54000 (0%)] Loss: -1741.360352\n",
      "Train Epoch: 180 [11264/54000 (21%)] Loss: -1748.526367\n",
      "Train Epoch: 180 [22528/54000 (42%)] Loss: -1748.401367\n",
      "Train Epoch: 180 [33792/54000 (63%)] Loss: -1746.152832\n",
      "Train Epoch: 180 [45056/54000 (83%)] Loss: -1746.094727\n",
      "    epoch          : 180\n",
      "    loss           : -1746.5090355063385\n",
      "    ess            : 26.939985815084206\n",
      "    log_marginal   : 1746.799010078862\n",
      "    val_loss       : -1755.5356038411458\n",
      "    val_ess        : 27.171137650807697\n",
      "    val_log_marginal: 1755.8066914876301\n",
      "Train Epoch: 181 [0/54000 (0%)] Loss: -1749.663574\n",
      "Train Epoch: 181 [11264/54000 (21%)] Loss: -1753.190918\n",
      "Train Epoch: 181 [22528/54000 (42%)] Loss: -1760.101074\n",
      "Train Epoch: 181 [33792/54000 (63%)] Loss: -1752.834595\n",
      "Train Epoch: 181 [45056/54000 (83%)] Loss: -1756.731323\n",
      "    epoch          : 181\n",
      "    loss           : -1756.2280112212559\n",
      "    ess            : 26.95417001112452\n",
      "    log_marginal   : 1756.5214774653596\n",
      "    val_loss       : -1758.9877421061199\n",
      "    val_ess        : 26.725457032521565\n",
      "    val_log_marginal: 1759.2935078938801\n",
      "Train Epoch: 182 [0/54000 (0%)] Loss: -1760.125977\n",
      "Train Epoch: 182 [11264/54000 (21%)] Loss: -1758.089600\n",
      "Train Epoch: 182 [22528/54000 (42%)] Loss: -1763.315186\n",
      "Train Epoch: 182 [33792/54000 (63%)] Loss: -1759.063232\n",
      "Train Epoch: 182 [45056/54000 (83%)] Loss: -1754.072021\n",
      "    epoch          : 182\n",
      "    loss           : -1759.1592591483638\n",
      "    ess            : 26.633719984090554\n",
      "    log_marginal   : 1759.4719503150795\n",
      "    val_loss       : -1761.0232747395833\n",
      "    val_ess        : 26.553953965504963\n",
      "    val_log_marginal: 1761.339823404948\n",
      "Train Epoch: 183 [0/54000 (0%)] Loss: -1760.447754\n",
      "Train Epoch: 183 [11264/54000 (21%)] Loss: -1757.655151\n",
      "Train Epoch: 183 [22528/54000 (42%)] Loss: -1762.617432\n",
      "Train Epoch: 183 [33792/54000 (63%)] Loss: -1760.997803\n",
      "Train Epoch: 183 [45056/54000 (83%)] Loss: -1761.804443\n",
      "    epoch          : 183\n",
      "    loss           : -1760.6794606334759\n",
      "    ess            : 26.506969164002616\n",
      "    log_marginal   : 1760.9999366616303\n",
      "    val_loss       : -1762.028544108073\n",
      "    val_ess        : 26.55869181950887\n",
      "    val_log_marginal: 1762.3506876627605\n",
      "Train Epoch: 184 [0/54000 (0%)] Loss: -1761.045166\n",
      "Train Epoch: 184 [11264/54000 (21%)] Loss: -1761.073242\n",
      "Train Epoch: 184 [22528/54000 (42%)] Loss: -1756.224243\n",
      "Train Epoch: 184 [33792/54000 (63%)] Loss: -1758.158813\n",
      "Train Epoch: 184 [45056/54000 (83%)] Loss: -1760.036987\n",
      "    epoch          : 184\n",
      "    loss           : -1761.7515581238945\n",
      "    ess            : 26.584204799724073\n",
      "    log_marginal   : 1762.0712994269604\n",
      "    val_loss       : -1762.9759318033855\n",
      "    val_ess        : 26.59713331858317\n",
      "    val_log_marginal: 1763.2871398925781\n",
      "Train Epoch: 185 [0/54000 (0%)] Loss: -1763.293701\n",
      "Train Epoch: 185 [11264/54000 (21%)] Loss: -1767.646606\n",
      "Train Epoch: 185 [22528/54000 (42%)] Loss: -1763.903076\n",
      "Train Epoch: 185 [33792/54000 (63%)] Loss: -1760.944946\n",
      "Train Epoch: 185 [45056/54000 (83%)] Loss: -1762.204346\n",
      "    epoch          : 185\n",
      "    loss           : -1756.7959237728478\n",
      "    ess            : 26.574780176270682\n",
      "    log_marginal   : 1757.1153909935142\n",
      "    val_loss       : -1666.7334899902344\n",
      "    val_ess        : 26.08492088317871\n",
      "    val_log_marginal: 1667.0428670247395\n",
      "Train Epoch: 186 [0/54000 (0%)] Loss: -1671.999390\n",
      "Train Epoch: 186 [11264/54000 (21%)] Loss: -1708.975220\n",
      "Train Epoch: 186 [22528/54000 (42%)] Loss: -1740.635132\n",
      "Train Epoch: 186 [33792/54000 (63%)] Loss: -1740.921509\n",
      "Train Epoch: 186 [45056/54000 (83%)] Loss: -1721.827881\n",
      "    epoch          : 186\n",
      "    loss           : -1720.140509839328\n",
      "    ess            : 26.55267112659958\n",
      "    log_marginal   : 1720.4394750055278\n",
      "    val_loss       : -1665.3114115397136\n",
      "    val_ess        : 28.92969258626302\n",
      "    val_log_marginal: 1665.508768717448\n",
      "Train Epoch: 187 [0/54000 (0%)] Loss: -1722.048096\n",
      "Train Epoch: 187 [11264/54000 (21%)] Loss: -1733.844360\n",
      "Train Epoch: 187 [22528/54000 (42%)] Loss: -1744.654785\n",
      "Train Epoch: 187 [33792/54000 (63%)] Loss: -1739.460938\n",
      "Train Epoch: 187 [45056/54000 (83%)] Loss: -1744.726807\n",
      "    epoch          : 187\n",
      "    loss           : -1738.298137160967\n",
      "    ess            : 27.618758507494658\n",
      "    log_marginal   : 1738.543729962043\n",
      "    val_loss       : -1726.287109375\n",
      "    val_ess        : 28.22676356633504\n",
      "    val_log_marginal: 1726.5045878092449\n",
      "Train Epoch: 188 [0/54000 (0%)] Loss: -1745.649902\n",
      "Train Epoch: 188 [11264/54000 (21%)] Loss: -1756.684326\n",
      "Train Epoch: 188 [22528/54000 (42%)] Loss: -1741.649780\n",
      "Train Epoch: 188 [33792/54000 (63%)] Loss: -1751.740234\n",
      "Train Epoch: 188 [45056/54000 (83%)] Loss: -1754.522095\n",
      "    epoch          : 188\n",
      "    loss           : -1748.8055120504127\n",
      "    ess            : 26.91476958652712\n",
      "    log_marginal   : 1749.0948693617336\n",
      "    val_loss       : -1738.7693684895833\n",
      "    val_ess        : 27.108649889628094\n",
      "    val_log_marginal: 1739.054931640625\n",
      "Train Epoch: 189 [0/54000 (0%)] Loss: -1752.032471\n",
      "Train Epoch: 189 [11264/54000 (21%)] Loss: -1747.827637\n",
      "Train Epoch: 189 [22528/54000 (42%)] Loss: -1749.570312\n",
      "Train Epoch: 189 [33792/54000 (63%)] Loss: -1753.019531\n",
      "Train Epoch: 189 [45056/54000 (83%)] Loss: -1757.695557\n",
      "    epoch          : 189\n",
      "    loss           : -1752.6518808040978\n",
      "    ess            : 26.628533975133355\n",
      "    log_marginal   : 1752.9586331349499\n",
      "    val_loss       : -1743.3287048339844\n",
      "    val_ess        : 26.76200803120931\n",
      "    val_log_marginal: 1743.6327006022136\n",
      "Train Epoch: 190 [0/54000 (0%)] Loss: -1754.472412\n",
      "Train Epoch: 190 [11264/54000 (21%)] Loss: -1749.956421\n",
      "Train Epoch: 190 [22528/54000 (42%)] Loss: -1756.123657\n",
      "Train Epoch: 190 [33792/54000 (63%)] Loss: -1755.135498\n",
      "Train Epoch: 190 [45056/54000 (83%)] Loss: -1756.040527\n",
      "    epoch          : 190\n",
      "    loss           : -1754.7113497752064\n",
      "    ess            : 26.456981371033866\n",
      "    log_marginal   : 1755.0303816885319\n",
      "    val_loss       : -1746.6915893554688\n",
      "    val_ess        : 26.81646156311035\n",
      "    val_log_marginal: 1746.9955647786458\n",
      "Train Epoch: 191 [0/54000 (0%)] Loss: -1757.314087\n",
      "Train Epoch: 191 [11264/54000 (21%)] Loss: -1758.493164\n",
      "Train Epoch: 191 [22528/54000 (42%)] Loss: -1750.795898\n",
      "Train Epoch: 191 [33792/54000 (63%)] Loss: -1754.950317\n",
      "Train Epoch: 191 [45056/54000 (83%)] Loss: -1758.874146\n",
      "    epoch          : 191\n",
      "    loss           : -1756.3401235904334\n",
      "    ess            : 26.463205877340066\n",
      "    log_marginal   : 1756.6593524285083\n",
      "    val_loss       : -1748.9468892415364\n",
      "    val_ess        : 26.718260447184246\n",
      "    val_log_marginal: 1749.2450764973958\n",
      "Train Epoch: 192 [0/54000 (0%)] Loss: -1765.279541\n",
      "Train Epoch: 192 [11264/54000 (21%)] Loss: -1758.671631\n",
      "Train Epoch: 192 [22528/54000 (42%)] Loss: -1761.747192\n",
      "Train Epoch: 192 [33792/54000 (63%)] Loss: -1757.163818\n",
      "Train Epoch: 192 [45056/54000 (83%)] Loss: -1754.940674\n",
      "    epoch          : 192\n",
      "    loss           : -1757.5488143057194\n",
      "    ess            : 26.5409873386599\n",
      "    log_marginal   : 1757.8668972951061\n",
      "    val_loss       : -1750.992696126302\n",
      "    val_ess        : 26.55552323659261\n",
      "    val_log_marginal: 1751.3126220703125\n",
      "Train Epoch: 193 [0/54000 (0%)] Loss: -1762.431885\n",
      "Train Epoch: 193 [11264/54000 (21%)] Loss: -1756.529541\n",
      "Train Epoch: 193 [22528/54000 (42%)] Loss: -1754.844971\n",
      "Train Epoch: 193 [33792/54000 (63%)] Loss: -1755.951050\n",
      "Train Epoch: 193 [45056/54000 (83%)] Loss: -1746.587158\n",
      "    epoch          : 193\n",
      "    loss           : -1753.677329009434\n",
      "    ess            : 26.450621640907144\n",
      "    log_marginal   : 1754.0023895839474\n",
      "    val_loss       : -1717.6460876464844\n",
      "    val_ess        : 26.41074816385905\n",
      "    val_log_marginal: 1717.9642232259114\n",
      "Train Epoch: 194 [0/54000 (0%)] Loss: -1720.170288\n",
      "Train Epoch: 194 [11264/54000 (21%)] Loss: -1720.338257\n",
      "Train Epoch: 194 [22528/54000 (42%)] Loss: -1729.525879\n",
      "Train Epoch: 194 [33792/54000 (63%)] Loss: -1736.463013\n",
      "Train Epoch: 194 [45056/54000 (83%)] Loss: -1730.614746\n",
      "    epoch          : 194\n",
      "    loss           : -1726.053198472509\n",
      "    ess            : 26.638412691512197\n",
      "    log_marginal   : 1726.3522097029777\n",
      "    val_loss       : -1734.4263814290364\n",
      "    val_ess        : 27.632909615834553\n",
      "    val_log_marginal: 1734.6785888671875\n",
      "Train Epoch: 195 [0/54000 (0%)] Loss: -1736.277100\n",
      "Train Epoch: 195 [11264/54000 (21%)] Loss: -1745.209717\n",
      "Train Epoch: 195 [22528/54000 (42%)] Loss: -1741.322754\n",
      "Train Epoch: 195 [33792/54000 (63%)] Loss: -1745.861694\n",
      "Train Epoch: 195 [45056/54000 (83%)] Loss: -1740.145508\n",
      "    epoch          : 195\n",
      "    loss           : -1743.546841603405\n",
      "    ess            : 27.551224204729188\n",
      "    log_marginal   : 1743.7984008789062\n",
      "    val_loss       : -1740.1646626790364\n",
      "    val_ess        : 27.015533606211346\n",
      "    val_log_marginal: 1740.4374186197917\n",
      "Train Epoch: 196 [0/54000 (0%)] Loss: -1749.183350\n",
      "Train Epoch: 196 [11264/54000 (21%)] Loss: -1747.136719\n",
      "Train Epoch: 196 [22528/54000 (42%)] Loss: -1747.602417\n",
      "Train Epoch: 196 [33792/54000 (63%)] Loss: -1750.117310\n",
      "Train Epoch: 196 [45056/54000 (83%)] Loss: -1745.139648\n",
      "    epoch          : 196\n",
      "    loss           : -1750.0940528725678\n",
      "    ess            : 26.79588172120868\n",
      "    log_marginal   : 1750.3923236199146\n",
      "    val_loss       : -1747.7830810546875\n",
      "    val_ess        : 26.73332405090332\n",
      "    val_log_marginal: 1748.0825500488281\n",
      "Train Epoch: 197 [0/54000 (0%)] Loss: -1756.020020\n",
      "Train Epoch: 197 [11264/54000 (21%)] Loss: -1752.686401\n",
      "Train Epoch: 197 [22528/54000 (42%)] Loss: -1754.045898\n",
      "Train Epoch: 197 [33792/54000 (63%)] Loss: -1751.470459\n",
      "Train Epoch: 197 [45056/54000 (83%)] Loss: -1751.561768\n",
      "    epoch          : 197\n",
      "    loss           : -1754.0951042895047\n",
      "    ess            : 26.695278527601708\n",
      "    log_marginal   : 1754.3974759083874\n",
      "    val_loss       : -1750.8407796223958\n",
      "    val_ess        : 26.690001328786213\n",
      "    val_log_marginal: 1751.1465962727864\n",
      "Train Epoch: 198 [0/54000 (0%)] Loss: -1754.871460\n",
      "Train Epoch: 198 [11264/54000 (21%)] Loss: -1761.093262\n",
      "Train Epoch: 198 [22528/54000 (42%)] Loss: -1753.508545\n",
      "Train Epoch: 198 [33792/54000 (63%)] Loss: -1759.609863\n",
      "Train Epoch: 198 [45056/54000 (83%)] Loss: -1755.947510\n",
      "    epoch          : 198\n",
      "    loss           : -1756.3194349756782\n",
      "    ess            : 26.496118851427763\n",
      "    log_marginal   : 1756.6405363262825\n",
      "    val_loss       : -1752.811055501302\n",
      "    val_ess        : 26.42186975479126\n",
      "    val_log_marginal: 1753.1357014973958\n",
      "Train Epoch: 199 [0/54000 (0%)] Loss: -1756.429932\n",
      "Train Epoch: 199 [11264/54000 (21%)] Loss: -1759.550293\n",
      "Train Epoch: 199 [22528/54000 (42%)] Loss: -1760.925293\n",
      "Train Epoch: 199 [33792/54000 (63%)] Loss: -1757.363037\n",
      "Train Epoch: 199 [45056/54000 (83%)] Loss: -1757.776978\n",
      "    epoch          : 199\n",
      "    loss           : -1757.8227942124852\n",
      "    ess            : 26.527441438638938\n",
      "    log_marginal   : 1758.1398453622494\n",
      "    val_loss       : -1754.1645812988281\n",
      "    val_ess        : 26.585916837056477\n",
      "    val_log_marginal: 1754.4677734375\n",
      "Train Epoch: 200 [0/54000 (0%)] Loss: -1754.559326\n",
      "Train Epoch: 200 [11264/54000 (21%)] Loss: -1758.159424\n",
      "Train Epoch: 200 [22528/54000 (42%)] Loss: -1760.567627\n",
      "Train Epoch: 200 [33792/54000 (63%)] Loss: -1757.727295\n",
      "Train Epoch: 200 [45056/54000 (83%)] Loss: -1755.580444\n",
      "    epoch          : 200\n",
      "    loss           : -1758.69712512898\n",
      "    ess            : 26.510587728248453\n",
      "    log_marginal   : 1759.016523253243\n",
      "    val_loss       : -1754.7562052408855\n",
      "    val_ess        : 26.53238073984782\n",
      "    val_log_marginal: 1755.0801900227864\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [0/54000 (0%)] Loss: -1760.148560\n",
      "Train Epoch: 201 [11264/54000 (21%)] Loss: -1767.049683\n",
      "Train Epoch: 201 [22528/54000 (42%)] Loss: -1758.466064\n",
      "Train Epoch: 201 [33792/54000 (63%)] Loss: -1685.146362\n",
      "Train Epoch: 201 [45056/54000 (83%)] Loss: -1736.120850\n",
      "    epoch          : 201\n",
      "    loss           : -1740.6179233766952\n",
      "    ess            : 26.472114688945265\n",
      "    log_marginal   : 1740.9331146816037\n",
      "    val_loss       : -1741.6124877929688\n",
      "    val_ess        : 26.329834938049316\n",
      "    val_log_marginal: 1741.9379069010417\n",
      "Train Epoch: 202 [0/54000 (0%)] Loss: -1736.664062\n",
      "Train Epoch: 202 [11264/54000 (21%)] Loss: -1741.136841\n",
      "Train Epoch: 202 [22528/54000 (42%)] Loss: -1749.703125\n",
      "Train Epoch: 202 [33792/54000 (63%)] Loss: -1747.391602\n",
      "Train Epoch: 202 [45056/54000 (83%)] Loss: -1750.003418\n",
      "    epoch          : 202\n",
      "    loss           : -1746.8244847711528\n",
      "    ess            : 27.11037178759305\n",
      "    log_marginal   : 1747.1023110443691\n",
      "    val_loss       : -1750.7186584472656\n",
      "    val_ess        : 26.89872185389201\n",
      "    val_log_marginal: 1751.0194193522136\n",
      "Train Epoch: 203 [0/54000 (0%)] Loss: -1749.391235\n",
      "Train Epoch: 203 [11264/54000 (21%)] Loss: -1757.594727\n",
      "Train Epoch: 203 [22528/54000 (42%)] Loss: -1754.170288\n",
      "Train Epoch: 203 [33792/54000 (63%)] Loss: -1755.512451\n",
      "Train Epoch: 203 [45056/54000 (83%)] Loss: -1754.939209\n",
      "    epoch          : 203\n",
      "    loss           : -1754.7952397184552\n",
      "    ess            : 26.864588863444776\n",
      "    log_marginal   : 1755.0915227926002\n",
      "    val_loss       : -1754.4507344563801\n",
      "    val_ess        : 26.425936698913574\n",
      "    val_log_marginal: 1754.7695922851562\n",
      "Train Epoch: 204 [0/54000 (0%)] Loss: -1758.723389\n",
      "Train Epoch: 204 [11264/54000 (21%)] Loss: -1757.530762\n",
      "Train Epoch: 204 [22528/54000 (42%)] Loss: -1756.352539\n",
      "Train Epoch: 204 [33792/54000 (63%)] Loss: -1751.738770\n",
      "Train Epoch: 204 [45056/54000 (83%)] Loss: -1758.127441\n",
      "    epoch          : 204\n",
      "    loss           : -1757.399985259434\n",
      "    ess            : 26.574301251825297\n",
      "    log_marginal   : 1757.7151765643425\n",
      "    val_loss       : -1756.1345113118489\n",
      "    val_ess        : 26.457974274953205\n",
      "    val_log_marginal: 1756.458251953125\n",
      "Train Epoch: 205 [0/54000 (0%)] Loss: -1757.617310\n",
      "Train Epoch: 205 [11264/54000 (21%)] Loss: -1761.358398\n",
      "Train Epoch: 205 [22528/54000 (42%)] Loss: -1752.434326\n",
      "Train Epoch: 205 [33792/54000 (63%)] Loss: -1760.501831\n",
      "Train Epoch: 205 [45056/54000 (83%)] Loss: -1756.435425\n",
      "    epoch          : 205\n",
      "    loss           : -1759.0173881098908\n",
      "    ess            : 26.504200629468233\n",
      "    log_marginal   : 1759.3340097103478\n",
      "    val_loss       : -1757.6629943847656\n",
      "    val_ess        : 26.543753306070965\n",
      "    val_log_marginal: 1757.9787699381511\n",
      "Train Epoch: 206 [0/54000 (0%)] Loss: -1759.610474\n",
      "Train Epoch: 206 [11264/54000 (21%)] Loss: -1761.084473\n",
      "Train Epoch: 206 [22528/54000 (42%)] Loss: -1760.393311\n",
      "Train Epoch: 206 [33792/54000 (63%)] Loss: -1759.209961\n",
      "Train Epoch: 206 [45056/54000 (83%)] Loss: -1758.627563\n",
      "    epoch          : 206\n",
      "    loss           : -1760.119057709316\n",
      "    ess            : 26.461692324224508\n",
      "    log_marginal   : 1760.4447816093013\n",
      "    val_loss       : -1758.4914652506511\n",
      "    val_ess        : 26.49958308537801\n",
      "    val_log_marginal: 1758.8175455729167\n",
      "Train Epoch: 207 [0/54000 (0%)] Loss: -1756.423462\n",
      "Train Epoch: 207 [11264/54000 (21%)] Loss: -1763.527344\n",
      "Train Epoch: 207 [22528/54000 (42%)] Loss: -1760.022461\n",
      "Train Epoch: 207 [33792/54000 (63%)] Loss: -1762.104614\n",
      "Train Epoch: 207 [45056/54000 (83%)] Loss: -1760.685791\n",
      "    epoch          : 207\n",
      "    loss           : -1761.125872917895\n",
      "    ess            : 26.6222539577844\n",
      "    log_marginal   : 1761.439883825914\n",
      "    val_loss       : -1758.9368896484375\n",
      "    val_ess        : 26.32784668604533\n",
      "    val_log_marginal: 1759.264872233073\n",
      "Train Epoch: 208 [0/54000 (0%)] Loss: -1759.383423\n",
      "Train Epoch: 208 [11264/54000 (21%)] Loss: -1765.918701\n",
      "Train Epoch: 208 [22528/54000 (42%)] Loss: -1761.142578\n",
      "Train Epoch: 208 [33792/54000 (63%)] Loss: -1758.804199\n",
      "Train Epoch: 208 [45056/54000 (83%)] Loss: -1747.729980\n",
      "    epoch          : 208\n",
      "    loss           : -1753.7335654204746\n",
      "    ess            : 26.617883358361585\n",
      "    log_marginal   : 1754.0479402362175\n",
      "    val_loss       : -1705.4018046061199\n",
      "    val_ess        : 26.04724931716919\n",
      "    val_log_marginal: 1705.7088623046875\n",
      "Train Epoch: 209 [0/54000 (0%)] Loss: -1704.778320\n",
      "Train Epoch: 209 [11264/54000 (21%)] Loss: -1737.504028\n",
      "Train Epoch: 209 [22528/54000 (42%)] Loss: -1733.605713\n",
      "Train Epoch: 209 [33792/54000 (63%)] Loss: -1742.341553\n",
      "Train Epoch: 209 [45056/54000 (83%)] Loss: -1745.139648\n",
      "    epoch          : 209\n",
      "    loss           : -1736.1620379753833\n",
      "    ess            : 26.693759000526285\n",
      "    log_marginal   : 1736.4639650740714\n",
      "    val_loss       : -1725.6224365234375\n",
      "    val_ess        : 27.96363623936971\n",
      "    val_log_marginal: 1725.8580017089844\n",
      "Train Epoch: 210 [0/54000 (0%)] Loss: -1753.895752\n",
      "Train Epoch: 210 [11264/54000 (21%)] Loss: -1749.349731\n",
      "Train Epoch: 210 [22528/54000 (42%)] Loss: -1755.056641\n",
      "Train Epoch: 210 [33792/54000 (63%)] Loss: -1753.941406\n",
      "Train Epoch: 210 [45056/54000 (83%)] Loss: -1752.586670\n",
      "    epoch          : 210\n",
      "    loss           : -1752.4097048201652\n",
      "    ess            : 27.40392711927306\n",
      "    log_marginal   : 1752.674034262603\n",
      "    val_loss       : -1743.0273539225261\n",
      "    val_ess        : 27.434775988260906\n",
      "    val_log_marginal: 1743.2917073567708\n",
      "Train Epoch: 211 [0/54000 (0%)] Loss: -1761.473389\n",
      "Train Epoch: 211 [11264/54000 (21%)] Loss: -1756.672852\n",
      "Train Epoch: 211 [22528/54000 (42%)] Loss: -1758.373779\n",
      "Train Epoch: 211 [33792/54000 (63%)] Loss: -1756.810547\n",
      "Train Epoch: 211 [45056/54000 (83%)] Loss: -1755.255371\n",
      "    epoch          : 211\n",
      "    loss           : -1757.3311283903302\n",
      "    ess            : 26.773899096362996\n",
      "    log_marginal   : 1757.6360300891804\n",
      "    val_loss       : -1748.4355061848958\n",
      "    val_ess        : 26.902937253316242\n",
      "    val_log_marginal: 1748.7227172851562\n",
      "Train Epoch: 212 [0/54000 (0%)] Loss: -1760.576782\n",
      "Train Epoch: 212 [11264/54000 (21%)] Loss: -1759.282715\n",
      "Train Epoch: 212 [22528/54000 (42%)] Loss: -1761.902344\n",
      "Train Epoch: 212 [33792/54000 (63%)] Loss: -1758.538818\n",
      "Train Epoch: 212 [45056/54000 (83%)] Loss: -1758.404297\n",
      "    epoch          : 212\n",
      "    loss           : -1759.4270272884728\n",
      "    ess            : 26.561862585679542\n",
      "    log_marginal   : 1759.743623553582\n",
      "    val_loss       : -1751.5723063151042\n",
      "    val_ess        : 26.716014226277668\n",
      "    val_log_marginal: 1751.9010518391926\n",
      "Train Epoch: 213 [0/54000 (0%)] Loss: -1761.356323\n",
      "Train Epoch: 213 [11264/54000 (21%)] Loss: -1760.871216\n",
      "Train Epoch: 213 [22528/54000 (42%)] Loss: -1762.005005\n",
      "Train Epoch: 213 [33792/54000 (63%)] Loss: -1754.503784\n",
      "Train Epoch: 213 [45056/54000 (83%)] Loss: -1762.204834\n",
      "    epoch          : 213\n",
      "    loss           : -1760.8209147903156\n",
      "    ess            : 26.56909870651533\n",
      "    log_marginal   : 1761.140248424602\n",
      "    val_loss       : -1753.5233052571614\n",
      "    val_ess        : 26.9120192527771\n",
      "    val_log_marginal: 1753.8312276204426\n",
      "Train Epoch: 214 [0/54000 (0%)] Loss: -1764.931152\n",
      "Train Epoch: 214 [11264/54000 (21%)] Loss: -1763.947510\n",
      "Train Epoch: 214 [22528/54000 (42%)] Loss: -1758.559082\n",
      "Train Epoch: 214 [33792/54000 (63%)] Loss: -1759.905518\n",
      "Train Epoch: 214 [45056/54000 (83%)] Loss: -1756.483643\n",
      "    epoch          : 214\n",
      "    loss           : -1761.769523188753\n",
      "    ess            : 26.529291530825056\n",
      "    log_marginal   : 1762.0976758273143\n",
      "    val_loss       : -1754.9691263834636\n",
      "    val_ess        : 26.52013651529948\n",
      "    val_log_marginal: 1755.3037109375\n",
      "Train Epoch: 215 [0/54000 (0%)] Loss: -1766.319336\n",
      "Train Epoch: 215 [11264/54000 (21%)] Loss: -1761.698486\n",
      "Train Epoch: 215 [22528/54000 (42%)] Loss: -1757.876343\n",
      "Train Epoch: 215 [33792/54000 (63%)] Loss: -1762.173584\n",
      "Train Epoch: 215 [45056/54000 (83%)] Loss: -1754.312500\n",
      "    epoch          : 215\n",
      "    loss           : -1761.0093568046138\n",
      "    ess            : 26.627383322085976\n",
      "    log_marginal   : 1761.3267119785526\n",
      "    val_loss       : -1732.3983866373699\n",
      "    val_ess        : 26.656875133514404\n",
      "    val_log_marginal: 1732.7054748535156\n",
      "Train Epoch: 216 [0/54000 (0%)] Loss: -1733.259033\n",
      "Train Epoch: 216 [11264/54000 (21%)] Loss: -1731.754028\n",
      "Train Epoch: 216 [22528/54000 (42%)] Loss: -1744.971924\n",
      "Train Epoch: 216 [33792/54000 (63%)] Loss: -1754.519775\n",
      "Train Epoch: 216 [45056/54000 (83%)] Loss: -1746.657959\n",
      "    epoch          : 216\n",
      "    loss           : -1740.5922483048348\n",
      "    ess            : 26.55648494216631\n",
      "    log_marginal   : 1740.904044673128\n",
      "    val_loss       : -1745.4485880533855\n",
      "    val_ess        : 27.35013262430827\n",
      "    val_log_marginal: 1745.7254638671875\n",
      "Train Epoch: 217 [0/54000 (0%)] Loss: -1753.479736\n",
      "Train Epoch: 217 [11264/54000 (21%)] Loss: -1736.153076\n",
      "Train Epoch: 217 [22528/54000 (42%)] Loss: -1741.308228\n",
      "Train Epoch: 217 [33792/54000 (63%)] Loss: -1754.523071\n",
      "Train Epoch: 217 [45056/54000 (83%)] Loss: -1749.174805\n",
      "    epoch          : 217\n",
      "    loss           : -1746.6450909308667\n",
      "    ess            : 27.33961654159258\n",
      "    log_marginal   : 1746.9133116524174\n",
      "    val_loss       : -1747.7985331217449\n",
      "    val_ess        : 26.75994412104289\n",
      "    val_log_marginal: 1748.1086730957031\n",
      "Train Epoch: 218 [0/54000 (0%)] Loss: -1753.212646\n",
      "Train Epoch: 218 [11264/54000 (21%)] Loss: -1719.825439\n",
      "Train Epoch: 218 [22528/54000 (42%)] Loss: -1749.357178\n",
      "Train Epoch: 218 [33792/54000 (63%)] Loss: -1757.577637\n",
      "Train Epoch: 218 [45056/54000 (83%)] Loss: -1753.049561\n",
      "    epoch          : 218\n",
      "    loss           : -1744.86285976194\n",
      "    ess            : 26.848071404223173\n",
      "    log_marginal   : 1745.154131043632\n",
      "    val_loss       : -1752.0360717773438\n",
      "    val_ess        : 26.807021776835125\n",
      "    val_log_marginal: 1752.3432006835938\n",
      "Train Epoch: 219 [0/54000 (0%)] Loss: -1753.745605\n",
      "Train Epoch: 219 [11264/54000 (21%)] Loss: -1743.271851\n",
      "Train Epoch: 219 [22528/54000 (42%)] Loss: -1750.578369\n",
      "Train Epoch: 219 [33792/54000 (63%)] Loss: -1752.437134\n",
      "Train Epoch: 219 [45056/54000 (83%)] Loss: -1749.265625\n",
      "    epoch          : 219\n",
      "    loss           : -1752.588929374263\n",
      "    ess            : 26.888175892380048\n",
      "    log_marginal   : 1752.8864227870724\n",
      "    val_loss       : -1753.545654296875\n",
      "    val_ess        : 26.699690341949463\n",
      "    val_log_marginal: 1753.8550821940105\n",
      "Train Epoch: 220 [0/54000 (0%)] Loss: -1758.229126\n",
      "Train Epoch: 220 [11264/54000 (21%)] Loss: -1757.150879\n",
      "Train Epoch: 220 [22528/54000 (42%)] Loss: -1757.864990\n",
      "Train Epoch: 220 [33792/54000 (63%)] Loss: -1757.560181\n",
      "Train Epoch: 220 [45056/54000 (83%)] Loss: -1755.962402\n",
      "    epoch          : 220\n",
      "    loss           : -1756.8272820238797\n",
      "    ess            : 26.639551522596825\n",
      "    log_marginal   : 1757.1375329359523\n",
      "    val_loss       : -1755.45458984375\n",
      "    val_ess        : 26.55818525950114\n",
      "    val_log_marginal: 1755.7604573567708\n",
      "Train Epoch: 221 [0/54000 (0%)] Loss: -1758.087769\n",
      "Train Epoch: 221 [11264/54000 (21%)] Loss: -1762.416504\n",
      "Train Epoch: 221 [22528/54000 (42%)] Loss: -1764.172119\n",
      "Train Epoch: 221 [33792/54000 (63%)] Loss: -1760.649536\n",
      "Train Epoch: 221 [45056/54000 (83%)] Loss: -1755.139404\n",
      "    epoch          : 221\n",
      "    loss           : -1758.8293595224056\n",
      "    ess            : 26.50424521824099\n",
      "    log_marginal   : 1759.1486920050854\n",
      "    val_loss       : -1757.0107014973958\n",
      "    val_ess        : 26.3579839070638\n",
      "    val_log_marginal: 1757.3336588541667\n",
      "Train Epoch: 222 [0/54000 (0%)] Loss: -1760.190430\n",
      "Train Epoch: 222 [11264/54000 (21%)] Loss: -1760.957031\n",
      "Train Epoch: 222 [22528/54000 (42%)] Loss: -1759.532104\n",
      "Train Epoch: 222 [33792/54000 (63%)] Loss: -1759.868530\n",
      "Train Epoch: 222 [45056/54000 (83%)] Loss: -1762.494751\n",
      "    epoch          : 222\n",
      "    loss           : -1760.3298685325767\n",
      "    ess            : 26.47616395410502\n",
      "    log_marginal   : 1760.6540723116893\n",
      "    val_loss       : -1758.3014526367188\n",
      "    val_ess        : 26.306114037831623\n",
      "    val_log_marginal: 1758.637430826823\n",
      "Train Epoch: 223 [0/54000 (0%)] Loss: -1765.324707\n",
      "Train Epoch: 223 [11264/54000 (21%)] Loss: -1763.758301\n",
      "Train Epoch: 223 [22528/54000 (42%)] Loss: -1759.987915\n",
      "Train Epoch: 223 [33792/54000 (63%)] Loss: -1761.093750\n",
      "Train Epoch: 223 [45056/54000 (83%)] Loss: -1762.934570\n",
      "    epoch          : 223\n",
      "    loss           : -1761.5466619527565\n",
      "    ess            : 26.527622510802072\n",
      "    log_marginal   : 1761.870137916421\n",
      "    val_loss       : -1758.8710123697917\n",
      "    val_ess        : 26.62965154647827\n",
      "    val_log_marginal: 1759.1929117838542\n",
      "Train Epoch: 224 [0/54000 (0%)] Loss: -1760.792969\n",
      "Train Epoch: 224 [11264/54000 (21%)] Loss: -1765.701416\n",
      "Train Epoch: 224 [22528/54000 (42%)] Loss: -1767.714966\n",
      "Train Epoch: 224 [33792/54000 (63%)] Loss: -1764.735229\n",
      "Train Epoch: 224 [45056/54000 (83%)] Loss: -1746.541016\n",
      "    epoch          : 224\n",
      "    loss           : -1755.8893616874263\n",
      "    ess            : 26.5719323428172\n",
      "    log_marginal   : 1756.2108937389446\n",
      "    val_loss       : -1720.4625244140625\n",
      "    val_ess        : 26.302979310353596\n",
      "    val_log_marginal: 1720.7742309570312\n",
      "Train Epoch: 225 [0/54000 (0%)] Loss: -1721.709961\n",
      "Train Epoch: 225 [11264/54000 (21%)] Loss: -1725.137695\n",
      "Train Epoch: 225 [22528/54000 (42%)] Loss: -1737.235596\n",
      "Train Epoch: 225 [33792/54000 (63%)] Loss: -1733.070557\n",
      "Train Epoch: 225 [45056/54000 (83%)] Loss: -1734.531982\n",
      "    epoch          : 225\n",
      "    loss           : -1730.4503335053066\n",
      "    ess            : 26.730206237649018\n",
      "    log_marginal   : 1730.7478015827683\n",
      "    val_loss       : -1729.044189453125\n",
      "    val_ess        : 27.901894569396973\n",
      "    val_log_marginal: 1729.2823893229167\n",
      "Train Epoch: 226 [0/54000 (0%)] Loss: -1742.847900\n",
      "Train Epoch: 226 [11264/54000 (21%)] Loss: -1746.528198\n",
      "Train Epoch: 226 [22528/54000 (42%)] Loss: -1749.887451\n",
      "Train Epoch: 226 [33792/54000 (63%)] Loss: -1749.119751\n",
      "Train Epoch: 226 [45056/54000 (83%)] Loss: -1750.212891\n",
      "    epoch          : 226\n",
      "    loss           : -1746.8935374133991\n",
      "    ess            : 27.476905678803067\n",
      "    log_marginal   : 1747.153278854658\n",
      "    val_loss       : -1744.0434163411458\n",
      "    val_ess        : 27.608839511871338\n",
      "    val_log_marginal: 1744.2997334798176\n",
      "Train Epoch: 227 [0/54000 (0%)] Loss: -1748.463257\n",
      "Train Epoch: 227 [11264/54000 (21%)] Loss: -1754.471680\n",
      "Train Epoch: 227 [22528/54000 (42%)] Loss: -1755.959839\n",
      "Train Epoch: 227 [33792/54000 (63%)] Loss: -1752.753784\n",
      "Train Epoch: 227 [45056/54000 (83%)] Loss: -1758.077271\n",
      "    epoch          : 227\n",
      "    loss           : -1754.18268743551\n",
      "    ess            : 26.857346210839612\n",
      "    log_marginal   : 1754.475383254717\n",
      "    val_loss       : -1750.576416015625\n",
      "    val_ess        : 26.869294325510662\n",
      "    val_log_marginal: 1750.8730570475261\n",
      "Train Epoch: 228 [0/54000 (0%)] Loss: -1756.927734\n",
      "Train Epoch: 228 [11264/54000 (21%)] Loss: -1758.183105\n",
      "Train Epoch: 228 [22528/54000 (42%)] Loss: -1758.694580\n",
      "Train Epoch: 228 [33792/54000 (63%)] Loss: -1756.724243\n",
      "Train Epoch: 228 [45056/54000 (83%)] Loss: -1755.964844\n",
      "    epoch          : 228\n",
      "    loss           : -1757.304381172612\n",
      "    ess            : 26.62889489587748\n",
      "    log_marginal   : 1757.6172796285377\n",
      "    val_loss       : -1753.8634134928386\n",
      "    val_ess        : 26.61348311106364\n",
      "    val_log_marginal: 1754.1776631673176\n",
      "Train Epoch: 229 [0/54000 (0%)] Loss: -1759.154785\n",
      "Train Epoch: 229 [11264/54000 (21%)] Loss: -1761.765625\n",
      "Train Epoch: 229 [22528/54000 (42%)] Loss: -1755.942383\n",
      "Train Epoch: 229 [33792/54000 (63%)] Loss: -1755.476318\n",
      "Train Epoch: 229 [45056/54000 (83%)] Loss: -1761.293945\n",
      "    epoch          : 229\n",
      "    loss           : -1759.232889427329\n",
      "    ess            : 26.551563982693654\n",
      "    log_marginal   : 1759.551302927845\n",
      "    val_loss       : -1755.5604146321614\n",
      "    val_ess        : 26.523917992909748\n",
      "    val_log_marginal: 1755.8929341634114\n",
      "Train Epoch: 230 [0/54000 (0%)] Loss: -1760.400635\n",
      "Train Epoch: 230 [11264/54000 (21%)] Loss: -1765.401123\n",
      "Train Epoch: 230 [22528/54000 (42%)] Loss: -1763.556030\n",
      "Train Epoch: 230 [33792/54000 (63%)] Loss: -1762.910400\n",
      "Train Epoch: 230 [45056/54000 (83%)] Loss: -1761.402588\n",
      "    epoch          : 230\n",
      "    loss           : -1760.4944907134434\n",
      "    ess            : 26.48068571990391\n",
      "    log_marginal   : 1760.818273004496\n",
      "    val_loss       : -1757.396484375\n",
      "    val_ess        : 26.56140152613322\n",
      "    val_log_marginal: 1757.7100931803386\n",
      "Train Epoch: 231 [0/54000 (0%)] Loss: -1761.566650\n",
      "Train Epoch: 231 [11264/54000 (21%)] Loss: -1766.446533\n",
      "Train Epoch: 231 [22528/54000 (42%)] Loss: -1756.876953\n",
      "Train Epoch: 231 [33792/54000 (63%)] Loss: -1760.024902\n",
      "Train Epoch: 231 [45056/54000 (83%)] Loss: -1760.979980\n",
      "    epoch          : 231\n",
      "    loss           : -1761.4771578806751\n",
      "    ess            : 26.574078289967662\n",
      "    log_marginal   : 1761.7974058906987\n",
      "    val_loss       : -1757.7693684895833\n",
      "    val_ess        : 26.5832200050354\n",
      "    val_log_marginal: 1758.0950419108074\n",
      "Train Epoch: 232 [0/54000 (0%)] Loss: -1763.436157\n",
      "Train Epoch: 232 [11264/54000 (21%)] Loss: -1763.616699\n",
      "Train Epoch: 232 [22528/54000 (42%)] Loss: -1718.160767\n",
      "Train Epoch: 232 [33792/54000 (63%)] Loss: -1717.508911\n",
      "Train Epoch: 232 [45056/54000 (83%)] Loss: -1744.481323\n",
      "    epoch          : 232\n",
      "    loss           : -1741.1955105763561\n",
      "    ess            : 26.546630283571638\n",
      "    log_marginal   : 1741.5084343676297\n",
      "    val_loss       : -1747.3997701009114\n",
      "    val_ess        : 26.563424587249756\n",
      "    val_log_marginal: 1747.7277018229167\n",
      "Train Epoch: 233 [0/54000 (0%)] Loss: -1749.140137\n",
      "Train Epoch: 233 [11264/54000 (21%)] Loss: -1755.340698\n",
      "Train Epoch: 233 [22528/54000 (42%)] Loss: -1752.995850\n",
      "Train Epoch: 233 [33792/54000 (63%)] Loss: -1748.927246\n",
      "Train Epoch: 233 [45056/54000 (83%)] Loss: -1752.699341\n",
      "    epoch          : 233\n",
      "    loss           : -1750.567751326651\n",
      "    ess            : 27.21333215821464\n",
      "    log_marginal   : 1750.845173385908\n",
      "    val_loss       : -1754.8163960774739\n",
      "    val_ess        : 26.95146656036377\n",
      "    val_log_marginal: 1755.1122131347656\n",
      "Train Epoch: 234 [0/54000 (0%)] Loss: -1757.100342\n",
      "Train Epoch: 234 [11264/54000 (21%)] Loss: -1755.078369\n",
      "Train Epoch: 234 [22528/54000 (42%)] Loss: -1760.995850\n",
      "Train Epoch: 234 [33792/54000 (63%)] Loss: -1754.643066\n",
      "Train Epoch: 234 [45056/54000 (83%)] Loss: -1758.559570\n",
      "    epoch          : 234\n",
      "    loss           : -1757.85016444944\n",
      "    ess            : 26.78906701645761\n",
      "    log_marginal   : 1758.1552423441185\n",
      "    val_loss       : -1758.5325012207031\n",
      "    val_ess        : 26.73892116546631\n",
      "    val_log_marginal: 1758.8253987630208\n",
      "Train Epoch: 235 [0/54000 (0%)] Loss: -1754.463867\n",
      "Train Epoch: 235 [11264/54000 (21%)] Loss: -1754.162109\n",
      "Train Epoch: 235 [22528/54000 (42%)] Loss: -1751.347168\n",
      "Train Epoch: 235 [33792/54000 (63%)] Loss: -1759.212158\n",
      "Train Epoch: 235 [45056/54000 (83%)] Loss: -1766.539551\n",
      "    epoch          : 235\n",
      "    loss           : -1760.422768646816\n",
      "    ess            : 26.648265640690642\n",
      "    log_marginal   : 1760.7362118127212\n",
      "    val_loss       : -1759.8861999511719\n",
      "    val_ess        : 26.33902708689372\n",
      "    val_log_marginal: 1760.2174072265625\n",
      "Train Epoch: 236 [0/54000 (0%)] Loss: -1762.144043\n",
      "Train Epoch: 236 [11264/54000 (21%)] Loss: -1762.520874\n",
      "Train Epoch: 236 [22528/54000 (42%)] Loss: -1761.223267\n",
      "Train Epoch: 236 [33792/54000 (63%)] Loss: -1761.100830\n",
      "Train Epoch: 236 [45056/54000 (83%)] Loss: -1763.563110\n",
      "    epoch          : 236\n",
      "    loss           : -1762.0500384636646\n",
      "    ess            : 26.640798190854632\n",
      "    log_marginal   : 1762.3695598098468\n",
      "    val_loss       : -1760.9578959147136\n",
      "    val_ess        : 26.389232953389484\n",
      "    val_log_marginal: 1761.286376953125\n",
      "Train Epoch: 237 [0/54000 (0%)] Loss: -1759.116211\n",
      "Train Epoch: 237 [11264/54000 (21%)] Loss: -1760.293823\n",
      "Train Epoch: 237 [22528/54000 (42%)] Loss: -1761.737793\n",
      "Train Epoch: 237 [33792/54000 (63%)] Loss: -1763.227295\n",
      "Train Epoch: 237 [45056/54000 (83%)] Loss: -1759.824951\n",
      "    epoch          : 237\n",
      "    loss           : -1763.0662392670254\n",
      "    ess            : 26.638584514833845\n",
      "    log_marginal   : 1763.384045870799\n",
      "    val_loss       : -1761.614969889323\n",
      "    val_ess        : 26.69080400466919\n",
      "    val_log_marginal: 1761.9164733886719\n",
      "Train Epoch: 238 [0/54000 (0%)] Loss: -1769.835938\n",
      "Train Epoch: 238 [11264/54000 (21%)] Loss: -1761.428223\n",
      "Train Epoch: 238 [22528/54000 (42%)] Loss: -1762.053833\n",
      "Train Epoch: 238 [33792/54000 (63%)] Loss: -1761.068970\n",
      "Train Epoch: 238 [45056/54000 (83%)] Loss: -1731.552246\n",
      "    epoch          : 238\n",
      "    loss           : -1756.3129088203862\n",
      "    ess            : 26.535263493375957\n",
      "    log_marginal   : 1756.6349372144016\n",
      "    val_loss       : -1741.660868326823\n",
      "    val_ess        : 26.30130100250244\n",
      "    val_log_marginal: 1741.9891459147136\n",
      "Train Epoch: 239 [0/54000 (0%)] Loss: -1748.331055\n",
      "Train Epoch: 239 [11264/54000 (21%)] Loss: -1713.361084\n",
      "Train Epoch: 239 [22528/54000 (42%)] Loss: -1739.352783\n",
      "Train Epoch: 239 [33792/54000 (63%)] Loss: -1729.177246\n",
      "Train Epoch: 239 [45056/54000 (83%)] Loss: -1742.445679\n",
      "    epoch          : 239\n",
      "    loss           : -1733.8548503371906\n",
      "    ess            : 26.726244890464926\n",
      "    log_marginal   : 1734.1559540370724\n",
      "    val_loss       : -1746.0829264322917\n",
      "    val_ess        : 27.128021081288654\n",
      "    val_log_marginal: 1746.3717346191406\n",
      "Train Epoch: 240 [0/54000 (0%)] Loss: -1751.080078\n",
      "Train Epoch: 240 [11264/54000 (21%)] Loss: -1751.085693\n",
      "Train Epoch: 240 [22528/54000 (42%)] Loss: -1754.951416\n",
      "Train Epoch: 240 [33792/54000 (63%)] Loss: -1748.958984\n",
      "Train Epoch: 240 [45056/54000 (83%)] Loss: -1750.383911\n",
      "    epoch          : 240\n",
      "    loss           : -1750.5758805184994\n",
      "    ess            : 27.45148869280545\n",
      "    log_marginal   : 1750.8438306124706\n",
      "    val_loss       : -1753.9817301432292\n",
      "    val_ess        : 27.041505336761475\n",
      "    val_log_marginal: 1754.2650146484375\n",
      "Train Epoch: 241 [0/54000 (0%)] Loss: -1763.229736\n",
      "Train Epoch: 241 [11264/54000 (21%)] Loss: -1757.634399\n",
      "Train Epoch: 241 [22528/54000 (42%)] Loss: -1756.660889\n",
      "Train Epoch: 241 [33792/54000 (63%)] Loss: -1755.474609\n",
      "Train Epoch: 241 [45056/54000 (83%)] Loss: -1758.001465\n",
      "    epoch          : 241\n",
      "    loss           : -1756.8981611143868\n",
      "    ess            : 26.746478026767946\n",
      "    log_marginal   : 1757.2048996259582\n",
      "    val_loss       : -1757.7213236490886\n",
      "    val_ess        : 26.613714059193928\n",
      "    val_log_marginal: 1758.0254618326824\n",
      "Train Epoch: 242 [0/54000 (0%)] Loss: -1756.838135\n",
      "Train Epoch: 242 [11264/54000 (21%)] Loss: -1757.137695\n",
      "Train Epoch: 242 [22528/54000 (42%)] Loss: -1756.871216\n",
      "Train Epoch: 242 [33792/54000 (63%)] Loss: -1759.238770\n",
      "Train Epoch: 242 [45056/54000 (83%)] Loss: -1758.360962\n",
      "    epoch          : 242\n",
      "    loss           : -1759.4169829746463\n",
      "    ess            : 26.61012385026464\n",
      "    log_marginal   : 1759.7315167121167\n",
      "    val_loss       : -1759.4176839192708\n",
      "    val_ess        : 26.65510098139445\n",
      "    val_log_marginal: 1759.7221171061199\n",
      "Train Epoch: 243 [0/54000 (0%)] Loss: -1762.141724\n",
      "Train Epoch: 243 [11264/54000 (21%)] Loss: -1754.885010\n",
      "Train Epoch: 243 [22528/54000 (42%)] Loss: -1765.965942\n",
      "Train Epoch: 243 [33792/54000 (63%)] Loss: -1764.116699\n",
      "Train Epoch: 243 [45056/54000 (83%)] Loss: -1759.316528\n",
      "    epoch          : 243\n",
      "    loss           : -1761.0227661132812\n",
      "    ess            : 26.588073568524056\n",
      "    log_marginal   : 1761.3431304355838\n",
      "    val_loss       : -1760.6866658528645\n",
      "    val_ess        : 26.519792874654133\n",
      "    val_log_marginal: 1761.0075276692708\n",
      "Train Epoch: 244 [0/54000 (0%)] Loss: -1763.199951\n",
      "Train Epoch: 244 [11264/54000 (21%)] Loss: -1763.893799\n",
      "Train Epoch: 244 [22528/54000 (42%)] Loss: -1759.201538\n",
      "Train Epoch: 244 [33792/54000 (63%)] Loss: -1760.847412\n",
      "Train Epoch: 244 [45056/54000 (83%)] Loss: -1762.766235\n",
      "    epoch          : 244\n",
      "    loss           : -1762.3033447265625\n",
      "    ess            : 26.56473334330433\n",
      "    log_marginal   : 1762.6267435325767\n",
      "    val_loss       : -1761.8612874348958\n",
      "    val_ess        : 26.676963329315186\n",
      "    val_log_marginal: 1762.1746826171875\n",
      "Train Epoch: 245 [0/54000 (0%)] Loss: -1764.966675\n",
      "Train Epoch: 245 [11264/54000 (21%)] Loss: -1765.958130\n",
      "Train Epoch: 245 [22528/54000 (42%)] Loss: -1762.480225\n",
      "Train Epoch: 245 [33792/54000 (63%)] Loss: -1765.562988\n",
      "Train Epoch: 245 [45056/54000 (83%)] Loss: -1763.671143\n",
      "    epoch          : 245\n",
      "    loss           : -1763.0613806382664\n",
      "    ess            : 26.599944132678914\n",
      "    log_marginal   : 1763.3843429853332\n",
      "    val_loss       : -1760.5661214192708\n",
      "    val_ess        : 26.681118965148926\n",
      "    val_log_marginal: 1760.8919169108074\n",
      "Train Epoch: 246 [0/54000 (0%)] Loss: -1756.241943\n",
      "Train Epoch: 246 [11264/54000 (21%)] Loss: -1758.225586\n",
      "Train Epoch: 246 [22528/54000 (42%)] Loss: -1736.755615\n",
      "Train Epoch: 246 [33792/54000 (63%)] Loss: -1760.747314\n",
      "Train Epoch: 246 [45056/54000 (83%)] Loss: -1691.536865\n",
      "    epoch          : 246\n",
      "    loss           : -1739.0633210955925\n",
      "    ess            : 26.458992580197894\n",
      "    log_marginal   : 1739.3808006430572\n",
      "    val_loss       : -1730.7176615397136\n",
      "    val_ess        : 26.612351576487224\n",
      "    val_log_marginal: 1731.0323181152344\n",
      "Train Epoch: 247 [0/54000 (0%)] Loss: -1720.358398\n",
      "Train Epoch: 247 [11264/54000 (21%)] Loss: -1733.015625\n",
      "Train Epoch: 247 [22528/54000 (42%)] Loss: -1737.027466\n",
      "Train Epoch: 247 [33792/54000 (63%)] Loss: -1747.876465\n",
      "Train Epoch: 247 [45056/54000 (83%)] Loss: -1739.457397\n",
      "    epoch          : 247\n",
      "    loss           : -1739.394832970961\n",
      "    ess            : 27.23677025201186\n",
      "    log_marginal   : 1739.6688911869842\n",
      "    val_loss       : -1743.0420633951824\n",
      "    val_ess        : 27.165127277374268\n",
      "    val_log_marginal: 1743.3106587727864\n",
      "Train Epoch: 248 [0/54000 (0%)] Loss: -1743.245361\n",
      "Train Epoch: 248 [11264/54000 (21%)] Loss: -1749.162842\n",
      "Train Epoch: 248 [22528/54000 (42%)] Loss: -1746.760986\n",
      "Train Epoch: 248 [33792/54000 (63%)] Loss: -1756.375000\n",
      "Train Epoch: 248 [45056/54000 (83%)] Loss: -1751.003540\n",
      "    epoch          : 248\n",
      "    loss           : -1752.0757642062206\n",
      "    ess            : 27.1009657517919\n",
      "    log_marginal   : 1752.3551935159935\n",
      "    val_loss       : -1753.5236714680989\n",
      "    val_ess        : 26.977816104888916\n",
      "    val_log_marginal: 1753.8116455078125\n",
      "Train Epoch: 249 [0/54000 (0%)] Loss: -1759.769653\n",
      "Train Epoch: 249 [11264/54000 (21%)] Loss: -1759.196655\n",
      "Train Epoch: 249 [22528/54000 (42%)] Loss: -1759.304688\n",
      "Train Epoch: 249 [33792/54000 (63%)] Loss: -1760.975342\n",
      "Train Epoch: 249 [45056/54000 (83%)] Loss: -1755.160156\n",
      "    epoch          : 249\n",
      "    loss           : -1756.9200312776386\n",
      "    ess            : 26.678237699112803\n",
      "    log_marginal   : 1757.2305251787293\n",
      "    val_loss       : -1757.6259155273438\n",
      "    val_ess        : 26.679142157236736\n",
      "    val_log_marginal: 1757.9303487141926\n",
      "Train Epoch: 250 [0/54000 (0%)] Loss: -1763.041992\n",
      "Train Epoch: 250 [11264/54000 (21%)] Loss: -1763.077637\n",
      "Train Epoch: 250 [22528/54000 (42%)] Loss: -1757.124268\n",
      "Train Epoch: 250 [33792/54000 (63%)] Loss: -1760.446289\n",
      "Train Epoch: 250 [45056/54000 (83%)] Loss: -1759.237915\n",
      "    epoch          : 250\n",
      "    loss           : -1759.0984105524028\n",
      "    ess            : 26.582252340496712\n",
      "    log_marginal   : 1759.4205564103036\n",
      "    val_loss       : -1759.4033813476562\n",
      "    val_ess        : 26.573881149291992\n",
      "    val_log_marginal: 1759.7187906901042\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch250.pth ...\n",
      "Train Epoch: 251 [0/54000 (0%)] Loss: -1760.734985\n",
      "Train Epoch: 251 [11264/54000 (21%)] Loss: -1759.891602\n",
      "Train Epoch: 251 [22528/54000 (42%)] Loss: -1756.764404\n",
      "Train Epoch: 251 [33792/54000 (63%)] Loss: -1759.113037\n",
      "Train Epoch: 251 [45056/54000 (83%)] Loss: -1757.371460\n",
      "    epoch          : 251\n",
      "    loss           : -1760.6454525353774\n",
      "    ess            : 26.52610271381882\n",
      "    log_marginal   : 1760.9697161980396\n",
      "    val_loss       : -1760.7612711588542\n",
      "    val_ess        : 26.423273881276447\n",
      "    val_log_marginal: 1761.0916748046875\n",
      "Train Epoch: 252 [0/54000 (0%)] Loss: -1759.826904\n",
      "Train Epoch: 252 [11264/54000 (21%)] Loss: -1760.196533\n",
      "Train Epoch: 252 [22528/54000 (42%)] Loss: -1760.651245\n",
      "Train Epoch: 252 [33792/54000 (63%)] Loss: -1761.618774\n",
      "Train Epoch: 252 [45056/54000 (83%)] Loss: -1763.242920\n",
      "    epoch          : 252\n",
      "    loss           : -1761.992841612618\n",
      "    ess            : 26.621661006279712\n",
      "    log_marginal   : 1762.315094569944\n",
      "    val_loss       : -1762.0847066243489\n",
      "    val_ess        : 26.822219689687092\n",
      "    val_log_marginal: 1762.384989420573\n",
      "Train Epoch: 253 [0/54000 (0%)] Loss: -1764.050293\n",
      "Train Epoch: 253 [11264/54000 (21%)] Loss: -1765.698853\n",
      "Train Epoch: 253 [22528/54000 (42%)] Loss: -1766.200073\n",
      "Train Epoch: 253 [33792/54000 (63%)] Loss: -1763.229248\n",
      "Train Epoch: 253 [45056/54000 (83%)] Loss: -1763.907471\n",
      "    epoch          : 253\n",
      "    loss           : -1763.0027258531102\n",
      "    ess            : 26.50588947871946\n",
      "    log_marginal   : 1763.328000626474\n",
      "    val_loss       : -1762.7576293945312\n",
      "    val_ess        : 26.6746408144633\n",
      "    val_log_marginal: 1763.0746256510417\n",
      "Train Epoch: 254 [0/54000 (0%)] Loss: -1766.777222\n",
      "Train Epoch: 254 [11264/54000 (21%)] Loss: -1760.575195\n",
      "Train Epoch: 254 [22528/54000 (42%)] Loss: -1753.414429\n",
      "Train Epoch: 254 [33792/54000 (63%)] Loss: -1728.113770\n",
      "Train Epoch: 254 [45056/54000 (83%)] Loss: -1732.555176\n",
      "    epoch          : 254\n",
      "    loss           : -1743.9737640956662\n",
      "    ess            : 26.4365884133105\n",
      "    log_marginal   : 1744.296978644605\n",
      "    val_loss       : -1743.203125\n",
      "    val_ess        : 26.485676924387615\n",
      "    val_log_marginal: 1743.5281778971355\n",
      "Train Epoch: 255 [0/54000 (0%)] Loss: -1746.107422\n",
      "Train Epoch: 255 [11264/54000 (21%)] Loss: -1739.674561\n",
      "Train Epoch: 255 [22528/54000 (42%)] Loss: -1742.593384\n",
      "Train Epoch: 255 [33792/54000 (63%)] Loss: -1741.167236\n",
      "Train Epoch: 255 [45056/54000 (83%)] Loss: -1746.302856\n",
      "    epoch          : 255\n",
      "    loss           : -1743.2821862562648\n",
      "    ess            : 27.264211798613925\n",
      "    log_marginal   : 1743.554046055056\n",
      "    val_loss       : -1752.196268717448\n",
      "    val_ess        : 27.237826188405354\n",
      "    val_log_marginal: 1752.457539876302\n",
      "Train Epoch: 256 [0/54000 (0%)] Loss: -1759.120850\n",
      "Train Epoch: 256 [11264/54000 (21%)] Loss: -1757.512329\n",
      "Train Epoch: 256 [22528/54000 (42%)] Loss: -1754.768188\n",
      "Train Epoch: 256 [33792/54000 (63%)] Loss: -1758.146973\n",
      "Train Epoch: 256 [45056/54000 (83%)] Loss: -1758.554199\n",
      "    epoch          : 256\n",
      "    loss           : -1754.9957885742188\n",
      "    ess            : 27.234289529188622\n",
      "    log_marginal   : 1755.273404103405\n",
      "    val_loss       : -1758.6870524088542\n",
      "    val_ess        : 26.750961621602375\n",
      "    val_log_marginal: 1758.9990641276042\n",
      "Train Epoch: 257 [0/54000 (0%)] Loss: -1760.403564\n",
      "Train Epoch: 257 [11264/54000 (21%)] Loss: -1759.538330\n",
      "Train Epoch: 257 [22528/54000 (42%)] Loss: -1759.167236\n",
      "Train Epoch: 257 [33792/54000 (63%)] Loss: -1758.811523\n",
      "Train Epoch: 257 [45056/54000 (83%)] Loss: -1761.210449\n",
      "    epoch          : 257\n",
      "    loss           : -1758.7408700619103\n",
      "    ess            : 26.665293747524046\n",
      "    log_marginal   : 1759.0560924602005\n",
      "    val_loss       : -1760.449442545573\n",
      "    val_ess        : 26.495065689086914\n",
      "    val_log_marginal: 1760.7874959309895\n",
      "Train Epoch: 258 [0/54000 (0%)] Loss: -1759.026855\n",
      "Train Epoch: 258 [11264/54000 (21%)] Loss: -1761.262695\n",
      "Train Epoch: 258 [22528/54000 (42%)] Loss: -1761.472412\n",
      "Train Epoch: 258 [33792/54000 (63%)] Loss: -1760.322388\n",
      "Train Epoch: 258 [45056/54000 (83%)] Loss: -1757.357178\n",
      "    epoch          : 258\n",
      "    loss           : -1760.7040209500294\n",
      "    ess            : 26.644410223331093\n",
      "    log_marginal   : 1761.0213853368218\n",
      "    val_loss       : -1762.1992492675781\n",
      "    val_ess        : 26.446960767110188\n",
      "    val_log_marginal: 1762.5164184570312\n",
      "Train Epoch: 259 [0/54000 (0%)] Loss: -1761.294922\n",
      "Train Epoch: 259 [11264/54000 (21%)] Loss: -1758.800781\n",
      "Train Epoch: 259 [22528/54000 (42%)] Loss: -1760.106689\n",
      "Train Epoch: 259 [33792/54000 (63%)] Loss: -1764.470459\n",
      "Train Epoch: 259 [45056/54000 (83%)] Loss: -1759.310425\n",
      "    epoch          : 259\n",
      "    loss           : -1762.179725503022\n",
      "    ess            : 26.567179463944345\n",
      "    log_marginal   : 1762.5026671211674\n",
      "    val_loss       : -1763.3848266601562\n",
      "    val_ess        : 26.30782111485799\n",
      "    val_log_marginal: 1763.7232869466145\n",
      "Train Epoch: 260 [0/54000 (0%)] Loss: -1763.677979\n",
      "Train Epoch: 260 [11264/54000 (21%)] Loss: -1768.472168\n",
      "Train Epoch: 260 [22528/54000 (42%)] Loss: -1761.982422\n",
      "Train Epoch: 260 [33792/54000 (63%)] Loss: -1760.248535\n",
      "Train Epoch: 260 [45056/54000 (83%)] Loss: -1761.961060\n",
      "    epoch          : 260\n",
      "    loss           : -1760.636399754938\n",
      "    ess            : 26.633839283349378\n",
      "    log_marginal   : 1760.9565084205483\n",
      "    val_loss       : -1731.0962829589844\n",
      "    val_ess        : 26.442435423533123\n",
      "    val_log_marginal: 1731.4216410319011\n",
      "Train Epoch: 261 [0/54000 (0%)] Loss: -1722.722778\n",
      "Train Epoch: 261 [11264/54000 (21%)] Loss: -1753.351929\n",
      "Train Epoch: 261 [22528/54000 (42%)] Loss: -1752.072754\n",
      "Train Epoch: 261 [33792/54000 (63%)] Loss: -1702.351929\n",
      "Train Epoch: 261 [45056/54000 (83%)] Loss: -1746.165039\n",
      "    epoch          : 261\n",
      "    loss           : -1734.3671621646522\n",
      "    ess            : 26.546869727800477\n",
      "    log_marginal   : 1734.6772345776828\n",
      "    val_loss       : -1731.9499613444011\n",
      "    val_ess        : 27.84053595860799\n",
      "    val_log_marginal: 1732.2029927571614\n",
      "Train Epoch: 262 [0/54000 (0%)] Loss: -1736.375488\n",
      "Train Epoch: 262 [11264/54000 (21%)] Loss: -1738.034424\n",
      "Train Epoch: 262 [22528/54000 (42%)] Loss: -1746.870239\n",
      "Train Epoch: 262 [33792/54000 (63%)] Loss: -1748.097412\n",
      "Train Epoch: 262 [45056/54000 (83%)] Loss: -1744.982422\n",
      "    epoch          : 262\n",
      "    loss           : -1746.9642241855838\n",
      "    ess            : 27.256214933575325\n",
      "    log_marginal   : 1747.2413905881485\n",
      "    val_loss       : -1751.025858561198\n",
      "    val_ess        : 27.10091733932495\n",
      "    val_log_marginal: 1751.3113199869792\n",
      "Train Epoch: 263 [0/54000 (0%)] Loss: -1752.680420\n",
      "Train Epoch: 263 [11264/54000 (21%)] Loss: -1749.655029\n",
      "Train Epoch: 263 [22528/54000 (42%)] Loss: -1756.471436\n",
      "Train Epoch: 263 [33792/54000 (63%)] Loss: -1752.383911\n",
      "Train Epoch: 263 [45056/54000 (83%)] Loss: -1752.851318\n",
      "    epoch          : 263\n",
      "    loss           : -1755.2088243016656\n",
      "    ess            : 26.855801888231962\n",
      "    log_marginal   : 1755.5110842146964\n",
      "    val_loss       : -1755.80029296875\n",
      "    val_ess        : 26.689552783966064\n",
      "    val_log_marginal: 1756.095438639323\n",
      "Train Epoch: 264 [0/54000 (0%)] Loss: -1760.097900\n",
      "Train Epoch: 264 [11264/54000 (21%)] Loss: -1759.493408\n",
      "Train Epoch: 264 [22528/54000 (42%)] Loss: -1763.604736\n",
      "Train Epoch: 264 [33792/54000 (63%)] Loss: -1762.927002\n",
      "Train Epoch: 264 [45056/54000 (83%)] Loss: -1755.595093\n",
      "    epoch          : 264\n",
      "    loss           : -1758.008673901828\n",
      "    ess            : 26.635287968617565\n",
      "    log_marginal   : 1758.3213604621167\n",
      "    val_loss       : -1757.9209289550781\n",
      "    val_ess        : 26.622185548146565\n",
      "    val_log_marginal: 1758.2296447753906\n",
      "Train Epoch: 265 [0/54000 (0%)] Loss: -1757.694092\n",
      "Train Epoch: 265 [11264/54000 (21%)] Loss: -1757.134521\n",
      "Train Epoch: 265 [22528/54000 (42%)] Loss: -1760.560791\n",
      "Train Epoch: 265 [33792/54000 (63%)] Loss: -1760.577148\n",
      "Train Epoch: 265 [45056/54000 (83%)] Loss: -1764.521362\n",
      "    epoch          : 265\n",
      "    loss           : -1759.7799889906398\n",
      "    ess            : 26.61412463997895\n",
      "    log_marginal   : 1760.0966647166126\n",
      "    val_loss       : -1758.8147481282551\n",
      "    val_ess        : 26.578145186106365\n",
      "    val_log_marginal: 1759.1350199381511\n",
      "Train Epoch: 266 [0/54000 (0%)] Loss: -1758.108643\n",
      "Train Epoch: 266 [11264/54000 (21%)] Loss: -1763.943359\n",
      "Train Epoch: 266 [22528/54000 (42%)] Loss: -1762.926147\n",
      "Train Epoch: 266 [33792/54000 (63%)] Loss: -1758.235596\n",
      "Train Epoch: 266 [45056/54000 (83%)] Loss: -1759.036865\n",
      "    epoch          : 266\n",
      "    loss           : -1761.0911185786408\n",
      "    ess            : 26.54458598370822\n",
      "    log_marginal   : 1761.416400261645\n",
      "    val_loss       : -1760.141845703125\n",
      "    val_ess        : 26.755610783894856\n",
      "    val_log_marginal: 1760.4457702636719\n",
      "Train Epoch: 267 [0/54000 (0%)] Loss: -1762.379150\n",
      "Train Epoch: 267 [11264/54000 (21%)] Loss: -1771.987061\n",
      "Train Epoch: 267 [22528/54000 (42%)] Loss: -1761.603638\n",
      "Train Epoch: 267 [33792/54000 (63%)] Loss: -1762.499268\n",
      "Train Epoch: 267 [45056/54000 (83%)] Loss: -1761.488403\n",
      "    epoch          : 267\n",
      "    loss           : -1761.0165428305572\n",
      "    ess            : 26.59905520025289\n",
      "    log_marginal   : 1761.3427008862766\n",
      "    val_loss       : -1751.3257853190105\n",
      "    val_ess        : 26.532123883565266\n",
      "    val_log_marginal: 1751.6488037109375\n",
      "Train Epoch: 268 [0/54000 (0%)] Loss: -1751.402588\n",
      "Train Epoch: 268 [11264/54000 (21%)] Loss: -1732.359497\n",
      "Train Epoch: 268 [22528/54000 (42%)] Loss: -1744.707886\n",
      "Train Epoch: 268 [33792/54000 (63%)] Loss: -1735.727173\n",
      "Train Epoch: 268 [45056/54000 (83%)] Loss: -1743.347900\n",
      "    epoch          : 268\n",
      "    loss           : -1739.6835292600235\n",
      "    ess            : 26.603075693238456\n",
      "    log_marginal   : 1739.9943156692218\n",
      "    val_loss       : -1745.6900329589844\n",
      "    val_ess        : 27.142605940500896\n",
      "    val_log_marginal: 1745.9792785644531\n",
      "Train Epoch: 269 [0/54000 (0%)] Loss: -1736.205078\n",
      "Train Epoch: 269 [11264/54000 (21%)] Loss: -1742.585205\n",
      "Train Epoch: 269 [22528/54000 (42%)] Loss: -1732.342529\n",
      "Train Epoch: 269 [33792/54000 (63%)] Loss: -1743.793945\n",
      "Train Epoch: 269 [45056/54000 (83%)] Loss: -1735.514160\n",
      "    epoch          : 269\n",
      "    loss           : -1741.5147163822967\n",
      "    ess            : 27.32196406598361\n",
      "    log_marginal   : 1741.781146355395\n",
      "    val_loss       : -1741.6136983235676\n",
      "    val_ess        : 26.901191870371502\n",
      "    val_log_marginal: 1741.9093119303386\n",
      "Train Epoch: 270 [0/54000 (0%)] Loss: -1749.955566\n",
      "Train Epoch: 270 [11264/54000 (21%)] Loss: -1750.012939\n",
      "Train Epoch: 270 [22528/54000 (42%)] Loss: -1749.514648\n",
      "Train Epoch: 270 [33792/54000 (63%)] Loss: -1749.788208\n",
      "Train Epoch: 270 [45056/54000 (83%)] Loss: -1752.514648\n",
      "    epoch          : 270\n",
      "    loss           : -1750.6811984080189\n",
      "    ess            : 27.009426854691416\n",
      "    log_marginal   : 1750.968394153523\n",
      "    val_loss       : -1751.9688618977864\n",
      "    val_ess        : 27.071313222249348\n",
      "    val_log_marginal: 1752.2510477701824\n",
      "Train Epoch: 271 [0/54000 (0%)] Loss: -1757.563477\n",
      "Train Epoch: 271 [11264/54000 (21%)] Loss: -1754.515381\n",
      "Train Epoch: 271 [22528/54000 (42%)] Loss: -1753.833984\n",
      "Train Epoch: 271 [33792/54000 (63%)] Loss: -1757.749634\n",
      "Train Epoch: 271 [45056/54000 (83%)] Loss: -1758.542236\n",
      "    epoch          : 271\n",
      "    loss           : -1755.7344510060436\n",
      "    ess            : 26.718094753769208\n",
      "    log_marginal   : 1756.0438439711086\n",
      "    val_loss       : -1756.213623046875\n",
      "    val_ess        : 26.67423391342163\n",
      "    val_log_marginal: 1756.5109151204426\n",
      "Train Epoch: 272 [0/54000 (0%)] Loss: -1759.442017\n",
      "Train Epoch: 272 [11264/54000 (21%)] Loss: -1753.097900\n",
      "Train Epoch: 272 [22528/54000 (42%)] Loss: -1758.381348\n",
      "Train Epoch: 272 [33792/54000 (63%)] Loss: -1756.874756\n",
      "Train Epoch: 272 [45056/54000 (83%)] Loss: -1763.822388\n",
      "    epoch          : 272\n",
      "    loss           : -1758.3094240584464\n",
      "    ess            : 26.697873529398215\n",
      "    log_marginal   : 1758.6218918134582\n",
      "    val_loss       : -1758.4177551269531\n",
      "    val_ess        : 26.549847920735676\n",
      "    val_log_marginal: 1758.7398173014324\n",
      "Train Epoch: 273 [0/54000 (0%)] Loss: -1761.582397\n",
      "Train Epoch: 273 [11264/54000 (21%)] Loss: -1757.499268\n",
      "Train Epoch: 273 [22528/54000 (42%)] Loss: -1760.148682\n",
      "Train Epoch: 273 [33792/54000 (63%)] Loss: -1762.256348\n",
      "Train Epoch: 273 [45056/54000 (83%)] Loss: -1758.267578\n",
      "    epoch          : 273\n",
      "    loss           : -1759.857922823924\n",
      "    ess            : 26.493784022781085\n",
      "    log_marginal   : 1760.1850240455483\n",
      "    val_loss       : -1759.5349527994792\n",
      "    val_ess        : 26.235867818196613\n",
      "    val_log_marginal: 1759.8772277832031\n",
      "Train Epoch: 274 [0/54000 (0%)] Loss: -1765.210815\n",
      "Train Epoch: 274 [11264/54000 (21%)] Loss: -1749.566895\n",
      "Train Epoch: 274 [22528/54000 (42%)] Loss: -1763.423828\n",
      "Train Epoch: 274 [33792/54000 (63%)] Loss: -1761.352173\n",
      "Train Epoch: 274 [45056/54000 (83%)] Loss: -1768.157715\n",
      "    epoch          : 274\n",
      "    loss           : -1761.0075545400944\n",
      "    ess            : 26.60505768038192\n",
      "    log_marginal   : 1761.325816028523\n",
      "    val_loss       : -1760.255126953125\n",
      "    val_ess        : 26.68880494435628\n",
      "    val_log_marginal: 1760.5707600911458\n",
      "Train Epoch: 275 [0/54000 (0%)] Loss: -1764.677124\n",
      "Train Epoch: 275 [11264/54000 (21%)] Loss: -1761.235107\n",
      "Train Epoch: 275 [22528/54000 (42%)] Loss: -1740.431641\n",
      "Train Epoch: 275 [33792/54000 (63%)] Loss: -1743.536865\n",
      "Train Epoch: 275 [45056/54000 (83%)] Loss: -1748.240479\n",
      "    epoch          : 275\n",
      "    loss           : -1747.2609103220814\n",
      "    ess            : 26.561488583402813\n",
      "    log_marginal   : 1747.5775111936173\n",
      "    val_loss       : -1720.5118509928386\n",
      "    val_ess        : 26.439582347869873\n",
      "    val_log_marginal: 1720.820576985677\n",
      "Train Epoch: 276 [0/54000 (0%)] Loss: -1729.520020\n",
      "Train Epoch: 276 [11264/54000 (21%)] Loss: -1739.796143\n",
      "Train Epoch: 276 [22528/54000 (42%)] Loss: -1738.458496\n",
      "Train Epoch: 276 [33792/54000 (63%)] Loss: -1743.030273\n",
      "Train Epoch: 276 [45056/54000 (83%)] Loss: -1741.502197\n",
      "    epoch          : 276\n",
      "    loss           : -1739.5022859393425\n",
      "    ess            : 26.929057859024912\n",
      "    log_marginal   : 1739.7932601065006\n",
      "    val_loss       : -1725.2350667317708\n",
      "    val_ess        : 27.64624261856079\n",
      "    val_log_marginal: 1725.4971110026042\n",
      "Train Epoch: 277 [0/54000 (0%)] Loss: -1743.612549\n",
      "Train Epoch: 277 [11264/54000 (21%)] Loss: -1740.178223\n",
      "Train Epoch: 277 [22528/54000 (42%)] Loss: -1748.539551\n",
      "Train Epoch: 277 [33792/54000 (63%)] Loss: -1741.557373\n",
      "Train Epoch: 277 [45056/54000 (83%)] Loss: -1741.838867\n",
      "    epoch          : 277\n",
      "    loss           : -1744.6462252634876\n",
      "    ess            : 27.192426717506265\n",
      "    log_marginal   : 1744.918051665684\n",
      "    val_loss       : -1743.1094156901042\n",
      "    val_ess        : 27.585525194803875\n",
      "    val_log_marginal: 1743.3595174153645\n",
      "Train Epoch: 278 [0/54000 (0%)] Loss: -1759.388672\n",
      "Train Epoch: 278 [11264/54000 (21%)] Loss: -1754.953735\n",
      "Train Epoch: 278 [22528/54000 (42%)] Loss: -1754.866455\n",
      "Train Epoch: 278 [33792/54000 (63%)] Loss: -1750.627441\n",
      "Train Epoch: 278 [45056/54000 (83%)] Loss: -1749.195312\n",
      "    epoch          : 278\n",
      "    loss           : -1754.108162358122\n",
      "    ess            : 27.035628372768187\n",
      "    log_marginal   : 1754.393794221698\n",
      "    val_loss       : -1750.3674825032551\n",
      "    val_ess        : 26.79226525624593\n",
      "    val_log_marginal: 1750.6761678059895\n",
      "Train Epoch: 279 [0/54000 (0%)] Loss: -1758.374756\n",
      "Train Epoch: 279 [11264/54000 (21%)] Loss: -1759.520386\n",
      "Train Epoch: 279 [22528/54000 (42%)] Loss: -1756.642700\n",
      "Train Epoch: 279 [33792/54000 (63%)] Loss: -1753.994385\n",
      "Train Epoch: 279 [45056/54000 (83%)] Loss: -1757.572876\n",
      "    epoch          : 279\n",
      "    loss           : -1757.6282912920105\n",
      "    ess            : 26.70070657190287\n",
      "    log_marginal   : 1757.9383706146816\n",
      "    val_loss       : -1754.0099487304688\n",
      "    val_ess        : 26.625168164571125\n",
      "    val_log_marginal: 1754.3241170247395\n",
      "Train Epoch: 280 [0/54000 (0%)] Loss: -1767.394043\n",
      "Train Epoch: 280 [11264/54000 (21%)] Loss: -1757.505615\n",
      "Train Epoch: 280 [22528/54000 (42%)] Loss: -1758.046875\n",
      "Train Epoch: 280 [33792/54000 (63%)] Loss: -1761.537720\n",
      "Train Epoch: 280 [45056/54000 (83%)] Loss: -1754.585693\n",
      "    epoch          : 280\n",
      "    loss           : -1759.4648161114387\n",
      "    ess            : 26.580572902031665\n",
      "    log_marginal   : 1759.7863504661705\n",
      "    val_loss       : -1756.0466918945312\n",
      "    val_ess        : 26.562404950459797\n",
      "    val_log_marginal: 1756.3782043457031\n",
      "Train Epoch: 281 [0/54000 (0%)] Loss: -1757.920166\n",
      "Train Epoch: 281 [11264/54000 (21%)] Loss: -1765.349731\n",
      "Train Epoch: 281 [22528/54000 (42%)] Loss: -1762.589478\n",
      "Train Epoch: 281 [33792/54000 (63%)] Loss: -1765.545654\n",
      "Train Epoch: 281 [45056/54000 (83%)] Loss: -1769.733765\n",
      "    epoch          : 281\n",
      "    loss           : -1760.844474360628\n",
      "    ess            : 26.531256333836968\n",
      "    log_marginal   : 1761.1702212927476\n",
      "    val_loss       : -1757.6971028645833\n",
      "    val_ess        : 26.595990498860676\n",
      "    val_log_marginal: 1758.0155131022136\n",
      "Train Epoch: 282 [0/54000 (0%)] Loss: -1761.729004\n",
      "Train Epoch: 282 [11264/54000 (21%)] Loss: -1763.145020\n",
      "Train Epoch: 282 [22528/54000 (42%)] Loss: -1765.315918\n",
      "Train Epoch: 282 [33792/54000 (63%)] Loss: -1762.480591\n",
      "Train Epoch: 282 [45056/54000 (83%)] Loss: -1761.003540\n",
      "    epoch          : 282\n",
      "    loss           : -1762.1061067401238\n",
      "    ess            : 26.55614035984255\n",
      "    log_marginal   : 1762.4301124428803\n",
      "    val_loss       : -1758.9189961751301\n",
      "    val_ess        : 26.740605036417644\n",
      "    val_log_marginal: 1759.2411397298176\n",
      "Train Epoch: 283 [0/54000 (0%)] Loss: -1762.414062\n",
      "Train Epoch: 283 [11264/54000 (21%)] Loss: -1765.713623\n",
      "Train Epoch: 283 [22528/54000 (42%)] Loss: -1763.188232\n",
      "Train Epoch: 283 [33792/54000 (63%)] Loss: -1762.621704\n",
      "Train Epoch: 283 [45056/54000 (83%)] Loss: -1765.771484\n",
      "    epoch          : 283\n",
      "    loss           : -1762.9752047556751\n",
      "    ess            : 26.527842071821105\n",
      "    log_marginal   : 1763.299043475457\n",
      "    val_loss       : -1759.9365234375\n",
      "    val_ess        : 26.624730269114178\n",
      "    val_log_marginal: 1760.2660013834636\n",
      "Train Epoch: 284 [0/54000 (0%)] Loss: -1762.670166\n",
      "Train Epoch: 284 [11264/54000 (21%)] Loss: -1760.784668\n",
      "Train Epoch: 284 [22528/54000 (42%)] Loss: -1764.950806\n",
      "Train Epoch: 284 [33792/54000 (63%)] Loss: -1764.616211\n",
      "Train Epoch: 284 [45056/54000 (83%)] Loss: -1696.492554\n",
      "    epoch          : 284\n",
      "    loss           : -1749.9751943912147\n",
      "    ess            : 26.53254975013013\n",
      "    log_marginal   : 1750.2973771005306\n",
      "    val_loss       : -1716.106465657552\n",
      "    val_ess        : 26.40789572397868\n",
      "    val_log_marginal: 1716.393290201823\n",
      "Train Epoch: 285 [0/54000 (0%)] Loss: -1719.164307\n",
      "Train Epoch: 285 [11264/54000 (21%)] Loss: -1733.516235\n",
      "Train Epoch: 285 [22528/54000 (42%)] Loss: -1737.673828\n",
      "Train Epoch: 285 [33792/54000 (63%)] Loss: -1731.279297\n",
      "Train Epoch: 285 [45056/54000 (83%)] Loss: -1729.674561\n",
      "    epoch          : 285\n",
      "    loss           : -1733.7233333947524\n",
      "    ess            : 26.76120795843736\n",
      "    log_marginal   : 1734.0239396005306\n",
      "    val_loss       : -1728.8057149251301\n",
      "    val_ess        : 27.429824829101562\n",
      "    val_log_marginal: 1729.0872599283855\n",
      "Train Epoch: 286 [0/54000 (0%)] Loss: -1744.033813\n",
      "Train Epoch: 286 [11264/54000 (21%)] Loss: -1753.240479\n",
      "Train Epoch: 286 [22528/54000 (42%)] Loss: -1749.985107\n",
      "Train Epoch: 286 [33792/54000 (63%)] Loss: -1754.848877\n",
      "Train Epoch: 286 [45056/54000 (83%)] Loss: -1751.312012\n",
      "    epoch          : 286\n",
      "    loss           : -1750.3395569999263\n",
      "    ess            : 27.31573518717064\n",
      "    log_marginal   : 1750.612039817954\n",
      "    val_loss       : -1742.7911783854167\n",
      "    val_ess        : 27.617382208506267\n",
      "    val_log_marginal: 1743.0445760091145\n",
      "Train Epoch: 287 [0/54000 (0%)] Loss: -1754.465576\n",
      "Train Epoch: 287 [11264/54000 (21%)] Loss: -1761.997314\n",
      "Train Epoch: 287 [22528/54000 (42%)] Loss: -1756.224609\n",
      "Train Epoch: 287 [33792/54000 (63%)] Loss: -1755.406006\n",
      "Train Epoch: 287 [45056/54000 (83%)] Loss: -1749.384033\n",
      "    epoch          : 287\n",
      "    loss           : -1755.4462084500294\n",
      "    ess            : 26.61623209827351\n",
      "    log_marginal   : 1755.7567299896816\n",
      "    val_loss       : -1749.5309956868489\n",
      "    val_ess        : 26.89031998316447\n",
      "    val_log_marginal: 1749.826416015625\n",
      "Train Epoch: 288 [0/54000 (0%)] Loss: -1754.479492\n",
      "Train Epoch: 288 [11264/54000 (21%)] Loss: -1755.487061\n",
      "Train Epoch: 288 [22528/54000 (42%)] Loss: -1758.021851\n",
      "Train Epoch: 288 [33792/54000 (63%)] Loss: -1755.108643\n",
      "Train Epoch: 288 [45056/54000 (83%)] Loss: -1761.855469\n",
      "    epoch          : 288\n",
      "    loss           : -1757.8266567014298\n",
      "    ess            : 26.61419566172474\n",
      "    log_marginal   : 1758.1426287956958\n",
      "    val_loss       : -1752.5167541503906\n",
      "    val_ess        : 26.692498683929443\n",
      "    val_log_marginal: 1752.8309020996094\n",
      "Train Epoch: 289 [0/54000 (0%)] Loss: -1759.699097\n",
      "Train Epoch: 289 [11264/54000 (21%)] Loss: -1759.315186\n",
      "Train Epoch: 289 [22528/54000 (42%)] Loss: -1760.527100\n",
      "Train Epoch: 289 [33792/54000 (63%)] Loss: -1758.255127\n",
      "Train Epoch: 289 [45056/54000 (83%)] Loss: -1753.956299\n",
      "    epoch          : 289\n",
      "    loss           : -1759.4874279094192\n",
      "    ess            : 26.59720548593773\n",
      "    log_marginal   : 1759.8064690355984\n",
      "    val_loss       : -1755.3550415039062\n",
      "    val_ess        : 26.905288219451904\n",
      "    val_log_marginal: 1755.6649780273438\n",
      "Train Epoch: 290 [0/54000 (0%)] Loss: -1760.151733\n",
      "Train Epoch: 290 [11264/54000 (21%)] Loss: -1759.262939\n",
      "Train Epoch: 290 [22528/54000 (42%)] Loss: -1763.169189\n",
      "Train Epoch: 290 [33792/54000 (63%)] Loss: -1757.982422\n",
      "Train Epoch: 290 [45056/54000 (83%)] Loss: -1731.621948\n",
      "    epoch          : 290\n",
      "    loss           : -1747.8067684533462\n",
      "    ess            : 26.504988616367555\n",
      "    log_marginal   : 1748.1268368127212\n",
      "    val_loss       : -1689.2051391601562\n",
      "    val_ess        : 26.050861994425457\n",
      "    val_log_marginal: 1689.5063883463542\n",
      "Train Epoch: 291 [0/54000 (0%)] Loss: -1692.733643\n",
      "Train Epoch: 291 [11264/54000 (21%)] Loss: -1723.458374\n",
      "Train Epoch: 291 [22528/54000 (42%)] Loss: -1736.975830\n",
      "Train Epoch: 291 [33792/54000 (63%)] Loss: -1736.255615\n",
      "Train Epoch: 291 [45056/54000 (83%)] Loss: -1739.707397\n",
      "    epoch          : 291\n",
      "    loss           : -1731.2700874760467\n",
      "    ess            : 26.776609204850107\n",
      "    log_marginal   : 1731.564684597951\n",
      "    val_loss       : -1721.1264343261719\n",
      "    val_ess        : 28.005776087443035\n",
      "    val_log_marginal: 1721.3865051269531\n",
      "Train Epoch: 292 [0/54000 (0%)] Loss: -1746.925537\n",
      "Train Epoch: 292 [11264/54000 (21%)] Loss: -1746.451416\n",
      "Train Epoch: 292 [22528/54000 (42%)] Loss: -1741.437256\n",
      "Train Epoch: 292 [33792/54000 (63%)] Loss: -1753.594116\n",
      "Train Epoch: 292 [45056/54000 (83%)] Loss: -1746.927490\n",
      "    epoch          : 292\n",
      "    loss           : -1747.5531915628685\n",
      "    ess            : 27.242460520762318\n",
      "    log_marginal   : 1747.8271541955337\n",
      "    val_loss       : -1737.0066019694011\n",
      "    val_ess        : 27.30830987294515\n",
      "    val_log_marginal: 1737.2663981119792\n",
      "Train Epoch: 293 [0/54000 (0%)] Loss: -1752.693359\n",
      "Train Epoch: 293 [11264/54000 (21%)] Loss: -1749.385498\n",
      "Train Epoch: 293 [22528/54000 (42%)] Loss: -1754.542969\n",
      "Train Epoch: 293 [33792/54000 (63%)] Loss: -1751.107056\n",
      "Train Epoch: 293 [45056/54000 (83%)] Loss: -1753.669800\n",
      "    epoch          : 293\n",
      "    loss           : -1752.979827305056\n",
      "    ess            : 26.703893193658793\n",
      "    log_marginal   : 1753.286803047612\n",
      "    val_loss       : -1743.3827819824219\n",
      "    val_ess        : 26.676945686340332\n",
      "    val_log_marginal: 1743.6973470052083\n",
      "Train Epoch: 294 [0/54000 (0%)] Loss: -1755.523926\n",
      "Train Epoch: 294 [11264/54000 (21%)] Loss: -1759.043701\n",
      "Train Epoch: 294 [22528/54000 (42%)] Loss: -1756.259277\n",
      "Train Epoch: 294 [33792/54000 (63%)] Loss: -1754.869629\n",
      "Train Epoch: 294 [45056/54000 (83%)] Loss: -1754.357666\n",
      "    epoch          : 294\n",
      "    loss           : -1755.4981447615714\n",
      "    ess            : 26.559246063232422\n",
      "    log_marginal   : 1755.8179252192658\n",
      "    val_loss       : -1746.7325032552083\n",
      "    val_ess        : 26.64485772450765\n",
      "    val_log_marginal: 1747.0616455078125\n",
      "Train Epoch: 295 [0/54000 (0%)] Loss: -1755.294434\n",
      "Train Epoch: 295 [11264/54000 (21%)] Loss: -1760.242676\n",
      "Train Epoch: 295 [22528/54000 (42%)] Loss: -1752.516724\n",
      "Train Epoch: 295 [33792/54000 (63%)] Loss: -1757.927979\n",
      "Train Epoch: 295 [45056/54000 (83%)] Loss: -1760.116211\n",
      "    epoch          : 295\n",
      "    loss           : -1757.0982366597877\n",
      "    ess            : 26.55968153251792\n",
      "    log_marginal   : 1757.414302034198\n",
      "    val_loss       : -1749.2831624348958\n",
      "    val_ess        : 26.799117883046467\n",
      "    val_log_marginal: 1749.5830688476562\n",
      "Train Epoch: 296 [0/54000 (0%)] Loss: -1754.610352\n",
      "Train Epoch: 296 [11264/54000 (21%)] Loss: -1760.247803\n",
      "Train Epoch: 296 [22528/54000 (42%)] Loss: -1760.722778\n",
      "Train Epoch: 296 [33792/54000 (63%)] Loss: -1756.566895\n",
      "Train Epoch: 296 [45056/54000 (83%)] Loss: -1759.415894\n",
      "    epoch          : 296\n",
      "    loss           : -1758.4572396908166\n",
      "    ess            : 26.53083657318691\n",
      "    log_marginal   : 1758.7833482274468\n",
      "    val_loss       : -1751.2630920410156\n",
      "    val_ess        : 26.968510309855144\n",
      "    val_log_marginal: 1751.5579121907551\n",
      "Train Epoch: 297 [0/54000 (0%)] Loss: -1762.908325\n",
      "Train Epoch: 297 [11264/54000 (21%)] Loss: -1763.434814\n",
      "Train Epoch: 297 [22528/54000 (42%)] Loss: -1761.102783\n",
      "Train Epoch: 297 [33792/54000 (63%)] Loss: -1761.704834\n",
      "Train Epoch: 297 [45056/54000 (83%)] Loss: -1756.506470\n",
      "    epoch          : 297\n",
      "    loss           : -1759.5446477926002\n",
      "    ess            : 26.5821178724181\n",
      "    log_marginal   : 1759.8647357292896\n",
      "    val_loss       : -1753.0678405761719\n",
      "    val_ess        : 26.47883478800456\n",
      "    val_log_marginal: 1753.4000752766926\n",
      "Train Epoch: 298 [0/54000 (0%)] Loss: -1761.208008\n",
      "Train Epoch: 298 [11264/54000 (21%)] Loss: -1764.083130\n",
      "Train Epoch: 298 [22528/54000 (42%)] Loss: -1758.289795\n",
      "Train Epoch: 298 [33792/54000 (63%)] Loss: -1761.785156\n",
      "Train Epoch: 298 [45056/54000 (83%)] Loss: -1739.750977\n",
      "    epoch          : 298\n",
      "    loss           : -1754.444311753759\n",
      "    ess            : 26.52345511598407\n",
      "    log_marginal   : 1754.7690970942658\n",
      "    val_loss       : -1743.0725606282551\n",
      "    val_ess        : 26.44941282272339\n",
      "    val_log_marginal: 1743.3929239908855\n",
      "Train Epoch: 299 [0/54000 (0%)] Loss: -1747.109619\n",
      "Train Epoch: 299 [11264/54000 (21%)] Loss: -1728.882568\n",
      "Train Epoch: 299 [22528/54000 (42%)] Loss: -1735.400879\n",
      "Train Epoch: 299 [33792/54000 (63%)] Loss: -1733.263672\n",
      "Train Epoch: 299 [45056/54000 (83%)] Loss: -1733.787476\n",
      "    epoch          : 299\n",
      "    loss           : -1735.5314883825913\n",
      "    ess            : 26.774279954298486\n",
      "    log_marginal   : 1735.8328143425708\n",
      "    val_loss       : -1743.7342529296875\n",
      "    val_ess        : 27.111824830373127\n",
      "    val_log_marginal: 1744.0206298828125\n",
      "Train Epoch: 300 [0/54000 (0%)] Loss: -1751.816406\n",
      "Train Epoch: 300 [11264/54000 (21%)] Loss: -1748.982178\n",
      "Train Epoch: 300 [22528/54000 (42%)] Loss: -1746.888916\n",
      "Train Epoch: 300 [33792/54000 (63%)] Loss: -1752.432739\n",
      "Train Epoch: 300 [45056/54000 (83%)] Loss: -1747.408569\n",
      "    epoch          : 300\n",
      "    loss           : -1748.9484563863502\n",
      "    ess            : 27.281196576244426\n",
      "    log_marginal   : 1749.221885825103\n",
      "    val_loss       : -1750.5149332682292\n",
      "    val_ess        : 27.2171893119812\n",
      "    val_log_marginal: 1750.7909037272136\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [0/54000 (0%)] Loss: -1753.864258\n",
      "Train Epoch: 301 [11264/54000 (21%)] Loss: -1759.229004\n",
      "Train Epoch: 301 [22528/54000 (42%)] Loss: -1756.790039\n",
      "Train Epoch: 301 [33792/54000 (63%)] Loss: -1758.928223\n",
      "Train Epoch: 301 [45056/54000 (83%)] Loss: -1751.989258\n",
      "    epoch          : 301\n",
      "    loss           : -1755.131827876253\n",
      "    ess            : 26.790084335039246\n",
      "    log_marginal   : 1755.4361088590802\n",
      "    val_loss       : -1753.8040974934895\n",
      "    val_ess        : 26.522730509440105\n",
      "    val_log_marginal: 1754.1195678710938\n",
      "Train Epoch: 302 [0/54000 (0%)] Loss: -1760.366699\n",
      "Train Epoch: 302 [11264/54000 (21%)] Loss: -1758.034912\n",
      "Train Epoch: 302 [22528/54000 (42%)] Loss: -1760.007935\n",
      "Train Epoch: 302 [33792/54000 (63%)] Loss: -1760.415283\n",
      "Train Epoch: 302 [45056/54000 (83%)] Loss: -1752.626221\n",
      "    epoch          : 302\n",
      "    loss           : -1757.6060710403156\n",
      "    ess            : 26.655019256303895\n",
      "    log_marginal   : 1757.9220673183224\n",
      "    val_loss       : -1755.4165751139324\n",
      "    val_ess        : 26.62756077448527\n",
      "    val_log_marginal: 1755.7402852376301\n",
      "Train Epoch: 303 [0/54000 (0%)] Loss: -1761.223145\n",
      "Train Epoch: 303 [11264/54000 (21%)] Loss: -1766.691772\n",
      "Train Epoch: 303 [22528/54000 (42%)] Loss: -1761.419556\n",
      "Train Epoch: 303 [33792/54000 (63%)] Loss: -1761.950928\n",
      "Train Epoch: 303 [45056/54000 (83%)] Loss: -1762.815674\n",
      "    epoch          : 303\n",
      "    loss           : -1759.0728874926297\n",
      "    ess            : 26.55231689956953\n",
      "    log_marginal   : 1759.3990628224499\n",
      "    val_loss       : -1756.8238525390625\n",
      "    val_ess        : 26.421477158864338\n",
      "    val_log_marginal: 1757.1532185872395\n",
      "Train Epoch: 304 [0/54000 (0%)] Loss: -1755.511963\n",
      "Train Epoch: 304 [11264/54000 (21%)] Loss: -1760.956177\n",
      "Train Epoch: 304 [22528/54000 (42%)] Loss: -1757.744385\n",
      "Train Epoch: 304 [33792/54000 (63%)] Loss: -1761.134521\n",
      "Train Epoch: 304 [45056/54000 (83%)] Loss: -1761.273438\n",
      "    epoch          : 304\n",
      "    loss           : -1760.3226548680718\n",
      "    ess            : 26.58321411204788\n",
      "    log_marginal   : 1760.6472283129422\n",
      "    val_loss       : -1758.0157165527344\n",
      "    val_ess        : 26.639314651489258\n",
      "    val_log_marginal: 1758.3321736653645\n",
      "Train Epoch: 305 [0/54000 (0%)] Loss: -1759.805176\n",
      "Train Epoch: 305 [11264/54000 (21%)] Loss: -1766.619873\n",
      "Train Epoch: 305 [22528/54000 (42%)] Loss: -1759.875977\n",
      "Train Epoch: 305 [33792/54000 (63%)] Loss: -1758.449585\n",
      "Train Epoch: 305 [45056/54000 (83%)] Loss: -1766.173096\n",
      "    epoch          : 305\n",
      "    loss           : -1760.674866874263\n",
      "    ess            : 26.569210448355044\n",
      "    log_marginal   : 1760.9971232864093\n",
      "    val_loss       : -1754.4408874511719\n",
      "    val_ess        : 26.471004327138264\n",
      "    val_log_marginal: 1754.7650451660156\n",
      "Train Epoch: 306 [0/54000 (0%)] Loss: -1754.063721\n",
      "Train Epoch: 306 [11264/54000 (21%)] Loss: -1732.546143\n",
      "Train Epoch: 306 [22528/54000 (42%)] Loss: -1742.862793\n",
      "Train Epoch: 306 [33792/54000 (63%)] Loss: -1751.199463\n",
      "Train Epoch: 306 [45056/54000 (83%)] Loss: -1741.702881\n",
      "    epoch          : 306\n",
      "    loss           : -1740.9362263229657\n",
      "    ess            : 26.522418705922252\n",
      "    log_marginal   : 1741.2530056935436\n",
      "    val_loss       : -1740.8014322916667\n",
      "    val_ess        : 26.62361415227254\n",
      "    val_log_marginal: 1741.1112772623699\n",
      "Train Epoch: 307 [0/54000 (0%)] Loss: -1752.038330\n",
      "Train Epoch: 307 [11264/54000 (21%)] Loss: -1750.590576\n",
      "Train Epoch: 307 [22528/54000 (42%)] Loss: -1754.363525\n",
      "Train Epoch: 307 [33792/54000 (63%)] Loss: -1754.326660\n",
      "Train Epoch: 307 [45056/54000 (83%)] Loss: -1750.979248\n",
      "    epoch          : 307\n",
      "    loss           : -1753.3894342386498\n",
      "    ess            : 27.253658942456514\n",
      "    log_marginal   : 1753.6671891122494\n",
      "    val_loss       : -1751.615458170573\n",
      "    val_ess        : 27.20264546076457\n",
      "    val_log_marginal: 1751.8975830078125\n",
      "Train Epoch: 308 [0/54000 (0%)] Loss: -1761.513916\n",
      "Train Epoch: 308 [11264/54000 (21%)] Loss: -1766.951172\n",
      "Train Epoch: 308 [22528/54000 (42%)] Loss: -1757.347290\n",
      "Train Epoch: 308 [33792/54000 (63%)] Loss: -1757.842773\n",
      "Train Epoch: 308 [45056/54000 (83%)] Loss: -1763.236816\n",
      "    epoch          : 308\n",
      "    loss           : -1758.3106274874706\n",
      "    ess            : 26.762430892800385\n",
      "    log_marginal   : 1758.6178059128094\n",
      "    val_loss       : -1756.2351379394531\n",
      "    val_ess        : 26.987519423166912\n",
      "    val_log_marginal: 1756.537129720052\n",
      "Train Epoch: 309 [0/54000 (0%)] Loss: -1758.410645\n",
      "Train Epoch: 309 [11264/54000 (21%)] Loss: -1757.780762\n",
      "Train Epoch: 309 [22528/54000 (42%)] Loss: -1760.686035\n",
      "Train Epoch: 309 [33792/54000 (63%)] Loss: -1759.498901\n",
      "Train Epoch: 309 [45056/54000 (83%)] Loss: -1759.935547\n",
      "    epoch          : 309\n",
      "    loss           : -1760.2509454691185\n",
      "    ess            : 26.496614132287366\n",
      "    log_marginal   : 1760.5782413122788\n",
      "    val_loss       : -1758.0761006673176\n",
      "    val_ess        : 26.766698678334553\n",
      "    val_log_marginal: 1758.38720703125\n",
      "Train Epoch: 310 [0/54000 (0%)] Loss: -1758.297607\n",
      "Train Epoch: 310 [11264/54000 (21%)] Loss: -1758.460571\n",
      "Train Epoch: 310 [22528/54000 (42%)] Loss: -1763.969360\n",
      "Train Epoch: 310 [33792/54000 (63%)] Loss: -1761.123047\n",
      "Train Epoch: 310 [45056/54000 (83%)] Loss: -1757.549316\n",
      "    epoch          : 310\n",
      "    loss           : -1761.6901694243809\n",
      "    ess            : 26.5450092171723\n",
      "    log_marginal   : 1762.015007738797\n",
      "    val_loss       : -1759.3185933430989\n",
      "    val_ess        : 26.720849355061848\n",
      "    val_log_marginal: 1759.6360575358074\n",
      "Train Epoch: 311 [0/54000 (0%)] Loss: -1764.444580\n",
      "Train Epoch: 311 [11264/54000 (21%)] Loss: -1762.950684\n",
      "Train Epoch: 311 [22528/54000 (42%)] Loss: -1762.668701\n",
      "Train Epoch: 311 [33792/54000 (63%)] Loss: -1761.886597\n",
      "Train Epoch: 311 [45056/54000 (83%)] Loss: -1766.950195\n",
      "    epoch          : 311\n",
      "    loss           : -1762.8112389906398\n",
      "    ess            : 26.60746802923814\n",
      "    log_marginal   : 1763.1327652841244\n",
      "    val_loss       : -1760.6293843587239\n",
      "    val_ess        : 26.49452781677246\n",
      "    val_log_marginal: 1760.9675191243489\n",
      "Train Epoch: 312 [0/54000 (0%)] Loss: -1766.429688\n",
      "Train Epoch: 312 [11264/54000 (21%)] Loss: -1764.389404\n",
      "Train Epoch: 312 [22528/54000 (42%)] Loss: -1764.194214\n",
      "Train Epoch: 312 [33792/54000 (63%)] Loss: -1763.773682\n",
      "Train Epoch: 312 [45056/54000 (83%)] Loss: -1757.676514\n",
      "    epoch          : 312\n",
      "    loss           : -1759.1418445515183\n",
      "    ess            : 26.624302666142302\n",
      "    log_marginal   : 1759.463999622273\n",
      "    val_loss       : -1733.1960347493489\n",
      "    val_ess        : 26.409602006276447\n",
      "    val_log_marginal: 1733.5156148274739\n",
      "Train Epoch: 313 [0/54000 (0%)] Loss: -1742.858276\n",
      "Train Epoch: 313 [11264/54000 (21%)] Loss: -1741.651367\n",
      "Train Epoch: 313 [22528/54000 (42%)] Loss: -1743.932007\n",
      "Train Epoch: 313 [33792/54000 (63%)] Loss: -1746.322754\n",
      "Train Epoch: 313 [45056/54000 (83%)] Loss: -1752.731079\n",
      "    epoch          : 313\n",
      "    loss           : -1743.1991450471698\n",
      "    ess            : 26.80043533613097\n",
      "    log_marginal   : 1743.498266831884\n",
      "    val_loss       : -1741.3350626627605\n",
      "    val_ess        : 27.559897899627686\n",
      "    val_log_marginal: 1741.599141438802\n",
      "Train Epoch: 314 [0/54000 (0%)] Loss: -1752.933594\n",
      "Train Epoch: 314 [11264/54000 (21%)] Loss: -1753.935059\n",
      "Train Epoch: 314 [22528/54000 (42%)] Loss: -1755.240967\n",
      "Train Epoch: 314 [33792/54000 (63%)] Loss: -1754.090332\n",
      "Train Epoch: 314 [45056/54000 (83%)] Loss: -1755.860352\n",
      "    epoch          : 314\n",
      "    loss           : -1755.0812711895637\n",
      "    ess            : 27.436720668144947\n",
      "    log_marginal   : 1755.3483852170548\n",
      "    val_loss       : -1752.631815592448\n",
      "    val_ess        : 27.27492904663086\n",
      "    val_log_marginal: 1752.9128926595051\n",
      "Train Epoch: 315 [0/54000 (0%)] Loss: -1761.926392\n",
      "Train Epoch: 315 [11264/54000 (21%)] Loss: -1762.631104\n",
      "Train Epoch: 315 [22528/54000 (42%)] Loss: -1763.259399\n",
      "Train Epoch: 315 [33792/54000 (63%)] Loss: -1757.794312\n",
      "Train Epoch: 315 [45056/54000 (83%)] Loss: -1761.884766\n",
      "    epoch          : 315\n",
      "    loss           : -1760.1151998267983\n",
      "    ess            : 26.90121616507476\n",
      "    log_marginal   : 1760.4153373286408\n",
      "    val_loss       : -1756.7190856933594\n",
      "    val_ess        : 26.82800753911336\n",
      "    val_log_marginal: 1757.0260416666667\n",
      "Train Epoch: 316 [0/54000 (0%)] Loss: -1765.546387\n",
      "Train Epoch: 316 [11264/54000 (21%)] Loss: -1764.193726\n",
      "Train Epoch: 316 [22528/54000 (42%)] Loss: -1765.162598\n",
      "Train Epoch: 316 [33792/54000 (63%)] Loss: -1760.803711\n",
      "Train Epoch: 316 [45056/54000 (83%)] Loss: -1761.842773\n",
      "    epoch          : 316\n",
      "    loss           : -1762.1195033811173\n",
      "    ess            : 26.781611190651947\n",
      "    log_marginal   : 1762.429869453862\n",
      "    val_loss       : -1758.5625406901042\n",
      "    val_ess        : 26.552857557932537\n",
      "    val_log_marginal: 1758.893086751302\n",
      "Train Epoch: 317 [0/54000 (0%)] Loss: -1761.645752\n",
      "Train Epoch: 317 [11264/54000 (21%)] Loss: -1757.314209\n",
      "Train Epoch: 317 [22528/54000 (42%)] Loss: -1761.301880\n",
      "Train Epoch: 317 [33792/54000 (63%)] Loss: -1762.315186\n",
      "Train Epoch: 317 [45056/54000 (83%)] Loss: -1760.929199\n",
      "    epoch          : 317\n",
      "    loss           : -1763.5126054871757\n",
      "    ess            : 26.657003258759122\n",
      "    log_marginal   : 1763.8359398032135\n",
      "    val_loss       : -1760.30029296875\n",
      "    val_ess        : 26.64545440673828\n",
      "    val_log_marginal: 1760.6259155273438\n",
      "Train Epoch: 318 [0/54000 (0%)] Loss: -1770.463379\n",
      "Train Epoch: 318 [11264/54000 (21%)] Loss: -1764.584961\n",
      "Train Epoch: 318 [22528/54000 (42%)] Loss: -1766.440063\n",
      "Train Epoch: 318 [33792/54000 (63%)] Loss: -1760.244995\n",
      "Train Epoch: 318 [45056/54000 (83%)] Loss: -1763.258667\n",
      "    epoch          : 318\n",
      "    loss           : -1764.3303199624115\n",
      "    ess            : 26.61354185500235\n",
      "    log_marginal   : 1764.6551720961086\n",
      "    val_loss       : -1760.3468627929688\n",
      "    val_ess        : 26.62118450800578\n",
      "    val_log_marginal: 1760.6746927897136\n",
      "Train Epoch: 319 [0/54000 (0%)] Loss: -1766.895508\n",
      "Train Epoch: 319 [11264/54000 (21%)] Loss: -1760.386108\n",
      "Train Epoch: 319 [22528/54000 (42%)] Loss: -1694.261963\n",
      "Train Epoch: 319 [33792/54000 (63%)] Loss: -1743.054932\n",
      "Train Epoch: 319 [45056/54000 (83%)] Loss: -1729.475342\n",
      "    epoch          : 319\n",
      "    loss           : -1732.9711614644752\n",
      "    ess            : 26.489574396385336\n",
      "    log_marginal   : 1733.2887619306457\n",
      "    val_loss       : -1735.2109069824219\n",
      "    val_ess        : 26.883265495300293\n",
      "    val_log_marginal: 1735.5098368326824\n",
      "Train Epoch: 320 [0/54000 (0%)] Loss: -1741.804932\n",
      "Train Epoch: 320 [11264/54000 (21%)] Loss: -1747.909912\n",
      "Train Epoch: 320 [22528/54000 (42%)] Loss: -1744.420654\n",
      "Train Epoch: 320 [33792/54000 (63%)] Loss: -1755.641357\n",
      "Train Epoch: 320 [45056/54000 (83%)] Loss: -1753.107422\n",
      "    epoch          : 320\n",
      "    loss           : -1747.5966278651974\n",
      "    ess            : 27.44841321909203\n",
      "    log_marginal   : 1747.8645480173939\n",
      "    val_loss       : -1748.6369120279949\n",
      "    val_ess        : 27.406746069590252\n",
      "    val_log_marginal: 1748.9142456054688\n",
      "Train Epoch: 321 [0/54000 (0%)] Loss: -1751.323242\n",
      "Train Epoch: 321 [11264/54000 (21%)] Loss: -1757.476318\n",
      "Train Epoch: 321 [22528/54000 (42%)] Loss: -1753.246826\n",
      "Train Epoch: 321 [33792/54000 (63%)] Loss: -1758.383301\n",
      "Train Epoch: 321 [45056/54000 (83%)] Loss: -1757.263550\n",
      "    epoch          : 321\n",
      "    loss           : -1756.208251953125\n",
      "    ess            : 27.019087233633364\n",
      "    log_marginal   : 1756.499532447671\n",
      "    val_loss       : -1755.7858378092449\n",
      "    val_ess        : 26.999150276184082\n",
      "    val_log_marginal: 1756.081298828125\n",
      "Train Epoch: 322 [0/54000 (0%)] Loss: -1757.806030\n",
      "Train Epoch: 322 [11264/54000 (21%)] Loss: -1760.306641\n",
      "Train Epoch: 322 [22528/54000 (42%)] Loss: -1763.986084\n",
      "Train Epoch: 322 [33792/54000 (63%)] Loss: -1757.687256\n",
      "Train Epoch: 322 [45056/54000 (83%)] Loss: -1755.488281\n",
      "    epoch          : 322\n",
      "    loss           : -1759.3409988115418\n",
      "    ess            : 26.62962803750668\n",
      "    log_marginal   : 1759.6583781692218\n",
      "    val_loss       : -1757.866923014323\n",
      "    val_ess        : 26.77028751373291\n",
      "    val_log_marginal: 1758.1706848144531\n",
      "Train Epoch: 323 [0/54000 (0%)] Loss: -1762.409180\n",
      "Train Epoch: 323 [11264/54000 (21%)] Loss: -1763.179932\n",
      "Train Epoch: 323 [22528/54000 (42%)] Loss: -1759.596924\n",
      "Train Epoch: 323 [33792/54000 (63%)] Loss: -1763.275391\n",
      "Train Epoch: 323 [45056/54000 (83%)] Loss: -1763.906982\n",
      "    epoch          : 323\n",
      "    loss           : -1761.1742173680718\n",
      "    ess            : 26.647754057398384\n",
      "    log_marginal   : 1761.4947187315743\n",
      "    val_loss       : -1759.4223327636719\n",
      "    val_ess        : 26.611855189005535\n",
      "    val_log_marginal: 1759.7510274251301\n",
      "Train Epoch: 324 [0/54000 (0%)] Loss: -1762.883667\n",
      "Train Epoch: 324 [11264/54000 (21%)] Loss: -1761.712402\n",
      "Train Epoch: 324 [22528/54000 (42%)] Loss: -1767.080200\n",
      "Train Epoch: 324 [33792/54000 (63%)] Loss: -1760.180908\n",
      "Train Epoch: 324 [45056/54000 (83%)] Loss: -1764.822021\n",
      "    epoch          : 324\n",
      "    loss           : -1762.5324315484966\n",
      "    ess            : 26.589149870962466\n",
      "    log_marginal   : 1762.8582360609523\n",
      "    val_loss       : -1760.7814636230469\n",
      "    val_ess        : 26.804654598236084\n",
      "    val_log_marginal: 1761.0913492838542\n",
      "Train Epoch: 325 [0/54000 (0%)] Loss: -1759.042969\n",
      "Train Epoch: 325 [11264/54000 (21%)] Loss: -1768.822632\n",
      "Train Epoch: 325 [22528/54000 (42%)] Loss: -1763.119995\n",
      "Train Epoch: 325 [33792/54000 (63%)] Loss: -1760.337646\n",
      "Train Epoch: 325 [45056/54000 (83%)] Loss: -1760.292114\n",
      "    epoch          : 325\n",
      "    loss           : -1758.7020136995136\n",
      "    ess            : 26.656211295217837\n",
      "    log_marginal   : 1759.0240559128094\n",
      "    val_loss       : -1680.6019490559895\n",
      "    val_ess        : 26.348140398661297\n",
      "    val_log_marginal: 1680.9308166503906\n",
      "Train Epoch: 326 [0/54000 (0%)] Loss: -1677.621582\n",
      "Train Epoch: 326 [11264/54000 (21%)] Loss: -1719.567383\n",
      "Train Epoch: 326 [22528/54000 (42%)] Loss: -1747.339111\n",
      "Train Epoch: 326 [33792/54000 (63%)] Loss: -1748.100830\n",
      "Train Epoch: 326 [45056/54000 (83%)] Loss: -1737.824341\n",
      "    epoch          : 326\n",
      "    loss           : -1729.2004279370578\n",
      "    ess            : 26.5950451616971\n",
      "    log_marginal   : 1729.5100949845223\n",
      "    val_loss       : -1717.6410725911458\n",
      "    val_ess        : 28.486005783081055\n",
      "    val_log_marginal: 1717.84423828125\n",
      "Train Epoch: 327 [0/54000 (0%)] Loss: -1736.617798\n",
      "Train Epoch: 327 [11264/54000 (21%)] Loss: -1754.753418\n",
      "Train Epoch: 327 [22528/54000 (42%)] Loss: -1749.503418\n",
      "Train Epoch: 327 [33792/54000 (63%)] Loss: -1754.973145\n",
      "Train Epoch: 327 [45056/54000 (83%)] Loss: -1751.573730\n",
      "    epoch          : 327\n",
      "    loss           : -1747.5908560123084\n",
      "    ess            : 27.543271514604676\n",
      "    log_marginal   : 1747.8494907595077\n",
      "    val_loss       : -1737.5537007649739\n",
      "    val_ess        : 27.61506923039754\n",
      "    val_log_marginal: 1737.8179117838542\n",
      "Train Epoch: 328 [0/54000 (0%)] Loss: -1750.067383\n",
      "Train Epoch: 328 [11264/54000 (21%)] Loss: -1756.889282\n",
      "Train Epoch: 328 [22528/54000 (42%)] Loss: -1755.682373\n",
      "Train Epoch: 328 [33792/54000 (63%)] Loss: -1761.273804\n",
      "Train Epoch: 328 [45056/54000 (83%)] Loss: -1756.832275\n",
      "    epoch          : 328\n",
      "    loss           : -1753.9086764353626\n",
      "    ess            : 26.852796212682183\n",
      "    log_marginal   : 1754.2085525224793\n",
      "    val_loss       : -1745.5531717936199\n",
      "    val_ess        : 27.14423354466756\n",
      "    val_log_marginal: 1745.8414611816406\n",
      "Train Epoch: 329 [0/54000 (0%)] Loss: -1757.648682\n",
      "Train Epoch: 329 [11264/54000 (21%)] Loss: -1750.864746\n",
      "Train Epoch: 329 [22528/54000 (42%)] Loss: -1759.535034\n",
      "Train Epoch: 329 [33792/54000 (63%)] Loss: -1763.171997\n",
      "Train Epoch: 329 [45056/54000 (83%)] Loss: -1760.311768\n",
      "    epoch          : 329\n",
      "    loss           : -1757.1781696823407\n",
      "    ess            : 26.611813995073426\n",
      "    log_marginal   : 1757.4963367390183\n",
      "    val_loss       : -1749.500244140625\n",
      "    val_ess        : 26.92417621612549\n",
      "    val_log_marginal: 1749.8099873860676\n",
      "Train Epoch: 330 [0/54000 (0%)] Loss: -1752.817871\n",
      "Train Epoch: 330 [11264/54000 (21%)] Loss: -1754.760254\n",
      "Train Epoch: 330 [22528/54000 (42%)] Loss: -1758.097656\n",
      "Train Epoch: 330 [33792/54000 (63%)] Loss: -1756.140625\n",
      "Train Epoch: 330 [45056/54000 (83%)] Loss: -1760.785645\n",
      "    epoch          : 330\n",
      "    loss           : -1758.8223001732017\n",
      "    ess            : 26.596405137260007\n",
      "    log_marginal   : 1759.1453442843456\n",
      "    val_loss       : -1751.4675699869792\n",
      "    val_ess        : 26.80256223678589\n",
      "    val_log_marginal: 1751.7889912923176\n",
      "Train Epoch: 331 [0/54000 (0%)] Loss: -1755.314697\n",
      "Train Epoch: 331 [11264/54000 (21%)] Loss: -1729.439941\n",
      "Train Epoch: 331 [22528/54000 (42%)] Loss: -1722.980713\n",
      "Train Epoch: 331 [33792/54000 (63%)] Loss: -1737.464355\n",
      "Train Epoch: 331 [45056/54000 (83%)] Loss: -1755.666382\n",
      "    epoch          : 331\n",
      "    loss           : -1738.2440312223614\n",
      "    ess            : 26.51752533102935\n",
      "    log_marginal   : 1738.5627982661408\n",
      "    val_loss       : -1750.676249186198\n",
      "    val_ess        : 26.900122960408527\n",
      "    val_log_marginal: 1750.9872538248699\n",
      "Train Epoch: 332 [0/54000 (0%)] Loss: -1734.771973\n",
      "Train Epoch: 332 [11264/54000 (21%)] Loss: -1744.710693\n",
      "Train Epoch: 332 [22528/54000 (42%)] Loss: -1747.527832\n",
      "Train Epoch: 332 [33792/54000 (63%)] Loss: -1745.368652\n",
      "Train Epoch: 332 [45056/54000 (83%)] Loss: -1749.345459\n",
      "    epoch          : 332\n",
      "    loss           : -1747.553380426371\n",
      "    ess            : 27.17863782846703\n",
      "    log_marginal   : 1747.8330112673202\n",
      "    val_loss       : -1751.0537414550781\n",
      "    val_ess        : 26.56554667154948\n",
      "    val_log_marginal: 1751.3682657877605\n",
      "Train Epoch: 333 [0/54000 (0%)] Loss: -1750.753418\n",
      "Train Epoch: 333 [11264/54000 (21%)] Loss: -1760.722778\n",
      "Train Epoch: 333 [22528/54000 (42%)] Loss: -1755.522461\n",
      "Train Epoch: 333 [33792/54000 (63%)] Loss: -1752.372314\n",
      "Train Epoch: 333 [45056/54000 (83%)] Loss: -1755.040039\n",
      "    epoch          : 333\n",
      "    loss           : -1754.4418231316333\n",
      "    ess            : 26.868237477428508\n",
      "    log_marginal   : 1754.745291080115\n",
      "    val_loss       : -1754.2078857421875\n",
      "    val_ess        : 26.570407231648762\n",
      "    val_log_marginal: 1754.511454264323\n",
      "Train Epoch: 334 [0/54000 (0%)] Loss: -1754.277222\n",
      "Train Epoch: 334 [11264/54000 (21%)] Loss: -1756.808594\n",
      "Train Epoch: 334 [22528/54000 (42%)] Loss: -1758.628174\n",
      "Train Epoch: 334 [33792/54000 (63%)] Loss: -1755.995117\n",
      "Train Epoch: 334 [45056/54000 (83%)] Loss: -1760.191162\n",
      "    epoch          : 334\n",
      "    loss           : -1756.9864789854805\n",
      "    ess            : 26.62874630262267\n",
      "    log_marginal   : 1757.3050755914653\n",
      "    val_loss       : -1755.8565165201824\n",
      "    val_ess        : 26.715452194213867\n",
      "    val_log_marginal: 1756.1754760742188\n",
      "Train Epoch: 335 [0/54000 (0%)] Loss: -1760.007568\n",
      "Train Epoch: 335 [11264/54000 (21%)] Loss: -1754.560059\n",
      "Train Epoch: 335 [22528/54000 (42%)] Loss: -1752.859497\n",
      "Train Epoch: 335 [33792/54000 (63%)] Loss: -1761.029541\n",
      "Train Epoch: 335 [45056/54000 (83%)] Loss: -1755.796387\n",
      "    epoch          : 335\n",
      "    loss           : -1758.5770920087707\n",
      "    ess            : 26.652308320099454\n",
      "    log_marginal   : 1758.8968183409493\n",
      "    val_loss       : -1756.6219685872395\n",
      "    val_ess        : 26.472293853759766\n",
      "    val_log_marginal: 1756.951924641927\n",
      "Train Epoch: 336 [0/54000 (0%)] Loss: -1757.728027\n",
      "Train Epoch: 336 [11264/54000 (21%)] Loss: -1757.892334\n",
      "Train Epoch: 336 [22528/54000 (42%)] Loss: -1762.074707\n",
      "Train Epoch: 336 [33792/54000 (63%)] Loss: -1757.648682\n",
      "Train Epoch: 336 [45056/54000 (83%)] Loss: -1754.308105\n",
      "    epoch          : 336\n",
      "    loss           : -1759.7714590396522\n",
      "    ess            : 26.60527250901708\n",
      "    log_marginal   : 1760.0967741192512\n",
      "    val_loss       : -1757.4594828287761\n",
      "    val_ess        : 26.58635886510213\n",
      "    val_log_marginal: 1757.7877298990886\n",
      "Train Epoch: 337 [0/54000 (0%)] Loss: -1762.115479\n",
      "Train Epoch: 337 [11264/54000 (21%)] Loss: -1764.330566\n",
      "Train Epoch: 337 [22528/54000 (42%)] Loss: -1751.810791\n",
      "Train Epoch: 337 [33792/54000 (63%)] Loss: -1737.471069\n",
      "Train Epoch: 337 [45056/54000 (83%)] Loss: -1715.455566\n",
      "    epoch          : 337\n",
      "    loss           : -1744.1504908147847\n",
      "    ess            : 26.44281317153067\n",
      "    log_marginal   : 1744.4741613999852\n",
      "    val_loss       : -1736.9999287923176\n",
      "    val_ess        : 26.432032585144043\n",
      "    val_log_marginal: 1737.3213297526042\n",
      "Train Epoch: 338 [0/54000 (0%)] Loss: -1739.266602\n",
      "Train Epoch: 338 [11264/54000 (21%)] Loss: -1745.594482\n",
      "Train Epoch: 338 [22528/54000 (42%)] Loss: -1749.335449\n",
      "Train Epoch: 338 [33792/54000 (63%)] Loss: -1718.935059\n",
      "Train Epoch: 338 [45056/54000 (83%)] Loss: -1708.609863\n",
      "    epoch          : 338\n",
      "    loss           : -1727.828207915684\n",
      "    ess            : 27.030696005191444\n",
      "    log_marginal   : 1728.1107373507518\n",
      "    val_loss       : -1706.210428873698\n",
      "    val_ess        : 27.13343620300293\n",
      "    val_log_marginal: 1706.4734191894531\n",
      "Train Epoch: 339 [0/54000 (0%)] Loss: -1711.463867\n",
      "Train Epoch: 339 [11264/54000 (21%)] Loss: -1712.860596\n",
      "Train Epoch: 339 [22528/54000 (42%)] Loss: -1715.877930\n",
      "Train Epoch: 339 [33792/54000 (63%)] Loss: -1718.432861\n",
      "Train Epoch: 339 [45056/54000 (83%)] Loss: -1698.520020\n",
      "    epoch          : 339\n",
      "    loss           : -1711.14690240824\n",
      "    ess            : 27.26228235352714\n",
      "    log_marginal   : 1711.4054657558224\n",
      "    val_loss       : -1717.0615132649739\n",
      "    val_ess        : 27.395469188690186\n",
      "    val_log_marginal: 1717.3129984537761\n",
      "Train Epoch: 340 [0/54000 (0%)] Loss: -1724.561523\n",
      "Train Epoch: 340 [11264/54000 (21%)] Loss: -1728.753296\n",
      "Train Epoch: 340 [22528/54000 (42%)] Loss: -1730.193115\n",
      "Train Epoch: 340 [33792/54000 (63%)] Loss: -1730.687134\n",
      "Train Epoch: 340 [45056/54000 (83%)] Loss: -1730.395874\n",
      "    epoch          : 340\n",
      "    loss           : -1732.5666400261646\n",
      "    ess            : 27.475990439360995\n",
      "    log_marginal   : 1732.8185240547612\n",
      "    val_loss       : -1734.4047241210938\n",
      "    val_ess        : 27.343366463979084\n",
      "    val_log_marginal: 1734.6819763183594\n",
      "Train Epoch: 341 [0/54000 (0%)] Loss: -1739.845947\n",
      "Train Epoch: 341 [11264/54000 (21%)] Loss: -1746.940308\n",
      "Train Epoch: 341 [22528/54000 (42%)] Loss: -1735.018066\n",
      "Train Epoch: 341 [33792/54000 (63%)] Loss: -1742.491577\n",
      "Train Epoch: 341 [45056/54000 (83%)] Loss: -1736.417480\n",
      "    epoch          : 341\n",
      "    loss           : -1741.078790628685\n",
      "    ess            : 26.811439604129433\n",
      "    log_marginal   : 1741.3694734393425\n",
      "    val_loss       : -1741.662577311198\n",
      "    val_ess        : 26.674354394276936\n",
      "    val_log_marginal: 1741.9643249511719\n",
      "Train Epoch: 342 [0/54000 (0%)] Loss: -1746.631592\n",
      "Train Epoch: 342 [11264/54000 (21%)] Loss: -1748.209106\n",
      "Train Epoch: 342 [22528/54000 (42%)] Loss: -1745.069580\n",
      "Train Epoch: 342 [33792/54000 (63%)] Loss: -1742.374146\n",
      "Train Epoch: 342 [45056/54000 (83%)] Loss: -1745.442993\n",
      "    epoch          : 342\n",
      "    loss           : -1744.9885760613208\n",
      "    ess            : 26.571324780302227\n",
      "    log_marginal   : 1745.2962853773586\n",
      "    val_loss       : -1744.8331298828125\n",
      "    val_ess        : 26.462477842966717\n",
      "    val_log_marginal: 1745.1436360677083\n",
      "Train Epoch: 343 [0/54000 (0%)] Loss: -1747.033447\n",
      "Train Epoch: 343 [11264/54000 (21%)] Loss: -1750.283813\n",
      "Train Epoch: 343 [22528/54000 (42%)] Loss: -1746.979736\n",
      "Train Epoch: 343 [33792/54000 (63%)] Loss: -1747.614746\n",
      "Train Epoch: 343 [45056/54000 (83%)] Loss: -1746.616211\n",
      "    epoch          : 343\n",
      "    loss           : -1747.3390744767098\n",
      "    ess            : 26.46001097841083\n",
      "    log_marginal   : 1747.6543602133697\n",
      "    val_loss       : -1747.0631510416667\n",
      "    val_ess        : 26.403728008270264\n",
      "    val_log_marginal: 1747.3858337402344\n",
      "Train Epoch: 344 [0/54000 (0%)] Loss: -1750.423340\n",
      "Train Epoch: 344 [11264/54000 (21%)] Loss: -1747.064941\n",
      "Train Epoch: 344 [22528/54000 (42%)] Loss: -1751.003662\n",
      "Train Epoch: 344 [33792/54000 (63%)] Loss: -1747.985840\n",
      "Train Epoch: 344 [45056/54000 (83%)] Loss: -1747.407471\n",
      "    epoch          : 344\n",
      "    loss           : -1749.2186152620136\n",
      "    ess            : 26.420569401866985\n",
      "    log_marginal   : 1749.5407058427918\n",
      "    val_loss       : -1748.6617736816406\n",
      "    val_ess        : 26.458741029103596\n",
      "    val_log_marginal: 1748.984354654948\n",
      "Train Epoch: 345 [0/54000 (0%)] Loss: -1749.075439\n",
      "Train Epoch: 345 [11264/54000 (21%)] Loss: -1754.472534\n",
      "Train Epoch: 345 [22528/54000 (42%)] Loss: -1750.117554\n",
      "Train Epoch: 345 [33792/54000 (63%)] Loss: -1749.750244\n",
      "Train Epoch: 345 [45056/54000 (83%)] Loss: -1757.006348\n",
      "    epoch          : 345\n",
      "    loss           : -1750.7318529812794\n",
      "    ess            : 26.39800732090788\n",
      "    log_marginal   : 1751.0540322357754\n",
      "    val_loss       : -1749.845703125\n",
      "    val_ess        : 26.593520005544026\n",
      "    val_log_marginal: 1750.1500040690105\n",
      "Train Epoch: 346 [0/54000 (0%)] Loss: -1752.202393\n",
      "Train Epoch: 346 [11264/54000 (21%)] Loss: -1752.989502\n",
      "Train Epoch: 346 [22528/54000 (42%)] Loss: -1749.125977\n",
      "Train Epoch: 346 [33792/54000 (63%)] Loss: -1751.712158\n",
      "Train Epoch: 346 [45056/54000 (83%)] Loss: -1744.347900\n",
      "    epoch          : 346\n",
      "    loss           : -1749.3720058225235\n",
      "    ess            : 26.426625521677845\n",
      "    log_marginal   : 1749.6932200305866\n",
      "    val_loss       : -1723.2279154459636\n",
      "    val_ess        : 26.364700158437092\n",
      "    val_log_marginal: 1723.5440877278645\n",
      "Train Epoch: 347 [0/54000 (0%)] Loss: -1732.500732\n",
      "Train Epoch: 347 [11264/54000 (21%)] Loss: -1694.979736\n",
      "Train Epoch: 347 [22528/54000 (42%)] Loss: -1724.646484\n",
      "Train Epoch: 347 [33792/54000 (63%)] Loss: -1722.717529\n",
      "Train Epoch: 347 [45056/54000 (83%)] Loss: -1713.329346\n",
      "    epoch          : 347\n",
      "    loss           : -1714.7312034750885\n",
      "    ess            : 26.54120384072358\n",
      "    log_marginal   : 1715.0331040868218\n",
      "    val_loss       : -1719.1929626464844\n",
      "    val_ess        : 27.37814458211263\n",
      "    val_log_marginal: 1719.458028157552\n",
      "Train Epoch: 348 [0/54000 (0%)] Loss: -1725.851318\n",
      "Train Epoch: 348 [11264/54000 (21%)] Loss: -1729.102417\n",
      "Train Epoch: 348 [22528/54000 (42%)] Loss: -1733.408203\n",
      "Train Epoch: 348 [33792/54000 (63%)] Loss: -1731.516968\n",
      "Train Epoch: 348 [45056/54000 (83%)] Loss: -1738.953857\n",
      "    epoch          : 348\n",
      "    loss           : -1734.5645510115714\n",
      "    ess            : 27.623598062767172\n",
      "    log_marginal   : 1734.809690079599\n",
      "    val_loss       : -1734.7479248046875\n",
      "    val_ess        : 27.62127224604289\n",
      "    val_log_marginal: 1734.9915974934895\n",
      "Train Epoch: 349 [0/54000 (0%)] Loss: -1747.156616\n",
      "Train Epoch: 349 [11264/54000 (21%)] Loss: -1744.162598\n",
      "Train Epoch: 349 [22528/54000 (42%)] Loss: -1742.582275\n",
      "Train Epoch: 349 [33792/54000 (63%)] Loss: -1743.750488\n",
      "Train Epoch: 349 [45056/54000 (83%)] Loss: -1744.212280\n",
      "    epoch          : 349\n",
      "    loss           : -1743.394452940743\n",
      "    ess            : 26.86381543357417\n",
      "    log_marginal   : 1743.6847326890477\n",
      "    val_loss       : -1742.4917704264324\n",
      "    val_ess        : 26.960709889729817\n",
      "    val_log_marginal: 1742.7817077636719\n",
      "Train Epoch: 350 [0/54000 (0%)] Loss: -1745.553223\n",
      "Train Epoch: 350 [11264/54000 (21%)] Loss: -1745.117920\n",
      "Train Epoch: 350 [22528/54000 (42%)] Loss: -1749.455078\n",
      "Train Epoch: 350 [33792/54000 (63%)] Loss: -1744.994019\n",
      "Train Epoch: 350 [45056/54000 (83%)] Loss: -1746.078125\n",
      "    epoch          : 350\n",
      "    loss           : -1746.8884680406102\n",
      "    ess            : 26.48449843784548\n",
      "    log_marginal   : 1747.2065107237618\n",
      "    val_loss       : -1745.3209940592449\n",
      "    val_ess        : 26.49000295003255\n",
      "    val_log_marginal: 1745.6357421875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch350.pth ...\n",
      "Train Epoch: 351 [0/54000 (0%)] Loss: -1751.002075\n",
      "Train Epoch: 351 [11264/54000 (21%)] Loss: -1747.942139\n",
      "Train Epoch: 351 [22528/54000 (42%)] Loss: -1746.313477\n",
      "Train Epoch: 351 [33792/54000 (63%)] Loss: -1747.085449\n",
      "Train Epoch: 351 [45056/54000 (83%)] Loss: -1743.076416\n",
      "    epoch          : 351\n",
      "    loss           : -1748.8609619140625\n",
      "    ess            : 26.422886776474286\n",
      "    log_marginal   : 1749.1813158719044\n",
      "    val_loss       : -1747.224873860677\n",
      "    val_ess        : 26.348530610402424\n",
      "    val_log_marginal: 1747.561014811198\n",
      "Train Epoch: 352 [0/54000 (0%)] Loss: -1755.051025\n",
      "Train Epoch: 352 [11264/54000 (21%)] Loss: -1747.715088\n",
      "Train Epoch: 352 [22528/54000 (42%)] Loss: -1755.247192\n",
      "Train Epoch: 352 [33792/54000 (63%)] Loss: -1744.509277\n",
      "Train Epoch: 352 [45056/54000 (83%)] Loss: -1746.672363\n",
      "    epoch          : 352\n",
      "    loss           : -1750.207784400796\n",
      "    ess            : 26.434679139335202\n",
      "    log_marginal   : 1750.528704949145\n",
      "    val_loss       : -1748.2672932942708\n",
      "    val_ess        : 26.278390884399414\n",
      "    val_log_marginal: 1748.6053873697917\n",
      "Train Epoch: 353 [0/54000 (0%)] Loss: -1752.689087\n",
      "Train Epoch: 353 [11264/54000 (21%)] Loss: -1756.826660\n",
      "Train Epoch: 353 [22528/54000 (42%)] Loss: -1752.904053\n",
      "Train Epoch: 353 [33792/54000 (63%)] Loss: -1748.019043\n",
      "Train Epoch: 353 [45056/54000 (83%)] Loss: -1747.850342\n",
      "    epoch          : 353\n",
      "    loss           : -1751.1634014777417\n",
      "    ess            : 26.495512458513367\n",
      "    log_marginal   : 1751.4829573721256\n",
      "    val_loss       : -1748.8321940104167\n",
      "    val_ess        : 26.5500594774882\n",
      "    val_log_marginal: 1749.1468302408855\n",
      "Train Epoch: 354 [0/54000 (0%)] Loss: -1751.890137\n",
      "Train Epoch: 354 [11264/54000 (21%)] Loss: -1748.832031\n",
      "Train Epoch: 354 [22528/54000 (42%)] Loss: -1748.361328\n",
      "Train Epoch: 354 [33792/54000 (63%)] Loss: -1746.103394\n",
      "Train Epoch: 354 [45056/54000 (83%)] Loss: -1744.038574\n",
      "    epoch          : 354\n",
      "    loss           : -1748.154959048865\n",
      "    ess            : 26.49220605166453\n",
      "    log_marginal   : 1748.470955326872\n",
      "    val_loss       : -1742.7733764648438\n",
      "    val_ess        : 26.38984759648641\n",
      "    val_log_marginal: 1743.1041158040364\n",
      "Train Epoch: 355 [0/54000 (0%)] Loss: -1746.135986\n",
      "Train Epoch: 355 [11264/54000 (21%)] Loss: -1749.988159\n",
      "Train Epoch: 355 [22528/54000 (42%)] Loss: -1750.072266\n",
      "Train Epoch: 355 [33792/54000 (63%)] Loss: -1748.864258\n",
      "Train Epoch: 355 [45056/54000 (83%)] Loss: -1748.649414\n",
      "    epoch          : 355\n",
      "    loss           : -1750.082577111586\n",
      "    ess            : 26.688805382206755\n",
      "    log_marginal   : 1750.3917466649468\n",
      "    val_loss       : -1748.2723185221355\n",
      "    val_ess        : 26.82193597157796\n",
      "    val_log_marginal: 1748.5693359375\n",
      "Train Epoch: 356 [0/54000 (0%)] Loss: -1753.568726\n",
      "Train Epoch: 356 [11264/54000 (21%)] Loss: -1747.399780\n",
      "Train Epoch: 356 [22528/54000 (42%)] Loss: -1758.308228\n",
      "Train Epoch: 356 [33792/54000 (63%)] Loss: -1756.476807\n",
      "Train Epoch: 356 [45056/54000 (83%)] Loss: -1752.553467\n",
      "    epoch          : 356\n",
      "    loss           : -1752.6862954193691\n",
      "    ess            : 26.54290148896991\n",
      "    log_marginal   : 1753.0019980376621\n",
      "    val_loss       : -1751.1216634114583\n",
      "    val_ess        : 26.628266016642254\n",
      "    val_log_marginal: 1751.4361165364583\n",
      "Train Epoch: 357 [0/54000 (0%)] Loss: -1754.352905\n",
      "Train Epoch: 357 [11264/54000 (21%)] Loss: -1754.638306\n",
      "Train Epoch: 357 [22528/54000 (42%)] Loss: -1751.867310\n",
      "Train Epoch: 357 [33792/54000 (63%)] Loss: -1753.192383\n",
      "Train Epoch: 357 [45056/54000 (83%)] Loss: -1755.247559\n",
      "    epoch          : 357\n",
      "    loss           : -1754.3579827074734\n",
      "    ess            : 26.566625289197237\n",
      "    log_marginal   : 1754.6771459039653\n",
      "    val_loss       : -1752.3016866048176\n",
      "    val_ess        : 26.682127316792805\n",
      "    val_log_marginal: 1752.6169942220051\n",
      "Train Epoch: 358 [0/54000 (0%)] Loss: -1754.677246\n",
      "Train Epoch: 358 [11264/54000 (21%)] Loss: -1754.502197\n",
      "Train Epoch: 358 [22528/54000 (42%)] Loss: -1758.396973\n",
      "Train Epoch: 358 [33792/54000 (63%)] Loss: -1751.071045\n",
      "Train Epoch: 358 [45056/54000 (83%)] Loss: -1748.676636\n",
      "    epoch          : 358\n",
      "    loss           : -1755.6157549012382\n",
      "    ess            : 26.519760689645445\n",
      "    log_marginal   : 1755.937512667674\n",
      "    val_loss       : -1754.0132853190105\n",
      "    val_ess        : 26.540903568267822\n",
      "    val_log_marginal: 1754.3253987630208\n",
      "Train Epoch: 359 [0/54000 (0%)] Loss: -1759.085938\n",
      "Train Epoch: 359 [11264/54000 (21%)] Loss: -1762.161133\n",
      "Train Epoch: 359 [22528/54000 (42%)] Loss: -1754.074951\n",
      "Train Epoch: 359 [33792/54000 (63%)] Loss: -1755.676636\n",
      "Train Epoch: 359 [45056/54000 (83%)] Loss: -1756.702393\n",
      "    epoch          : 359\n",
      "    loss           : -1755.369016251474\n",
      "    ess            : 26.52907639629436\n",
      "    log_marginal   : 1755.6923263837707\n",
      "    val_loss       : -1745.3161010742188\n",
      "    val_ess        : 26.28900369008382\n",
      "    val_log_marginal: 1745.6473795572917\n",
      "Train Epoch: 360 [0/54000 (0%)] Loss: -1752.468628\n",
      "Train Epoch: 360 [11264/54000 (21%)] Loss: -1728.450928\n",
      "Train Epoch: 360 [22528/54000 (42%)] Loss: -1737.395752\n",
      "Train Epoch: 360 [33792/54000 (63%)] Loss: -1712.798340\n",
      "Train Epoch: 360 [45056/54000 (83%)] Loss: -1735.648804\n",
      "    epoch          : 360\n",
      "    loss           : -1731.3229945920548\n",
      "    ess            : 26.481400687739534\n",
      "    log_marginal   : 1731.6371436928803\n",
      "    val_loss       : -1739.1321105957031\n",
      "    val_ess        : 26.967281341552734\n",
      "    val_log_marginal: 1739.4265645345051\n",
      "Train Epoch: 361 [0/54000 (0%)] Loss: -1726.609619\n",
      "Train Epoch: 361 [11264/54000 (21%)] Loss: -1744.479370\n",
      "Train Epoch: 361 [22528/54000 (42%)] Loss: -1737.909302\n",
      "Train Epoch: 361 [33792/54000 (63%)] Loss: -1740.470703\n",
      "Train Epoch: 361 [45056/54000 (83%)] Loss: -1726.172485\n",
      "    epoch          : 361\n",
      "    loss           : -1736.2802227668042\n",
      "    ess            : 27.33323996921755\n",
      "    log_marginal   : 1736.5501386534493\n",
      "    val_loss       : -1721.8480936686199\n",
      "    val_ess        : 26.771188418070476\n",
      "    val_log_marginal: 1722.1303304036458\n",
      "Train Epoch: 362 [0/54000 (0%)] Loss: -1731.359253\n",
      "Train Epoch: 362 [11264/54000 (21%)] Loss: -1716.719116\n",
      "Train Epoch: 362 [22528/54000 (42%)] Loss: -1712.757324\n",
      "Train Epoch: 362 [33792/54000 (63%)] Loss: -1717.524170\n",
      "Train Epoch: 362 [45056/54000 (83%)] Loss: -1712.207397\n",
      "    epoch          : 362\n",
      "    loss           : -1713.569704451651\n",
      "    ess            : 26.936204208517974\n",
      "    log_marginal   : 1713.8453991008255\n",
      "    val_loss       : -1725.7471415201824\n",
      "    val_ess        : 27.384459972381592\n",
      "    val_log_marginal: 1726.0048828125\n",
      "Train Epoch: 363 [0/54000 (0%)] Loss: -1727.260376\n",
      "Train Epoch: 363 [11264/54000 (21%)] Loss: -1734.228271\n",
      "Train Epoch: 363 [22528/54000 (42%)] Loss: -1735.041626\n",
      "Train Epoch: 363 [33792/54000 (63%)] Loss: -1733.173828\n",
      "Train Epoch: 363 [45056/54000 (83%)] Loss: -1729.177856\n",
      "    epoch          : 363\n",
      "    loss           : -1732.4515288730838\n",
      "    ess            : 27.55140299167273\n",
      "    log_marginal   : 1732.6976594744988\n",
      "    val_loss       : -1737.3922220865886\n",
      "    val_ess        : 26.837679227193195\n",
      "    val_log_marginal: 1737.676493326823\n",
      "Train Epoch: 364 [0/54000 (0%)] Loss: -1743.272217\n",
      "Train Epoch: 364 [11264/54000 (21%)] Loss: -1742.476807\n",
      "Train Epoch: 364 [22528/54000 (42%)] Loss: -1737.843018\n",
      "Train Epoch: 364 [33792/54000 (63%)] Loss: -1737.177856\n",
      "Train Epoch: 364 [45056/54000 (83%)] Loss: -1742.139282\n",
      "    epoch          : 364\n",
      "    loss           : -1740.213958164431\n",
      "    ess            : 26.734262934270895\n",
      "    log_marginal   : 1740.5042022129276\n",
      "    val_loss       : -1743.1244303385417\n",
      "    val_ess        : 26.687193552652996\n",
      "    val_log_marginal: 1743.4168904622395\n",
      "Train Epoch: 365 [0/54000 (0%)] Loss: -1745.230103\n",
      "Train Epoch: 365 [11264/54000 (21%)] Loss: -1744.586426\n",
      "Train Epoch: 365 [22528/54000 (42%)] Loss: -1742.147095\n",
      "Train Epoch: 365 [33792/54000 (63%)] Loss: -1747.977905\n",
      "Train Epoch: 365 [45056/54000 (83%)] Loss: -1741.677856\n",
      "    epoch          : 365\n",
      "    loss           : -1743.7325232163914\n",
      "    ess            : 26.431749181927376\n",
      "    log_marginal   : 1744.0495467275944\n",
      "    val_loss       : -1745.5105489095051\n",
      "    val_ess        : 26.441415786743164\n",
      "    val_log_marginal: 1745.8133138020833\n",
      "Train Epoch: 366 [0/54000 (0%)] Loss: -1746.694946\n",
      "Train Epoch: 366 [11264/54000 (21%)] Loss: -1745.457153\n",
      "Train Epoch: 366 [22528/54000 (42%)] Loss: -1747.761475\n",
      "Train Epoch: 366 [33792/54000 (63%)] Loss: -1748.138428\n",
      "Train Epoch: 366 [45056/54000 (83%)] Loss: -1743.941650\n",
      "    epoch          : 366\n",
      "    loss           : -1745.8743078843602\n",
      "    ess            : 26.453015651343005\n",
      "    log_marginal   : 1746.190760198629\n",
      "    val_loss       : -1747.1964213053386\n",
      "    val_ess        : 26.408676147460938\n",
      "    val_log_marginal: 1747.5159505208333\n",
      "Train Epoch: 367 [0/54000 (0%)] Loss: -1744.534424\n",
      "Train Epoch: 367 [11264/54000 (21%)] Loss: -1747.630859\n",
      "Train Epoch: 367 [22528/54000 (42%)] Loss: -1743.958252\n",
      "Train Epoch: 367 [33792/54000 (63%)] Loss: -1679.103760\n",
      "Train Epoch: 367 [45056/54000 (83%)] Loss: -1700.676880\n",
      "    epoch          : 367\n",
      "    loss           : -1726.874826107385\n",
      "    ess            : 26.43358504097417\n",
      "    log_marginal   : 1727.181420668116\n",
      "    val_loss       : -1720.97998046875\n",
      "    val_ess        : 26.508984247843426\n",
      "    val_log_marginal: 1721.3049621582031\n",
      "Train Epoch: 368 [0/54000 (0%)] Loss: -1724.683838\n",
      "Train Epoch: 368 [11264/54000 (21%)] Loss: -1723.539795\n",
      "Train Epoch: 368 [22528/54000 (42%)] Loss: -1717.214722\n",
      "Train Epoch: 368 [33792/54000 (63%)] Loss: -1723.914307\n",
      "Train Epoch: 368 [45056/54000 (83%)] Loss: -1717.563721\n",
      "    epoch          : 368\n",
      "    loss           : -1717.9781286851414\n",
      "    ess            : 26.880651869863833\n",
      "    log_marginal   : 1718.2589122844192\n",
      "    val_loss       : -1733.4383951822917\n",
      "    val_ess        : 27.159069220225017\n",
      "    val_log_marginal: 1733.7043863932292\n",
      "Train Epoch: 369 [0/54000 (0%)] Loss: -1733.293213\n",
      "Train Epoch: 369 [11264/54000 (21%)] Loss: -1738.810303\n",
      "Train Epoch: 369 [22528/54000 (42%)] Loss: -1728.896362\n",
      "Train Epoch: 369 [33792/54000 (63%)] Loss: -1737.409180\n",
      "Train Epoch: 369 [45056/54000 (83%)] Loss: -1734.505371\n",
      "    epoch          : 369\n",
      "    loss           : -1734.0863705041274\n",
      "    ess            : 27.21063124458745\n",
      "    log_marginal   : 1734.3512872659935\n",
      "    val_loss       : -1739.8191630045574\n",
      "    val_ess        : 26.539345264434814\n",
      "    val_log_marginal: 1740.1138509114583\n",
      "Train Epoch: 370 [0/54000 (0%)] Loss: -1738.208984\n",
      "Train Epoch: 370 [11264/54000 (21%)] Loss: -1739.813965\n",
      "Train Epoch: 370 [22528/54000 (42%)] Loss: -1738.221924\n",
      "Train Epoch: 370 [33792/54000 (63%)] Loss: -1741.839600\n",
      "Train Epoch: 370 [45056/54000 (83%)] Loss: -1740.903076\n",
      "    epoch          : 370\n",
      "    loss           : -1740.0081407079156\n",
      "    ess            : 26.58889973838374\n",
      "    log_marginal   : 1740.3064701872052\n",
      "    val_loss       : -1743.3767903645833\n",
      "    val_ess        : 26.620272636413574\n",
      "    val_log_marginal: 1743.6616516113281\n",
      "Train Epoch: 371 [0/54000 (0%)] Loss: -1738.779297\n",
      "Train Epoch: 371 [11264/54000 (21%)] Loss: -1740.995728\n",
      "Train Epoch: 371 [22528/54000 (42%)] Loss: -1741.896484\n",
      "Train Epoch: 371 [33792/54000 (63%)] Loss: -1738.652100\n",
      "Train Epoch: 371 [45056/54000 (83%)] Loss: -1745.873901\n",
      "    epoch          : 371\n",
      "    loss           : -1742.674726378243\n",
      "    ess            : 26.378588550495653\n",
      "    log_marginal   : 1742.9878470942658\n",
      "    val_loss       : -1745.2502034505208\n",
      "    val_ess        : 26.351343631744385\n",
      "    val_log_marginal: 1745.5686136881511\n",
      "Train Epoch: 372 [0/54000 (0%)] Loss: -1743.099609\n",
      "Train Epoch: 372 [11264/54000 (21%)] Loss: -1747.183228\n",
      "Train Epoch: 372 [22528/54000 (42%)] Loss: -1740.229248\n",
      "Train Epoch: 372 [33792/54000 (63%)] Loss: -1749.436768\n",
      "Train Epoch: 372 [45056/54000 (83%)] Loss: -1750.110352\n",
      "    epoch          : 372\n",
      "    loss           : -1744.5497436523438\n",
      "    ess            : 26.371861889677227\n",
      "    log_marginal   : 1744.8647196067955\n",
      "    val_loss       : -1746.3902282714844\n",
      "    val_ess        : 26.077587445576984\n",
      "    val_log_marginal: 1746.7343241373699\n",
      "Train Epoch: 373 [0/54000 (0%)] Loss: -1746.231689\n",
      "Train Epoch: 373 [11264/54000 (21%)] Loss: -1745.842163\n",
      "Train Epoch: 373 [22528/54000 (42%)] Loss: -1747.487183\n",
      "Train Epoch: 373 [33792/54000 (63%)] Loss: -1747.943970\n",
      "Train Epoch: 373 [45056/54000 (83%)] Loss: -1750.680908\n",
      "    epoch          : 373\n",
      "    loss           : -1746.0611572265625\n",
      "    ess            : 26.331666982398843\n",
      "    log_marginal   : 1746.3823714346256\n",
      "    val_loss       : -1747.2358500162761\n",
      "    val_ess        : 26.27338171005249\n",
      "    val_log_marginal: 1747.5597839355469\n",
      "Train Epoch: 374 [0/54000 (0%)] Loss: -1753.654053\n",
      "Train Epoch: 374 [11264/54000 (21%)] Loss: -1748.244507\n",
      "Train Epoch: 374 [22528/54000 (42%)] Loss: -1748.690063\n",
      "Train Epoch: 374 [33792/54000 (63%)] Loss: -1750.715698\n",
      "Train Epoch: 374 [45056/54000 (83%)] Loss: -1743.414307\n",
      "    epoch          : 374\n",
      "    loss           : -1747.338924767836\n",
      "    ess            : 26.362385497902924\n",
      "    log_marginal   : 1747.6565540241745\n",
      "    val_loss       : -1748.3732198079426\n",
      "    val_ess        : 26.32527764638265\n",
      "    val_log_marginal: 1748.6935323079426\n",
      "Train Epoch: 375 [0/54000 (0%)] Loss: -1750.333740\n",
      "Train Epoch: 375 [11264/54000 (21%)] Loss: -1741.639038\n",
      "Train Epoch: 375 [22528/54000 (42%)] Loss: -1750.646973\n",
      "Train Epoch: 375 [33792/54000 (63%)] Loss: -1743.267090\n",
      "Train Epoch: 375 [45056/54000 (83%)] Loss: -1744.722900\n",
      "    epoch          : 375\n",
      "    loss           : -1747.4256349959464\n",
      "    ess            : 26.446233479481823\n",
      "    log_marginal   : 1747.7433805645637\n",
      "    val_loss       : -1740.8199666341145\n",
      "    val_ess        : 26.2271466255188\n",
      "    val_log_marginal: 1741.1517842610676\n",
      "Train Epoch: 376 [0/54000 (0%)] Loss: -1739.905762\n",
      "Train Epoch: 376 [11264/54000 (21%)] Loss: -1709.472900\n",
      "Train Epoch: 376 [22528/54000 (42%)] Loss: -1729.393799\n",
      "Train Epoch: 376 [33792/54000 (63%)] Loss: -1700.765869\n",
      "Train Epoch: 376 [45056/54000 (83%)] Loss: -1712.433594\n",
      "    epoch          : 376\n",
      "    loss           : -1717.9136790149616\n",
      "    ess            : 26.43831364613659\n",
      "    log_marginal   : 1718.2206605155513\n",
      "    val_loss       : -1724.6228942871094\n",
      "    val_ess        : 26.802998224894207\n",
      "    val_log_marginal: 1724.898905436198\n",
      "Train Epoch: 377 [0/54000 (0%)] Loss: -1721.857910\n",
      "Train Epoch: 377 [11264/54000 (21%)] Loss: -1728.167603\n",
      "Train Epoch: 377 [22528/54000 (42%)] Loss: -1728.933105\n",
      "Train Epoch: 377 [33792/54000 (63%)] Loss: -1729.786133\n",
      "Train Epoch: 377 [45056/54000 (83%)] Loss: -1728.672852\n",
      "    epoch          : 377\n",
      "    loss           : -1728.4844406415832\n",
      "    ess            : 27.332746937589825\n",
      "    log_marginal   : 1728.7405418539947\n",
      "    val_loss       : -1736.6874694824219\n",
      "    val_ess        : 27.232715765635174\n",
      "    val_log_marginal: 1736.9494934082031\n",
      "Train Epoch: 378 [0/54000 (0%)] Loss: -1738.962158\n",
      "Train Epoch: 378 [11264/54000 (21%)] Loss: -1744.271973\n",
      "Train Epoch: 378 [22528/54000 (42%)] Loss: -1737.965088\n",
      "Train Epoch: 378 [33792/54000 (63%)] Loss: -1738.386841\n",
      "Train Epoch: 378 [45056/54000 (83%)] Loss: -1744.921875\n",
      "    epoch          : 378\n",
      "    loss           : -1739.205309597951\n",
      "    ess            : 26.85193693412925\n",
      "    log_marginal   : 1739.4861288970371\n",
      "    val_loss       : -1743.4734802246094\n",
      "    val_ess        : 26.69280433654785\n",
      "    val_log_marginal: 1743.7588399251301\n",
      "Train Epoch: 379 [0/54000 (0%)] Loss: -1742.480713\n",
      "Train Epoch: 379 [11264/54000 (21%)] Loss: -1741.270752\n",
      "Train Epoch: 379 [22528/54000 (42%)] Loss: -1744.213501\n",
      "Train Epoch: 379 [33792/54000 (63%)] Loss: -1742.744751\n",
      "Train Epoch: 379 [45056/54000 (83%)] Loss: -1743.427490\n",
      "    epoch          : 379\n",
      "    loss           : -1743.1813769070607\n",
      "    ess            : 26.4695432770927\n",
      "    log_marginal   : 1743.489576807562\n",
      "    val_loss       : -1746.0508219401042\n",
      "    val_ess        : 26.514959971110027\n",
      "    val_log_marginal: 1746.3558451334636\n",
      "Train Epoch: 380 [0/54000 (0%)] Loss: -1738.340332\n",
      "Train Epoch: 380 [11264/54000 (21%)] Loss: -1746.503662\n",
      "Train Epoch: 380 [22528/54000 (42%)] Loss: -1740.121094\n",
      "Train Epoch: 380 [33792/54000 (63%)] Loss: -1743.593994\n",
      "Train Epoch: 380 [45056/54000 (83%)] Loss: -1746.990234\n",
      "    epoch          : 380\n",
      "    loss           : -1745.2378920069282\n",
      "    ess            : 26.400415708433908\n",
      "    log_marginal   : 1745.5559519641804\n",
      "    val_loss       : -1747.1483662923176\n",
      "    val_ess        : 26.638507843017578\n",
      "    val_log_marginal: 1747.4433695475261\n",
      "Train Epoch: 381 [0/54000 (0%)] Loss: -1747.852051\n",
      "Train Epoch: 381 [11264/54000 (21%)] Loss: -1743.779785\n",
      "Train Epoch: 381 [22528/54000 (42%)] Loss: -1745.073486\n",
      "Train Epoch: 381 [33792/54000 (63%)] Loss: -1745.687256\n",
      "Train Epoch: 381 [45056/54000 (83%)] Loss: -1744.198730\n",
      "    epoch          : 381\n",
      "    loss           : -1746.7673973227447\n",
      "    ess            : 26.479448714346255\n",
      "    log_marginal   : 1747.0823283645343\n",
      "    val_loss       : -1748.5176289876301\n",
      "    val_ess        : 26.560411135355633\n",
      "    val_log_marginal: 1748.8191833496094\n",
      "Train Epoch: 382 [0/54000 (0%)] Loss: -1751.743408\n",
      "Train Epoch: 382 [11264/54000 (21%)] Loss: -1748.830078\n",
      "Train Epoch: 382 [22528/54000 (42%)] Loss: -1746.802124\n",
      "Train Epoch: 382 [33792/54000 (63%)] Loss: -1744.659180\n",
      "Train Epoch: 382 [45056/54000 (83%)] Loss: -1746.237305\n",
      "    epoch          : 382\n",
      "    loss           : -1747.9894996499115\n",
      "    ess            : 26.339218283599276\n",
      "    log_marginal   : 1748.3106631872788\n",
      "    val_loss       : -1749.0043436686199\n",
      "    val_ess        : 26.268781185150146\n",
      "    val_log_marginal: 1749.3402811686199\n",
      "Train Epoch: 383 [0/54000 (0%)] Loss: -1747.593506\n",
      "Train Epoch: 383 [11264/54000 (21%)] Loss: -1749.531982\n",
      "Train Epoch: 383 [22528/54000 (42%)] Loss: -1745.578125\n",
      "Train Epoch: 383 [33792/54000 (63%)] Loss: -1721.985352\n",
      "Train Epoch: 383 [45056/54000 (83%)] Loss: -1719.313232\n",
      "    epoch          : 383\n",
      "    loss           : -1735.565554061026\n",
      "    ess            : 26.350977231871408\n",
      "    log_marginal   : 1735.8860957307636\n",
      "    val_loss       : -1723.2498881022136\n",
      "    val_ess        : 26.404688199361164\n",
      "    val_log_marginal: 1723.5528259277344\n",
      "Train Epoch: 384 [0/54000 (0%)] Loss: -1732.950806\n",
      "Train Epoch: 384 [11264/54000 (21%)] Loss: -1731.645508\n",
      "Train Epoch: 384 [22528/54000 (42%)] Loss: -1722.195068\n",
      "Train Epoch: 384 [33792/54000 (63%)] Loss: -1711.319702\n",
      "Train Epoch: 384 [45056/54000 (83%)] Loss: -1720.120483\n",
      "    epoch          : 384\n",
      "    loss           : -1722.4550746701798\n",
      "    ess            : 26.843886411414957\n",
      "    log_marginal   : 1722.7433690484966\n",
      "    val_loss       : -1732.8914082845051\n",
      "    val_ess        : 27.420692284901936\n",
      "    val_log_marginal: 1733.1476440429688\n",
      "Train Epoch: 385 [0/54000 (0%)] Loss: -1734.697876\n",
      "Train Epoch: 385 [11264/54000 (21%)] Loss: -1739.572021\n",
      "Train Epoch: 385 [22528/54000 (42%)] Loss: -1741.731323\n",
      "Train Epoch: 385 [33792/54000 (63%)] Loss: -1740.302002\n",
      "Train Epoch: 385 [45056/54000 (83%)] Loss: -1740.238770\n",
      "    epoch          : 385\n",
      "    loss           : -1736.9820049933667\n",
      "    ess            : 27.227575122185474\n",
      "    log_marginal   : 1737.2440715285968\n",
      "    val_loss       : -1741.1203206380208\n",
      "    val_ess        : 26.671416759490967\n",
      "    val_log_marginal: 1741.4132588704426\n",
      "Train Epoch: 386 [0/54000 (0%)] Loss: -1745.898926\n",
      "Train Epoch: 386 [11264/54000 (21%)] Loss: -1740.149170\n",
      "Train Epoch: 386 [22528/54000 (42%)] Loss: -1740.950439\n",
      "Train Epoch: 386 [33792/54000 (63%)] Loss: -1745.795898\n",
      "Train Epoch: 386 [45056/54000 (83%)] Loss: -1748.678711\n",
      "    epoch          : 386\n",
      "    loss           : -1742.9999274487766\n",
      "    ess            : 26.62460769797271\n",
      "    log_marginal   : 1743.3000522829452\n",
      "    val_loss       : -1744.977803548177\n",
      "    val_ess        : 26.458370367685955\n",
      "    val_log_marginal: 1745.2869771321614\n",
      "Train Epoch: 387 [0/54000 (0%)] Loss: -1749.120239\n",
      "Train Epoch: 387 [11264/54000 (21%)] Loss: -1743.750244\n",
      "Train Epoch: 387 [22528/54000 (42%)] Loss: -1749.791016\n",
      "Train Epoch: 387 [33792/54000 (63%)] Loss: -1745.772461\n",
      "Train Epoch: 387 [45056/54000 (83%)] Loss: -1741.232056\n",
      "    epoch          : 387\n",
      "    loss           : -1745.6054756596404\n",
      "    ess            : 26.443339707716454\n",
      "    log_marginal   : 1745.9198861751916\n",
      "    val_loss       : -1746.8213806152344\n",
      "    val_ess        : 26.351017951965332\n",
      "    val_log_marginal: 1747.1456298828125\n",
      "Train Epoch: 388 [0/54000 (0%)] Loss: -1748.791016\n",
      "Train Epoch: 388 [11264/54000 (21%)] Loss: -1747.072266\n",
      "Train Epoch: 388 [22528/54000 (42%)] Loss: -1751.468750\n",
      "Train Epoch: 388 [33792/54000 (63%)] Loss: -1750.473511\n",
      "Train Epoch: 388 [45056/54000 (83%)] Loss: -1745.176636\n",
      "    epoch          : 388\n",
      "    loss           : -1747.238359559257\n",
      "    ess            : 26.49443378088609\n",
      "    log_marginal   : 1747.5495950950767\n",
      "    val_loss       : -1748.3529764811199\n",
      "    val_ess        : 26.088666915893555\n",
      "    val_log_marginal: 1748.6891276041667\n",
      "Train Epoch: 389 [0/54000 (0%)] Loss: -1745.659668\n",
      "Train Epoch: 389 [11264/54000 (21%)] Loss: -1745.755127\n",
      "Train Epoch: 389 [22528/54000 (42%)] Loss: -1750.945312\n",
      "Train Epoch: 389 [33792/54000 (63%)] Loss: -1741.550537\n",
      "Train Epoch: 389 [45056/54000 (83%)] Loss: -1749.927979\n",
      "    epoch          : 389\n",
      "    loss           : -1748.5854607348172\n",
      "    ess            : 26.328107905837726\n",
      "    log_marginal   : 1748.9080476580925\n",
      "    val_loss       : -1749.5925801595051\n",
      "    val_ess        : 26.67467721303304\n",
      "    val_log_marginal: 1749.8850504557292\n",
      "Train Epoch: 390 [0/54000 (0%)] Loss: -1756.233032\n",
      "Train Epoch: 390 [11264/54000 (21%)] Loss: -1751.717407\n",
      "Train Epoch: 390 [22528/54000 (42%)] Loss: -1749.874390\n",
      "Train Epoch: 390 [33792/54000 (63%)] Loss: -1751.855347\n",
      "Train Epoch: 390 [45056/54000 (83%)] Loss: -1748.802490\n",
      "    epoch          : 390\n",
      "    loss           : -1747.28857421875\n",
      "    ess            : 26.365594504014503\n",
      "    log_marginal   : 1747.612958800118\n",
      "    val_loss       : -1716.9296264648438\n",
      "    val_ess        : 26.42344601949056\n",
      "    val_log_marginal: 1717.240254720052\n",
      "Train Epoch: 391 [0/54000 (0%)] Loss: -1730.016724\n",
      "Train Epoch: 391 [11264/54000 (21%)] Loss: -1694.010132\n",
      "Train Epoch: 391 [22528/54000 (42%)] Loss: -1716.713135\n",
      "Train Epoch: 391 [33792/54000 (63%)] Loss: -1724.829346\n",
      "Train Epoch: 391 [45056/54000 (83%)] Loss: -1732.482056\n",
      "    epoch          : 391\n",
      "    loss           : -1716.450878215286\n",
      "    ess            : 26.41604365942613\n",
      "    log_marginal   : 1716.7582017430718\n",
      "    val_loss       : -1729.1234741210938\n",
      "    val_ess        : 27.635504722595215\n",
      "    val_log_marginal: 1729.3745727539062\n",
      "Train Epoch: 392 [0/54000 (0%)] Loss: -1729.791260\n",
      "Train Epoch: 392 [11264/54000 (21%)] Loss: -1732.595459\n",
      "Train Epoch: 392 [22528/54000 (42%)] Loss: -1735.065308\n",
      "Train Epoch: 392 [33792/54000 (63%)] Loss: -1742.275146\n",
      "Train Epoch: 392 [45056/54000 (83%)] Loss: -1731.244385\n",
      "    epoch          : 392\n",
      "    loss           : -1734.620572072155\n",
      "    ess            : 27.383348806849067\n",
      "    log_marginal   : 1734.879100871536\n",
      "    val_loss       : -1740.2305704752605\n",
      "    val_ess        : 26.945618152618408\n",
      "    val_log_marginal: 1740.5067240397136\n",
      "Train Epoch: 393 [0/54000 (0%)] Loss: -1736.795166\n",
      "Train Epoch: 393 [11264/54000 (21%)] Loss: -1744.209717\n",
      "Train Epoch: 393 [22528/54000 (42%)] Loss: -1737.798706\n",
      "Train Epoch: 393 [33792/54000 (63%)] Loss: -1741.774536\n",
      "Train Epoch: 393 [45056/54000 (83%)] Loss: -1736.023804\n",
      "    epoch          : 393\n",
      "    loss           : -1741.4486855560879\n",
      "    ess            : 26.610778790599895\n",
      "    log_marginal   : 1741.7525795990566\n",
      "    val_loss       : -1744.0976460774739\n",
      "    val_ess        : 26.54154856999715\n",
      "    val_log_marginal: 1744.3980611165364\n",
      "Train Epoch: 394 [0/54000 (0%)] Loss: -1742.916626\n",
      "Train Epoch: 394 [11264/54000 (21%)] Loss: -1746.366211\n",
      "Train Epoch: 394 [22528/54000 (42%)] Loss: -1746.629883\n",
      "Train Epoch: 394 [33792/54000 (63%)] Loss: -1747.658325\n",
      "Train Epoch: 394 [45056/54000 (83%)] Loss: -1742.072510\n",
      "    epoch          : 394\n",
      "    loss           : -1744.232268711306\n",
      "    ess            : 26.41117759920516\n",
      "    log_marginal   : 1744.5495340599205\n",
      "    val_loss       : -1745.8699951171875\n",
      "    val_ess        : 26.74112145105998\n",
      "    val_log_marginal: 1746.1703694661458\n",
      "Train Epoch: 395 [0/54000 (0%)] Loss: -1742.957520\n",
      "Train Epoch: 395 [11264/54000 (21%)] Loss: -1745.567505\n",
      "Train Epoch: 395 [22528/54000 (42%)] Loss: -1743.454224\n",
      "Train Epoch: 395 [33792/54000 (63%)] Loss: -1748.492920\n",
      "Train Epoch: 395 [45056/54000 (83%)] Loss: -1742.075806\n",
      "    epoch          : 395\n",
      "    loss           : -1746.0723116892689\n",
      "    ess            : 26.483694814286142\n",
      "    log_marginal   : 1746.380781065743\n",
      "    val_loss       : -1747.2915344238281\n",
      "    val_ess        : 26.168883800506592\n",
      "    val_log_marginal: 1747.6327006022136\n",
      "Train Epoch: 396 [0/54000 (0%)] Loss: -1746.876221\n",
      "Train Epoch: 396 [11264/54000 (21%)] Loss: -1749.466309\n",
      "Train Epoch: 396 [22528/54000 (42%)] Loss: -1748.588257\n",
      "Train Epoch: 396 [33792/54000 (63%)] Loss: -1744.762207\n",
      "Train Epoch: 396 [45056/54000 (83%)] Loss: -1744.506104\n",
      "    epoch          : 396\n",
      "    loss           : -1747.4941463830337\n",
      "    ess            : 26.406196684207558\n",
      "    log_marginal   : 1747.8130654389004\n",
      "    val_loss       : -1748.3739013671875\n",
      "    val_ess        : 26.38058598836263\n",
      "    val_log_marginal: 1748.6970825195312\n",
      "Train Epoch: 397 [0/54000 (0%)] Loss: -1750.398926\n",
      "Train Epoch: 397 [11264/54000 (21%)] Loss: -1750.151001\n",
      "Train Epoch: 397 [22528/54000 (42%)] Loss: -1750.575928\n",
      "Train Epoch: 397 [33792/54000 (63%)] Loss: -1746.380737\n",
      "Train Epoch: 397 [45056/54000 (83%)] Loss: -1747.700928\n",
      "    epoch          : 397\n",
      "    loss           : -1745.0171036630306\n",
      "    ess            : 26.447055942607374\n",
      "    log_marginal   : 1745.3350012437352\n",
      "    val_loss       : -1712.8683980305989\n",
      "    val_ess        : 25.927184740702312\n",
      "    val_log_marginal: 1713.1948649088542\n",
      "Train Epoch: 398 [0/54000 (0%)] Loss: -1719.584229\n",
      "Train Epoch: 398 [11264/54000 (21%)] Loss: -1732.511475\n",
      "Train Epoch: 398 [22528/54000 (42%)] Loss: -1730.414795\n",
      "Train Epoch: 398 [33792/54000 (63%)] Loss: -1713.430298\n",
      "Train Epoch: 398 [45056/54000 (83%)] Loss: -1715.451416\n",
      "    epoch          : 398\n",
      "    loss           : -1722.0941703364533\n",
      "    ess            : 26.49894228521383\n",
      "    log_marginal   : 1722.4000301720962\n",
      "    val_loss       : -1702.8360493977864\n",
      "    val_ess        : 27.318614800771076\n",
      "    val_log_marginal: 1703.1031290690105\n",
      "Train Epoch: 399 [0/54000 (0%)] Loss: -1720.493164\n",
      "Train Epoch: 399 [11264/54000 (21%)] Loss: -1719.659546\n",
      "Train Epoch: 399 [22528/54000 (42%)] Loss: -1722.573242\n",
      "Train Epoch: 399 [33792/54000 (63%)] Loss: -1715.269043\n",
      "Train Epoch: 399 [45056/54000 (83%)] Loss: -1710.482056\n",
      "    epoch          : 399\n",
      "    loss           : -1713.7610715470223\n",
      "    ess            : 27.293452136921434\n",
      "    log_marginal   : 1714.0185765680278\n",
      "    val_loss       : -1699.1818135579426\n",
      "    val_ess        : 27.591504732767742\n",
      "    val_log_marginal: 1699.4217529296875\n",
      "Train Epoch: 400 [0/54000 (0%)] Loss: -1715.431641\n",
      "Train Epoch: 400 [11264/54000 (21%)] Loss: -1727.002686\n",
      "Train Epoch: 400 [22528/54000 (42%)] Loss: -1731.163086\n",
      "Train Epoch: 400 [33792/54000 (63%)] Loss: -1732.306152\n",
      "Train Epoch: 400 [45056/54000 (83%)] Loss: -1728.160034\n",
      "    epoch          : 400\n",
      "    loss           : -1728.3213316719487\n",
      "    ess            : 27.33101326564573\n",
      "    log_marginal   : 1728.568905236586\n",
      "    val_loss       : -1715.8278299967449\n",
      "    val_ess        : 27.65139373143514\n",
      "    val_log_marginal: 1716.0765889485676\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [0/54000 (0%)] Loss: -1739.705200\n",
      "Train Epoch: 401 [11264/54000 (21%)] Loss: -1739.903809\n",
      "Train Epoch: 401 [22528/54000 (42%)] Loss: -1737.175171\n",
      "Train Epoch: 401 [33792/54000 (63%)] Loss: -1728.937012\n",
      "Train Epoch: 401 [45056/54000 (83%)] Loss: -1732.265869\n",
      "    epoch          : 401\n",
      "    loss           : -1736.2840818009286\n",
      "    ess            : 26.674564793424786\n",
      "    log_marginal   : 1736.575522368809\n",
      "    val_loss       : -1728.502197265625\n",
      "    val_ess        : 26.99748134613037\n",
      "    val_log_marginal: 1728.7795817057292\n",
      "Train Epoch: 402 [0/54000 (0%)] Loss: -1742.126587\n",
      "Train Epoch: 402 [11264/54000 (21%)] Loss: -1736.325317\n",
      "Train Epoch: 402 [22528/54000 (42%)] Loss: -1738.126953\n",
      "Train Epoch: 402 [33792/54000 (63%)] Loss: -1736.732422\n",
      "Train Epoch: 402 [45056/54000 (83%)] Loss: -1741.983643\n",
      "    epoch          : 402\n",
      "    loss           : -1740.0554187702683\n",
      "    ess            : 26.494745632387556\n",
      "    log_marginal   : 1740.363455142615\n",
      "    val_loss       : -1733.146016438802\n",
      "    val_ess        : 26.34118143717448\n",
      "    val_log_marginal: 1733.471923828125\n",
      "Train Epoch: 403 [0/54000 (0%)] Loss: -1742.417114\n",
      "Train Epoch: 403 [11264/54000 (21%)] Loss: -1744.706787\n",
      "Train Epoch: 403 [22528/54000 (42%)] Loss: -1742.103760\n",
      "Train Epoch: 403 [33792/54000 (63%)] Loss: -1737.959473\n",
      "Train Epoch: 403 [45056/54000 (83%)] Loss: -1748.555908\n",
      "    epoch          : 403\n",
      "    loss           : -1742.257625939711\n",
      "    ess            : 26.35668612426182\n",
      "    log_marginal   : 1742.575278228184\n",
      "    val_loss       : -1735.9946797688801\n",
      "    val_ess        : 26.34073082605998\n",
      "    val_log_marginal: 1736.3145039876301\n",
      "Train Epoch: 404 [0/54000 (0%)] Loss: -1746.402466\n",
      "Train Epoch: 404 [11264/54000 (21%)] Loss: -1740.975098\n",
      "Train Epoch: 404 [22528/54000 (42%)] Loss: -1744.099121\n",
      "Train Epoch: 404 [33792/54000 (63%)] Loss: -1740.825439\n",
      "Train Epoch: 404 [45056/54000 (83%)] Loss: -1744.650391\n",
      "    epoch          : 404\n",
      "    loss           : -1743.7961828843602\n",
      "    ess            : 26.40851965490377\n",
      "    log_marginal   : 1744.108406498747\n",
      "    val_loss       : -1738.675069173177\n",
      "    val_ess        : 26.401896794637043\n",
      "    val_log_marginal: 1739.0084635416667\n",
      "Train Epoch: 405 [0/54000 (0%)] Loss: -1743.903198\n",
      "Train Epoch: 405 [11264/54000 (21%)] Loss: -1745.009521\n",
      "Train Epoch: 405 [22528/54000 (42%)] Loss: -1743.360352\n",
      "Train Epoch: 405 [33792/54000 (63%)] Loss: -1744.348389\n",
      "Train Epoch: 405 [45056/54000 (83%)] Loss: -1742.694580\n",
      "    epoch          : 405\n",
      "    loss           : -1745.1157088369694\n",
      "    ess            : 26.479528553081007\n",
      "    log_marginal   : 1745.4271516619988\n",
      "    val_loss       : -1740.2118225097656\n",
      "    val_ess        : 26.555899620056152\n",
      "    val_log_marginal: 1740.5267944335938\n",
      "Train Epoch: 406 [0/54000 (0%)] Loss: -1752.291016\n",
      "Train Epoch: 406 [11264/54000 (21%)] Loss: -1749.234619\n",
      "Train Epoch: 406 [22528/54000 (42%)] Loss: -1743.641113\n",
      "Train Epoch: 406 [33792/54000 (63%)] Loss: -1746.011841\n",
      "Train Epoch: 406 [45056/54000 (83%)] Loss: -1744.341187\n",
      "    epoch          : 406\n",
      "    loss           : -1746.1659027675412\n",
      "    ess            : 26.306769371032715\n",
      "    log_marginal   : 1746.489526136866\n",
      "    val_loss       : -1741.4224141438801\n",
      "    val_ess        : 26.626357078552246\n",
      "    val_log_marginal: 1741.7378641764324\n",
      "Train Epoch: 407 [0/54000 (0%)] Loss: -1744.828125\n",
      "Train Epoch: 407 [11264/54000 (21%)] Loss: -1742.050293\n",
      "Train Epoch: 407 [22528/54000 (42%)] Loss: -1734.830200\n",
      "Train Epoch: 407 [33792/54000 (63%)] Loss: -1704.819458\n",
      "Train Epoch: 407 [45056/54000 (83%)] Loss: -1722.882324\n",
      "    epoch          : 407\n",
      "    loss           : -1725.5635214751621\n",
      "    ess            : 26.390017275540334\n",
      "    log_marginal   : 1725.8742491524174\n",
      "    val_loss       : -1721.0253601074219\n",
      "    val_ess        : 26.441190878550213\n",
      "    val_log_marginal: 1721.3314107259114\n",
      "Train Epoch: 408 [0/54000 (0%)] Loss: -1722.945435\n",
      "Train Epoch: 408 [11264/54000 (21%)] Loss: -1733.177246\n",
      "Train Epoch: 408 [22528/54000 (42%)] Loss: -1733.607056\n",
      "Train Epoch: 408 [33792/54000 (63%)] Loss: -1733.210938\n",
      "Train Epoch: 408 [45056/54000 (83%)] Loss: -1731.974243\n",
      "    epoch          : 408\n",
      "    loss           : -1733.0600125294811\n",
      "    ess            : 27.123868960254597\n",
      "    log_marginal   : 1733.3286247973172\n",
      "    val_loss       : -1732.6581624348958\n",
      "    val_ess        : 27.108744621276855\n",
      "    val_log_marginal: 1732.9207255045574\n",
      "Train Epoch: 409 [0/54000 (0%)] Loss: -1740.945190\n",
      "Train Epoch: 409 [11264/54000 (21%)] Loss: -1743.699219\n",
      "Train Epoch: 409 [22528/54000 (42%)] Loss: -1741.550049\n",
      "Train Epoch: 409 [33792/54000 (63%)] Loss: -1739.798950\n",
      "Train Epoch: 409 [45056/54000 (83%)] Loss: -1741.892822\n",
      "    epoch          : 409\n",
      "    loss           : -1741.0634569851857\n",
      "    ess            : 26.744538127251392\n",
      "    log_marginal   : 1741.3575289744251\n",
      "    val_loss       : -1739.1812438964844\n",
      "    val_ess        : 26.564260959625244\n",
      "    val_log_marginal: 1739.4911499023438\n",
      "Train Epoch: 410 [0/54000 (0%)] Loss: -1746.016846\n",
      "Train Epoch: 410 [11264/54000 (21%)] Loss: -1745.150269\n",
      "Train Epoch: 410 [22528/54000 (42%)] Loss: -1744.260376\n",
      "Train Epoch: 410 [33792/54000 (63%)] Loss: -1742.048340\n",
      "Train Epoch: 410 [45056/54000 (83%)] Loss: -1741.744629\n",
      "    epoch          : 410\n",
      "    loss           : -1744.2420205170254\n",
      "    ess            : 26.464317033875663\n",
      "    log_marginal   : 1744.5533159363945\n",
      "    val_loss       : -1741.6094767252605\n",
      "    val_ess        : 26.506847858428955\n",
      "    val_log_marginal: 1741.9140319824219\n",
      "Train Epoch: 411 [0/54000 (0%)] Loss: -1746.177979\n",
      "Train Epoch: 411 [11264/54000 (21%)] Loss: -1749.508545\n",
      "Train Epoch: 411 [22528/54000 (42%)] Loss: -1748.990723\n",
      "Train Epoch: 411 [33792/54000 (63%)] Loss: -1746.003052\n",
      "Train Epoch: 411 [45056/54000 (83%)] Loss: -1744.829224\n",
      "    epoch          : 411\n",
      "    loss           : -1745.8836301407723\n",
      "    ess            : 26.435672184206403\n",
      "    log_marginal   : 1746.2027714567364\n",
      "    val_loss       : -1743.2395935058594\n",
      "    val_ess        : 26.40071217219035\n",
      "    val_log_marginal: 1743.5596008300781\n",
      "Train Epoch: 412 [0/54000 (0%)] Loss: -1745.480591\n",
      "Train Epoch: 412 [11264/54000 (21%)] Loss: -1752.617676\n",
      "Train Epoch: 412 [22528/54000 (42%)] Loss: -1743.842041\n",
      "Train Epoch: 412 [33792/54000 (63%)] Loss: -1743.423706\n",
      "Train Epoch: 412 [45056/54000 (83%)] Loss: -1745.521973\n",
      "    epoch          : 412\n",
      "    loss           : -1747.2801006964917\n",
      "    ess            : 26.43283007279882\n",
      "    log_marginal   : 1747.599087697155\n",
      "    val_loss       : -1744.7981058756511\n",
      "    val_ess        : 26.440799872080486\n",
      "    val_log_marginal: 1745.1152954101562\n",
      "Train Epoch: 413 [0/54000 (0%)] Loss: -1748.290527\n",
      "Train Epoch: 413 [11264/54000 (21%)] Loss: -1746.792847\n",
      "Train Epoch: 413 [22528/54000 (42%)] Loss: -1749.284790\n",
      "Train Epoch: 413 [33792/54000 (63%)] Loss: -1744.949951\n",
      "Train Epoch: 413 [45056/54000 (83%)] Loss: -1745.699463\n",
      "    epoch          : 413\n",
      "    loss           : -1748.136271926592\n",
      "    ess            : 26.443979587195056\n",
      "    log_marginal   : 1748.4547487654777\n",
      "    val_loss       : -1744.513671875\n",
      "    val_ess        : 26.468377272288006\n",
      "    val_log_marginal: 1744.822774251302\n",
      "Train Epoch: 414 [0/54000 (0%)] Loss: -1750.017334\n",
      "Train Epoch: 414 [11264/54000 (21%)] Loss: -1733.450928\n",
      "Train Epoch: 414 [22528/54000 (42%)] Loss: -1704.651855\n",
      "Train Epoch: 414 [33792/54000 (63%)] Loss: -1712.731079\n",
      "Train Epoch: 414 [45056/54000 (83%)] Loss: -1714.454102\n",
      "    epoch          : 414\n",
      "    loss           : -1719.3424314103036\n",
      "    ess            : 26.39051027118035\n",
      "    log_marginal   : 1719.6501142393868\n",
      "    val_loss       : -1718.3682149251301\n",
      "    val_ess        : 26.512932777404785\n",
      "    val_log_marginal: 1718.669921875\n",
      "Train Epoch: 415 [0/54000 (0%)] Loss: -1728.647949\n",
      "Train Epoch: 415 [11264/54000 (21%)] Loss: -1731.314209\n",
      "Train Epoch: 415 [22528/54000 (42%)] Loss: -1732.571411\n",
      "Train Epoch: 415 [33792/54000 (63%)] Loss: -1735.574707\n",
      "Train Epoch: 415 [45056/54000 (83%)] Loss: -1730.796631\n",
      "    epoch          : 415\n",
      "    loss           : -1731.7897073997642\n",
      "    ess            : 27.331740091431815\n",
      "    log_marginal   : 1732.0492450066333\n",
      "    val_loss       : -1731.6054280598958\n",
      "    val_ess        : 27.44994004567464\n",
      "    val_log_marginal: 1731.8565673828125\n",
      "Train Epoch: 416 [0/54000 (0%)] Loss: -1741.848633\n",
      "Train Epoch: 416 [11264/54000 (21%)] Loss: -1738.757202\n",
      "Train Epoch: 416 [22528/54000 (42%)] Loss: -1740.778198\n",
      "Train Epoch: 416 [33792/54000 (63%)] Loss: -1738.510376\n",
      "Train Epoch: 416 [45056/54000 (83%)] Loss: -1740.590820\n",
      "    epoch          : 416\n",
      "    loss           : -1739.7894701687794\n",
      "    ess            : 26.765141217213756\n",
      "    log_marginal   : 1740.0776528412441\n",
      "    val_loss       : -1738.7855936686199\n",
      "    val_ess        : 26.722972869873047\n",
      "    val_log_marginal: 1739.0771891276042\n",
      "Train Epoch: 417 [0/54000 (0%)] Loss: -1742.839600\n",
      "Train Epoch: 417 [11264/54000 (21%)] Loss: -1746.867676\n",
      "Train Epoch: 417 [22528/54000 (42%)] Loss: -1742.659424\n",
      "Train Epoch: 417 [33792/54000 (63%)] Loss: -1735.557861\n",
      "Train Epoch: 417 [45056/54000 (83%)] Loss: -1741.996948\n",
      "    epoch          : 417\n",
      "    loss           : -1742.9703207915684\n",
      "    ess            : 26.4994460231853\n",
      "    log_marginal   : 1743.278315706073\n",
      "    val_loss       : -1741.7452087402344\n",
      "    val_ess        : 26.288292407989502\n",
      "    val_log_marginal: 1742.0776062011719\n",
      "Train Epoch: 418 [0/54000 (0%)] Loss: -1745.221558\n",
      "Train Epoch: 418 [11264/54000 (21%)] Loss: -1743.962402\n",
      "Train Epoch: 418 [22528/54000 (42%)] Loss: -1745.635254\n",
      "Train Epoch: 418 [33792/54000 (63%)] Loss: -1743.777832\n",
      "Train Epoch: 418 [45056/54000 (83%)] Loss: -1748.265747\n",
      "    epoch          : 418\n",
      "    loss           : -1744.8553236475532\n",
      "    ess            : 26.471621675311393\n",
      "    log_marginal   : 1745.168572191922\n",
      "    val_loss       : -1743.4895731608074\n",
      "    val_ess        : 26.53567632039388\n",
      "    val_log_marginal: 1743.7922465006511\n",
      "Train Epoch: 419 [0/54000 (0%)] Loss: -1748.675537\n",
      "Train Epoch: 419 [11264/54000 (21%)] Loss: -1744.553223\n",
      "Train Epoch: 419 [22528/54000 (42%)] Loss: -1748.471313\n",
      "Train Epoch: 419 [33792/54000 (63%)] Loss: -1752.343140\n",
      "Train Epoch: 419 [45056/54000 (83%)] Loss: -1748.486084\n",
      "    epoch          : 419\n",
      "    loss           : -1746.2733211877212\n",
      "    ess            : 26.468980735203004\n",
      "    log_marginal   : 1746.5902928766216\n",
      "    val_loss       : -1744.893819173177\n",
      "    val_ess        : 26.385877927144367\n",
      "    val_log_marginal: 1745.2308247884114\n",
      "Train Epoch: 420 [0/54000 (0%)] Loss: -1748.668457\n",
      "Train Epoch: 420 [11264/54000 (21%)] Loss: -1748.676514\n",
      "Train Epoch: 420 [22528/54000 (42%)] Loss: -1749.391602\n",
      "Train Epoch: 420 [33792/54000 (63%)] Loss: -1748.009644\n",
      "Train Epoch: 420 [45056/54000 (83%)] Loss: -1746.870483\n",
      "    epoch          : 420\n",
      "    loss           : -1746.5762156360554\n",
      "    ess            : 26.442840000368513\n",
      "    log_marginal   : 1746.8929236070164\n",
      "    val_loss       : -1732.9081115722656\n",
      "    val_ess        : 26.5206241607666\n",
      "    val_log_marginal: 1733.2233174641926\n",
      "Train Epoch: 421 [0/54000 (0%)] Loss: -1736.193604\n",
      "Train Epoch: 421 [11264/54000 (21%)] Loss: -1700.303467\n",
      "Train Epoch: 421 [22528/54000 (42%)] Loss: -1729.259521\n",
      "Train Epoch: 421 [33792/54000 (63%)] Loss: -1723.285767\n",
      "Train Epoch: 421 [45056/54000 (83%)] Loss: -1715.880615\n",
      "    epoch          : 421\n",
      "    loss           : -1716.4188566387825\n",
      "    ess            : 26.474389562066996\n",
      "    log_marginal   : 1716.7202701208726\n",
      "    val_loss       : -1728.672607421875\n",
      "    val_ess        : 26.951913833618164\n",
      "    val_log_marginal: 1728.9560648600261\n",
      "Train Epoch: 422 [0/54000 (0%)] Loss: -1722.990723\n",
      "Train Epoch: 422 [11264/54000 (21%)] Loss: -1733.159180\n",
      "Train Epoch: 422 [22528/54000 (42%)] Loss: -1733.929321\n",
      "Train Epoch: 422 [33792/54000 (63%)] Loss: -1735.167480\n",
      "Train Epoch: 422 [45056/54000 (83%)] Loss: -1729.867188\n",
      "    epoch          : 422\n",
      "    loss           : -1732.4533910211528\n",
      "    ess            : 27.39547860847329\n",
      "    log_marginal   : 1732.7140664154629\n",
      "    val_loss       : -1735.6199951171875\n",
      "    val_ess        : 27.020102977752686\n",
      "    val_log_marginal: 1735.8882242838542\n",
      "Train Epoch: 423 [0/54000 (0%)] Loss: -1742.005981\n",
      "Train Epoch: 423 [11264/54000 (21%)] Loss: -1742.349609\n",
      "Train Epoch: 423 [22528/54000 (42%)] Loss: -1743.578857\n",
      "Train Epoch: 423 [33792/54000 (63%)] Loss: -1739.991943\n",
      "Train Epoch: 423 [45056/54000 (83%)] Loss: -1740.451904\n",
      "    epoch          : 423\n",
      "    loss           : -1739.7317124852593\n",
      "    ess            : 26.61900147851908\n",
      "    log_marginal   : 1740.0318350162147\n",
      "    val_loss       : -1740.6051635742188\n",
      "    val_ess        : 26.721421877543133\n",
      "    val_log_marginal: 1740.903299967448\n",
      "Train Epoch: 424 [0/54000 (0%)] Loss: -1739.747070\n",
      "Train Epoch: 424 [11264/54000 (21%)] Loss: -1739.082031\n",
      "Train Epoch: 424 [22528/54000 (42%)] Loss: -1740.268311\n",
      "Train Epoch: 424 [33792/54000 (63%)] Loss: -1744.656982\n",
      "Train Epoch: 424 [45056/54000 (83%)] Loss: -1743.919678\n",
      "    epoch          : 424\n",
      "    loss           : -1742.5600747162441\n",
      "    ess            : 26.42933868912031\n",
      "    log_marginal   : 1742.872633448187\n",
      "    val_loss       : -1742.7029927571614\n",
      "    val_ess        : 26.601553916931152\n",
      "    val_log_marginal: 1743.0149739583333\n",
      "Train Epoch: 425 [0/54000 (0%)] Loss: -1743.530029\n",
      "Train Epoch: 425 [11264/54000 (21%)] Loss: -1741.686646\n",
      "Train Epoch: 425 [22528/54000 (42%)] Loss: -1741.274292\n",
      "Train Epoch: 425 [33792/54000 (63%)] Loss: -1741.569092\n",
      "Train Epoch: 425 [45056/54000 (83%)] Loss: -1739.942993\n",
      "    epoch          : 425\n",
      "    loss           : -1744.2698283645343\n",
      "    ess            : 26.45854070051661\n",
      "    log_marginal   : 1744.5822489036705\n",
      "    val_loss       : -1743.9193420410156\n",
      "    val_ess        : 26.269529183705647\n",
      "    val_log_marginal: 1744.256368001302\n",
      "Train Epoch: 426 [0/54000 (0%)] Loss: -1743.193359\n",
      "Train Epoch: 426 [11264/54000 (21%)] Loss: -1749.520752\n",
      "Train Epoch: 426 [22528/54000 (42%)] Loss: -1743.627197\n",
      "Train Epoch: 426 [33792/54000 (63%)] Loss: -1745.397705\n",
      "Train Epoch: 426 [45056/54000 (83%)] Loss: -1746.631836\n",
      "    epoch          : 426\n",
      "    loss           : -1745.6766933225235\n",
      "    ess            : 26.469256976865374\n",
      "    log_marginal   : 1745.9883503464032\n",
      "    val_loss       : -1745.216776529948\n",
      "    val_ess        : 26.529198328653973\n",
      "    val_log_marginal: 1745.5355529785156\n",
      "Train Epoch: 427 [0/54000 (0%)] Loss: -1751.581787\n",
      "Train Epoch: 427 [11264/54000 (21%)] Loss: -1744.356201\n",
      "Train Epoch: 427 [22528/54000 (42%)] Loss: -1749.718750\n",
      "Train Epoch: 427 [33792/54000 (63%)] Loss: -1749.332520\n",
      "Train Epoch: 427 [45056/54000 (83%)] Loss: -1740.921997\n",
      "    epoch          : 427\n",
      "    loss           : -1746.630259387898\n",
      "    ess            : 26.474423894342387\n",
      "    log_marginal   : 1746.9392642614976\n",
      "    val_loss       : -1744.46826171875\n",
      "    val_ess        : 26.549949804941814\n",
      "    val_log_marginal: 1744.7899169921875\n",
      "Train Epoch: 428 [0/54000 (0%)] Loss: -1745.925537\n",
      "Train Epoch: 428 [11264/54000 (21%)] Loss: -1740.605225\n",
      "Train Epoch: 428 [22528/54000 (42%)] Loss: -1674.670898\n",
      "Train Epoch: 428 [33792/54000 (63%)] Loss: -1727.445679\n",
      "Train Epoch: 428 [45056/54000 (83%)] Loss: -1729.225586\n",
      "    epoch          : 428\n",
      "    loss           : -1720.9771947320903\n",
      "    ess            : 26.3312841451393\n",
      "    log_marginal   : 1721.2908636129127\n",
      "    val_loss       : -1688.8399658203125\n",
      "    val_ess        : 26.60642385482788\n",
      "    val_log_marginal: 1689.1353251139324\n",
      "Train Epoch: 429 [0/54000 (0%)] Loss: -1714.711914\n",
      "Train Epoch: 429 [11264/54000 (21%)] Loss: -1717.708496\n",
      "Train Epoch: 429 [22528/54000 (42%)] Loss: -1707.765381\n",
      "Train Epoch: 429 [33792/54000 (63%)] Loss: -1717.956787\n",
      "Train Epoch: 429 [45056/54000 (83%)] Loss: -1717.245850\n",
      "    epoch          : 429\n",
      "    loss           : -1715.3560710403156\n",
      "    ess            : 27.105159651558353\n",
      "    log_marginal   : 1715.6183402583283\n",
      "    val_loss       : -1711.2085673014324\n",
      "    val_ess        : 27.9710693359375\n",
      "    val_log_marginal: 1711.4220479329426\n",
      "Train Epoch: 430 [0/54000 (0%)] Loss: -1724.839233\n",
      "Train Epoch: 430 [11264/54000 (21%)] Loss: -1734.089844\n",
      "Train Epoch: 430 [22528/54000 (42%)] Loss: -1736.911133\n",
      "Train Epoch: 430 [33792/54000 (63%)] Loss: -1736.313599\n",
      "Train Epoch: 430 [45056/54000 (83%)] Loss: -1736.329590\n",
      "    epoch          : 430\n",
      "    loss           : -1731.4700064029334\n",
      "    ess            : 27.246497532106794\n",
      "    log_marginal   : 1731.7293747236145\n",
      "    val_loss       : -1725.8761494954426\n",
      "    val_ess        : 27.258209387461346\n",
      "    val_log_marginal: 1726.1331380208333\n",
      "Train Epoch: 431 [0/54000 (0%)] Loss: -1737.813599\n",
      "Train Epoch: 431 [11264/54000 (21%)] Loss: -1739.651367\n",
      "Train Epoch: 431 [22528/54000 (42%)] Loss: -1742.662720\n",
      "Train Epoch: 431 [33792/54000 (63%)] Loss: -1732.477051\n",
      "Train Epoch: 431 [45056/54000 (83%)] Loss: -1736.799316\n",
      "    epoch          : 431\n",
      "    loss           : -1737.6306612986439\n",
      "    ess            : 26.60739578391021\n",
      "    log_marginal   : 1737.9307711619251\n",
      "    val_loss       : -1732.7875162760417\n",
      "    val_ess        : 26.588820298512776\n",
      "    val_log_marginal: 1733.0822347005208\n",
      "Train Epoch: 432 [0/54000 (0%)] Loss: -1744.693481\n",
      "Train Epoch: 432 [11264/54000 (21%)] Loss: -1737.509888\n",
      "Train Epoch: 432 [22528/54000 (42%)] Loss: -1738.635010\n",
      "Train Epoch: 432 [33792/54000 (63%)] Loss: -1746.027588\n",
      "Train Epoch: 432 [45056/54000 (83%)] Loss: -1742.758545\n",
      "    epoch          : 432\n",
      "    loss           : -1740.431375755454\n",
      "    ess            : 26.392358492005545\n",
      "    log_marginal   : 1740.747276450103\n",
      "    val_loss       : -1736.0\n",
      "    val_ess        : 26.543628851572674\n",
      "    val_log_marginal: 1736.3085835774739\n",
      "Train Epoch: 433 [0/54000 (0%)] Loss: -1744.571777\n",
      "Train Epoch: 433 [11264/54000 (21%)] Loss: -1741.229492\n",
      "Train Epoch: 433 [22528/54000 (42%)] Loss: -1739.302368\n",
      "Train Epoch: 433 [33792/54000 (63%)] Loss: -1739.850830\n",
      "Train Epoch: 433 [45056/54000 (83%)] Loss: -1744.341797\n",
      "    epoch          : 433\n",
      "    loss           : -1742.2832560989093\n",
      "    ess            : 26.434307224345655\n",
      "    log_marginal   : 1742.5972854326355\n",
      "    val_loss       : -1738.2981262207031\n",
      "    val_ess        : 26.441256523132324\n",
      "    val_log_marginal: 1738.615946451823\n",
      "Train Epoch: 434 [0/54000 (0%)] Loss: -1742.196533\n",
      "Train Epoch: 434 [11264/54000 (21%)] Loss: -1740.459961\n",
      "Train Epoch: 434 [22528/54000 (42%)] Loss: -1738.452881\n",
      "Train Epoch: 434 [33792/54000 (63%)] Loss: -1744.881592\n",
      "Train Epoch: 434 [45056/54000 (83%)] Loss: -1747.134521\n",
      "    epoch          : 434\n",
      "    loss           : -1743.8329813255455\n",
      "    ess            : 26.40863796450057\n",
      "    log_marginal   : 1744.1493265403892\n",
      "    val_loss       : -1740.1571655273438\n",
      "    val_ess        : 26.414244492848713\n",
      "    val_log_marginal: 1740.4630533854167\n",
      "Train Epoch: 435 [0/54000 (0%)] Loss: -1744.434570\n",
      "Train Epoch: 435 [11264/54000 (21%)] Loss: -1749.066406\n",
      "Train Epoch: 435 [22528/54000 (42%)] Loss: -1744.318359\n",
      "Train Epoch: 435 [33792/54000 (63%)] Loss: -1738.256470\n",
      "Train Epoch: 435 [45056/54000 (83%)] Loss: -1742.052734\n",
      "    epoch          : 435\n",
      "    loss           : -1744.9370888764004\n",
      "    ess            : 26.448159253822183\n",
      "    log_marginal   : 1745.254092810289\n",
      "    val_loss       : -1741.6762797037761\n",
      "    val_ess        : 26.560047785441082\n",
      "    val_log_marginal: 1741.9768981933594\n",
      "Train Epoch: 436 [0/54000 (0%)] Loss: -1745.690308\n",
      "Train Epoch: 436 [11264/54000 (21%)] Loss: -1746.098267\n",
      "Train Epoch: 436 [22528/54000 (42%)] Loss: -1747.044922\n",
      "Train Epoch: 436 [33792/54000 (63%)] Loss: -1744.795898\n",
      "Train Epoch: 436 [45056/54000 (83%)] Loss: -1743.125488\n",
      "    epoch          : 436\n",
      "    loss           : -1745.8092616818985\n",
      "    ess            : 26.43006771015671\n",
      "    log_marginal   : 1746.1286943543632\n",
      "    val_loss       : -1742.0587972005208\n",
      "    val_ess        : 26.436145146687824\n",
      "    val_log_marginal: 1742.3828837076824\n",
      "Train Epoch: 437 [0/54000 (0%)] Loss: -1753.552979\n",
      "Train Epoch: 437 [11264/54000 (21%)] Loss: -1747.085449\n",
      "Train Epoch: 437 [22528/54000 (42%)] Loss: -1706.277466\n",
      "Train Epoch: 437 [33792/54000 (63%)] Loss: -1731.877075\n",
      "Train Epoch: 437 [45056/54000 (83%)] Loss: -1722.646729\n",
      "    epoch          : 437\n",
      "    loss           : -1730.8592103202388\n",
      "    ess            : 26.43475183450951\n",
      "    log_marginal   : 1731.1733801499852\n",
      "    val_loss       : -1733.1954142252605\n",
      "    val_ess        : 26.668720563252766\n",
      "    val_log_marginal: 1733.4900004069011\n",
      "Train Epoch: 438 [0/54000 (0%)] Loss: -1727.889648\n",
      "Train Epoch: 438 [11264/54000 (21%)] Loss: -1731.358643\n",
      "Train Epoch: 438 [22528/54000 (42%)] Loss: -1737.548096\n",
      "Train Epoch: 438 [33792/54000 (63%)] Loss: -1731.240967\n",
      "Train Epoch: 438 [45056/54000 (83%)] Loss: -1739.023560\n",
      "    epoch          : 438\n",
      "    loss           : -1736.7082461950913\n",
      "    ess            : 27.056590278193635\n",
      "    log_marginal   : 1736.9831070809994\n",
      "    val_loss       : -1737.084004720052\n",
      "    val_ess        : 26.61904255549113\n",
      "    val_log_marginal: 1737.3861389160156\n",
      "Train Epoch: 439 [0/54000 (0%)] Loss: -1740.195068\n",
      "Train Epoch: 439 [11264/54000 (21%)] Loss: -1749.085449\n",
      "Train Epoch: 439 [22528/54000 (42%)] Loss: -1741.613037\n",
      "Train Epoch: 439 [33792/54000 (63%)] Loss: -1743.736938\n",
      "Train Epoch: 439 [45056/54000 (83%)] Loss: -1745.204834\n",
      "    epoch          : 439\n",
      "    loss           : -1742.9372201595666\n",
      "    ess            : 26.690283721348024\n",
      "    log_marginal   : 1743.2395537754276\n",
      "    val_loss       : -1743.1947631835938\n",
      "    val_ess        : 26.699418544769287\n",
      "    val_log_marginal: 1743.4918009440105\n",
      "Train Epoch: 440 [0/54000 (0%)] Loss: -1742.550049\n",
      "Train Epoch: 440 [11264/54000 (21%)] Loss: -1742.349121\n",
      "Train Epoch: 440 [22528/54000 (42%)] Loss: -1746.726562\n",
      "Train Epoch: 440 [33792/54000 (63%)] Loss: -1742.508179\n",
      "Train Epoch: 440 [45056/54000 (83%)] Loss: -1746.565186\n",
      "    epoch          : 440\n",
      "    loss           : -1745.6103112562648\n",
      "    ess            : 26.548557443438835\n",
      "    log_marginal   : 1745.9203779112618\n",
      "    val_loss       : -1744.5359191894531\n",
      "    val_ess        : 26.53316291173299\n",
      "    val_log_marginal: 1744.8489888509114\n",
      "Train Epoch: 441 [0/54000 (0%)] Loss: -1748.451660\n",
      "Train Epoch: 441 [11264/54000 (21%)] Loss: -1741.320801\n",
      "Train Epoch: 441 [22528/54000 (42%)] Loss: -1744.549072\n",
      "Train Epoch: 441 [33792/54000 (63%)] Loss: -1745.829834\n",
      "Train Epoch: 441 [45056/54000 (83%)] Loss: -1742.022461\n",
      "    epoch          : 441\n",
      "    loss           : -1746.7867258899616\n",
      "    ess            : 26.467181061798673\n",
      "    log_marginal   : 1747.1010223964474\n",
      "    val_loss       : -1744.398213704427\n",
      "    val_ess        : 26.412715593973797\n",
      "    val_log_marginal: 1744.714090983073\n",
      "Train Epoch: 442 [0/54000 (0%)] Loss: -1748.151733\n",
      "Train Epoch: 442 [11264/54000 (21%)] Loss: -1726.055420\n",
      "Train Epoch: 442 [22528/54000 (42%)] Loss: -1721.248657\n",
      "Train Epoch: 442 [33792/54000 (63%)] Loss: -1720.867920\n",
      "Train Epoch: 442 [45056/54000 (83%)] Loss: -1718.767822\n",
      "    epoch          : 442\n",
      "    loss           : -1724.2101083431603\n",
      "    ess            : 26.328102219779538\n",
      "    log_marginal   : 1724.5261218952683\n",
      "    val_loss       : -1727.855204264323\n",
      "    val_ess        : 26.314781665802002\n",
      "    val_log_marginal: 1728.1732177734375\n",
      "Train Epoch: 443 [0/54000 (0%)] Loss: -1734.532715\n",
      "Train Epoch: 443 [11264/54000 (21%)] Loss: -1738.641602\n",
      "Train Epoch: 443 [22528/54000 (42%)] Loss: -1736.909424\n",
      "Train Epoch: 443 [33792/54000 (63%)] Loss: -1739.636841\n",
      "Train Epoch: 443 [45056/54000 (83%)] Loss: -1727.406738\n",
      "    epoch          : 443\n",
      "    loss           : -1737.8495944041126\n",
      "    ess            : 27.14803652493459\n",
      "    log_marginal   : 1738.1189955225532\n",
      "    val_loss       : -1738.2336324055989\n",
      "    val_ess        : 27.239000638326008\n",
      "    val_log_marginal: 1738.5007425944011\n",
      "Train Epoch: 444 [0/54000 (0%)] Loss: -1740.496826\n",
      "Train Epoch: 444 [11264/54000 (21%)] Loss: -1740.985352\n",
      "Train Epoch: 444 [22528/54000 (42%)] Loss: -1739.169434\n",
      "Train Epoch: 444 [33792/54000 (63%)] Loss: -1746.587402\n",
      "Train Epoch: 444 [45056/54000 (83%)] Loss: -1743.328369\n",
      "    epoch          : 444\n",
      "    loss           : -1743.3679337411556\n",
      "    ess            : 26.657252293712688\n",
      "    log_marginal   : 1743.6710792397553\n",
      "    val_loss       : -1743.4719136555989\n",
      "    val_ess        : 26.268812497456867\n",
      "    val_log_marginal: 1743.7949727376301\n",
      "Train Epoch: 445 [0/54000 (0%)] Loss: -1748.943359\n",
      "Train Epoch: 445 [11264/54000 (21%)] Loss: -1748.304199\n",
      "Train Epoch: 445 [22528/54000 (42%)] Loss: -1745.770752\n",
      "Train Epoch: 445 [33792/54000 (63%)] Loss: -1746.232300\n",
      "Train Epoch: 445 [45056/54000 (83%)] Loss: -1749.655029\n",
      "    epoch          : 445\n",
      "    loss           : -1745.8031121020047\n",
      "    ess            : 26.460850427735526\n",
      "    log_marginal   : 1746.1192051149765\n",
      "    val_loss       : -1745.5441182454426\n",
      "    val_ess        : 26.237175941467285\n",
      "    val_log_marginal: 1745.8610331217449\n",
      "Train Epoch: 446 [0/54000 (0%)] Loss: -1745.147461\n",
      "Train Epoch: 446 [11264/54000 (21%)] Loss: -1744.729980\n",
      "Train Epoch: 446 [22528/54000 (42%)] Loss: -1744.980957\n",
      "Train Epoch: 446 [33792/54000 (63%)] Loss: -1748.741211\n",
      "Train Epoch: 446 [45056/54000 (83%)] Loss: -1744.797607\n",
      "    epoch          : 446\n",
      "    loss           : -1747.3957945625737\n",
      "    ess            : 26.395424590920502\n",
      "    log_marginal   : 1747.7175972416717\n",
      "    val_loss       : -1746.465799967448\n",
      "    val_ess        : 26.68795363108317\n",
      "    val_log_marginal: 1746.7684631347656\n",
      "Train Epoch: 447 [0/54000 (0%)] Loss: -1752.647217\n",
      "Train Epoch: 447 [11264/54000 (21%)] Loss: -1743.420410\n",
      "Train Epoch: 447 [22528/54000 (42%)] Loss: -1751.846313\n",
      "Train Epoch: 447 [33792/54000 (63%)] Loss: -1750.750000\n",
      "Train Epoch: 447 [45056/54000 (83%)] Loss: -1749.450806\n",
      "    epoch          : 447\n",
      "    loss           : -1748.5135981721698\n",
      "    ess            : 26.535540868651193\n",
      "    log_marginal   : 1748.8277461213886\n",
      "    val_loss       : -1747.5119018554688\n",
      "    val_ess        : 26.419020970662434\n",
      "    val_log_marginal: 1747.823750813802\n",
      "Train Epoch: 448 [0/54000 (0%)] Loss: -1748.845093\n",
      "Train Epoch: 448 [11264/54000 (21%)] Loss: -1750.600098\n",
      "Train Epoch: 448 [22528/54000 (42%)] Loss: -1753.539551\n",
      "Train Epoch: 448 [33792/54000 (63%)] Loss: -1751.673462\n",
      "Train Epoch: 448 [45056/54000 (83%)] Loss: -1748.778809\n",
      "    epoch          : 448\n",
      "    loss           : -1749.552183906987\n",
      "    ess            : 26.520789416331166\n",
      "    log_marginal   : 1749.869988207547\n",
      "    val_loss       : -1747.3862406412761\n",
      "    val_ess        : 26.460594018300373\n",
      "    val_log_marginal: 1747.7073974609375\n",
      "Train Epoch: 449 [0/54000 (0%)] Loss: -1744.140503\n",
      "Train Epoch: 449 [11264/54000 (21%)] Loss: -1681.446045\n",
      "Train Epoch: 449 [22528/54000 (42%)] Loss: -1722.610596\n",
      "Train Epoch: 449 [33792/54000 (63%)] Loss: -1729.948242\n",
      "Train Epoch: 449 [45056/54000 (83%)] Loss: -1719.693481\n",
      "    epoch          : 449\n",
      "    loss           : -1723.309409087559\n",
      "    ess            : 26.36801543325748\n",
      "    log_marginal   : 1723.6236123139004\n",
      "    val_loss       : -1727.7856750488281\n",
      "    val_ess        : 26.473286469777424\n",
      "    val_log_marginal: 1728.0824890136719\n",
      "Train Epoch: 450 [0/54000 (0%)] Loss: -1733.236694\n",
      "Train Epoch: 450 [11264/54000 (21%)] Loss: -1732.039062\n",
      "Train Epoch: 450 [22528/54000 (42%)] Loss: -1740.912842\n",
      "Train Epoch: 450 [33792/54000 (63%)] Loss: -1733.497559\n",
      "Train Epoch: 450 [45056/54000 (83%)] Loss: -1740.830811\n",
      "    epoch          : 450\n",
      "    loss           : -1736.919880417158\n",
      "    ess            : 27.324186648962634\n",
      "    log_marginal   : 1737.1801585071491\n",
      "    val_loss       : -1736.6270650227864\n",
      "    val_ess        : 27.234487692515057\n",
      "    val_log_marginal: 1736.9032084147136\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [0/54000 (0%)] Loss: -1741.966675\n",
      "Train Epoch: 451 [11264/54000 (21%)] Loss: -1739.631348\n",
      "Train Epoch: 451 [22528/54000 (42%)] Loss: -1746.091797\n",
      "Train Epoch: 451 [33792/54000 (63%)] Loss: -1746.043457\n",
      "Train Epoch: 451 [45056/54000 (83%)] Loss: -1743.945068\n",
      "    epoch          : 451\n",
      "    loss           : -1743.1141069520195\n",
      "    ess            : 26.621651325585706\n",
      "    log_marginal   : 1743.4217045622052\n",
      "    val_loss       : -1741.6182861328125\n",
      "    val_ess        : 26.638622442881267\n",
      "    val_log_marginal: 1741.9333801269531\n",
      "Train Epoch: 452 [0/54000 (0%)] Loss: -1748.572021\n",
      "Train Epoch: 452 [11264/54000 (21%)] Loss: -1749.713745\n",
      "Train Epoch: 452 [22528/54000 (42%)] Loss: -1744.253052\n",
      "Train Epoch: 452 [33792/54000 (63%)] Loss: -1745.291260\n",
      "Train Epoch: 452 [45056/54000 (83%)] Loss: -1745.038086\n",
      "    epoch          : 452\n",
      "    loss           : -1745.6040027546433\n",
      "    ess            : 26.50982239561261\n",
      "    log_marginal   : 1745.9173457307636\n",
      "    val_loss       : -1743.9827270507812\n",
      "    val_ess        : 26.58375374476115\n",
      "    val_log_marginal: 1744.3029073079426\n",
      "Train Epoch: 453 [0/54000 (0%)] Loss: -1744.435059\n",
      "Train Epoch: 453 [11264/54000 (21%)] Loss: -1748.570801\n",
      "Train Epoch: 453 [22528/54000 (42%)] Loss: -1747.071533\n",
      "Train Epoch: 453 [33792/54000 (63%)] Loss: -1744.363281\n",
      "Train Epoch: 453 [45056/54000 (83%)] Loss: -1740.385620\n",
      "    epoch          : 453\n",
      "    loss           : -1747.158964337043\n",
      "    ess            : 26.47597588233228\n",
      "    log_marginal   : 1747.4747521742336\n",
      "    val_loss       : -1745.8813069661458\n",
      "    val_ess        : 26.410351435343426\n",
      "    val_log_marginal: 1746.1883951822917\n",
      "Train Epoch: 454 [0/54000 (0%)] Loss: -1745.889648\n",
      "Train Epoch: 454 [11264/54000 (21%)] Loss: -1750.354248\n",
      "Train Epoch: 454 [22528/54000 (42%)] Loss: -1747.986816\n",
      "Train Epoch: 454 [33792/54000 (63%)] Loss: -1748.397095\n",
      "Train Epoch: 454 [45056/54000 (83%)] Loss: -1747.099854\n",
      "    epoch          : 454\n",
      "    loss           : -1748.4632902325325\n",
      "    ess            : 26.42692727862664\n",
      "    log_marginal   : 1748.7849777509582\n",
      "    val_loss       : -1747.0441487630208\n",
      "    val_ess        : 26.5132474899292\n",
      "    val_log_marginal: 1747.3492228190105\n",
      "Train Epoch: 455 [0/54000 (0%)] Loss: -1752.546631\n",
      "Train Epoch: 455 [11264/54000 (21%)] Loss: -1751.620850\n",
      "Train Epoch: 455 [22528/54000 (42%)] Loss: -1751.040894\n",
      "Train Epoch: 455 [33792/54000 (63%)] Loss: -1748.773193\n",
      "Train Epoch: 455 [45056/54000 (83%)] Loss: -1746.995605\n",
      "    epoch          : 455\n",
      "    loss           : -1749.3367977502212\n",
      "    ess            : 26.531943465178866\n",
      "    log_marginal   : 1749.6542784492924\n",
      "    val_loss       : -1747.0032145182292\n",
      "    val_ess        : 26.467876593271892\n",
      "    val_log_marginal: 1747.3217264811199\n",
      "Train Epoch: 456 [0/54000 (0%)] Loss: -1749.906738\n",
      "Train Epoch: 456 [11264/54000 (21%)] Loss: -1748.684570\n",
      "Train Epoch: 456 [22528/54000 (42%)] Loss: -1747.066650\n",
      "Train Epoch: 456 [33792/54000 (63%)] Loss: -1698.257080\n",
      "Train Epoch: 456 [45056/54000 (83%)] Loss: -1733.846802\n",
      "    epoch          : 456\n",
      "    loss           : -1730.896752699366\n",
      "    ess            : 26.421137054011506\n",
      "    log_marginal   : 1731.2110872088738\n",
      "    val_loss       : -1721.6065063476562\n",
      "    val_ess        : 26.525686105092365\n",
      "    val_log_marginal: 1721.9110107421875\n",
      "Train Epoch: 457 [0/54000 (0%)] Loss: -1717.945557\n",
      "Train Epoch: 457 [11264/54000 (21%)] Loss: -1722.065918\n",
      "Train Epoch: 457 [22528/54000 (42%)] Loss: -1730.082275\n",
      "Train Epoch: 457 [33792/54000 (63%)] Loss: -1741.464111\n",
      "Train Epoch: 457 [45056/54000 (83%)] Loss: -1732.062256\n",
      "    epoch          : 457\n",
      "    loss           : -1730.6901763340213\n",
      "    ess            : 26.98476490884457\n",
      "    log_marginal   : 1730.971952618293\n",
      "    val_loss       : -1731.0980529785156\n",
      "    val_ess        : 27.306972980499268\n",
      "    val_log_marginal: 1731.3695780436199\n",
      "Train Epoch: 458 [0/54000 (0%)] Loss: -1738.871460\n",
      "Train Epoch: 458 [11264/54000 (21%)] Loss: -1739.961060\n",
      "Train Epoch: 458 [22528/54000 (42%)] Loss: -1730.531006\n",
      "Train Epoch: 458 [33792/54000 (63%)] Loss: -1730.938721\n",
      "Train Epoch: 458 [45056/54000 (83%)] Loss: -1737.144531\n",
      "    epoch          : 458\n",
      "    loss           : -1736.9067820423054\n",
      "    ess            : 26.9490093375152\n",
      "    log_marginal   : 1737.1940906452683\n",
      "    val_loss       : -1739.7792358398438\n",
      "    val_ess        : 26.716758092244465\n",
      "    val_log_marginal: 1740.0797424316406\n",
      "Train Epoch: 459 [0/54000 (0%)] Loss: -1738.759277\n",
      "Train Epoch: 459 [11264/54000 (21%)] Loss: -1740.771240\n",
      "Train Epoch: 459 [22528/54000 (42%)] Loss: -1738.378418\n",
      "Train Epoch: 459 [33792/54000 (63%)] Loss: -1746.194458\n",
      "Train Epoch: 459 [45056/54000 (83%)] Loss: -1746.769287\n",
      "    epoch          : 459\n",
      "    loss           : -1743.6027601709907\n",
      "    ess            : 26.7810214240596\n",
      "    log_marginal   : 1743.8988186818249\n",
      "    val_loss       : -1743.95947265625\n",
      "    val_ess        : 26.71892515818278\n",
      "    val_log_marginal: 1744.2587381998699\n",
      "Train Epoch: 460 [0/54000 (0%)] Loss: -1745.084595\n",
      "Train Epoch: 460 [11264/54000 (21%)] Loss: -1744.502441\n",
      "Train Epoch: 460 [22528/54000 (42%)] Loss: -1749.560547\n",
      "Train Epoch: 460 [33792/54000 (63%)] Loss: -1741.644043\n",
      "Train Epoch: 460 [45056/54000 (83%)] Loss: -1745.744507\n",
      "    epoch          : 460\n",
      "    loss           : -1746.425127137382\n",
      "    ess            : 26.466037516324025\n",
      "    log_marginal   : 1746.740540702388\n",
      "    val_loss       : -1746.6442464192708\n",
      "    val_ess        : 26.54167954126994\n",
      "    val_log_marginal: 1746.9638163248699\n",
      "Train Epoch: 461 [0/54000 (0%)] Loss: -1748.388428\n",
      "Train Epoch: 461 [11264/54000 (21%)] Loss: -1748.742188\n",
      "Train Epoch: 461 [22528/54000 (42%)] Loss: -1745.510010\n",
      "Train Epoch: 461 [33792/54000 (63%)] Loss: -1748.440674\n",
      "Train Epoch: 461 [45056/54000 (83%)] Loss: -1743.749268\n",
      "    epoch          : 461\n",
      "    loss           : -1748.342934662441\n",
      "    ess            : 26.460855142125542\n",
      "    log_marginal   : 1748.657801214254\n",
      "    val_loss       : -1747.9270935058594\n",
      "    val_ess        : 26.41433572769165\n",
      "    val_log_marginal: 1748.2354125976562\n",
      "Train Epoch: 462 [0/54000 (0%)] Loss: -1756.415527\n",
      "Train Epoch: 462 [11264/54000 (21%)] Loss: -1747.224609\n",
      "Train Epoch: 462 [22528/54000 (42%)] Loss: -1750.581787\n",
      "Train Epoch: 462 [33792/54000 (63%)] Loss: -1747.075073\n",
      "Train Epoch: 462 [45056/54000 (83%)] Loss: -1749.717041\n",
      "    epoch          : 462\n",
      "    loss           : -1749.6143603054982\n",
      "    ess            : 26.433446794185997\n",
      "    log_marginal   : 1749.93561712301\n",
      "    val_loss       : -1749.0440063476562\n",
      "    val_ess        : 26.37231222788493\n",
      "    val_log_marginal: 1749.370340983073\n",
      "Train Epoch: 463 [0/54000 (0%)] Loss: -1748.926758\n",
      "Train Epoch: 463 [11264/54000 (21%)] Loss: -1749.328857\n",
      "Train Epoch: 463 [22528/54000 (42%)] Loss: -1748.363281\n",
      "Train Epoch: 463 [33792/54000 (63%)] Loss: -1745.868408\n",
      "Train Epoch: 463 [45056/54000 (83%)] Loss: -1748.300781\n",
      "    epoch          : 463\n",
      "    loss           : -1746.726648870504\n",
      "    ess            : 26.509577967085928\n",
      "    log_marginal   : 1747.0468807580337\n",
      "    val_loss       : -1710.9623006184895\n",
      "    val_ess        : 26.37942345937093\n",
      "    val_log_marginal: 1711.2703247070312\n",
      "Train Epoch: 464 [0/54000 (0%)] Loss: -1708.347168\n",
      "Train Epoch: 464 [11264/54000 (21%)] Loss: -1706.225464\n",
      "Train Epoch: 464 [22528/54000 (42%)] Loss: -1713.203247\n",
      "Train Epoch: 464 [33792/54000 (63%)] Loss: -1711.493408\n",
      "Train Epoch: 464 [45056/54000 (83%)] Loss: -1721.428345\n",
      "    epoch          : 464\n",
      "    loss           : -1712.6474010539505\n",
      "    ess            : 26.463418654675753\n",
      "    log_marginal   : 1712.9459009710347\n",
      "    val_loss       : -1731.7546895345051\n",
      "    val_ess        : 27.71317211786906\n",
      "    val_log_marginal: 1731.982645670573\n",
      "Train Epoch: 465 [0/54000 (0%)] Loss: -1730.877197\n",
      "Train Epoch: 465 [11264/54000 (21%)] Loss: -1730.149902\n",
      "Train Epoch: 465 [22528/54000 (42%)] Loss: -1733.521973\n",
      "Train Epoch: 465 [33792/54000 (63%)] Loss: -1740.097168\n",
      "Train Epoch: 465 [45056/54000 (83%)] Loss: -1736.619385\n",
      "    epoch          : 465\n",
      "    loss           : -1734.0489905015477\n",
      "    ess            : 27.421252340640663\n",
      "    log_marginal   : 1734.3059611770343\n",
      "    val_loss       : -1739.1912536621094\n",
      "    val_ess        : 26.718536218007404\n",
      "    val_log_marginal: 1739.4798583984375\n",
      "Train Epoch: 466 [0/54000 (0%)] Loss: -1738.266357\n",
      "Train Epoch: 466 [11264/54000 (21%)] Loss: -1737.078613\n",
      "Train Epoch: 466 [22528/54000 (42%)] Loss: -1741.025391\n",
      "Train Epoch: 466 [33792/54000 (63%)] Loss: -1739.545532\n",
      "Train Epoch: 466 [45056/54000 (83%)] Loss: -1740.734131\n",
      "    epoch          : 466\n",
      "    loss           : -1740.0039753464032\n",
      "    ess            : 26.65106820160488\n",
      "    log_marginal   : 1740.2982557764594\n",
      "    val_loss       : -1742.3890177408855\n",
      "    val_ess        : 26.56066131591797\n",
      "    val_log_marginal: 1742.6788330078125\n",
      "Train Epoch: 467 [0/54000 (0%)] Loss: -1742.549927\n",
      "Train Epoch: 467 [11264/54000 (21%)] Loss: -1743.611084\n",
      "Train Epoch: 467 [22528/54000 (42%)] Loss: -1742.357910\n",
      "Train Epoch: 467 [33792/54000 (63%)] Loss: -1738.355347\n",
      "Train Epoch: 467 [45056/54000 (83%)] Loss: -1743.488892\n",
      "    epoch          : 467\n",
      "    loss           : -1742.7357419571786\n",
      "    ess            : 26.458714233254486\n",
      "    log_marginal   : 1743.0478550173202\n",
      "    val_loss       : -1744.0069783528645\n",
      "    val_ess        : 26.469672520955402\n",
      "    val_log_marginal: 1744.3134053548176\n",
      "Train Epoch: 468 [0/54000 (0%)] Loss: -1749.318970\n",
      "Train Epoch: 468 [11264/54000 (21%)] Loss: -1746.109619\n",
      "Train Epoch: 468 [22528/54000 (42%)] Loss: -1740.148682\n",
      "Train Epoch: 468 [33792/54000 (63%)] Loss: -1744.089600\n",
      "Train Epoch: 468 [45056/54000 (83%)] Loss: -1749.554932\n",
      "    epoch          : 468\n",
      "    loss           : -1744.5237668595223\n",
      "    ess            : 26.365506496069568\n",
      "    log_marginal   : 1744.8465000368515\n",
      "    val_loss       : -1745.430440266927\n",
      "    val_ess        : 26.286985397338867\n",
      "    val_log_marginal: 1745.750996907552\n",
      "Train Epoch: 469 [0/54000 (0%)] Loss: -1749.861084\n",
      "Train Epoch: 469 [11264/54000 (21%)] Loss: -1743.814209\n",
      "Train Epoch: 469 [22528/54000 (42%)] Loss: -1745.830811\n",
      "Train Epoch: 469 [33792/54000 (63%)] Loss: -1747.602417\n",
      "Train Epoch: 469 [45056/54000 (83%)] Loss: -1747.215698\n",
      "    epoch          : 469\n",
      "    loss           : -1746.0066516804245\n",
      "    ess            : 26.48267922311459\n",
      "    log_marginal   : 1746.319005426371\n",
      "    val_loss       : -1746.1606953938801\n",
      "    val_ess        : 26.4835368792216\n",
      "    val_log_marginal: 1746.4646911621094\n",
      "Train Epoch: 470 [0/54000 (0%)] Loss: -1750.884033\n",
      "Train Epoch: 470 [11264/54000 (21%)] Loss: -1746.384399\n",
      "Train Epoch: 470 [22528/54000 (42%)] Loss: -1743.656006\n",
      "Train Epoch: 470 [33792/54000 (63%)] Loss: -1751.331299\n",
      "Train Epoch: 470 [45056/54000 (83%)] Loss: -1742.929565\n",
      "    epoch          : 470\n",
      "    loss           : -1747.3214848356427\n",
      "    ess            : 26.418710204790223\n",
      "    log_marginal   : 1747.6399524616745\n",
      "    val_loss       : -1747.4884643554688\n",
      "    val_ess        : 26.25281222661336\n",
      "    val_log_marginal: 1747.8060099283855\n",
      "Train Epoch: 471 [0/54000 (0%)] Loss: -1746.916138\n",
      "Train Epoch: 471 [11264/54000 (21%)] Loss: -1753.234009\n",
      "Train Epoch: 471 [22528/54000 (42%)] Loss: -1754.561523\n",
      "Train Epoch: 471 [33792/54000 (63%)] Loss: -1748.731934\n",
      "Train Epoch: 471 [45056/54000 (83%)] Loss: -1748.196777\n",
      "    epoch          : 471\n",
      "    loss           : -1748.4354754753833\n",
      "    ess            : 26.452123084158266\n",
      "    log_marginal   : 1748.7508245504127\n",
      "    val_loss       : -1748.3896382649739\n",
      "    val_ess        : 26.45834954579671\n",
      "    val_log_marginal: 1748.7095642089844\n",
      "Train Epoch: 472 [0/54000 (0%)] Loss: -1752.069336\n",
      "Train Epoch: 472 [11264/54000 (21%)] Loss: -1746.610352\n",
      "Train Epoch: 472 [22528/54000 (42%)] Loss: -1747.692749\n",
      "Train Epoch: 472 [33792/54000 (63%)] Loss: -1753.197998\n",
      "Train Epoch: 472 [45056/54000 (83%)] Loss: -1746.141113\n",
      "    epoch          : 472\n",
      "    loss           : -1747.771422188237\n",
      "    ess            : 26.501548713108278\n",
      "    log_marginal   : 1748.0887151754127\n",
      "    val_loss       : -1730.3450826009114\n",
      "    val_ess        : 26.525036493937176\n",
      "    val_log_marginal: 1730.667236328125\n",
      "Train Epoch: 473 [0/54000 (0%)] Loss: -1735.875366\n",
      "Train Epoch: 473 [11264/54000 (21%)] Loss: -1715.023438\n",
      "Train Epoch: 473 [22528/54000 (42%)] Loss: -1727.986084\n",
      "Train Epoch: 473 [33792/54000 (63%)] Loss: -1717.271851\n",
      "Train Epoch: 473 [45056/54000 (83%)] Loss: -1710.827881\n",
      "    epoch          : 473\n",
      "    loss           : -1716.4856417673939\n",
      "    ess            : 26.432167665013726\n",
      "    log_marginal   : 1716.7952800246906\n",
      "    val_loss       : -1708.9513854980469\n",
      "    val_ess        : 27.175988515218098\n",
      "    val_log_marginal: 1709.2225646972656\n",
      "Train Epoch: 474 [0/54000 (0%)] Loss: -1713.609985\n",
      "Train Epoch: 474 [11264/54000 (21%)] Loss: -1725.930664\n",
      "Train Epoch: 474 [22528/54000 (42%)] Loss: -1725.041016\n",
      "Train Epoch: 474 [33792/54000 (63%)] Loss: -1729.564209\n",
      "Train Epoch: 474 [45056/54000 (83%)] Loss: -1734.915771\n",
      "    epoch          : 474\n",
      "    loss           : -1727.2336851875737\n",
      "    ess            : 27.455967399309266\n",
      "    log_marginal   : 1727.4860114331516\n",
      "    val_loss       : -1727.2815551757812\n",
      "    val_ess        : 27.47480312983195\n",
      "    val_log_marginal: 1727.5330810546875\n",
      "Train Epoch: 475 [0/54000 (0%)] Loss: -1732.212036\n",
      "Train Epoch: 475 [11264/54000 (21%)] Loss: -1740.915405\n",
      "Train Epoch: 475 [22528/54000 (42%)] Loss: -1741.605469\n",
      "Train Epoch: 475 [33792/54000 (63%)] Loss: -1738.739746\n",
      "Train Epoch: 475 [45056/54000 (83%)] Loss: -1736.593262\n",
      "    epoch          : 475\n",
      "    loss           : -1738.1950130822524\n",
      "    ess            : 26.866237100565208\n",
      "    log_marginal   : 1738.4868256191037\n",
      "    val_loss       : -1737.7452799479167\n",
      "    val_ess        : 26.78561019897461\n",
      "    val_log_marginal: 1738.0375874837239\n",
      "Train Epoch: 476 [0/54000 (0%)] Loss: -1743.996338\n",
      "Train Epoch: 476 [11264/54000 (21%)] Loss: -1746.218750\n",
      "Train Epoch: 476 [22528/54000 (42%)] Loss: -1744.778564\n",
      "Train Epoch: 476 [33792/54000 (63%)] Loss: -1747.245605\n",
      "Train Epoch: 476 [45056/54000 (83%)] Loss: -1738.623535\n",
      "    epoch          : 476\n",
      "    loss           : -1742.2115823997642\n",
      "    ess            : 26.5499033118194\n",
      "    log_marginal   : 1742.517085237323\n",
      "    val_loss       : -1740.8633219401042\n",
      "    val_ess        : 26.441776275634766\n",
      "    val_log_marginal: 1741.1704915364583\n",
      "Train Epoch: 477 [0/54000 (0%)] Loss: -1742.024536\n",
      "Train Epoch: 477 [11264/54000 (21%)] Loss: -1739.626465\n",
      "Train Epoch: 477 [22528/54000 (42%)] Loss: -1741.946777\n",
      "Train Epoch: 477 [33792/54000 (63%)] Loss: -1748.307007\n",
      "Train Epoch: 477 [45056/54000 (83%)] Loss: -1748.638672\n",
      "    epoch          : 477\n",
      "    loss           : -1744.3937504606427\n",
      "    ess            : 26.527195354677595\n",
      "    log_marginal   : 1744.7080055092865\n",
      "    val_loss       : -1743.0372823079426\n",
      "    val_ess        : 26.49980068206787\n",
      "    val_log_marginal: 1743.3454081217449\n",
      "Train Epoch: 478 [0/54000 (0%)] Loss: -1751.125732\n",
      "Train Epoch: 478 [11264/54000 (21%)] Loss: -1745.707275\n",
      "Train Epoch: 478 [22528/54000 (42%)] Loss: -1748.240234\n",
      "Train Epoch: 478 [33792/54000 (63%)] Loss: -1745.153564\n",
      "Train Epoch: 478 [45056/54000 (83%)] Loss: -1743.878296\n",
      "    epoch          : 478\n",
      "    loss           : -1745.9127197265625\n",
      "    ess            : 26.53147495917554\n",
      "    log_marginal   : 1746.22209772074\n",
      "    val_loss       : -1744.2003275553386\n",
      "    val_ess        : 26.399831930796307\n",
      "    val_log_marginal: 1744.5214131673176\n",
      "Train Epoch: 479 [0/54000 (0%)] Loss: -1748.226562\n",
      "Train Epoch: 479 [11264/54000 (21%)] Loss: -1744.128296\n",
      "Train Epoch: 479 [22528/54000 (42%)] Loss: -1747.257080\n",
      "Train Epoch: 479 [33792/54000 (63%)] Loss: -1742.101074\n",
      "Train Epoch: 479 [45056/54000 (83%)] Loss: -1743.312500\n",
      "    epoch          : 479\n",
      "    loss           : -1747.1535943948998\n",
      "    ess            : 26.3628375395289\n",
      "    log_marginal   : 1747.4827880859375\n",
      "    val_loss       : -1745.4940388997395\n",
      "    val_ess        : 26.44522174199422\n",
      "    val_log_marginal: 1745.8294677734375\n",
      "Train Epoch: 480 [0/54000 (0%)] Loss: -1749.231201\n",
      "Train Epoch: 480 [11264/54000 (21%)] Loss: -1749.930908\n",
      "Train Epoch: 480 [22528/54000 (42%)] Loss: -1743.937256\n",
      "Train Epoch: 480 [33792/54000 (63%)] Loss: -1750.681396\n",
      "Train Epoch: 480 [45056/54000 (83%)] Loss: -1741.783691\n",
      "    epoch          : 480\n",
      "    loss           : -1748.367518011129\n",
      "    ess            : 26.465564637813927\n",
      "    log_marginal   : 1748.687946823408\n",
      "    val_loss       : -1746.7849019368489\n",
      "    val_ess        : 26.302889664967854\n",
      "    val_log_marginal: 1747.1182454427083\n",
      "Train Epoch: 481 [0/54000 (0%)] Loss: -1749.794434\n",
      "Train Epoch: 481 [11264/54000 (21%)] Loss: -1753.255371\n",
      "Train Epoch: 481 [22528/54000 (42%)] Loss: -1747.438232\n",
      "Train Epoch: 481 [33792/54000 (63%)] Loss: -1751.619873\n",
      "Train Epoch: 481 [45056/54000 (83%)] Loss: -1746.604248\n",
      "    epoch          : 481\n",
      "    loss           : -1749.0213530918338\n",
      "    ess            : 26.525853750840675\n",
      "    log_marginal   : 1749.3378065577094\n",
      "    val_loss       : -1745.4010213216145\n",
      "    val_ess        : 26.648300488789875\n",
      "    val_log_marginal: 1745.7090759277344\n",
      "Train Epoch: 482 [0/54000 (0%)] Loss: -1748.893188\n",
      "Train Epoch: 482 [11264/54000 (21%)] Loss: -1731.989502\n",
      "Train Epoch: 482 [22528/54000 (42%)] Loss: -1718.275513\n",
      "Train Epoch: 482 [33792/54000 (63%)] Loss: -1721.237793\n",
      "Train Epoch: 482 [45056/54000 (83%)] Loss: -1715.892334\n",
      "    epoch          : 482\n",
      "    loss           : -1723.8519782300266\n",
      "    ess            : 26.363288969363808\n",
      "    log_marginal   : 1724.164236392615\n",
      "    val_loss       : -1723.3219299316406\n",
      "    val_ess        : 26.55179437001546\n",
      "    val_log_marginal: 1723.6153055826824\n",
      "Train Epoch: 483 [0/54000 (0%)] Loss: -1727.748047\n",
      "Train Epoch: 483 [11264/54000 (21%)] Loss: -1739.118896\n",
      "Train Epoch: 483 [22528/54000 (42%)] Loss: -1744.419800\n",
      "Train Epoch: 483 [33792/54000 (63%)] Loss: -1735.273804\n",
      "Train Epoch: 483 [45056/54000 (83%)] Loss: -1739.592773\n",
      "    epoch          : 483\n",
      "    loss           : -1736.5668507701946\n",
      "    ess            : 27.296882467449837\n",
      "    log_marginal   : 1736.8263089161999\n",
      "    val_loss       : -1733.64501953125\n",
      "    val_ess        : 27.029062271118164\n",
      "    val_log_marginal: 1733.9375508626301\n",
      "Train Epoch: 484 [0/54000 (0%)] Loss: -1739.419922\n",
      "Train Epoch: 484 [11264/54000 (21%)] Loss: -1744.251343\n",
      "Train Epoch: 484 [22528/54000 (42%)] Loss: -1739.406128\n",
      "Train Epoch: 484 [33792/54000 (63%)] Loss: -1744.985840\n",
      "Train Epoch: 484 [45056/54000 (83%)] Loss: -1737.844482\n",
      "    epoch          : 484\n",
      "    loss           : -1742.626981915168\n",
      "    ess            : 26.66103523182419\n",
      "    log_marginal   : 1742.9264768204598\n",
      "    val_loss       : -1741.8042093912761\n",
      "    val_ess        : 26.758094310760498\n",
      "    val_log_marginal: 1742.1065673828125\n",
      "Train Epoch: 485 [0/54000 (0%)] Loss: -1749.288086\n",
      "Train Epoch: 485 [11264/54000 (21%)] Loss: -1746.243652\n",
      "Train Epoch: 485 [22528/54000 (42%)] Loss: -1740.021973\n",
      "Train Epoch: 485 [33792/54000 (63%)] Loss: -1745.549927\n",
      "Train Epoch: 485 [45056/54000 (83%)] Loss: -1745.279297\n",
      "    epoch          : 485\n",
      "    loss           : -1745.413875939711\n",
      "    ess            : 26.466423736428315\n",
      "    log_marginal   : 1745.7238930756191\n",
      "    val_loss       : -1744.1313985188801\n",
      "    val_ess        : 26.20823844273885\n",
      "    val_log_marginal: 1744.4476725260417\n",
      "Train Epoch: 486 [0/54000 (0%)] Loss: -1745.474121\n",
      "Train Epoch: 486 [11264/54000 (21%)] Loss: -1747.952881\n",
      "Train Epoch: 486 [22528/54000 (42%)] Loss: -1746.489502\n",
      "Train Epoch: 486 [33792/54000 (63%)] Loss: -1744.145264\n",
      "Train Epoch: 486 [45056/54000 (83%)] Loss: -1747.388306\n",
      "    epoch          : 486\n",
      "    loss           : -1747.1157675689121\n",
      "    ess            : 26.47250961807539\n",
      "    log_marginal   : 1747.431128160009\n",
      "    val_loss       : -1745.6805826822917\n",
      "    val_ess        : 26.704528331756592\n",
      "    val_log_marginal: 1745.9901835123699\n",
      "Train Epoch: 487 [0/54000 (0%)] Loss: -1751.641968\n",
      "Train Epoch: 487 [11264/54000 (21%)] Loss: -1749.843628\n",
      "Train Epoch: 487 [22528/54000 (42%)] Loss: -1749.464722\n",
      "Train Epoch: 487 [33792/54000 (63%)] Loss: -1750.824463\n",
      "Train Epoch: 487 [45056/54000 (83%)] Loss: -1746.986084\n",
      "    epoch          : 487\n",
      "    loss           : -1748.718931953862\n",
      "    ess            : 26.457729483550448\n",
      "    log_marginal   : 1749.036352769384\n",
      "    val_loss       : -1747.5962931315105\n",
      "    val_ess        : 26.37598180770874\n",
      "    val_log_marginal: 1747.9229838053386\n",
      "Train Epoch: 488 [0/54000 (0%)] Loss: -1753.973145\n",
      "Train Epoch: 488 [11264/54000 (21%)] Loss: -1752.994141\n",
      "Train Epoch: 488 [22528/54000 (42%)] Loss: -1750.071045\n",
      "Train Epoch: 488 [33792/54000 (63%)] Loss: -1748.489014\n",
      "Train Epoch: 488 [45056/54000 (83%)] Loss: -1750.516846\n",
      "    epoch          : 488\n",
      "    loss           : -1750.0238705041274\n",
      "    ess            : 26.51453979060335\n",
      "    log_marginal   : 1750.341544673128\n",
      "    val_loss       : -1748.622049967448\n",
      "    val_ess        : 26.503051280975342\n",
      "    val_log_marginal: 1748.9425048828125\n",
      "Train Epoch: 489 [0/54000 (0%)] Loss: -1752.288208\n",
      "Train Epoch: 489 [11264/54000 (21%)] Loss: -1753.026367\n",
      "Train Epoch: 489 [22528/54000 (42%)] Loss: -1748.709961\n",
      "Train Epoch: 489 [33792/54000 (63%)] Loss: -1749.030396\n",
      "Train Epoch: 489 [45056/54000 (83%)] Loss: -1750.299194\n",
      "    epoch          : 489\n",
      "    loss           : -1750.8375923588592\n",
      "    ess            : 26.54884599289804\n",
      "    log_marginal   : 1751.1538673256928\n",
      "    val_loss       : -1749.088602701823\n",
      "    val_ess        : 26.560076077779133\n",
      "    val_log_marginal: 1749.4119059244792\n",
      "Train Epoch: 490 [0/54000 (0%)] Loss: -1755.507324\n",
      "Train Epoch: 490 [11264/54000 (21%)] Loss: -1754.471436\n",
      "Train Epoch: 490 [22528/54000 (42%)] Loss: -1743.333496\n",
      "Train Epoch: 490 [33792/54000 (63%)] Loss: -1702.917969\n",
      "Train Epoch: 490 [45056/54000 (83%)] Loss: -1728.010254\n",
      "    epoch          : 490\n",
      "    loss           : -1732.1579958357902\n",
      "    ess            : 26.38494966614921\n",
      "    log_marginal   : 1732.4731548957104\n",
      "    val_loss       : -1729.467061360677\n",
      "    val_ess        : 26.541767756144207\n",
      "    val_log_marginal: 1729.764892578125\n",
      "Train Epoch: 491 [0/54000 (0%)] Loss: -1730.709961\n",
      "Train Epoch: 491 [11264/54000 (21%)] Loss: -1733.832764\n",
      "Train Epoch: 491 [22528/54000 (42%)] Loss: -1744.149536\n",
      "Train Epoch: 491 [33792/54000 (63%)] Loss: -1742.783203\n",
      "Train Epoch: 491 [45056/54000 (83%)] Loss: -1742.025513\n",
      "    epoch          : 491\n",
      "    loss           : -1738.74365234375\n",
      "    ess            : 26.905663814184802\n",
      "    log_marginal   : 1739.0296861180718\n",
      "    val_loss       : -1740.7040608723958\n",
      "    val_ess        : 27.182472387949627\n",
      "    val_log_marginal: 1740.9725748697917\n",
      "Train Epoch: 492 [0/54000 (0%)] Loss: -1748.036011\n",
      "Train Epoch: 492 [11264/54000 (21%)] Loss: -1745.743896\n",
      "Train Epoch: 492 [22528/54000 (42%)] Loss: -1747.224121\n",
      "Train Epoch: 492 [33792/54000 (63%)] Loss: -1739.525635\n",
      "Train Epoch: 492 [45056/54000 (83%)] Loss: -1750.713989\n",
      "    epoch          : 492\n",
      "    loss           : -1745.8559927310584\n",
      "    ess            : 26.75737748056088\n",
      "    log_marginal   : 1746.155579764888\n",
      "    val_loss       : -1746.5607096354167\n",
      "    val_ess        : 26.66734727223714\n",
      "    val_log_marginal: 1746.858133951823\n",
      "Train Epoch: 493 [0/54000 (0%)] Loss: -1748.909058\n",
      "Train Epoch: 493 [11264/54000 (21%)] Loss: -1748.032715\n",
      "Train Epoch: 493 [22528/54000 (42%)] Loss: -1754.023804\n",
      "Train Epoch: 493 [33792/54000 (63%)] Loss: -1755.583984\n",
      "Train Epoch: 493 [45056/54000 (83%)] Loss: -1746.715576\n",
      "    epoch          : 493\n",
      "    loss           : -1748.6595401404038\n",
      "    ess            : 26.526169938861198\n",
      "    log_marginal   : 1748.9715921653892\n",
      "    val_loss       : -1748.4173889160156\n",
      "    val_ess        : 26.589006423950195\n",
      "    val_log_marginal: 1748.736307779948\n",
      "Train Epoch: 494 [0/54000 (0%)] Loss: -1749.731812\n",
      "Train Epoch: 494 [11264/54000 (21%)] Loss: -1753.627563\n",
      "Train Epoch: 494 [22528/54000 (42%)] Loss: -1741.419067\n",
      "Train Epoch: 494 [33792/54000 (63%)] Loss: -1754.282104\n",
      "Train Epoch: 494 [45056/54000 (83%)] Loss: -1750.795776\n",
      "    epoch          : 494\n",
      "    loss           : -1750.4177050320607\n",
      "    ess            : 26.512114326908904\n",
      "    log_marginal   : 1750.734296690743\n",
      "    val_loss       : -1749.6937662760417\n",
      "    val_ess        : 26.66078233718872\n",
      "    val_log_marginal: 1749.9974568684895\n",
      "Train Epoch: 495 [0/54000 (0%)] Loss: -1753.948975\n",
      "Train Epoch: 495 [11264/54000 (21%)] Loss: -1748.897217\n",
      "Train Epoch: 495 [22528/54000 (42%)] Loss: -1753.387573\n",
      "Train Epoch: 495 [33792/54000 (63%)] Loss: -1752.239990\n",
      "Train Epoch: 495 [45056/54000 (83%)] Loss: -1748.673096\n",
      "    epoch          : 495\n",
      "    loss           : -1751.6053017670254\n",
      "    ess            : 26.503474577417915\n",
      "    log_marginal   : 1751.9237878187648\n",
      "    val_loss       : -1750.9602762858074\n",
      "    val_ess        : 26.34161615371704\n",
      "    val_log_marginal: 1751.2904561360676\n",
      "Train Epoch: 496 [0/54000 (0%)] Loss: -1753.489624\n",
      "Train Epoch: 496 [11264/54000 (21%)] Loss: -1751.660034\n",
      "Train Epoch: 496 [22528/54000 (42%)] Loss: -1754.422485\n",
      "Train Epoch: 496 [33792/54000 (63%)] Loss: -1750.942383\n",
      "Train Epoch: 496 [45056/54000 (83%)] Loss: -1754.690552\n",
      "    epoch          : 496\n",
      "    loss           : -1752.6806133918042\n",
      "    ess            : 26.539412516467976\n",
      "    log_marginal   : 1753.000206137603\n",
      "    val_loss       : -1751.6631469726562\n",
      "    val_ess        : 26.611833095550537\n",
      "    val_log_marginal: 1751.982177734375\n",
      "Train Epoch: 497 [0/54000 (0%)] Loss: -1748.102173\n",
      "Train Epoch: 497 [11264/54000 (21%)] Loss: -1750.675171\n",
      "Train Epoch: 497 [22528/54000 (42%)] Loss: -1753.045776\n",
      "Train Epoch: 497 [33792/54000 (63%)] Loss: -1740.104736\n",
      "Train Epoch: 497 [45056/54000 (83%)] Loss: -1712.215576\n",
      "    epoch          : 497\n",
      "    loss           : -1739.1630145378833\n",
      "    ess            : 26.487798150980247\n",
      "    log_marginal   : 1739.4787632204452\n",
      "    val_loss       : -1713.4596862792969\n",
      "    val_ess        : 26.311593850453693\n",
      "    val_log_marginal: 1713.7626851399739\n",
      "Train Epoch: 498 [0/54000 (0%)] Loss: -1719.670410\n",
      "Train Epoch: 498 [11264/54000 (21%)] Loss: -1724.736572\n",
      "Train Epoch: 498 [22528/54000 (42%)] Loss: -1729.387695\n",
      "Train Epoch: 498 [33792/54000 (63%)] Loss: -1723.855957\n",
      "Train Epoch: 498 [45056/54000 (83%)] Loss: -1726.275391\n",
      "    epoch          : 498\n",
      "    loss           : -1726.458781692217\n",
      "    ess            : 26.83093250922437\n",
      "    log_marginal   : 1726.7468745393573\n",
      "    val_loss       : -1729.5017801920574\n",
      "    val_ess        : 27.765747547149658\n",
      "    val_log_marginal: 1729.7511698404949\n",
      "Train Epoch: 499 [0/54000 (0%)] Loss: -1733.672363\n",
      "Train Epoch: 499 [11264/54000 (21%)] Loss: -1742.903564\n",
      "Train Epoch: 499 [22528/54000 (42%)] Loss: -1743.137573\n",
      "Train Epoch: 499 [33792/54000 (63%)] Loss: -1741.833374\n",
      "Train Epoch: 499 [45056/54000 (83%)] Loss: -1741.781738\n",
      "    epoch          : 499\n",
      "    loss           : -1740.5072850641216\n",
      "    ess            : 27.28504616359495\n",
      "    log_marginal   : 1740.774131918853\n",
      "    val_loss       : -1740.839579264323\n",
      "    val_ess        : 26.949432531992596\n",
      "    val_log_marginal: 1741.1297403971355\n",
      "Train Epoch: 500 [0/54000 (0%)] Loss: -1739.973633\n",
      "Train Epoch: 500 [11264/54000 (21%)] Loss: -1748.394897\n",
      "Train Epoch: 500 [22528/54000 (42%)] Loss: -1744.601685\n",
      "Train Epoch: 500 [33792/54000 (63%)] Loss: -1745.400391\n",
      "Train Epoch: 500 [45056/54000 (83%)] Loss: -1747.035400\n",
      "    epoch          : 500\n",
      "    loss           : -1745.6130647479363\n",
      "    ess            : 26.588013271115862\n",
      "    log_marginal   : 1745.9229459942512\n",
      "    val_loss       : -1744.862569173177\n",
      "    val_ess        : 26.82190402348836\n",
      "    val_log_marginal: 1745.1629638671875\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [0/54000 (0%)] Loss: -1749.903931\n",
      "Train Epoch: 501 [11264/54000 (21%)] Loss: -1754.769775\n",
      "Train Epoch: 501 [22528/54000 (42%)] Loss: -1746.773926\n",
      "Train Epoch: 501 [33792/54000 (63%)] Loss: -1747.392090\n",
      "Train Epoch: 501 [45056/54000 (83%)] Loss: -1748.697510\n",
      "    epoch          : 501\n",
      "    loss           : -1748.0071065650795\n",
      "    ess            : 26.448465185345345\n",
      "    log_marginal   : 1748.3301103699882\n",
      "    val_loss       : -1747.1824137369792\n",
      "    val_ess        : 26.710035006205242\n",
      "    val_log_marginal: 1747.4811909993489\n",
      "Train Epoch: 502 [0/54000 (0%)] Loss: -1749.756348\n",
      "Train Epoch: 502 [11264/54000 (21%)] Loss: -1745.481689\n",
      "Train Epoch: 502 [22528/54000 (42%)] Loss: -1756.671143\n",
      "Train Epoch: 502 [33792/54000 (63%)] Loss: -1749.947754\n",
      "Train Epoch: 502 [45056/54000 (83%)] Loss: -1746.356079\n",
      "    epoch          : 502\n",
      "    loss           : -1749.712153596698\n",
      "    ess            : 26.469616188193267\n",
      "    log_marginal   : 1750.0345827498527\n",
      "    val_loss       : -1748.8728535970051\n",
      "    val_ess        : 26.591392358144123\n",
      "    val_log_marginal: 1749.1834411621094\n",
      "Train Epoch: 503 [0/54000 (0%)] Loss: -1751.595947\n",
      "Train Epoch: 503 [11264/54000 (21%)] Loss: -1751.117065\n",
      "Train Epoch: 503 [22528/54000 (42%)] Loss: -1749.018555\n",
      "Train Epoch: 503 [33792/54000 (63%)] Loss: -1749.623779\n",
      "Train Epoch: 503 [45056/54000 (83%)] Loss: -1748.135010\n",
      "    epoch          : 503\n",
      "    loss           : -1751.0834419682342\n",
      "    ess            : 26.417982659249937\n",
      "    log_marginal   : 1751.40520318949\n",
      "    val_loss       : -1750.0779113769531\n",
      "    val_ess        : 26.66643524169922\n",
      "    val_log_marginal: 1750.3955688476562\n",
      "Train Epoch: 504 [0/54000 (0%)] Loss: -1751.811890\n",
      "Train Epoch: 504 [11264/54000 (21%)] Loss: -1749.897949\n",
      "Train Epoch: 504 [22528/54000 (42%)] Loss: -1752.368530\n",
      "Train Epoch: 504 [33792/54000 (63%)] Loss: -1745.226562\n",
      "Train Epoch: 504 [45056/54000 (83%)] Loss: -1755.908936\n",
      "    epoch          : 504\n",
      "    loss           : -1752.1173210863797\n",
      "    ess            : 26.57288463160677\n",
      "    log_marginal   : 1752.4332402067364\n",
      "    val_loss       : -1750.4473063151042\n",
      "    val_ess        : 26.4881534576416\n",
      "    val_log_marginal: 1750.7620035807292\n",
      "Train Epoch: 505 [0/54000 (0%)] Loss: -1756.120117\n",
      "Train Epoch: 505 [11264/54000 (21%)] Loss: -1746.093140\n",
      "Train Epoch: 505 [22528/54000 (42%)] Loss: -1739.658081\n",
      "Train Epoch: 505 [33792/54000 (63%)] Loss: -1727.168213\n",
      "Train Epoch: 505 [45056/54000 (83%)] Loss: -1724.538574\n",
      "    epoch          : 505\n",
      "    loss           : -1732.3506181824882\n",
      "    ess            : 26.486241052735526\n",
      "    log_marginal   : 1732.6607136276532\n",
      "    val_loss       : -1718.7194213867188\n",
      "    val_ess        : 26.469995975494385\n",
      "    val_log_marginal: 1719.0231424967449\n",
      "Train Epoch: 506 [0/54000 (0%)] Loss: -1729.118652\n",
      "Train Epoch: 506 [11264/54000 (21%)] Loss: -1739.836670\n",
      "Train Epoch: 506 [22528/54000 (42%)] Loss: -1742.055054\n",
      "Train Epoch: 506 [33792/54000 (63%)] Loss: -1743.003906\n",
      "Train Epoch: 506 [45056/54000 (83%)] Loss: -1738.457886\n",
      "    epoch          : 506\n",
      "    loss           : -1739.6476336785083\n",
      "    ess            : 27.13740149084127\n",
      "    log_marginal   : 1739.9249774285083\n",
      "    val_loss       : -1732.3233947753906\n",
      "    val_ess        : 27.695629278818767\n",
      "    val_log_marginal: 1732.5794372558594\n",
      "Train Epoch: 507 [0/54000 (0%)] Loss: -1746.717896\n",
      "Train Epoch: 507 [11264/54000 (21%)] Loss: -1749.770508\n",
      "Train Epoch: 507 [22528/54000 (42%)] Loss: -1744.568726\n",
      "Train Epoch: 507 [33792/54000 (63%)] Loss: -1744.746582\n",
      "Train Epoch: 507 [45056/54000 (83%)] Loss: -1744.938721\n",
      "    epoch          : 507\n",
      "    loss           : -1745.8265081441627\n",
      "    ess            : 26.7336270134404\n",
      "    log_marginal   : 1746.1301234983048\n",
      "    val_loss       : -1740.2650349934895\n",
      "    val_ess        : 26.55528195699056\n",
      "    val_log_marginal: 1740.5916951497395\n",
      "Train Epoch: 508 [0/54000 (0%)] Loss: -1750.166382\n",
      "Train Epoch: 508 [11264/54000 (21%)] Loss: -1749.331299\n",
      "Train Epoch: 508 [22528/54000 (42%)] Loss: -1746.551880\n",
      "Train Epoch: 508 [33792/54000 (63%)] Loss: -1745.893311\n",
      "Train Epoch: 508 [45056/54000 (83%)] Loss: -1749.865967\n",
      "    epoch          : 508\n",
      "    loss           : -1748.467687066996\n",
      "    ess            : 26.634172583526034\n",
      "    log_marginal   : 1748.7794684644016\n",
      "    val_loss       : -1743.3756103515625\n",
      "    val_ess        : 26.611122449239094\n",
      "    val_log_marginal: 1743.6817728678386\n",
      "Train Epoch: 509 [0/54000 (0%)] Loss: -1747.183594\n",
      "Train Epoch: 509 [11264/54000 (21%)] Loss: -1748.832397\n",
      "Train Epoch: 509 [22528/54000 (42%)] Loss: -1746.384644\n",
      "Train Epoch: 509 [33792/54000 (63%)] Loss: -1745.328003\n",
      "Train Epoch: 509 [45056/54000 (83%)] Loss: -1754.949707\n",
      "    epoch          : 509\n",
      "    loss           : -1750.1222637824292\n",
      "    ess            : 26.489665571248757\n",
      "    log_marginal   : 1750.4439708781692\n",
      "    val_loss       : -1745.8364664713542\n",
      "    val_ess        : 26.620615482330322\n",
      "    val_log_marginal: 1746.1494140625\n",
      "Train Epoch: 510 [0/54000 (0%)] Loss: -1748.399902\n",
      "Train Epoch: 510 [11264/54000 (21%)] Loss: -1755.239990\n",
      "Train Epoch: 510 [22528/54000 (42%)] Loss: -1748.110107\n",
      "Train Epoch: 510 [33792/54000 (63%)] Loss: -1753.043213\n",
      "Train Epoch: 510 [45056/54000 (83%)] Loss: -1755.094971\n",
      "    epoch          : 510\n",
      "    loss           : -1751.2760309183373\n",
      "    ess            : 26.45900868469814\n",
      "    log_marginal   : 1751.5992086158608\n",
      "    val_loss       : -1747.2447408040364\n",
      "    val_ess        : 26.649049758911133\n",
      "    val_log_marginal: 1747.555887858073\n",
      "Train Epoch: 511 [0/54000 (0%)] Loss: -1750.119995\n",
      "Train Epoch: 511 [11264/54000 (21%)] Loss: -1747.920410\n",
      "Train Epoch: 511 [22528/54000 (42%)] Loss: -1751.416992\n",
      "Train Epoch: 511 [33792/54000 (63%)] Loss: -1749.777832\n",
      "Train Epoch: 511 [45056/54000 (83%)] Loss: -1754.812744\n",
      "    epoch          : 511\n",
      "    loss           : -1752.4885564840065\n",
      "    ess            : 26.54449788579401\n",
      "    log_marginal   : 1752.8098052402713\n",
      "    val_loss       : -1748.7735900878906\n",
      "    val_ess        : 26.817673047383625\n",
      "    val_log_marginal: 1749.0654398600261\n",
      "Train Epoch: 512 [0/54000 (0%)] Loss: -1756.503540\n",
      "Train Epoch: 512 [11264/54000 (21%)] Loss: -1752.757568\n",
      "Train Epoch: 512 [22528/54000 (42%)] Loss: -1753.102417\n",
      "Train Epoch: 512 [33792/54000 (63%)] Loss: -1751.684937\n",
      "Train Epoch: 512 [45056/54000 (83%)] Loss: -1756.812500\n",
      "    epoch          : 512\n",
      "    loss           : -1752.5993767504422\n",
      "    ess            : 26.538722650060112\n",
      "    log_marginal   : 1752.9225936025944\n",
      "    val_loss       : -1742.2008260091145\n",
      "    val_ess        : 26.634212493896484\n",
      "    val_log_marginal: 1742.5170084635417\n",
      "Train Epoch: 513 [0/54000 (0%)] Loss: -1748.112183\n",
      "Train Epoch: 513 [11264/54000 (21%)] Loss: -1720.442139\n",
      "Train Epoch: 513 [22528/54000 (42%)] Loss: -1724.318848\n",
      "Train Epoch: 513 [33792/54000 (63%)] Loss: -1729.489258\n",
      "Train Epoch: 513 [45056/54000 (83%)] Loss: -1721.247559\n",
      "    epoch          : 513\n",
      "    loss           : -1724.7437122272995\n",
      "    ess            : 26.371621959614306\n",
      "    log_marginal   : 1725.0593296266952\n",
      "    val_loss       : -1726.9845682779949\n",
      "    val_ess        : 26.77047109603882\n",
      "    val_log_marginal: 1727.2801208496094\n",
      "Train Epoch: 514 [0/54000 (0%)] Loss: -1740.280762\n",
      "Train Epoch: 514 [11264/54000 (21%)] Loss: -1744.890869\n",
      "Train Epoch: 514 [22528/54000 (42%)] Loss: -1741.166016\n",
      "Train Epoch: 514 [33792/54000 (63%)] Loss: -1736.990723\n",
      "Train Epoch: 514 [45056/54000 (83%)] Loss: -1745.603027\n",
      "    epoch          : 514\n",
      "    loss           : -1739.8883252413768\n",
      "    ess            : 27.40474513791642\n",
      "    log_marginal   : 1740.1462805406102\n",
      "    val_loss       : -1737.5641377766926\n",
      "    val_ess        : 27.101406892140705\n",
      "    val_log_marginal: 1737.8411763509114\n",
      "Train Epoch: 515 [0/54000 (0%)] Loss: -1743.499268\n",
      "Train Epoch: 515 [11264/54000 (21%)] Loss: -1745.635620\n",
      "Train Epoch: 515 [22528/54000 (42%)] Loss: -1746.827881\n",
      "Train Epoch: 515 [33792/54000 (63%)] Loss: -1745.000977\n",
      "Train Epoch: 515 [45056/54000 (83%)] Loss: -1743.109863\n",
      "    epoch          : 515\n",
      "    loss           : -1746.0048033516362\n",
      "    ess            : 26.717002598744518\n",
      "    log_marginal   : 1746.3066671119545\n",
      "    val_loss       : -1743.5371398925781\n",
      "    val_ess        : 26.74250300725301\n",
      "    val_log_marginal: 1743.8362223307292\n",
      "Train Epoch: 516 [0/54000 (0%)] Loss: -1754.108154\n",
      "Train Epoch: 516 [11264/54000 (21%)] Loss: -1748.452148\n",
      "Train Epoch: 516 [22528/54000 (42%)] Loss: -1749.948975\n",
      "Train Epoch: 516 [33792/54000 (63%)] Loss: -1754.958618\n",
      "Train Epoch: 516 [45056/54000 (83%)] Loss: -1756.355347\n",
      "    epoch          : 516\n",
      "    loss           : -1748.6053178895195\n",
      "    ess            : 26.482163375278688\n",
      "    log_marginal   : 1748.9256545732605\n",
      "    val_loss       : -1745.3615620930989\n",
      "    val_ess        : 26.73562701543172\n",
      "    val_log_marginal: 1745.6752115885417\n",
      "Train Epoch: 517 [0/54000 (0%)] Loss: -1750.122681\n",
      "Train Epoch: 517 [11264/54000 (21%)] Loss: -1753.182373\n",
      "Train Epoch: 517 [22528/54000 (42%)] Loss: -1749.516479\n",
      "Train Epoch: 517 [33792/54000 (63%)] Loss: -1756.746338\n",
      "Train Epoch: 517 [45056/54000 (83%)] Loss: -1754.672974\n",
      "    epoch          : 517\n",
      "    loss           : -1750.3361540020637\n",
      "    ess            : 26.511532477612764\n",
      "    log_marginal   : 1750.6524853976268\n",
      "    val_loss       : -1747.490234375\n",
      "    val_ess        : 26.638188044230144\n",
      "    val_log_marginal: 1747.7973225911458\n",
      "Train Epoch: 518 [0/54000 (0%)] Loss: -1753.310913\n",
      "Train Epoch: 518 [11264/54000 (21%)] Loss: -1754.373535\n",
      "Train Epoch: 518 [22528/54000 (42%)] Loss: -1749.622437\n",
      "Train Epoch: 518 [33792/54000 (63%)] Loss: -1755.693359\n",
      "Train Epoch: 518 [45056/54000 (83%)] Loss: -1752.577881\n",
      "    epoch          : 518\n",
      "    loss           : -1751.5898621757076\n",
      "    ess            : 26.501758287537772\n",
      "    log_marginal   : 1751.9109255232902\n",
      "    val_loss       : -1748.734395345052\n",
      "    val_ess        : 26.6851011912028\n",
      "    val_log_marginal: 1749.050557454427\n",
      "Train Epoch: 519 [0/54000 (0%)] Loss: -1755.834473\n",
      "Train Epoch: 519 [11264/54000 (21%)] Loss: -1747.492188\n",
      "Train Epoch: 519 [22528/54000 (42%)] Loss: -1752.867676\n",
      "Train Epoch: 519 [33792/54000 (63%)] Loss: -1751.300659\n",
      "Train Epoch: 519 [45056/54000 (83%)] Loss: -1754.344604\n",
      "    epoch          : 519\n",
      "    loss           : -1751.9491876566185\n",
      "    ess            : 26.553762651839346\n",
      "    log_marginal   : 1752.2724713019604\n",
      "    val_loss       : -1746.5414225260417\n",
      "    val_ess        : 26.433048725128174\n",
      "    val_log_marginal: 1746.8698221842449\n",
      "Train Epoch: 520 [0/54000 (0%)] Loss: -1749.332031\n",
      "Train Epoch: 520 [11264/54000 (21%)] Loss: -1734.316406\n",
      "Train Epoch: 520 [22528/54000 (42%)] Loss: -1735.089111\n",
      "Train Epoch: 520 [33792/54000 (63%)] Loss: -1745.437744\n",
      "Train Epoch: 520 [45056/54000 (83%)] Loss: -1742.014893\n",
      "    epoch          : 520\n",
      "    loss           : -1738.2864195625737\n",
      "    ess            : 26.52223813758706\n",
      "    log_marginal   : 1738.6058130804097\n",
      "    val_loss       : -1730.8397827148438\n",
      "    val_ess        : 26.57992108662923\n",
      "    val_log_marginal: 1731.1513570149739\n",
      "Train Epoch: 521 [0/54000 (0%)] Loss: -1734.587646\n",
      "Train Epoch: 521 [11264/54000 (21%)] Loss: -1747.759277\n",
      "Train Epoch: 521 [22528/54000 (42%)] Loss: -1747.496704\n",
      "Train Epoch: 521 [33792/54000 (63%)] Loss: -1746.542969\n",
      "Train Epoch: 521 [45056/54000 (83%)] Loss: -1748.229492\n",
      "    epoch          : 521\n",
      "    loss           : -1744.2973471587559\n",
      "    ess            : 26.96901218846159\n",
      "    log_marginal   : 1744.5884802476414\n",
      "    val_loss       : -1738.1138509114583\n",
      "    val_ess        : 26.94144614537557\n",
      "    val_log_marginal: 1738.4042358398438\n",
      "Train Epoch: 522 [0/54000 (0%)] Loss: -1748.527832\n",
      "Train Epoch: 522 [11264/54000 (21%)] Loss: -1748.480225\n",
      "Train Epoch: 522 [22528/54000 (42%)] Loss: -1752.160645\n",
      "Train Epoch: 522 [33792/54000 (63%)] Loss: -1739.646362\n",
      "Train Epoch: 522 [45056/54000 (83%)] Loss: -1737.088379\n",
      "    epoch          : 522\n",
      "    loss           : -1743.9814637382076\n",
      "    ess            : 26.66397125316116\n",
      "    log_marginal   : 1744.2839159695607\n",
      "    val_loss       : -1734.8675944010417\n",
      "    val_ess        : 26.978885014851887\n",
      "    val_log_marginal: 1735.1492919921875\n",
      "Train Epoch: 523 [0/54000 (0%)] Loss: -1746.387939\n",
      "Train Epoch: 523 [11264/54000 (21%)] Loss: -1748.172363\n",
      "Train Epoch: 523 [22528/54000 (42%)] Loss: -1747.939331\n",
      "Train Epoch: 523 [33792/54000 (63%)] Loss: -1747.298340\n",
      "Train Epoch: 523 [45056/54000 (83%)] Loss: -1748.961182\n",
      "    epoch          : 523\n",
      "    loss           : -1746.2900954912293\n",
      "    ess            : 26.677612214718224\n",
      "    log_marginal   : 1746.5946494048496\n",
      "    val_loss       : -1742.2844950358074\n",
      "    val_ess        : 26.894496122996014\n",
      "    val_log_marginal: 1742.5802917480469\n",
      "Train Epoch: 524 [0/54000 (0%)] Loss: -1752.184082\n",
      "Train Epoch: 524 [11264/54000 (21%)] Loss: -1745.056030\n",
      "Train Epoch: 524 [22528/54000 (42%)] Loss: -1748.814941\n",
      "Train Epoch: 524 [33792/54000 (63%)] Loss: -1746.161133\n",
      "Train Epoch: 524 [45056/54000 (83%)] Loss: -1751.405640\n",
      "    epoch          : 524\n",
      "    loss           : -1749.9798215470223\n",
      "    ess            : 26.608750703199853\n",
      "    log_marginal   : 1750.2901945294075\n",
      "    val_loss       : -1746.4718221028645\n",
      "    val_ess        : 26.57223892211914\n",
      "    val_log_marginal: 1746.7931620279949\n",
      "Train Epoch: 525 [0/54000 (0%)] Loss: -1750.700684\n",
      "Train Epoch: 525 [11264/54000 (21%)] Loss: -1752.236206\n",
      "Train Epoch: 525 [22528/54000 (42%)] Loss: -1750.157715\n",
      "Train Epoch: 525 [33792/54000 (63%)] Loss: -1753.316284\n",
      "Train Epoch: 525 [45056/54000 (83%)] Loss: -1757.371582\n",
      "    epoch          : 525\n",
      "    loss           : -1752.0523543447819\n",
      "    ess            : 26.546530903510327\n",
      "    log_marginal   : 1752.3717939268868\n",
      "    val_loss       : -1748.4065551757812\n",
      "    val_ess        : 26.639801025390625\n",
      "    val_log_marginal: 1748.7222798665364\n",
      "Train Epoch: 526 [0/54000 (0%)] Loss: -1752.329590\n",
      "Train Epoch: 526 [11264/54000 (21%)] Loss: -1753.962280\n",
      "Train Epoch: 526 [22528/54000 (42%)] Loss: -1753.065918\n",
      "Train Epoch: 526 [33792/54000 (63%)] Loss: -1757.182129\n",
      "Train Epoch: 526 [45056/54000 (83%)] Loss: -1751.299072\n",
      "    epoch          : 526\n",
      "    loss           : -1753.444431520858\n",
      "    ess            : 26.57891215918199\n",
      "    log_marginal   : 1753.7648085108344\n",
      "    val_loss       : -1750.1769917805989\n",
      "    val_ess        : 26.869685014088947\n",
      "    val_log_marginal: 1750.4867045084636\n",
      "Train Epoch: 527 [0/54000 (0%)] Loss: -1758.472168\n",
      "Train Epoch: 527 [11264/54000 (21%)] Loss: -1753.305542\n",
      "Train Epoch: 527 [22528/54000 (42%)] Loss: -1761.543335\n",
      "Train Epoch: 527 [33792/54000 (63%)] Loss: -1754.886719\n",
      "Train Epoch: 527 [45056/54000 (83%)] Loss: -1754.004517\n",
      "    epoch          : 527\n",
      "    loss           : -1754.6621773197967\n",
      "    ess            : 26.578438650886966\n",
      "    log_marginal   : 1754.9816825434846\n",
      "    val_loss       : -1751.1724548339844\n",
      "    val_ess        : 26.72707176208496\n",
      "    val_log_marginal: 1751.4829508463542\n",
      "Train Epoch: 528 [0/54000 (0%)] Loss: -1760.440308\n",
      "Train Epoch: 528 [11264/54000 (21%)] Loss: -1755.124756\n",
      "Train Epoch: 528 [22528/54000 (42%)] Loss: -1756.617920\n",
      "Train Epoch: 528 [33792/54000 (63%)] Loss: -1753.128418\n",
      "Train Epoch: 528 [45056/54000 (83%)] Loss: -1755.063477\n",
      "    epoch          : 528\n",
      "    loss           : -1755.609751575398\n",
      "    ess            : 26.497482443755526\n",
      "    log_marginal   : 1755.9364969505455\n",
      "    val_loss       : -1752.14306640625\n",
      "    val_ess        : 26.45577573776245\n",
      "    val_log_marginal: 1752.4797261555989\n",
      "Train Epoch: 529 [0/54000 (0%)] Loss: -1762.859619\n",
      "Train Epoch: 529 [11264/54000 (21%)] Loss: -1757.231689\n",
      "Train Epoch: 529 [22528/54000 (42%)] Loss: -1757.513794\n",
      "Train Epoch: 529 [33792/54000 (63%)] Loss: -1757.128296\n",
      "Train Epoch: 529 [45056/54000 (83%)] Loss: -1757.727295\n",
      "    epoch          : 529\n",
      "    loss           : -1756.2272880122346\n",
      "    ess            : 26.605017320165093\n",
      "    log_marginal   : 1756.5488453991009\n",
      "    val_loss       : -1751.4309590657551\n",
      "    val_ess        : 26.611833095550537\n",
      "    val_log_marginal: 1751.7660624186199\n",
      "Train Epoch: 530 [0/54000 (0%)] Loss: -1753.385742\n",
      "Train Epoch: 530 [11264/54000 (21%)] Loss: -1730.582520\n",
      "Train Epoch: 530 [22528/54000 (42%)] Loss: -1716.795288\n",
      "Train Epoch: 530 [33792/54000 (63%)] Loss: -1730.659180\n",
      "Train Epoch: 530 [45056/54000 (83%)] Loss: -1730.205200\n",
      "    epoch          : 530\n",
      "    loss           : -1728.0477744048496\n",
      "    ess            : 26.520207854936707\n",
      "    log_marginal   : 1728.3610586490272\n",
      "    val_loss       : -1731.7609151204426\n",
      "    val_ess        : 26.910054524739582\n",
      "    val_log_marginal: 1732.05615234375\n",
      "Train Epoch: 531 [0/54000 (0%)] Loss: -1733.371826\n",
      "Train Epoch: 531 [11264/54000 (21%)] Loss: -1741.238770\n",
      "Train Epoch: 531 [22528/54000 (42%)] Loss: -1746.744141\n",
      "Train Epoch: 531 [33792/54000 (63%)] Loss: -1742.119141\n",
      "Train Epoch: 531 [45056/54000 (83%)] Loss: -1747.997437\n",
      "    epoch          : 531\n",
      "    loss           : -1743.0736141564712\n",
      "    ess            : 27.262913020151966\n",
      "    log_marginal   : 1743.3480385834316\n",
      "    val_loss       : -1744.1147155761719\n",
      "    val_ess        : 27.36941607793172\n",
      "    val_log_marginal: 1744.3853658040364\n",
      "Train Epoch: 532 [0/54000 (0%)] Loss: -1751.961060\n",
      "Train Epoch: 532 [11264/54000 (21%)] Loss: -1748.683594\n",
      "Train Epoch: 532 [22528/54000 (42%)] Loss: -1750.338135\n",
      "Train Epoch: 532 [33792/54000 (63%)] Loss: -1754.425781\n",
      "Train Epoch: 532 [45056/54000 (83%)] Loss: -1749.954102\n",
      "    epoch          : 532\n",
      "    loss           : -1749.8894607256043\n",
      "    ess            : 26.746394427317494\n",
      "    log_marginal   : 1750.1935943027713\n",
      "    val_loss       : -1749.2286478678386\n",
      "    val_ess        : 26.626911799112957\n",
      "    val_log_marginal: 1749.5391031901042\n",
      "Train Epoch: 533 [0/54000 (0%)] Loss: -1754.520020\n",
      "Train Epoch: 533 [11264/54000 (21%)] Loss: -1752.162842\n",
      "Train Epoch: 533 [22528/54000 (42%)] Loss: -1755.528076\n",
      "Train Epoch: 533 [33792/54000 (63%)] Loss: -1751.122070\n",
      "Train Epoch: 533 [45056/54000 (83%)] Loss: -1756.284912\n",
      "    epoch          : 533\n",
      "    loss           : -1752.432794534935\n",
      "    ess            : 26.56226949871711\n",
      "    log_marginal   : 1752.7492998231132\n",
      "    val_loss       : -1751.2918701171875\n",
      "    val_ess        : 26.788344224294026\n",
      "    val_log_marginal: 1751.6027730305989\n",
      "Train Epoch: 534 [0/54000 (0%)] Loss: -1756.790527\n",
      "Train Epoch: 534 [11264/54000 (21%)] Loss: -1752.273682\n",
      "Train Epoch: 534 [22528/54000 (42%)] Loss: -1751.503174\n",
      "Train Epoch: 534 [33792/54000 (63%)] Loss: -1754.614990\n",
      "Train Epoch: 534 [45056/54000 (83%)] Loss: -1750.677734\n",
      "    epoch          : 534\n",
      "    loss           : -1754.0184556493218\n",
      "    ess            : 26.50694580797879\n",
      "    log_marginal   : 1754.340576171875\n",
      "    val_loss       : -1752.6439310709636\n",
      "    val_ess        : 26.581904411315918\n",
      "    val_log_marginal: 1752.9545491536458\n",
      "Train Epoch: 535 [0/54000 (0%)] Loss: -1755.836792\n",
      "Train Epoch: 535 [11264/54000 (21%)] Loss: -1756.562500\n",
      "Train Epoch: 535 [22528/54000 (42%)] Loss: -1756.391602\n",
      "Train Epoch: 535 [33792/54000 (63%)] Loss: -1753.506592\n",
      "Train Epoch: 535 [45056/54000 (83%)] Loss: -1753.412354\n",
      "    epoch          : 535\n",
      "    loss           : -1755.361141564711\n",
      "    ess            : 26.50120409479681\n",
      "    log_marginal   : 1755.68980091023\n",
      "    val_loss       : -1753.8663126627605\n",
      "    val_ess        : 26.413633187611897\n",
      "    val_log_marginal: 1754.195821126302\n",
      "Train Epoch: 536 [0/54000 (0%)] Loss: -1752.469482\n",
      "Train Epoch: 536 [11264/54000 (21%)] Loss: -1753.289429\n",
      "Train Epoch: 536 [22528/54000 (42%)] Loss: -1760.062256\n",
      "Train Epoch: 536 [33792/54000 (63%)] Loss: -1754.746582\n",
      "Train Epoch: 536 [45056/54000 (83%)] Loss: -1758.250488\n",
      "    epoch          : 536\n",
      "    loss           : -1755.7293943009286\n",
      "    ess            : 26.57269670378487\n",
      "    log_marginal   : 1756.0516484098614\n",
      "    val_loss       : -1748.3704427083333\n",
      "    val_ess        : 26.404709657033283\n",
      "    val_log_marginal: 1748.6959533691406\n",
      "Train Epoch: 537 [0/54000 (0%)] Loss: -1751.875732\n",
      "Train Epoch: 537 [11264/54000 (21%)] Loss: -1714.858032\n",
      "Train Epoch: 537 [22528/54000 (42%)] Loss: -1747.701660\n",
      "Train Epoch: 537 [33792/54000 (63%)] Loss: -1722.462036\n",
      "Train Epoch: 537 [45056/54000 (83%)] Loss: -1734.768555\n",
      "    epoch          : 537\n",
      "    loss           : -1732.1843031397407\n",
      "    ess            : 26.516559312928397\n",
      "    log_marginal   : 1732.500682902786\n",
      "    val_loss       : -1740.8346455891926\n",
      "    val_ess        : 27.041929721832275\n",
      "    val_log_marginal: 1741.1233011881511\n",
      "Train Epoch: 538 [0/54000 (0%)] Loss: -1747.320068\n",
      "Train Epoch: 538 [11264/54000 (21%)] Loss: -1745.302734\n",
      "Train Epoch: 538 [22528/54000 (42%)] Loss: -1747.016113\n",
      "Train Epoch: 538 [33792/54000 (63%)] Loss: -1742.106934\n",
      "Train Epoch: 538 [45056/54000 (83%)] Loss: -1742.831055\n",
      "    epoch          : 538\n",
      "    loss           : -1743.6910285229953\n",
      "    ess            : 27.46934280755385\n",
      "    log_marginal   : 1743.9503093215656\n",
      "    val_loss       : -1748.634521484375\n",
      "    val_ess        : 26.930697917938232\n",
      "    val_log_marginal: 1748.9266153971355\n",
      "Train Epoch: 539 [0/54000 (0%)] Loss: -1751.833252\n",
      "Train Epoch: 539 [11264/54000 (21%)] Loss: -1750.245728\n",
      "Train Epoch: 539 [22528/54000 (42%)] Loss: -1751.120117\n",
      "Train Epoch: 539 [33792/54000 (63%)] Loss: -1751.439697\n",
      "Train Epoch: 539 [45056/54000 (83%)] Loss: -1754.070190\n",
      "    epoch          : 539\n",
      "    loss           : -1750.6894957344487\n",
      "    ess            : 26.812966814580953\n",
      "    log_marginal   : 1750.9915598743366\n",
      "    val_loss       : -1752.5892537434895\n",
      "    val_ess        : 26.54674832026164\n",
      "    val_log_marginal: 1752.9198099772136\n",
      "Train Epoch: 540 [0/54000 (0%)] Loss: -1755.265381\n",
      "Train Epoch: 540 [11264/54000 (21%)] Loss: -1755.280273\n",
      "Train Epoch: 540 [22528/54000 (42%)] Loss: -1750.657471\n",
      "Train Epoch: 540 [33792/54000 (63%)] Loss: -1752.831055\n",
      "Train Epoch: 540 [45056/54000 (83%)] Loss: -1754.103516\n",
      "    epoch          : 540\n",
      "    loss           : -1753.2162475585938\n",
      "    ess            : 26.57144683262087\n",
      "    log_marginal   : 1753.5359209168632\n",
      "    val_loss       : -1753.9903564453125\n",
      "    val_ess        : 26.556878725687664\n",
      "    val_log_marginal: 1754.3147379557292\n",
      "Train Epoch: 541 [0/54000 (0%)] Loss: -1755.995483\n",
      "Train Epoch: 541 [11264/54000 (21%)] Loss: -1751.506348\n",
      "Train Epoch: 541 [22528/54000 (42%)] Loss: -1756.838867\n",
      "Train Epoch: 541 [33792/54000 (63%)] Loss: -1757.358032\n",
      "Train Epoch: 541 [45056/54000 (83%)] Loss: -1756.104370\n",
      "    epoch          : 541\n",
      "    loss           : -1754.969978764372\n",
      "    ess            : 26.592670278729134\n",
      "    log_marginal   : 1755.293725355616\n",
      "    val_loss       : -1755.1663411458333\n",
      "    val_ess        : 26.4423991839091\n",
      "    val_log_marginal: 1755.4877522786458\n",
      "Train Epoch: 542 [0/54000 (0%)] Loss: -1753.593994\n",
      "Train Epoch: 542 [11264/54000 (21%)] Loss: -1752.595825\n",
      "Train Epoch: 542 [22528/54000 (42%)] Loss: -1757.969971\n",
      "Train Epoch: 542 [33792/54000 (63%)] Loss: -1756.839233\n",
      "Train Epoch: 542 [45056/54000 (83%)] Loss: -1759.067383\n",
      "    epoch          : 542\n",
      "    loss           : -1756.2140548993957\n",
      "    ess            : 26.56771244193023\n",
      "    log_marginal   : 1756.5436919590213\n",
      "    val_loss       : -1756.2077229817708\n",
      "    val_ess        : 26.536351044972736\n",
      "    val_log_marginal: 1756.5386352539062\n",
      "Train Epoch: 543 [0/54000 (0%)] Loss: -1753.021973\n",
      "Train Epoch: 543 [11264/54000 (21%)] Loss: -1757.898560\n",
      "Train Epoch: 543 [22528/54000 (42%)] Loss: -1760.679321\n",
      "Train Epoch: 543 [33792/54000 (63%)] Loss: -1759.685059\n",
      "Train Epoch: 543 [45056/54000 (83%)] Loss: -1760.634766\n",
      "    epoch          : 543\n",
      "    loss           : -1757.2081978276092\n",
      "    ess            : 26.63857292679121\n",
      "    log_marginal   : 1757.5246121388561\n",
      "    val_loss       : -1756.4649759928386\n",
      "    val_ess        : 26.68012348810832\n",
      "    val_log_marginal: 1756.8027038574219\n",
      "Train Epoch: 544 [0/54000 (0%)] Loss: -1756.676392\n",
      "Train Epoch: 544 [11264/54000 (21%)] Loss: -1758.502441\n",
      "Train Epoch: 544 [22528/54000 (42%)] Loss: -1752.632080\n",
      "Train Epoch: 544 [33792/54000 (63%)] Loss: -1711.990601\n",
      "Train Epoch: 544 [45056/54000 (83%)] Loss: -1726.102173\n",
      "    epoch          : 544\n",
      "    loss           : -1738.5919051260319\n",
      "    ess            : 26.493063728764373\n",
      "    log_marginal   : 1738.9144194980838\n",
      "    val_loss       : -1729.1158955891926\n",
      "    val_ess        : 26.57003355026245\n",
      "    val_log_marginal: 1729.4348551432292\n",
      "Train Epoch: 545 [0/54000 (0%)] Loss: -1736.537109\n",
      "Train Epoch: 545 [11264/54000 (21%)] Loss: -1744.503418\n",
      "Train Epoch: 545 [22528/54000 (42%)] Loss: -1748.701904\n",
      "Train Epoch: 545 [33792/54000 (63%)] Loss: -1739.905518\n",
      "Train Epoch: 545 [45056/54000 (83%)] Loss: -1738.162598\n",
      "    epoch          : 545\n",
      "    loss           : -1740.0149271263267\n",
      "    ess            : 27.16551699728336\n",
      "    log_marginal   : 1740.2941549049233\n",
      "    val_loss       : -1739.7422688802083\n",
      "    val_ess        : 27.44637155532837\n",
      "    val_log_marginal: 1740.0101216634114\n",
      "Train Epoch: 546 [0/54000 (0%)] Loss: -1744.813232\n",
      "Train Epoch: 546 [11264/54000 (21%)] Loss: -1745.337891\n",
      "Train Epoch: 546 [22528/54000 (42%)] Loss: -1747.345459\n",
      "Train Epoch: 546 [33792/54000 (63%)] Loss: -1746.381348\n",
      "Train Epoch: 546 [45056/54000 (83%)] Loss: -1746.361816\n",
      "    epoch          : 546\n",
      "    loss           : -1748.17571100199\n",
      "    ess            : 26.977386294670826\n",
      "    log_marginal   : 1748.4653919147995\n",
      "    val_loss       : -1745.3936055501301\n",
      "    val_ess        : 26.42446279525757\n",
      "    val_log_marginal: 1745.7216898600261\n",
      "Train Epoch: 547 [0/54000 (0%)] Loss: -1750.724365\n",
      "Train Epoch: 547 [11264/54000 (21%)] Loss: -1750.519043\n",
      "Train Epoch: 547 [22528/54000 (42%)] Loss: -1746.087891\n",
      "Train Epoch: 547 [33792/54000 (63%)] Loss: -1755.503418\n",
      "Train Epoch: 547 [45056/54000 (83%)] Loss: -1749.161377\n",
      "    epoch          : 547\n",
      "    loss           : -1752.1925037312058\n",
      "    ess            : 26.660426103843832\n",
      "    log_marginal   : 1752.50516034972\n",
      "    val_loss       : -1750.517842610677\n",
      "    val_ess        : 26.915222962697346\n",
      "    val_log_marginal: 1750.8133138020833\n",
      "Train Epoch: 548 [0/54000 (0%)] Loss: -1759.933594\n",
      "Train Epoch: 548 [11264/54000 (21%)] Loss: -1760.774658\n",
      "Train Epoch: 548 [22528/54000 (42%)] Loss: -1754.902710\n",
      "Train Epoch: 548 [33792/54000 (63%)] Loss: -1757.053955\n",
      "Train Epoch: 548 [45056/54000 (83%)] Loss: -1754.730591\n",
      "    epoch          : 548\n",
      "    loss           : -1754.4190190153302\n",
      "    ess            : 26.634654530939066\n",
      "    log_marginal   : 1754.736150777565\n",
      "    val_loss       : -1752.7163187662761\n",
      "    val_ess        : 26.51018238067627\n",
      "    val_log_marginal: 1753.0404154459636\n",
      "Train Epoch: 549 [0/54000 (0%)] Loss: -1758.234619\n",
      "Train Epoch: 549 [11264/54000 (21%)] Loss: -1761.477661\n",
      "Train Epoch: 549 [22528/54000 (42%)] Loss: -1753.935791\n",
      "Train Epoch: 549 [33792/54000 (63%)] Loss: -1756.489380\n",
      "Train Epoch: 549 [45056/54000 (83%)] Loss: -1755.802368\n",
      "    epoch          : 549\n",
      "    loss           : -1755.8234713572376\n",
      "    ess            : 26.584485593831765\n",
      "    log_marginal   : 1756.143219569944\n",
      "    val_loss       : -1754.2717386881511\n",
      "    val_ess        : 26.362639904022217\n",
      "    val_log_marginal: 1754.6072489420574\n",
      "Train Epoch: 550 [0/54000 (0%)] Loss: -1759.672119\n",
      "Train Epoch: 550 [11264/54000 (21%)] Loss: -1764.188110\n",
      "Train Epoch: 550 [22528/54000 (42%)] Loss: -1759.115845\n",
      "Train Epoch: 550 [33792/54000 (63%)] Loss: -1761.557861\n",
      "Train Epoch: 550 [45056/54000 (83%)] Loss: -1753.187500\n",
      "    epoch          : 550\n",
      "    loss           : -1756.9974307654038\n",
      "    ess            : 26.545381276112682\n",
      "    log_marginal   : 1757.3235888211232\n",
      "    val_loss       : -1755.8120625813801\n",
      "    val_ess        : 26.429773966471355\n",
      "    val_log_marginal: 1756.1381123860676\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch550.pth ...\n",
      "Train Epoch: 551 [0/54000 (0%)] Loss: -1759.808716\n",
      "Train Epoch: 551 [11264/54000 (21%)] Loss: -1759.759766\n",
      "Train Epoch: 551 [22528/54000 (42%)] Loss: -1756.447510\n",
      "Train Epoch: 551 [33792/54000 (63%)] Loss: -1757.768921\n",
      "Train Epoch: 551 [45056/54000 (83%)] Loss: -1755.577881\n",
      "    epoch          : 551\n",
      "    loss           : -1758.045161409198\n",
      "    ess            : 26.540841498464907\n",
      "    log_marginal   : 1758.3728257665093\n",
      "    val_loss       : -1756.7322489420574\n",
      "    val_ess        : 26.8120862642924\n",
      "    val_log_marginal: 1757.0376993815105\n",
      "Train Epoch: 552 [0/54000 (0%)] Loss: -1758.588135\n",
      "Train Epoch: 552 [11264/54000 (21%)] Loss: -1760.995850\n",
      "Train Epoch: 552 [22528/54000 (42%)] Loss: -1755.114014\n",
      "Train Epoch: 552 [33792/54000 (63%)] Loss: -1756.245850\n",
      "Train Epoch: 552 [45056/54000 (83%)] Loss: -1763.047363\n",
      "    epoch          : 552\n",
      "    loss           : -1758.7898789891656\n",
      "    ess            : 26.624955771104347\n",
      "    log_marginal   : 1759.1141357421875\n",
      "    val_loss       : -1754.2716776529949\n",
      "    val_ess        : 26.692733446757\n",
      "    val_log_marginal: 1754.6014506022136\n",
      "Train Epoch: 553 [0/54000 (0%)] Loss: -1760.490479\n",
      "Train Epoch: 553 [11264/54000 (21%)] Loss: -1692.997559\n",
      "Train Epoch: 553 [22528/54000 (42%)] Loss: -1716.770142\n",
      "Train Epoch: 553 [33792/54000 (63%)] Loss: -1718.063477\n",
      "Train Epoch: 553 [45056/54000 (83%)] Loss: -1714.244629\n",
      "    epoch          : 553\n",
      "    loss           : -1718.555626059478\n",
      "    ess            : 26.390517990544158\n",
      "    log_marginal   : 1718.8686362212559\n",
      "    val_loss       : -1720.8490091959636\n",
      "    val_ess        : 26.59014892578125\n",
      "    val_log_marginal: 1721.1330871582031\n",
      "Train Epoch: 554 [0/54000 (0%)] Loss: -1731.363525\n",
      "Train Epoch: 554 [11264/54000 (21%)] Loss: -1735.568848\n",
      "Train Epoch: 554 [22528/54000 (42%)] Loss: -1739.855957\n",
      "Train Epoch: 554 [33792/54000 (63%)] Loss: -1737.953369\n",
      "Train Epoch: 554 [45056/54000 (83%)] Loss: -1735.895508\n",
      "    epoch          : 554\n",
      "    loss           : -1738.7806177679097\n",
      "    ess            : 27.555348018430315\n",
      "    log_marginal   : 1739.0328737654777\n",
      "    val_loss       : -1736.69189453125\n",
      "    val_ess        : 27.5957989692688\n",
      "    val_log_marginal: 1736.9417928059895\n",
      "Train Epoch: 555 [0/54000 (0%)] Loss: -1745.629028\n",
      "Train Epoch: 555 [11264/54000 (21%)] Loss: -1750.081909\n",
      "Train Epoch: 555 [22528/54000 (42%)] Loss: -1742.386108\n",
      "Train Epoch: 555 [33792/54000 (63%)] Loss: -1740.263916\n",
      "Train Epoch: 555 [45056/54000 (83%)] Loss: -1744.942139\n",
      "    epoch          : 555\n",
      "    loss           : -1746.3064909161262\n",
      "    ess            : 26.73775377813375\n",
      "    log_marginal   : 1746.6063566387825\n",
      "    val_loss       : -1743.5772603352864\n",
      "    val_ess        : 26.837665875752766\n",
      "    val_log_marginal: 1743.8784790039062\n",
      "Train Epoch: 556 [0/54000 (0%)] Loss: -1749.177002\n",
      "Train Epoch: 556 [11264/54000 (21%)] Loss: -1747.478027\n",
      "Train Epoch: 556 [22528/54000 (42%)] Loss: -1748.731445\n",
      "Train Epoch: 556 [33792/54000 (63%)] Loss: -1746.585205\n",
      "Train Epoch: 556 [45056/54000 (83%)] Loss: -1755.857422\n",
      "    epoch          : 556\n",
      "    loss           : -1749.363012925634\n",
      "    ess            : 26.532228217934662\n",
      "    log_marginal   : 1749.678508254717\n",
      "    val_loss       : -1746.9304911295574\n",
      "    val_ess        : 26.569403807322185\n",
      "    val_log_marginal: 1747.2473653157551\n",
      "Train Epoch: 557 [0/54000 (0%)] Loss: -1751.710938\n",
      "Train Epoch: 557 [11264/54000 (21%)] Loss: -1745.942017\n",
      "Train Epoch: 557 [22528/54000 (42%)] Loss: -1746.807861\n",
      "Train Epoch: 557 [33792/54000 (63%)] Loss: -1753.135010\n",
      "Train Epoch: 557 [45056/54000 (83%)] Loss: -1747.385864\n",
      "    epoch          : 557\n",
      "    loss           : -1751.3060867021668\n",
      "    ess            : 26.5732629524087\n",
      "    log_marginal   : 1751.6205985591096\n",
      "    val_loss       : -1748.6560160319011\n",
      "    val_ess        : 26.45503282546997\n",
      "    val_log_marginal: 1748.9976704915364\n",
      "Train Epoch: 558 [0/54000 (0%)] Loss: -1750.983154\n",
      "Train Epoch: 558 [11264/54000 (21%)] Loss: -1755.863525\n",
      "Train Epoch: 558 [22528/54000 (42%)] Loss: -1755.880859\n",
      "Train Epoch: 558 [33792/54000 (63%)] Loss: -1752.590576\n",
      "Train Epoch: 558 [45056/54000 (83%)] Loss: -1755.176147\n",
      "    epoch          : 558\n",
      "    loss           : -1752.8511053121315\n",
      "    ess            : 26.602666279055036\n",
      "    log_marginal   : 1753.1676370872642\n",
      "    val_loss       : -1750.5525410970051\n",
      "    val_ess        : 26.64762846628825\n",
      "    val_log_marginal: 1750.8577168782551\n",
      "Train Epoch: 559 [0/54000 (0%)] Loss: -1756.428711\n",
      "Train Epoch: 559 [11264/54000 (21%)] Loss: -1755.546631\n",
      "Train Epoch: 559 [22528/54000 (42%)] Loss: -1753.834229\n",
      "Train Epoch: 559 [33792/54000 (63%)] Loss: -1751.123291\n",
      "Train Epoch: 559 [45056/54000 (83%)] Loss: -1756.844971\n",
      "    epoch          : 559\n",
      "    loss           : -1754.072497097951\n",
      "    ess            : 26.550299086660708\n",
      "    log_marginal   : 1754.3917973356427\n",
      "    val_loss       : -1751.4881286621094\n",
      "    val_ess        : 26.66960334777832\n",
      "    val_log_marginal: 1751.8037007649739\n",
      "Train Epoch: 560 [0/54000 (0%)] Loss: -1763.644531\n",
      "Train Epoch: 560 [11264/54000 (21%)] Loss: -1753.427979\n",
      "Train Epoch: 560 [22528/54000 (42%)] Loss: -1749.872803\n",
      "Train Epoch: 560 [33792/54000 (63%)] Loss: -1747.455322\n",
      "Train Epoch: 560 [45056/54000 (83%)] Loss: -1711.466064\n",
      "    epoch          : 560\n",
      "    loss           : -1741.7229533645343\n",
      "    ess            : 26.476201255366487\n",
      "    log_marginal   : 1742.044151450103\n",
      "    val_loss       : -1739.4819844563801\n",
      "    val_ess        : 26.623396078745525\n",
      "    val_log_marginal: 1739.7926127115886\n",
      "Train Epoch: 561 [0/54000 (0%)] Loss: -1733.978149\n",
      "Train Epoch: 561 [11264/54000 (21%)] Loss: -1737.089600\n",
      "Train Epoch: 561 [22528/54000 (42%)] Loss: -1739.633789\n",
      "Train Epoch: 561 [33792/54000 (63%)] Loss: -1734.991333\n",
      "Train Epoch: 561 [45056/54000 (83%)] Loss: -1738.580933\n",
      "    epoch          : 561\n",
      "    loss           : -1737.2612707749852\n",
      "    ess            : 26.891213165139252\n",
      "    log_marginal   : 1737.5567661501327\n",
      "    val_loss       : -1742.0906880696614\n",
      "    val_ess        : 26.994788964589436\n",
      "    val_log_marginal: 1742.3782857259114\n",
      "Train Epoch: 562 [0/54000 (0%)] Loss: -1747.177246\n",
      "Train Epoch: 562 [11264/54000 (21%)] Loss: -1753.151611\n",
      "Train Epoch: 562 [22528/54000 (42%)] Loss: -1747.771973\n",
      "Train Epoch: 562 [33792/54000 (63%)] Loss: -1745.882324\n",
      "Train Epoch: 562 [45056/54000 (83%)] Loss: -1747.376587\n",
      "    epoch          : 562\n",
      "    loss           : -1747.8026238207547\n",
      "    ess            : 27.034594769747752\n",
      "    log_marginal   : 1748.0864718455189\n",
      "    val_loss       : -1748.0248006184895\n",
      "    val_ess        : 26.90964412689209\n",
      "    val_log_marginal: 1748.3073628743489\n",
      "Train Epoch: 563 [0/54000 (0%)] Loss: -1745.895142\n",
      "Train Epoch: 563 [11264/54000 (21%)] Loss: -1746.417236\n",
      "Train Epoch: 563 [22528/54000 (42%)] Loss: -1753.673340\n",
      "Train Epoch: 563 [33792/54000 (63%)] Loss: -1747.953247\n",
      "Train Epoch: 563 [45056/54000 (83%)] Loss: -1758.427490\n",
      "    epoch          : 563\n",
      "    loss           : -1751.5700913915093\n",
      "    ess            : 26.66374024805033\n",
      "    log_marginal   : 1751.8790559588738\n",
      "    val_loss       : -1751.7864278157551\n",
      "    val_ess        : 26.45793628692627\n",
      "    val_log_marginal: 1752.1156412760417\n",
      "Train Epoch: 564 [0/54000 (0%)] Loss: -1752.072021\n",
      "Train Epoch: 564 [11264/54000 (21%)] Loss: -1753.975342\n",
      "Train Epoch: 564 [22528/54000 (42%)] Loss: -1754.336914\n",
      "Train Epoch: 564 [33792/54000 (63%)] Loss: -1755.533203\n",
      "Train Epoch: 564 [45056/54000 (83%)] Loss: -1752.471802\n",
      "    epoch          : 564\n",
      "    loss           : -1753.4501642191185\n",
      "    ess            : 26.588258041525787\n",
      "    log_marginal   : 1753.771351940227\n",
      "    val_loss       : -1753.4330444335938\n",
      "    val_ess        : 26.601895332336426\n",
      "    val_log_marginal: 1753.7557067871094\n",
      "Train Epoch: 565 [0/54000 (0%)] Loss: -1756.593262\n",
      "Train Epoch: 565 [11264/54000 (21%)] Loss: -1755.951660\n",
      "Train Epoch: 565 [22528/54000 (42%)] Loss: -1752.227661\n",
      "Train Epoch: 565 [33792/54000 (63%)] Loss: -1756.441162\n",
      "Train Epoch: 565 [45056/54000 (83%)] Loss: -1750.562012\n",
      "    epoch          : 565\n",
      "    loss           : -1754.8104582012825\n",
      "    ess            : 26.591957416174548\n",
      "    log_marginal   : 1755.126489027491\n",
      "    val_loss       : -1754.3284200032551\n",
      "    val_ess        : 26.394401391347248\n",
      "    val_log_marginal: 1754.6636047363281\n",
      "Train Epoch: 566 [0/54000 (0%)] Loss: -1756.722412\n",
      "Train Epoch: 566 [11264/54000 (21%)] Loss: -1756.218018\n",
      "Train Epoch: 566 [22528/54000 (42%)] Loss: -1762.005493\n",
      "Train Epoch: 566 [33792/54000 (63%)] Loss: -1757.784546\n",
      "Train Epoch: 566 [45056/54000 (83%)] Loss: -1755.549805\n",
      "    epoch          : 566\n",
      "    loss           : -1756.037994960569\n",
      "    ess            : 26.541496672720278\n",
      "    log_marginal   : 1756.3623311744545\n",
      "    val_loss       : -1755.4159749348958\n",
      "    val_ess        : 26.596619764963787\n",
      "    val_log_marginal: 1755.7419331868489\n",
      "Train Epoch: 567 [0/54000 (0%)] Loss: -1757.535767\n",
      "Train Epoch: 567 [11264/54000 (21%)] Loss: -1758.131592\n",
      "Train Epoch: 567 [22528/54000 (42%)] Loss: -1759.860474\n",
      "Train Epoch: 567 [33792/54000 (63%)] Loss: -1751.427979\n",
      "Train Epoch: 567 [45056/54000 (83%)] Loss: -1753.592896\n",
      "    epoch          : 567\n",
      "    loss           : -1754.7299113723468\n",
      "    ess            : 26.60876704162022\n",
      "    log_marginal   : 1755.0519593436763\n",
      "    val_loss       : -1719.0079956054688\n",
      "    val_ess        : 26.597755591074627\n",
      "    val_log_marginal: 1719.3363037109375\n",
      "Train Epoch: 568 [0/54000 (0%)] Loss: -1721.996094\n",
      "Train Epoch: 568 [11264/54000 (21%)] Loss: -1729.908203\n",
      "Train Epoch: 568 [22528/54000 (42%)] Loss: -1747.253662\n",
      "Train Epoch: 568 [33792/54000 (63%)] Loss: -1747.900879\n",
      "Train Epoch: 568 [45056/54000 (83%)] Loss: -1718.385010\n",
      "    epoch          : 568\n",
      "    loss           : -1732.8712906747494\n",
      "    ess            : 26.618931770324707\n",
      "    log_marginal   : 1733.1780234282871\n",
      "    val_loss       : -1726.4433186848958\n",
      "    val_ess        : 27.668720722198486\n",
      "    val_log_marginal: 1726.6865641276042\n",
      "Train Epoch: 569 [0/54000 (0%)] Loss: -1734.021606\n",
      "Train Epoch: 569 [11264/54000 (21%)] Loss: -1741.908691\n",
      "Train Epoch: 569 [22528/54000 (42%)] Loss: -1741.529419\n",
      "Train Epoch: 569 [33792/54000 (63%)] Loss: -1742.515503\n",
      "Train Epoch: 569 [45056/54000 (83%)] Loss: -1745.087646\n",
      "    epoch          : 569\n",
      "    loss           : -1743.9123926702534\n",
      "    ess            : 27.22093996011986\n",
      "    log_marginal   : 1744.1886078456662\n",
      "    val_loss       : -1741.1134948730469\n",
      "    val_ess        : 27.32463280359904\n",
      "    val_log_marginal: 1741.3888753255208\n",
      "Train Epoch: 570 [0/54000 (0%)] Loss: -1751.751953\n",
      "Train Epoch: 570 [11264/54000 (21%)] Loss: -1753.956543\n",
      "Train Epoch: 570 [22528/54000 (42%)] Loss: -1747.725342\n",
      "Train Epoch: 570 [33792/54000 (63%)] Loss: -1750.321533\n",
      "Train Epoch: 570 [45056/54000 (83%)] Loss: -1750.862793\n",
      "    epoch          : 570\n",
      "    loss           : -1750.5143893259876\n",
      "    ess            : 26.771037569585836\n",
      "    log_marginal   : 1750.82435924602\n",
      "    val_loss       : -1748.9968668619792\n",
      "    val_ess        : 26.82918643951416\n",
      "    val_log_marginal: 1749.300760904948\n",
      "Train Epoch: 571 [0/54000 (0%)] Loss: -1749.719971\n",
      "Train Epoch: 571 [11264/54000 (21%)] Loss: -1754.376831\n",
      "Train Epoch: 571 [22528/54000 (42%)] Loss: -1752.478027\n",
      "Train Epoch: 571 [33792/54000 (63%)] Loss: -1756.511597\n",
      "Train Epoch: 571 [45056/54000 (83%)] Loss: -1748.469360\n",
      "    epoch          : 571\n",
      "    loss           : -1753.3066843860554\n",
      "    ess            : 26.562057675055737\n",
      "    log_marginal   : 1753.6332247752064\n",
      "    val_loss       : -1751.0770365397136\n",
      "    val_ess        : 26.671907424926758\n",
      "    val_log_marginal: 1751.3977661132812\n",
      "Train Epoch: 572 [0/54000 (0%)] Loss: -1757.909790\n",
      "Train Epoch: 572 [11264/54000 (21%)] Loss: -1754.169434\n",
      "Train Epoch: 572 [22528/54000 (42%)] Loss: -1754.615234\n",
      "Train Epoch: 572 [33792/54000 (63%)] Loss: -1756.339722\n",
      "Train Epoch: 572 [45056/54000 (83%)] Loss: -1751.755493\n",
      "    epoch          : 572\n",
      "    loss           : -1754.9339772350384\n",
      "    ess            : 26.614670105700224\n",
      "    log_marginal   : 1755.252321639151\n",
      "    val_loss       : -1753.1402893066406\n",
      "    val_ess        : 26.546876430511475\n",
      "    val_log_marginal: 1753.4614156087239\n",
      "Train Epoch: 573 [0/54000 (0%)] Loss: -1751.466675\n",
      "Train Epoch: 573 [11264/54000 (21%)] Loss: -1755.105225\n",
      "Train Epoch: 573 [22528/54000 (42%)] Loss: -1754.581421\n",
      "Train Epoch: 573 [33792/54000 (63%)] Loss: -1757.703125\n",
      "Train Epoch: 573 [45056/54000 (83%)] Loss: -1752.323608\n",
      "    epoch          : 573\n",
      "    loss           : -1756.2348367942955\n",
      "    ess            : 26.584375633383697\n",
      "    log_marginal   : 1756.5554682893573\n",
      "    val_loss       : -1754.325439453125\n",
      "    val_ess        : 26.34159294764201\n",
      "    val_log_marginal: 1754.6512044270833\n",
      "Train Epoch: 574 [0/54000 (0%)] Loss: -1759.658203\n",
      "Train Epoch: 574 [11264/54000 (21%)] Loss: -1759.735107\n",
      "Train Epoch: 574 [22528/54000 (42%)] Loss: -1757.923096\n",
      "Train Epoch: 574 [33792/54000 (63%)] Loss: -1753.728638\n",
      "Train Epoch: 574 [45056/54000 (83%)] Loss: -1755.462280\n",
      "    epoch          : 574\n",
      "    loss           : -1756.9150229400059\n",
      "    ess            : 26.675465853709095\n",
      "    log_marginal   : 1757.2327397184552\n",
      "    val_loss       : -1753.7518412272136\n",
      "    val_ess        : 26.7673126856486\n",
      "    val_log_marginal: 1754.0650939941406\n",
      "Train Epoch: 575 [0/54000 (0%)] Loss: -1760.422729\n",
      "Train Epoch: 575 [11264/54000 (21%)] Loss: -1735.786377\n",
      "Train Epoch: 575 [22528/54000 (42%)] Loss: -1724.820068\n",
      "Train Epoch: 575 [33792/54000 (63%)] Loss: -1731.354858\n",
      "Train Epoch: 575 [45056/54000 (83%)] Loss: -1731.997070\n",
      "    epoch          : 575\n",
      "    loss           : -1732.2637271521226\n",
      "    ess            : 26.51141762283613\n",
      "    log_marginal   : 1732.5789622180866\n",
      "    val_loss       : -1744.1158650716145\n",
      "    val_ess        : 26.456759293874104\n",
      "    val_log_marginal: 1744.4447835286458\n",
      "Train Epoch: 576 [0/54000 (0%)] Loss: -1738.625732\n",
      "Train Epoch: 576 [11264/54000 (21%)] Loss: -1747.653320\n",
      "Train Epoch: 576 [22528/54000 (42%)] Loss: -1738.752197\n",
      "Train Epoch: 576 [33792/54000 (63%)] Loss: -1745.397339\n",
      "Train Epoch: 576 [45056/54000 (83%)] Loss: -1748.104980\n",
      "    epoch          : 576\n",
      "    loss           : -1744.7058220629422\n",
      "    ess            : 27.317059444931317\n",
      "    log_marginal   : 1744.9763747881043\n",
      "    val_loss       : -1749.4984334309895\n",
      "    val_ess        : 26.94576581319173\n",
      "    val_log_marginal: 1749.7952677408855\n",
      "Train Epoch: 577 [0/54000 (0%)] Loss: -1752.726440\n",
      "Train Epoch: 577 [11264/54000 (21%)] Loss: -1749.199097\n",
      "Train Epoch: 577 [22528/54000 (42%)] Loss: -1753.348389\n",
      "Train Epoch: 577 [33792/54000 (63%)] Loss: -1747.608276\n",
      "Train Epoch: 577 [45056/54000 (83%)] Loss: -1753.026855\n",
      "    epoch          : 577\n",
      "    loss           : -1750.3181002634876\n",
      "    ess            : 26.808189518046827\n",
      "    log_marginal   : 1750.621888358638\n",
      "    val_loss       : -1752.3265584309895\n",
      "    val_ess        : 26.308191299438477\n",
      "    val_log_marginal: 1752.6641540527344\n",
      "Train Epoch: 578 [0/54000 (0%)] Loss: -1755.321289\n",
      "Train Epoch: 578 [11264/54000 (21%)] Loss: -1745.401123\n",
      "Train Epoch: 578 [22528/54000 (42%)] Loss: -1752.349609\n",
      "Train Epoch: 578 [33792/54000 (63%)] Loss: -1752.951904\n",
      "Train Epoch: 578 [45056/54000 (83%)] Loss: -1747.411133\n",
      "    epoch          : 578\n",
      "    loss           : -1752.6657415426002\n",
      "    ess            : 26.607668120906038\n",
      "    log_marginal   : 1752.9872885650059\n",
      "    val_loss       : -1753.9367065429688\n",
      "    val_ess        : 26.685333093007404\n",
      "    val_log_marginal: 1754.2481892903645\n",
      "Train Epoch: 579 [0/54000 (0%)] Loss: -1758.040894\n",
      "Train Epoch: 579 [11264/54000 (21%)] Loss: -1757.824951\n",
      "Train Epoch: 579 [22528/54000 (42%)] Loss: -1760.058838\n",
      "Train Epoch: 579 [33792/54000 (63%)] Loss: -1749.829346\n",
      "Train Epoch: 579 [45056/54000 (83%)] Loss: -1758.393921\n",
      "    epoch          : 579\n",
      "    loss           : -1754.342342736586\n",
      "    ess            : 26.56677528597274\n",
      "    log_marginal   : 1754.6656494140625\n",
      "    val_loss       : -1754.666483561198\n",
      "    val_ess        : 26.454249540964764\n",
      "    val_log_marginal: 1755.0034281412761\n",
      "Train Epoch: 580 [0/54000 (0%)] Loss: -1754.012939\n",
      "Train Epoch: 580 [11264/54000 (21%)] Loss: -1755.320679\n",
      "Train Epoch: 580 [22528/54000 (42%)] Loss: -1756.390991\n",
      "Train Epoch: 580 [33792/54000 (63%)] Loss: -1753.366211\n",
      "Train Epoch: 580 [45056/54000 (83%)] Loss: -1758.032959\n",
      "    epoch          : 580\n",
      "    loss           : -1755.6085654204746\n",
      "    ess            : 26.56413753077669\n",
      "    log_marginal   : 1755.9323983822228\n",
      "    val_loss       : -1755.8276672363281\n",
      "    val_ess        : 26.27491505940755\n",
      "    val_log_marginal: 1756.1658223470051\n",
      "Train Epoch: 581 [0/54000 (0%)] Loss: -1759.218018\n",
      "Train Epoch: 581 [11264/54000 (21%)] Loss: -1753.383911\n",
      "Train Epoch: 581 [22528/54000 (42%)] Loss: -1762.249023\n",
      "Train Epoch: 581 [33792/54000 (63%)] Loss: -1757.167236\n",
      "Train Epoch: 581 [45056/54000 (83%)] Loss: -1755.837646\n",
      "    epoch          : 581\n",
      "    loss           : -1756.453046690743\n",
      "    ess            : 26.620313554439903\n",
      "    log_marginal   : 1756.7759272737323\n",
      "    val_loss       : -1755.7878824869792\n",
      "    val_ess        : 26.80013418197632\n",
      "    val_log_marginal: 1756.0997212727864\n",
      "Train Epoch: 582 [0/54000 (0%)] Loss: -1761.564941\n",
      "Train Epoch: 582 [11264/54000 (21%)] Loss: -1754.588867\n",
      "Train Epoch: 582 [22528/54000 (42%)] Loss: -1756.173950\n",
      "Train Epoch: 582 [33792/54000 (63%)] Loss: -1738.745728\n",
      "Train Epoch: 582 [45056/54000 (83%)] Loss: -1748.304688\n",
      "    epoch          : 582\n",
      "    loss           : -1751.6964975033166\n",
      "    ess            : 26.611497861034465\n",
      "    log_marginal   : 1752.0175953991009\n",
      "    val_loss       : -1750.6168924967449\n",
      "    val_ess        : 26.569546381632488\n",
      "    val_log_marginal: 1750.9412129720051\n",
      "Train Epoch: 583 [0/54000 (0%)] Loss: -1750.950195\n",
      "Train Epoch: 583 [11264/54000 (21%)] Loss: -1746.914062\n",
      "Train Epoch: 583 [22528/54000 (42%)] Loss: -1702.904785\n",
      "Train Epoch: 583 [33792/54000 (63%)] Loss: -1713.660767\n",
      "Train Epoch: 583 [45056/54000 (83%)] Loss: -1729.050049\n",
      "    epoch          : 583\n",
      "    loss           : -1727.6968234080189\n",
      "    ess            : 26.7131430068106\n",
      "    log_marginal   : 1727.9974111880897\n",
      "    val_loss       : -1737.6271158854167\n",
      "    val_ess        : 26.618987719217937\n",
      "    val_log_marginal: 1737.9367574055989\n",
      "Train Epoch: 584 [0/54000 (0%)] Loss: -1737.514160\n",
      "Train Epoch: 584 [11264/54000 (21%)] Loss: -1736.010132\n",
      "Train Epoch: 584 [22528/54000 (42%)] Loss: -1741.888306\n",
      "Train Epoch: 584 [33792/54000 (63%)] Loss: -1740.540771\n",
      "Train Epoch: 584 [45056/54000 (83%)] Loss: -1744.537964\n",
      "    epoch          : 584\n",
      "    loss           : -1741.409101378243\n",
      "    ess            : 27.363536312895\n",
      "    log_marginal   : 1741.6769547372494\n",
      "    val_loss       : -1747.3271484375\n",
      "    val_ess        : 27.131372451782227\n",
      "    val_log_marginal: 1747.6018371582031\n",
      "Train Epoch: 585 [0/54000 (0%)] Loss: -1747.256592\n",
      "Train Epoch: 585 [11264/54000 (21%)] Loss: -1748.511597\n",
      "Train Epoch: 585 [22528/54000 (42%)] Loss: -1748.693604\n",
      "Train Epoch: 585 [33792/54000 (63%)] Loss: -1747.610352\n",
      "Train Epoch: 585 [45056/54000 (83%)] Loss: -1746.343262\n",
      "    epoch          : 585\n",
      "    loss           : -1748.1995561707695\n",
      "    ess            : 26.812981785468335\n",
      "    log_marginal   : 1748.5013577443249\n",
      "    val_loss       : -1751.352315266927\n",
      "    val_ess        : 26.35739008585612\n",
      "    val_log_marginal: 1751.6774597167969\n",
      "Train Epoch: 586 [0/54000 (0%)] Loss: -1749.171875\n",
      "Train Epoch: 586 [11264/54000 (21%)] Loss: -1749.047852\n",
      "Train Epoch: 586 [22528/54000 (42%)] Loss: -1748.410400\n",
      "Train Epoch: 586 [33792/54000 (63%)] Loss: -1745.971191\n",
      "Train Epoch: 586 [45056/54000 (83%)] Loss: -1756.464355\n",
      "    epoch          : 586\n",
      "    loss           : -1751.0623698684406\n",
      "    ess            : 26.54603049440204\n",
      "    log_marginal   : 1751.3835771668632\n",
      "    val_loss       : -1753.1238606770833\n",
      "    val_ess        : 26.27961317698161\n",
      "    val_log_marginal: 1753.455586751302\n",
      "Train Epoch: 587 [0/54000 (0%)] Loss: -1751.596436\n",
      "Train Epoch: 587 [11264/54000 (21%)] Loss: -1754.026489\n",
      "Train Epoch: 587 [22528/54000 (42%)] Loss: -1745.205811\n",
      "Train Epoch: 587 [33792/54000 (63%)] Loss: -1757.050537\n",
      "Train Epoch: 587 [45056/54000 (83%)] Loss: -1756.180664\n",
      "    epoch          : 587\n",
      "    loss           : -1752.9049521392246\n",
      "    ess            : 26.555744692964375\n",
      "    log_marginal   : 1753.2238228276092\n",
      "    val_loss       : -1754.1937967936199\n",
      "    val_ess        : 26.45377016067505\n",
      "    val_log_marginal: 1754.5289103190105\n",
      "Train Epoch: 588 [0/54000 (0%)] Loss: -1756.441406\n",
      "Train Epoch: 588 [11264/54000 (21%)] Loss: -1757.341431\n",
      "Train Epoch: 588 [22528/54000 (42%)] Loss: -1752.334961\n",
      "Train Epoch: 588 [33792/54000 (63%)] Loss: -1750.152588\n",
      "Train Epoch: 588 [45056/54000 (83%)] Loss: -1753.414917\n",
      "    epoch          : 588\n",
      "    loss           : -1754.2683128500885\n",
      "    ess            : 26.517626798377847\n",
      "    log_marginal   : 1754.5922241210938\n",
      "    val_loss       : -1754.9818827311199\n",
      "    val_ess        : 26.46202850341797\n",
      "    val_log_marginal: 1755.3116760253906\n",
      "Train Epoch: 589 [0/54000 (0%)] Loss: -1760.695435\n",
      "Train Epoch: 589 [11264/54000 (21%)] Loss: -1753.724121\n",
      "Train Epoch: 589 [22528/54000 (42%)] Loss: -1745.395020\n",
      "Train Epoch: 589 [33792/54000 (63%)] Loss: -1737.720825\n",
      "Train Epoch: 589 [45056/54000 (83%)] Loss: -1745.489990\n",
      "    epoch          : 589\n",
      "    loss           : -1747.6253800302181\n",
      "    ess            : 26.549316028379046\n",
      "    log_marginal   : 1747.9460472250885\n",
      "    val_loss       : -1748.059102376302\n",
      "    val_ess        : 26.33029572168986\n",
      "    val_log_marginal: 1748.3883768717449\n",
      "Train Epoch: 590 [0/54000 (0%)] Loss: -1752.005249\n",
      "Train Epoch: 590 [11264/54000 (21%)] Loss: -1750.437134\n",
      "Train Epoch: 590 [22528/54000 (42%)] Loss: -1750.067261\n",
      "Train Epoch: 590 [33792/54000 (63%)] Loss: -1749.083130\n",
      "Train Epoch: 590 [45056/54000 (83%)] Loss: -1752.600586\n",
      "    epoch          : 590\n",
      "    loss           : -1751.5607553158166\n",
      "    ess            : 26.735593597843962\n",
      "    log_marginal   : 1751.872807340802\n",
      "    val_loss       : -1753.8903910319011\n",
      "    val_ess        : 26.619516849517822\n",
      "    val_log_marginal: 1754.2089029947917\n",
      "Train Epoch: 591 [0/54000 (0%)] Loss: -1753.581787\n",
      "Train Epoch: 591 [11264/54000 (21%)] Loss: -1755.774658\n",
      "Train Epoch: 591 [22528/54000 (42%)] Loss: -1758.174194\n",
      "Train Epoch: 591 [33792/54000 (63%)] Loss: -1753.838623\n",
      "Train Epoch: 591 [45056/54000 (83%)] Loss: -1752.927734\n",
      "    epoch          : 591\n",
      "    loss           : -1754.8322857550854\n",
      "    ess            : 26.679308639382416\n",
      "    log_marginal   : 1755.1471949163472\n",
      "    val_loss       : -1755.6571044921875\n",
      "    val_ess        : 26.67557160059611\n",
      "    val_log_marginal: 1755.9838765462239\n",
      "Train Epoch: 592 [0/54000 (0%)] Loss: -1758.818848\n",
      "Train Epoch: 592 [11264/54000 (21%)] Loss: -1757.707031\n",
      "Train Epoch: 592 [22528/54000 (42%)] Loss: -1762.618286\n",
      "Train Epoch: 592 [33792/54000 (63%)] Loss: -1751.123169\n",
      "Train Epoch: 592 [45056/54000 (83%)] Loss: -1754.585449\n",
      "    epoch          : 592\n",
      "    loss           : -1756.3956448536999\n",
      "    ess            : 26.56909240866607\n",
      "    log_marginal   : 1756.7227483785377\n",
      "    val_loss       : -1756.9936828613281\n",
      "    val_ess        : 26.47931957244873\n",
      "    val_log_marginal: 1757.3140665690105\n",
      "Train Epoch: 593 [0/54000 (0%)] Loss: -1756.823730\n",
      "Train Epoch: 593 [11264/54000 (21%)] Loss: -1761.917603\n",
      "Train Epoch: 593 [22528/54000 (42%)] Loss: -1758.068115\n",
      "Train Epoch: 593 [33792/54000 (63%)] Loss: -1760.302612\n",
      "Train Epoch: 593 [45056/54000 (83%)] Loss: -1752.440186\n",
      "    epoch          : 593\n",
      "    loss           : -1757.5333044663914\n",
      "    ess            : 26.58578539794346\n",
      "    log_marginal   : 1757.8600302642246\n",
      "    val_loss       : -1757.6453552246094\n",
      "    val_ess        : 26.38502820332845\n",
      "    val_log_marginal: 1757.9906412760417\n",
      "Train Epoch: 594 [0/54000 (0%)] Loss: -1759.433838\n",
      "Train Epoch: 594 [11264/54000 (21%)] Loss: -1760.525635\n",
      "Train Epoch: 594 [22528/54000 (42%)] Loss: -1761.232666\n",
      "Train Epoch: 594 [33792/54000 (63%)] Loss: -1757.956543\n",
      "Train Epoch: 594 [45056/54000 (83%)] Loss: -1763.446289\n",
      "    epoch          : 594\n",
      "    loss           : -1758.4935982182342\n",
      "    ess            : 26.60783402424938\n",
      "    log_marginal   : 1758.8223162956958\n",
      "    val_loss       : -1758.3314717610676\n",
      "    val_ess        : 26.76996835072835\n",
      "    val_log_marginal: 1758.6353251139324\n",
      "Train Epoch: 595 [0/54000 (0%)] Loss: -1759.422363\n",
      "Train Epoch: 595 [11264/54000 (21%)] Loss: -1760.608643\n",
      "Train Epoch: 595 [22528/54000 (42%)] Loss: -1763.983887\n",
      "Train Epoch: 595 [33792/54000 (63%)] Loss: -1757.725708\n",
      "Train Epoch: 595 [45056/54000 (83%)] Loss: -1754.131836\n",
      "    epoch          : 595\n",
      "    loss           : -1759.110136212043\n",
      "    ess            : 26.701573659788888\n",
      "    log_marginal   : 1759.4265528265034\n",
      "    val_loss       : -1757.8824564615886\n",
      "    val_ess        : 26.761638005574543\n",
      "    val_log_marginal: 1758.2053934733074\n",
      "Train Epoch: 596 [0/54000 (0%)] Loss: -1762.366089\n",
      "Train Epoch: 596 [11264/54000 (21%)] Loss: -1752.778809\n",
      "Train Epoch: 596 [22528/54000 (42%)] Loss: -1720.776978\n",
      "Train Epoch: 596 [33792/54000 (63%)] Loss: -1743.296875\n",
      "Train Epoch: 596 [45056/54000 (83%)] Loss: -1731.351929\n",
      "    epoch          : 596\n",
      "    loss           : -1737.8270010318397\n",
      "    ess            : 26.620534518979632\n",
      "    log_marginal   : 1738.1416476267689\n",
      "    val_loss       : -1723.7514546712239\n",
      "    val_ess        : 26.51671250661214\n",
      "    val_log_marginal: 1724.0671488444011\n",
      "Train Epoch: 597 [0/54000 (0%)] Loss: -1729.040527\n",
      "Train Epoch: 597 [11264/54000 (21%)] Loss: -1742.454834\n",
      "Train Epoch: 597 [22528/54000 (42%)] Loss: -1749.593262\n",
      "Train Epoch: 597 [33792/54000 (63%)] Loss: -1753.842529\n",
      "Train Epoch: 597 [45056/54000 (83%)] Loss: -1749.542969\n",
      "    epoch          : 597\n",
      "    loss           : -1745.160740114608\n",
      "    ess            : 27.263673728367067\n",
      "    log_marginal   : 1745.437342229879\n",
      "    val_loss       : -1734.2198588053386\n",
      "    val_ess        : 27.808266003926594\n",
      "    val_log_marginal: 1734.4656168619792\n",
      "Train Epoch: 598 [0/54000 (0%)] Loss: -1754.306885\n",
      "Train Epoch: 598 [11264/54000 (21%)] Loss: -1753.937256\n",
      "Train Epoch: 598 [22528/54000 (42%)] Loss: -1757.291626\n",
      "Train Epoch: 598 [33792/54000 (63%)] Loss: -1748.665283\n",
      "Train Epoch: 598 [45056/54000 (83%)] Loss: -1753.955566\n",
      "    epoch          : 598\n",
      "    loss           : -1752.5111452498527\n",
      "    ess            : 26.934320773718493\n",
      "    log_marginal   : 1752.809546128759\n",
      "    val_loss       : -1745.0924784342449\n",
      "    val_ess        : 27.206849575042725\n",
      "    val_log_marginal: 1745.3796997070312\n",
      "Train Epoch: 599 [0/54000 (0%)] Loss: -1758.092163\n",
      "Train Epoch: 599 [11264/54000 (21%)] Loss: -1759.837402\n",
      "Train Epoch: 599 [22528/54000 (42%)] Loss: -1757.152588\n",
      "Train Epoch: 599 [33792/54000 (63%)] Loss: -1756.476807\n",
      "Train Epoch: 599 [45056/54000 (83%)] Loss: -1753.706299\n",
      "    epoch          : 599\n",
      "    loss           : -1755.627709730616\n",
      "    ess            : 26.678064310325766\n",
      "    log_marginal   : 1755.9455428213444\n",
      "    val_loss       : -1749.3473510742188\n",
      "    val_ess        : 26.923136075337727\n",
      "    val_log_marginal: 1749.6510111490886\n",
      "Train Epoch: 600 [0/54000 (0%)] Loss: -1756.441406\n",
      "Train Epoch: 600 [11264/54000 (21%)] Loss: -1755.057129\n",
      "Train Epoch: 600 [22528/54000 (42%)] Loss: -1755.026123\n",
      "Train Epoch: 600 [33792/54000 (63%)] Loss: -1754.598877\n",
      "Train Epoch: 600 [45056/54000 (83%)] Loss: -1758.303101\n",
      "    epoch          : 600\n",
      "    loss           : -1757.258077369546\n",
      "    ess            : 26.67934126224158\n",
      "    log_marginal   : 1757.5786743164062\n",
      "    val_loss       : -1751.5902201334636\n",
      "    val_ess        : 26.776797612508137\n",
      "    val_log_marginal: 1751.9154968261719\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [0/54000 (0%)] Loss: -1754.598511\n",
      "Train Epoch: 601 [11264/54000 (21%)] Loss: -1762.333008\n",
      "Train Epoch: 601 [22528/54000 (42%)] Loss: -1757.337769\n",
      "Train Epoch: 601 [33792/54000 (63%)] Loss: -1760.464966\n",
      "Train Epoch: 601 [45056/54000 (83%)] Loss: -1760.205078\n",
      "    epoch          : 601\n",
      "    loss           : -1758.6191302605396\n",
      "    ess            : 26.715882607226103\n",
      "    log_marginal   : 1758.938000948924\n",
      "    val_loss       : -1752.8453776041667\n",
      "    val_ess        : 26.691855748494465\n",
      "    val_log_marginal: 1753.1835632324219\n",
      "Train Epoch: 602 [0/54000 (0%)] Loss: -1762.676758\n",
      "Train Epoch: 602 [11264/54000 (21%)] Loss: -1763.414062\n",
      "Train Epoch: 602 [22528/54000 (42%)] Loss: -1760.321655\n",
      "Train Epoch: 602 [33792/54000 (63%)] Loss: -1760.725098\n",
      "Train Epoch: 602 [45056/54000 (83%)] Loss: -1759.929199\n",
      "    epoch          : 602\n",
      "    loss           : -1759.6707798220077\n",
      "    ess            : 26.795422949880923\n",
      "    log_marginal   : 1759.9895756559552\n",
      "    val_loss       : -1754.8205871582031\n",
      "    val_ess        : 26.689590454101562\n",
      "    val_log_marginal: 1755.1528422037761\n",
      "Train Epoch: 603 [0/54000 (0%)] Loss: -1759.046997\n",
      "Train Epoch: 603 [11264/54000 (21%)] Loss: -1759.715576\n",
      "Train Epoch: 603 [22528/54000 (42%)] Loss: -1759.938354\n",
      "Train Epoch: 603 [33792/54000 (63%)] Loss: -1764.302734\n",
      "Train Epoch: 603 [45056/54000 (83%)] Loss: -1759.764648\n",
      "    epoch          : 603\n",
      "    loss           : -1760.6356742427033\n",
      "    ess            : 26.698026711086058\n",
      "    log_marginal   : 1760.958508761424\n",
      "    val_loss       : -1755.7097574869792\n",
      "    val_ess        : 26.621864477793377\n",
      "    val_log_marginal: 1756.0305989583333\n",
      "Train Epoch: 604 [0/54000 (0%)] Loss: -1760.234375\n",
      "Train Epoch: 604 [11264/54000 (21%)] Loss: -1760.492676\n",
      "Train Epoch: 604 [22528/54000 (42%)] Loss: -1764.162354\n",
      "Train Epoch: 604 [33792/54000 (63%)] Loss: -1763.731079\n",
      "Train Epoch: 604 [45056/54000 (83%)] Loss: -1757.764893\n",
      "    epoch          : 604\n",
      "    loss           : -1761.5284205022847\n",
      "    ess            : 26.698204508367574\n",
      "    log_marginal   : 1761.8487399119251\n",
      "    val_loss       : -1757.2556559244792\n",
      "    val_ess        : 26.588962237040203\n",
      "    val_log_marginal: 1757.5960591634114\n",
      "Train Epoch: 605 [0/54000 (0%)] Loss: -1758.813477\n",
      "Train Epoch: 605 [11264/54000 (21%)] Loss: -1766.246826\n",
      "Train Epoch: 605 [22528/54000 (42%)] Loss: -1764.880737\n",
      "Train Epoch: 605 [33792/54000 (63%)] Loss: -1761.761963\n",
      "Train Epoch: 605 [45056/54000 (83%)] Loss: -1761.569458\n",
      "    epoch          : 605\n",
      "    loss           : -1762.30768743551\n",
      "    ess            : 26.711180650962973\n",
      "    log_marginal   : 1762.6287899377212\n",
      "    val_loss       : -1758.2624409993489\n",
      "    val_ess        : 26.57169198989868\n",
      "    val_log_marginal: 1758.5976867675781\n",
      "Train Epoch: 606 [0/54000 (0%)] Loss: -1766.407471\n",
      "Train Epoch: 606 [11264/54000 (21%)] Loss: -1759.855469\n",
      "Train Epoch: 606 [22528/54000 (42%)] Loss: -1764.914551\n",
      "Train Epoch: 606 [33792/54000 (63%)] Loss: -1757.782471\n",
      "Train Epoch: 606 [45056/54000 (83%)] Loss: -1759.707397\n",
      "    epoch          : 606\n",
      "    loss           : -1762.9638856132076\n",
      "    ess            : 26.75140897283014\n",
      "    log_marginal   : 1763.2830660838001\n",
      "    val_loss       : -1757.5478210449219\n",
      "    val_ess        : 26.565663814544678\n",
      "    val_log_marginal: 1757.8922220865886\n",
      "Train Epoch: 607 [0/54000 (0%)] Loss: -1769.678955\n",
      "Train Epoch: 607 [11264/54000 (21%)] Loss: -1763.869019\n",
      "Train Epoch: 607 [22528/54000 (42%)] Loss: -1693.608887\n",
      "Train Epoch: 607 [33792/54000 (63%)] Loss: -1734.628906\n",
      "Train Epoch: 607 [45056/54000 (83%)] Loss: -1740.492676\n",
      "    epoch          : 607\n",
      "    loss           : -1740.1207736033314\n",
      "    ess            : 26.575982903534513\n",
      "    log_marginal   : 1740.439689204378\n",
      "    val_loss       : -1743.830810546875\n",
      "    val_ess        : 26.7382648785909\n",
      "    val_log_marginal: 1744.1338602701824\n",
      "Train Epoch: 608 [0/54000 (0%)] Loss: -1742.007568\n",
      "Train Epoch: 608 [11264/54000 (21%)] Loss: -1751.167358\n",
      "Train Epoch: 608 [22528/54000 (42%)] Loss: -1753.541260\n",
      "Train Epoch: 608 [33792/54000 (63%)] Loss: -1751.131836\n",
      "Train Epoch: 608 [45056/54000 (83%)] Loss: -1756.021973\n",
      "    epoch          : 608\n",
      "    loss           : -1750.4967697431457\n",
      "    ess            : 27.379543394412636\n",
      "    log_marginal   : 1750.7707381338444\n",
      "    val_loss       : -1752.8960062662761\n",
      "    val_ess        : 27.055132548014324\n",
      "    val_log_marginal: 1753.1915079752605\n",
      "Train Epoch: 609 [0/54000 (0%)] Loss: -1753.891846\n",
      "Train Epoch: 609 [11264/54000 (21%)] Loss: -1759.287109\n",
      "Train Epoch: 609 [22528/54000 (42%)] Loss: -1759.156250\n",
      "Train Epoch: 609 [33792/54000 (63%)] Loss: -1761.636719\n",
      "Train Epoch: 609 [45056/54000 (83%)] Loss: -1756.132446\n",
      "    epoch          : 609\n",
      "    loss           : -1756.8444352059994\n",
      "    ess            : 26.97299039588784\n",
      "    log_marginal   : 1757.144481730911\n",
      "    val_loss       : -1757.0657958984375\n",
      "    val_ess        : 26.653428077697754\n",
      "    val_log_marginal: 1757.3936360677083\n",
      "Train Epoch: 610 [0/54000 (0%)] Loss: -1761.048340\n",
      "Train Epoch: 610 [11264/54000 (21%)] Loss: -1762.266113\n",
      "Train Epoch: 610 [22528/54000 (42%)] Loss: -1761.261475\n",
      "Train Epoch: 610 [33792/54000 (63%)] Loss: -1756.845215\n",
      "Train Epoch: 610 [45056/54000 (83%)] Loss: -1757.492310\n",
      "    epoch          : 610\n",
      "    loss           : -1759.305946206147\n",
      "    ess            : 26.654920164144265\n",
      "    log_marginal   : 1759.630677421138\n",
      "    val_loss       : -1758.2195536295574\n",
      "    val_ess        : 26.83972183863322\n",
      "    val_log_marginal: 1758.5282796223958\n",
      "Train Epoch: 611 [0/54000 (0%)] Loss: -1762.598145\n",
      "Train Epoch: 611 [11264/54000 (21%)] Loss: -1760.030151\n",
      "Train Epoch: 611 [22528/54000 (42%)] Loss: -1755.397583\n",
      "Train Epoch: 611 [33792/54000 (63%)] Loss: -1764.126221\n",
      "Train Epoch: 611 [45056/54000 (83%)] Loss: -1760.145996\n",
      "    epoch          : 611\n",
      "    loss           : -1760.8886787846404\n",
      "    ess            : 26.810129561514223\n",
      "    log_marginal   : 1761.2050193930572\n",
      "    val_loss       : -1759.9508870442708\n",
      "    val_ess        : 26.72121747334798\n",
      "    val_log_marginal: 1760.262919108073\n",
      "Train Epoch: 612 [0/54000 (0%)] Loss: -1762.811768\n",
      "Train Epoch: 612 [11264/54000 (21%)] Loss: -1761.040527\n",
      "Train Epoch: 612 [22528/54000 (42%)] Loss: -1758.621094\n",
      "Train Epoch: 612 [33792/54000 (63%)] Loss: -1764.478882\n",
      "Train Epoch: 612 [45056/54000 (83%)] Loss: -1762.417114\n",
      "    epoch          : 612\n",
      "    loss           : -1762.0749880232902\n",
      "    ess            : 26.699369034677183\n",
      "    log_marginal   : 1762.398806014151\n",
      "    val_loss       : -1760.836405436198\n",
      "    val_ess        : 26.74989938735962\n",
      "    val_log_marginal: 1761.1527913411458\n",
      "Train Epoch: 613 [0/54000 (0%)] Loss: -1759.588623\n",
      "Train Epoch: 613 [11264/54000 (21%)] Loss: -1765.261230\n",
      "Train Epoch: 613 [22528/54000 (42%)] Loss: -1761.568604\n",
      "Train Epoch: 613 [33792/54000 (63%)] Loss: -1760.314941\n",
      "Train Epoch: 613 [45056/54000 (83%)] Loss: -1768.013062\n",
      "    epoch          : 613\n",
      "    loss           : -1763.2709776680424\n",
      "    ess            : 26.697061034868348\n",
      "    log_marginal   : 1763.5943764740566\n",
      "    val_loss       : -1761.4905395507812\n",
      "    val_ess        : 26.58578109741211\n",
      "    val_log_marginal: 1761.8199157714844\n",
      "Train Epoch: 614 [0/54000 (0%)] Loss: -1758.862915\n",
      "Train Epoch: 614 [11264/54000 (21%)] Loss: -1763.299561\n",
      "Train Epoch: 614 [22528/54000 (42%)] Loss: -1766.653687\n",
      "Train Epoch: 614 [33792/54000 (63%)] Loss: -1763.552734\n",
      "Train Epoch: 614 [45056/54000 (83%)] Loss: -1765.069824\n",
      "    epoch          : 614\n",
      "    loss           : -1763.9484667508107\n",
      "    ess            : 26.78994365908065\n",
      "    log_marginal   : 1764.2694437278892\n",
      "    val_loss       : -1761.6012878417969\n",
      "    val_ess        : 26.847858428955078\n",
      "    val_log_marginal: 1761.9114685058594\n",
      "Train Epoch: 615 [0/54000 (0%)] Loss: -1767.935425\n",
      "Train Epoch: 615 [11264/54000 (21%)] Loss: -1764.055908\n",
      "Train Epoch: 615 [22528/54000 (42%)] Loss: -1768.177979\n",
      "Train Epoch: 615 [33792/54000 (63%)] Loss: -1758.630493\n",
      "Train Epoch: 615 [45056/54000 (83%)] Loss: -1692.162598\n",
      "    epoch          : 615\n",
      "    loss           : -1750.1808529260024\n",
      "    ess            : 26.71104306994744\n",
      "    log_marginal   : 1750.499590028007\n",
      "    val_loss       : -1735.2275390625\n",
      "    val_ess        : 26.433903376261394\n",
      "    val_log_marginal: 1735.5399271647136\n",
      "Train Epoch: 616 [0/54000 (0%)] Loss: -1747.169189\n",
      "Train Epoch: 616 [11264/54000 (21%)] Loss: -1750.311279\n",
      "Train Epoch: 616 [22528/54000 (42%)] Loss: -1750.928589\n",
      "Train Epoch: 616 [33792/54000 (63%)] Loss: -1750.993286\n",
      "Train Epoch: 616 [45056/54000 (83%)] Loss: -1752.487305\n",
      "    epoch          : 616\n",
      "    loss           : -1750.6202012547906\n",
      "    ess            : 26.975547934478183\n",
      "    log_marginal   : 1750.9162897073998\n",
      "    val_loss       : -1750.4554850260417\n",
      "    val_ess        : 27.39665873845418\n",
      "    val_log_marginal: 1750.7391967773438\n",
      "Train Epoch: 617 [0/54000 (0%)] Loss: -1758.421875\n",
      "Train Epoch: 617 [11264/54000 (21%)] Loss: -1752.170410\n",
      "Train Epoch: 617 [22528/54000 (42%)] Loss: -1753.136719\n",
      "Train Epoch: 617 [33792/54000 (63%)] Loss: -1758.400879\n",
      "Train Epoch: 617 [45056/54000 (83%)] Loss: -1761.743164\n",
      "    epoch          : 617\n",
      "    loss           : -1758.2702936136498\n",
      "    ess            : 26.958583345953024\n",
      "    log_marginal   : 1758.574558473983\n",
      "    val_loss       : -1756.693115234375\n",
      "    val_ess        : 26.950304349263508\n",
      "    val_log_marginal: 1756.995869954427\n",
      "Train Epoch: 618 [0/54000 (0%)] Loss: -1760.935059\n",
      "Train Epoch: 618 [11264/54000 (21%)] Loss: -1758.529419\n",
      "Train Epoch: 618 [22528/54000 (42%)] Loss: -1762.683960\n",
      "Train Epoch: 618 [33792/54000 (63%)] Loss: -1759.352173\n",
      "Train Epoch: 618 [45056/54000 (83%)] Loss: -1761.856079\n",
      "    epoch          : 618\n",
      "    loss           : -1761.0816777067364\n",
      "    ess            : 26.705610815084206\n",
      "    log_marginal   : 1761.4026477741745\n",
      "    val_loss       : -1759.1417338053386\n",
      "    val_ess        : 26.73464012145996\n",
      "    val_log_marginal: 1759.4610799153645\n",
      "Train Epoch: 619 [0/54000 (0%)] Loss: -1763.901855\n",
      "Train Epoch: 619 [11264/54000 (21%)] Loss: -1761.369629\n",
      "Train Epoch: 619 [22528/54000 (42%)] Loss: -1760.709351\n",
      "Train Epoch: 619 [33792/54000 (63%)] Loss: -1762.179199\n",
      "Train Epoch: 619 [45056/54000 (83%)] Loss: -1761.079834\n",
      "    epoch          : 619\n",
      "    loss           : -1762.67096523069\n",
      "    ess            : 26.68831197270807\n",
      "    log_marginal   : 1762.9944020397259\n",
      "    val_loss       : -1760.6935933430989\n",
      "    val_ess        : 26.587116559346516\n",
      "    val_log_marginal: 1761.0389912923176\n",
      "Train Epoch: 620 [0/54000 (0%)] Loss: -1766.215698\n",
      "Train Epoch: 620 [11264/54000 (21%)] Loss: -1763.268555\n",
      "Train Epoch: 620 [22528/54000 (42%)] Loss: -1760.603882\n",
      "Train Epoch: 620 [33792/54000 (63%)] Loss: -1766.600220\n",
      "Train Epoch: 620 [45056/54000 (83%)] Loss: -1765.291992\n",
      "    epoch          : 620\n",
      "    loss           : -1763.9126736622936\n",
      "    ess            : 26.78798322857551\n",
      "    log_marginal   : 1764.2350175965507\n",
      "    val_loss       : -1762.0268656412761\n",
      "    val_ess        : 26.722452958424885\n",
      "    val_log_marginal: 1762.3399353027344\n",
      "Train Epoch: 621 [0/54000 (0%)] Loss: -1766.503418\n",
      "Train Epoch: 621 [11264/54000 (21%)] Loss: -1763.936279\n",
      "Train Epoch: 621 [22528/54000 (42%)] Loss: -1761.691406\n",
      "Train Epoch: 621 [33792/54000 (63%)] Loss: -1765.229248\n",
      "Train Epoch: 621 [45056/54000 (83%)] Loss: -1767.773193\n",
      "    epoch          : 621\n",
      "    loss           : -1764.6862528099205\n",
      "    ess            : 26.736818061684662\n",
      "    log_marginal   : 1765.013071887898\n",
      "    val_loss       : -1762.1437886555989\n",
      "    val_ess        : 26.694459597269695\n",
      "    val_log_marginal: 1762.4768575032551\n",
      "Train Epoch: 622 [0/54000 (0%)] Loss: -1766.125854\n",
      "Train Epoch: 622 [11264/54000 (21%)] Loss: -1762.062012\n",
      "Train Epoch: 622 [22528/54000 (42%)] Loss: -1766.565918\n",
      "Train Epoch: 622 [33792/54000 (63%)] Loss: -1758.427734\n",
      "Train Epoch: 622 [45056/54000 (83%)] Loss: -1724.912598\n",
      "    epoch          : 622\n",
      "    loss           : -1754.535615741082\n",
      "    ess            : 26.677434453424418\n",
      "    log_marginal   : 1754.8558487802181\n",
      "    val_loss       : -1726.5001322428386\n",
      "    val_ess        : 26.27710485458374\n",
      "    val_log_marginal: 1726.8190104166667\n",
      "Train Epoch: 623 [0/54000 (0%)] Loss: -1734.440063\n",
      "Train Epoch: 623 [11264/54000 (21%)] Loss: -1739.733887\n",
      "Train Epoch: 623 [22528/54000 (42%)] Loss: -1749.289795\n",
      "Train Epoch: 623 [33792/54000 (63%)] Loss: -1745.583374\n",
      "Train Epoch: 623 [45056/54000 (83%)] Loss: -1752.128662\n",
      "    epoch          : 623\n",
      "    loss           : -1746.090654481132\n",
      "    ess            : 26.87364322734329\n",
      "    log_marginal   : 1746.3924779352153\n",
      "    val_loss       : -1744.6635233561199\n",
      "    val_ess        : 27.818885167439777\n",
      "    val_log_marginal: 1744.9152018229167\n",
      "Train Epoch: 624 [0/54000 (0%)] Loss: -1750.359619\n",
      "Train Epoch: 624 [11264/54000 (21%)] Loss: -1752.448364\n",
      "Train Epoch: 624 [22528/54000 (42%)] Loss: -1758.070435\n",
      "Train Epoch: 624 [33792/54000 (63%)] Loss: -1754.351196\n",
      "Train Epoch: 624 [45056/54000 (83%)] Loss: -1755.383423\n",
      "    epoch          : 624\n",
      "    loss           : -1757.1374995393573\n",
      "    ess            : 27.217999404331422\n",
      "    log_marginal   : 1757.4292510410526\n",
      "    val_loss       : -1754.1976318359375\n",
      "    val_ess        : 26.997055689493816\n",
      "    val_log_marginal: 1754.505147298177\n",
      "Train Epoch: 625 [0/54000 (0%)] Loss: -1760.933228\n",
      "Train Epoch: 625 [11264/54000 (21%)] Loss: -1759.850586\n",
      "Train Epoch: 625 [22528/54000 (42%)] Loss: -1763.014648\n",
      "Train Epoch: 625 [33792/54000 (63%)] Loss: -1759.717773\n",
      "Train Epoch: 625 [45056/54000 (83%)] Loss: -1760.543335\n",
      "    epoch          : 625\n",
      "    loss           : -1760.6272629072082\n",
      "    ess            : 26.738384156856895\n",
      "    log_marginal   : 1760.9474303047612\n",
      "    val_loss       : -1757.378397623698\n",
      "    val_ess        : 26.973709106445312\n",
      "    val_log_marginal: 1757.6840108235676\n",
      "Train Epoch: 626 [0/54000 (0%)] Loss: -1762.225586\n",
      "Train Epoch: 626 [11264/54000 (21%)] Loss: -1762.960327\n",
      "Train Epoch: 626 [22528/54000 (42%)] Loss: -1765.917603\n",
      "Train Epoch: 626 [33792/54000 (63%)] Loss: -1759.930542\n",
      "Train Epoch: 626 [45056/54000 (83%)] Loss: -1763.062500\n",
      "    epoch          : 626\n",
      "    loss           : -1762.4095263211232\n",
      "    ess            : 26.711300400068176\n",
      "    log_marginal   : 1762.7310698887088\n",
      "    val_loss       : -1759.0741271972656\n",
      "    val_ess        : 26.830655256907146\n",
      "    val_log_marginal: 1759.3892211914062\n",
      "Train Epoch: 627 [0/54000 (0%)] Loss: -1765.765259\n",
      "Train Epoch: 627 [11264/54000 (21%)] Loss: -1763.464111\n",
      "Train Epoch: 627 [22528/54000 (42%)] Loss: -1760.114014\n",
      "Train Epoch: 627 [33792/54000 (63%)] Loss: -1770.964111\n",
      "Train Epoch: 627 [45056/54000 (83%)] Loss: -1767.142334\n",
      "    epoch          : 627\n",
      "    loss           : -1763.8348238963001\n",
      "    ess            : 26.709854251933546\n",
      "    log_marginal   : 1764.162712816922\n",
      "    val_loss       : -1760.8557637532551\n",
      "    val_ess        : 26.90138594309489\n",
      "    val_log_marginal: 1761.1719156901042\n",
      "Train Epoch: 628 [0/54000 (0%)] Loss: -1763.942871\n",
      "Train Epoch: 628 [11264/54000 (21%)] Loss: -1764.716309\n",
      "Train Epoch: 628 [22528/54000 (42%)] Loss: -1762.875000\n",
      "Train Epoch: 628 [33792/54000 (63%)] Loss: -1767.364014\n",
      "Train Epoch: 628 [45056/54000 (83%)] Loss: -1763.960449\n",
      "    epoch          : 628\n",
      "    loss           : -1764.9585617353332\n",
      "    ess            : 26.69356585448643\n",
      "    log_marginal   : 1765.2852034658756\n",
      "    val_loss       : -1762.2942810058594\n",
      "    val_ess        : 26.603731473286945\n",
      "    val_log_marginal: 1762.6292724609375\n",
      "Train Epoch: 629 [0/54000 (0%)] Loss: -1766.080444\n",
      "Train Epoch: 629 [11264/54000 (21%)] Loss: -1766.602539\n",
      "Train Epoch: 629 [22528/54000 (42%)] Loss: -1766.023926\n",
      "Train Epoch: 629 [33792/54000 (63%)] Loss: -1764.550659\n",
      "Train Epoch: 629 [45056/54000 (83%)] Loss: -1751.641479\n",
      "    epoch          : 629\n",
      "    loss           : -1763.4915322357754\n",
      "    ess            : 26.69456741045106\n",
      "    log_marginal   : 1763.819294479658\n",
      "    val_loss       : -1755.9798380533855\n",
      "    val_ess        : 26.904074986775715\n",
      "    val_log_marginal: 1756.2983907063801\n",
      "Train Epoch: 630 [0/54000 (0%)] Loss: -1766.076782\n",
      "Train Epoch: 630 [11264/54000 (21%)] Loss: -1757.525513\n",
      "Train Epoch: 630 [22528/54000 (42%)] Loss: -1752.795166\n",
      "Train Epoch: 630 [33792/54000 (63%)] Loss: -1747.223633\n",
      "Train Epoch: 630 [45056/54000 (83%)] Loss: -1752.813477\n",
      "    epoch          : 630\n",
      "    loss           : -1752.8315176334022\n",
      "    ess            : 26.713249044598275\n",
      "    log_marginal   : 1753.1495568617336\n",
      "    val_loss       : -1758.7008056640625\n",
      "    val_ess        : 27.03080685933431\n",
      "    val_log_marginal: 1758.9939982096355\n",
      "Train Epoch: 631 [0/54000 (0%)] Loss: -1758.961304\n",
      "Train Epoch: 631 [11264/54000 (21%)] Loss: -1759.227905\n",
      "Train Epoch: 631 [22528/54000 (42%)] Loss: -1761.820801\n",
      "Train Epoch: 631 [33792/54000 (63%)] Loss: -1760.262451\n",
      "Train Epoch: 631 [45056/54000 (83%)] Loss: -1756.976929\n",
      "    epoch          : 631\n",
      "    loss           : -1761.6870382057045\n",
      "    ess            : 27.214408406671488\n",
      "    log_marginal   : 1761.9813036648732\n",
      "    val_loss       : -1761.3777974446614\n",
      "    val_ess        : 26.674319585164387\n",
      "    val_log_marginal: 1761.6907653808594\n",
      "Train Epoch: 632 [0/54000 (0%)] Loss: -1767.702637\n",
      "Train Epoch: 632 [11264/54000 (21%)] Loss: -1765.477783\n",
      "Train Epoch: 632 [22528/54000 (42%)] Loss: -1768.708496\n",
      "Train Epoch: 632 [33792/54000 (63%)] Loss: -1764.218262\n",
      "Train Epoch: 632 [45056/54000 (83%)] Loss: -1760.314575\n",
      "    epoch          : 632\n",
      "    loss           : -1764.4571325913914\n",
      "    ess            : 26.778726775691194\n",
      "    log_marginal   : 1764.7805521263267\n",
      "    val_loss       : -1763.4424540201824\n",
      "    val_ess        : 26.86383358637492\n",
      "    val_log_marginal: 1763.7650858561199\n",
      "Train Epoch: 633 [0/54000 (0%)] Loss: -1766.718872\n",
      "Train Epoch: 633 [11264/54000 (21%)] Loss: -1760.836182\n",
      "Train Epoch: 633 [22528/54000 (42%)] Loss: -1763.678467\n",
      "Train Epoch: 633 [33792/54000 (63%)] Loss: -1766.574097\n",
      "Train Epoch: 633 [45056/54000 (83%)] Loss: -1764.607422\n",
      "    epoch          : 633\n",
      "    loss           : -1765.8259588277565\n",
      "    ess            : 26.749561417777585\n",
      "    log_marginal   : 1766.1520834868809\n",
      "    val_loss       : -1763.8657328287761\n",
      "    val_ess        : 26.70458189646403\n",
      "    val_log_marginal: 1764.2002360026042\n",
      "Train Epoch: 634 [0/54000 (0%)] Loss: -1766.994385\n",
      "Train Epoch: 634 [11264/54000 (21%)] Loss: -1763.658325\n",
      "Train Epoch: 634 [22528/54000 (42%)] Loss: -1690.218262\n",
      "Train Epoch: 634 [33792/54000 (63%)] Loss: -1720.597046\n",
      "Train Epoch: 634 [45056/54000 (83%)] Loss: -1732.610352\n",
      "    epoch          : 634\n",
      "    loss           : -1736.8453541881634\n",
      "    ess            : 26.567365430436045\n",
      "    log_marginal   : 1737.164923901828\n",
      "    val_loss       : -1735.1287333170574\n",
      "    val_ess        : 26.50745137532552\n",
      "    val_log_marginal: 1735.4479370117188\n",
      "Train Epoch: 635 [0/54000 (0%)] Loss: -1741.514160\n",
      "Train Epoch: 635 [11264/54000 (21%)] Loss: -1747.283447\n",
      "Train Epoch: 635 [22528/54000 (42%)] Loss: -1747.307373\n",
      "Train Epoch: 635 [33792/54000 (63%)] Loss: -1749.153320\n",
      "Train Epoch: 635 [45056/54000 (83%)] Loss: -1754.396362\n",
      "    epoch          : 635\n",
      "    loss           : -1749.0929335108344\n",
      "    ess            : 27.340493831994397\n",
      "    log_marginal   : 1749.3707655420844\n",
      "    val_loss       : -1750.7497456868489\n",
      "    val_ess        : 27.562273025512695\n",
      "    val_log_marginal: 1751.0141499837239\n",
      "Train Epoch: 636 [0/54000 (0%)] Loss: -1757.132812\n",
      "Train Epoch: 636 [11264/54000 (21%)] Loss: -1750.409424\n",
      "Train Epoch: 636 [22528/54000 (42%)] Loss: -1752.056885\n",
      "Train Epoch: 636 [33792/54000 (63%)] Loss: -1756.172607\n",
      "Train Epoch: 636 [45056/54000 (83%)] Loss: -1756.218994\n",
      "    epoch          : 636\n",
      "    loss           : -1756.713366238576\n",
      "    ess            : 27.05602712451287\n",
      "    log_marginal   : 1757.0100938329156\n",
      "    val_loss       : -1756.8784484863281\n",
      "    val_ess        : 26.87869930267334\n",
      "    val_log_marginal: 1757.1814778645833\n",
      "Train Epoch: 637 [0/54000 (0%)] Loss: -1757.464844\n",
      "Train Epoch: 637 [11264/54000 (21%)] Loss: -1759.923706\n",
      "Train Epoch: 637 [22528/54000 (42%)] Loss: -1755.467285\n",
      "Train Epoch: 637 [33792/54000 (63%)] Loss: -1760.085693\n",
      "Train Epoch: 637 [45056/54000 (83%)] Loss: -1755.382568\n",
      "    epoch          : 637\n",
      "    loss           : -1759.6847776017098\n",
      "    ess            : 26.73738512003197\n",
      "    log_marginal   : 1759.999975816259\n",
      "    val_loss       : -1759.4642232259114\n",
      "    val_ess        : 26.61201508839925\n",
      "    val_log_marginal: 1759.7874959309895\n",
      "Train Epoch: 638 [0/54000 (0%)] Loss: -1764.439697\n",
      "Train Epoch: 638 [11264/54000 (21%)] Loss: -1758.484985\n",
      "Train Epoch: 638 [22528/54000 (42%)] Loss: -1759.532471\n",
      "Train Epoch: 638 [33792/54000 (63%)] Loss: -1760.490967\n",
      "Train Epoch: 638 [45056/54000 (83%)] Loss: -1762.749023\n",
      "    epoch          : 638\n",
      "    loss           : -1761.6019252561173\n",
      "    ess            : 26.633224901163352\n",
      "    log_marginal   : 1761.9295320330925\n",
      "    val_loss       : -1760.9077758789062\n",
      "    val_ess        : 26.710680961608887\n",
      "    val_log_marginal: 1761.23388671875\n",
      "Train Epoch: 639 [0/54000 (0%)] Loss: -1764.647583\n",
      "Train Epoch: 639 [11264/54000 (21%)] Loss: -1766.276733\n",
      "Train Epoch: 639 [22528/54000 (42%)] Loss: -1763.208008\n",
      "Train Epoch: 639 [33792/54000 (63%)] Loss: -1765.793701\n",
      "Train Epoch: 639 [45056/54000 (83%)] Loss: -1759.439331\n",
      "    epoch          : 639\n",
      "    loss           : -1762.9252457528744\n",
      "    ess            : 26.648110353721762\n",
      "    log_marginal   : 1763.251303618809\n",
      "    val_loss       : -1761.9301656087239\n",
      "    val_ess        : 26.779605229695637\n",
      "    val_log_marginal: 1762.2562357584636\n",
      "Train Epoch: 640 [0/54000 (0%)] Loss: -1765.837646\n",
      "Train Epoch: 640 [11264/54000 (21%)] Loss: -1761.888184\n",
      "Train Epoch: 640 [22528/54000 (42%)] Loss: -1761.578247\n",
      "Train Epoch: 640 [33792/54000 (63%)] Loss: -1762.281860\n",
      "Train Epoch: 640 [45056/54000 (83%)] Loss: -1763.139893\n",
      "    epoch          : 640\n",
      "    loss           : -1764.1778184422906\n",
      "    ess            : 26.717603593502403\n",
      "    log_marginal   : 1764.4993401293484\n",
      "    val_loss       : -1763.2863260904949\n",
      "    val_ess        : 26.782853921254475\n",
      "    val_log_marginal: 1763.6091817220051\n",
      "Train Epoch: 641 [0/54000 (0%)] Loss: -1769.262939\n",
      "Train Epoch: 641 [11264/54000 (21%)] Loss: -1764.364258\n",
      "Train Epoch: 641 [22528/54000 (42%)] Loss: -1766.411621\n",
      "Train Epoch: 641 [33792/54000 (63%)] Loss: -1762.116211\n",
      "Train Epoch: 641 [45056/54000 (83%)] Loss: -1766.155518\n",
      "    epoch          : 641\n",
      "    loss           : -1765.1075888579746\n",
      "    ess            : 26.741207554655254\n",
      "    log_marginal   : 1765.4298809699292\n",
      "    val_loss       : -1764.0259195963542\n",
      "    val_ess        : 26.64611355463664\n",
      "    val_log_marginal: 1764.3556823730469\n",
      "Train Epoch: 642 [0/54000 (0%)] Loss: -1763.513184\n",
      "Train Epoch: 642 [11264/54000 (21%)] Loss: -1762.979126\n",
      "Train Epoch: 642 [22528/54000 (42%)] Loss: -1766.510254\n",
      "Train Epoch: 642 [33792/54000 (63%)] Loss: -1765.279297\n",
      "Train Epoch: 642 [45056/54000 (83%)] Loss: -1765.647705\n",
      "    epoch          : 642\n",
      "    loss           : -1766.0665697781544\n",
      "    ess            : 26.672702195509423\n",
      "    log_marginal   : 1766.39920331847\n",
      "    val_loss       : -1765.0817362467449\n",
      "    val_ess        : 26.546161492665608\n",
      "    val_log_marginal: 1765.4156087239583\n",
      "Train Epoch: 643 [0/54000 (0%)] Loss: -1768.415405\n",
      "Train Epoch: 643 [11264/54000 (21%)] Loss: -1767.535034\n",
      "Train Epoch: 643 [22528/54000 (42%)] Loss: -1768.729858\n",
      "Train Epoch: 643 [33792/54000 (63%)] Loss: -1766.254639\n",
      "Train Epoch: 643 [45056/54000 (83%)] Loss: -1761.541992\n",
      "    epoch          : 643\n",
      "    loss           : -1766.2853002008403\n",
      "    ess            : 26.757909342927753\n",
      "    log_marginal   : 1766.608692097214\n",
      "    val_loss       : -1758.5780639648438\n",
      "    val_ess        : 27.01500924428304\n",
      "    val_log_marginal: 1758.8700459798176\n",
      "Train Epoch: 644 [0/54000 (0%)] Loss: -1756.412109\n",
      "Train Epoch: 644 [11264/54000 (21%)] Loss: -1707.169556\n",
      "Train Epoch: 644 [22528/54000 (42%)] Loss: -1746.432129\n",
      "Train Epoch: 644 [33792/54000 (63%)] Loss: -1737.644775\n",
      "Train Epoch: 644 [45056/54000 (83%)] Loss: -1742.313110\n",
      "    epoch          : 644\n",
      "    loss           : -1733.5349017449146\n",
      "    ess            : 26.537942688420134\n",
      "    log_marginal   : 1733.8534027675412\n",
      "    val_loss       : -1748.6466471354167\n",
      "    val_ess        : 27.081905682881672\n",
      "    val_log_marginal: 1748.9463399251301\n",
      "Train Epoch: 645 [0/54000 (0%)] Loss: -1751.669922\n",
      "Train Epoch: 645 [11264/54000 (21%)] Loss: -1759.176392\n",
      "Train Epoch: 645 [22528/54000 (42%)] Loss: -1753.101074\n",
      "Train Epoch: 645 [33792/54000 (63%)] Loss: -1751.742920\n",
      "Train Epoch: 645 [45056/54000 (83%)] Loss: -1749.234131\n",
      "    epoch          : 645\n",
      "    loss           : -1752.340625690964\n",
      "    ess            : 27.610306469899303\n",
      "    log_marginal   : 1752.6014150943397\n",
      "    val_loss       : -1756.771728515625\n",
      "    val_ess        : 27.093247413635254\n",
      "    val_log_marginal: 1757.0668640136719\n",
      "Train Epoch: 646 [0/54000 (0%)] Loss: -1758.556885\n",
      "Train Epoch: 646 [11264/54000 (21%)] Loss: -1755.226074\n",
      "Train Epoch: 646 [22528/54000 (42%)] Loss: -1759.293945\n",
      "Train Epoch: 646 [33792/54000 (63%)] Loss: -1758.872070\n",
      "Train Epoch: 646 [45056/54000 (83%)] Loss: -1759.739990\n",
      "    epoch          : 646\n",
      "    loss           : -1758.215414946934\n",
      "    ess            : 26.858738989200234\n",
      "    log_marginal   : 1758.5244036980396\n",
      "    val_loss       : -1760.5167338053386\n",
      "    val_ess        : 26.70335308710734\n",
      "    val_log_marginal: 1760.8286539713542\n",
      "Train Epoch: 647 [0/54000 (0%)] Loss: -1760.231201\n",
      "Train Epoch: 647 [11264/54000 (21%)] Loss: -1761.166382\n",
      "Train Epoch: 647 [22528/54000 (42%)] Loss: -1755.687256\n",
      "Train Epoch: 647 [33792/54000 (63%)] Loss: -1765.656128\n",
      "Train Epoch: 647 [45056/54000 (83%)] Loss: -1758.514893\n",
      "    epoch          : 647\n",
      "    loss           : -1760.64034746278\n",
      "    ess            : 26.63644421775386\n",
      "    log_marginal   : 1760.9671964825325\n",
      "    val_loss       : -1762.1415100097656\n",
      "    val_ess        : 26.811339537302654\n",
      "    val_log_marginal: 1762.4639282226562\n",
      "Train Epoch: 648 [0/54000 (0%)] Loss: -1758.930908\n",
      "Train Epoch: 648 [11264/54000 (21%)] Loss: -1766.059082\n",
      "Train Epoch: 648 [22528/54000 (42%)] Loss: -1757.554810\n",
      "Train Epoch: 648 [33792/54000 (63%)] Loss: -1760.268555\n",
      "Train Epoch: 648 [45056/54000 (83%)] Loss: -1763.616699\n",
      "    epoch          : 648\n",
      "    loss           : -1762.5306649837853\n",
      "    ess            : 26.71119535194253\n",
      "    log_marginal   : 1762.8510834316037\n",
      "    val_loss       : -1763.334737141927\n",
      "    val_ess        : 26.749507904052734\n",
      "    val_log_marginal: 1763.6558329264324\n",
      "Train Epoch: 649 [0/54000 (0%)] Loss: -1763.794678\n",
      "Train Epoch: 649 [11264/54000 (21%)] Loss: -1763.606567\n",
      "Train Epoch: 649 [22528/54000 (42%)] Loss: -1763.059692\n",
      "Train Epoch: 649 [33792/54000 (63%)] Loss: -1759.583252\n",
      "Train Epoch: 649 [45056/54000 (83%)] Loss: -1765.535889\n",
      "    epoch          : 649\n",
      "    loss           : -1763.679567732901\n",
      "    ess            : 26.713858046621645\n",
      "    log_marginal   : 1764.0033235369988\n",
      "    val_loss       : -1764.4253031412761\n",
      "    val_ess        : 26.47584851582845\n",
      "    val_log_marginal: 1764.7544352213542\n",
      "Train Epoch: 650 [0/54000 (0%)] Loss: -1764.855103\n",
      "Train Epoch: 650 [11264/54000 (21%)] Loss: -1759.602295\n",
      "Train Epoch: 650 [22528/54000 (42%)] Loss: -1762.265503\n",
      "Train Epoch: 650 [33792/54000 (63%)] Loss: -1766.937500\n",
      "Train Epoch: 650 [45056/54000 (83%)] Loss: -1763.013916\n",
      "    epoch          : 650\n",
      "    loss           : -1764.7762669977153\n",
      "    ess            : 26.701530546512245\n",
      "    log_marginal   : 1765.103084924086\n",
      "    val_loss       : -1765.1548665364583\n",
      "    val_ess        : 26.643401781717937\n",
      "    val_log_marginal: 1765.473612467448\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch650.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 651 [0/54000 (0%)] Loss: -1768.190918\n",
      "Train Epoch: 651 [11264/54000 (21%)] Loss: -1767.064697\n",
      "Train Epoch: 651 [22528/54000 (42%)] Loss: -1767.437744\n",
      "Train Epoch: 651 [33792/54000 (63%)] Loss: -1761.506348\n",
      "Train Epoch: 651 [45056/54000 (83%)] Loss: -1771.292236\n",
      "    epoch          : 651\n",
      "    loss           : -1765.7694748212707\n",
      "    ess            : 26.74882447944497\n",
      "    log_marginal   : 1766.0976666144604\n",
      "    val_loss       : -1765.9987691243489\n",
      "    val_ess        : 26.77548662821452\n",
      "    val_log_marginal: 1766.3222961425781\n",
      "Train Epoch: 652 [0/54000 (0%)] Loss: -1765.784912\n",
      "Train Epoch: 652 [11264/54000 (21%)] Loss: -1761.856567\n",
      "Train Epoch: 652 [22528/54000 (42%)] Loss: -1769.902100\n",
      "Train Epoch: 652 [33792/54000 (63%)] Loss: -1762.730469\n",
      "Train Epoch: 652 [45056/54000 (83%)] Loss: -1769.312500\n",
      "    epoch          : 652\n",
      "    loss           : -1766.6683798735996\n",
      "    ess            : 26.802663155321806\n",
      "    log_marginal   : 1766.9869292637088\n",
      "    val_loss       : -1766.3137308756511\n",
      "    val_ess        : 26.791722615559895\n",
      "    val_log_marginal: 1766.6374409993489\n",
      "Train Epoch: 653 [0/54000 (0%)] Loss: -1768.942993\n",
      "Train Epoch: 653 [11264/54000 (21%)] Loss: -1766.226562\n",
      "Train Epoch: 653 [22528/54000 (42%)] Loss: -1733.848145\n",
      "Train Epoch: 653 [33792/54000 (63%)] Loss: -1735.990479\n",
      "Train Epoch: 653 [45056/54000 (83%)] Loss: -1740.697754\n",
      "    epoch          : 653\n",
      "    loss           : -1749.4867933741157\n",
      "    ess            : 26.59271060295825\n",
      "    log_marginal   : 1749.8119794737618\n",
      "    val_loss       : -1755.7588602701824\n",
      "    val_ess        : 26.60024070739746\n",
      "    val_log_marginal: 1756.0833536783855\n",
      "Train Epoch: 654 [0/54000 (0%)] Loss: -1757.753296\n",
      "Train Epoch: 654 [11264/54000 (21%)] Loss: -1759.186279\n",
      "Train Epoch: 654 [22528/54000 (42%)] Loss: -1756.188965\n",
      "Train Epoch: 654 [33792/54000 (63%)] Loss: -1755.348022\n",
      "Train Epoch: 654 [45056/54000 (83%)] Loss: -1759.208130\n",
      "    epoch          : 654\n",
      "    loss           : -1758.4872413491303\n",
      "    ess            : 27.270149734784972\n",
      "    log_marginal   : 1758.7761000147407\n",
      "    val_loss       : -1762.3788350423176\n",
      "    val_ess        : 27.00780502955119\n",
      "    val_log_marginal: 1762.6893615722656\n",
      "Train Epoch: 655 [0/54000 (0%)] Loss: -1759.664673\n",
      "Train Epoch: 655 [11264/54000 (21%)] Loss: -1761.197266\n",
      "Train Epoch: 655 [22528/54000 (42%)] Loss: -1760.678223\n",
      "Train Epoch: 655 [33792/54000 (63%)] Loss: -1763.347656\n",
      "Train Epoch: 655 [45056/54000 (83%)] Loss: -1764.134521\n",
      "    epoch          : 655\n",
      "    loss           : -1762.9374228423496\n",
      "    ess            : 26.93820550306788\n",
      "    log_marginal   : 1763.2464392320164\n",
      "    val_loss       : -1764.5295003255208\n",
      "    val_ess        : 26.77652867635091\n",
      "    val_log_marginal: 1764.8437805175781\n",
      "Train Epoch: 656 [0/54000 (0%)] Loss: -1764.857300\n",
      "Train Epoch: 656 [11264/54000 (21%)] Loss: -1765.417725\n",
      "Train Epoch: 656 [22528/54000 (42%)] Loss: -1762.467529\n",
      "Train Epoch: 656 [33792/54000 (63%)] Loss: -1765.436646\n",
      "Train Epoch: 656 [45056/54000 (83%)] Loss: -1766.420898\n",
      "    epoch          : 656\n",
      "    loss           : -1765.0130995264594\n",
      "    ess            : 26.753291831826264\n",
      "    log_marginal   : 1765.3344093178803\n",
      "    val_loss       : -1765.9368184407551\n",
      "    val_ess        : 26.909106254577637\n",
      "    val_log_marginal: 1766.2342427571614\n",
      "Train Epoch: 657 [0/54000 (0%)] Loss: -1767.973267\n",
      "Train Epoch: 657 [11264/54000 (21%)] Loss: -1771.076172\n",
      "Train Epoch: 657 [22528/54000 (42%)] Loss: -1763.552246\n",
      "Train Epoch: 657 [33792/54000 (63%)] Loss: -1768.101929\n",
      "Train Epoch: 657 [45056/54000 (83%)] Loss: -1768.552490\n",
      "    epoch          : 657\n",
      "    loss           : -1766.345190660009\n",
      "    ess            : 26.821593176643802\n",
      "    log_marginal   : 1766.6623730929393\n",
      "    val_loss       : -1766.7329610188801\n",
      "    val_ess        : 26.617472012837727\n",
      "    val_log_marginal: 1767.0601908365886\n",
      "Train Epoch: 658 [0/54000 (0%)] Loss: -1767.511719\n",
      "Train Epoch: 658 [11264/54000 (21%)] Loss: -1766.432129\n",
      "Train Epoch: 658 [22528/54000 (42%)] Loss: -1766.161743\n",
      "Train Epoch: 658 [33792/54000 (63%)] Loss: -1766.897461\n",
      "Train Epoch: 658 [45056/54000 (83%)] Loss: -1762.728271\n",
      "    epoch          : 658\n",
      "    loss           : -1767.290436366819\n",
      "    ess            : 26.86245295686542\n",
      "    log_marginal   : 1767.6054549307194\n",
      "    val_loss       : -1767.4030354817708\n",
      "    val_ess        : 26.91338539123535\n",
      "    val_log_marginal: 1767.7135721842449\n",
      "Train Epoch: 659 [0/54000 (0%)] Loss: -1768.999756\n",
      "Train Epoch: 659 [11264/54000 (21%)] Loss: -1764.993164\n",
      "Train Epoch: 659 [22528/54000 (42%)] Loss: -1768.078003\n",
      "Train Epoch: 659 [33792/54000 (63%)] Loss: -1768.257812\n",
      "Train Epoch: 659 [45056/54000 (83%)] Loss: -1765.518555\n",
      "    epoch          : 659\n",
      "    loss           : -1767.4472264703716\n",
      "    ess            : 26.754506057163454\n",
      "    log_marginal   : 1767.7769683262088\n",
      "    val_loss       : -1759.4263916015625\n",
      "    val_ess        : 26.53676700592041\n",
      "    val_log_marginal: 1759.7545064290364\n",
      "Train Epoch: 660 [0/54000 (0%)] Loss: -1759.679932\n",
      "Train Epoch: 660 [11264/54000 (21%)] Loss: -1750.689575\n",
      "Train Epoch: 660 [22528/54000 (42%)] Loss: -1757.065674\n",
      "Train Epoch: 660 [33792/54000 (63%)] Loss: -1748.731689\n",
      "Train Epoch: 660 [45056/54000 (83%)] Loss: -1741.954346\n",
      "    epoch          : 660\n",
      "    loss           : -1747.2660153946786\n",
      "    ess            : 26.652163775462025\n",
      "    log_marginal   : 1747.5880288178066\n",
      "    val_loss       : -1741.0071614583333\n",
      "    val_ess        : 26.806464831034344\n",
      "    val_log_marginal: 1741.313212076823\n",
      "Train Epoch: 661 [0/54000 (0%)] Loss: -1747.062256\n",
      "Train Epoch: 661 [11264/54000 (21%)] Loss: -1755.201172\n",
      "Train Epoch: 661 [22528/54000 (42%)] Loss: -1757.276978\n",
      "Train Epoch: 661 [33792/54000 (63%)] Loss: -1758.916626\n",
      "Train Epoch: 661 [45056/54000 (83%)] Loss: -1754.866943\n",
      "    epoch          : 661\n",
      "    loss           : -1755.4449658663768\n",
      "    ess            : 27.391280714071023\n",
      "    log_marginal   : 1755.725266942438\n",
      "    val_loss       : -1751.4888509114583\n",
      "    val_ess        : 27.834887504577637\n",
      "    val_log_marginal: 1751.756571451823\n",
      "Train Epoch: 662 [0/54000 (0%)] Loss: -1757.769653\n",
      "Train Epoch: 662 [11264/54000 (21%)] Loss: -1754.454346\n",
      "Train Epoch: 662 [22528/54000 (42%)] Loss: -1734.430664\n",
      "Train Epoch: 662 [33792/54000 (63%)] Loss: -1723.626465\n",
      "Train Epoch: 662 [45056/54000 (83%)] Loss: -1739.001587\n",
      "    epoch          : 662\n",
      "    loss           : -1738.924900270858\n",
      "    ess            : 26.88877647327927\n",
      "    log_marginal   : 1739.2229545161408\n",
      "    val_loss       : -1739.9100952148438\n",
      "    val_ess        : 26.921173095703125\n",
      "    val_log_marginal: 1740.2091471354167\n",
      "Train Epoch: 663 [0/54000 (0%)] Loss: -1745.828613\n",
      "Train Epoch: 663 [11264/54000 (21%)] Loss: -1751.373901\n",
      "Train Epoch: 663 [22528/54000 (42%)] Loss: -1750.151367\n",
      "Train Epoch: 663 [33792/54000 (63%)] Loss: -1752.768555\n",
      "Train Epoch: 663 [45056/54000 (83%)] Loss: -1751.191406\n",
      "    epoch          : 663\n",
      "    loss           : -1751.7005672814712\n",
      "    ess            : 27.263044465262936\n",
      "    log_marginal   : 1751.9811355302918\n",
      "    val_loss       : -1753.2272033691406\n",
      "    val_ess        : 27.20445744196574\n",
      "    val_log_marginal: 1753.5208638509114\n",
      "Train Epoch: 664 [0/54000 (0%)] Loss: -1759.874146\n",
      "Train Epoch: 664 [11264/54000 (21%)] Loss: -1763.572998\n",
      "Train Epoch: 664 [22528/54000 (42%)] Loss: -1759.710205\n",
      "Train Epoch: 664 [33792/54000 (63%)] Loss: -1756.358887\n",
      "Train Epoch: 664 [45056/54000 (83%)] Loss: -1755.805420\n",
      "    epoch          : 664\n",
      "    loss           : -1757.6415981076798\n",
      "    ess            : 26.880905349299592\n",
      "    log_marginal   : 1757.9470848227447\n",
      "    val_loss       : -1758.228535970052\n",
      "    val_ess        : 26.91556469599406\n",
      "    val_log_marginal: 1758.5375671386719\n",
      "Train Epoch: 665 [0/54000 (0%)] Loss: -1758.885986\n",
      "Train Epoch: 665 [11264/54000 (21%)] Loss: -1764.575439\n",
      "Train Epoch: 665 [22528/54000 (42%)] Loss: -1763.349243\n",
      "Train Epoch: 665 [33792/54000 (63%)] Loss: -1759.337402\n",
      "Train Epoch: 665 [45056/54000 (83%)] Loss: -1757.899414\n",
      "    epoch          : 665\n",
      "    loss           : -1760.5288719321197\n",
      "    ess            : 26.67567636381905\n",
      "    log_marginal   : 1760.848032825398\n",
      "    val_loss       : -1760.679219563802\n",
      "    val_ess        : 26.92311429977417\n",
      "    val_log_marginal: 1760.9813639322917\n",
      "Train Epoch: 666 [0/54000 (0%)] Loss: -1760.406250\n",
      "Train Epoch: 666 [11264/54000 (21%)] Loss: -1764.042725\n",
      "Train Epoch: 666 [22528/54000 (42%)] Loss: -1762.967285\n",
      "Train Epoch: 666 [33792/54000 (63%)] Loss: -1761.790771\n",
      "Train Epoch: 666 [45056/54000 (83%)] Loss: -1763.710205\n",
      "    epoch          : 666\n",
      "    loss           : -1762.3734096311173\n",
      "    ess            : 26.664833392737048\n",
      "    log_marginal   : 1762.6957570201946\n",
      "    val_loss       : -1762.5404764811199\n",
      "    val_ess        : 26.81077988942464\n",
      "    val_log_marginal: 1762.8598225911458\n",
      "Train Epoch: 667 [0/54000 (0%)] Loss: -1763.694336\n",
      "Train Epoch: 667 [11264/54000 (21%)] Loss: -1770.250000\n",
      "Train Epoch: 667 [22528/54000 (42%)] Loss: -1766.026367\n",
      "Train Epoch: 667 [33792/54000 (63%)] Loss: -1766.422363\n",
      "Train Epoch: 667 [45056/54000 (83%)] Loss: -1759.450684\n",
      "    epoch          : 667\n",
      "    loss           : -1763.703116938753\n",
      "    ess            : 26.685340773384524\n",
      "    log_marginal   : 1764.0247549380897\n",
      "    val_loss       : -1763.80810546875\n",
      "    val_ess        : 26.847059567769367\n",
      "    val_log_marginal: 1764.1036682128906\n",
      "Train Epoch: 668 [0/54000 (0%)] Loss: -1766.143311\n",
      "Train Epoch: 668 [11264/54000 (21%)] Loss: -1761.799072\n",
      "Train Epoch: 668 [22528/54000 (42%)] Loss: -1763.518311\n",
      "Train Epoch: 668 [33792/54000 (63%)] Loss: -1767.091309\n",
      "Train Epoch: 668 [45056/54000 (83%)] Loss: -1770.351196\n",
      "    epoch          : 668\n",
      "    loss           : -1764.9159476802033\n",
      "    ess            : 26.721014112796425\n",
      "    log_marginal   : 1765.2424201245578\n",
      "    val_loss       : -1764.530049641927\n",
      "    val_ess        : 26.807167847951252\n",
      "    val_log_marginal: 1764.8510640462239\n",
      "Train Epoch: 669 [0/54000 (0%)] Loss: -1768.234375\n",
      "Train Epoch: 669 [11264/54000 (21%)] Loss: -1761.244873\n",
      "Train Epoch: 669 [22528/54000 (42%)] Loss: -1765.332520\n",
      "Train Epoch: 669 [33792/54000 (63%)] Loss: -1766.437012\n",
      "Train Epoch: 669 [45056/54000 (83%)] Loss: -1764.033691\n",
      "    epoch          : 669\n",
      "    loss           : -1766.0123440724499\n",
      "    ess            : 26.697815643166596\n",
      "    log_marginal   : 1766.340778854658\n",
      "    val_loss       : -1765.6310221354167\n",
      "    val_ess        : 26.898512840270996\n",
      "    val_log_marginal: 1765.9383850097656\n",
      "Train Epoch: 670 [0/54000 (0%)] Loss: -1765.513062\n",
      "Train Epoch: 670 [11264/54000 (21%)] Loss: -1768.661865\n",
      "Train Epoch: 670 [22528/54000 (42%)] Loss: -1763.434692\n",
      "Train Epoch: 670 [33792/54000 (63%)] Loss: -1765.816040\n",
      "Train Epoch: 670 [45056/54000 (83%)] Loss: -1766.378296\n",
      "    epoch          : 670\n",
      "    loss           : -1766.9022792600235\n",
      "    ess            : 26.825506606191958\n",
      "    log_marginal   : 1767.219721956073\n",
      "    val_loss       : -1766.3587239583333\n",
      "    val_ess        : 26.506389141082764\n",
      "    val_log_marginal: 1766.686543782552\n",
      "Train Epoch: 671 [0/54000 (0%)] Loss: -1769.220703\n",
      "Train Epoch: 671 [11264/54000 (21%)] Loss: -1764.434570\n",
      "Train Epoch: 671 [22528/54000 (42%)] Loss: -1764.054199\n",
      "Train Epoch: 671 [33792/54000 (63%)] Loss: -1771.835938\n",
      "Train Epoch: 671 [45056/54000 (83%)] Loss: -1766.946045\n",
      "    epoch          : 671\n",
      "    loss           : -1767.8651468528892\n",
      "    ess            : 26.777038844126576\n",
      "    log_marginal   : 1768.1896512013561\n",
      "    val_loss       : -1767.1709493001301\n",
      "    val_ess        : 27.105417092641193\n",
      "    val_log_marginal: 1767.4619954427083\n",
      "Train Epoch: 672 [0/54000 (0%)] Loss: -1767.106323\n",
      "Train Epoch: 672 [11264/54000 (21%)] Loss: -1774.226074\n",
      "Train Epoch: 672 [22528/54000 (42%)] Loss: -1772.826294\n",
      "Train Epoch: 672 [33792/54000 (63%)] Loss: -1771.467651\n",
      "Train Epoch: 672 [45056/54000 (83%)] Loss: -1760.949951\n",
      "    epoch          : 672\n",
      "    loss           : -1768.6177195423054\n",
      "    ess            : 26.798138150629008\n",
      "    log_marginal   : 1768.9408661464474\n",
      "    val_loss       : -1768.1935221354167\n",
      "    val_ess        : 26.82554229100545\n",
      "    val_log_marginal: 1768.5174458821614\n",
      "Train Epoch: 673 [0/54000 (0%)] Loss: -1772.236450\n",
      "Train Epoch: 673 [11264/54000 (21%)] Loss: -1766.199829\n",
      "Train Epoch: 673 [22528/54000 (42%)] Loss: -1752.722290\n",
      "Train Epoch: 673 [33792/54000 (63%)] Loss: -1726.311157\n",
      "Train Epoch: 673 [45056/54000 (83%)] Loss: -1734.705811\n",
      "    epoch          : 673\n",
      "    loss           : -1747.344134636645\n",
      "    ess            : 26.595051891398878\n",
      "    log_marginal   : 1747.6679238373379\n",
      "    val_loss       : -1738.0088399251301\n",
      "    val_ess        : 26.64774751663208\n",
      "    val_log_marginal: 1738.3109436035156\n",
      "Train Epoch: 674 [0/54000 (0%)] Loss: -1742.177734\n",
      "Train Epoch: 674 [11264/54000 (21%)] Loss: -1752.602661\n",
      "Train Epoch: 674 [22528/54000 (42%)] Loss: -1749.078979\n",
      "Train Epoch: 674 [33792/54000 (63%)] Loss: -1750.082886\n",
      "Train Epoch: 674 [45056/54000 (83%)] Loss: -1731.207764\n",
      "    epoch          : 674\n",
      "    loss           : -1745.1343429853332\n",
      "    ess            : 27.30721975722403\n",
      "    log_marginal   : 1745.4132817106427\n",
      "    val_loss       : -1745.2365315755208\n",
      "    val_ess        : 27.50275230407715\n",
      "    val_log_marginal: 1745.51220703125\n",
      "Train Epoch: 675 [0/54000 (0%)] Loss: -1749.820801\n",
      "Train Epoch: 675 [11264/54000 (21%)] Loss: -1755.074219\n",
      "Train Epoch: 675 [22528/54000 (42%)] Loss: -1756.343750\n",
      "Train Epoch: 675 [33792/54000 (63%)] Loss: -1757.128906\n",
      "Train Epoch: 675 [45056/54000 (83%)] Loss: -1764.327393\n",
      "    epoch          : 675\n",
      "    loss           : -1755.7729952830189\n",
      "    ess            : 27.33147610358472\n",
      "    log_marginal   : 1756.0541888542896\n",
      "    val_loss       : -1754.9439086914062\n",
      "    val_ess        : 27.21178452173869\n",
      "    val_log_marginal: 1755.2384847005208\n",
      "Train Epoch: 676 [0/54000 (0%)] Loss: -1764.222900\n",
      "Train Epoch: 676 [11264/54000 (21%)] Loss: -1763.633301\n",
      "Train Epoch: 676 [22528/54000 (42%)] Loss: -1760.250977\n",
      "Train Epoch: 676 [33792/54000 (63%)] Loss: -1759.181396\n",
      "Train Epoch: 676 [45056/54000 (83%)] Loss: -1765.010742\n",
      "    epoch          : 676\n",
      "    loss           : -1760.739270480174\n",
      "    ess            : 26.799746927225364\n",
      "    log_marginal   : 1761.0565519512825\n",
      "    val_loss       : -1760.1281636555989\n",
      "    val_ess        : 26.910892645517986\n",
      "    val_log_marginal: 1760.4366251627605\n",
      "Train Epoch: 677 [0/54000 (0%)] Loss: -1762.813843\n",
      "Train Epoch: 677 [11264/54000 (21%)] Loss: -1762.753052\n",
      "Train Epoch: 677 [22528/54000 (42%)] Loss: -1761.615479\n",
      "Train Epoch: 677 [33792/54000 (63%)] Loss: -1761.285767\n",
      "Train Epoch: 677 [45056/54000 (83%)] Loss: -1763.778320\n",
      "    epoch          : 677\n",
      "    loss           : -1763.074434100457\n",
      "    ess            : 26.768251275116544\n",
      "    log_marginal   : 1763.393567355174\n",
      "    val_loss       : -1762.6601664225261\n",
      "    val_ess        : 26.88816515604655\n",
      "    val_log_marginal: 1762.9688110351562\n",
      "Train Epoch: 678 [0/54000 (0%)] Loss: -1759.927246\n",
      "Train Epoch: 678 [11264/54000 (21%)] Loss: -1764.631348\n",
      "Train Epoch: 678 [22528/54000 (42%)] Loss: -1765.972168\n",
      "Train Epoch: 678 [33792/54000 (63%)] Loss: -1764.636230\n",
      "Train Epoch: 678 [45056/54000 (83%)] Loss: -1761.816895\n",
      "    epoch          : 678\n",
      "    loss           : -1764.60602727926\n",
      "    ess            : 26.74733671152367\n",
      "    log_marginal   : 1764.9257133052033\n",
      "    val_loss       : -1764.1140645345051\n",
      "    val_ess        : 26.644439220428467\n",
      "    val_log_marginal: 1764.4361572265625\n",
      "Train Epoch: 679 [0/54000 (0%)] Loss: -1768.194336\n",
      "Train Epoch: 679 [11264/54000 (21%)] Loss: -1771.862793\n",
      "Train Epoch: 679 [22528/54000 (42%)] Loss: -1763.831421\n",
      "Train Epoch: 679 [33792/54000 (63%)] Loss: -1766.268555\n",
      "Train Epoch: 679 [45056/54000 (83%)] Loss: -1767.721191\n",
      "    epoch          : 679\n",
      "    loss           : -1765.9920193654186\n",
      "    ess            : 26.71790216553886\n",
      "    log_marginal   : 1766.318772801813\n",
      "    val_loss       : -1765.7744852701824\n",
      "    val_ess        : 26.94844388961792\n",
      "    val_log_marginal: 1766.0762329101562\n",
      "Train Epoch: 680 [0/54000 (0%)] Loss: -1768.981812\n",
      "Train Epoch: 680 [11264/54000 (21%)] Loss: -1771.838013\n",
      "Train Epoch: 680 [22528/54000 (42%)] Loss: -1769.884521\n",
      "Train Epoch: 680 [33792/54000 (63%)] Loss: -1770.247192\n",
      "Train Epoch: 680 [45056/54000 (83%)] Loss: -1763.730225\n",
      "    epoch          : 680\n",
      "    loss           : -1767.0787572320903\n",
      "    ess            : 26.70923278016864\n",
      "    log_marginal   : 1767.4065874207695\n",
      "    val_loss       : -1766.8311462402344\n",
      "    val_ess        : 26.638198534647625\n",
      "    val_log_marginal: 1767.1653849283855\n",
      "Train Epoch: 681 [0/54000 (0%)] Loss: -1769.230225\n",
      "Train Epoch: 681 [11264/54000 (21%)] Loss: -1764.733398\n",
      "Train Epoch: 681 [22528/54000 (42%)] Loss: -1768.221191\n",
      "Train Epoch: 681 [33792/54000 (63%)] Loss: -1770.825684\n",
      "Train Epoch: 681 [45056/54000 (83%)] Loss: -1769.637939\n",
      "    epoch          : 681\n",
      "    loss           : -1767.9300997752064\n",
      "    ess            : 26.767262368831993\n",
      "    log_marginal   : 1768.2567058059406\n",
      "    val_loss       : -1767.335205078125\n",
      "    val_ess        : 26.86929718653361\n",
      "    val_log_marginal: 1767.6556498209636\n",
      "Train Epoch: 682 [0/54000 (0%)] Loss: -1772.730347\n",
      "Train Epoch: 682 [11264/54000 (21%)] Loss: -1765.407593\n",
      "Train Epoch: 682 [22528/54000 (42%)] Loss: -1770.700195\n",
      "Train Epoch: 682 [33792/54000 (63%)] Loss: -1765.375610\n",
      "Train Epoch: 682 [45056/54000 (83%)] Loss: -1764.366455\n",
      "    epoch          : 682\n",
      "    loss           : -1768.8950356537441\n",
      "    ess            : 26.836913864567595\n",
      "    log_marginal   : 1769.2150901938385\n",
      "    val_loss       : -1767.7687683105469\n",
      "    val_ess        : 26.664655367533367\n",
      "    val_log_marginal: 1768.09521484375\n",
      "Train Epoch: 683 [0/54000 (0%)] Loss: -1768.843140\n",
      "Train Epoch: 683 [11264/54000 (21%)] Loss: -1767.804443\n",
      "Train Epoch: 683 [22528/54000 (42%)] Loss: -1768.815186\n",
      "Train Epoch: 683 [33792/54000 (63%)] Loss: -1769.898193\n",
      "Train Epoch: 683 [45056/54000 (83%)] Loss: -1769.447021\n",
      "    epoch          : 683\n",
      "    loss           : -1769.683751520121\n",
      "    ess            : 26.89110727130242\n",
      "    log_marginal   : 1770.0023066682636\n",
      "    val_loss       : -1769.374979654948\n",
      "    val_ess        : 27.042272567749023\n",
      "    val_log_marginal: 1769.6769002278645\n",
      "Train Epoch: 684 [0/54000 (0%)] Loss: -1768.963623\n",
      "Train Epoch: 684 [11264/54000 (21%)] Loss: -1768.087646\n",
      "Train Epoch: 684 [22528/54000 (42%)] Loss: -1772.563110\n",
      "Train Epoch: 684 [33792/54000 (63%)] Loss: -1766.046265\n",
      "Train Epoch: 684 [45056/54000 (83%)] Loss: -1766.616211\n",
      "    epoch          : 684\n",
      "    loss           : -1768.7184620983196\n",
      "    ess            : 26.803132722962577\n",
      "    log_marginal   : 1769.0428167379127\n",
      "    val_loss       : -1759.558085123698\n",
      "    val_ess        : 26.784194946289062\n",
      "    val_log_marginal: 1759.8752848307292\n",
      "Train Epoch: 685 [0/54000 (0%)] Loss: -1758.535645\n",
      "Train Epoch: 685 [11264/54000 (21%)] Loss: -1766.208008\n",
      "Train Epoch: 685 [22528/54000 (42%)] Loss: -1757.327026\n",
      "Train Epoch: 685 [33792/54000 (63%)] Loss: -1752.906128\n",
      "Train Epoch: 685 [45056/54000 (83%)] Loss: -1756.849487\n",
      "    epoch          : 685\n",
      "    loss           : -1757.1828394475972\n",
      "    ess            : 26.82983333659622\n",
      "    log_marginal   : 1757.4938423588592\n",
      "    val_loss       : -1757.8417256673176\n",
      "    val_ess        : 27.050333817799885\n",
      "    val_log_marginal: 1758.1427815755208\n",
      "Train Epoch: 686 [0/54000 (0%)] Loss: -1763.843018\n",
      "Train Epoch: 686 [11264/54000 (21%)] Loss: -1765.922852\n",
      "Train Epoch: 686 [22528/54000 (42%)] Loss: -1764.407227\n",
      "Train Epoch: 686 [33792/54000 (63%)] Loss: -1764.423584\n",
      "Train Epoch: 686 [45056/54000 (83%)] Loss: -1768.909058\n",
      "    epoch          : 686\n",
      "    loss           : -1765.0891907889888\n",
      "    ess            : 27.295899697069853\n",
      "    log_marginal   : 1765.3809135005158\n",
      "    val_loss       : -1763.9436950683594\n",
      "    val_ess        : 26.988091945648193\n",
      "    val_log_marginal: 1764.2571105957031\n",
      "Train Epoch: 687 [0/54000 (0%)] Loss: -1772.315918\n",
      "Train Epoch: 687 [11264/54000 (21%)] Loss: -1769.141479\n",
      "Train Epoch: 687 [22528/54000 (42%)] Loss: -1764.420776\n",
      "Train Epoch: 687 [33792/54000 (63%)] Loss: -1771.486084\n",
      "Train Epoch: 687 [45056/54000 (83%)] Loss: -1768.240479\n",
      "    epoch          : 687\n",
      "    loss           : -1768.6457554079452\n",
      "    ess            : 26.970623808087044\n",
      "    log_marginal   : 1768.958831211306\n",
      "    val_loss       : -1768.2132873535156\n",
      "    val_ess        : 27.216981252034504\n",
      "    val_log_marginal: 1768.5103658040364\n",
      "Train Epoch: 688 [0/54000 (0%)] Loss: -1772.886230\n",
      "Train Epoch: 688 [11264/54000 (21%)] Loss: -1771.559814\n",
      "Train Epoch: 688 [22528/54000 (42%)] Loss: -1769.306152\n",
      "Train Epoch: 688 [33792/54000 (63%)] Loss: -1772.275269\n",
      "Train Epoch: 688 [45056/54000 (83%)] Loss: -1770.937500\n",
      "    epoch          : 688\n",
      "    loss           : -1770.330860065964\n",
      "    ess            : 26.906578567792785\n",
      "    log_marginal   : 1770.6489580262382\n",
      "    val_loss       : -1769.8350321451824\n",
      "    val_ess        : 26.854943593343098\n",
      "    val_log_marginal: 1770.1564432779949\n",
      "Train Epoch: 689 [0/54000 (0%)] Loss: -1767.417358\n",
      "Train Epoch: 689 [11264/54000 (21%)] Loss: -1768.777100\n",
      "Train Epoch: 689 [22528/54000 (42%)] Loss: -1768.746948\n",
      "Train Epoch: 689 [33792/54000 (63%)] Loss: -1773.855713\n",
      "Train Epoch: 689 [45056/54000 (83%)] Loss: -1770.698486\n",
      "    epoch          : 689\n",
      "    loss           : -1771.5052605395047\n",
      "    ess            : 26.936881947067548\n",
      "    log_marginal   : 1771.819348605174\n",
      "    val_loss       : -1771.1859639485676\n",
      "    val_ess        : 26.67964760462443\n",
      "    val_log_marginal: 1771.5234985351562\n",
      "Train Epoch: 690 [0/54000 (0%)] Loss: -1772.363037\n",
      "Train Epoch: 690 [11264/54000 (21%)] Loss: -1774.879639\n",
      "Train Epoch: 690 [22528/54000 (42%)] Loss: -1771.971924\n",
      "Train Epoch: 690 [33792/54000 (63%)] Loss: -1772.158447\n",
      "Train Epoch: 690 [45056/54000 (83%)] Loss: -1765.109985\n",
      "    epoch          : 690\n",
      "    loss           : -1772.1937716502064\n",
      "    ess            : 26.69870905606252\n",
      "    log_marginal   : 1772.5287832584022\n",
      "    val_loss       : -1771.330078125\n",
      "    val_ess        : 26.904489517211914\n",
      "    val_log_marginal: 1771.655741373698\n",
      "Train Epoch: 691 [0/54000 (0%)] Loss: -1767.007324\n",
      "Train Epoch: 691 [11264/54000 (21%)] Loss: -1764.868164\n",
      "Train Epoch: 691 [22528/54000 (42%)] Loss: -1765.204102\n",
      "Train Epoch: 691 [33792/54000 (63%)] Loss: -1730.590576\n",
      "Train Epoch: 691 [45056/54000 (83%)] Loss: -1749.118164\n",
      "    epoch          : 691\n",
      "    loss           : -1755.5474277712265\n",
      "    ess            : 26.65374802643398\n",
      "    log_marginal   : 1755.872020793411\n",
      "    val_loss       : -1759.9191385904949\n",
      "    val_ess        : 27.04535897572835\n",
      "    val_log_marginal: 1760.212890625\n",
      "Train Epoch: 692 [0/54000 (0%)] Loss: -1757.604858\n",
      "Train Epoch: 692 [11264/54000 (21%)] Loss: -1761.475464\n",
      "Train Epoch: 692 [22528/54000 (42%)] Loss: -1763.461426\n",
      "Train Epoch: 692 [33792/54000 (63%)] Loss: -1763.841064\n",
      "Train Epoch: 692 [45056/54000 (83%)] Loss: -1763.284668\n",
      "    epoch          : 692\n",
      "    loss           : -1762.7908728257664\n",
      "    ess            : 27.222264037941986\n",
      "    log_marginal   : 1763.0825713535526\n",
      "    val_loss       : -1767.0377197265625\n",
      "    val_ess        : 27.24932638804118\n",
      "    val_log_marginal: 1767.3356526692708\n",
      "Train Epoch: 693 [0/54000 (0%)] Loss: -1766.847656\n",
      "Train Epoch: 693 [11264/54000 (21%)] Loss: -1764.333008\n",
      "Train Epoch: 693 [22528/54000 (42%)] Loss: -1765.987305\n",
      "Train Epoch: 693 [33792/54000 (63%)] Loss: -1772.370361\n",
      "Train Epoch: 693 [45056/54000 (83%)] Loss: -1768.313232\n",
      "    epoch          : 693\n",
      "    loss           : -1767.880052098688\n",
      "    ess            : 27.043520207674998\n",
      "    log_marginal   : 1768.1858543539947\n",
      "    val_loss       : -1769.5315755208333\n",
      "    val_ess        : 26.84919198354085\n",
      "    val_log_marginal: 1769.8418273925781\n",
      "Train Epoch: 694 [0/54000 (0%)] Loss: -1773.822754\n",
      "Train Epoch: 694 [11264/54000 (21%)] Loss: -1773.093506\n",
      "Train Epoch: 694 [22528/54000 (42%)] Loss: -1766.099487\n",
      "Train Epoch: 694 [33792/54000 (63%)] Loss: -1766.562256\n",
      "Train Epoch: 694 [45056/54000 (83%)] Loss: -1772.148682\n",
      "    epoch          : 694\n",
      "    loss           : -1769.9605183151532\n",
      "    ess            : 26.868235696036862\n",
      "    log_marginal   : 1770.2791782595077\n",
      "    val_loss       : -1770.9137674967449\n",
      "    val_ess        : 26.856014251708984\n",
      "    val_log_marginal: 1771.2359517415364\n",
      "Train Epoch: 695 [0/54000 (0%)] Loss: -1773.406738\n",
      "Train Epoch: 695 [11264/54000 (21%)] Loss: -1771.401855\n",
      "Train Epoch: 695 [22528/54000 (42%)] Loss: -1771.283203\n",
      "Train Epoch: 695 [33792/54000 (63%)] Loss: -1769.354492\n",
      "Train Epoch: 695 [45056/54000 (83%)] Loss: -1772.175781\n",
      "    epoch          : 695\n",
      "    loss           : -1771.2962266454156\n",
      "    ess            : 26.870765506096607\n",
      "    log_marginal   : 1771.6154681511646\n",
      "    val_loss       : -1772.2085673014324\n",
      "    val_ess        : 26.661467870076496\n",
      "    val_log_marginal: 1772.5450439453125\n",
      "Train Epoch: 696 [0/54000 (0%)] Loss: -1775.863037\n",
      "Train Epoch: 696 [11264/54000 (21%)] Loss: -1775.169312\n",
      "Train Epoch: 696 [22528/54000 (42%)] Loss: -1772.169556\n",
      "Train Epoch: 696 [33792/54000 (63%)] Loss: -1777.894775\n",
      "Train Epoch: 696 [45056/54000 (83%)] Loss: -1776.735840\n",
      "    epoch          : 696\n",
      "    loss           : -1772.3082436615566\n",
      "    ess            : 26.805670702232504\n",
      "    log_marginal   : 1772.6326892780808\n",
      "    val_loss       : -1772.8185221354167\n",
      "    val_ess        : 26.69590409596761\n",
      "    val_log_marginal: 1773.1516011555989\n",
      "Train Epoch: 697 [0/54000 (0%)] Loss: -1769.616821\n",
      "Train Epoch: 697 [11264/54000 (21%)] Loss: -1773.903564\n",
      "Train Epoch: 697 [22528/54000 (42%)] Loss: -1777.109131\n",
      "Train Epoch: 697 [33792/54000 (63%)] Loss: -1771.299561\n",
      "Train Epoch: 697 [45056/54000 (83%)] Loss: -1777.214600\n",
      "    epoch          : 697\n",
      "    loss           : -1773.0944916347287\n",
      "    ess            : 26.83186811771033\n",
      "    log_marginal   : 1773.4179756596404\n",
      "    val_loss       : -1773.3582153320312\n",
      "    val_ess        : 26.80769411722819\n",
      "    val_log_marginal: 1773.678690592448\n",
      "Train Epoch: 698 [0/54000 (0%)] Loss: -1775.003662\n",
      "Train Epoch: 698 [11264/54000 (21%)] Loss: -1772.769287\n",
      "Train Epoch: 698 [22528/54000 (42%)] Loss: -1778.312500\n",
      "Train Epoch: 698 [33792/54000 (63%)] Loss: -1770.268188\n",
      "Train Epoch: 698 [45056/54000 (83%)] Loss: -1712.083984\n",
      "    epoch          : 698\n",
      "    loss           : -1760.4380331939121\n",
      "    ess            : 26.800553231869102\n",
      "    log_marginal   : 1760.7571238391804\n",
      "    val_loss       : -1726.0136617024739\n",
      "    val_ess        : 26.24844233194987\n",
      "    val_log_marginal: 1726.333028157552\n",
      "Train Epoch: 699 [0/54000 (0%)] Loss: -1730.471924\n",
      "Train Epoch: 699 [11264/54000 (21%)] Loss: -1749.646851\n",
      "Train Epoch: 699 [22528/54000 (42%)] Loss: -1762.983521\n",
      "Train Epoch: 699 [33792/54000 (63%)] Loss: -1761.484863\n",
      "Train Epoch: 699 [45056/54000 (83%)] Loss: -1767.269531\n",
      "    epoch          : 699\n",
      "    loss           : -1756.1110321620724\n",
      "    ess            : 27.030451504689342\n",
      "    log_marginal   : 1756.4114829009434\n",
      "    val_loss       : -1745.7896321614583\n",
      "    val_ess        : 28.210910320281982\n",
      "    val_log_marginal: 1746.0388081868489\n",
      "Train Epoch: 700 [0/54000 (0%)] Loss: -1763.702759\n",
      "Train Epoch: 700 [11264/54000 (21%)] Loss: -1762.775757\n",
      "Train Epoch: 700 [22528/54000 (42%)] Loss: -1763.347900\n",
      "Train Epoch: 700 [33792/54000 (63%)] Loss: -1760.685303\n",
      "Train Epoch: 700 [45056/54000 (83%)] Loss: -1763.233765\n",
      "    epoch          : 700\n",
      "    loss           : -1764.665431760392\n",
      "    ess            : 27.10204477130242\n",
      "    log_marginal   : 1764.9667462043042\n",
      "    val_loss       : -1759.2294311523438\n",
      "    val_ess        : 27.53082052866618\n",
      "    val_log_marginal: 1759.5088907877605\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [0/54000 (0%)] Loss: -1769.297119\n",
      "Train Epoch: 701 [11264/54000 (21%)] Loss: -1765.591797\n",
      "Train Epoch: 701 [22528/54000 (42%)] Loss: -1766.614380\n",
      "Train Epoch: 701 [33792/54000 (63%)] Loss: -1763.953735\n",
      "Train Epoch: 701 [45056/54000 (83%)] Loss: -1765.949829\n",
      "    epoch          : 701\n",
      "    loss           : -1767.751783838812\n",
      "    ess            : 26.93474672425468\n",
      "    log_marginal   : 1768.0708468455189\n",
      "    val_loss       : -1763.0465393066406\n",
      "    val_ess        : 26.960909366607666\n",
      "    val_log_marginal: 1763.3635762532551\n",
      "Train Epoch: 702 [0/54000 (0%)] Loss: -1768.317139\n",
      "Train Epoch: 702 [11264/54000 (21%)] Loss: -1769.948364\n",
      "Train Epoch: 702 [22528/54000 (42%)] Loss: -1767.202393\n",
      "Train Epoch: 702 [33792/54000 (63%)] Loss: -1767.756104\n",
      "Train Epoch: 702 [45056/54000 (83%)] Loss: -1768.016357\n",
      "    epoch          : 702\n",
      "    loss           : -1769.5531132536114\n",
      "    ess            : 26.768087477054237\n",
      "    log_marginal   : 1769.8757024801002\n",
      "    val_loss       : -1765.7004699707031\n",
      "    val_ess        : 27.018362522125244\n",
      "    val_log_marginal: 1766.0147806803386\n",
      "Train Epoch: 703 [0/54000 (0%)] Loss: -1766.943359\n",
      "Train Epoch: 703 [11264/54000 (21%)] Loss: -1770.939209\n",
      "Train Epoch: 703 [22528/54000 (42%)] Loss: -1770.433350\n",
      "Train Epoch: 703 [33792/54000 (63%)] Loss: -1770.829834\n",
      "Train Epoch: 703 [45056/54000 (83%)] Loss: -1773.224854\n",
      "    epoch          : 703\n",
      "    loss           : -1770.7638987415241\n",
      "    ess            : 26.831354555094016\n",
      "    log_marginal   : 1771.0891458763267\n",
      "    val_loss       : -1767.5551045735676\n",
      "    val_ess        : 27.075642903645832\n",
      "    val_log_marginal: 1767.8708089192708\n",
      "Train Epoch: 704 [0/54000 (0%)] Loss: -1772.411255\n",
      "Train Epoch: 704 [11264/54000 (21%)] Loss: -1773.389648\n",
      "Train Epoch: 704 [22528/54000 (42%)] Loss: -1767.729614\n",
      "Train Epoch: 704 [33792/54000 (63%)] Loss: -1776.824707\n",
      "Train Epoch: 704 [45056/54000 (83%)] Loss: -1774.151245\n",
      "    epoch          : 704\n",
      "    loss           : -1771.281307580336\n",
      "    ess            : 26.872664559562253\n",
      "    log_marginal   : 1771.5990773326946\n",
      "    val_loss       : -1764.6782836914062\n",
      "    val_ess        : 26.940887610117596\n",
      "    val_log_marginal: 1765.0047810872395\n",
      "Train Epoch: 705 [0/54000 (0%)] Loss: -1770.578491\n",
      "Train Epoch: 705 [11264/54000 (21%)] Loss: -1731.411621\n",
      "Train Epoch: 705 [22528/54000 (42%)] Loss: -1755.225586\n",
      "Train Epoch: 705 [33792/54000 (63%)] Loss: -1760.909912\n",
      "Train Epoch: 705 [45056/54000 (83%)] Loss: -1749.426636\n",
      "    epoch          : 705\n",
      "    loss           : -1749.2317458818543\n",
      "    ess            : 26.681748066308362\n",
      "    log_marginal   : 1749.5510507259728\n",
      "    val_loss       : -1756.108174641927\n",
      "    val_ess        : 26.694514274597168\n",
      "    val_log_marginal: 1756.4327799479167\n",
      "Train Epoch: 706 [0/54000 (0%)] Loss: -1759.623779\n",
      "Train Epoch: 706 [11264/54000 (21%)] Loss: -1758.661621\n",
      "Train Epoch: 706 [22528/54000 (42%)] Loss: -1764.906128\n",
      "Train Epoch: 706 [33792/54000 (63%)] Loss: -1768.897461\n",
      "Train Epoch: 706 [45056/54000 (83%)] Loss: -1764.376221\n",
      "    epoch          : 706\n",
      "    loss           : -1762.4942431179982\n",
      "    ess            : 27.501368252736217\n",
      "    log_marginal   : 1762.7714452203716\n",
      "    val_loss       : -1764.0391947428386\n",
      "    val_ess        : 27.170825322469074\n",
      "    val_log_marginal: 1764.3326314290364\n",
      "Train Epoch: 707 [0/54000 (0%)] Loss: -1766.256348\n",
      "Train Epoch: 707 [11264/54000 (21%)] Loss: -1765.305664\n",
      "Train Epoch: 707 [22528/54000 (42%)] Loss: -1771.256714\n",
      "Train Epoch: 707 [33792/54000 (63%)] Loss: -1764.302979\n",
      "Train Epoch: 707 [45056/54000 (83%)] Loss: -1769.048462\n",
      "    epoch          : 707\n",
      "    loss           : -1767.121288371536\n",
      "    ess            : 26.89049978076287\n",
      "    log_marginal   : 1767.4381771447524\n",
      "    val_loss       : -1767.3152974446614\n",
      "    val_ess        : 26.750008583068848\n",
      "    val_log_marginal: 1767.6454366048176\n",
      "Train Epoch: 708 [0/54000 (0%)] Loss: -1774.539795\n",
      "Train Epoch: 708 [11264/54000 (21%)] Loss: -1772.143188\n",
      "Train Epoch: 708 [22528/54000 (42%)] Loss: -1769.250977\n",
      "Train Epoch: 708 [33792/54000 (63%)] Loss: -1768.876587\n",
      "Train Epoch: 708 [45056/54000 (83%)] Loss: -1764.355347\n",
      "    epoch          : 708\n",
      "    loss           : -1769.354774331147\n",
      "    ess            : 26.829199449071343\n",
      "    log_marginal   : 1769.6790978773586\n",
      "    val_loss       : -1768.645772298177\n",
      "    val_ess        : 26.81641435623169\n",
      "    val_log_marginal: 1768.9868876139324\n",
      "Train Epoch: 709 [0/54000 (0%)] Loss: -1765.654541\n",
      "Train Epoch: 709 [11264/54000 (21%)] Loss: -1767.959717\n",
      "Train Epoch: 709 [22528/54000 (42%)] Loss: -1771.505981\n",
      "Train Epoch: 709 [33792/54000 (63%)] Loss: -1768.175049\n",
      "Train Epoch: 709 [45056/54000 (83%)] Loss: -1775.207886\n",
      "    epoch          : 709\n",
      "    loss           : -1770.7362187223614\n",
      "    ess            : 26.836077726112222\n",
      "    log_marginal   : 1771.0619034677181\n",
      "    val_loss       : -1769.6913655598958\n",
      "    val_ess        : 26.619129816691082\n",
      "    val_log_marginal: 1770.0253499348958\n",
      "Train Epoch: 710 [0/54000 (0%)] Loss: -1776.448975\n",
      "Train Epoch: 710 [11264/54000 (21%)] Loss: -1769.396118\n",
      "Train Epoch: 710 [22528/54000 (42%)] Loss: -1775.012451\n",
      "Train Epoch: 710 [33792/54000 (63%)] Loss: -1773.329712\n",
      "Train Epoch: 710 [45056/54000 (83%)] Loss: -1773.131836\n",
      "    epoch          : 710\n",
      "    loss           : -1771.8439250442218\n",
      "    ess            : 26.86396598815918\n",
      "    log_marginal   : 1772.1636836213886\n",
      "    val_loss       : -1770.5677795410156\n",
      "    val_ess        : 26.645108858744305\n",
      "    val_log_marginal: 1770.8988850911458\n",
      "Train Epoch: 711 [0/54000 (0%)] Loss: -1772.558594\n",
      "Train Epoch: 711 [11264/54000 (21%)] Loss: -1768.592529\n",
      "Train Epoch: 711 [22528/54000 (42%)] Loss: -1775.197510\n",
      "Train Epoch: 711 [33792/54000 (63%)] Loss: -1776.465820\n",
      "Train Epoch: 711 [45056/54000 (83%)] Loss: -1772.534180\n",
      "    epoch          : 711\n",
      "    loss           : -1772.821206146816\n",
      "    ess            : 26.868586108369648\n",
      "    log_marginal   : 1773.1450909308667\n",
      "    val_loss       : -1771.4805196126301\n",
      "    val_ess        : 26.80770508448283\n",
      "    val_log_marginal: 1771.7960510253906\n",
      "Train Epoch: 712 [0/54000 (0%)] Loss: -1769.578979\n",
      "Train Epoch: 712 [11264/54000 (21%)] Loss: -1773.026855\n",
      "Train Epoch: 712 [22528/54000 (42%)] Loss: -1775.362305\n",
      "Train Epoch: 712 [33792/54000 (63%)] Loss: -1771.688354\n",
      "Train Epoch: 712 [45056/54000 (83%)] Loss: -1711.879150\n",
      "    epoch          : 712\n",
      "    loss           : -1760.5319686025944\n",
      "    ess            : 26.838126416476268\n",
      "    log_marginal   : 1760.8450478607754\n",
      "    val_loss       : -1732.2682800292969\n",
      "    val_ess        : 26.408601601918537\n",
      "    val_log_marginal: 1732.5901997884114\n",
      "Train Epoch: 713 [0/54000 (0%)] Loss: -1736.949341\n",
      "Train Epoch: 713 [11264/54000 (21%)] Loss: -1741.021851\n",
      "Train Epoch: 713 [22528/54000 (42%)] Loss: -1744.785889\n",
      "Train Epoch: 713 [33792/54000 (63%)] Loss: -1749.331055\n",
      "Train Epoch: 713 [45056/54000 (83%)] Loss: -1753.999634\n",
      "    epoch          : 713\n",
      "    loss           : -1746.830044728405\n",
      "    ess            : 26.847813840182322\n",
      "    log_marginal   : 1747.1404787459464\n",
      "    val_loss       : -1748.0074564615886\n",
      "    val_ess        : 27.54060951868693\n",
      "    val_log_marginal: 1748.2791137695312\n",
      "Train Epoch: 714 [0/54000 (0%)] Loss: -1766.778564\n",
      "Train Epoch: 714 [11264/54000 (21%)] Loss: -1762.861938\n",
      "Train Epoch: 714 [22528/54000 (42%)] Loss: -1762.004395\n",
      "Train Epoch: 714 [33792/54000 (63%)] Loss: -1759.566528\n",
      "Train Epoch: 714 [45056/54000 (83%)] Loss: -1758.294922\n",
      "    epoch          : 714\n",
      "    loss           : -1759.8221688900353\n",
      "    ess            : 27.336709274435943\n",
      "    log_marginal   : 1760.1093070552033\n",
      "    val_loss       : -1759.433329264323\n",
      "    val_ess        : 27.168165524800617\n",
      "    val_log_marginal: 1759.725362141927\n",
      "Train Epoch: 715 [0/54000 (0%)] Loss: -1763.390625\n",
      "Train Epoch: 715 [11264/54000 (21%)] Loss: -1766.775879\n",
      "Train Epoch: 715 [22528/54000 (42%)] Loss: -1761.444336\n",
      "Train Epoch: 715 [33792/54000 (63%)] Loss: -1765.825928\n",
      "Train Epoch: 715 [45056/54000 (83%)] Loss: -1767.442871\n",
      "    epoch          : 715\n",
      "    loss           : -1764.2547757130749\n",
      "    ess            : 26.83606919702494\n",
      "    log_marginal   : 1764.5707650814416\n",
      "    val_loss       : -1762.4706115722656\n",
      "    val_ess        : 26.65305503209432\n",
      "    val_log_marginal: 1762.8024495442708\n",
      "Train Epoch: 716 [0/54000 (0%)] Loss: -1763.487427\n",
      "Train Epoch: 716 [11264/54000 (21%)] Loss: -1766.135132\n",
      "Train Epoch: 716 [22528/54000 (42%)] Loss: -1762.994507\n",
      "Train Epoch: 716 [33792/54000 (63%)] Loss: -1770.638306\n",
      "Train Epoch: 716 [45056/54000 (83%)] Loss: -1769.622314\n",
      "    epoch          : 716\n",
      "    loss           : -1766.3331713406544\n",
      "    ess            : 26.866448474380206\n",
      "    log_marginal   : 1766.6487300081073\n",
      "    val_loss       : -1764.3426310221355\n",
      "    val_ess        : 26.977799733479817\n",
      "    val_log_marginal: 1764.6538492838542\n",
      "Train Epoch: 717 [0/54000 (0%)] Loss: -1768.730957\n",
      "Train Epoch: 717 [11264/54000 (21%)] Loss: -1771.532471\n",
      "Train Epoch: 717 [22528/54000 (42%)] Loss: -1764.533936\n",
      "Train Epoch: 717 [33792/54000 (63%)] Loss: -1767.278442\n",
      "Train Epoch: 717 [45056/54000 (83%)] Loss: -1769.550293\n",
      "    epoch          : 717\n",
      "    loss           : -1767.826564572892\n",
      "    ess            : 26.784936545030128\n",
      "    log_marginal   : 1768.146819492556\n",
      "    val_loss       : -1765.7287190755208\n",
      "    val_ess        : 26.795568307240803\n",
      "    val_log_marginal: 1766.0414632161458\n",
      "Train Epoch: 718 [0/54000 (0%)] Loss: -1769.186768\n",
      "Train Epoch: 718 [11264/54000 (21%)] Loss: -1771.498535\n",
      "Train Epoch: 718 [22528/54000 (42%)] Loss: -1766.980591\n",
      "Train Epoch: 718 [33792/54000 (63%)] Loss: -1765.640869\n",
      "Train Epoch: 718 [45056/54000 (83%)] Loss: -1773.305176\n",
      "    epoch          : 718\n",
      "    loss           : -1769.0471248986587\n",
      "    ess            : 26.81623478655545\n",
      "    log_marginal   : 1769.3667798312206\n",
      "    val_loss       : -1767.3582255045574\n",
      "    val_ess        : 26.869677702585857\n",
      "    val_log_marginal: 1767.6777852376301\n",
      "Train Epoch: 719 [0/54000 (0%)] Loss: -1772.727295\n",
      "Train Epoch: 719 [11264/54000 (21%)] Loss: -1771.967041\n",
      "Train Epoch: 719 [22528/54000 (42%)] Loss: -1773.293823\n",
      "Train Epoch: 719 [33792/54000 (63%)] Loss: -1772.539551\n",
      "Train Epoch: 719 [45056/54000 (83%)] Loss: -1765.598267\n",
      "    epoch          : 719\n",
      "    loss           : -1770.1326132720371\n",
      "    ess            : 26.793593460658812\n",
      "    log_marginal   : 1770.4591882093898\n",
      "    val_loss       : -1767.9080098470051\n",
      "    val_ess        : 26.803780873616535\n",
      "    val_log_marginal: 1768.2371622721355\n",
      "Train Epoch: 720 [0/54000 (0%)] Loss: -1772.973389\n",
      "Train Epoch: 720 [11264/54000 (21%)] Loss: -1770.507568\n",
      "Train Epoch: 720 [22528/54000 (42%)] Loss: -1766.439941\n",
      "Train Epoch: 720 [33792/54000 (63%)] Loss: -1764.954712\n",
      "Train Epoch: 720 [45056/54000 (83%)] Loss: -1768.685913\n",
      "    epoch          : 720\n",
      "    loss           : -1770.4328555700913\n",
      "    ess            : 26.87485633706147\n",
      "    log_marginal   : 1770.752470196418\n",
      "    val_loss       : -1764.6350708007812\n",
      "    val_ess        : 26.63663895924886\n",
      "    val_log_marginal: 1764.9525044759114\n",
      "Train Epoch: 721 [0/54000 (0%)] Loss: -1770.606567\n",
      "Train Epoch: 721 [11264/54000 (21%)] Loss: -1736.841675\n",
      "Train Epoch: 721 [22528/54000 (42%)] Loss: -1745.457031\n",
      "Train Epoch: 721 [33792/54000 (63%)] Loss: -1742.050049\n",
      "Train Epoch: 721 [45056/54000 (83%)] Loss: -1732.885986\n",
      "    epoch          : 721\n",
      "    loss           : -1742.8768563900353\n",
      "    ess            : 26.463092534047252\n",
      "    log_marginal   : 1743.2079064711086\n",
      "    val_loss       : -1744.2522379557292\n",
      "    val_ess        : 26.85979970296224\n",
      "    val_log_marginal: 1744.548848470052\n",
      "Train Epoch: 722 [0/54000 (0%)] Loss: -1747.597900\n",
      "Train Epoch: 722 [11264/54000 (21%)] Loss: -1758.499512\n",
      "Train Epoch: 722 [22528/54000 (42%)] Loss: -1761.644043\n",
      "Train Epoch: 722 [33792/54000 (63%)] Loss: -1757.593506\n",
      "Train Epoch: 722 [45056/54000 (83%)] Loss: -1752.504028\n",
      "    epoch          : 722\n",
      "    loss           : -1757.8754145784198\n",
      "    ess            : 27.466477646017974\n",
      "    log_marginal   : 1758.148619453862\n",
      "    val_loss       : -1755.963643391927\n",
      "    val_ess        : 27.49449078241984\n",
      "    val_log_marginal: 1756.2451985677083\n",
      "Train Epoch: 723 [0/54000 (0%)] Loss: -1767.855347\n",
      "Train Epoch: 723 [11264/54000 (21%)] Loss: -1763.208008\n",
      "Train Epoch: 723 [22528/54000 (42%)] Loss: -1768.441650\n",
      "Train Epoch: 723 [33792/54000 (63%)] Loss: -1761.385498\n",
      "Train Epoch: 723 [45056/54000 (83%)] Loss: -1764.566162\n",
      "    epoch          : 723\n",
      "    loss           : -1763.457615114608\n",
      "    ess            : 26.85250413642739\n",
      "    log_marginal   : 1763.7745315263855\n",
      "    val_loss       : -1761.7289225260417\n",
      "    val_ess        : 27.01655451456706\n",
      "    val_log_marginal: 1762.0351155598958\n",
      "Train Epoch: 724 [0/54000 (0%)] Loss: -1766.485352\n",
      "Train Epoch: 724 [11264/54000 (21%)] Loss: -1764.954834\n",
      "Train Epoch: 724 [22528/54000 (42%)] Loss: -1765.935425\n",
      "Train Epoch: 724 [33792/54000 (63%)] Loss: -1764.016846\n",
      "Train Epoch: 724 [45056/54000 (83%)] Loss: -1763.916870\n",
      "    epoch          : 724\n",
      "    loss           : -1765.9618046598614\n",
      "    ess            : 26.78601088613834\n",
      "    log_marginal   : 1766.27992565227\n",
      "    val_loss       : -1764.1534627278645\n",
      "    val_ess        : 26.696903546651203\n",
      "    val_log_marginal: 1764.4757080078125\n",
      "Train Epoch: 725 [0/54000 (0%)] Loss: -1768.081787\n",
      "Train Epoch: 725 [11264/54000 (21%)] Loss: -1770.672363\n",
      "Train Epoch: 725 [22528/54000 (42%)] Loss: -1769.582886\n",
      "Train Epoch: 725 [33792/54000 (63%)] Loss: -1767.871094\n",
      "Train Epoch: 725 [45056/54000 (83%)] Loss: -1767.869873\n",
      "    epoch          : 725\n",
      "    loss           : -1767.5383266233048\n",
      "    ess            : 26.762241561457795\n",
      "    log_marginal   : 1767.8598817069576\n",
      "    val_loss       : -1765.8087463378906\n",
      "    val_ess        : 26.67611328760783\n",
      "    val_log_marginal: 1766.1400248209636\n",
      "Train Epoch: 726 [0/54000 (0%)] Loss: -1765.799072\n",
      "Train Epoch: 726 [11264/54000 (21%)] Loss: -1765.719482\n",
      "Train Epoch: 726 [22528/54000 (42%)] Loss: -1767.593384\n",
      "Train Epoch: 726 [33792/54000 (63%)] Loss: -1774.106689\n",
      "Train Epoch: 726 [45056/54000 (83%)] Loss: -1773.273804\n",
      "    epoch          : 726\n",
      "    loss           : -1768.7972423625442\n",
      "    ess            : 26.80376668246287\n",
      "    log_marginal   : 1769.115925339033\n",
      "    val_loss       : -1766.9713745117188\n",
      "    val_ess        : 26.6463721593221\n",
      "    val_log_marginal: 1767.3036499023438\n",
      "Train Epoch: 727 [0/54000 (0%)] Loss: -1767.830688\n",
      "Train Epoch: 727 [11264/54000 (21%)] Loss: -1769.096191\n",
      "Train Epoch: 727 [22528/54000 (42%)] Loss: -1770.652466\n",
      "Train Epoch: 727 [33792/54000 (63%)] Loss: -1767.548584\n",
      "Train Epoch: 727 [45056/54000 (83%)] Loss: -1767.430664\n",
      "    epoch          : 727\n",
      "    loss           : -1769.8003390330189\n",
      "    ess            : 26.846619228147112\n",
      "    log_marginal   : 1770.122893711306\n",
      "    val_loss       : -1767.9326985677083\n",
      "    val_ess        : 26.871206919352215\n",
      "    val_log_marginal: 1768.2467244466145\n",
      "Train Epoch: 728 [0/54000 (0%)] Loss: -1774.515625\n",
      "Train Epoch: 728 [11264/54000 (21%)] Loss: -1768.667358\n",
      "Train Epoch: 728 [22528/54000 (42%)] Loss: -1769.880005\n",
      "Train Epoch: 728 [33792/54000 (63%)] Loss: -1766.999756\n",
      "Train Epoch: 728 [45056/54000 (83%)] Loss: -1727.319580\n",
      "    epoch          : 728\n",
      "    loss           : -1758.8865356445312\n",
      "    ess            : 26.721718014411206\n",
      "    log_marginal   : 1759.209547510687\n",
      "    val_loss       : -1722.0819702148438\n",
      "    val_ess        : 26.442874749501545\n",
      "    val_log_marginal: 1722.384256998698\n",
      "Train Epoch: 729 [0/54000 (0%)] Loss: -1723.434082\n",
      "Train Epoch: 729 [11264/54000 (21%)] Loss: -1742.569092\n",
      "Train Epoch: 729 [22528/54000 (42%)] Loss: -1742.822998\n",
      "Train Epoch: 729 [33792/54000 (63%)] Loss: -1741.429077\n",
      "Train Epoch: 729 [45056/54000 (83%)] Loss: -1743.045166\n",
      "    epoch          : 729\n",
      "    loss           : -1742.3256375294811\n",
      "    ess            : 26.86512167948597\n",
      "    log_marginal   : 1742.6294590212265\n",
      "    val_loss       : -1735.9844156901042\n",
      "    val_ess        : 28.117645740509033\n",
      "    val_log_marginal: 1736.2290445963542\n",
      "Train Epoch: 730 [0/54000 (0%)] Loss: -1749.205811\n",
      "Train Epoch: 730 [11264/54000 (21%)] Loss: -1759.324829\n",
      "Train Epoch: 730 [22528/54000 (42%)] Loss: -1757.135254\n",
      "Train Epoch: 730 [33792/54000 (63%)] Loss: -1751.943115\n",
      "Train Epoch: 730 [45056/54000 (83%)] Loss: -1760.287598\n",
      "    epoch          : 730\n",
      "    loss           : -1756.7065890330189\n",
      "    ess            : 27.457878886528736\n",
      "    log_marginal   : 1756.9802844929245\n",
      "    val_loss       : -1751.1591084798176\n",
      "    val_ess        : 27.574005603790283\n",
      "    val_log_marginal: 1751.4318949381511\n",
      "Train Epoch: 731 [0/54000 (0%)] Loss: -1758.376709\n",
      "Train Epoch: 731 [11264/54000 (21%)] Loss: -1762.224976\n",
      "Train Epoch: 731 [22528/54000 (42%)] Loss: -1758.751465\n",
      "Train Epoch: 731 [33792/54000 (63%)] Loss: -1763.740234\n",
      "Train Epoch: 731 [45056/54000 (83%)] Loss: -1766.269287\n",
      "    epoch          : 731\n",
      "    loss           : -1761.9333380933078\n",
      "    ess            : 26.93888397936551\n",
      "    log_marginal   : 1762.2430408405808\n",
      "    val_loss       : -1756.5824584960938\n",
      "    val_ess        : 27.056026776631672\n",
      "    val_log_marginal: 1756.8760986328125\n",
      "Train Epoch: 732 [0/54000 (0%)] Loss: -1766.229492\n",
      "Train Epoch: 732 [11264/54000 (21%)] Loss: -1763.996094\n",
      "Train Epoch: 732 [22528/54000 (42%)] Loss: -1764.544434\n",
      "Train Epoch: 732 [33792/54000 (63%)] Loss: -1765.232910\n",
      "Train Epoch: 732 [45056/54000 (83%)] Loss: -1760.957153\n",
      "    epoch          : 732\n",
      "    loss           : -1764.4135546414357\n",
      "    ess            : 26.7052640914917\n",
      "    log_marginal   : 1764.7392946639152\n",
      "    val_loss       : -1760.0104573567708\n",
      "    val_ess        : 26.865155537923176\n",
      "    val_log_marginal: 1760.3290913899739\n",
      "Train Epoch: 733 [0/54000 (0%)] Loss: -1768.356567\n",
      "Train Epoch: 733 [11264/54000 (21%)] Loss: -1761.607666\n",
      "Train Epoch: 733 [22528/54000 (42%)] Loss: -1766.741455\n",
      "Train Epoch: 733 [33792/54000 (63%)] Loss: -1768.842285\n",
      "Train Epoch: 733 [45056/54000 (83%)] Loss: -1763.066406\n",
      "    epoch          : 733\n",
      "    loss           : -1766.0579891564712\n",
      "    ess            : 26.721235347243976\n",
      "    log_marginal   : 1766.3865287348908\n",
      "    val_loss       : -1761.7285766601562\n",
      "    val_ess        : 26.853351910909016\n",
      "    val_log_marginal: 1762.0539245605469\n",
      "Train Epoch: 734 [0/54000 (0%)] Loss: -1773.148315\n",
      "Train Epoch: 734 [11264/54000 (21%)] Loss: -1771.633179\n",
      "Train Epoch: 734 [22528/54000 (42%)] Loss: -1768.394897\n",
      "Train Epoch: 734 [33792/54000 (63%)] Loss: -1768.057129\n",
      "Train Epoch: 734 [45056/54000 (83%)] Loss: -1766.817749\n",
      "    epoch          : 734\n",
      "    loss           : -1767.3795177531692\n",
      "    ess            : 26.680496503721994\n",
      "    log_marginal   : 1767.7152134157577\n",
      "    val_loss       : -1763.5330098470051\n",
      "    val_ess        : 26.857843557993572\n",
      "    val_log_marginal: 1763.852559407552\n",
      "Train Epoch: 735 [0/54000 (0%)] Loss: -1770.596069\n",
      "Train Epoch: 735 [11264/54000 (21%)] Loss: -1767.533936\n",
      "Train Epoch: 735 [22528/54000 (42%)] Loss: -1769.350098\n",
      "Train Epoch: 735 [33792/54000 (63%)] Loss: -1765.517212\n",
      "Train Epoch: 735 [45056/54000 (83%)] Loss: -1770.804199\n",
      "    epoch          : 735\n",
      "    loss           : -1768.6734112433667\n",
      "    ess            : 26.724489931790334\n",
      "    log_marginal   : 1768.9987493551002\n",
      "    val_loss       : -1764.8286539713542\n",
      "    val_ess        : 26.76686652501424\n",
      "    val_log_marginal: 1765.1532185872395\n",
      "Train Epoch: 736 [0/54000 (0%)] Loss: -1773.126465\n",
      "Train Epoch: 736 [11264/54000 (21%)] Loss: -1768.497559\n",
      "Train Epoch: 736 [22528/54000 (42%)] Loss: -1769.364746\n",
      "Train Epoch: 736 [33792/54000 (63%)] Loss: -1767.186646\n",
      "Train Epoch: 736 [45056/54000 (83%)] Loss: -1765.286865\n",
      "    epoch          : 736\n",
      "    loss           : -1769.7628807211822\n",
      "    ess            : 26.8249221657807\n",
      "    log_marginal   : 1770.0863981426887\n",
      "    val_loss       : -1766.3018290201824\n",
      "    val_ess        : 26.834002653757732\n",
      "    val_log_marginal: 1766.6322937011719\n",
      "Train Epoch: 737 [0/54000 (0%)] Loss: -1776.873413\n",
      "Train Epoch: 737 [11264/54000 (21%)] Loss: -1769.508667\n",
      "Train Epoch: 737 [22528/54000 (42%)] Loss: -1767.161255\n",
      "Train Epoch: 737 [33792/54000 (63%)] Loss: -1773.006592\n",
      "Train Epoch: 737 [45056/54000 (83%)] Loss: -1771.071899\n",
      "    epoch          : 737\n",
      "    loss           : -1769.808328880454\n",
      "    ess            : 26.78529615222283\n",
      "    log_marginal   : 1770.134020535451\n",
      "    val_loss       : -1753.8003946940105\n",
      "    val_ess        : 26.682478109995525\n",
      "    val_log_marginal: 1754.1310628255208\n",
      "Train Epoch: 738 [0/54000 (0%)] Loss: -1764.576172\n",
      "Train Epoch: 738 [11264/54000 (21%)] Loss: -1740.789917\n",
      "Train Epoch: 738 [22528/54000 (42%)] Loss: -1759.445312\n",
      "Train Epoch: 738 [33792/54000 (63%)] Loss: -1764.589478\n",
      "Train Epoch: 738 [45056/54000 (83%)] Loss: -1760.670654\n",
      "    epoch          : 738\n",
      "    loss           : -1757.7386566737912\n",
      "    ess            : 26.65232645790532\n",
      "    log_marginal   : 1758.0647007204452\n",
      "    val_loss       : -1762.9108784993489\n",
      "    val_ess        : 27.3403426806132\n",
      "    val_log_marginal: 1763.1853535970051\n",
      "Train Epoch: 739 [0/54000 (0%)] Loss: -1763.259155\n",
      "Train Epoch: 739 [11264/54000 (21%)] Loss: -1765.372681\n",
      "Train Epoch: 739 [22528/54000 (42%)] Loss: -1769.206421\n",
      "Train Epoch: 739 [33792/54000 (63%)] Loss: -1766.710571\n",
      "Train Epoch: 739 [45056/54000 (83%)] Loss: -1767.032593\n",
      "    epoch          : 739\n",
      "    loss           : -1766.6992659658756\n",
      "    ess            : 27.30659330116128\n",
      "    log_marginal   : 1766.9879968031398\n",
      "    val_loss       : -1766.0233052571614\n",
      "    val_ess        : 26.878705660502117\n",
      "    val_log_marginal: 1766.3403015136719\n",
      "Train Epoch: 740 [0/54000 (0%)] Loss: -1768.366577\n",
      "Train Epoch: 740 [11264/54000 (21%)] Loss: -1767.643311\n",
      "Train Epoch: 740 [22528/54000 (42%)] Loss: -1769.335205\n",
      "Train Epoch: 740 [33792/54000 (63%)] Loss: -1767.857178\n",
      "Train Epoch: 740 [45056/54000 (83%)] Loss: -1773.332275\n",
      "    epoch          : 740\n",
      "    loss           : -1769.6554853331368\n",
      "    ess            : 26.88047398261304\n",
      "    log_marginal   : 1769.9751621462265\n",
      "    val_loss       : -1767.651590983073\n",
      "    val_ess        : 27.012563228607178\n",
      "    val_log_marginal: 1767.9533182779949\n",
      "Train Epoch: 741 [0/54000 (0%)] Loss: -1768.039185\n",
      "Train Epoch: 741 [11264/54000 (21%)] Loss: -1771.714722\n",
      "Train Epoch: 741 [22528/54000 (42%)] Loss: -1771.575928\n",
      "Train Epoch: 741 [33792/54000 (63%)] Loss: -1769.663208\n",
      "Train Epoch: 741 [45056/54000 (83%)] Loss: -1770.698730\n",
      "    epoch          : 741\n",
      "    loss           : -1771.1388400095814\n",
      "    ess            : 26.817670228346337\n",
      "    log_marginal   : 1771.4622307543484\n",
      "    val_loss       : -1768.7526957194011\n",
      "    val_ess        : 26.673012733459473\n",
      "    val_log_marginal: 1769.0825907389324\n",
      "Train Epoch: 742 [0/54000 (0%)] Loss: -1780.189453\n",
      "Train Epoch: 742 [11264/54000 (21%)] Loss: -1775.093018\n",
      "Train Epoch: 742 [22528/54000 (42%)] Loss: -1769.271118\n",
      "Train Epoch: 742 [33792/54000 (63%)] Loss: -1775.600830\n",
      "Train Epoch: 742 [45056/54000 (83%)] Loss: -1773.487305\n",
      "    epoch          : 742\n",
      "    loss           : -1772.2764754385319\n",
      "    ess            : 26.802866521871316\n",
      "    log_marginal   : 1772.6004638671875\n",
      "    val_loss       : -1769.4044392903645\n",
      "    val_ess        : 26.783362070719402\n",
      "    val_log_marginal: 1769.7392476399739\n",
      "Train Epoch: 743 [0/54000 (0%)] Loss: -1775.107788\n",
      "Train Epoch: 743 [11264/54000 (21%)] Loss: -1774.159424\n",
      "Train Epoch: 743 [22528/54000 (42%)] Loss: -1773.382080\n",
      "Train Epoch: 743 [33792/54000 (63%)] Loss: -1769.414551\n",
      "Train Epoch: 743 [45056/54000 (83%)] Loss: -1773.661865\n",
      "    epoch          : 743\n",
      "    loss           : -1772.9742397092423\n",
      "    ess            : 26.84698950569585\n",
      "    log_marginal   : 1773.2982995375148\n",
      "    val_loss       : -1769.4503987630208\n",
      "    val_ess        : 26.957902908325195\n",
      "    val_log_marginal: 1769.779296875\n",
      "Train Epoch: 744 [0/54000 (0%)] Loss: -1774.392334\n",
      "Train Epoch: 744 [11264/54000 (21%)] Loss: -1758.184326\n",
      "Train Epoch: 744 [22528/54000 (42%)] Loss: -1761.409912\n",
      "Train Epoch: 744 [33792/54000 (63%)] Loss: -1768.017090\n",
      "Train Epoch: 744 [45056/54000 (83%)] Loss: -1760.832886\n",
      "    epoch          : 744\n",
      "    loss           : -1764.2321961600826\n",
      "    ess            : 26.795267806862885\n",
      "    log_marginal   : 1764.5555788436027\n",
      "    val_loss       : -1763.7518208821614\n",
      "    val_ess        : 27.207749366760254\n",
      "    val_log_marginal: 1764.0534566243489\n",
      "Train Epoch: 745 [0/54000 (0%)] Loss: -1772.745239\n",
      "Train Epoch: 745 [11264/54000 (21%)] Loss: -1768.043823\n",
      "Train Epoch: 745 [22528/54000 (42%)] Loss: -1768.264282\n",
      "Train Epoch: 745 [33792/54000 (63%)] Loss: -1768.119141\n",
      "Train Epoch: 745 [45056/54000 (83%)] Loss: -1775.286865\n",
      "    epoch          : 745\n",
      "    loss           : -1770.1663945036114\n",
      "    ess            : 27.163568802599638\n",
      "    log_marginal   : 1770.468812186763\n",
      "    val_loss       : -1768.58740234375\n",
      "    val_ess        : 27.07085927327474\n",
      "    val_log_marginal: 1768.9026285807292\n",
      "Train Epoch: 746 [0/54000 (0%)] Loss: -1769.362793\n",
      "Train Epoch: 746 [11264/54000 (21%)] Loss: -1777.052490\n",
      "Train Epoch: 746 [22528/54000 (42%)] Loss: -1772.515625\n",
      "Train Epoch: 746 [33792/54000 (63%)] Loss: -1770.531128\n",
      "Train Epoch: 746 [45056/54000 (83%)] Loss: -1772.023926\n",
      "    epoch          : 746\n",
      "    loss           : -1772.6165518130897\n",
      "    ess            : 26.952099188318794\n",
      "    log_marginal   : 1772.9316544442806\n",
      "    val_loss       : -1771.3792826334636\n",
      "    val_ess        : 26.983955542246502\n",
      "    val_log_marginal: 1771.7054138183594\n",
      "Train Epoch: 747 [0/54000 (0%)] Loss: -1774.241943\n",
      "Train Epoch: 747 [11264/54000 (21%)] Loss: -1773.673584\n",
      "Train Epoch: 747 [22528/54000 (42%)] Loss: -1773.449219\n",
      "Train Epoch: 747 [33792/54000 (63%)] Loss: -1771.035400\n",
      "Train Epoch: 747 [45056/54000 (83%)] Loss: -1776.059204\n",
      "    epoch          : 747\n",
      "    loss           : -1773.9434584131782\n",
      "    ess            : 26.91972628179586\n",
      "    log_marginal   : 1774.2652818211968\n",
      "    val_loss       : -1771.239013671875\n",
      "    val_ess        : 26.959097862243652\n",
      "    val_log_marginal: 1771.5524393717449\n",
      "Train Epoch: 748 [0/54000 (0%)] Loss: -1779.049194\n",
      "Train Epoch: 748 [11264/54000 (21%)] Loss: -1776.263794\n",
      "Train Epoch: 748 [22528/54000 (42%)] Loss: -1777.181519\n",
      "Train Epoch: 748 [33792/54000 (63%)] Loss: -1774.846802\n",
      "Train Epoch: 748 [45056/54000 (83%)] Loss: -1775.333740\n",
      "    epoch          : 748\n",
      "    loss           : -1774.8040138100678\n",
      "    ess            : 26.88097725274428\n",
      "    log_marginal   : 1775.1284525169517\n",
      "    val_loss       : -1772.7933756510417\n",
      "    val_ess        : 26.8241229057312\n",
      "    val_log_marginal: 1773.1244608561199\n",
      "Train Epoch: 749 [0/54000 (0%)] Loss: -1772.789062\n",
      "Train Epoch: 749 [11264/54000 (21%)] Loss: -1778.327026\n",
      "Train Epoch: 749 [22528/54000 (42%)] Loss: -1776.286499\n",
      "Train Epoch: 749 [33792/54000 (63%)] Loss: -1772.956665\n",
      "Train Epoch: 749 [45056/54000 (83%)] Loss: -1772.735229\n",
      "    epoch          : 749\n",
      "    loss           : -1775.436700784935\n",
      "    ess            : 26.908950121897572\n",
      "    log_marginal   : 1775.7590067161705\n",
      "    val_loss       : -1772.622782389323\n",
      "    val_ess        : 26.933475176493328\n",
      "    val_log_marginal: 1772.9336242675781\n",
      "Train Epoch: 750 [0/54000 (0%)] Loss: -1775.606445\n",
      "Train Epoch: 750 [11264/54000 (21%)] Loss: -1780.738281\n",
      "Train Epoch: 750 [22528/54000 (42%)] Loss: -1781.697266\n",
      "Train Epoch: 750 [33792/54000 (63%)] Loss: -1773.149048\n",
      "Train Epoch: 750 [45056/54000 (83%)] Loss: -1773.426758\n",
      "    epoch          : 750\n",
      "    loss           : -1776.3105192364387\n",
      "    ess            : 26.906207912373095\n",
      "    log_marginal   : 1776.6322021484375\n",
      "    val_loss       : -1773.7694702148438\n",
      "    val_ess        : 27.058972994486492\n",
      "    val_log_marginal: 1774.0861918131511\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch750.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "Train Epoch: 751 [0/54000 (0%)] Loss: -1777.065796\n",
      "Train Epoch: 751 [11264/54000 (21%)] Loss: -1772.891724\n",
      "Train Epoch: 751 [22528/54000 (42%)] Loss: -1776.146484\n",
      "Train Epoch: 751 [33792/54000 (63%)] Loss: -1781.177856\n",
      "Train Epoch: 751 [45056/54000 (83%)] Loss: -1778.284424\n",
      "    epoch          : 751\n",
      "    loss           : -1776.7318069170105\n",
      "    ess            : 26.946849625065642\n",
      "    log_marginal   : 1777.0472331496906\n",
      "    val_loss       : -1774.7345784505208\n",
      "    val_ess        : 27.109772205352783\n",
      "    val_log_marginal: 1775.051249186198\n",
      "Train Epoch: 752 [0/54000 (0%)] Loss: -1773.320801\n",
      "Train Epoch: 752 [11264/54000 (21%)] Loss: -1781.918457\n",
      "Train Epoch: 752 [22528/54000 (42%)] Loss: -1779.734131\n",
      "Train Epoch: 752 [33792/54000 (63%)] Loss: -1749.230591\n",
      "Train Epoch: 752 [45056/54000 (83%)] Loss: -1739.319458\n",
      "    epoch          : 752\n",
      "    loss           : -1762.887889934036\n",
      "    ess            : 26.842155186635143\n",
      "    log_marginal   : 1763.2099874244545\n",
      "    val_loss       : -1759.3971761067708\n",
      "    val_ess        : 26.77302583058675\n",
      "    val_log_marginal: 1759.7242024739583\n",
      "Train Epoch: 753 [0/54000 (0%)] Loss: -1759.198242\n",
      "Train Epoch: 753 [11264/54000 (21%)] Loss: -1760.785156\n",
      "Train Epoch: 753 [22528/54000 (42%)] Loss: -1757.168701\n",
      "Train Epoch: 753 [33792/54000 (63%)] Loss: -1742.132568\n",
      "Train Epoch: 753 [45056/54000 (83%)] Loss: -1757.282959\n",
      "    epoch          : 753\n",
      "    loss           : -1753.9576876658314\n",
      "    ess            : 27.13086874979847\n",
      "    log_marginal   : 1754.2558374944722\n",
      "    val_loss       : -1758.8265279134114\n",
      "    val_ess        : 27.186105569203693\n",
      "    val_log_marginal: 1759.1182250976562\n",
      "Train Epoch: 754 [0/54000 (0%)] Loss: -1764.023438\n",
      "Train Epoch: 754 [11264/54000 (21%)] Loss: -1763.066650\n",
      "Train Epoch: 754 [22528/54000 (42%)] Loss: -1765.293457\n",
      "Train Epoch: 754 [33792/54000 (63%)] Loss: -1766.574219\n",
      "Train Epoch: 754 [45056/54000 (83%)] Loss: -1768.097778\n",
      "    epoch          : 754\n",
      "    loss           : -1764.3667464346256\n",
      "    ess            : 27.40166817071303\n",
      "    log_marginal   : 1764.6549325619103\n",
      "    val_loss       : -1767.3802795410156\n",
      "    val_ess        : 27.23268922170003\n",
      "    val_log_marginal: 1767.6722005208333\n",
      "Train Epoch: 755 [0/54000 (0%)] Loss: -1766.546631\n",
      "Train Epoch: 755 [11264/54000 (21%)] Loss: -1774.994263\n",
      "Train Epoch: 755 [22528/54000 (42%)] Loss: -1776.285522\n",
      "Train Epoch: 755 [33792/54000 (63%)] Loss: -1769.873535\n",
      "Train Epoch: 755 [45056/54000 (83%)] Loss: -1766.451172\n",
      "    epoch          : 755\n",
      "    loss           : -1769.569104464549\n",
      "    ess            : 27.011792812707288\n",
      "    log_marginal   : 1769.879825232164\n",
      "    val_loss       : -1770.1293640136719\n",
      "    val_ess        : 26.896629810333252\n",
      "    val_log_marginal: 1770.460673014323\n",
      "Train Epoch: 756 [0/54000 (0%)] Loss: -1766.880615\n",
      "Train Epoch: 756 [11264/54000 (21%)] Loss: -1771.107056\n",
      "Train Epoch: 756 [22528/54000 (42%)] Loss: -1769.364990\n",
      "Train Epoch: 756 [33792/54000 (63%)] Loss: -1769.616211\n",
      "Train Epoch: 756 [45056/54000 (83%)] Loss: -1770.494873\n",
      "    epoch          : 756\n",
      "    loss           : -1771.7209656913326\n",
      "    ess            : 26.930073522171885\n",
      "    log_marginal   : 1772.0386663472877\n",
      "    val_loss       : -1771.78173828125\n",
      "    val_ess        : 26.828783988952637\n",
      "    val_log_marginal: 1772.1099243164062\n",
      "Train Epoch: 757 [0/54000 (0%)] Loss: -1773.467041\n",
      "Train Epoch: 757 [11264/54000 (21%)] Loss: -1772.352417\n",
      "Train Epoch: 757 [22528/54000 (42%)] Loss: -1776.773438\n",
      "Train Epoch: 757 [33792/54000 (63%)] Loss: -1771.850586\n",
      "Train Epoch: 757 [45056/54000 (83%)] Loss: -1773.138184\n",
      "    epoch          : 757\n",
      "    loss           : -1773.1256552642246\n",
      "    ess            : 26.935358461344016\n",
      "    log_marginal   : 1773.4450936947228\n",
      "    val_loss       : -1773.0031229654949\n",
      "    val_ess        : 26.846982796986897\n",
      "    val_log_marginal: 1773.325439453125\n",
      "Train Epoch: 758 [0/54000 (0%)] Loss: -1778.866577\n",
      "Train Epoch: 758 [11264/54000 (21%)] Loss: -1772.186646\n",
      "Train Epoch: 758 [22528/54000 (42%)] Loss: -1767.802246\n",
      "Train Epoch: 758 [33792/54000 (63%)] Loss: -1772.127075\n",
      "Train Epoch: 758 [45056/54000 (83%)] Loss: -1773.182495\n",
      "    epoch          : 758\n",
      "    loss           : -1774.3318965120136\n",
      "    ess            : 26.90136544209606\n",
      "    log_marginal   : 1774.654090737397\n",
      "    val_loss       : -1773.8794352213542\n",
      "    val_ess        : 26.857587814331055\n",
      "    val_log_marginal: 1774.207987467448\n",
      "Train Epoch: 759 [0/54000 (0%)] Loss: -1775.095337\n",
      "Train Epoch: 759 [11264/54000 (21%)] Loss: -1771.218018\n",
      "Train Epoch: 759 [22528/54000 (42%)] Loss: -1775.380371\n",
      "Train Epoch: 759 [33792/54000 (63%)] Loss: -1776.377319\n",
      "Train Epoch: 759 [45056/54000 (83%)] Loss: -1772.262329\n",
      "    epoch          : 759\n",
      "    loss           : -1775.2099344505455\n",
      "    ess            : 26.869491127302062\n",
      "    log_marginal   : 1775.5350503021816\n",
      "    val_loss       : -1774.1371968587239\n",
      "    val_ess        : 26.725433190663654\n",
      "    val_log_marginal: 1774.467997233073\n",
      "Train Epoch: 760 [0/54000 (0%)] Loss: -1774.422729\n",
      "Train Epoch: 760 [11264/54000 (21%)] Loss: -1771.229980\n",
      "Train Epoch: 760 [22528/54000 (42%)] Loss: -1775.508911\n",
      "Train Epoch: 760 [33792/54000 (63%)] Loss: -1779.351074\n",
      "Train Epoch: 760 [45056/54000 (83%)] Loss: -1746.973145\n",
      "    epoch          : 760\n",
      "    loss           : -1768.9470733066776\n",
      "    ess            : 26.89334086652072\n",
      "    log_marginal   : 1769.269208800118\n",
      "    val_loss       : -1740.141825358073\n",
      "    val_ess        : 26.699606736501057\n",
      "    val_log_marginal: 1740.4517313639324\n",
      "Train Epoch: 761 [0/54000 (0%)] Loss: -1747.772705\n",
      "Train Epoch: 761 [11264/54000 (21%)] Loss: -1747.586548\n",
      "Train Epoch: 761 [22528/54000 (42%)] Loss: -1747.754883\n",
      "Train Epoch: 761 [33792/54000 (63%)] Loss: -1739.598511\n",
      "Train Epoch: 761 [45056/54000 (83%)] Loss: -1738.220215\n",
      "    epoch          : 761\n",
      "    loss           : -1744.8040115068543\n",
      "    ess            : 26.739214987125038\n",
      "    log_marginal   : 1745.1165391454156\n",
      "    val_loss       : -1755.6743876139324\n",
      "    val_ess        : 27.59498182932536\n",
      "    val_log_marginal: 1755.9481099446614\n",
      "Train Epoch: 762 [0/54000 (0%)] Loss: -1754.328125\n",
      "Train Epoch: 762 [11264/54000 (21%)] Loss: -1762.915771\n",
      "Train Epoch: 762 [22528/54000 (42%)] Loss: -1762.025146\n",
      "Train Epoch: 762 [33792/54000 (63%)] Loss: -1755.424561\n",
      "Train Epoch: 762 [45056/54000 (83%)] Loss: -1759.593506\n",
      "    epoch          : 762\n",
      "    loss           : -1761.5486496259582\n",
      "    ess            : 27.545339674319862\n",
      "    log_marginal   : 1761.820915941922\n",
      "    val_loss       : -1764.0204162597656\n",
      "    val_ess        : 26.903263092041016\n",
      "    val_log_marginal: 1764.3314921061199\n",
      "Train Epoch: 763 [0/54000 (0%)] Loss: -1771.054443\n",
      "Train Epoch: 763 [11264/54000 (21%)] Loss: -1766.118408\n",
      "Train Epoch: 763 [22528/54000 (42%)] Loss: -1771.782471\n",
      "Train Epoch: 763 [33792/54000 (63%)] Loss: -1762.956421\n",
      "Train Epoch: 763 [45056/54000 (83%)] Loss: -1763.402344\n",
      "    epoch          : 763\n",
      "    loss           : -1766.2511228165536\n",
      "    ess            : 26.837673637102235\n",
      "    log_marginal   : 1766.5696353552476\n",
      "    val_loss       : -1766.92529296875\n",
      "    val_ess        : 27.154368718465168\n",
      "    val_log_marginal: 1767.2173767089844\n",
      "Train Epoch: 764 [0/54000 (0%)] Loss: -1768.715820\n",
      "Train Epoch: 764 [11264/54000 (21%)] Loss: -1769.144165\n",
      "Train Epoch: 764 [22528/54000 (42%)] Loss: -1763.406006\n",
      "Train Epoch: 764 [33792/54000 (63%)] Loss: -1763.741699\n",
      "Train Epoch: 764 [45056/54000 (83%)] Loss: -1766.743652\n",
      "    epoch          : 764\n",
      "    loss           : -1768.486307396079\n",
      "    ess            : 26.785436324353487\n",
      "    log_marginal   : 1768.8095115805572\n",
      "    val_loss       : -1768.2157185872395\n",
      "    val_ess        : 26.645118236541748\n",
      "    val_log_marginal: 1768.5560709635417\n",
      "Train Epoch: 765 [0/54000 (0%)] Loss: -1774.710938\n",
      "Train Epoch: 765 [11264/54000 (21%)] Loss: -1771.539062\n",
      "Train Epoch: 765 [22528/54000 (42%)] Loss: -1771.099854\n",
      "Train Epoch: 765 [33792/54000 (63%)] Loss: -1773.335938\n",
      "Train Epoch: 765 [45056/54000 (83%)] Loss: -1770.417969\n",
      "    epoch          : 765\n",
      "    loss           : -1770.1857184644016\n",
      "    ess            : 26.8176674033111\n",
      "    log_marginal   : 1770.5073587669517\n",
      "    val_loss       : -1769.7214253743489\n",
      "    val_ess        : 26.841670989990234\n",
      "    val_log_marginal: 1770.0530904134114\n",
      "Train Epoch: 766 [0/54000 (0%)] Loss: -1771.487183\n",
      "Train Epoch: 766 [11264/54000 (21%)] Loss: -1769.164185\n",
      "Train Epoch: 766 [22528/54000 (42%)] Loss: -1773.609009\n",
      "Train Epoch: 766 [33792/54000 (63%)] Loss: -1773.033813\n",
      "Train Epoch: 766 [45056/54000 (83%)] Loss: -1774.866577\n",
      "    epoch          : 766\n",
      "    loss           : -1771.4979950526974\n",
      "    ess            : 26.829805823991883\n",
      "    log_marginal   : 1771.8218982624558\n",
      "    val_loss       : -1771.1057230631511\n",
      "    val_ess        : 27.0765167872111\n",
      "    val_log_marginal: 1771.422831217448\n",
      "Train Epoch: 767 [0/54000 (0%)] Loss: -1769.555664\n",
      "Train Epoch: 767 [11264/54000 (21%)] Loss: -1769.185913\n",
      "Train Epoch: 767 [22528/54000 (42%)] Loss: -1773.303711\n",
      "Train Epoch: 767 [33792/54000 (63%)] Loss: -1775.680908\n",
      "Train Epoch: 767 [45056/54000 (83%)] Loss: -1775.401611\n",
      "    epoch          : 767\n",
      "    loss           : -1772.4732009599793\n",
      "    ess            : 26.881381358740466\n",
      "    log_marginal   : 1772.795749880233\n",
      "    val_loss       : -1771.7866109212239\n",
      "    val_ess        : 26.765286127726238\n",
      "    val_log_marginal: 1772.1132507324219\n",
      "Train Epoch: 768 [0/54000 (0%)] Loss: -1770.247437\n",
      "Train Epoch: 768 [11264/54000 (21%)] Loss: -1779.742432\n",
      "Train Epoch: 768 [22528/54000 (42%)] Loss: -1777.651367\n",
      "Train Epoch: 768 [33792/54000 (63%)] Loss: -1772.480225\n",
      "Train Epoch: 768 [45056/54000 (83%)] Loss: -1774.767578\n",
      "    epoch          : 768\n",
      "    loss           : -1773.2192221587559\n",
      "    ess            : 26.837459690165968\n",
      "    log_marginal   : 1773.5450784935142\n",
      "    val_loss       : -1771.172587076823\n",
      "    val_ess        : 27.088039716084797\n",
      "    val_log_marginal: 1771.4931640625\n",
      "Train Epoch: 769 [0/54000 (0%)] Loss: -1774.664307\n",
      "Train Epoch: 769 [11264/54000 (21%)] Loss: -1773.965332\n",
      "Train Epoch: 769 [22528/54000 (42%)] Loss: -1763.382935\n",
      "Train Epoch: 769 [33792/54000 (63%)] Loss: -1735.054443\n",
      "Train Epoch: 769 [45056/54000 (83%)] Loss: -1759.274414\n",
      "    epoch          : 769\n",
      "    loss           : -1757.9865077756485\n",
      "    ess            : 26.788889794979454\n",
      "    log_marginal   : 1758.3076528873084\n",
      "    val_loss       : -1754.2428588867188\n",
      "    val_ess        : 26.722932815551758\n",
      "    val_log_marginal: 1754.5707295735676\n",
      "Train Epoch: 770 [0/54000 (0%)] Loss: -1756.947998\n",
      "Train Epoch: 770 [11264/54000 (21%)] Loss: -1759.202148\n",
      "Train Epoch: 770 [22528/54000 (42%)] Loss: -1766.904175\n",
      "Train Epoch: 770 [33792/54000 (63%)] Loss: -1766.586670\n",
      "Train Epoch: 770 [45056/54000 (83%)] Loss: -1763.296387\n",
      "    epoch          : 770\n",
      "    loss           : -1763.9126172335643\n",
      "    ess            : 27.308488234034126\n",
      "    log_marginal   : 1764.1992648142689\n",
      "    val_loss       : -1762.4114990234375\n",
      "    val_ess        : 27.338866233825684\n",
      "    val_log_marginal: 1762.701639811198\n",
      "Train Epoch: 771 [0/54000 (0%)] Loss: -1769.149170\n",
      "Train Epoch: 771 [11264/54000 (21%)] Loss: -1769.892944\n",
      "Train Epoch: 771 [22528/54000 (42%)] Loss: -1772.916504\n",
      "Train Epoch: 771 [33792/54000 (63%)] Loss: -1775.519775\n",
      "Train Epoch: 771 [45056/54000 (83%)] Loss: -1765.152100\n",
      "    epoch          : 771\n",
      "    loss           : -1768.8838500976562\n",
      "    ess            : 27.087199948868662\n",
      "    log_marginal   : 1769.1886435454746\n",
      "    val_loss       : -1768.4622090657551\n",
      "    val_ess        : 27.084635098775227\n",
      "    val_log_marginal: 1768.7658589680989\n",
      "Train Epoch: 772 [0/54000 (0%)] Loss: -1768.352295\n",
      "Train Epoch: 772 [11264/54000 (21%)] Loss: -1775.316162\n",
      "Train Epoch: 772 [22528/54000 (42%)] Loss: -1768.903931\n",
      "Train Epoch: 772 [33792/54000 (63%)] Loss: -1769.054688\n",
      "Train Epoch: 772 [45056/54000 (83%)] Loss: -1774.919067\n",
      "    epoch          : 772\n",
      "    loss           : -1771.183598356427\n",
      "    ess            : 26.917503302952028\n",
      "    log_marginal   : 1771.503848669664\n",
      "    val_loss       : -1769.8917744954426\n",
      "    val_ess        : 26.773640314737957\n",
      "    val_log_marginal: 1770.2202860514324\n",
      "Train Epoch: 773 [0/54000 (0%)] Loss: -1771.713623\n",
      "Train Epoch: 773 [11264/54000 (21%)] Loss: -1770.543701\n",
      "Train Epoch: 773 [22528/54000 (42%)] Loss: -1771.189575\n",
      "Train Epoch: 773 [33792/54000 (63%)] Loss: -1772.276611\n",
      "Train Epoch: 773 [45056/54000 (83%)] Loss: -1772.662598\n",
      "    epoch          : 773\n",
      "    loss           : -1772.5473598264298\n",
      "    ess            : 26.833007830493855\n",
      "    log_marginal   : 1772.873990040905\n",
      "    val_loss       : -1771.1853434244792\n",
      "    val_ess        : 26.78538417816162\n",
      "    val_log_marginal: 1771.5068969726562\n",
      "Train Epoch: 774 [0/54000 (0%)] Loss: -1772.324829\n",
      "Train Epoch: 774 [11264/54000 (21%)] Loss: -1776.280518\n",
      "Train Epoch: 774 [22528/54000 (42%)] Loss: -1771.910645\n",
      "Train Epoch: 774 [33792/54000 (63%)] Loss: -1776.637695\n",
      "Train Epoch: 774 [45056/54000 (83%)] Loss: -1776.574829\n",
      "    epoch          : 774\n",
      "    loss           : -1773.6197026090802\n",
      "    ess            : 26.89310027068516\n",
      "    log_marginal   : 1773.941253086306\n",
      "    val_loss       : -1772.3157857259114\n",
      "    val_ess        : 26.72722339630127\n",
      "    val_log_marginal: 1772.6442362467449\n",
      "Train Epoch: 775 [0/54000 (0%)] Loss: -1775.097168\n",
      "Train Epoch: 775 [11264/54000 (21%)] Loss: -1775.983398\n",
      "Train Epoch: 775 [22528/54000 (42%)] Loss: -1772.760864\n",
      "Train Epoch: 775 [33792/54000 (63%)] Loss: -1771.260742\n",
      "Train Epoch: 775 [45056/54000 (83%)] Loss: -1772.892090\n",
      "    epoch          : 775\n",
      "    loss           : -1774.4952311965656\n",
      "    ess            : 26.902097738014078\n",
      "    log_marginal   : 1774.818826927329\n",
      "    val_loss       : -1773.3834533691406\n",
      "    val_ess        : 26.912782669067383\n",
      "    val_log_marginal: 1773.7082214355469\n",
      "Train Epoch: 776 [0/54000 (0%)] Loss: -1776.589844\n",
      "Train Epoch: 776 [11264/54000 (21%)] Loss: -1774.425659\n",
      "Train Epoch: 776 [22528/54000 (42%)] Loss: -1776.818481\n",
      "Train Epoch: 776 [33792/54000 (63%)] Loss: -1774.613892\n",
      "Train Epoch: 776 [45056/54000 (83%)] Loss: -1777.641113\n",
      "    epoch          : 776\n",
      "    loss           : -1775.3859748120578\n",
      "    ess            : 26.87074823199578\n",
      "    log_marginal   : 1775.713738207547\n",
      "    val_loss       : -1774.084248860677\n",
      "    val_ess        : 26.93683322270711\n",
      "    val_log_marginal: 1774.4079895019531\n",
      "Train Epoch: 777 [0/54000 (0%)] Loss: -1775.170898\n",
      "Train Epoch: 777 [11264/54000 (21%)] Loss: -1777.280518\n",
      "Train Epoch: 777 [22528/54000 (42%)] Loss: -1777.671265\n",
      "Train Epoch: 777 [33792/54000 (63%)] Loss: -1776.886230\n",
      "Train Epoch: 777 [45056/54000 (83%)] Loss: -1772.099365\n",
      "    epoch          : 777\n",
      "    loss           : -1776.0883535709022\n",
      "    ess            : 26.900541737394512\n",
      "    log_marginal   : 1776.411008438974\n",
      "    val_loss       : -1774.8532816569011\n",
      "    val_ess        : 26.98859977722168\n",
      "    val_log_marginal: 1775.17626953125\n",
      "Train Epoch: 778 [0/54000 (0%)] Loss: -1778.398193\n",
      "Train Epoch: 778 [11264/54000 (21%)] Loss: -1771.159058\n",
      "Train Epoch: 778 [22528/54000 (42%)] Loss: -1765.095947\n",
      "Train Epoch: 778 [33792/54000 (63%)] Loss: -1771.575195\n",
      "Train Epoch: 778 [45056/54000 (83%)] Loss: -1772.152100\n",
      "    epoch          : 778\n",
      "    loss           : -1771.9293063181751\n",
      "    ess            : 26.91128556233532\n",
      "    log_marginal   : 1772.2507427863354\n",
      "    val_loss       : -1769.5477396647136\n",
      "    val_ess        : 26.837690989176433\n",
      "    val_log_marginal: 1769.8784281412761\n",
      "Train Epoch: 779 [0/54000 (0%)] Loss: -1777.371338\n",
      "Train Epoch: 779 [11264/54000 (21%)] Loss: -1772.696045\n",
      "Train Epoch: 779 [22528/54000 (42%)] Loss: -1778.833252\n",
      "Train Epoch: 779 [33792/54000 (63%)] Loss: -1771.055176\n",
      "Train Epoch: 779 [45056/54000 (83%)] Loss: -1776.893311\n",
      "    epoch          : 779\n",
      "    loss           : -1775.0320757020195\n",
      "    ess            : 27.11900412361577\n",
      "    log_marginal   : 1775.3470792950325\n",
      "    val_loss       : -1773.4298299153645\n",
      "    val_ess        : 27.155157407124836\n",
      "    val_log_marginal: 1773.7427673339844\n",
      "Train Epoch: 780 [0/54000 (0%)] Loss: -1775.705322\n",
      "Train Epoch: 780 [11264/54000 (21%)] Loss: -1772.110107\n",
      "Train Epoch: 780 [22528/54000 (42%)] Loss: -1760.568848\n",
      "Train Epoch: 780 [33792/54000 (63%)] Loss: -1755.742065\n",
      "Train Epoch: 780 [45056/54000 (83%)] Loss: -1755.386719\n",
      "    epoch          : 780\n",
      "    loss           : -1761.5855344376473\n",
      "    ess            : 26.87591685888902\n",
      "    log_marginal   : 1761.9060991395195\n",
      "    val_loss       : -1756.2468668619792\n",
      "    val_ess        : 26.751191298166912\n",
      "    val_log_marginal: 1756.5675455729167\n",
      "Train Epoch: 781 [0/54000 (0%)] Loss: -1764.401855\n",
      "Train Epoch: 781 [11264/54000 (21%)] Loss: -1766.232666\n",
      "Train Epoch: 781 [22528/54000 (42%)] Loss: -1769.723999\n",
      "Train Epoch: 781 [33792/54000 (63%)] Loss: -1774.250732\n",
      "Train Epoch: 781 [45056/54000 (83%)] Loss: -1767.932861\n",
      "    epoch          : 781\n",
      "    loss           : -1768.6791669737618\n",
      "    ess            : 27.398857314631623\n",
      "    log_marginal   : 1768.9685288915093\n",
      "    val_loss       : -1767.5114237467449\n",
      "    val_ess        : 27.778603076934814\n",
      "    val_log_marginal: 1767.7708129882812\n",
      "Train Epoch: 782 [0/54000 (0%)] Loss: -1774.742188\n",
      "Train Epoch: 782 [11264/54000 (21%)] Loss: -1776.700195\n",
      "Train Epoch: 782 [22528/54000 (42%)] Loss: -1767.411621\n",
      "Train Epoch: 782 [33792/54000 (63%)] Loss: -1773.955200\n",
      "Train Epoch: 782 [45056/54000 (83%)] Loss: -1771.837402\n",
      "    epoch          : 782\n",
      "    loss           : -1773.1220587964328\n",
      "    ess            : 27.126125173748665\n",
      "    log_marginal   : 1773.4293040149616\n",
      "    val_loss       : -1771.8300882975261\n",
      "    val_ess        : 27.128395716349285\n",
      "    val_log_marginal: 1772.1387736002605\n",
      "Train Epoch: 783 [0/54000 (0%)] Loss: -1775.487915\n",
      "Train Epoch: 783 [11264/54000 (21%)] Loss: -1771.644043\n",
      "Train Epoch: 783 [22528/54000 (42%)] Loss: -1774.043213\n",
      "Train Epoch: 783 [33792/54000 (63%)] Loss: -1774.773560\n",
      "Train Epoch: 783 [45056/54000 (83%)] Loss: -1771.236328\n",
      "    epoch          : 783\n",
      "    loss           : -1775.0328023658608\n",
      "    ess            : 26.86431663441208\n",
      "    log_marginal   : 1775.3564268867924\n",
      "    val_loss       : -1773.9141845703125\n",
      "    val_ess        : 26.840776920318604\n",
      "    val_log_marginal: 1774.2379048665364\n",
      "Train Epoch: 784 [0/54000 (0%)] Loss: -1779.162354\n",
      "Train Epoch: 784 [11264/54000 (21%)] Loss: -1781.611328\n",
      "Train Epoch: 784 [22528/54000 (42%)] Loss: -1775.386353\n",
      "Train Epoch: 784 [33792/54000 (63%)] Loss: -1774.716919\n",
      "Train Epoch: 784 [45056/54000 (83%)] Loss: -1773.467773\n",
      "    epoch          : 784\n",
      "    loss           : -1776.2949771521226\n",
      "    ess            : 26.94123185355708\n",
      "    log_marginal   : 1776.615888487618\n",
      "    val_loss       : -1774.8831583658855\n",
      "    val_ess        : 26.85001548131307\n",
      "    val_log_marginal: 1775.2024841308594\n",
      "Train Epoch: 785 [0/54000 (0%)] Loss: -1774.751343\n",
      "Train Epoch: 785 [11264/54000 (21%)] Loss: -1779.939453\n",
      "Train Epoch: 785 [22528/54000 (42%)] Loss: -1773.326416\n",
      "Train Epoch: 785 [33792/54000 (63%)] Loss: -1775.371338\n",
      "Train Epoch: 785 [45056/54000 (83%)] Loss: -1783.740479\n",
      "    epoch          : 785\n",
      "    loss           : -1777.1742565227005\n",
      "    ess            : 26.957473718895102\n",
      "    log_marginal   : 1777.4961950913914\n",
      "    val_loss       : -1776.1768290201824\n",
      "    val_ess        : 27.131407101949055\n",
      "    val_log_marginal: 1776.500508626302\n",
      "Train Epoch: 786 [0/54000 (0%)] Loss: -1779.789062\n",
      "Train Epoch: 786 [11264/54000 (21%)] Loss: -1777.102295\n",
      "Train Epoch: 786 [22528/54000 (42%)] Loss: -1783.157715\n",
      "Train Epoch: 786 [33792/54000 (63%)] Loss: -1780.651123\n",
      "Train Epoch: 786 [45056/54000 (83%)] Loss: -1776.735474\n",
      "    epoch          : 786\n",
      "    loss           : -1777.890223089254\n",
      "    ess            : 26.942442192221588\n",
      "    log_marginal   : 1778.2122629993366\n",
      "    val_loss       : -1776.0343729654949\n",
      "    val_ess        : 26.998911062876385\n",
      "    val_log_marginal: 1776.3596801757812\n",
      "Train Epoch: 787 [0/54000 (0%)] Loss: -1774.766357\n",
      "Train Epoch: 787 [11264/54000 (21%)] Loss: -1782.825684\n",
      "Train Epoch: 787 [22528/54000 (42%)] Loss: -1778.878052\n",
      "Train Epoch: 787 [33792/54000 (63%)] Loss: -1770.467041\n",
      "Train Epoch: 787 [45056/54000 (83%)] Loss: -1732.285156\n",
      "    epoch          : 787\n",
      "    loss           : -1762.3472359135467\n",
      "    ess            : 26.780863509987885\n",
      "    log_marginal   : 1762.6716297077683\n",
      "    val_loss       : -1753.3750813802083\n",
      "    val_ess        : 26.450222969055176\n",
      "    val_log_marginal: 1753.7220357259114\n",
      "Train Epoch: 788 [0/54000 (0%)] Loss: -1753.425903\n",
      "Train Epoch: 788 [11264/54000 (21%)] Loss: -1768.439697\n",
      "Train Epoch: 788 [22528/54000 (42%)] Loss: -1767.752197\n",
      "Train Epoch: 788 [33792/54000 (63%)] Loss: -1764.735107\n",
      "Train Epoch: 788 [45056/54000 (83%)] Loss: -1767.257080\n",
      "    epoch          : 788\n",
      "    loss           : -1764.667939959832\n",
      "    ess            : 27.255252334306824\n",
      "    log_marginal   : 1764.9621812352593\n",
      "    val_loss       : -1765.4883321126301\n",
      "    val_ess        : 27.725128650665283\n",
      "    val_log_marginal: 1765.7625732421875\n",
      "Train Epoch: 789 [0/54000 (0%)] Loss: -1770.330078\n",
      "Train Epoch: 789 [11264/54000 (21%)] Loss: -1771.685303\n",
      "Train Epoch: 789 [22528/54000 (42%)] Loss: -1769.851318\n",
      "Train Epoch: 789 [33792/54000 (63%)] Loss: -1768.177246\n",
      "Train Epoch: 789 [45056/54000 (83%)] Loss: -1771.764893\n",
      "    epoch          : 789\n",
      "    loss           : -1771.0705750663326\n",
      "    ess            : 27.207400267978883\n",
      "    log_marginal   : 1771.366814379422\n",
      "    val_loss       : -1771.5189819335938\n",
      "    val_ess        : 27.12871567408244\n",
      "    val_log_marginal: 1771.8203430175781\n",
      "Train Epoch: 790 [0/54000 (0%)] Loss: -1778.713501\n",
      "Train Epoch: 790 [11264/54000 (21%)] Loss: -1771.847900\n",
      "Train Epoch: 790 [22528/54000 (42%)] Loss: -1779.726440\n",
      "Train Epoch: 790 [33792/54000 (63%)] Loss: -1772.117676\n",
      "Train Epoch: 790 [45056/54000 (83%)] Loss: -1778.133179\n",
      "    epoch          : 790\n",
      "    loss           : -1773.6566496075325\n",
      "    ess            : 26.915648640326733\n",
      "    log_marginal   : 1773.9805320883697\n",
      "    val_loss       : -1773.5087280273438\n",
      "    val_ess        : 26.803648471832275\n",
      "    val_log_marginal: 1773.8428955078125\n",
      "Train Epoch: 791 [0/54000 (0%)] Loss: -1773.161621\n",
      "Train Epoch: 791 [11264/54000 (21%)] Loss: -1773.594116\n",
      "Train Epoch: 791 [22528/54000 (42%)] Loss: -1775.004395\n",
      "Train Epoch: 791 [33792/54000 (63%)] Loss: -1771.542236\n",
      "Train Epoch: 791 [45056/54000 (83%)] Loss: -1774.392822\n",
      "    epoch          : 791\n",
      "    loss           : -1775.1680171174823\n",
      "    ess            : 26.966772043480063\n",
      "    log_marginal   : 1775.490684653228\n",
      "    val_loss       : -1774.8145548502605\n",
      "    val_ess        : 26.771832307179768\n",
      "    val_log_marginal: 1775.155517578125\n",
      "Train Epoch: 792 [0/54000 (0%)] Loss: -1779.263428\n",
      "Train Epoch: 792 [11264/54000 (21%)] Loss: -1779.358887\n",
      "Train Epoch: 792 [22528/54000 (42%)] Loss: -1771.003906\n",
      "Train Epoch: 792 [33792/54000 (63%)] Loss: -1775.823975\n",
      "Train Epoch: 792 [45056/54000 (83%)] Loss: -1777.433594\n",
      "    epoch          : 792\n",
      "    loss           : -1776.2692157097583\n",
      "    ess            : 26.957606711477602\n",
      "    log_marginal   : 1776.5844001050266\n",
      "    val_loss       : -1775.387186686198\n",
      "    val_ess        : 27.016918818155926\n",
      "    val_log_marginal: 1775.7139994303386\n",
      "Train Epoch: 793 [0/54000 (0%)] Loss: -1782.354126\n",
      "Train Epoch: 793 [11264/54000 (21%)] Loss: -1780.339355\n",
      "Train Epoch: 793 [22528/54000 (42%)] Loss: -1773.855469\n",
      "Train Epoch: 793 [33792/54000 (63%)] Loss: -1779.184692\n",
      "Train Epoch: 793 [45056/54000 (83%)] Loss: -1778.656250\n",
      "    epoch          : 793\n",
      "    loss           : -1777.0527159492924\n",
      "    ess            : 26.8879390932479\n",
      "    log_marginal   : 1777.3775358380012\n",
      "    val_loss       : -1776.4113057454426\n",
      "    val_ess        : 26.935776710510254\n",
      "    val_log_marginal: 1776.732930501302\n",
      "Train Epoch: 794 [0/54000 (0%)] Loss: -1776.931885\n",
      "Train Epoch: 794 [11264/54000 (21%)] Loss: -1781.678711\n",
      "Train Epoch: 794 [22528/54000 (42%)] Loss: -1779.960693\n",
      "Train Epoch: 794 [33792/54000 (63%)] Loss: -1777.705566\n",
      "Train Epoch: 794 [45056/54000 (83%)] Loss: -1779.321777\n",
      "    epoch          : 794\n",
      "    loss           : -1777.829982541642\n",
      "    ess            : 26.927959136243135\n",
      "    log_marginal   : 1778.1525406747494\n",
      "    val_loss       : -1776.902364095052\n",
      "    val_ess        : 26.885230382283527\n",
      "    val_log_marginal: 1777.2174173990886\n",
      "Train Epoch: 795 [0/54000 (0%)] Loss: -1781.952515\n",
      "Train Epoch: 795 [11264/54000 (21%)] Loss: -1784.650513\n",
      "Train Epoch: 795 [22528/54000 (42%)] Loss: -1780.700195\n",
      "Train Epoch: 795 [33792/54000 (63%)] Loss: -1775.124268\n",
      "Train Epoch: 795 [45056/54000 (83%)] Loss: -1778.600586\n",
      "    epoch          : 795\n",
      "    loss           : -1778.530112212559\n",
      "    ess            : 27.016051472357983\n",
      "    log_marginal   : 1778.8470516564712\n",
      "    val_loss       : -1776.9640604654949\n",
      "    val_ess        : 26.92726723353068\n",
      "    val_log_marginal: 1777.2831522623699\n",
      "Train Epoch: 796 [0/54000 (0%)] Loss: -1777.295410\n",
      "Train Epoch: 796 [11264/54000 (21%)] Loss: -1776.726685\n",
      "Train Epoch: 796 [22528/54000 (42%)] Loss: -1775.753418\n",
      "Train Epoch: 796 [33792/54000 (63%)] Loss: -1766.685669\n",
      "Train Epoch: 796 [45056/54000 (83%)] Loss: -1746.254883\n",
      "    epoch          : 796\n",
      "    loss           : -1769.0839751621463\n",
      "    ess            : 26.92792572165435\n",
      "    log_marginal   : 1769.4021940411262\n",
      "    val_loss       : -1759.9491170247395\n",
      "    val_ess        : 26.605351607004803\n",
      "    val_log_marginal: 1760.2735799153645\n",
      "Train Epoch: 797 [0/54000 (0%)] Loss: -1762.449219\n",
      "Train Epoch: 797 [11264/54000 (21%)] Loss: -1768.336914\n",
      "Train Epoch: 797 [22528/54000 (42%)] Loss: -1770.175781\n",
      "Train Epoch: 797 [33792/54000 (63%)] Loss: -1767.931885\n",
      "Train Epoch: 797 [45056/54000 (83%)] Loss: -1762.731445\n",
      "    epoch          : 797\n",
      "    loss           : -1765.6243527970223\n",
      "    ess            : 27.151591516890615\n",
      "    log_marginal   : 1765.9201072836822\n",
      "    val_loss       : -1762.5926920572917\n",
      "    val_ess        : 27.185684363047283\n",
      "    val_log_marginal: 1762.9011128743489\n",
      "Train Epoch: 798 [0/54000 (0%)] Loss: -1768.525146\n",
      "Train Epoch: 798 [11264/54000 (21%)] Loss: -1771.987915\n",
      "Train Epoch: 798 [22528/54000 (42%)] Loss: -1774.173584\n",
      "Train Epoch: 798 [33792/54000 (63%)] Loss: -1773.540039\n",
      "Train Epoch: 798 [45056/54000 (83%)] Loss: -1771.847412\n",
      "    epoch          : 798\n",
      "    loss           : -1772.4831646613354\n",
      "    ess            : 27.262612360828328\n",
      "    log_marginal   : 1772.781444621536\n",
      "    val_loss       : -1769.6359354654949\n",
      "    val_ess        : 27.313662846883137\n",
      "    val_log_marginal: 1769.9266357421875\n",
      "Train Epoch: 799 [0/54000 (0%)] Loss: -1774.241699\n",
      "Train Epoch: 799 [11264/54000 (21%)] Loss: -1778.227539\n",
      "Train Epoch: 799 [22528/54000 (42%)] Loss: -1775.083496\n",
      "Train Epoch: 799 [33792/54000 (63%)] Loss: -1775.325073\n",
      "Train Epoch: 799 [45056/54000 (83%)] Loss: -1774.729614\n",
      "    epoch          : 799\n",
      "    loss           : -1775.4700317382812\n",
      "    ess            : 26.993026103613513\n",
      "    log_marginal   : 1775.7871807746167\n",
      "    val_loss       : -1774.2843119303386\n",
      "    val_ess        : 27.155147870381672\n",
      "    val_log_marginal: 1774.5977274576824\n",
      "Train Epoch: 800 [0/54000 (0%)] Loss: -1777.969971\n",
      "Train Epoch: 800 [11264/54000 (21%)] Loss: -1775.844727\n",
      "Train Epoch: 800 [22528/54000 (42%)] Loss: -1778.603271\n",
      "Train Epoch: 800 [33792/54000 (63%)] Loss: -1778.604004\n",
      "Train Epoch: 800 [45056/54000 (83%)] Loss: -1779.505737\n",
      "    epoch          : 800\n",
      "    loss           : -1777.0932179576946\n",
      "    ess            : 26.98403864086799\n",
      "    log_marginal   : 1777.4139369748673\n",
      "    val_loss       : -1775.838602701823\n",
      "    val_ess        : 26.72735834121704\n",
      "    val_log_marginal: 1776.1682535807292\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [0/54000 (0%)] Loss: -1778.953247\n",
      "Train Epoch: 801 [11264/54000 (21%)] Loss: -1778.260742\n",
      "Train Epoch: 801 [22528/54000 (42%)] Loss: -1777.520142\n",
      "Train Epoch: 801 [33792/54000 (63%)] Loss: -1774.273193\n",
      "Train Epoch: 801 [45056/54000 (83%)] Loss: -1774.937134\n",
      "    epoch          : 801\n",
      "    loss           : -1778.082035856427\n",
      "    ess            : 26.89594779824311\n",
      "    log_marginal   : 1778.4054323592277\n",
      "    val_loss       : -1776.6533711751301\n",
      "    val_ess        : 26.86104663213094\n",
      "    val_log_marginal: 1776.9868774414062\n",
      "Train Epoch: 802 [0/54000 (0%)] Loss: -1781.669922\n",
      "Train Epoch: 802 [11264/54000 (21%)] Loss: -1782.925903\n",
      "Train Epoch: 802 [22528/54000 (42%)] Loss: -1777.820557\n",
      "Train Epoch: 802 [33792/54000 (63%)] Loss: -1777.114014\n",
      "Train Epoch: 802 [45056/54000 (83%)] Loss: -1782.462036\n",
      "    epoch          : 802\n",
      "    loss           : -1779.0927008862766\n",
      "    ess            : 27.032818488354952\n",
      "    log_marginal   : 1779.4087063771374\n",
      "    val_loss       : -1777.7143249511719\n",
      "    val_ess        : 26.95180320739746\n",
      "    val_log_marginal: 1778.0390930175781\n",
      "Train Epoch: 803 [0/54000 (0%)] Loss: -1778.274292\n",
      "Train Epoch: 803 [11264/54000 (21%)] Loss: -1782.103394\n",
      "Train Epoch: 803 [22528/54000 (42%)] Loss: -1777.752808\n",
      "Train Epoch: 803 [33792/54000 (63%)] Loss: -1784.948486\n",
      "Train Epoch: 803 [45056/54000 (83%)] Loss: -1780.128174\n",
      "    epoch          : 803\n",
      "    loss           : -1779.6375029941776\n",
      "    ess            : 26.99753250266021\n",
      "    log_marginal   : 1779.9590235296284\n",
      "    val_loss       : -1778.2266031901042\n",
      "    val_ess        : 26.860132694244385\n",
      "    val_log_marginal: 1778.5599670410156\n",
      "Train Epoch: 804 [0/54000 (0%)] Loss: -1777.909180\n",
      "Train Epoch: 804 [11264/54000 (21%)] Loss: -1777.895142\n",
      "Train Epoch: 804 [22528/54000 (42%)] Loss: -1778.834229\n",
      "Train Epoch: 804 [33792/54000 (63%)] Loss: -1782.548340\n",
      "Train Epoch: 804 [45056/54000 (83%)] Loss: -1777.826660\n",
      "    epoch          : 804\n",
      "    loss           : -1779.9471654352153\n",
      "    ess            : 27.03146475665974\n",
      "    log_marginal   : 1780.2668929190006\n",
      "    val_loss       : -1777.4067077636719\n",
      "    val_ess        : 27.144887924194336\n",
      "    val_log_marginal: 1777.728271484375\n",
      "Train Epoch: 805 [0/54000 (0%)] Loss: -1779.239014\n",
      "Train Epoch: 805 [11264/54000 (21%)] Loss: -1760.977417\n",
      "Train Epoch: 805 [22528/54000 (42%)] Loss: -1762.750000\n",
      "Train Epoch: 805 [33792/54000 (63%)] Loss: -1766.597656\n",
      "Train Epoch: 805 [45056/54000 (83%)] Loss: -1769.192139\n",
      "    epoch          : 805\n",
      "    loss           : -1768.3977315650795\n",
      "    ess            : 26.783948484456765\n",
      "    log_marginal   : 1768.7271348485406\n",
      "    val_loss       : -1768.5971781412761\n",
      "    val_ess        : 26.908040205637615\n",
      "    val_log_marginal: 1768.925557454427\n",
      "Train Epoch: 806 [0/54000 (0%)] Loss: -1770.062988\n",
      "Train Epoch: 806 [11264/54000 (21%)] Loss: -1778.133545\n",
      "Train Epoch: 806 [22528/54000 (42%)] Loss: -1774.136719\n",
      "Train Epoch: 806 [33792/54000 (63%)] Loss: -1772.727905\n",
      "Train Epoch: 806 [45056/54000 (83%)] Loss: -1775.068848\n",
      "    epoch          : 806\n",
      "    loss           : -1775.5056543890034\n",
      "    ess            : 27.386475347123056\n",
      "    log_marginal   : 1775.7983571178509\n",
      "    val_loss       : -1775.4070943196614\n",
      "    val_ess        : 27.348360379536945\n",
      "    val_log_marginal: 1775.7187805175781\n",
      "Train Epoch: 807 [0/54000 (0%)] Loss: -1779.788452\n",
      "Train Epoch: 807 [11264/54000 (21%)] Loss: -1780.635986\n",
      "Train Epoch: 807 [22528/54000 (42%)] Loss: -1775.036133\n",
      "Train Epoch: 807 [33792/54000 (63%)] Loss: -1782.621094\n",
      "Train Epoch: 807 [45056/54000 (83%)] Loss: -1778.811523\n",
      "    epoch          : 807\n",
      "    loss           : -1778.6898043650501\n",
      "    ess            : 27.047408229899855\n",
      "    log_marginal   : 1779.0057119693397\n",
      "    val_loss       : -1778.388448079427\n",
      "    val_ess        : 26.87961991628011\n",
      "    val_log_marginal: 1778.7268473307292\n",
      "Train Epoch: 808 [0/54000 (0%)] Loss: -1783.578979\n",
      "Train Epoch: 808 [11264/54000 (21%)] Loss: -1786.081665\n",
      "Train Epoch: 808 [22528/54000 (42%)] Loss: -1780.509521\n",
      "Train Epoch: 808 [33792/54000 (63%)] Loss: -1782.079834\n",
      "Train Epoch: 808 [45056/54000 (83%)] Loss: -1776.082275\n",
      "    epoch          : 808\n",
      "    loss           : -1780.0489628629864\n",
      "    ess            : 26.99678564971348\n",
      "    log_marginal   : 1780.3684646318543\n",
      "    val_loss       : -1779.118631998698\n",
      "    val_ess        : 26.638585408528645\n",
      "    val_log_marginal: 1779.4649454752605\n",
      "Train Epoch: 809 [0/54000 (0%)] Loss: -1787.063721\n",
      "Train Epoch: 809 [11264/54000 (21%)] Loss: -1779.103027\n",
      "Train Epoch: 809 [22528/54000 (42%)] Loss: -1780.816040\n",
      "Train Epoch: 809 [33792/54000 (63%)] Loss: -1779.049805\n",
      "Train Epoch: 809 [45056/54000 (83%)] Loss: -1785.191528\n",
      "    epoch          : 809\n",
      "    loss           : -1780.9530282650353\n",
      "    ess            : 27.003532607600373\n",
      "    log_marginal   : 1781.2777111125442\n",
      "    val_loss       : -1780.4461975097656\n",
      "    val_ess        : 27.08046754201253\n",
      "    val_log_marginal: 1780.7703348795574\n",
      "Train Epoch: 810 [0/54000 (0%)] Loss: -1780.028564\n",
      "Train Epoch: 810 [11264/54000 (21%)] Loss: -1780.630249\n",
      "Train Epoch: 810 [22528/54000 (42%)] Loss: -1782.577881\n",
      "Train Epoch: 810 [33792/54000 (63%)] Loss: -1781.610596\n",
      "Train Epoch: 810 [45056/54000 (83%)] Loss: -1779.894531\n",
      "    epoch          : 810\n",
      "    loss           : -1781.6209682248673\n",
      "    ess            : 27.045270272021025\n",
      "    log_marginal   : 1781.9368124907871\n",
      "    val_loss       : -1780.7663269042969\n",
      "    val_ess        : 26.7930170694987\n",
      "    val_log_marginal: 1781.1094462076824\n",
      "Train Epoch: 811 [0/54000 (0%)] Loss: -1788.985718\n",
      "Train Epoch: 811 [11264/54000 (21%)] Loss: -1782.487427\n",
      "Train Epoch: 811 [22528/54000 (42%)] Loss: -1781.437134\n",
      "Train Epoch: 811 [33792/54000 (63%)] Loss: -1786.844482\n",
      "Train Epoch: 811 [45056/54000 (83%)] Loss: -1756.258545\n",
      "    epoch          : 811\n",
      "    loss           : -1776.3265219634434\n",
      "    ess            : 26.93070085993353\n",
      "    log_marginal   : 1776.6546757536114\n",
      "    val_loss       : -1765.5339864095051\n",
      "    val_ess        : 26.811674276987713\n",
      "    val_log_marginal: 1765.8602396647136\n",
      "Train Epoch: 812 [0/54000 (0%)] Loss: -1764.326538\n",
      "Train Epoch: 812 [11264/54000 (21%)] Loss: -1771.706787\n",
      "Train Epoch: 812 [22528/54000 (42%)] Loss: -1763.750732\n",
      "Train Epoch: 812 [33792/54000 (63%)] Loss: -1761.573975\n",
      "Train Epoch: 812 [45056/54000 (83%)] Loss: -1747.378906\n",
      "    epoch          : 812\n",
      "    loss           : -1760.0883812094635\n",
      "    ess            : 26.97706091179038\n",
      "    log_marginal   : 1760.4040630988354\n",
      "    val_loss       : -1726.6670633951824\n",
      "    val_ess        : 26.91752815246582\n",
      "    val_log_marginal: 1726.9789530436199\n",
      "Train Epoch: 813 [0/54000 (0%)] Loss: -1751.808105\n",
      "Train Epoch: 813 [11264/54000 (21%)] Loss: -1748.723755\n",
      "Train Epoch: 813 [22528/54000 (42%)] Loss: -1705.453125\n",
      "Train Epoch: 813 [33792/54000 (63%)] Loss: -1712.056519\n",
      "Train Epoch: 813 [45056/54000 (83%)] Loss: -1724.907471\n",
      "    epoch          : 813\n",
      "    loss           : -1726.9225279610112\n",
      "    ess            : 27.13503367945833\n",
      "    log_marginal   : 1727.2040036759286\n",
      "    val_loss       : -1749.242411295573\n",
      "    val_ess        : 27.763068517049152\n",
      "    val_log_marginal: 1749.5083719889324\n",
      "Train Epoch: 814 [0/54000 (0%)] Loss: -1749.286133\n",
      "Train Epoch: 814 [11264/54000 (21%)] Loss: -1751.857300\n",
      "Train Epoch: 814 [22528/54000 (42%)] Loss: -1750.572998\n",
      "Train Epoch: 814 [33792/54000 (63%)] Loss: -1751.109253\n",
      "Train Epoch: 814 [45056/54000 (83%)] Loss: -1749.897217\n",
      "    epoch          : 814\n",
      "    loss           : -1749.4917429798054\n",
      "    ess            : 27.757355923922557\n",
      "    log_marginal   : 1749.7449214143573\n",
      "    val_loss       : -1758.8568725585938\n",
      "    val_ess        : 27.037062009175617\n",
      "    val_log_marginal: 1759.1542663574219\n",
      "Train Epoch: 815 [0/54000 (0%)] Loss: -1758.467896\n",
      "Train Epoch: 815 [11264/54000 (21%)] Loss: -1760.866211\n",
      "Train Epoch: 815 [22528/54000 (42%)] Loss: -1756.617065\n",
      "Train Epoch: 815 [33792/54000 (63%)] Loss: -1756.987305\n",
      "Train Epoch: 815 [45056/54000 (83%)] Loss: -1759.955078\n",
      "    epoch          : 815\n",
      "    loss           : -1758.021993385171\n",
      "    ess            : 27.010766515191996\n",
      "    log_marginal   : 1758.3284704820164\n",
      "    val_loss       : -1763.3548889160156\n",
      "    val_ess        : 26.736007531483967\n",
      "    val_log_marginal: 1763.6830444335938\n",
      "Train Epoch: 816 [0/54000 (0%)] Loss: -1761.135254\n",
      "Train Epoch: 816 [11264/54000 (21%)] Loss: -1765.407959\n",
      "Train Epoch: 816 [22528/54000 (42%)] Loss: -1757.922363\n",
      "Train Epoch: 816 [33792/54000 (63%)] Loss: -1758.909668\n",
      "Train Epoch: 816 [45056/54000 (83%)] Loss: -1764.242432\n",
      "    epoch          : 816\n",
      "    loss           : -1761.97509765625\n",
      "    ess            : 26.89716697189043\n",
      "    log_marginal   : 1762.291822901312\n",
      "    val_loss       : -1765.5641988118489\n",
      "    val_ess        : 26.507705847422283\n",
      "    val_log_marginal: 1765.8985493977864\n",
      "Train Epoch: 817 [0/54000 (0%)] Loss: -1764.239014\n",
      "Train Epoch: 817 [11264/54000 (21%)] Loss: -1761.956543\n",
      "Train Epoch: 817 [22528/54000 (42%)] Loss: -1765.658081\n",
      "Train Epoch: 817 [33792/54000 (63%)] Loss: -1766.460815\n",
      "Train Epoch: 817 [45056/54000 (83%)] Loss: -1764.525879\n",
      "    epoch          : 817\n",
      "    loss           : -1764.4745368237766\n",
      "    ess            : 26.846585021828705\n",
      "    log_marginal   : 1764.7948792655513\n",
      "    val_loss       : -1766.9539082845051\n",
      "    val_ess        : 26.64111614227295\n",
      "    val_log_marginal: 1767.2921956380208\n",
      "Train Epoch: 818 [0/54000 (0%)] Loss: -1765.979980\n",
      "Train Epoch: 818 [11264/54000 (21%)] Loss: -1768.531860\n",
      "Train Epoch: 818 [22528/54000 (42%)] Loss: -1762.347290\n",
      "Train Epoch: 818 [33792/54000 (63%)] Loss: -1764.583740\n",
      "Train Epoch: 818 [45056/54000 (83%)] Loss: -1768.555664\n",
      "    epoch          : 818\n",
      "    loss           : -1766.3403907631928\n",
      "    ess            : 26.780186275266253\n",
      "    log_marginal   : 1766.6641338996167\n",
      "    val_loss       : -1768.5091654459636\n",
      "    val_ess        : 26.90666961669922\n",
      "    val_log_marginal: 1768.8261820475261\n",
      "Train Epoch: 819 [0/54000 (0%)] Loss: -1773.476562\n",
      "Train Epoch: 819 [11264/54000 (21%)] Loss: -1770.556885\n",
      "Train Epoch: 819 [22528/54000 (42%)] Loss: -1767.216064\n",
      "Train Epoch: 819 [33792/54000 (63%)] Loss: -1766.635986\n",
      "Train Epoch: 819 [45056/54000 (83%)] Loss: -1763.684814\n",
      "    epoch          : 819\n",
      "    loss           : -1767.9208707989387\n",
      "    ess            : 26.84204259908424\n",
      "    log_marginal   : 1768.2397103939416\n",
      "    val_loss       : -1769.6860860188801\n",
      "    val_ess        : 26.96441189448039\n",
      "    val_log_marginal: 1770.0071919759114\n",
      "Train Epoch: 820 [0/54000 (0%)] Loss: -1773.950928\n",
      "Train Epoch: 820 [11264/54000 (21%)] Loss: -1770.372437\n",
      "Train Epoch: 820 [22528/54000 (42%)] Loss: -1766.998169\n",
      "Train Epoch: 820 [33792/54000 (63%)] Loss: -1772.088379\n",
      "Train Epoch: 820 [45056/54000 (83%)] Loss: -1766.010132\n",
      "    epoch          : 820\n",
      "    loss           : -1769.3394349296138\n",
      "    ess            : 26.847982892450297\n",
      "    log_marginal   : 1769.6627980358196\n",
      "    val_loss       : -1770.9016215006511\n",
      "    val_ess        : 26.852766354878742\n",
      "    val_log_marginal: 1771.2180989583333\n",
      "Train Epoch: 821 [0/54000 (0%)] Loss: -1772.531006\n",
      "Train Epoch: 821 [11264/54000 (21%)] Loss: -1772.907349\n",
      "Train Epoch: 821 [22528/54000 (42%)] Loss: -1769.033691\n",
      "Train Epoch: 821 [33792/54000 (63%)] Loss: -1768.049561\n",
      "Train Epoch: 821 [45056/54000 (83%)] Loss: -1768.719360\n",
      "    epoch          : 821\n",
      "    loss           : -1770.6456310344192\n",
      "    ess            : 26.84431606868528\n",
      "    log_marginal   : 1770.970318488355\n",
      "    val_loss       : -1771.8273213704426\n",
      "    val_ess        : 26.91292603810628\n",
      "    val_log_marginal: 1772.141825358073\n",
      "Train Epoch: 822 [0/54000 (0%)] Loss: -1767.046875\n",
      "Train Epoch: 822 [11264/54000 (21%)] Loss: -1772.127930\n",
      "Train Epoch: 822 [22528/54000 (42%)] Loss: -1773.051758\n",
      "Train Epoch: 822 [33792/54000 (63%)] Loss: -1774.630005\n",
      "Train Epoch: 822 [45056/54000 (83%)] Loss: -1772.580811\n",
      "    epoch          : 822\n",
      "    loss           : -1771.6445899819428\n",
      "    ess            : 26.856893017606914\n",
      "    log_marginal   : 1771.9728888745578\n",
      "    val_loss       : -1772.6814270019531\n",
      "    val_ess        : 26.859925905863445\n",
      "    val_log_marginal: 1773.0106099446614\n",
      "Train Epoch: 823 [0/54000 (0%)] Loss: -1774.359985\n",
      "Train Epoch: 823 [11264/54000 (21%)] Loss: -1771.266479\n",
      "Train Epoch: 823 [22528/54000 (42%)] Loss: -1773.200684\n",
      "Train Epoch: 823 [33792/54000 (63%)] Loss: -1770.140625\n",
      "Train Epoch: 823 [45056/54000 (83%)] Loss: -1773.670898\n",
      "    epoch          : 823\n",
      "    loss           : -1772.5856818433078\n",
      "    ess            : 26.847681729298717\n",
      "    log_marginal   : 1772.913445238797\n",
      "    val_loss       : -1773.558349609375\n",
      "    val_ess        : 26.827415943145752\n",
      "    val_log_marginal: 1773.8636678059895\n",
      "Train Epoch: 824 [0/54000 (0%)] Loss: -1773.810181\n",
      "Train Epoch: 824 [11264/54000 (21%)] Loss: -1774.244263\n",
      "Train Epoch: 824 [22528/54000 (42%)] Loss: -1777.940552\n",
      "Train Epoch: 824 [33792/54000 (63%)] Loss: -1775.724243\n",
      "Train Epoch: 824 [45056/54000 (83%)] Loss: -1770.106689\n",
      "    epoch          : 824\n",
      "    loss           : -1773.5544744527565\n",
      "    ess            : 26.88789893096348\n",
      "    log_marginal   : 1773.8808455557194\n",
      "    val_loss       : -1774.241963704427\n",
      "    val_ess        : 27.156089305877686\n",
      "    val_log_marginal: 1774.5444030761719\n",
      "Train Epoch: 825 [0/54000 (0%)] Loss: -1776.696167\n",
      "Train Epoch: 825 [11264/54000 (21%)] Loss: -1773.179810\n",
      "Train Epoch: 825 [22528/54000 (42%)] Loss: -1777.422363\n",
      "Train Epoch: 825 [33792/54000 (63%)] Loss: -1775.612183\n",
      "Train Epoch: 825 [45056/54000 (83%)] Loss: -1773.361572\n",
      "    epoch          : 825\n",
      "    loss           : -1774.4269512824292\n",
      "    ess            : 26.971086753989166\n",
      "    log_marginal   : 1774.7480560878537\n",
      "    val_loss       : -1775.0024312337239\n",
      "    val_ess        : 26.86408011118571\n",
      "    val_log_marginal: 1775.3174133300781\n",
      "Train Epoch: 826 [0/54000 (0%)] Loss: -1776.970215\n",
      "Train Epoch: 826 [11264/54000 (21%)] Loss: -1774.197021\n",
      "Train Epoch: 826 [22528/54000 (42%)] Loss: -1771.485596\n",
      "Train Epoch: 826 [33792/54000 (63%)] Loss: -1768.621338\n",
      "Train Epoch: 826 [45056/54000 (83%)] Loss: -1772.396484\n",
      "    epoch          : 826\n",
      "    loss           : -1774.859403790168\n",
      "    ess            : 26.913765709355193\n",
      "    log_marginal   : 1775.184905430056\n",
      "    val_loss       : -1775.2435709635417\n",
      "    val_ess        : 26.882513523101807\n",
      "    val_log_marginal: 1775.5686645507812\n",
      "Train Epoch: 827 [0/54000 (0%)] Loss: -1771.848999\n",
      "Train Epoch: 827 [11264/54000 (21%)] Loss: -1774.850220\n",
      "Train Epoch: 827 [22528/54000 (42%)] Loss: -1748.115723\n",
      "Train Epoch: 827 [33792/54000 (63%)] Loss: -1758.447876\n",
      "Train Epoch: 827 [45056/54000 (83%)] Loss: -1760.422363\n",
      "    epoch          : 827\n",
      "    loss           : -1762.0543120762088\n",
      "    ess            : 26.753422719127727\n",
      "    log_marginal   : 1762.3863387197819\n",
      "    val_loss       : -1755.9383646647136\n",
      "    val_ess        : 26.78657595316569\n",
      "    val_log_marginal: 1756.2538452148438\n",
      "Train Epoch: 828 [0/54000 (0%)] Loss: -1761.291260\n",
      "Train Epoch: 828 [11264/54000 (21%)] Loss: -1766.900635\n",
      "Train Epoch: 828 [22528/54000 (42%)] Loss: -1768.919922\n",
      "Train Epoch: 828 [33792/54000 (63%)] Loss: -1770.506836\n",
      "Train Epoch: 828 [45056/54000 (83%)] Loss: -1770.742676\n",
      "    epoch          : 828\n",
      "    loss           : -1769.0009880785672\n",
      "    ess            : 27.318126282601987\n",
      "    log_marginal   : 1769.2922524506191\n",
      "    val_loss       : -1767.2023213704426\n",
      "    val_ess        : 27.66651725769043\n",
      "    val_log_marginal: 1767.4751383463542\n",
      "Train Epoch: 829 [0/54000 (0%)] Loss: -1771.853271\n",
      "Train Epoch: 829 [11264/54000 (21%)] Loss: -1771.878906\n",
      "Train Epoch: 829 [22528/54000 (42%)] Loss: -1774.156006\n",
      "Train Epoch: 829 [33792/54000 (63%)] Loss: -1772.266357\n",
      "Train Epoch: 829 [45056/54000 (83%)] Loss: -1773.549072\n",
      "    epoch          : 829\n",
      "    loss           : -1772.9368124907871\n",
      "    ess            : 27.0755532822519\n",
      "    log_marginal   : 1773.2456768683667\n",
      "    val_loss       : -1771.9250183105469\n",
      "    val_ess        : 27.274777094523113\n",
      "    val_log_marginal: 1772.2325337727864\n",
      "Train Epoch: 830 [0/54000 (0%)] Loss: -1773.536011\n",
      "Train Epoch: 830 [11264/54000 (21%)] Loss: -1776.279785\n",
      "Train Epoch: 830 [22528/54000 (42%)] Loss: -1770.701416\n",
      "Train Epoch: 830 [33792/54000 (63%)] Loss: -1774.723389\n",
      "Train Epoch: 830 [45056/54000 (83%)] Loss: -1775.131836\n",
      "    epoch          : 830\n",
      "    loss           : -1774.7481631872788\n",
      "    ess            : 26.9827673210288\n",
      "    log_marginal   : 1775.0654976322967\n",
      "    val_loss       : -1773.8269653320312\n",
      "    val_ess        : 26.840316613515217\n",
      "    val_log_marginal: 1774.143330891927\n",
      "Train Epoch: 831 [0/54000 (0%)] Loss: -1777.732788\n",
      "Train Epoch: 831 [11264/54000 (21%)] Loss: -1779.333252\n",
      "Train Epoch: 831 [22528/54000 (42%)] Loss: -1777.606934\n",
      "Train Epoch: 831 [33792/54000 (63%)] Loss: -1774.540771\n",
      "Train Epoch: 831 [45056/54000 (83%)] Loss: -1776.513428\n",
      "    epoch          : 831\n",
      "    loss           : -1775.8968102797023\n",
      "    ess            : 26.926422802907116\n",
      "    log_marginal   : 1776.2207964051445\n",
      "    val_loss       : -1775.0544738769531\n",
      "    val_ess        : 26.985883394877117\n",
      "    val_log_marginal: 1775.3725687662761\n",
      "Train Epoch: 832 [0/54000 (0%)] Loss: -1775.753296\n",
      "Train Epoch: 832 [11264/54000 (21%)] Loss: -1775.747681\n",
      "Train Epoch: 832 [22528/54000 (42%)] Loss: -1776.786133\n",
      "Train Epoch: 832 [33792/54000 (63%)] Loss: -1770.875244\n",
      "Train Epoch: 832 [45056/54000 (83%)] Loss: -1774.449463\n",
      "    epoch          : 832\n",
      "    loss           : -1776.7595111199146\n",
      "    ess            : 26.904239780498\n",
      "    log_marginal   : 1777.0842296672317\n",
      "    val_loss       : -1776.3298645019531\n",
      "    val_ess        : 26.92403968175252\n",
      "    val_log_marginal: 1776.6521504720051\n",
      "Train Epoch: 833 [0/54000 (0%)] Loss: -1779.562500\n",
      "Train Epoch: 833 [11264/54000 (21%)] Loss: -1775.716797\n",
      "Train Epoch: 833 [22528/54000 (42%)] Loss: -1776.272949\n",
      "Train Epoch: 833 [33792/54000 (63%)] Loss: -1772.138428\n",
      "Train Epoch: 833 [45056/54000 (83%)] Loss: -1776.163452\n",
      "    epoch          : 833\n",
      "    loss           : -1777.588556253685\n",
      "    ess            : 26.958638407149405\n",
      "    log_marginal   : 1777.9162459463444\n",
      "    val_loss       : -1777.1449686686199\n",
      "    val_ess        : 27.118830680847168\n",
      "    val_log_marginal: 1777.4564717610676\n",
      "Train Epoch: 834 [0/54000 (0%)] Loss: -1781.605347\n",
      "Train Epoch: 834 [11264/54000 (21%)] Loss: -1776.506104\n",
      "Train Epoch: 834 [22528/54000 (42%)] Loss: -1777.581787\n",
      "Train Epoch: 834 [33792/54000 (63%)] Loss: -1782.807617\n",
      "Train Epoch: 834 [45056/54000 (83%)] Loss: -1776.660156\n",
      "    epoch          : 834\n",
      "    loss           : -1778.202607928582\n",
      "    ess            : 26.983321027935677\n",
      "    log_marginal   : 1778.5252766159344\n",
      "    val_loss       : -1777.6535339355469\n",
      "    val_ess        : 26.940568606058758\n",
      "    val_log_marginal: 1777.9797668457031\n",
      "Train Epoch: 835 [0/54000 (0%)] Loss: -1776.101562\n",
      "Train Epoch: 835 [11264/54000 (21%)] Loss: -1778.128418\n",
      "Train Epoch: 835 [22528/54000 (42%)] Loss: -1780.737305\n",
      "Train Epoch: 835 [33792/54000 (63%)] Loss: -1772.136963\n",
      "Train Epoch: 835 [45056/54000 (83%)] Loss: -1723.622559\n",
      "    epoch          : 835\n",
      "    loss           : -1764.6573163878243\n",
      "    ess            : 26.797522023039043\n",
      "    log_marginal   : 1764.984532770121\n",
      "    val_loss       : -1749.1428120930989\n",
      "    val_ess        : 26.383519013722736\n",
      "    val_log_marginal: 1749.4716898600261\n",
      "Train Epoch: 836 [0/54000 (0%)] Loss: -1746.277100\n",
      "Train Epoch: 836 [11264/54000 (21%)] Loss: -1758.666016\n",
      "Train Epoch: 836 [22528/54000 (42%)] Loss: -1761.039917\n",
      "Train Epoch: 836 [33792/54000 (63%)] Loss: -1765.458252\n",
      "Train Epoch: 836 [45056/54000 (83%)] Loss: -1760.451538\n",
      "    epoch          : 836\n",
      "    loss           : -1759.784328244767\n",
      "    ess            : 27.12253189086914\n",
      "    log_marginal   : 1760.084269973467\n",
      "    val_loss       : -1765.173075358073\n",
      "    val_ess        : 27.722272872924805\n",
      "    val_log_marginal: 1765.4397074381511\n",
      "Train Epoch: 837 [0/54000 (0%)] Loss: -1769.640869\n",
      "Train Epoch: 837 [11264/54000 (21%)] Loss: -1769.415527\n",
      "Train Epoch: 837 [22528/54000 (42%)] Loss: -1770.990234\n",
      "Train Epoch: 837 [33792/54000 (63%)] Loss: -1771.228149\n",
      "Train Epoch: 837 [45056/54000 (83%)] Loss: -1770.244995\n",
      "    epoch          : 837\n",
      "    loss           : -1769.5587400040536\n",
      "    ess            : 27.26566226527376\n",
      "    log_marginal   : 1769.8583109153892\n",
      "    val_loss       : -1770.1909484863281\n",
      "    val_ess        : 26.921746571858723\n",
      "    val_log_marginal: 1770.5184224446614\n",
      "Train Epoch: 838 [0/54000 (0%)] Loss: -1775.732666\n",
      "Train Epoch: 838 [11264/54000 (21%)] Loss: -1774.587036\n",
      "Train Epoch: 838 [22528/54000 (42%)] Loss: -1775.611206\n",
      "Train Epoch: 838 [33792/54000 (63%)] Loss: -1773.661987\n",
      "Train Epoch: 838 [45056/54000 (83%)] Loss: -1773.323486\n",
      "    epoch          : 838\n",
      "    loss           : -1772.9635620117188\n",
      "    ess            : 26.93101798363452\n",
      "    log_marginal   : 1773.286319372789\n",
      "    val_loss       : -1772.9674275716145\n",
      "    val_ess        : 27.12009604771932\n",
      "    val_log_marginal: 1773.2701924641926\n",
      "Train Epoch: 839 [0/54000 (0%)] Loss: -1774.293213\n",
      "Train Epoch: 839 [11264/54000 (21%)] Loss: -1771.451660\n",
      "Train Epoch: 839 [22528/54000 (42%)] Loss: -1766.170898\n",
      "Train Epoch: 839 [33792/54000 (63%)] Loss: -1776.991211\n",
      "Train Epoch: 839 [45056/54000 (83%)] Loss: -1775.076904\n",
      "    epoch          : 839\n",
      "    loss           : -1774.6108087503685\n",
      "    ess            : 26.94030587178356\n",
      "    log_marginal   : 1774.9311085826946\n",
      "    val_loss       : -1774.3610738118489\n",
      "    val_ess        : 26.872858842213947\n",
      "    val_log_marginal: 1774.6866760253906\n",
      "Train Epoch: 840 [0/54000 (0%)] Loss: -1775.788696\n",
      "Train Epoch: 840 [11264/54000 (21%)] Loss: -1779.672363\n",
      "Train Epoch: 840 [22528/54000 (42%)] Loss: -1774.352783\n",
      "Train Epoch: 840 [33792/54000 (63%)] Loss: -1774.301025\n",
      "Train Epoch: 840 [45056/54000 (83%)] Loss: -1770.672852\n",
      "    epoch          : 840\n",
      "    loss           : -1775.8705870430424\n",
      "    ess            : 26.913993043719596\n",
      "    log_marginal   : 1776.1943589696343\n",
      "    val_loss       : -1775.6468607584636\n",
      "    val_ess        : 26.795193354288738\n",
      "    val_log_marginal: 1775.974141438802\n",
      "Train Epoch: 841 [0/54000 (0%)] Loss: -1777.986328\n",
      "Train Epoch: 841 [11264/54000 (21%)] Loss: -1780.889526\n",
      "Train Epoch: 841 [22528/54000 (42%)] Loss: -1779.039551\n",
      "Train Epoch: 841 [33792/54000 (63%)] Loss: -1775.475586\n",
      "Train Epoch: 841 [45056/54000 (83%)] Loss: -1775.581787\n",
      "    epoch          : 841\n",
      "    loss           : -1776.8520646005306\n",
      "    ess            : 26.95222611697215\n",
      "    log_marginal   : 1777.1780994343308\n",
      "    val_loss       : -1776.7285461425781\n",
      "    val_ess        : 26.751206556955974\n",
      "    val_log_marginal: 1777.0626118977864\n",
      "Train Epoch: 842 [0/54000 (0%)] Loss: -1779.090088\n",
      "Train Epoch: 842 [11264/54000 (21%)] Loss: -1772.431641\n",
      "Train Epoch: 842 [22528/54000 (42%)] Loss: -1773.999634\n",
      "Train Epoch: 842 [33792/54000 (63%)] Loss: -1779.505493\n",
      "Train Epoch: 842 [45056/54000 (83%)] Loss: -1776.435791\n",
      "    epoch          : 842\n",
      "    loss           : -1777.7575004145783\n",
      "    ess            : 26.85800079129777\n",
      "    log_marginal   : 1778.082706091539\n",
      "    val_loss       : -1777.5978698730469\n",
      "    val_ess        : 27.10099220275879\n",
      "    val_log_marginal: 1777.9067281087239\n",
      "Train Epoch: 843 [0/54000 (0%)] Loss: -1778.674805\n",
      "Train Epoch: 843 [11264/54000 (21%)] Loss: -1778.255371\n",
      "Train Epoch: 843 [22528/54000 (42%)] Loss: -1778.465332\n",
      "Train Epoch: 843 [33792/54000 (63%)] Loss: -1781.758545\n",
      "Train Epoch: 843 [45056/54000 (83%)] Loss: -1780.219849\n",
      "    epoch          : 843\n",
      "    loss           : -1778.4192977041569\n",
      "    ess            : 26.956607692646532\n",
      "    log_marginal   : 1778.7449812979069\n",
      "    val_loss       : -1778.1579182942708\n",
      "    val_ess        : 26.947833220163982\n",
      "    val_log_marginal: 1778.4815979003906\n",
      "Train Epoch: 844 [0/54000 (0%)] Loss: -1781.214844\n",
      "Train Epoch: 844 [11264/54000 (21%)] Loss: -1777.960815\n",
      "Train Epoch: 844 [22528/54000 (42%)] Loss: -1779.968018\n",
      "Train Epoch: 844 [33792/54000 (63%)] Loss: -1778.642456\n",
      "Train Epoch: 844 [45056/54000 (83%)] Loss: -1782.330078\n",
      "    epoch          : 844\n",
      "    loss           : -1779.1091158884876\n",
      "    ess            : 26.93960031473412\n",
      "    log_marginal   : 1779.4336870301445\n",
      "    val_loss       : -1778.4993286132812\n",
      "    val_ess        : 27.005898475646973\n",
      "    val_log_marginal: 1778.8108622233074\n",
      "Train Epoch: 845 [0/54000 (0%)] Loss: -1776.675537\n",
      "Train Epoch: 845 [11264/54000 (21%)] Loss: -1782.895508\n",
      "Train Epoch: 845 [22528/54000 (42%)] Loss: -1786.349365\n",
      "Train Epoch: 845 [33792/54000 (63%)] Loss: -1775.890503\n",
      "Train Epoch: 845 [45056/54000 (83%)] Loss: -1777.450439\n",
      "    epoch          : 845\n",
      "    loss           : -1779.668452424823\n",
      "    ess            : 26.921673468823702\n",
      "    log_marginal   : 1779.9971071639152\n",
      "    val_loss       : -1779.1866455078125\n",
      "    val_ess        : 26.91097354888916\n",
      "    val_log_marginal: 1779.5250040690105\n",
      "Train Epoch: 846 [0/54000 (0%)] Loss: -1780.148438\n",
      "Train Epoch: 846 [11264/54000 (21%)] Loss: -1779.764771\n",
      "Train Epoch: 846 [22528/54000 (42%)] Loss: -1778.140137\n",
      "Train Epoch: 846 [33792/54000 (63%)] Loss: -1775.591431\n",
      "Train Epoch: 846 [45056/54000 (83%)] Loss: -1776.698486\n",
      "    epoch          : 846\n",
      "    loss           : -1775.750004606427\n",
      "    ess            : 26.993573962517505\n",
      "    log_marginal   : 1776.0691896834464\n",
      "    val_loss       : -1744.2416381835938\n",
      "    val_ess        : 26.8170067469279\n",
      "    val_log_marginal: 1744.5611267089844\n",
      "Train Epoch: 847 [0/54000 (0%)] Loss: -1744.460693\n",
      "Train Epoch: 847 [11264/54000 (21%)] Loss: -1761.206543\n",
      "Train Epoch: 847 [22528/54000 (42%)] Loss: -1769.248535\n",
      "Train Epoch: 847 [33792/54000 (63%)] Loss: -1745.497192\n",
      "Train Epoch: 847 [45056/54000 (83%)] Loss: -1750.231689\n",
      "    epoch          : 847\n",
      "    loss           : -1753.0239580262382\n",
      "    ess            : 26.91947186667964\n",
      "    log_marginal   : 1753.3311306935436\n",
      "    val_loss       : -1759.298563639323\n",
      "    val_ess        : 27.9699813524882\n",
      "    val_log_marginal: 1759.5585021972656\n",
      "Train Epoch: 848 [0/54000 (0%)] Loss: -1767.225708\n",
      "Train Epoch: 848 [11264/54000 (21%)] Loss: -1773.150879\n",
      "Train Epoch: 848 [22528/54000 (42%)] Loss: -1769.588501\n",
      "Train Epoch: 848 [33792/54000 (63%)] Loss: -1768.790771\n",
      "Train Epoch: 848 [45056/54000 (83%)] Loss: -1772.177124\n",
      "    epoch          : 848\n",
      "    loss           : -1768.321892504422\n",
      "    ess            : 27.68546665839429\n",
      "    log_marginal   : 1768.5969721956073\n",
      "    val_loss       : -1770.1344299316406\n",
      "    val_ess        : 27.25130542119344\n",
      "    val_log_marginal: 1770.4499409993489\n",
      "Train Epoch: 849 [0/54000 (0%)] Loss: -1774.222412\n",
      "Train Epoch: 849 [11264/54000 (21%)] Loss: -1773.980957\n",
      "Train Epoch: 849 [22528/54000 (42%)] Loss: -1774.046753\n",
      "Train Epoch: 849 [33792/54000 (63%)] Loss: -1775.909912\n",
      "Train Epoch: 849 [45056/54000 (83%)] Loss: -1771.616211\n",
      "    epoch          : 849\n",
      "    loss           : -1773.1669196362766\n",
      "    ess            : 27.051582174481087\n",
      "    log_marginal   : 1773.4782081460053\n",
      "    val_loss       : -1773.316141764323\n",
      "    val_ess        : 26.848026434580486\n",
      "    val_log_marginal: 1773.6320902506511\n",
      "Train Epoch: 850 [0/54000 (0%)] Loss: -1771.692749\n",
      "Train Epoch: 850 [11264/54000 (21%)] Loss: -1769.315918\n",
      "Train Epoch: 850 [22528/54000 (42%)] Loss: -1776.095703\n",
      "Train Epoch: 850 [33792/54000 (63%)] Loss: -1777.451172\n",
      "Train Epoch: 850 [45056/54000 (83%)] Loss: -1771.794800\n",
      "    epoch          : 850\n",
      "    loss           : -1775.188009010171\n",
      "    ess            : 26.99845375204986\n",
      "    log_marginal   : 1775.505209868809\n",
      "    val_loss       : -1775.301045735677\n",
      "    val_ess        : 26.937708377838135\n",
      "    val_log_marginal: 1775.6127827962239\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [0/54000 (0%)] Loss: -1778.630615\n",
      "Train Epoch: 851 [11264/54000 (21%)] Loss: -1775.488770\n",
      "Train Epoch: 851 [22528/54000 (42%)] Loss: -1774.399170\n",
      "Train Epoch: 851 [33792/54000 (63%)] Loss: -1778.276123\n",
      "Train Epoch: 851 [45056/54000 (83%)] Loss: -1776.575684\n",
      "    epoch          : 851\n",
      "    loss           : -1776.654805885171\n",
      "    ess            : 26.872720232549703\n",
      "    log_marginal   : 1776.9840629145783\n",
      "    val_loss       : -1776.1364237467449\n",
      "    val_ess        : 27.046926339467365\n",
      "    val_log_marginal: 1776.4582824707031\n",
      "Train Epoch: 852 [0/54000 (0%)] Loss: -1776.142334\n",
      "Train Epoch: 852 [11264/54000 (21%)] Loss: -1775.802979\n",
      "Train Epoch: 852 [22528/54000 (42%)] Loss: -1780.581543\n",
      "Train Epoch: 852 [33792/54000 (63%)] Loss: -1776.061768\n",
      "Train Epoch: 852 [45056/54000 (83%)] Loss: -1778.998779\n",
      "    epoch          : 852\n",
      "    loss           : -1777.7807594155365\n",
      "    ess            : 26.976260707063496\n",
      "    log_marginal   : 1778.0962892928214\n",
      "    val_loss       : -1776.8652750651042\n",
      "    val_ess        : 26.983997503916424\n",
      "    val_log_marginal: 1777.187255859375\n",
      "Train Epoch: 853 [0/54000 (0%)] Loss: -1776.359497\n",
      "Train Epoch: 853 [11264/54000 (21%)] Loss: -1780.869385\n",
      "Train Epoch: 853 [22528/54000 (42%)] Loss: -1778.099854\n",
      "Train Epoch: 853 [33792/54000 (63%)] Loss: -1781.779419\n",
      "Train Epoch: 853 [45056/54000 (83%)] Loss: -1782.396729\n",
      "    epoch          : 853\n",
      "    loss           : -1778.625330511129\n",
      "    ess            : 27.010101210396243\n",
      "    log_marginal   : 1778.9441804705925\n",
      "    val_loss       : -1778.1881713867188\n",
      "    val_ess        : 27.06471522649129\n",
      "    val_log_marginal: 1778.5188496907551\n",
      "Train Epoch: 854 [0/54000 (0%)] Loss: -1780.005127\n",
      "Train Epoch: 854 [11264/54000 (21%)] Loss: -1779.120117\n",
      "Train Epoch: 854 [22528/54000 (42%)] Loss: -1775.830566\n",
      "Train Epoch: 854 [33792/54000 (63%)] Loss: -1776.440063\n",
      "Train Epoch: 854 [45056/54000 (83%)] Loss: -1776.328857\n",
      "    epoch          : 854\n",
      "    loss           : -1778.4695054540093\n",
      "    ess            : 27.004327792041707\n",
      "    log_marginal   : 1778.7896060583726\n",
      "    val_loss       : -1773.8478291829426\n",
      "    val_ess        : 26.721866448720295\n",
      "    val_log_marginal: 1774.1833190917969\n",
      "Train Epoch: 855 [0/54000 (0%)] Loss: -1770.221680\n",
      "Train Epoch: 855 [11264/54000 (21%)] Loss: -1747.548096\n",
      "Train Epoch: 855 [22528/54000 (42%)] Loss: -1774.176025\n",
      "Train Epoch: 855 [33792/54000 (63%)] Loss: -1773.074219\n",
      "Train Epoch: 855 [45056/54000 (83%)] Loss: -1743.689453\n",
      "    epoch          : 855\n",
      "    loss           : -1759.4244165960347\n",
      "    ess            : 26.842364779058492\n",
      "    log_marginal   : 1759.743858481353\n",
      "    val_loss       : -1756.6403401692708\n",
      "    val_ess        : 26.75629774729411\n",
      "    val_log_marginal: 1756.9524027506511\n",
      "Train Epoch: 856 [0/54000 (0%)] Loss: -1755.861328\n",
      "Train Epoch: 856 [11264/54000 (21%)] Loss: -1764.472168\n",
      "Train Epoch: 856 [22528/54000 (42%)] Loss: -1767.722412\n",
      "Train Epoch: 856 [33792/54000 (63%)] Loss: -1767.839111\n",
      "Train Epoch: 856 [45056/54000 (83%)] Loss: -1768.381592\n",
      "    epoch          : 856\n",
      "    loss           : -1769.6644690171727\n",
      "    ess            : 27.504825897936552\n",
      "    log_marginal   : 1769.9462752432194\n",
      "    val_loss       : -1768.2283325195312\n",
      "    val_ess        : 27.57149585088094\n",
      "    val_log_marginal: 1768.5157674153645\n",
      "Train Epoch: 857 [0/54000 (0%)] Loss: -1780.390381\n",
      "Train Epoch: 857 [11264/54000 (21%)] Loss: -1773.395996\n",
      "Train Epoch: 857 [22528/54000 (42%)] Loss: -1773.566040\n",
      "Train Epoch: 857 [33792/54000 (63%)] Loss: -1774.001343\n",
      "Train Epoch: 857 [45056/54000 (83%)] Loss: -1773.574097\n",
      "    epoch          : 857\n",
      "    loss           : -1774.4324041402565\n",
      "    ess            : 27.044330363003713\n",
      "    log_marginal   : 1774.7493735259434\n",
      "    val_loss       : -1773.5538635253906\n",
      "    val_ess        : 27.208502928415935\n",
      "    val_log_marginal: 1773.8555094401042\n",
      "Train Epoch: 858 [0/54000 (0%)] Loss: -1782.216553\n",
      "Train Epoch: 858 [11264/54000 (21%)] Loss: -1778.474121\n",
      "Train Epoch: 858 [22528/54000 (42%)] Loss: -1773.896606\n",
      "Train Epoch: 858 [33792/54000 (63%)] Loss: -1777.816162\n",
      "Train Epoch: 858 [45056/54000 (83%)] Loss: -1774.732910\n",
      "    epoch          : 858\n",
      "    loss           : -1776.345707731427\n",
      "    ess            : 27.004860410150492\n",
      "    log_marginal   : 1776.6626690558667\n",
      "    val_loss       : -1775.9438374837239\n",
      "    val_ess        : 27.006121317545574\n",
      "    val_log_marginal: 1776.26904296875\n",
      "Train Epoch: 859 [0/54000 (0%)] Loss: -1777.557251\n",
      "Train Epoch: 859 [11264/54000 (21%)] Loss: -1775.593872\n",
      "Train Epoch: 859 [22528/54000 (42%)] Loss: -1781.361206\n",
      "Train Epoch: 859 [33792/54000 (63%)] Loss: -1778.479004\n",
      "Train Epoch: 859 [45056/54000 (83%)] Loss: -1781.375488\n",
      "    epoch          : 859\n",
      "    loss           : -1777.7132614423645\n",
      "    ess            : 26.932381611949992\n",
      "    log_marginal   : 1778.0362710053066\n",
      "    val_loss       : -1776.9941914876301\n",
      "    val_ess        : 27.164921760559082\n",
      "    val_log_marginal: 1777.3072713216145\n",
      "Train Epoch: 860 [0/54000 (0%)] Loss: -1780.209473\n",
      "Train Epoch: 860 [11264/54000 (21%)] Loss: -1779.436646\n",
      "Train Epoch: 860 [22528/54000 (42%)] Loss: -1781.739258\n",
      "Train Epoch: 860 [33792/54000 (63%)] Loss: -1781.092773\n",
      "Train Epoch: 860 [45056/54000 (83%)] Loss: -1778.501465\n",
      "    epoch          : 860\n",
      "    loss           : -1778.7118138727153\n",
      "    ess            : 26.92874616946814\n",
      "    log_marginal   : 1779.0353911777713\n",
      "    val_loss       : -1778.0020853678386\n",
      "    val_ess        : 26.89454444249471\n",
      "    val_log_marginal: 1778.3334655761719\n",
      "Train Epoch: 861 [0/54000 (0%)] Loss: -1776.388062\n",
      "Train Epoch: 861 [11264/54000 (21%)] Loss: -1777.957886\n",
      "Train Epoch: 861 [22528/54000 (42%)] Loss: -1779.085205\n",
      "Train Epoch: 861 [33792/54000 (63%)] Loss: -1776.294434\n",
      "Train Epoch: 861 [45056/54000 (83%)] Loss: -1782.710449\n",
      "    epoch          : 861\n",
      "    loss           : -1779.4870755177624\n",
      "    ess            : 26.971724780100697\n",
      "    log_marginal   : 1779.8109050246906\n",
      "    val_loss       : -1778.9578959147136\n",
      "    val_ess        : 27.162057717641193\n",
      "    val_log_marginal: 1779.2725728352864\n",
      "Train Epoch: 862 [0/54000 (0%)] Loss: -1786.817993\n",
      "Train Epoch: 862 [11264/54000 (21%)] Loss: -1783.037354\n",
      "Train Epoch: 862 [22528/54000 (42%)] Loss: -1778.886475\n",
      "Train Epoch: 862 [33792/54000 (63%)] Loss: -1780.994263\n",
      "Train Epoch: 862 [45056/54000 (83%)] Loss: -1777.832764\n",
      "    epoch          : 862\n",
      "    loss           : -1780.231048008181\n",
      "    ess            : 26.95680053279085\n",
      "    log_marginal   : 1780.5571542415978\n",
      "    val_loss       : -1779.428466796875\n",
      "    val_ess        : 26.982520580291748\n",
      "    val_log_marginal: 1779.7471110026042\n",
      "Train Epoch: 863 [0/54000 (0%)] Loss: -1781.262451\n",
      "Train Epoch: 863 [11264/54000 (21%)] Loss: -1781.174561\n",
      "Train Epoch: 863 [22528/54000 (42%)] Loss: -1779.029053\n",
      "Train Epoch: 863 [33792/54000 (63%)] Loss: -1782.511108\n",
      "Train Epoch: 863 [45056/54000 (83%)] Loss: -1774.843506\n",
      "    epoch          : 863\n",
      "    loss           : -1780.695933216023\n",
      "    ess            : 26.996716031488383\n",
      "    log_marginal   : 1781.0198859448703\n",
      "    val_loss       : -1779.4268188476562\n",
      "    val_ess        : 26.856157938639324\n",
      "    val_log_marginal: 1779.7592468261719\n",
      "Train Epoch: 864 [0/54000 (0%)] Loss: -1781.868896\n",
      "Train Epoch: 864 [11264/54000 (21%)] Loss: -1781.886719\n",
      "Train Epoch: 864 [22528/54000 (42%)] Loss: -1773.269531\n",
      "Train Epoch: 864 [33792/54000 (63%)] Loss: -1766.609375\n",
      "Train Epoch: 864 [45056/54000 (83%)] Loss: -1767.727539\n",
      "    epoch          : 864\n",
      "    loss           : -1772.5561419792896\n",
      "    ess            : 26.876421190657705\n",
      "    log_marginal   : 1772.8848174473026\n",
      "    val_loss       : -1769.254903157552\n",
      "    val_ess        : 27.05221350987752\n",
      "    val_log_marginal: 1769.5613911946614\n",
      "Train Epoch: 865 [0/54000 (0%)] Loss: -1771.992188\n",
      "Train Epoch: 865 [11264/54000 (21%)] Loss: -1777.974121\n",
      "Train Epoch: 865 [22528/54000 (42%)] Loss: -1732.877197\n",
      "Train Epoch: 865 [33792/54000 (63%)] Loss: -1735.122314\n",
      "Train Epoch: 865 [45056/54000 (83%)] Loss: -1756.793945\n",
      "    epoch          : 865\n",
      "    loss           : -1753.2226838885613\n",
      "    ess            : 27.101228678001547\n",
      "    log_marginal   : 1753.5242205925708\n",
      "    val_loss       : -1754.0082499186199\n",
      "    val_ess        : 27.176873842875164\n",
      "    val_log_marginal: 1754.2974446614583\n",
      "Train Epoch: 866 [0/54000 (0%)] Loss: -1759.798950\n",
      "Train Epoch: 866 [11264/54000 (21%)] Loss: -1764.519165\n",
      "Train Epoch: 866 [22528/54000 (42%)] Loss: -1765.081543\n",
      "Train Epoch: 866 [33792/54000 (63%)] Loss: -1768.353394\n",
      "Train Epoch: 866 [45056/54000 (83%)] Loss: -1767.180420\n",
      "    epoch          : 866\n",
      "    loss           : -1765.0774087006191\n",
      "    ess            : 27.618430479517524\n",
      "    log_marginal   : 1765.3497349001327\n",
      "    val_loss       : -1767.2962036132812\n",
      "    val_ess        : 27.667388598124187\n",
      "    val_log_marginal: 1767.56640625\n",
      "Train Epoch: 867 [0/54000 (0%)] Loss: -1771.070068\n",
      "Train Epoch: 867 [11264/54000 (21%)] Loss: -1772.812256\n",
      "Train Epoch: 867 [22528/54000 (42%)] Loss: -1772.574219\n",
      "Train Epoch: 867 [33792/54000 (63%)] Loss: -1773.091187\n",
      "Train Epoch: 867 [45056/54000 (83%)] Loss: -1772.788818\n",
      "    epoch          : 867\n",
      "    loss           : -1771.7303328604069\n",
      "    ess            : 27.168032160345113\n",
      "    log_marginal   : 1772.0331017836086\n",
      "    val_loss       : -1772.427998860677\n",
      "    val_ess        : 27.081008752187092\n",
      "    val_log_marginal: 1772.7411193847656\n",
      "Train Epoch: 868 [0/54000 (0%)] Loss: -1774.215332\n",
      "Train Epoch: 868 [11264/54000 (21%)] Loss: -1777.804565\n",
      "Train Epoch: 868 [22528/54000 (42%)] Loss: -1777.124634\n",
      "Train Epoch: 868 [33792/54000 (63%)] Loss: -1773.257324\n",
      "Train Epoch: 868 [45056/54000 (83%)] Loss: -1772.462402\n",
      "    epoch          : 868\n",
      "    loss           : -1774.3567113336528\n",
      "    ess            : 27.004329033617704\n",
      "    log_marginal   : 1774.670438946418\n",
      "    val_loss       : -1774.284932454427\n",
      "    val_ess        : 26.807933648427326\n",
      "    val_log_marginal: 1774.6217651367188\n",
      "Train Epoch: 869 [0/54000 (0%)] Loss: -1774.323730\n",
      "Train Epoch: 869 [11264/54000 (21%)] Loss: -1777.684937\n",
      "Train Epoch: 869 [22528/54000 (42%)] Loss: -1776.789795\n",
      "Train Epoch: 869 [33792/54000 (63%)] Loss: -1777.417969\n",
      "Train Epoch: 869 [45056/54000 (83%)] Loss: -1779.406006\n",
      "    epoch          : 869\n",
      "    loss           : -1775.9153108416863\n",
      "    ess            : 26.916232432959216\n",
      "    log_marginal   : 1776.2371860720077\n",
      "    val_loss       : -1775.6284891764324\n",
      "    val_ess        : 26.959710280100506\n",
      "    val_log_marginal: 1775.9662577311199\n",
      "Train Epoch: 870 [0/54000 (0%)] Loss: -1776.825195\n",
      "Train Epoch: 870 [11264/54000 (21%)] Loss: -1774.179199\n",
      "Train Epoch: 870 [22528/54000 (42%)] Loss: -1778.717773\n",
      "Train Epoch: 870 [33792/54000 (63%)] Loss: -1779.302612\n",
      "Train Epoch: 870 [45056/54000 (83%)] Loss: -1773.821777\n",
      "    epoch          : 870\n",
      "    loss           : -1777.2331450840213\n",
      "    ess            : 26.921887721655505\n",
      "    log_marginal   : 1777.5558932322376\n",
      "    val_loss       : -1777.2042643229167\n",
      "    val_ess        : 26.79893684387207\n",
      "    val_log_marginal: 1777.5464986165364\n",
      "Train Epoch: 871 [0/54000 (0%)] Loss: -1773.887695\n",
      "Train Epoch: 871 [11264/54000 (21%)] Loss: -1783.820068\n",
      "Train Epoch: 871 [22528/54000 (42%)] Loss: -1785.272217\n",
      "Train Epoch: 871 [33792/54000 (63%)] Loss: -1776.890869\n",
      "Train Epoch: 871 [45056/54000 (83%)] Loss: -1774.823242\n",
      "    epoch          : 871\n",
      "    loss           : -1778.1551720961086\n",
      "    ess            : 26.89766613942272\n",
      "    log_marginal   : 1778.4813773677033\n",
      "    val_loss       : -1777.9456583658855\n",
      "    val_ess        : 26.94023021062215\n",
      "    val_log_marginal: 1778.2743428548176\n",
      "Train Epoch: 872 [0/54000 (0%)] Loss: -1776.512451\n",
      "Train Epoch: 872 [11264/54000 (21%)] Loss: -1779.385254\n",
      "Train Epoch: 872 [22528/54000 (42%)] Loss: -1776.820190\n",
      "Train Epoch: 872 [33792/54000 (63%)] Loss: -1781.180420\n",
      "Train Epoch: 872 [45056/54000 (83%)] Loss: -1778.167480\n",
      "    epoch          : 872\n",
      "    loss           : -1779.1390542084316\n",
      "    ess            : 26.934099197387695\n",
      "    log_marginal   : 1779.4575748083726\n",
      "    val_loss       : -1779.0581359863281\n",
      "    val_ess        : 27.03879960378011\n",
      "    val_log_marginal: 1779.3706563313801\n",
      "Train Epoch: 873 [0/54000 (0%)] Loss: -1778.337036\n",
      "Train Epoch: 873 [11264/54000 (21%)] Loss: -1781.983032\n",
      "Train Epoch: 873 [22528/54000 (42%)] Loss: -1782.058228\n",
      "Train Epoch: 873 [33792/54000 (63%)] Loss: -1782.150635\n",
      "Train Epoch: 873 [45056/54000 (83%)] Loss: -1782.273682\n",
      "    epoch          : 873\n",
      "    loss           : -1779.8696150869694\n",
      "    ess            : 26.947993980263764\n",
      "    log_marginal   : 1780.1921478847287\n",
      "    val_loss       : -1779.8642272949219\n",
      "    val_ess        : 26.94663079579671\n",
      "    val_log_marginal: 1780.1890360514324\n",
      "Train Epoch: 874 [0/54000 (0%)] Loss: -1778.275879\n",
      "Train Epoch: 874 [11264/54000 (21%)] Loss: -1780.531250\n",
      "Train Epoch: 874 [22528/54000 (42%)] Loss: -1782.885254\n",
      "Train Epoch: 874 [33792/54000 (63%)] Loss: -1779.547363\n",
      "Train Epoch: 874 [45056/54000 (83%)] Loss: -1778.091797\n",
      "    epoch          : 874\n",
      "    loss           : -1780.3690519512825\n",
      "    ess            : 27.0052796309849\n",
      "    log_marginal   : 1780.6929689803214\n",
      "    val_loss       : -1779.8779703776042\n",
      "    val_ess        : 26.97173325220744\n",
      "    val_log_marginal: 1780.1964619954426\n",
      "Train Epoch: 875 [0/54000 (0%)] Loss: -1781.560059\n",
      "Train Epoch: 875 [11264/54000 (21%)] Loss: -1779.380249\n",
      "Train Epoch: 875 [22528/54000 (42%)] Loss: -1774.645264\n",
      "Train Epoch: 875 [33792/54000 (63%)] Loss: -1776.543945\n",
      "Train Epoch: 875 [45056/54000 (83%)] Loss: -1720.158081\n",
      "    epoch          : 875\n",
      "    loss           : -1767.2454119988208\n",
      "    ess            : 26.9485172955495\n",
      "    log_marginal   : 1767.566224296138\n",
      "    val_loss       : -1749.4067687988281\n",
      "    val_ess        : 26.331499099731445\n",
      "    val_log_marginal: 1749.7341206868489\n",
      "Train Epoch: 876 [0/54000 (0%)] Loss: -1743.362549\n",
      "Train Epoch: 876 [11264/54000 (21%)] Loss: -1765.227295\n",
      "Train Epoch: 876 [22528/54000 (42%)] Loss: -1765.699219\n",
      "Train Epoch: 876 [33792/54000 (63%)] Loss: -1764.869507\n",
      "Train Epoch: 876 [45056/54000 (83%)] Loss: -1772.557373\n",
      "    epoch          : 876\n",
      "    loss           : -1766.8294067382812\n",
      "    ess            : 27.106976743014354\n",
      "    log_marginal   : 1767.1346596771816\n",
      "    val_loss       : -1766.4739074707031\n",
      "    val_ess        : 27.777784665425617\n",
      "    val_log_marginal: 1766.7347005208333\n",
      "Train Epoch: 877 [0/54000 (0%)] Loss: -1774.784668\n",
      "Train Epoch: 877 [11264/54000 (21%)] Loss: -1774.587891\n",
      "Train Epoch: 877 [22528/54000 (42%)] Loss: -1771.105225\n",
      "Train Epoch: 877 [33792/54000 (63%)] Loss: -1774.025269\n",
      "Train Epoch: 877 [45056/54000 (83%)] Loss: -1774.258057\n",
      "    epoch          : 877\n",
      "    loss           : -1773.8090728183963\n",
      "    ess            : 27.2223383705571\n",
      "    log_marginal   : 1774.1130301997346\n",
      "    val_loss       : -1773.2023824055989\n",
      "    val_ess        : 27.59404468536377\n",
      "    val_log_marginal: 1773.4860127766926\n",
      "Train Epoch: 878 [0/54000 (0%)] Loss: -1776.532104\n",
      "Train Epoch: 878 [11264/54000 (21%)] Loss: -1776.410522\n",
      "Train Epoch: 878 [22528/54000 (42%)] Loss: -1770.007568\n",
      "Train Epoch: 878 [33792/54000 (63%)] Loss: -1778.109619\n",
      "Train Epoch: 878 [45056/54000 (83%)] Loss: -1776.354736\n",
      "    epoch          : 878\n",
      "    loss           : -1776.559048634655\n",
      "    ess            : 26.96176887008379\n",
      "    log_marginal   : 1776.8782809275501\n",
      "    val_loss       : -1775.8301798502605\n",
      "    val_ess        : 26.836779594421387\n",
      "    val_log_marginal: 1776.1801656087239\n",
      "Train Epoch: 879 [0/54000 (0%)] Loss: -1778.234253\n",
      "Train Epoch: 879 [11264/54000 (21%)] Loss: -1776.106445\n",
      "Train Epoch: 879 [22528/54000 (42%)] Loss: -1776.365479\n",
      "Train Epoch: 879 [33792/54000 (63%)] Loss: -1782.005981\n",
      "Train Epoch: 879 [45056/54000 (83%)] Loss: -1775.686890\n",
      "    epoch          : 879\n",
      "    loss           : -1777.952727695681\n",
      "    ess            : 26.97076709315462\n",
      "    log_marginal   : 1778.273442106427\n",
      "    val_loss       : -1777.2224019368489\n",
      "    val_ess        : 26.919374306996662\n",
      "    val_log_marginal: 1777.5568237304688\n",
      "Train Epoch: 880 [0/54000 (0%)] Loss: -1779.271973\n",
      "Train Epoch: 880 [11264/54000 (21%)] Loss: -1777.053467\n",
      "Train Epoch: 880 [22528/54000 (42%)] Loss: -1779.712769\n",
      "Train Epoch: 880 [33792/54000 (63%)] Loss: -1779.817993\n",
      "Train Epoch: 880 [45056/54000 (83%)] Loss: -1781.925537\n",
      "    epoch          : 880\n",
      "    loss           : -1778.993800901017\n",
      "    ess            : 27.035220955902677\n",
      "    log_marginal   : 1779.3104075305866\n",
      "    val_loss       : -1778.4150492350261\n",
      "    val_ess        : 27.142877737681072\n",
      "    val_log_marginal: 1778.7342325846355\n",
      "Train Epoch: 881 [0/54000 (0%)] Loss: -1780.076416\n",
      "Train Epoch: 881 [11264/54000 (21%)] Loss: -1779.319946\n",
      "Train Epoch: 881 [22528/54000 (42%)] Loss: -1780.448242\n",
      "Train Epoch: 881 [33792/54000 (63%)] Loss: -1782.057739\n",
      "Train Epoch: 881 [45056/54000 (83%)] Loss: -1774.692261\n",
      "    epoch          : 881\n",
      "    loss           : -1779.9010712245724\n",
      "    ess            : 26.94632400656646\n",
      "    log_marginal   : 1780.2246519844487\n",
      "    val_loss       : -1779.7079569498699\n",
      "    val_ess        : 26.954269568125408\n",
      "    val_log_marginal: 1780.0320129394531\n",
      "Train Epoch: 882 [0/54000 (0%)] Loss: -1784.804199\n",
      "Train Epoch: 882 [11264/54000 (21%)] Loss: -1779.100586\n",
      "Train Epoch: 882 [22528/54000 (42%)] Loss: -1779.380371\n",
      "Train Epoch: 882 [33792/54000 (63%)] Loss: -1779.385620\n",
      "Train Epoch: 882 [45056/54000 (83%)] Loss: -1780.786621\n",
      "    epoch          : 882\n",
      "    loss           : -1780.6146090525501\n",
      "    ess            : 27.07429164310671\n",
      "    log_marginal   : 1780.9331814747936\n",
      "    val_loss       : -1779.9909973144531\n",
      "    val_ess        : 27.017438570658367\n",
      "    val_log_marginal: 1780.312520345052\n",
      "Train Epoch: 883 [0/54000 (0%)] Loss: -1780.569092\n",
      "Train Epoch: 883 [11264/54000 (21%)] Loss: -1782.183105\n",
      "Train Epoch: 883 [22528/54000 (42%)] Loss: -1784.766724\n",
      "Train Epoch: 883 [33792/54000 (63%)] Loss: -1778.089844\n",
      "Train Epoch: 883 [45056/54000 (83%)] Loss: -1773.124512\n",
      "    epoch          : 883\n",
      "    loss           : -1781.301178554319\n",
      "    ess            : 26.90761668727083\n",
      "    log_marginal   : 1781.6339272553066\n",
      "    val_loss       : -1780.5936787923176\n",
      "    val_ess        : 26.9232120513916\n",
      "    val_log_marginal: 1780.922098795573\n",
      "Train Epoch: 884 [0/54000 (0%)] Loss: -1785.725342\n",
      "Train Epoch: 884 [11264/54000 (21%)] Loss: -1780.400269\n",
      "Train Epoch: 884 [22528/54000 (42%)] Loss: -1781.550171\n",
      "Train Epoch: 884 [33792/54000 (63%)] Loss: -1777.208252\n",
      "Train Epoch: 884 [45056/54000 (83%)] Loss: -1781.367920\n",
      "    epoch          : 884\n",
      "    loss           : -1781.7591921248527\n",
      "    ess            : 27.070964075484365\n",
      "    log_marginal   : 1782.0740483122052\n",
      "    val_loss       : -1781.0290222167969\n",
      "    val_ess        : 26.989169597625732\n",
      "    val_log_marginal: 1781.3510131835938\n",
      "Train Epoch: 885 [0/54000 (0%)] Loss: -1782.450195\n",
      "Train Epoch: 885 [11264/54000 (21%)] Loss: -1786.903564\n",
      "Train Epoch: 885 [22528/54000 (42%)] Loss: -1777.958740\n",
      "Train Epoch: 885 [33792/54000 (63%)] Loss: -1767.992798\n",
      "Train Epoch: 885 [45056/54000 (83%)] Loss: -1743.353271\n",
      "    epoch          : 885\n",
      "    loss           : -1768.1410741266216\n",
      "    ess            : 26.849189920245475\n",
      "    log_marginal   : 1768.4610756928066\n",
      "    val_loss       : -1768.05908203125\n",
      "    val_ess        : 26.605672041575115\n",
      "    val_log_marginal: 1768.4009806315105\n",
      "Train Epoch: 886 [0/54000 (0%)] Loss: -1759.729614\n",
      "Train Epoch: 886 [11264/54000 (21%)] Loss: -1771.577393\n",
      "Train Epoch: 886 [22528/54000 (42%)] Loss: -1763.611328\n",
      "Train Epoch: 886 [33792/54000 (63%)] Loss: -1761.283081\n",
      "Train Epoch: 886 [45056/54000 (83%)] Loss: -1766.348877\n",
      "    epoch          : 886\n",
      "    loss           : -1765.1128747328273\n",
      "    ess            : 27.247853441058464\n",
      "    log_marginal   : 1765.4105374318249\n",
      "    val_loss       : -1774.100606282552\n",
      "    val_ess        : 27.04411204655965\n",
      "    val_log_marginal: 1774.4169921875\n",
      "Train Epoch: 887 [0/54000 (0%)] Loss: -1773.456299\n",
      "Train Epoch: 887 [11264/54000 (21%)] Loss: -1779.012207\n",
      "Train Epoch: 887 [22528/54000 (42%)] Loss: -1773.082275\n",
      "Train Epoch: 887 [33792/54000 (63%)] Loss: -1777.504395\n",
      "Train Epoch: 887 [45056/54000 (83%)] Loss: -1776.529541\n",
      "    epoch          : 887\n",
      "    loss           : -1774.2909614994842\n",
      "    ess            : 27.3904213095611\n",
      "    log_marginal   : 1774.581365621315\n",
      "    val_loss       : -1777.8414815266926\n",
      "    val_ess        : 27.284276326497395\n",
      "    val_log_marginal: 1778.1368713378906\n",
      "Train Epoch: 888 [0/54000 (0%)] Loss: -1779.088013\n",
      "Train Epoch: 888 [11264/54000 (21%)] Loss: -1776.578857\n",
      "Train Epoch: 888 [22528/54000 (42%)] Loss: -1779.945312\n",
      "Train Epoch: 888 [33792/54000 (63%)] Loss: -1776.973877\n",
      "Train Epoch: 888 [45056/54000 (83%)] Loss: -1778.853516\n",
      "    epoch          : 888\n",
      "    loss           : -1777.4018278301887\n",
      "    ess            : 27.125165507478535\n",
      "    log_marginal   : 1777.711952065522\n",
      "    val_loss       : -1779.2650655110676\n",
      "    val_ess        : 26.867352326711018\n",
      "    val_log_marginal: 1779.6054280598958\n",
      "Train Epoch: 889 [0/54000 (0%)] Loss: -1781.449219\n",
      "Train Epoch: 889 [11264/54000 (21%)] Loss: -1782.837402\n",
      "Train Epoch: 889 [22528/54000 (42%)] Loss: -1781.598877\n",
      "Train Epoch: 889 [33792/54000 (63%)] Loss: -1775.387939\n",
      "Train Epoch: 889 [45056/54000 (83%)] Loss: -1773.730225\n",
      "    epoch          : 889\n",
      "    loss           : -1779.047755979142\n",
      "    ess            : 26.896763009845085\n",
      "    log_marginal   : 1779.377971145342\n",
      "    val_loss       : -1780.5291442871094\n",
      "    val_ess        : 26.759369532267254\n",
      "    val_log_marginal: 1780.8623352050781\n",
      "Train Epoch: 890 [0/54000 (0%)] Loss: -1778.790283\n",
      "Train Epoch: 890 [11264/54000 (21%)] Loss: -1778.203613\n",
      "Train Epoch: 890 [22528/54000 (42%)] Loss: -1783.111572\n",
      "Train Epoch: 890 [33792/54000 (63%)] Loss: -1778.835815\n",
      "Train Epoch: 890 [45056/54000 (83%)] Loss: -1782.001465\n",
      "    epoch          : 890\n",
      "    loss           : -1780.1655434662441\n",
      "    ess            : 27.039711106498288\n",
      "    log_marginal   : 1780.4839673312206\n",
      "    val_loss       : -1781.0584716796875\n",
      "    val_ess        : 26.87447230021159\n",
      "    val_log_marginal: 1781.3670349121094\n",
      "Train Epoch: 891 [0/54000 (0%)] Loss: -1777.160522\n",
      "Train Epoch: 891 [11264/54000 (21%)] Loss: -1788.152588\n",
      "Train Epoch: 891 [22528/54000 (42%)] Loss: -1780.526611\n",
      "Train Epoch: 891 [33792/54000 (63%)] Loss: -1776.164429\n",
      "Train Epoch: 891 [45056/54000 (83%)] Loss: -1779.737305\n",
      "    epoch          : 891\n",
      "    loss           : -1780.8783189305718\n",
      "    ess            : 27.0190313267258\n",
      "    log_marginal   : 1781.199256753022\n",
      "    val_loss       : -1780.7527567545574\n",
      "    val_ess        : 26.956805388132732\n",
      "    val_log_marginal: 1781.0674743652344\n",
      "Train Epoch: 892 [0/54000 (0%)] Loss: -1784.199097\n",
      "Train Epoch: 892 [11264/54000 (21%)] Loss: -1779.206543\n",
      "Train Epoch: 892 [22528/54000 (42%)] Loss: -1784.285034\n",
      "Train Epoch: 892 [33792/54000 (63%)] Loss: -1774.937744\n",
      "Train Epoch: 892 [45056/54000 (83%)] Loss: -1762.611816\n",
      "    epoch          : 892\n",
      "    loss           : -1775.114704635908\n",
      "    ess            : 26.906803275054354\n",
      "    log_marginal   : 1775.437793659714\n",
      "    val_loss       : -1762.7181193033855\n",
      "    val_ess        : 26.974181811014812\n",
      "    val_log_marginal: 1763.0285746256511\n",
      "Train Epoch: 893 [0/54000 (0%)] Loss: -1762.207275\n",
      "Train Epoch: 893 [11264/54000 (21%)] Loss: -1757.234863\n",
      "Train Epoch: 893 [22528/54000 (42%)] Loss: -1752.275635\n",
      "Train Epoch: 893 [33792/54000 (63%)] Loss: -1743.686523\n",
      "Train Epoch: 893 [45056/54000 (83%)] Loss: -1751.366943\n",
      "    epoch          : 893\n",
      "    loss           : -1752.6253996075325\n",
      "    ess            : 26.908430531339825\n",
      "    log_marginal   : 1752.9408857237618\n",
      "    val_loss       : -1764.7450561523438\n",
      "    val_ess        : 27.3010466893514\n",
      "    val_log_marginal: 1765.0358276367188\n",
      "Train Epoch: 894 [0/54000 (0%)] Loss: -1766.010742\n",
      "Train Epoch: 894 [11264/54000 (21%)] Loss: -1763.068726\n",
      "Train Epoch: 894 [22528/54000 (42%)] Loss: -1763.760132\n",
      "Train Epoch: 894 [33792/54000 (63%)] Loss: -1767.007812\n",
      "Train Epoch: 894 [45056/54000 (83%)] Loss: -1770.002686\n",
      "    epoch          : 894\n",
      "    loss           : -1767.5025047446197\n",
      "    ess            : 27.624067702383364\n",
      "    log_marginal   : 1767.7747560896964\n",
      "    val_loss       : -1771.7561543782551\n",
      "    val_ess        : 27.08999840418498\n",
      "    val_log_marginal: 1772.0608317057292\n",
      "Train Epoch: 895 [0/54000 (0%)] Loss: -1773.762939\n",
      "Train Epoch: 895 [11264/54000 (21%)] Loss: -1768.470215\n",
      "Train Epoch: 895 [22528/54000 (42%)] Loss: -1777.993530\n",
      "Train Epoch: 895 [33792/54000 (63%)] Loss: -1770.498413\n",
      "Train Epoch: 895 [45056/54000 (83%)] Loss: -1768.016113\n",
      "    epoch          : 895\n",
      "    loss           : -1772.7681712024616\n",
      "    ess            : 27.06465240694442\n",
      "    log_marginal   : 1773.0745722932636\n",
      "    val_loss       : -1775.9218851725261\n",
      "    val_ess        : 26.937709013621014\n",
      "    val_log_marginal: 1776.2293497721355\n",
      "Train Epoch: 896 [0/54000 (0%)] Loss: -1773.158325\n",
      "Train Epoch: 896 [11264/54000 (21%)] Loss: -1778.639404\n",
      "Train Epoch: 896 [22528/54000 (42%)] Loss: -1774.822266\n",
      "Train Epoch: 896 [33792/54000 (63%)] Loss: -1768.499512\n",
      "Train Epoch: 896 [45056/54000 (83%)] Loss: -1776.123291\n",
      "    epoch          : 896\n",
      "    loss           : -1775.2444170106132\n",
      "    ess            : 26.965657306167316\n",
      "    log_marginal   : 1775.5632543024028\n",
      "    val_loss       : -1777.3780924479167\n",
      "    val_ess        : 26.879031817118328\n",
      "    val_log_marginal: 1777.6985677083333\n",
      "Train Epoch: 897 [0/54000 (0%)] Loss: -1775.647095\n",
      "Train Epoch: 897 [11264/54000 (21%)] Loss: -1778.497559\n",
      "Train Epoch: 897 [22528/54000 (42%)] Loss: -1779.794434\n",
      "Train Epoch: 897 [33792/54000 (63%)] Loss: -1775.939087\n",
      "Train Epoch: 897 [45056/54000 (83%)] Loss: -1775.817383\n",
      "    epoch          : 897\n",
      "    loss           : -1776.8049431566922\n",
      "    ess            : 26.949619149262052\n",
      "    log_marginal   : 1777.1277120338295\n",
      "    val_loss       : -1778.2546081542969\n",
      "    val_ess        : 26.890456358591717\n",
      "    val_log_marginal: 1778.5718892415364\n",
      "Train Epoch: 898 [0/54000 (0%)] Loss: -1781.088379\n",
      "Train Epoch: 898 [11264/54000 (21%)] Loss: -1779.514160\n",
      "Train Epoch: 898 [22528/54000 (42%)] Loss: -1773.766357\n",
      "Train Epoch: 898 [33792/54000 (63%)] Loss: -1770.732056\n",
      "Train Epoch: 898 [45056/54000 (83%)] Loss: -1772.187012\n",
      "    epoch          : 898\n",
      "    loss           : -1778.1168961434994\n",
      "    ess            : 26.90224508969289\n",
      "    log_marginal   : 1778.4403076171875\n",
      "    val_loss       : -1779.1321818033855\n",
      "    val_ess        : 26.90049393971761\n",
      "    val_log_marginal: 1779.455830891927\n",
      "Train Epoch: 899 [0/54000 (0%)] Loss: -1782.047485\n",
      "Train Epoch: 899 [11264/54000 (21%)] Loss: -1781.245972\n",
      "Train Epoch: 899 [22528/54000 (42%)] Loss: -1779.882324\n",
      "Train Epoch: 899 [33792/54000 (63%)] Loss: -1780.333252\n",
      "Train Epoch: 899 [45056/54000 (83%)] Loss: -1779.350830\n",
      "    epoch          : 899\n",
      "    loss           : -1779.0959656913326\n",
      "    ess            : 26.971282149260897\n",
      "    log_marginal   : 1779.4175461103332\n",
      "    val_loss       : -1780.0710144042969\n",
      "    val_ess        : 26.880942980448406\n",
      "    val_log_marginal: 1780.4034525553386\n",
      "Train Epoch: 900 [0/54000 (0%)] Loss: -1779.304932\n",
      "Train Epoch: 900 [11264/54000 (21%)] Loss: -1781.038330\n",
      "Train Epoch: 900 [22528/54000 (42%)] Loss: -1780.714478\n",
      "Train Epoch: 900 [33792/54000 (63%)] Loss: -1780.435547\n",
      "Train Epoch: 900 [45056/54000 (83%)] Loss: -1774.518799\n",
      "    epoch          : 900\n",
      "    loss           : -1780.0223066221993\n",
      "    ess            : 26.929363088787728\n",
      "    log_marginal   : 1780.3502323942364\n",
      "    val_loss       : -1780.6860656738281\n",
      "    val_ess        : 27.10837475458781\n",
      "    val_log_marginal: 1780.998291015625\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [0/54000 (0%)] Loss: -1781.156982\n",
      "Train Epoch: 901 [11264/54000 (21%)] Loss: -1777.640625\n",
      "Train Epoch: 901 [22528/54000 (42%)] Loss: -1778.424927\n",
      "Train Epoch: 901 [33792/54000 (63%)] Loss: -1784.768066\n",
      "Train Epoch: 901 [45056/54000 (83%)] Loss: -1787.608032\n",
      "    epoch          : 901\n",
      "    loss           : -1780.9622572413032\n",
      "    ess            : 27.011657948763865\n",
      "    log_marginal   : 1781.2861351157135\n",
      "    val_loss       : -1781.4082336425781\n",
      "    val_ess        : 26.904046535491943\n",
      "    val_log_marginal: 1781.7342732747395\n",
      "Train Epoch: 902 [0/54000 (0%)] Loss: -1787.366089\n",
      "Train Epoch: 902 [11264/54000 (21%)] Loss: -1782.741211\n",
      "Train Epoch: 902 [22528/54000 (42%)] Loss: -1783.347778\n",
      "Train Epoch: 902 [33792/54000 (63%)] Loss: -1775.145996\n",
      "Train Epoch: 902 [45056/54000 (83%)] Loss: -1752.200684\n",
      "    epoch          : 902\n",
      "    loss           : -1774.8943550541717\n",
      "    ess            : 26.902918311784852\n",
      "    log_marginal   : 1775.2189400151092\n",
      "    val_loss       : -1775.0915934244792\n",
      "    val_ess        : 27.014285882314045\n",
      "    val_log_marginal: 1775.4105834960938\n",
      "Train Epoch: 903 [0/54000 (0%)] Loss: -1773.041504\n",
      "Train Epoch: 903 [11264/54000 (21%)] Loss: -1775.650146\n",
      "Train Epoch: 903 [22528/54000 (42%)] Loss: -1777.999023\n",
      "Train Epoch: 903 [33792/54000 (63%)] Loss: -1775.415894\n",
      "Train Epoch: 903 [45056/54000 (83%)] Loss: -1778.323486\n",
      "    epoch          : 903\n",
      "    loss           : -1774.2562451632518\n",
      "    ess            : 27.143504988472415\n",
      "    log_marginal   : 1774.561531498747\n",
      "    val_loss       : -1779.8324076334636\n",
      "    val_ess        : 26.891072750091553\n",
      "    val_log_marginal: 1780.147196451823\n",
      "Train Epoch: 904 [0/54000 (0%)] Loss: -1780.570312\n",
      "Train Epoch: 904 [11264/54000 (21%)] Loss: -1783.193726\n",
      "Train Epoch: 904 [22528/54000 (42%)] Loss: -1775.403809\n",
      "Train Epoch: 904 [33792/54000 (63%)] Loss: -1776.487305\n",
      "Train Epoch: 904 [45056/54000 (83%)] Loss: -1776.073975\n",
      "    epoch          : 904\n",
      "    loss           : -1779.1277396723908\n",
      "    ess            : 27.176054072829913\n",
      "    log_marginal   : 1779.4369230450325\n",
      "    val_loss       : -1780.8720601399739\n",
      "    val_ess        : 26.920754273732502\n",
      "    val_log_marginal: 1781.2005411783855\n",
      "Train Epoch: 905 [0/54000 (0%)] Loss: -1779.588379\n",
      "Train Epoch: 905 [11264/54000 (21%)] Loss: -1786.435303\n",
      "Train Epoch: 905 [22528/54000 (42%)] Loss: -1779.943604\n",
      "Train Epoch: 905 [33792/54000 (63%)] Loss: -1782.694702\n",
      "Train Epoch: 905 [45056/54000 (83%)] Loss: -1786.190186\n",
      "    epoch          : 905\n",
      "    loss           : -1781.1029283055718\n",
      "    ess            : 27.02655065284585\n",
      "    log_marginal   : 1781.4211253040241\n",
      "    val_loss       : -1782.3129984537761\n",
      "    val_ess        : 26.950637499491375\n",
      "    val_log_marginal: 1782.6221618652344\n",
      "Train Epoch: 906 [0/54000 (0%)] Loss: -1782.879761\n",
      "Train Epoch: 906 [11264/54000 (21%)] Loss: -1782.341064\n",
      "Train Epoch: 906 [22528/54000 (42%)] Loss: -1785.207764\n",
      "Train Epoch: 906 [33792/54000 (63%)] Loss: -1785.210083\n",
      "Train Epoch: 906 [45056/54000 (83%)] Loss: -1777.303955\n",
      "    epoch          : 906\n",
      "    loss           : -1782.1698205336086\n",
      "    ess            : 27.013331845121563\n",
      "    log_marginal   : 1782.4948949274028\n",
      "    val_loss       : -1783.1252034505208\n",
      "    val_ess        : 27.086121877034504\n",
      "    val_log_marginal: 1783.4466959635417\n",
      "Train Epoch: 907 [0/54000 (0%)] Loss: -1783.885010\n",
      "Train Epoch: 907 [11264/54000 (21%)] Loss: -1785.489380\n",
      "Train Epoch: 907 [22528/54000 (42%)] Loss: -1782.018066\n",
      "Train Epoch: 907 [33792/54000 (63%)] Loss: -1776.696045\n",
      "Train Epoch: 907 [45056/54000 (83%)] Loss: -1778.621582\n",
      "    epoch          : 907\n",
      "    loss           : -1779.9093581865418\n",
      "    ess            : 26.95235288368081\n",
      "    log_marginal   : 1780.233390376253\n",
      "    val_loss       : -1756.437479654948\n",
      "    val_ess        : 26.52893892923991\n",
      "    val_log_marginal: 1756.7841491699219\n",
      "Train Epoch: 908 [0/54000 (0%)] Loss: -1760.357422\n",
      "Train Epoch: 908 [11264/54000 (21%)] Loss: -1758.313477\n",
      "Train Epoch: 908 [22528/54000 (42%)] Loss: -1755.437256\n",
      "Train Epoch: 908 [33792/54000 (63%)] Loss: -1764.347656\n",
      "Train Epoch: 908 [45056/54000 (83%)] Loss: -1763.232056\n",
      "    epoch          : 908\n",
      "    loss           : -1756.171283074145\n",
      "    ess            : 26.795785688004404\n",
      "    log_marginal   : 1756.491612848246\n",
      "    val_loss       : -1766.899434407552\n",
      "    val_ess        : 27.686516761779785\n",
      "    val_log_marginal: 1767.1599527994792\n",
      "Train Epoch: 909 [0/54000 (0%)] Loss: -1771.251465\n",
      "Train Epoch: 909 [11264/54000 (21%)] Loss: -1773.505493\n",
      "Train Epoch: 909 [22528/54000 (42%)] Loss: -1775.930054\n",
      "Train Epoch: 909 [33792/54000 (63%)] Loss: -1769.739136\n",
      "Train Epoch: 909 [45056/54000 (83%)] Loss: -1769.128784\n",
      "    epoch          : 909\n",
      "    loss           : -1772.0780662680572\n",
      "    ess            : 27.788012540565347\n",
      "    log_marginal   : 1772.3456927605396\n",
      "    val_loss       : -1774.5949300130208\n",
      "    val_ess        : 27.42162577311198\n",
      "    val_log_marginal: 1774.8804423014324\n",
      "Train Epoch: 910 [0/54000 (0%)] Loss: -1777.430786\n",
      "Train Epoch: 910 [11264/54000 (21%)] Loss: -1781.106934\n",
      "Train Epoch: 910 [22528/54000 (42%)] Loss: -1775.219604\n",
      "Train Epoch: 910 [33792/54000 (63%)] Loss: -1781.584961\n",
      "Train Epoch: 910 [45056/54000 (83%)] Loss: -1777.291504\n",
      "    epoch          : 910\n",
      "    loss           : -1776.8608214180424\n",
      "    ess            : 27.117516427669884\n",
      "    log_marginal   : 1777.1758215562352\n",
      "    val_loss       : -1778.0460510253906\n",
      "    val_ess        : 26.86440658569336\n",
      "    val_log_marginal: 1778.3817647298176\n",
      "Train Epoch: 911 [0/54000 (0%)] Loss: -1778.745239\n",
      "Train Epoch: 911 [11264/54000 (21%)] Loss: -1779.960327\n",
      "Train Epoch: 911 [22528/54000 (42%)] Loss: -1778.219482\n",
      "Train Epoch: 911 [33792/54000 (63%)] Loss: -1776.857910\n",
      "Train Epoch: 911 [45056/54000 (83%)] Loss: -1776.622803\n",
      "    epoch          : 911\n",
      "    loss           : -1778.9597720739976\n",
      "    ess            : 27.009632650411355\n",
      "    log_marginal   : 1779.2765122899468\n",
      "    val_loss       : -1779.8164876302083\n",
      "    val_ess        : 26.836928526560467\n",
      "    val_log_marginal: 1780.1426696777344\n",
      "Train Epoch: 912 [0/54000 (0%)] Loss: -1779.206055\n",
      "Train Epoch: 912 [11264/54000 (21%)] Loss: -1781.331177\n",
      "Train Epoch: 912 [22528/54000 (42%)] Loss: -1786.305542\n",
      "Train Epoch: 912 [33792/54000 (63%)] Loss: -1780.997437\n",
      "Train Epoch: 912 [45056/54000 (83%)] Loss: -1784.164307\n",
      "    epoch          : 912\n",
      "    loss           : -1780.3746107569282\n",
      "    ess            : 27.01375371105266\n",
      "    log_marginal   : 1780.690975549086\n",
      "    val_loss       : -1780.9593709309895\n",
      "    val_ess        : 26.957921028137207\n",
      "    val_log_marginal: 1781.2666422526042\n",
      "Train Epoch: 913 [0/54000 (0%)] Loss: -1783.885742\n",
      "Train Epoch: 913 [11264/54000 (21%)] Loss: -1779.813110\n",
      "Train Epoch: 913 [22528/54000 (42%)] Loss: -1784.484741\n",
      "Train Epoch: 913 [33792/54000 (63%)] Loss: -1773.804443\n",
      "Train Epoch: 913 [45056/54000 (83%)] Loss: -1779.630981\n",
      "    epoch          : 913\n",
      "    loss           : -1781.4571533203125\n",
      "    ess            : 26.983078218855947\n",
      "    log_marginal   : 1781.7793233619545\n",
      "    val_loss       : -1781.9465738932292\n",
      "    val_ess        : 26.96558666229248\n",
      "    val_log_marginal: 1782.276631673177\n",
      "Train Epoch: 914 [0/54000 (0%)] Loss: -1785.664062\n",
      "Train Epoch: 914 [11264/54000 (21%)] Loss: -1777.826904\n",
      "Train Epoch: 914 [22528/54000 (42%)] Loss: -1787.889404\n",
      "Train Epoch: 914 [33792/54000 (63%)] Loss: -1782.490723\n",
      "Train Epoch: 914 [45056/54000 (83%)] Loss: -1782.664185\n",
      "    epoch          : 914\n",
      "    loss           : -1782.3830209408166\n",
      "    ess            : 27.020989813894595\n",
      "    log_marginal   : 1782.7038182672466\n",
      "    val_loss       : -1782.8854268391926\n",
      "    val_ess        : 27.019450187683105\n",
      "    val_log_marginal: 1783.2135111490886\n",
      "Train Epoch: 915 [0/54000 (0%)] Loss: -1783.560303\n",
      "Train Epoch: 915 [11264/54000 (21%)] Loss: -1779.924927\n",
      "Train Epoch: 915 [22528/54000 (42%)] Loss: -1784.226318\n",
      "Train Epoch: 915 [33792/54000 (63%)] Loss: -1774.856689\n",
      "Train Epoch: 915 [45056/54000 (83%)] Loss: -1785.289917\n",
      "    epoch          : 915\n",
      "    loss           : -1783.130710817733\n",
      "    ess            : 26.965012406403165\n",
      "    log_marginal   : 1783.4586607735112\n",
      "    val_loss       : -1783.164815266927\n",
      "    val_ess        : 26.90746275583903\n",
      "    val_log_marginal: 1783.4916585286458\n",
      "Train Epoch: 916 [0/54000 (0%)] Loss: -1788.918701\n",
      "Train Epoch: 916 [11264/54000 (21%)] Loss: -1783.702881\n",
      "Train Epoch: 916 [22528/54000 (42%)] Loss: -1783.862549\n",
      "Train Epoch: 916 [33792/54000 (63%)] Loss: -1779.050659\n",
      "Train Epoch: 916 [45056/54000 (83%)] Loss: -1779.207031\n",
      "    epoch          : 916\n",
      "    loss           : -1781.051737083579\n",
      "    ess            : 26.886133715791523\n",
      "    log_marginal   : 1781.3777707657723\n",
      "    val_loss       : -1772.1183980305989\n",
      "    val_ess        : 26.908443768819172\n",
      "    val_log_marginal: 1772.4499918619792\n",
      "Train Epoch: 917 [0/54000 (0%)] Loss: -1770.632202\n",
      "Train Epoch: 917 [11264/54000 (21%)] Loss: -1766.041504\n",
      "Train Epoch: 917 [22528/54000 (42%)] Loss: -1752.125977\n",
      "Train Epoch: 917 [33792/54000 (63%)] Loss: -1758.548828\n",
      "Train Epoch: 917 [45056/54000 (83%)] Loss: -1749.570068\n",
      "    epoch          : 917\n",
      "    loss           : -1760.0897792600235\n",
      "    ess            : 26.76829071764676\n",
      "    log_marginal   : 1760.4181967681309\n",
      "    val_loss       : -1765.4447123209636\n",
      "    val_ess        : 27.02464993794759\n",
      "    val_log_marginal: 1765.7483927408855\n",
      "Train Epoch: 918 [0/54000 (0%)] Loss: -1769.260498\n",
      "Train Epoch: 918 [11264/54000 (21%)] Loss: -1770.718262\n",
      "Train Epoch: 918 [22528/54000 (42%)] Loss: -1773.607666\n",
      "Train Epoch: 918 [33792/54000 (63%)] Loss: -1777.976196\n",
      "Train Epoch: 918 [45056/54000 (83%)] Loss: -1770.460205\n",
      "    epoch          : 918\n",
      "    loss           : -1772.0833279591686\n",
      "    ess            : 27.40591407272051\n",
      "    log_marginal   : 1772.374478322155\n",
      "    val_loss       : -1773.5655212402344\n",
      "    val_ess        : 27.292266209920246\n",
      "    val_log_marginal: 1773.8646138509114\n",
      "Train Epoch: 919 [0/54000 (0%)] Loss: -1777.216309\n",
      "Train Epoch: 919 [11264/54000 (21%)] Loss: -1777.193970\n",
      "Train Epoch: 919 [22528/54000 (42%)] Loss: -1776.938721\n",
      "Train Epoch: 919 [33792/54000 (63%)] Loss: -1776.293945\n",
      "Train Epoch: 919 [45056/54000 (83%)] Loss: -1777.367920\n",
      "    epoch          : 919\n",
      "    loss           : -1776.3867705723026\n",
      "    ess            : 27.170270146064038\n",
      "    log_marginal   : 1776.6942668410968\n",
      "    val_loss       : -1777.5645650227864\n",
      "    val_ess        : 27.14214547475179\n",
      "    val_log_marginal: 1777.8621520996094\n",
      "Train Epoch: 920 [0/54000 (0%)] Loss: -1777.472900\n",
      "Train Epoch: 920 [11264/54000 (21%)] Loss: -1781.691162\n",
      "Train Epoch: 920 [22528/54000 (42%)] Loss: -1778.653198\n",
      "Train Epoch: 920 [33792/54000 (63%)] Loss: -1782.609741\n",
      "Train Epoch: 920 [45056/54000 (83%)] Loss: -1778.047607\n",
      "    epoch          : 920\n",
      "    loss           : -1778.5618113391804\n",
      "    ess            : 26.955083901027464\n",
      "    log_marginal   : 1778.8861544627064\n",
      "    val_loss       : -1779.4508158365886\n",
      "    val_ess        : 27.023011525472004\n",
      "    val_log_marginal: 1779.771952311198\n",
      "Train Epoch: 921 [0/54000 (0%)] Loss: -1777.474854\n",
      "Train Epoch: 921 [11264/54000 (21%)] Loss: -1779.331543\n",
      "Train Epoch: 921 [22528/54000 (42%)] Loss: -1783.877441\n",
      "Train Epoch: 921 [33792/54000 (63%)] Loss: -1782.972778\n",
      "Train Epoch: 921 [45056/54000 (83%)] Loss: -1781.629883\n",
      "    epoch          : 921\n",
      "    loss           : -1779.9422883807488\n",
      "    ess            : 26.939053103608906\n",
      "    log_marginal   : 1780.2633966409935\n",
      "    val_loss       : -1780.1593017578125\n",
      "    val_ess        : 26.888426780700684\n",
      "    val_log_marginal: 1780.4807535807292\n",
      "Train Epoch: 922 [0/54000 (0%)] Loss: -1776.920166\n",
      "Train Epoch: 922 [11264/54000 (21%)] Loss: -1784.135010\n",
      "Train Epoch: 922 [22528/54000 (42%)] Loss: -1780.318115\n",
      "Train Epoch: 922 [33792/54000 (63%)] Loss: -1783.586914\n",
      "Train Epoch: 922 [45056/54000 (83%)] Loss: -1780.284912\n",
      "    epoch          : 922\n",
      "    loss           : -1780.9424634249706\n",
      "    ess            : 27.061417273755342\n",
      "    log_marginal   : 1781.2613375681751\n",
      "    val_loss       : -1781.1357828776042\n",
      "    val_ess        : 27.03132088979085\n",
      "    val_log_marginal: 1781.4591878255208\n",
      "Train Epoch: 923 [0/54000 (0%)] Loss: -1778.597412\n",
      "Train Epoch: 923 [11264/54000 (21%)] Loss: -1781.089844\n",
      "Train Epoch: 923 [22528/54000 (42%)] Loss: -1783.918945\n",
      "Train Epoch: 923 [33792/54000 (63%)] Loss: -1783.430664\n",
      "Train Epoch: 923 [45056/54000 (83%)] Loss: -1778.387207\n",
      "    epoch          : 923\n",
      "    loss           : -1781.9575840212265\n",
      "    ess            : 27.10226883078521\n",
      "    log_marginal   : 1782.2739764519458\n",
      "    val_loss       : -1781.8699645996094\n",
      "    val_ess        : 27.01468324661255\n",
      "    val_log_marginal: 1782.1947733561199\n",
      "Train Epoch: 924 [0/54000 (0%)] Loss: -1785.663086\n",
      "Train Epoch: 924 [11264/54000 (21%)] Loss: -1785.602539\n",
      "Train Epoch: 924 [22528/54000 (42%)] Loss: -1784.297852\n",
      "Train Epoch: 924 [33792/54000 (63%)] Loss: -1782.226440\n",
      "Train Epoch: 924 [45056/54000 (83%)] Loss: -1772.100342\n",
      "    epoch          : 924\n",
      "    loss           : -1778.3772479363208\n",
      "    ess            : 27.04797771741759\n",
      "    log_marginal   : 1778.6944464917453\n",
      "    val_loss       : -1771.2254638671875\n",
      "    val_ess        : 26.879117329915363\n",
      "    val_log_marginal: 1771.5447998046875\n",
      "Train Epoch: 925 [0/54000 (0%)] Loss: -1774.374756\n",
      "Train Epoch: 925 [11264/54000 (21%)] Loss: -1770.753906\n",
      "Train Epoch: 925 [22528/54000 (42%)] Loss: -1762.927734\n",
      "Train Epoch: 925 [33792/54000 (63%)] Loss: -1752.954224\n",
      "Train Epoch: 925 [45056/54000 (83%)] Loss: -1762.838623\n",
      "    epoch          : 925\n",
      "    loss           : -1763.0028536814564\n",
      "    ess            : 26.924070070374686\n",
      "    log_marginal   : 1763.3193059957252\n",
      "    val_loss       : -1765.1863301595051\n",
      "    val_ess        : 27.176915963490803\n",
      "    val_log_marginal: 1765.4812723795574\n",
      "Train Epoch: 926 [0/54000 (0%)] Loss: -1763.486084\n",
      "Train Epoch: 926 [11264/54000 (21%)] Loss: -1767.055298\n",
      "Train Epoch: 926 [22528/54000 (42%)] Loss: -1769.611694\n",
      "Train Epoch: 926 [33792/54000 (63%)] Loss: -1776.781250\n",
      "Train Epoch: 926 [45056/54000 (83%)] Loss: -1778.845337\n",
      "    epoch          : 926\n",
      "    loss           : -1773.0165359209168\n",
      "    ess            : 27.552058849694593\n",
      "    log_marginal   : 1773.2965905531398\n",
      "    val_loss       : -1774.5167134602864\n",
      "    val_ess        : 27.631329854329426\n",
      "    val_log_marginal: 1774.7995096842449\n",
      "Train Epoch: 927 [0/54000 (0%)] Loss: -1779.734863\n",
      "Train Epoch: 927 [11264/54000 (21%)] Loss: -1777.567261\n",
      "Train Epoch: 927 [22528/54000 (42%)] Loss: -1781.388062\n",
      "Train Epoch: 927 [33792/54000 (63%)] Loss: -1780.356689\n",
      "Train Epoch: 927 [45056/54000 (83%)] Loss: -1781.641846\n",
      "    epoch          : 927\n",
      "    loss           : -1777.8451791439416\n",
      "    ess            : 27.11249265130961\n",
      "    log_marginal   : 1778.153486143868\n",
      "    val_loss       : -1778.154805501302\n",
      "    val_ess        : 27.12581205368042\n",
      "    val_log_marginal: 1778.4573872884114\n",
      "Train Epoch: 928 [0/54000 (0%)] Loss: -1780.953247\n",
      "Train Epoch: 928 [11264/54000 (21%)] Loss: -1782.080322\n",
      "Train Epoch: 928 [22528/54000 (42%)] Loss: -1780.873657\n",
      "Train Epoch: 928 [33792/54000 (63%)] Loss: -1782.303955\n",
      "Train Epoch: 928 [45056/54000 (83%)] Loss: -1776.317383\n",
      "    epoch          : 928\n",
      "    loss           : -1779.9619900685436\n",
      "    ess            : 27.056496134344137\n",
      "    log_marginal   : 1780.2764570128243\n",
      "    val_loss       : -1780.1643473307292\n",
      "    val_ess        : 26.95574680964152\n",
      "    val_log_marginal: 1780.4830322265625\n",
      "Train Epoch: 929 [0/54000 (0%)] Loss: -1783.191284\n",
      "Train Epoch: 929 [11264/54000 (21%)] Loss: -1780.559570\n",
      "Train Epoch: 929 [22528/54000 (42%)] Loss: -1777.890381\n",
      "Train Epoch: 929 [33792/54000 (63%)] Loss: -1784.982056\n",
      "Train Epoch: 929 [45056/54000 (83%)] Loss: -1778.657959\n",
      "    epoch          : 929\n",
      "    loss           : -1781.2537588443397\n",
      "    ess            : 27.008857763038492\n",
      "    log_marginal   : 1781.5699140440743\n",
      "    val_loss       : -1781.259501139323\n",
      "    val_ess        : 26.74220546086629\n",
      "    val_log_marginal: 1781.5953470865886\n",
      "Train Epoch: 930 [0/54000 (0%)] Loss: -1776.964478\n",
      "Train Epoch: 930 [11264/54000 (21%)] Loss: -1786.618896\n",
      "Train Epoch: 930 [22528/54000 (42%)] Loss: -1778.113037\n",
      "Train Epoch: 930 [33792/54000 (63%)] Loss: -1782.195068\n",
      "Train Epoch: 930 [45056/54000 (83%)] Loss: -1779.265259\n",
      "    epoch          : 930\n",
      "    loss           : -1782.236969569944\n",
      "    ess            : 27.034543361303943\n",
      "    log_marginal   : 1782.5563412072524\n",
      "    val_loss       : -1782.3859354654949\n",
      "    val_ess        : 27.381940364837646\n",
      "    val_log_marginal: 1782.6856282552083\n",
      "Train Epoch: 931 [0/54000 (0%)] Loss: -1782.735107\n",
      "Train Epoch: 931 [11264/54000 (21%)] Loss: -1780.032593\n",
      "Train Epoch: 931 [22528/54000 (42%)] Loss: -1784.652100\n",
      "Train Epoch: 931 [33792/54000 (63%)] Loss: -1779.846436\n",
      "Train Epoch: 931 [45056/54000 (83%)] Loss: -1781.712524\n",
      "    epoch          : 931\n",
      "    loss           : -1783.1128781876473\n",
      "    ess            : 27.03271430393435\n",
      "    log_marginal   : 1783.4340935473172\n",
      "    val_loss       : -1782.8702494303386\n",
      "    val_ess        : 27.11918354034424\n",
      "    val_log_marginal: 1783.1846211751301\n",
      "Train Epoch: 932 [0/54000 (0%)] Loss: -1783.536499\n",
      "Train Epoch: 932 [11264/54000 (21%)] Loss: -1786.459473\n",
      "Train Epoch: 932 [22528/54000 (42%)] Loss: -1778.526367\n",
      "Train Epoch: 932 [33792/54000 (63%)] Loss: -1781.837158\n",
      "Train Epoch: 932 [45056/54000 (83%)] Loss: -1783.432129\n",
      "    epoch          : 932\n",
      "    loss           : -1783.7471348024765\n",
      "    ess            : 27.048348390831137\n",
      "    log_marginal   : 1784.0643794221698\n",
      "    val_loss       : -1783.2950642903645\n",
      "    val_ess        : 27.033247311909992\n",
      "    val_log_marginal: 1783.6057027180989\n",
      "Train Epoch: 933 [0/54000 (0%)] Loss: -1781.574097\n",
      "Train Epoch: 933 [11264/54000 (21%)] Loss: -1784.671021\n",
      "Train Epoch: 933 [22528/54000 (42%)] Loss: -1782.318115\n",
      "Train Epoch: 933 [33792/54000 (63%)] Loss: -1754.740601\n",
      "Train Epoch: 933 [45056/54000 (83%)] Loss: -1740.462158\n",
      "    epoch          : 933\n",
      "    loss           : -1764.0048517191185\n",
      "    ess            : 26.849899993752533\n",
      "    log_marginal   : 1764.331956395563\n",
      "    val_loss       : -1750.8582661946614\n",
      "    val_ess        : 26.750760237375896\n",
      "    val_log_marginal: 1751.1801045735676\n",
      "Train Epoch: 934 [0/54000 (0%)] Loss: -1749.541748\n",
      "Train Epoch: 934 [11264/54000 (21%)] Loss: -1767.279297\n",
      "Train Epoch: 934 [22528/54000 (42%)] Loss: -1769.687012\n",
      "Train Epoch: 934 [33792/54000 (63%)] Loss: -1767.833130\n",
      "Train Epoch: 934 [45056/54000 (83%)] Loss: -1775.298462\n",
      "    epoch          : 934\n",
      "    loss           : -1766.8305652546433\n",
      "    ess            : 27.351275048165952\n",
      "    log_marginal   : 1767.1251600733344\n",
      "    val_loss       : -1768.8180643717449\n",
      "    val_ess        : 27.938294887542725\n",
      "    val_log_marginal: 1769.0796712239583\n",
      "Train Epoch: 935 [0/54000 (0%)] Loss: -1779.382446\n",
      "Train Epoch: 935 [11264/54000 (21%)] Loss: -1779.062866\n",
      "Train Epoch: 935 [22528/54000 (42%)] Loss: -1775.779541\n",
      "Train Epoch: 935 [33792/54000 (63%)] Loss: -1776.555786\n",
      "Train Epoch: 935 [45056/54000 (83%)] Loss: -1774.780029\n",
      "    epoch          : 935\n",
      "    loss           : -1775.4858824531987\n",
      "    ess            : 27.398929811873526\n",
      "    log_marginal   : 1775.7763994324882\n",
      "    val_loss       : -1774.9067789713542\n",
      "    val_ess        : 27.140168984731037\n",
      "    val_log_marginal: 1775.2191772460938\n",
      "Train Epoch: 936 [0/54000 (0%)] Loss: -1777.981445\n",
      "Train Epoch: 936 [11264/54000 (21%)] Loss: -1777.735962\n",
      "Train Epoch: 936 [22528/54000 (42%)] Loss: -1780.940674\n",
      "Train Epoch: 936 [33792/54000 (63%)] Loss: -1776.611572\n",
      "Train Epoch: 936 [45056/54000 (83%)] Loss: -1775.205322\n",
      "    epoch          : 936\n",
      "    loss           : -1778.6283177789653\n",
      "    ess            : 27.07688385585569\n",
      "    log_marginal   : 1778.9417874318249\n",
      "    val_loss       : -1777.7871398925781\n",
      "    val_ess        : 27.10359001159668\n",
      "    val_log_marginal: 1778.1081237792969\n",
      "Train Epoch: 937 [0/54000 (0%)] Loss: -1786.795654\n",
      "Train Epoch: 937 [11264/54000 (21%)] Loss: -1777.566406\n",
      "Train Epoch: 937 [22528/54000 (42%)] Loss: -1781.509033\n",
      "Train Epoch: 937 [33792/54000 (63%)] Loss: -1779.230469\n",
      "Train Epoch: 937 [45056/54000 (83%)] Loss: -1783.287842\n",
      "    epoch          : 937\n",
      "    loss           : -1780.1192039633697\n",
      "    ess            : 26.98176828420387\n",
      "    log_marginal   : 1780.4432672464623\n",
      "    val_loss       : -1779.2943318684895\n",
      "    val_ess        : 26.923364957173664\n",
      "    val_log_marginal: 1779.6277974446614\n",
      "Train Epoch: 938 [0/54000 (0%)] Loss: -1782.200562\n",
      "Train Epoch: 938 [11264/54000 (21%)] Loss: -1777.506592\n",
      "Train Epoch: 938 [22528/54000 (42%)] Loss: -1776.680908\n",
      "Train Epoch: 938 [33792/54000 (63%)] Loss: -1782.192261\n",
      "Train Epoch: 938 [45056/54000 (83%)] Loss: -1780.364258\n",
      "    epoch          : 938\n",
      "    loss           : -1781.2813432801445\n",
      "    ess            : 26.98239628773815\n",
      "    log_marginal   : 1781.6049539817955\n",
      "    val_loss       : -1780.8164367675781\n",
      "    val_ess        : 26.88448445002238\n",
      "    val_log_marginal: 1781.1469319661458\n",
      "Train Epoch: 939 [0/54000 (0%)] Loss: -1784.539917\n",
      "Train Epoch: 939 [11264/54000 (21%)] Loss: -1783.336792\n",
      "Train Epoch: 939 [22528/54000 (42%)] Loss: -1786.362427\n",
      "Train Epoch: 939 [33792/54000 (63%)] Loss: -1782.310181\n",
      "Train Epoch: 939 [45056/54000 (83%)] Loss: -1778.644775\n",
      "    epoch          : 939\n",
      "    loss           : -1782.2267743956368\n",
      "    ess            : 26.989819454696942\n",
      "    log_marginal   : 1782.5553105192364\n",
      "    val_loss       : -1781.5164591471355\n",
      "    val_ess        : 27.14763339360555\n",
      "    val_log_marginal: 1781.8226013183594\n",
      "Train Epoch: 940 [0/54000 (0%)] Loss: -1784.486816\n",
      "Train Epoch: 940 [11264/54000 (21%)] Loss: -1778.634277\n",
      "Train Epoch: 940 [22528/54000 (42%)] Loss: -1785.952637\n",
      "Train Epoch: 940 [33792/54000 (63%)] Loss: -1784.139893\n",
      "Train Epoch: 940 [45056/54000 (83%)] Loss: -1783.918945\n",
      "    epoch          : 940\n",
      "    loss           : -1783.0107963130158\n",
      "    ess            : 27.095651446648365\n",
      "    log_marginal   : 1783.3272428692512\n",
      "    val_loss       : -1782.4145202636719\n",
      "    val_ess        : 26.8161883354187\n",
      "    val_log_marginal: 1782.7413635253906\n",
      "Train Epoch: 941 [0/54000 (0%)] Loss: -1779.163574\n",
      "Train Epoch: 941 [11264/54000 (21%)] Loss: -1783.861206\n",
      "Train Epoch: 941 [22528/54000 (42%)] Loss: -1780.859131\n",
      "Train Epoch: 941 [33792/54000 (63%)] Loss: -1713.136475\n",
      "Train Epoch: 941 [45056/54000 (83%)] Loss: -1749.102783\n",
      "    epoch          : 941\n",
      "    loss           : -1759.7810622881043\n",
      "    ess            : 26.851442768888653\n",
      "    log_marginal   : 1760.1065788988797\n",
      "    val_loss       : -1758.2067260742188\n",
      "    val_ess        : 26.545036951700848\n",
      "    val_log_marginal: 1758.5537719726562\n",
      "Train Epoch: 942 [0/54000 (0%)] Loss: -1755.651245\n",
      "Train Epoch: 942 [11264/54000 (21%)] Loss: -1760.017944\n",
      "Train Epoch: 942 [22528/54000 (42%)] Loss: -1768.418213\n",
      "Train Epoch: 942 [33792/54000 (63%)] Loss: -1764.835449\n",
      "Train Epoch: 942 [45056/54000 (83%)] Loss: -1767.311035\n",
      "    epoch          : 942\n",
      "    loss           : -1761.9007326521964\n",
      "    ess            : 27.27293304227433\n",
      "    log_marginal   : 1762.1977239644752\n",
      "    val_loss       : -1771.3466491699219\n",
      "    val_ess        : 27.34600257873535\n",
      "    val_log_marginal: 1771.6325581868489\n",
      "Train Epoch: 943 [0/54000 (0%)] Loss: -1773.182495\n",
      "Train Epoch: 943 [11264/54000 (21%)] Loss: -1770.594849\n",
      "Train Epoch: 943 [22528/54000 (42%)] Loss: -1770.703369\n",
      "Train Epoch: 943 [33792/54000 (63%)] Loss: -1766.039062\n",
      "Train Epoch: 943 [45056/54000 (83%)] Loss: -1770.491943\n",
      "    epoch          : 943\n",
      "    loss           : -1771.419020166937\n",
      "    ess            : 27.319654230801564\n",
      "    log_marginal   : 1771.7134894604953\n",
      "    val_loss       : -1775.314208984375\n",
      "    val_ess        : 27.04379367828369\n",
      "    val_log_marginal: 1775.6251220703125\n",
      "Train Epoch: 944 [0/54000 (0%)] Loss: -1773.710449\n",
      "Train Epoch: 944 [11264/54000 (21%)] Loss: -1777.777100\n",
      "Train Epoch: 944 [22528/54000 (42%)] Loss: -1777.333862\n",
      "Train Epoch: 944 [33792/54000 (63%)] Loss: -1776.050903\n",
      "Train Epoch: 944 [45056/54000 (83%)] Loss: -1772.610840\n",
      "    epoch          : 944\n",
      "    loss           : -1774.6826885871167\n",
      "    ess            : 27.024382213376605\n",
      "    log_marginal   : 1774.998568552845\n",
      "    val_loss       : -1777.2324625651042\n",
      "    val_ess        : 27.051330248514812\n",
      "    val_log_marginal: 1777.543233235677\n",
      "Train Epoch: 945 [0/54000 (0%)] Loss: -1772.623169\n",
      "Train Epoch: 945 [11264/54000 (21%)] Loss: -1776.582031\n",
      "Train Epoch: 945 [22528/54000 (42%)] Loss: -1775.804688\n",
      "Train Epoch: 945 [33792/54000 (63%)] Loss: -1779.267578\n",
      "Train Epoch: 945 [45056/54000 (83%)] Loss: -1776.069580\n",
      "    epoch          : 945\n",
      "    loss           : -1776.4440572486733\n",
      "    ess            : 26.93648957306484\n",
      "    log_marginal   : 1776.7642004624852\n",
      "    val_loss       : -1778.4338989257812\n",
      "    val_ess        : 26.896541436513264\n",
      "    val_log_marginal: 1778.7557576497395\n",
      "Train Epoch: 946 [0/54000 (0%)] Loss: -1778.275391\n",
      "Train Epoch: 946 [11264/54000 (21%)] Loss: -1775.405518\n",
      "Train Epoch: 946 [22528/54000 (42%)] Loss: -1778.098511\n",
      "Train Epoch: 946 [33792/54000 (63%)] Loss: -1776.675415\n",
      "Train Epoch: 946 [45056/54000 (83%)] Loss: -1780.023315\n",
      "    epoch          : 946\n",
      "    loss           : -1777.9122325969192\n",
      "    ess            : 26.981325545400942\n",
      "    log_marginal   : 1778.2280089180424\n",
      "    val_loss       : -1779.5287068684895\n",
      "    val_ess        : 26.944220066070557\n",
      "    val_log_marginal: 1779.8511657714844\n",
      "Train Epoch: 947 [0/54000 (0%)] Loss: -1777.075073\n",
      "Train Epoch: 947 [11264/54000 (21%)] Loss: -1777.291260\n",
      "Train Epoch: 947 [22528/54000 (42%)] Loss: -1782.703857\n",
      "Train Epoch: 947 [33792/54000 (63%)] Loss: -1777.189209\n",
      "Train Epoch: 947 [45056/54000 (83%)] Loss: -1783.408936\n",
      "    epoch          : 947\n",
      "    loss           : -1778.9474498820755\n",
      "    ess            : 26.94697788526427\n",
      "    log_marginal   : 1779.2689208984375\n",
      "    val_loss       : -1779.8893229166667\n",
      "    val_ess        : 27.034298419952393\n",
      "    val_log_marginal: 1780.2082417805989\n",
      "Train Epoch: 948 [0/54000 (0%)] Loss: -1780.663818\n",
      "Train Epoch: 948 [11264/54000 (21%)] Loss: -1781.407959\n",
      "Train Epoch: 948 [22528/54000 (42%)] Loss: -1776.394775\n",
      "Train Epoch: 948 [33792/54000 (63%)] Loss: -1778.006104\n",
      "Train Epoch: 948 [45056/54000 (83%)] Loss: -1780.255371\n",
      "    epoch          : 948\n",
      "    loss           : -1779.8032330207104\n",
      "    ess            : 26.92494705488097\n",
      "    log_marginal   : 1780.1316321031102\n",
      "    val_loss       : -1780.591776529948\n",
      "    val_ess        : 26.763933658599854\n",
      "    val_log_marginal: 1780.9271138509114\n",
      "Train Epoch: 949 [0/54000 (0%)] Loss: -1780.757568\n",
      "Train Epoch: 949 [11264/54000 (21%)] Loss: -1785.417114\n",
      "Train Epoch: 949 [22528/54000 (42%)] Loss: -1780.906738\n",
      "Train Epoch: 949 [33792/54000 (63%)] Loss: -1778.567139\n",
      "Train Epoch: 949 [45056/54000 (83%)] Loss: -1778.732666\n",
      "    epoch          : 949\n",
      "    loss           : -1780.621478386645\n",
      "    ess            : 27.00151270740437\n",
      "    log_marginal   : 1780.9414004919663\n",
      "    val_loss       : -1781.0193684895833\n",
      "    val_ess        : 26.924089908599854\n",
      "    val_log_marginal: 1781.3373311360676\n",
      "Train Epoch: 950 [0/54000 (0%)] Loss: -1780.945068\n",
      "Train Epoch: 950 [11264/54000 (21%)] Loss: -1782.037231\n",
      "Train Epoch: 950 [22528/54000 (42%)] Loss: -1777.758911\n",
      "Train Epoch: 950 [33792/54000 (63%)] Loss: -1781.582031\n",
      "Train Epoch: 950 [45056/54000 (83%)] Loss: -1781.581055\n",
      "    epoch          : 950\n",
      "    loss           : -1781.389346716539\n",
      "    ess            : 27.050074073503602\n",
      "    log_marginal   : 1781.7079490805572\n",
      "    val_loss       : -1781.8473103841145\n",
      "    val_ess        : 27.014559427897137\n",
      "    val_log_marginal: 1782.1622924804688\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch950.pth ...\n",
      "Train Epoch: 951 [0/54000 (0%)] Loss: -1783.907104\n",
      "Train Epoch: 951 [11264/54000 (21%)] Loss: -1781.470093\n",
      "Train Epoch: 951 [22528/54000 (42%)] Loss: -1784.455566\n",
      "Train Epoch: 951 [33792/54000 (63%)] Loss: -1780.234863\n",
      "Train Epoch: 951 [45056/54000 (83%)] Loss: -1786.562500\n",
      "    epoch          : 951\n",
      "    loss           : -1782.1403486143868\n",
      "    ess            : 27.04624616874839\n",
      "    log_marginal   : 1782.456737590286\n",
      "    val_loss       : -1782.4847106933594\n",
      "    val_ess        : 26.909531434377033\n",
      "    val_log_marginal: 1782.815653483073\n",
      "Train Epoch: 952 [0/54000 (0%)] Loss: -1780.539185\n",
      "Train Epoch: 952 [11264/54000 (21%)] Loss: -1779.644287\n",
      "Train Epoch: 952 [22528/54000 (42%)] Loss: -1783.004150\n",
      "Train Epoch: 952 [33792/54000 (63%)] Loss: -1783.989502\n",
      "Train Epoch: 952 [45056/54000 (83%)] Loss: -1786.528564\n",
      "    epoch          : 952\n",
      "    loss           : -1782.7231456828567\n",
      "    ess            : 27.08937439828549\n",
      "    log_marginal   : 1783.0422248120578\n",
      "    val_loss       : -1783.4109700520833\n",
      "    val_ess        : 26.806989669799805\n",
      "    val_log_marginal: 1783.7388305664062\n",
      "Train Epoch: 953 [0/54000 (0%)] Loss: -1787.515259\n",
      "Train Epoch: 953 [11264/54000 (21%)] Loss: -1784.216309\n",
      "Train Epoch: 953 [22528/54000 (42%)] Loss: -1783.958740\n",
      "Train Epoch: 953 [33792/54000 (63%)] Loss: -1782.939941\n",
      "Train Epoch: 953 [45056/54000 (83%)] Loss: -1776.284424\n",
      "    epoch          : 953\n",
      "    loss           : -1780.1571171598614\n",
      "    ess            : 27.00319614050523\n",
      "    log_marginal   : 1780.4776853165536\n",
      "    val_loss       : -1774.90576171875\n",
      "    val_ess        : 26.780007521311443\n",
      "    val_log_marginal: 1775.233378092448\n",
      "Train Epoch: 954 [0/54000 (0%)] Loss: -1778.555420\n",
      "Train Epoch: 954 [11264/54000 (21%)] Loss: -1774.062256\n",
      "Train Epoch: 954 [22528/54000 (42%)] Loss: -1771.522827\n",
      "Train Epoch: 954 [33792/54000 (63%)] Loss: -1768.370239\n",
      "Train Epoch: 954 [45056/54000 (83%)] Loss: -1763.576416\n",
      "    epoch          : 954\n",
      "    loss           : -1770.922438135687\n",
      "    ess            : 27.035191715888256\n",
      "    log_marginal   : 1771.235761534493\n",
      "    val_loss       : -1776.8721516927083\n",
      "    val_ess        : 27.16573651631673\n",
      "    val_log_marginal: 1777.1704915364583\n",
      "Train Epoch: 955 [0/54000 (0%)] Loss: -1776.395752\n",
      "Train Epoch: 955 [11264/54000 (21%)] Loss: -1780.088379\n",
      "Train Epoch: 955 [22528/54000 (42%)] Loss: -1781.334961\n",
      "Train Epoch: 955 [33792/54000 (63%)] Loss: -1776.253784\n",
      "Train Epoch: 955 [45056/54000 (83%)] Loss: -1779.400757\n",
      "    epoch          : 955\n",
      "    loss           : -1777.9819117132222\n",
      "    ess            : 27.485661344708138\n",
      "    log_marginal   : 1778.2737576466686\n",
      "    val_loss       : -1780.997538248698\n",
      "    val_ess        : 27.07396109898885\n",
      "    val_log_marginal: 1781.3190511067708\n",
      "Train Epoch: 956 [0/54000 (0%)] Loss: -1782.370605\n",
      "Train Epoch: 956 [11264/54000 (21%)] Loss: -1780.680908\n",
      "Train Epoch: 956 [22528/54000 (42%)] Loss: -1780.244873\n",
      "Train Epoch: 956 [33792/54000 (63%)] Loss: -1780.615479\n",
      "Train Epoch: 956 [45056/54000 (83%)] Loss: -1780.812744\n",
      "    epoch          : 956\n",
      "    loss           : -1780.9010101894162\n",
      "    ess            : 27.11529891895798\n",
      "    log_marginal   : 1781.2149335753243\n",
      "    val_loss       : -1782.3679606119792\n",
      "    val_ess        : 27.061354955037434\n",
      "    val_log_marginal: 1782.6806335449219\n",
      "Train Epoch: 957 [0/54000 (0%)] Loss: -1783.739014\n",
      "Train Epoch: 957 [11264/54000 (21%)] Loss: -1782.696655\n",
      "Train Epoch: 957 [22528/54000 (42%)] Loss: -1777.896851\n",
      "Train Epoch: 957 [33792/54000 (63%)] Loss: -1781.555908\n",
      "Train Epoch: 957 [45056/54000 (83%)] Loss: -1779.792969\n",
      "    epoch          : 957\n",
      "    loss           : -1782.1929470997936\n",
      "    ess            : 26.989309814741027\n",
      "    log_marginal   : 1782.517784262603\n",
      "    val_loss       : -1783.4698486328125\n",
      "    val_ess        : 26.837279001871746\n",
      "    val_log_marginal: 1783.7988789876301\n",
      "Train Epoch: 958 [0/54000 (0%)] Loss: -1783.490234\n",
      "Train Epoch: 958 [11264/54000 (21%)] Loss: -1781.851440\n",
      "Train Epoch: 958 [22528/54000 (42%)] Loss: -1782.743164\n",
      "Train Epoch: 958 [33792/54000 (63%)] Loss: -1788.033203\n",
      "Train Epoch: 958 [45056/54000 (83%)] Loss: -1781.417725\n",
      "    epoch          : 958\n",
      "    loss           : -1782.9567767449146\n",
      "    ess            : 27.022456762925636\n",
      "    log_marginal   : 1783.2810484688237\n",
      "    val_loss       : -1783.3285420735676\n",
      "    val_ess        : 27.021421750386555\n",
      "    val_log_marginal: 1783.6531066894531\n",
      "Train Epoch: 959 [0/54000 (0%)] Loss: -1783.019043\n",
      "Train Epoch: 959 [11264/54000 (21%)] Loss: -1786.820312\n",
      "Train Epoch: 959 [22528/54000 (42%)] Loss: -1782.430786\n",
      "Train Epoch: 959 [33792/54000 (63%)] Loss: -1714.772461\n",
      "Train Epoch: 959 [45056/54000 (83%)] Loss: -1746.908569\n",
      "    epoch          : 959\n",
      "    loss           : -1761.5316795493072\n",
      "    ess            : 26.804978082764823\n",
      "    log_marginal   : 1761.8623058391067\n",
      "    val_loss       : -1766.5825602213542\n",
      "    val_ess        : 26.755725224812824\n",
      "    val_log_marginal: 1766.9066569010417\n",
      "Train Epoch: 960 [0/54000 (0%)] Loss: -1764.857788\n",
      "Train Epoch: 960 [11264/54000 (21%)] Loss: -1773.530029\n",
      "Train Epoch: 960 [22528/54000 (42%)] Loss: -1774.808594\n",
      "Train Epoch: 960 [33792/54000 (63%)] Loss: -1767.855957\n",
      "Train Epoch: 960 [45056/54000 (83%)] Loss: -1772.669678\n",
      "    epoch          : 960\n",
      "    loss           : -1768.7986841741597\n",
      "    ess            : 27.36739111846348\n",
      "    log_marginal   : 1769.091482486365\n",
      "    val_loss       : -1776.4651184082031\n",
      "    val_ess        : 27.2542667388916\n",
      "    val_log_marginal: 1776.7657368977864\n",
      "Train Epoch: 961 [0/54000 (0%)] Loss: -1770.840820\n",
      "Train Epoch: 961 [11264/54000 (21%)] Loss: -1777.080933\n",
      "Train Epoch: 961 [22528/54000 (42%)] Loss: -1775.783813\n",
      "Train Epoch: 961 [33792/54000 (63%)] Loss: -1776.907227\n",
      "Train Epoch: 961 [45056/54000 (83%)] Loss: -1772.791992\n",
      "    epoch          : 961\n",
      "    loss           : -1775.3691728699882\n",
      "    ess            : 27.177701896091676\n",
      "    log_marginal   : 1775.6783666070903\n",
      "    val_loss       : -1779.3817850748699\n",
      "    val_ess        : 26.93450180689494\n",
      "    val_log_marginal: 1779.6923828125\n",
      "Train Epoch: 962 [0/54000 (0%)] Loss: -1778.293945\n",
      "Train Epoch: 962 [11264/54000 (21%)] Loss: -1777.508301\n",
      "Train Epoch: 962 [22528/54000 (42%)] Loss: -1777.812134\n",
      "Train Epoch: 962 [33792/54000 (63%)] Loss: -1777.915771\n",
      "Train Epoch: 962 [45056/54000 (83%)] Loss: -1782.426147\n",
      "    epoch          : 962\n",
      "    loss           : -1777.937975613576\n",
      "    ess            : 27.00909706331649\n",
      "    log_marginal   : 1778.2576950361145\n",
      "    val_loss       : -1780.8668721516926\n",
      "    val_ess        : 26.96041202545166\n",
      "    val_log_marginal: 1781.1759541829426\n",
      "Train Epoch: 963 [0/54000 (0%)] Loss: -1778.230957\n",
      "Train Epoch: 963 [11264/54000 (21%)] Loss: -1778.724731\n",
      "Train Epoch: 963 [22528/54000 (42%)] Loss: -1780.914551\n",
      "Train Epoch: 963 [33792/54000 (63%)] Loss: -1780.181152\n",
      "Train Epoch: 963 [45056/54000 (83%)] Loss: -1778.160400\n",
      "    epoch          : 963\n",
      "    loss           : -1779.4323695920548\n",
      "    ess            : 27.010286349170613\n",
      "    log_marginal   : 1779.7503293595223\n",
      "    val_loss       : -1781.7401326497395\n",
      "    val_ess        : 26.990417162577312\n",
      "    val_log_marginal: 1782.06640625\n",
      "Train Epoch: 964 [0/54000 (0%)] Loss: -1780.299927\n",
      "Train Epoch: 964 [11264/54000 (21%)] Loss: -1782.964478\n",
      "Train Epoch: 964 [22528/54000 (42%)] Loss: -1779.002441\n",
      "Train Epoch: 964 [33792/54000 (63%)] Loss: -1776.748535\n",
      "Train Epoch: 964 [45056/54000 (83%)] Loss: -1781.401367\n",
      "    epoch          : 964\n",
      "    loss           : -1780.5603418890034\n",
      "    ess            : 26.935431624358554\n",
      "    log_marginal   : 1780.8823414928509\n",
      "    val_loss       : -1782.2674255371094\n",
      "    val_ess        : 26.906986395517986\n",
      "    val_log_marginal: 1782.5963033040364\n",
      "Train Epoch: 965 [0/54000 (0%)] Loss: -1781.148193\n",
      "Train Epoch: 965 [11264/54000 (21%)] Loss: -1781.712402\n",
      "Train Epoch: 965 [22528/54000 (42%)] Loss: -1781.263184\n",
      "Train Epoch: 965 [33792/54000 (63%)] Loss: -1786.785889\n",
      "Train Epoch: 965 [45056/54000 (83%)] Loss: -1780.873657\n",
      "    epoch          : 965\n",
      "    loss           : -1781.5345113502358\n",
      "    ess            : 26.98060427971606\n",
      "    log_marginal   : 1781.8580402878094\n",
      "    val_loss       : -1783.2070007324219\n",
      "    val_ess        : 26.665217717488606\n",
      "    val_log_marginal: 1783.5503946940105\n",
      "Train Epoch: 966 [0/54000 (0%)] Loss: -1781.538086\n",
      "Train Epoch: 966 [11264/54000 (21%)] Loss: -1780.878784\n",
      "Train Epoch: 966 [22528/54000 (42%)] Loss: -1782.263672\n",
      "Train Epoch: 966 [33792/54000 (63%)] Loss: -1783.481567\n",
      "Train Epoch: 966 [45056/54000 (83%)] Loss: -1778.869385\n",
      "    epoch          : 966\n",
      "    loss           : -1781.214350862323\n",
      "    ess            : 27.045746173498767\n",
      "    log_marginal   : 1781.5342683612175\n",
      "    val_loss       : -1779.7290649414062\n",
      "    val_ess        : 26.894010066986084\n",
      "    val_log_marginal: 1780.0441996256511\n",
      "Train Epoch: 967 [0/54000 (0%)] Loss: -1778.421631\n",
      "Train Epoch: 967 [11264/54000 (21%)] Loss: -1780.340332\n",
      "Train Epoch: 967 [22528/54000 (42%)] Loss: -1773.428955\n",
      "Train Epoch: 967 [33792/54000 (63%)] Loss: -1745.926025\n",
      "Train Epoch: 967 [45056/54000 (83%)] Loss: -1753.199219\n",
      "    epoch          : 967\n",
      "    loss           : -1764.6231735517395\n",
      "    ess            : 26.927921601061552\n",
      "    log_marginal   : 1764.9426108306309\n",
      "    val_loss       : -1761.6863301595051\n",
      "    val_ess        : 26.735956986745197\n",
      "    val_log_marginal: 1762.0044047037761\n",
      "Train Epoch: 968 [0/54000 (0%)] Loss: -1766.801514\n",
      "Train Epoch: 968 [11264/54000 (21%)] Loss: -1771.722290\n",
      "Train Epoch: 968 [22528/54000 (42%)] Loss: -1774.434692\n",
      "Train Epoch: 968 [33792/54000 (63%)] Loss: -1772.864258\n",
      "Train Epoch: 968 [45056/54000 (83%)] Loss: -1775.504028\n",
      "    epoch          : 968\n",
      "    loss           : -1772.0670960624263\n",
      "    ess            : 27.493195047918356\n",
      "    log_marginal   : 1772.3531505656692\n",
      "    val_loss       : -1772.827901204427\n",
      "    val_ess        : 27.541720708211262\n",
      "    val_log_marginal: 1773.1208190917969\n",
      "Train Epoch: 969 [0/54000 (0%)] Loss: -1777.493896\n",
      "Train Epoch: 969 [11264/54000 (21%)] Loss: -1776.480713\n",
      "Train Epoch: 969 [22528/54000 (42%)] Loss: -1780.699707\n",
      "Train Epoch: 969 [33792/54000 (63%)] Loss: -1778.809570\n",
      "Train Epoch: 969 [45056/54000 (83%)] Loss: -1776.029907\n",
      "    epoch          : 969\n",
      "    loss           : -1776.9426165886646\n",
      "    ess            : 27.183065216496306\n",
      "    log_marginal   : 1777.2466246406987\n",
      "    val_loss       : -1778.0205688476562\n",
      "    val_ess        : 27.110035101572674\n",
      "    val_log_marginal: 1778.33349609375\n",
      "Train Epoch: 970 [0/54000 (0%)] Loss: -1783.823975\n",
      "Train Epoch: 970 [11264/54000 (21%)] Loss: -1778.316406\n",
      "Train Epoch: 970 [22528/54000 (42%)] Loss: -1777.065796\n",
      "Train Epoch: 970 [33792/54000 (63%)] Loss: -1781.513916\n",
      "Train Epoch: 970 [45056/54000 (83%)] Loss: -1783.805298\n",
      "    epoch          : 970\n",
      "    loss           : -1779.0513869951355\n",
      "    ess            : 27.002490925339032\n",
      "    log_marginal   : 1779.3713517099056\n",
      "    val_loss       : -1780.2305094401042\n",
      "    val_ess        : 26.889474709828693\n",
      "    val_log_marginal: 1780.5531819661458\n",
      "Train Epoch: 971 [0/54000 (0%)] Loss: -1778.005859\n",
      "Train Epoch: 971 [11264/54000 (21%)] Loss: -1782.485107\n",
      "Train Epoch: 971 [22528/54000 (42%)] Loss: -1782.285400\n",
      "Train Epoch: 971 [33792/54000 (63%)] Loss: -1778.022217\n",
      "Train Epoch: 971 [45056/54000 (83%)] Loss: -1780.062622\n",
      "    epoch          : 971\n",
      "    loss           : -1780.4958484577683\n",
      "    ess            : 27.062160833826606\n",
      "    log_marginal   : 1780.8083277288472\n",
      "    val_loss       : -1781.6078999837239\n",
      "    val_ess        : 26.990855534871418\n",
      "    val_log_marginal: 1781.9313659667969\n",
      "Train Epoch: 972 [0/54000 (0%)] Loss: -1783.853882\n",
      "Train Epoch: 972 [11264/54000 (21%)] Loss: -1783.419922\n",
      "Train Epoch: 972 [22528/54000 (42%)] Loss: -1779.131226\n",
      "Train Epoch: 972 [33792/54000 (63%)] Loss: -1779.150146\n",
      "Train Epoch: 972 [45056/54000 (83%)] Loss: -1785.195679\n",
      "    epoch          : 972\n",
      "    loss           : -1781.374296368293\n",
      "    ess            : 27.008503338076032\n",
      "    log_marginal   : 1781.6945075269016\n",
      "    val_loss       : -1782.2843017578125\n",
      "    val_ess        : 27.048741181691486\n",
      "    val_log_marginal: 1782.6118469238281\n",
      "Train Epoch: 973 [0/54000 (0%)] Loss: -1779.444580\n",
      "Train Epoch: 973 [11264/54000 (21%)] Loss: -1780.389404\n",
      "Train Epoch: 973 [22528/54000 (42%)] Loss: -1785.200439\n",
      "Train Epoch: 973 [33792/54000 (63%)] Loss: -1784.093750\n",
      "Train Epoch: 973 [45056/54000 (83%)] Loss: -1781.584961\n",
      "    epoch          : 973\n",
      "    loss           : -1782.1462033829598\n",
      "    ess            : 26.997065058294332\n",
      "    log_marginal   : 1782.4712455317658\n",
      "    val_loss       : -1782.6421000162761\n",
      "    val_ess        : 26.96542978286743\n",
      "    val_log_marginal: 1782.9696044921875\n",
      "Train Epoch: 974 [0/54000 (0%)] Loss: -1782.601807\n",
      "Train Epoch: 974 [11264/54000 (21%)] Loss: -1781.824707\n",
      "Train Epoch: 974 [22528/54000 (42%)] Loss: -1780.902344\n",
      "Train Epoch: 974 [33792/54000 (63%)] Loss: -1780.245361\n",
      "Train Epoch: 974 [45056/54000 (83%)] Loss: -1786.464844\n",
      "    epoch          : 974\n",
      "    loss           : -1782.8614156471108\n",
      "    ess            : 27.01575419587909\n",
      "    log_marginal   : 1783.1794974848908\n",
      "    val_loss       : -1783.6898905436199\n",
      "    val_ess        : 27.09540383021037\n",
      "    val_log_marginal: 1784.0035298665364\n",
      "Train Epoch: 975 [0/54000 (0%)] Loss: -1777.320679\n",
      "Train Epoch: 975 [11264/54000 (21%)] Loss: -1786.496582\n",
      "Train Epoch: 975 [22528/54000 (42%)] Loss: -1780.666992\n",
      "Train Epoch: 975 [33792/54000 (63%)] Loss: -1786.602051\n",
      "Train Epoch: 975 [45056/54000 (83%)] Loss: -1781.431152\n",
      "    epoch          : 975\n",
      "    loss           : -1782.7965709758255\n",
      "    ess            : 26.967096346729207\n",
      "    log_marginal   : 1783.1237309293927\n",
      "    val_loss       : -1780.4424845377605\n",
      "    val_ess        : 26.74893267949422\n",
      "    val_log_marginal: 1780.7857767740886\n",
      "Train Epoch: 976 [0/54000 (0%)] Loss: -1780.451172\n",
      "Train Epoch: 976 [11264/54000 (21%)] Loss: -1772.543945\n",
      "Train Epoch: 976 [22528/54000 (42%)] Loss: -1767.459961\n",
      "Train Epoch: 976 [33792/54000 (63%)] Loss: -1764.470459\n",
      "Train Epoch: 976 [45056/54000 (83%)] Loss: -1746.259644\n",
      "    epoch          : 976\n",
      "    loss           : -1765.049602004717\n",
      "    ess            : 26.924655104583163\n",
      "    log_marginal   : 1765.3704960661114\n",
      "    val_loss       : -1765.0624389648438\n",
      "    val_ess        : 27.00132926305135\n",
      "    val_log_marginal: 1765.3684794108074\n",
      "Train Epoch: 977 [0/54000 (0%)] Loss: -1761.830933\n",
      "Train Epoch: 977 [11264/54000 (21%)] Loss: -1762.152344\n",
      "Train Epoch: 977 [22528/54000 (42%)] Loss: -1773.016846\n",
      "Train Epoch: 977 [33792/54000 (63%)] Loss: -1771.001221\n",
      "Train Epoch: 977 [45056/54000 (83%)] Loss: -1772.140625\n",
      "    epoch          : 977\n",
      "    loss           : -1770.0238820201946\n",
      "    ess            : 27.485905467339283\n",
      "    log_marginal   : 1770.3084509507664\n",
      "    val_loss       : -1774.8757934570312\n",
      "    val_ess        : 27.41833766301473\n",
      "    val_log_marginal: 1775.1636657714844\n",
      "Train Epoch: 978 [0/54000 (0%)] Loss: -1778.666382\n",
      "Train Epoch: 978 [11264/54000 (21%)] Loss: -1781.396606\n",
      "Train Epoch: 978 [22528/54000 (42%)] Loss: -1778.079346\n",
      "Train Epoch: 978 [33792/54000 (63%)] Loss: -1777.782471\n",
      "Train Epoch: 978 [45056/54000 (83%)] Loss: -1769.302246\n",
      "    epoch          : 978\n",
      "    loss           : -1773.3526726488797\n",
      "    ess            : 27.317486996920604\n",
      "    log_marginal   : 1773.6493265403892\n",
      "    val_loss       : -1739.2078348795574\n",
      "    val_ess        : 26.96624453862508\n",
      "    val_log_marginal: 1739.5151265462239\n",
      "Train Epoch: 979 [0/54000 (0%)] Loss: -1736.481201\n",
      "Train Epoch: 979 [11264/54000 (21%)] Loss: -1764.190063\n",
      "Train Epoch: 979 [22528/54000 (42%)] Loss: -1767.155151\n",
      "Train Epoch: 979 [33792/54000 (63%)] Loss: -1762.866455\n",
      "Train Epoch: 979 [45056/54000 (83%)] Loss: -1765.403564\n",
      "    epoch          : 979\n",
      "    loss           : -1759.3999541660526\n",
      "    ess            : 27.008265711226553\n",
      "    log_marginal   : 1759.7090500165832\n",
      "    val_loss       : -1757.9855651855469\n",
      "    val_ess        : 28.179778734842937\n",
      "    val_log_marginal: 1758.2243041992188\n",
      "Train Epoch: 980 [0/54000 (0%)] Loss: -1771.618896\n",
      "Train Epoch: 980 [11264/54000 (21%)] Loss: -1773.273071\n",
      "Train Epoch: 980 [22528/54000 (42%)] Loss: -1772.805908\n",
      "Train Epoch: 980 [33792/54000 (63%)] Loss: -1774.573730\n",
      "Train Epoch: 980 [45056/54000 (83%)] Loss: -1772.207153\n",
      "    epoch          : 980\n",
      "    loss           : -1771.9455105763561\n",
      "    ess            : 27.52871716697261\n",
      "    log_marginal   : 1772.2263494527565\n",
      "    val_loss       : -1770.0099487304688\n",
      "    val_ess        : 27.436402161916096\n",
      "    val_log_marginal: 1770.2920633951824\n",
      "Train Epoch: 981 [0/54000 (0%)] Loss: -1777.874268\n",
      "Train Epoch: 981 [11264/54000 (21%)] Loss: -1771.626709\n",
      "Train Epoch: 981 [22528/54000 (42%)] Loss: -1778.048340\n",
      "Train Epoch: 981 [33792/54000 (63%)] Loss: -1778.424072\n",
      "Train Epoch: 981 [45056/54000 (83%)] Loss: -1773.026367\n",
      "    epoch          : 981\n",
      "    loss           : -1775.8719897000294\n",
      "    ess            : 27.04266987206801\n",
      "    log_marginal   : 1776.187235130454\n",
      "    val_loss       : -1773.2997639973958\n",
      "    val_ess        : 27.024154663085938\n",
      "    val_log_marginal: 1773.6183776855469\n",
      "Train Epoch: 982 [0/54000 (0%)] Loss: -1778.238037\n",
      "Train Epoch: 982 [11264/54000 (21%)] Loss: -1779.690430\n",
      "Train Epoch: 982 [22528/54000 (42%)] Loss: -1780.418213\n",
      "Train Epoch: 982 [33792/54000 (63%)] Loss: -1776.167969\n",
      "Train Epoch: 982 [45056/54000 (83%)] Loss: -1774.144775\n",
      "    epoch          : 982\n",
      "    loss           : -1777.8196238391804\n",
      "    ess            : 26.971783691982054\n",
      "    log_marginal   : 1778.1378001087116\n",
      "    val_loss       : -1775.5211791992188\n",
      "    val_ess        : 26.81819995244344\n",
      "    val_log_marginal: 1775.8655598958333\n",
      "Train Epoch: 983 [0/54000 (0%)] Loss: -1782.014160\n",
      "Train Epoch: 983 [11264/54000 (21%)] Loss: -1780.643799\n",
      "Train Epoch: 983 [22528/54000 (42%)] Loss: -1781.160522\n",
      "Train Epoch: 983 [33792/54000 (63%)] Loss: -1783.376953\n",
      "Train Epoch: 983 [45056/54000 (83%)] Loss: -1783.880371\n",
      "    epoch          : 983\n",
      "    loss           : -1779.2955529554836\n",
      "    ess            : 26.961198338922465\n",
      "    log_marginal   : 1779.6213367390183\n",
      "    val_loss       : -1777.3120727539062\n",
      "    val_ess        : 26.89376974105835\n",
      "    val_log_marginal: 1777.6479187011719\n",
      "Train Epoch: 984 [0/54000 (0%)] Loss: -1782.521240\n",
      "Train Epoch: 984 [11264/54000 (21%)] Loss: -1783.073486\n",
      "Train Epoch: 984 [22528/54000 (42%)] Loss: -1777.979004\n",
      "Train Epoch: 984 [33792/54000 (63%)] Loss: -1776.292114\n",
      "Train Epoch: 984 [45056/54000 (83%)] Loss: -1781.166504\n",
      "    epoch          : 984\n",
      "    loss           : -1780.3576383770637\n",
      "    ess            : 27.02117336920972\n",
      "    log_marginal   : 1780.6815415868218\n",
      "    val_loss       : -1778.7114562988281\n",
      "    val_ess        : 27.033538182576496\n",
      "    val_log_marginal: 1779.0357055664062\n",
      "Train Epoch: 985 [0/54000 (0%)] Loss: -1778.309814\n",
      "Train Epoch: 985 [11264/54000 (21%)] Loss: -1779.790771\n",
      "Train Epoch: 985 [22528/54000 (42%)] Loss: -1775.484497\n",
      "Train Epoch: 985 [33792/54000 (63%)] Loss: -1782.335449\n",
      "Train Epoch: 985 [45056/54000 (83%)] Loss: -1782.367676\n",
      "    epoch          : 985\n",
      "    loss           : -1781.3133015182782\n",
      "    ess            : 26.96311157154587\n",
      "    log_marginal   : 1781.6381697744694\n",
      "    val_loss       : -1779.9716389973958\n",
      "    val_ess        : 26.99330472946167\n",
      "    val_log_marginal: 1780.2926228841145\n",
      "Train Epoch: 986 [0/54000 (0%)] Loss: -1782.717773\n",
      "Train Epoch: 986 [11264/54000 (21%)] Loss: -1781.538574\n",
      "Train Epoch: 986 [22528/54000 (42%)] Loss: -1786.180542\n",
      "Train Epoch: 986 [33792/54000 (63%)] Loss: -1782.029785\n",
      "Train Epoch: 986 [45056/54000 (83%)] Loss: -1783.822021\n",
      "    epoch          : 986\n",
      "    loss           : -1782.0418252045254\n",
      "    ess            : 27.073349358900536\n",
      "    log_marginal   : 1782.3567781268425\n",
      "    val_loss       : -1780.3264973958333\n",
      "    val_ess        : 26.93522055943807\n",
      "    val_log_marginal: 1780.6519978841145\n",
      "Train Epoch: 987 [0/54000 (0%)] Loss: -1784.076416\n",
      "Train Epoch: 987 [11264/54000 (21%)] Loss: -1776.090088\n",
      "Train Epoch: 987 [22528/54000 (42%)] Loss: -1781.119873\n",
      "Train Epoch: 987 [33792/54000 (63%)] Loss: -1784.226807\n",
      "Train Epoch: 987 [45056/54000 (83%)] Loss: -1781.503662\n",
      "    epoch          : 987\n",
      "    loss           : -1782.7117597471993\n",
      "    ess            : 26.98756043416149\n",
      "    log_marginal   : 1783.0353059588738\n",
      "    val_loss       : -1781.4273783365886\n",
      "    val_ess        : 26.980605761210125\n",
      "    val_log_marginal: 1781.7501729329426\n",
      "Train Epoch: 988 [0/54000 (0%)] Loss: -1787.837891\n",
      "Train Epoch: 988 [11264/54000 (21%)] Loss: -1780.923828\n",
      "Train Epoch: 988 [22528/54000 (42%)] Loss: -1781.608154\n",
      "Train Epoch: 988 [33792/54000 (63%)] Loss: -1779.757324\n",
      "Train Epoch: 988 [45056/54000 (83%)] Loss: -1782.527588\n",
      "    epoch          : 988\n",
      "    loss           : -1781.301293714991\n",
      "    ess            : 26.99715554939126\n",
      "    log_marginal   : 1781.629121600457\n",
      "    val_loss       : -1753.237569173177\n",
      "    val_ess        : 26.78280480702718\n",
      "    val_log_marginal: 1753.5697631835938\n",
      "Train Epoch: 989 [0/54000 (0%)] Loss: -1749.718750\n",
      "Train Epoch: 989 [11264/54000 (21%)] Loss: -1758.238525\n",
      "Train Epoch: 989 [22528/54000 (42%)] Loss: -1769.653809\n",
      "Train Epoch: 989 [33792/54000 (63%)] Loss: -1767.834473\n",
      "Train Epoch: 989 [45056/54000 (83%)] Loss: -1760.939453\n",
      "    epoch          : 989\n",
      "    loss           : -1761.602547123747\n",
      "    ess            : 26.911995311952985\n",
      "    log_marginal   : 1761.9241851230838\n",
      "    val_loss       : -1767.0196634928386\n",
      "    val_ess        : 27.833922545115154\n",
      "    val_log_marginal: 1767.2856343587239\n",
      "Train Epoch: 990 [0/54000 (0%)] Loss: -1771.914551\n",
      "Train Epoch: 990 [11264/54000 (21%)] Loss: -1773.304688\n",
      "Train Epoch: 990 [22528/54000 (42%)] Loss: -1776.998291\n",
      "Train Epoch: 990 [33792/54000 (63%)] Loss: -1775.613403\n",
      "Train Epoch: 990 [45056/54000 (83%)] Loss: -1772.287964\n",
      "    epoch          : 990\n",
      "    loss           : -1774.3180023769162\n",
      "    ess            : 27.665481891272204\n",
      "    log_marginal   : 1774.5986546930278\n",
      "    val_loss       : -1774.8888854980469\n",
      "    val_ess        : 27.27463658650716\n",
      "    val_log_marginal: 1775.2047424316406\n",
      "Train Epoch: 991 [0/54000 (0%)] Loss: -1782.620117\n",
      "Train Epoch: 991 [11264/54000 (21%)] Loss: -1776.273926\n",
      "Train Epoch: 991 [22528/54000 (42%)] Loss: -1782.690430\n",
      "Train Epoch: 991 [33792/54000 (63%)] Loss: -1776.740723\n",
      "Train Epoch: 991 [45056/54000 (83%)] Loss: -1781.881104\n",
      "    epoch          : 991\n",
      "    loss           : -1778.24846490824\n",
      "    ess            : 27.088660654032005\n",
      "    log_marginal   : 1778.5629410653744\n",
      "    val_loss       : -1777.6003926595051\n",
      "    val_ess        : 27.073812166849773\n",
      "    val_log_marginal: 1777.904541015625\n",
      "Train Epoch: 992 [0/54000 (0%)] Loss: -1779.902100\n",
      "Train Epoch: 992 [11264/54000 (21%)] Loss: -1780.207031\n",
      "Train Epoch: 992 [22528/54000 (42%)] Loss: -1775.410034\n",
      "Train Epoch: 992 [33792/54000 (63%)] Loss: -1785.454102\n",
      "Train Epoch: 992 [45056/54000 (83%)] Loss: -1785.370361\n",
      "    epoch          : 992\n",
      "    loss           : -1779.9865123820755\n",
      "    ess            : 27.02109725520296\n",
      "    log_marginal   : 1780.3092455594044\n",
      "    val_loss       : -1779.0607299804688\n",
      "    val_ess        : 27.11100196838379\n",
      "    val_log_marginal: 1779.3693542480469\n",
      "Train Epoch: 993 [0/54000 (0%)] Loss: -1779.766113\n",
      "Train Epoch: 993 [11264/54000 (21%)] Loss: -1778.849243\n",
      "Train Epoch: 993 [22528/54000 (42%)] Loss: -1780.499756\n",
      "Train Epoch: 993 [33792/54000 (63%)] Loss: -1778.801636\n",
      "Train Epoch: 993 [45056/54000 (83%)] Loss: -1776.265381\n",
      "    epoch          : 993\n",
      "    loss           : -1781.2119601267689\n",
      "    ess            : 27.026194338528615\n",
      "    log_marginal   : 1781.5300730579304\n",
      "    val_loss       : -1780.4029032389324\n",
      "    val_ess        : 27.013014634450276\n",
      "    val_log_marginal: 1780.7310587565105\n",
      "Train Epoch: 994 [0/54000 (0%)] Loss: -1783.279785\n",
      "Train Epoch: 994 [11264/54000 (21%)] Loss: -1775.361206\n",
      "Train Epoch: 994 [22528/54000 (42%)] Loss: -1781.383545\n",
      "Train Epoch: 994 [33792/54000 (63%)] Loss: -1779.362183\n",
      "Train Epoch: 994 [45056/54000 (83%)] Loss: -1778.730957\n",
      "    epoch          : 994\n",
      "    loss           : -1782.0997763579746\n",
      "    ess            : 27.0051681230653\n",
      "    log_marginal   : 1782.42326959574\n",
      "    val_loss       : -1781.3978780110676\n",
      "    val_ess        : 27.014219443003338\n",
      "    val_log_marginal: 1781.7255961100261\n",
      "Train Epoch: 995 [0/54000 (0%)] Loss: -1780.076416\n",
      "Train Epoch: 995 [11264/54000 (21%)] Loss: -1779.532471\n",
      "Train Epoch: 995 [22528/54000 (42%)] Loss: -1785.390869\n",
      "Train Epoch: 995 [33792/54000 (63%)] Loss: -1779.750366\n",
      "Train Epoch: 995 [45056/54000 (83%)] Loss: -1788.162720\n",
      "    epoch          : 995\n",
      "    loss           : -1782.9399586803509\n",
      "    ess            : 26.984079522906608\n",
      "    log_marginal   : 1783.264934035967\n",
      "    val_loss       : -1782.1870625813801\n",
      "    val_ess        : 27.004478931427002\n",
      "    val_log_marginal: 1782.5113321940105\n",
      "Train Epoch: 996 [0/54000 (0%)] Loss: -1787.774414\n",
      "Train Epoch: 996 [11264/54000 (21%)] Loss: -1785.290161\n",
      "Train Epoch: 996 [22528/54000 (42%)] Loss: -1785.236816\n",
      "Train Epoch: 996 [33792/54000 (63%)] Loss: -1781.988525\n",
      "Train Epoch: 996 [45056/54000 (83%)] Loss: -1782.474976\n",
      "    epoch          : 996\n",
      "    loss           : -1783.720864349941\n",
      "    ess            : 26.997409928519772\n",
      "    log_marginal   : 1784.0483697855248\n",
      "    val_loss       : -1782.7071228027344\n",
      "    val_ess        : 27.311124006907146\n",
      "    val_log_marginal: 1783.0186767578125\n",
      "Train Epoch: 997 [0/54000 (0%)] Loss: -1783.261353\n",
      "Train Epoch: 997 [11264/54000 (21%)] Loss: -1788.162109\n",
      "Train Epoch: 997 [22528/54000 (42%)] Loss: -1784.671143\n",
      "Train Epoch: 997 [33792/54000 (63%)] Loss: -1780.890137\n",
      "Train Epoch: 997 [45056/54000 (83%)] Loss: -1783.727783\n",
      "    epoch          : 997\n",
      "    loss           : -1784.3636889187794\n",
      "    ess            : 27.11633948560031\n",
      "    log_marginal   : 1784.6780464604217\n",
      "    val_loss       : -1783.1062723795574\n",
      "    val_ess        : 26.97982374827067\n",
      "    val_log_marginal: 1783.4471842447917\n",
      "Train Epoch: 998 [0/54000 (0%)] Loss: -1784.489502\n",
      "Train Epoch: 998 [11264/54000 (21%)] Loss: -1790.156006\n",
      "Train Epoch: 998 [22528/54000 (42%)] Loss: -1785.356934\n",
      "Train Epoch: 998 [33792/54000 (63%)] Loss: -1782.243896\n",
      "Train Epoch: 998 [45056/54000 (83%)] Loss: -1785.448975\n",
      "    epoch          : 998\n",
      "    loss           : -1784.6522412570018\n",
      "    ess            : 27.05542929667347\n",
      "    log_marginal   : 1784.972900390625\n",
      "    val_loss       : -1782.7662658691406\n",
      "    val_ess        : 26.975316683451336\n",
      "    val_log_marginal: 1783.1048889160156\n",
      "Train Epoch: 999 [0/54000 (0%)] Loss: -1790.057007\n",
      "Train Epoch: 999 [11264/54000 (21%)] Loss: -1758.971680\n",
      "Train Epoch: 999 [22528/54000 (42%)] Loss: -1765.797119\n",
      "Train Epoch: 999 [33792/54000 (63%)] Loss: -1768.841797\n",
      "Train Epoch: 999 [45056/54000 (83%)] Loss: -1766.118164\n",
      "    epoch          : 999\n",
      "    loss           : -1768.8095104289505\n",
      "    ess            : 26.851304845989876\n",
      "    log_marginal   : 1769.1336612341538\n",
      "    val_loss       : -1770.3898010253906\n",
      "    val_ess        : 27.123977184295654\n",
      "    val_log_marginal: 1770.7014668782551\n",
      "Train Epoch: 1000 [0/54000 (0%)] Loss: -1773.960815\n",
      "Train Epoch: 1000 [11264/54000 (21%)] Loss: -1779.489380\n",
      "Train Epoch: 1000 [22528/54000 (42%)] Loss: -1777.846436\n",
      "Train Epoch: 1000 [33792/54000 (63%)] Loss: -1779.617310\n",
      "Train Epoch: 1000 [45056/54000 (83%)] Loss: -1781.600220\n",
      "    epoch          : 1000\n",
      "    loss           : -1778.227361715065\n",
      "    ess            : 27.63254942983951\n",
      "    log_marginal   : 1778.5066090709759\n",
      "    val_loss       : -1779.2879638671875\n",
      "    val_ess        : 27.54915777842204\n",
      "    val_log_marginal: 1779.5724080403645\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0321_141154/checkpoint-epoch1000.pth ...\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa5b900-0121-4cf6-91b6-2c9b0b12716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParticleDict(\n",
       "    (z1): Parameter containing: [torch.FloatTensor of size 32x6000x10]\n",
       "    (z2): Parameter containing: [torch.FloatTensor of size 32x6000x128]\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.eval()\n",
    "trainer.model.cpu()\n",
    "trainer.cpu()\n",
    "trainer.train_particles.cpu()\n",
    "trainer.valid_particles.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9d528cb-d45e-4a37-be86-9622aec9ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.graph.clear()\n",
    "trainer._load_particles(range(trainer.data_loader.batch_size), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e26726a6-74e5-4e0f-81d5-746dba00f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in trainer.model.graph.nodes:\n",
    "    trainer.model.graph.nodes[site]['is_observed'] = trainer.model.graph.nodes[site]['value'] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cb94c06-7112-4c5e-b781-0ac215a7e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60a2eeb8-32e3-467e-9e9a-0ac1e2af9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate_stack(\"forward\", (trainer.num_particles, trainer.data_loader.batch_size)):\n",
    "    model = pyro.condition(trainer.model, data={k: v['value'] for k, v in trainer.model.graph.nodes.items()})\n",
    "    xs = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6e9ba59-7b26-4ef3-9bfd-23f7c8a26464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b1509d2-9afc-444e-821f-b7ccda42aa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlu0lEQVR4nO3dfXBU153m8ed2I7WE3OoEg96CrFIlECeGoja2A2b8AkystWbCBuMk2J5KwWzssWNgl8UuVwg1ZSq1i1z2mGIqxGTjyRJITMxsld+yEGNlMCJeQhYzOGYJw+C1HOQFRYHYaiGJbqQ++wdBGxmM+3cs6ejl+6nqKqvVP9+j27f70UXdT0fOOScAAAKIhV4AAGDsIoQAAMEQQgCAYAghAEAwhBAAIBhCCAAQDCEEAAiGEAIABDMu9ALeL5fL6cSJE0omk4qiKPRyAABGzjl1dHSoqqpKsdjlz3WGXQidOHFC1dXVoZcBAPiIWlpaNHny5MveZtiFUDKZlCTdkvyqxkWFec+5bNa+sYIC+4yvc+fMI1FJiXnGdXaaZ3LZHvOMJMWK8r9/+vic3Xo0S0VFRfbtSHKZjH1b8bh9Qz4zHvvOnT1r347ktb4h+5eLmMd+OOd3jOtDfou/5LbO2p+LooIhOoYkuaz9uShWnDDdvsdl1dS+re/5/HIGLYSefPJJPf744zp58qSuueYarV+/XjfddNOHzl04kMdFhbYQ8jn+oyEMIY8HaBSzP8m7yH6A5TyfPGKG+6eP17Y8Qshj30mSizy2FfkEiseMz5NvlLNvR/Ja35CFkE8YR55//vaY8zuGPJ6KfY4h+T1Xej3Wld8xMSgvTNi2bZtWrFih1atX6+DBg7rppptUX1+v48ePD8bmAAAj1KCE0Lp16/T1r39d99xzjz7zmc9o/fr1qq6u1saNGwdjcwCAEWrAQyibzerAgQOqq6vrd31dXZ327t170e0zmYzS6XS/CwBgbBjwEDp16pR6e3tVXl7e7/ry8nK1trZedPuGhgalUqm+C6+MA4CxY9DerPr+P0g55y75R6pVq1apvb2979LS0jJYSwIADDMD/uq4iRMnKh6PX3TW09bWdtHZkSQlEgklEraX/wEARocBPxMqLCzUtddeq8bGxn7XNzY2avbs2QO9OQDACDYo7xNauXKlvva1r+m6667TDTfcoO9///s6fvy47r///sHYHABghBqUEFq0aJFOnz6tb3/72zp58qSmTZumHTt2qKamZjA2BwAYoSLnPDpRBlE6nVYqldK8ImNtj0+1yxAWpEZXeFTwdHXbtzPO/nuF7yEQxe3/mtubPmOeiRV6NFv4Vpr02OtdYsUeFUEe68u129++EBs/3jzjy/X2Ds12PO4jn8eF97Z8Ko/GF9tnPP+W7lPtZa096nFZ7er8idrb21VaWnrZ2/JRDgCAYAghAEAwhBAAIBhCCAAQDCEEAAiGEAIABEMIAQCCIYQAAMEQQgCAYAghAEAwhBAAIBhCCAAQzKC0aIcQ8ykI7T7rta3Io7DSZ1s+hZBea/MoFfXdVtzjfpJHgWnvH96zb0d+5ZPubMa+nWJ7YaUi+++MLpu1b0d+63NdXeYZn8etz32U81ib5Fd8GpV4HOMZ+zHU43mMx4o8ik9zOdvtXf7PXZwJAQCCIYQAAMEQQgCAYAghAEAwhBAAIBhCCAAQDCEEAAiGEAIABEMIAQCCIYQAAMEQQgCAYAghAEAwhBAAIJhh26IdlZQoihXmP+CcfRsJjzZZSfJot/Zan0dbsKLIPuPJp+XbebQFq9v+u1IU89sPUYH9IeG1H3wap0uvMM8oZz/uJMn19JhnvJrse43tzJIij1Z1+TyWPOXefdc+5NGQHk+V2rcjyXV3e80NFs6EAADBEEIAgGAIIQBAMIQQACAYQggAEAwhBAAIhhACAARDCAEAgiGEAADBEEIAgGAIIQBAMIQQACCYYVtgqlxOcvmXG7ps1ryJqNBQkPqnPEohfUouI48yUpex7wfLfv6oonEeBaFe5a9+923urL1g1atodoj2uVdhrORV+Ok89p0K7GWkrvusfTs+pcOS5PEcERUXm2d89l1U5FfA7FNgGhnLaaNcgZTn3cSZEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEM2wLTF0mIxcZiis9ChdzXV3mGcmvhNOnjNSnYDXnUVgZS5WaZyRJHj+TenrsM9lz5pGo0F6MKUmxnL1Y1KewUjGPclqf/VBdZZ6RpPT0K80zpUfeM8+45hb7jE8ZsMdj1ntbHs9FUYF9fbl0h3lGkl85bZet9NS5/IuUORMCAARDCAEAghnwEFqzZo2iKOp3qaioGOjNAABGgUH5m9A111yjn//8531fx30+9AsAMOoNSgiNGzeOsx8AwIcalL8JHTt2TFVVVaqtrdWdd96pt9566wNvm8lklE6n+10AAGPDgIfQzJkztWXLFu3cuVNPPfWUWltbNXv2bJ0+ffqSt29oaFAqleq7VFdXD/SSAADD1ICHUH19ve644w5Nnz5dX/jCF7R9+3ZJ0ubNmy95+1WrVqm9vb3v0tJif98AAGBkGvQ3q5aUlGj69Ok6duzYJb+fSCSUSCQGexkAgGFo0N8nlMlkdOTIEVVWVg72pgAAI8yAh9BDDz2kpqYmNTc361e/+pW+/OUvK51Oa/HixQO9KQDACDfg/xz3zjvv6K677tKpU6c0adIkzZo1S/v27VNNTc1AbwoAMMINeAg988wzA/L/icaNUxQZludRWBnF/U4Ec91nzTMxj797eZWRFheZZ+RR0ihJ7pxHGakzlNJe4FEq6lP2KUmKeRwTV37MPPLmPfb30W356gbzTFHkcR9JKo/b91/co9D2L3/91+aZiV99xzzjsvkXav4pr+JTn+PV4zHo9ViXpJz9MWh9LnIu/31AdxwAIBhCCAAQDCEEAAiGEAIABEMIAQCCIYQAAMEQQgCAYAghAEAwhBAAIBhCCAAQDCEEAAiGEAIABDPoH2rny2WzcpY+xB6PokaPwkVJigoLzTM+BYU+5Yk+5apeJY2SX/Fpgb1o1ud+iirL7NuRdHTNx8wzL9/0HfNMKmb/mc56lL8mY3HzjCS902OfK4/bizt/NmOTeeaOP/9P5pmi7QfMM5L8nld67fvBp4w0Ki42z0iS6+yybytuOx4il/9zA2dCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACGbYtmhHRQlFUf5t1S57zr6RmF8Gu2zWvqlEwr6hAo+7x16iLZfJ2IckRR4/UyxVap458vBk88yeBU+YZyTJp3M67tHyXRTZt/ROj307/3ajvXFaks5OsjdBv/rlvzPPpGL2Rvrj/87eJv7pl/2e6nzarb3k7D9TLt3hty2P9ntnbHB3Lv/jhzMhAEAwhBAAIBhCCAAQDCEEAAiGEAIABEMIAQCCIYQAAMEQQgCAYAghAEAwhBAAIBhCCAAQDCEEAAhm2BaYuuw5OUMxpE+ZpuvuNs9IUlRoL110PT32DXkUDUZxjwpOn3JV+ZXGtny1xjyz7/bHzTMJj4JQSYrLXhJ6RcxecvnDdJl55r/f+nnzTM2ZI+YZSYquKDHPdNzhUeTq7I+Lz3zq/5pnnM/jQpI85nweF9E4j6din+cUeT5/dRubkQ2Fp5wJAQCCIYQAAMEQQgCAYAghAEAwhBAAIBhCCAAQDCEEAAiGEAIABEMIAQCCIYQAAMEQQgCAYAghAEAww7bAVFF0/pKnXFeXfRMeRX6SpHP2gkIvMfvvCM5QHPgnQ/YZSbFie3HnHYt3m2cSkX0/dOTs5a+S9FbPFeaZFY9/wzxT+TOPEs6OdvNMzlo8+UcxlzPPJCP7cVTgUTR75Ohk88zV8Q7zjK8obj9efZ6/fB5/kmfBqvFnilwk5bkZzoQAAMEQQgCAYMwhtGfPHs2fP19VVVWKokjPP/98v+8757RmzRpVVVWpuLhYc+bM0eHDhwdqvQCAUcQcQp2dnZoxY4Y2bNhwye8/9thjWrdunTZs2KD9+/eroqJCt956qzo6hu7fZAEAI4P5hQn19fWqr6+/5Pecc1q/fr1Wr16thQsXSpI2b96s8vJybd26Vffdd99HWy0AYFQZ0L8JNTc3q7W1VXV1dX3XJRIJ3XLLLdq7d+8lZzKZjNLpdL8LAGBsGNAQam1tlSSVl5f3u768vLzve+/X0NCgVCrVd6murh7IJQEAhrFBeXVc9L739zjnLrruglWrVqm9vb3v0tLSMhhLAgAMQwP6ZtWKigpJ58+IKisr+65va2u76OzogkQioUQiMZDLAACMEAN6JlRbW6uKigo1Njb2XZfNZtXU1KTZs2cP5KYAAKOA+UzozJkzevPNN/u+bm5u1uuvv64JEyboqquu0ooVK7R27VpNmTJFU6ZM0dq1azV+/HjdfffdA7pwAMDIZw6h1157TXPnzu37euXKlZKkxYsX64c//KEefvhhdXd364EHHtC7776rmTNn6uWXX1YymRy4VQMARoXIeTVeDp50Oq1UKqV5JXdpXJR/wWjkUebnMlnzjHTxCy/y4VMkGRV4/MnOY23q9Sv79CmAfe8vPmueuXXVL8wzW/7nn5lnJOmz/+Ud84w7a79vfUokfYpzo+Ji+3YkRUX2v9Nu3f+ceaYosh/jC+q/Zp6Jjp80z/hy53rsQx5lxT5FqZLkzmbsQwUFppv3uKx2dTyt9vZ2lZaWXva2dMcBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgmAH9ZNWBFBWPVxQztDT32Jtro3FD9+NHhbYW2vMz9pbqXEeHfTue+8F57PPUTw+ZZ/b/vMI889krWs0zkpRL2/efVwu5R9u5T+F9bLxfi/acnUfNMwWKm2d+1vVx80zU8jvzjHJ+Hxbg036vmP2+9Xmse4vb7yfrJwdEyv/2nAkBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDDDtsBUPVkZOvCkaOjy1GUy9pls1j7jU8rqUYQYJRLmGUmSy5lHcp3d5pnIo3DRdZwxz0hSVDHJPPPm18vNMz1V9mNo4pX2ctVbKt80z0jSwuSvzTO/8+hxXffQ3eaZ8WdeN8/4FAhLUhS3P6+4XvvjwqdE2Oc5xVevsRi5153L+7acCQEAgiGEAADBEEIAgGAIIQBAMIQQACAYQggAEAwhBAAIhhACAARDCAEAgiGEAADBEEIAgGAIIQBAMMO2wDR3pku5KP8SPJ8CwKHkUxLqVWDqsx88ikglyZ3zWJ9HIaQ8Ckz/5ZEp9u1Ieuov/8E8M6Wg3TxTFFnaec8bH9n3Q5fzaBWVlPDZVs6+rZYF9pmrd3kU7vb67YeouNg8k2tPm2d6PWaiAr/nPJ/Hbcy4H2IuLnXleVvzagAAGCCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACGb4tn5GsfOXPPmUfcauKDHPSJJyzjzinH0m8ii5zHWfNc/EiovMM5LfPj+x7FrzzPeXfsc8Myn+U/OMJI2373L9tsdecrmzY7p5pr701+aZGYX2IlJJOudRfBr3OF4fmvmyeWbHxM+ZZ3Kn/mCekTyfVzweT5FHSa/LZs0zkhQVFti3ZSyAdYZSZM6EAADBEEIAgGDMIbRnzx7Nnz9fVVVViqJIzz//fL/vL1myRFEU9bvMmjVroNYLABhFzCHU2dmpGTNmaMOGDR94m9tuu00nT57su+zYseMjLRIAMDqZX5hQX1+v+vr6y94mkUiooqLCe1EAgLFhUP4mtHv3bpWVlWnq1Km699571dbW9oG3zWQySqfT/S4AgLFhwEOovr5eTz/9tHbt2qUnnnhC+/fv17x585TJZC55+4aGBqVSqb5LdXX1QC8JADBMDfj7hBYtWtT339OmTdN1112nmpoabd++XQsXLrzo9qtWrdLKlSv7vk6n0wQRAIwRg/5m1crKStXU1OjYsWOX/H4ikVAikRjsZQAAhqFBf5/Q6dOn1dLSosrKysHeFABghDGfCZ05c0Zvvvlm39fNzc16/fXXNWHCBE2YMEFr1qzRHXfcocrKSr399tv61re+pYkTJ+r2228f0IUDAEY+cwi99tprmjt3bt/XF/6es3jxYm3cuFGHDh3Sli1b9N5776myslJz587Vtm3blEwmB27VAIBRwRxCc+bMuWwZ586dOz/Sgi6IJUsUixXmP3DOXjToPGa8xez/8hmVjLdvJ3vOPOJT0ihJv/vHWvPM/uv+3mtbVq90X+k193f3/JV5JnH0hHkmV/Zx80zXDw2Phz/69KRfmmckqUD2Qs1eZz+OvnTFEfNM+wv2x8Wu//Bn5hlJKtj3G/NM7GMp80yu44x5xqcUWfIrRrYWrEaGAly64wAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABDMoH+yqreeHinKPyNz3WfNm4gVF5lnJM/W6XMe7da9+TfRXhAVFphnTj1TYZ6RpN0zNpln/uDxM71w5tPmmZ/++XTzjCQVvGtvTXYebefNq+0Pvf+YtDdOr3inzjwjSf+nfaJ55iuT/9k887niZvPMXyTfMM/M/MGbH36jS1j2o/vMMzUvtJtnYpmseSYqtLeqS1Jve9o8E79ygun2Ua5A6srvtpwJAQCCIYQAAMEQQgCAYAghAEAwhBAAIBhCCAAQDCEEAAiGEAIABEMIAQCCIYQAAMEQQgCAYAghAEAwkXPOhV7En0qn00qlUpqb+KrGRfmXcfqU+UXj/PpbXdZeNuhVepqz3zXTf2UvSl058RfmGUn6Qy5unlnyvxebZyb99bvmGZ2z30eSlLn2U+aZv/2+vcj18wl74e5//v115pnX77aXv0qSWk/ZZ+L232lbvzzVPDN+we/MM//16qfNM5KUjNkLdx946yvmmT98r8Y887GX7IW2kuTOeTwXGWOix2W1q+sZtbe3q7S09LK35UwIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAILxa/AcjnI5+0yvvZzQVxRF5pl/ffzfmGd+MmmdeeaKWLF5RpJ+n7OXpV75t/mX0vaZ9HHzyN+8sMO+HUmzi+xzrb32Itf/lRlvnvn1AnvJpTt1wjxzftBenutTCFz+ozfs29lmLytedN+D5hlJuvvufzLPHPln+/30yePd5hmvIlLJ676V+fkr/9tzJgQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwQzbAtMoHlMU5V8M6XrsZX4uay/g9BUrLjLP/I8F9jLSXtnLCdtzZ80zktTSc6V5ZupT/2qe+fdXvmqemTzOr9zRowZXd+y93zzzqXvs+yEqsd9PPo8LSYqNtxes5rq6zDM+xb65M53mmerv/No8I0mvPllunpnqDptn3NmMeSbyeE6RJJfN2ofi9pLefHEmBAAIhhACAARjCqGGhgZdf/31SiaTKisr04IFC3T06NF+t3HOac2aNaqqqlJxcbHmzJmjw4ftp6cAgNHPFEJNTU1aunSp9u3bp8bGRvX09Kiurk6dnf//32gfe+wxrVu3Ths2bND+/ftVUVGhW2+9VR0dHQO+eADAyGZ6YcJLL73U7+tNmzaprKxMBw4c0M033yznnNavX6/Vq1dr4cKFkqTNmzervLxcW7du1X333TdwKwcAjHgf6W9C7e3tkqQJEyZIkpqbm9Xa2qq6urq+2yQSCd1yyy3au3fvJf8fmUxG6XS63wUAMDZ4h5BzTitXrtSNN96oadOmSZJaW1slSeXl/V/WWF5e3ve992toaFAqleq7VFdX+y4JADDCeIfQsmXL9MYbb+gnP/nJRd97/2v/nXMf+H6AVatWqb29ve/S0tLiuyQAwAjj9WbV5cuX68UXX9SePXs0efLkvusrKioknT8jqqys7Lu+ra3torOjCxKJhBKJhM8yAAAjnOlMyDmnZcuW6dlnn9WuXbtUW1vb7/u1tbWqqKhQY2Nj33XZbFZNTU2aPXv2wKwYADBqmM6Eli5dqq1bt+qFF15QMpns+ztPKpVScXGxoijSihUrtHbtWk2ZMkVTpkzR2rVrNX78eN19992D8gMAAEYuUwht3LhRkjRnzpx+12/atElLliyRJD388MPq7u7WAw88oHfffVczZ87Uyy+/rGQyOSALBgCMHpFzzt54OYjS6bRSqZTmldylcVFh6OVckk/xaayk2DxzZtsE88w/XP1j88yJHr9fEN4+N9E8k4zZSzjjkb1WdOXLf2WekaRPb2w3z7h/edM+k7M/7GIl9lLRaLz9uJMk13HGPBMrtR9HXk8/3fZjKJexF4RKfgWrPj9TVGh/roviw7d1rcdl9U/v/Ujt7e0qLS297G2H708BABj1CCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACMbrk1WHguvplYt68r59FI/bt9Hba56RpKjI/kmw7qy9xTf5N/n//BfcddtD5pniU/aWakkq7LDvv0Rbl3km9vv3zDNTT71unpGk3Dn7Po9faW87z6XT5hmv1mSPxmlJynV3e81ZRcVF5hmXzdo35NFaLkkqsrdbx3yat3vsx53L+T1ucx7HRPzjKeNG8n8+5kwIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIZtgWmUSRFhiLAaJzHj+JReipJ8ig+dc5eoJj7/WnzzKT/9jvzTCyVNM9IkvMpx4zZf+/xqWm0HDt/KmYtapTkOjrMMz6Fuz7Fk75i48fbh3yO8TOd5hmffRcVFJhnfPk81odSzKOA2fyc5/K/PWdCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABDMsC0wdb1OLsq/utKrrjLnU40puWzWPONTsOo8ilJjJcXmmVzHGfPM+UF7UWOsuMi+mUzGPOMr8tjn8ijHzHV2mWfipVeYZ1z2nHnGdy6K23+njSXsZZo+BaG+hbY+pbGxK0rMM+6cx/72KSKVpMjj3MP5PVfmgzMhAEAwhBAAIBhCCAAQDCEEAAiGEAIABEMIAQCCIYQAAMEQQgCAYAghAEAwhBAAIBhCCAAQDCEEAAhm2BaYWvmUGvryKSONiu3FolHMXrroUzzpU7goSc6j3NH19JhnfEoufUtP3Tn7+nz2uU8Z6VDyKSN1vfaSS9dlL3KNhqj0VJKiQns5rRvCwl0fOZ99biyAdS7/kmfOhAAAwRBCAIBgTCHU0NCg66+/XslkUmVlZVqwYIGOHj3a7zZLlixRFEX9LrNmzRrQRQMARgdTCDU1NWnp0qXat2+fGhsb1dPTo7q6OnV2dva73W233aaTJ0/2XXbs2DGgiwYAjA6mv7C/9NJL/b7etGmTysrKdODAAd1888191ycSCVVUVAzMCgEAo9ZH+ptQe3u7JGnChAn9rt+9e7fKyso0depU3XvvvWpra/vA/0cmk1E6ne53AQCMDd4h5JzTypUrdeONN2ratGl919fX1+vpp5/Wrl279MQTT2j//v2aN2+eMh/wssWGhgalUqm+S3V1te+SAAAjTOQ8X0C/dOlSbd++Xa+++qomT578gbc7efKkampq9Mwzz2jhwoUXfT+TyfQLqHQ6rerqas0t+IrGRfm/Rj8qsr93QDn7+xokSb295hGf9wlpiN4n5PNeCMnvfUI+fN6X5fs+IZ9teb03q8TjePDgszZJXo8Nn/cJydlnfN4nJN/3ERrfH+O9LY/97fWcJynn8bi1vk+ox2W16+w/qr29XaWlpZe9rdebVZcvX64XX3xRe/bsuWwASVJlZaVqamp07NixS34/kUgo4XNQAQBGPFMIOee0fPlyPffcc9q9e7dqa2s/dOb06dNqaWlRZWWl9yIBAKOT6W9CS5cu1Y9//GNt3bpVyWRSra2tam1tVXd3tyTpzJkzeuihh/TLX/5Sb7/9tnbv3q358+dr4sSJuv322wflBwAAjFymM6GNGzdKkubMmdPv+k2bNmnJkiWKx+M6dOiQtmzZovfee0+VlZWaO3eutm3bpmQyOWCLBgCMDuZ/jruc4uJi7dy58yMtCAAwdgzbFu2oIK4oyn95uTNnzNvwaWeWpJzPq6FiHq+G93hlThSPm2d8X+Xm1TB8dmgahr2bwX1eTebxKsaheIWSJEUl480zkt8xERV4vMrynOer94x82tElKVZcZN+Wx6vjvNbn+TNFhYXmGZfNvxVbsr1AkAJTAEAwhBAAIBhCCAAQDCEEAAiGEAIABEMIAQCCIYQAAMEQQgCAYAghAEAwhBAAIBhCCAAQDCEEAAhm2BaYKpeTovw/8tanjNSnyE/yS25rAaAkuR57QWF80iT7djw/Clu99rJUn48k9vrY6CH66HFJUs5eWOn1keoeHyvv/RHsPh9r7VNG6lF66lOCGxX4PdV5Fc16bMtrxqOsWPL7mayFwDGXlfK8mzgTAgAEQwgBAIIhhAAAwRBCAIBgCCEAQDCEEAAgGEIIABAMIQQACIYQAgAEQwgBAIIhhAAAwQy77jjnzvdw9TiPHiqjyF75JUlyzqMHznn0fjl7d5zL2deW89zXPvsvcvbfe5zz6I7z2N++fO7byHnsPJ+fyWN/n+fRHee1Pvt+cB7Ha+RzDMn3vvXb1lBtx+fxHjM+5/X88fYuj/s3cvncagi98847qq6uDr0MAMBH1NLSosmTJ1/2NsMuhHK5nE6cOKFkMqnofU2+6XRa1dXVamlpUWlpaaAVhsd+OI/9cB774Tz2w3nDYT8459TR0aGqqirFYpc/Gx92/xwXi8U+NDlLS0vH9EF2AfvhPPbDeeyH89gP54XeD6lUKq/b8cIEAEAwhBAAIJgRFUKJREKPPPKIEh6fojqasB/OYz+cx344j/1w3kjbD8PuhQkAgLFjRJ0JAQBGF0IIABAMIQQACIYQAgAEM6JC6Mknn1Rtba2Kiop07bXX6he/+EXoJQ2pNWvWKIqifpeKiorQyxp0e/bs0fz581VVVaUoivT888/3+75zTmvWrFFVVZWKi4s1Z84cHT58OMxiB9GH7YclS5ZcdHzMmjUrzGIHSUNDg66//nolk0mVlZVpwYIFOnr0aL/bjIXjIZ/9MFKOhxETQtu2bdOKFSu0evVqHTx4UDfddJPq6+t1/Pjx0EsbUtdcc41OnjzZdzl06FDoJQ26zs5OzZgxQxs2bLjk9x977DGtW7dOGzZs0P79+1VRUaFbb71VHR0dQ7zSwfVh+0GSbrvttn7Hx44dO4ZwhYOvqalJS5cu1b59+9TY2Kienh7V1dWps7Oz7zZj4XjIZz9II+R4cCPE5z//eXf//ff3u+7qq6923/zmNwOtaOg98sgjbsaMGaGXEZQk99xzz/V9ncvlXEVFhXv00Uf7rjt79qxLpVLue9/7XoAVDo337wfnnFu8eLH70pe+FGQ9obS1tTlJrqmpyTk3do+H9+8H50bO8TAizoSy2awOHDigurq6ftfX1dVp7969gVYVxrFjx1RVVaXa2lrdeeedeuutt0IvKajm5ma1trb2OzYSiYRuueWWMXdsSNLu3btVVlamqVOn6t5771VbW1voJQ2q9vZ2SdKECRMkjd3j4f374YKRcDyMiBA6deqUent7VV5e3u/68vJytba2BlrV0Js5c6a2bNminTt36qmnnlJra6tmz56t06dPh15aMBfu/7F+bEhSfX29nn76ae3atUtPPPGE9u/fr3nz5imTyYRe2qBwzmnlypW68cYbNW3aNElj83i41H6QRs7xMOxatC/n/R/t4Jy76LrRrL6+vu+/p0+frhtuuEGf/OQntXnzZq1cuTLgysIb68eGJC1atKjvv6dNm6brrrtONTU12r59uxYuXBhwZYNj2bJleuONN/Tqq69e9L2xdDx80H4YKcfDiDgTmjhxouLx+EW/ybS1tV30G89YUlJSounTp+vYsWOhlxLMhVcHcmxcrLKyUjU1NaPy+Fi+fLlefPFFvfLKK/0++mWsHQ8ftB8uZbgeDyMihAoLC3XttdeqsbGx3/WNjY2aPXt2oFWFl8lkdOTIEVVWVoZeSjC1tbWqqKjod2xks1k1NTWN6WNDkk6fPq2WlpZRdXw457Rs2TI9++yz2rVrl2pra/t9f6wcDx+2Hy5l2B4PAV8UYfLMM8+4goIC94Mf/MD95je/cStWrHAlJSXu7bffDr20IfPggw+63bt3u7feesvt27fPffGLX3TJZHLU74OOjg538OBBd/DgQSfJrVu3zh08eND99re/dc459+ijj7pUKuWeffZZd+jQIXfXXXe5yspKl06nA698YF1uP3R0dLgHH3zQ7d271zU3N7tXXnnF3XDDDe4Tn/jEqNoP3/jGN1wqlXK7d+92J0+e7Lt0dXX13WYsHA8fth9G0vEwYkLIOee++93vupqaGldYWOg+97nP9Xs54liwaNEiV1lZ6QoKClxVVZVbuHChO3z4cOhlDbpXXnnFSbrosnjxYufc+ZflPvLII66iosIlEgl38803u0OHDoVd9CC43H7o6upydXV1btKkSa6goMBdddVVbvHixe748eOhlz2gLvXzS3KbNm3qu81YOB4+bD+MpOOBj3IAAAQzIv4mBAAYnQghAEAwhBAAIBhCCAAQDCEEAAiGEAIABEMIAQCCIYQAAMEQQgCAYAghAEAwhBAAIBhCCAAQzP8DrQez3OmCvZoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(xs.mean(dim=0)[i].squeeze().detach().cpu().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2029315-afe9-4ae8-9f64-c342ef8b830b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34a71d-84a2-48f0-8150-3607e77ed6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ppc] *",
   "language": "python",
   "name": "conda-env-ppc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
