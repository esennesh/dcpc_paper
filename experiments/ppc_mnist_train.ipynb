{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ef93e3-8eb5-4883-8265-5fbe97d06e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eli/AnacondaProjects/ppc_experiments\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94520ed3-45be-4735-a0f2-b8f380838c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import numpy as np\n",
    "import pyro\n",
    "import torch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "import trainer.trainer as module_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ac4be4-19eb-4713-a88d-9bec118c7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyro.enable_validation(True)\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75ea7b9-6fe5-4f8a-a825-3572e421242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1445d1-45bb-43f9-893d-7a2b2bad1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_json\n",
    "\n",
    "config = read_json(\"experiments/ppc_mnist_config.json\")\n",
    "config = ConfigParser(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca35026-5f64-47f8-98c7-a5e228013d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistPpc(\n",
      "  (digit_features): DigitFeatures()\n",
      "  (decoder): DigitDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=200, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=200, out_features=400, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=400, out_features=784, bias=True)\n",
      "      (5): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (graph): GraphicalModel()\n",
      ")\n",
      "Trainable parameters: 396984\n",
      "Initialize particles: train batch 0\n",
      "Initialize particles: train batch 1\n",
      "Initialize particles: train batch 2\n",
      "Initialize particles: train batch 3\n",
      "Initialize particles: train batch 4\n",
      "Initialize particles: train batch 5\n",
      "Initialize particles: train batch 6\n",
      "Initialize particles: train batch 7\n",
      "Initialize particles: train batch 8\n",
      "Initialize particles: train batch 9\n",
      "Initialize particles: train batch 10\n",
      "Initialize particles: train batch 11\n",
      "Initialize particles: train batch 12\n",
      "Initialize particles: train batch 13\n",
      "Initialize particles: train batch 14\n",
      "Initialize particles: train batch 15\n",
      "Initialize particles: train batch 16\n",
      "Initialize particles: train batch 17\n",
      "Initialize particles: train batch 18\n",
      "Initialize particles: train batch 19\n",
      "Initialize particles: train batch 20\n",
      "Initialize particles: train batch 21\n",
      "Initialize particles: train batch 22\n",
      "Initialize particles: train batch 23\n",
      "Initialize particles: train batch 24\n",
      "Initialize particles: train batch 25\n",
      "Initialize particles: train batch 26\n",
      "Initialize particles: train batch 27\n",
      "Initialize particles: train batch 28\n",
      "Initialize particles: train batch 29\n",
      "Initialize particles: train batch 30\n",
      "Initialize particles: train batch 31\n",
      "Initialize particles: train batch 32\n",
      "Initialize particles: train batch 33\n",
      "Initialize particles: train batch 34\n",
      "Initialize particles: train batch 35\n",
      "Initialize particles: train batch 36\n",
      "Initialize particles: train batch 37\n",
      "Initialize particles: train batch 38\n",
      "Initialize particles: train batch 39\n",
      "Initialize particles: train batch 40\n",
      "Initialize particles: train batch 41\n",
      "Initialize particles: train batch 42\n",
      "Initialize particles: train batch 43\n",
      "Initialize particles: train batch 44\n",
      "Initialize particles: train batch 45\n",
      "Initialize particles: train batch 46\n",
      "Initialize particles: train batch 47\n",
      "Initialize particles: train batch 48\n",
      "Initialize particles: train batch 49\n",
      "Initialize particles: train batch 50\n",
      "Initialize particles: train batch 51\n",
      "Initialize particles: train batch 52\n",
      "Initialize particles: train batch 53\n",
      "Initialize particles: train batch 54\n",
      "Initialize particles: train batch 55\n",
      "Initialize particles: train batch 56\n",
      "Initialize particles: train batch 57\n",
      "Initialize particles: train batch 58\n",
      "Initialize particles: train batch 59\n",
      "Initialize particles: train batch 60\n",
      "Initialize particles: train batch 61\n",
      "Initialize particles: train batch 62\n",
      "Initialize particles: train batch 63\n",
      "Initialize particles: train batch 64\n",
      "Initialize particles: train batch 65\n",
      "Initialize particles: train batch 66\n",
      "Initialize particles: train batch 67\n",
      "Initialize particles: train batch 68\n",
      "Initialize particles: train batch 69\n",
      "Initialize particles: train batch 70\n",
      "Initialize particles: train batch 71\n",
      "Initialize particles: train batch 72\n",
      "Initialize particles: train batch 73\n",
      "Initialize particles: train batch 74\n",
      "Initialize particles: train batch 75\n",
      "Initialize particles: train batch 76\n",
      "Initialize particles: train batch 77\n",
      "Initialize particles: train batch 78\n",
      "Initialize particles: train batch 79\n",
      "Initialize particles: train batch 80\n",
      "Initialize particles: train batch 81\n",
      "Initialize particles: train batch 82\n",
      "Initialize particles: train batch 83\n",
      "Initialize particles: train batch 84\n",
      "Initialize particles: train batch 85\n",
      "Initialize particles: train batch 86\n",
      "Initialize particles: train batch 87\n",
      "Initialize particles: train batch 88\n",
      "Initialize particles: train batch 89\n",
      "Initialize particles: train batch 90\n",
      "Initialize particles: train batch 91\n",
      "Initialize particles: train batch 92\n",
      "Initialize particles: train batch 93\n",
      "Initialize particles: train batch 94\n",
      "Initialize particles: train batch 95\n",
      "Initialize particles: train batch 96\n",
      "Initialize particles: train batch 97\n",
      "Initialize particles: train batch 98\n",
      "Initialize particles: train batch 99\n",
      "Initialize particles: train batch 100\n",
      "Initialize particles: train batch 101\n",
      "Initialize particles: train batch 102\n",
      "Initialize particles: train batch 103\n",
      "Initialize particles: train batch 104\n",
      "Initialize particles: train batch 105\n",
      "Initialize particles: valid batch 0\n",
      "Initialize particles: valid batch 1\n",
      "Initialize particles: valid batch 2\n",
      "Initialize particles: valid batch 3\n",
      "Initialize particles: valid batch 4\n",
      "Initialize particles: valid batch 5\n",
      "Initialize particles: valid batch 6\n",
      "Initialize particles: valid batch 7\n",
      "Initialize particles: valid batch 8\n",
      "Initialize particles: valid batch 9\n",
      "Initialize particles: valid batch 10\n",
      "Initialize particles: valid batch 11\n"
     ]
    }
   ],
   "source": [
    "logger = config.get_logger('train')\n",
    "\n",
    "# setup data_loader instances\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "valid_data_loader = data_loader.split_validation()\n",
    "\n",
    "# build model architecture, then print to console\n",
    "model = config.init_obj('arch', module_arch)\n",
    "logger.info(model)\n",
    "\n",
    "# get function handles of metrics\n",
    "metrics = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# build optimizer.\n",
    "if \"lr_scheduler\" in config:\n",
    "    lr_scheduler = getattr(pyro.optim, config[\"lr_scheduler\"][\"type\"])\n",
    "    lr_scheduler = optimizer = lr_scheduler({\n",
    "        \"optimizer\": getattr(torch.optim, config[\"optimizer\"][\"type\"]),\n",
    "        \"optim_args\": config[\"optimizer\"][\"args\"][\"optim_args\"],\n",
    "        **config[\"lr_scheduler\"][\"args\"]\n",
    "    })\n",
    "else:\n",
    "    optimizer = config.init_obj('optimizer', pyro.optim)\n",
    "    lr_scheduler = None\n",
    "\n",
    "# build trainer\n",
    "# kwargs = config['trainer'].pop('args')\n",
    "trainer = config.init_obj('trainer', module_trainer, model, metrics, optimizer,\n",
    "                          config=config, data_loader=data_loader,\n",
    "                          valid_data_loader=valid_data_loader,\n",
    "                          lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5cdd31-7fae-4e6f-8fe2-ef5c023919de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved/log/Mnist_Ppc/0208_133044\n"
     ]
    }
   ],
   "source": [
    "logger.info(trainer.config.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05daa11b-4367-42e6-b449-cf630e65b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTIVITIES = [torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA]\n",
    "# SCHEDULE = torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1)\n",
    "# ON_TRACE_READY = torch.profiler.tensorboard_trace_handler(trainer.config.log_dir)\n",
    "# with torch.profiler.profile(activities=ACTIVITIES, on_trace_ready=ON_TRACE_READY, profile_memory=True, schedule=SCHEDULE, with_stack=True) as profiler:\n",
    "#     trainer.train(profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820b982-1a39-4bde-850e-1a1d9a92557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/54000 (0%)] Loss: 16.100006\n",
      "Train Epoch: 1 [11264/54000 (21%)] Loss: -1386.249268\n",
      "Train Epoch: 1 [22528/54000 (42%)] Loss: -1361.787842\n",
      "Train Epoch: 1 [33792/54000 (63%)] Loss: -1444.942749\n",
      "Train Epoch: 1 [45056/54000 (83%)] Loss: -1420.182129\n",
      "    epoch          : 1\n",
      "    loss           : -1371.6550497378944\n",
      "    ess            : 8.001120202946213\n",
      "    log_marginal   : 1371.6550520411079\n",
      "    val_loss       : -1461.624532063802\n",
      "    val_ess        : 8.00117572148641\n",
      "    val_log_marginal: 1461.624532063802\n",
      "Train Epoch: 2 [0/54000 (0%)] Loss: -1425.940552\n",
      "Train Epoch: 2 [11264/54000 (21%)] Loss: -1477.173462\n",
      "Train Epoch: 2 [22528/54000 (42%)] Loss: -1459.281372\n",
      "Train Epoch: 2 [33792/54000 (63%)] Loss: -1525.834595\n",
      "Train Epoch: 2 [45056/54000 (83%)] Loss: -1499.562866\n",
      "    epoch          : 2\n",
      "    loss           : -1465.0692006237102\n",
      "    ess            : 8.001165551959344\n",
      "    log_marginal   : 1465.069201775317\n",
      "    val_loss       : -1512.1118265787761\n",
      "    val_ess        : 8.001176516215006\n",
      "    val_log_marginal: 1512.1118265787761\n",
      "Train Epoch: 3 [0/54000 (0%)] Loss: -1511.306274\n",
      "Train Epoch: 3 [11264/54000 (21%)] Loss: -1538.043701\n",
      "Train Epoch: 3 [22528/54000 (42%)] Loss: -1465.577271\n",
      "Train Epoch: 3 [33792/54000 (63%)] Loss: -1525.485107\n",
      "Train Epoch: 3 [45056/54000 (83%)] Loss: -1519.274536\n",
      "    epoch          : 3\n",
      "    loss           : -1505.1728987783756\n",
      "    ess            : 8.001172641538224\n",
      "    log_marginal   : 1505.1728987783756\n",
      "    val_loss       : -1541.2795003255208\n",
      "    val_ess        : 8.001179218292236\n",
      "    val_log_marginal: 1541.2795003255208\n",
      "Train Epoch: 4 [0/54000 (0%)] Loss: -1551.787964\n",
      "Train Epoch: 4 [11264/54000 (21%)] Loss: -1559.597412\n",
      "Train Epoch: 4 [22528/54000 (42%)] Loss: -1505.138794\n",
      "Train Epoch: 4 [33792/54000 (63%)] Loss: -1565.581909\n",
      "Train Epoch: 4 [45056/54000 (83%)] Loss: -1568.244873\n",
      "    epoch          : 4\n",
      "    loss           : -1544.1310493901092\n",
      "    ess            : 8.00117652821091\n",
      "    log_marginal   : 1544.1310493901092\n",
      "    val_loss       : -1575.1084798177083\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1575.1084798177083\n",
      "Train Epoch: 5 [0/54000 (0%)] Loss: -1591.660400\n",
      "Train Epoch: 5 [11264/54000 (21%)] Loss: -1570.426758\n",
      "Train Epoch: 5 [22528/54000 (42%)] Loss: -1551.962891\n",
      "Train Epoch: 5 [33792/54000 (63%)] Loss: -1608.118896\n",
      "Train Epoch: 5 [45056/54000 (83%)] Loss: -1585.765625\n",
      "    epoch          : 5\n",
      "    loss           : -1576.2041833265773\n",
      "    ess            : 8.001182214269098\n",
      "    log_marginal   : 1576.204184478184\n",
      "    val_loss       : -1600.5672709147136\n",
      "    val_ess        : 8.001184066136679\n",
      "    val_log_marginal: 1600.5672709147136\n",
      "Train Epoch: 6 [0/54000 (0%)] Loss: -1622.229004\n",
      "Train Epoch: 6 [11264/54000 (21%)] Loss: -1621.310059\n",
      "Train Epoch: 6 [22528/54000 (42%)] Loss: -1588.255859\n",
      "Train Epoch: 6 [33792/54000 (63%)] Loss: -1628.557983\n",
      "Train Epoch: 6 [45056/54000 (83%)] Loss: -1588.251221\n",
      "    epoch          : 6\n",
      "    loss           : -1600.6332236235996\n",
      "    ess            : 8.001183608792863\n",
      "    log_marginal   : 1600.633225926813\n",
      "    val_loss       : -1614.0740966796875\n",
      "    val_ess        : 8.001182794570923\n",
      "    val_log_marginal: 1614.0740966796875\n",
      "Train Epoch: 7 [0/54000 (0%)] Loss: -1631.662964\n",
      "Train Epoch: 7 [11264/54000 (21%)] Loss: -1624.953003\n",
      "Train Epoch: 7 [22528/54000 (42%)] Loss: -1591.913818\n",
      "Train Epoch: 7 [33792/54000 (63%)] Loss: -1650.234131\n",
      "Train Epoch: 7 [45056/54000 (83%)] Loss: -1602.530762\n",
      "    epoch          : 7\n",
      "    loss           : -1610.7215610720077\n",
      "    ess            : 8.001183698762137\n",
      "    log_marginal   : 1610.7215610720077\n",
      "    val_loss       : -1610.8818868001301\n",
      "    val_ess        : 8.001183112462362\n",
      "    val_log_marginal: 1610.8818868001301\n",
      "Train Epoch: 8 [0/54000 (0%)] Loss: -1635.036011\n",
      "Train Epoch: 8 [11264/54000 (21%)] Loss: -1624.666016\n",
      "Train Epoch: 8 [22528/54000 (42%)] Loss: -1613.128174\n",
      "Train Epoch: 8 [33792/54000 (63%)] Loss: -1665.944824\n",
      "Train Epoch: 8 [45056/54000 (83%)] Loss: -1623.611328\n",
      "    epoch          : 8\n",
      "    loss           : -1624.6810014832695\n",
      "    ess            : 8.001183896694544\n",
      "    log_marginal   : 1624.6810014832695\n",
      "    val_loss       : -1637.5815022786458\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1637.5814819335938\n",
      "Train Epoch: 9 [0/54000 (0%)] Loss: -1660.765503\n",
      "Train Epoch: 9 [11264/54000 (21%)] Loss: -1648.344482\n",
      "Train Epoch: 9 [22528/54000 (42%)] Loss: -1637.699463\n",
      "Train Epoch: 9 [33792/54000 (63%)] Loss: -1653.765503\n",
      "Train Epoch: 9 [45056/54000 (83%)] Loss: -1629.326172\n",
      "    epoch          : 9\n",
      "    loss           : -1636.9579145323555\n",
      "    ess            : 8.001184616448745\n",
      "    log_marginal   : 1636.9579145323555\n",
      "    val_loss       : -1649.0393473307292\n",
      "    val_ess        : 8.001183271408081\n",
      "    val_log_marginal: 1649.0393473307292\n",
      "Train Epoch: 10 [0/54000 (0%)] Loss: -1674.125000\n",
      "Train Epoch: 10 [11264/54000 (21%)] Loss: -1673.524414\n",
      "Train Epoch: 10 [22528/54000 (42%)] Loss: -1653.124512\n",
      "Train Epoch: 10 [33792/54000 (63%)] Loss: -1684.177002\n",
      "Train Epoch: 10 [45056/54000 (83%)] Loss: -1650.914795\n",
      "    epoch          : 10\n",
      "    loss           : -1658.11739824403\n",
      "    ess            : 8.001184328547064\n",
      "    log_marginal   : 1658.11739824403\n",
      "    val_loss       : -1683.1005452473958\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1683.1005249023438\n",
      "Train Epoch: 11 [0/54000 (0%)] Loss: -1702.953979\n",
      "Train Epoch: 11 [11264/54000 (21%)] Loss: -1689.051514\n",
      "Train Epoch: 11 [22528/54000 (42%)] Loss: -1663.360840\n",
      "Train Epoch: 11 [33792/54000 (63%)] Loss: -1682.746826\n",
      "Train Epoch: 11 [45056/54000 (83%)] Loss: -1656.858154\n",
      "    epoch          : 11\n",
      "    loss           : -1672.593108555056\n",
      "    ess            : 8.001184832375005\n",
      "    log_marginal   : 1672.593108555056\n",
      "    val_loss       : -1675.150614420573\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1675.1505940755208\n",
      "Train Epoch: 12 [0/54000 (0%)] Loss: -1697.973511\n",
      "Train Epoch: 12 [11264/54000 (21%)] Loss: -1695.375732\n",
      "Train Epoch: 12 [22528/54000 (42%)] Loss: -1654.141113\n",
      "Train Epoch: 12 [33792/54000 (63%)] Loss: -1697.863525\n",
      "Train Epoch: 12 [45056/54000 (83%)] Loss: -1686.679443\n",
      "    epoch          : 12\n",
      "    loss           : -1681.7235614128833\n",
      "    ess            : 8.00118440951941\n",
      "    log_marginal   : 1681.7235614128833\n",
      "    val_loss       : -1697.2069803873699\n",
      "    val_ess        : 8.001184622446695\n",
      "    val_log_marginal: 1697.2069803873699\n",
      "Train Epoch: 13 [0/54000 (0%)] Loss: -1716.825195\n",
      "Train Epoch: 13 [11264/54000 (21%)] Loss: -1711.228882\n",
      "Train Epoch: 13 [22528/54000 (42%)] Loss: -1686.695557\n",
      "Train Epoch: 13 [33792/54000 (63%)] Loss: -1721.425903\n",
      "Train Epoch: 13 [45056/54000 (83%)] Loss: -1696.706543\n",
      "    epoch          : 13\n",
      "    loss           : -1700.7388881467423\n",
      "    ess            : 8.001184715414947\n",
      "    log_marginal   : 1700.738889298349\n",
      "    val_loss       : -1704.7873840332031\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1704.7874043782551\n",
      "Train Epoch: 14 [0/54000 (0%)] Loss: -1727.053101\n",
      "Train Epoch: 14 [11264/54000 (21%)] Loss: -1705.226929\n",
      "Train Epoch: 14 [22528/54000 (42%)] Loss: -1680.754883\n",
      "Train Epoch: 14 [33792/54000 (63%)] Loss: -1719.826416\n",
      "Train Epoch: 14 [45056/54000 (83%)] Loss: -1679.297607\n",
      "    epoch          : 14\n",
      "    loss           : -1694.1381697744694\n",
      "    ess            : 8.001185291218308\n",
      "    log_marginal   : 1694.1381697744694\n",
      "    val_loss       : -1693.7373860677083\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1693.7373860677083\n",
      "Train Epoch: 15 [0/54000 (0%)] Loss: -1710.381592\n",
      "Train Epoch: 15 [11264/54000 (21%)] Loss: -1716.218872\n",
      "Train Epoch: 15 [22528/54000 (42%)] Loss: -1689.988281\n",
      "Train Epoch: 15 [33792/54000 (63%)] Loss: -1731.544434\n",
      "Train Epoch: 15 [45056/54000 (83%)] Loss: -1705.161987\n",
      "    epoch          : 15\n",
      "    loss           : -1704.294491174086\n",
      "    ess            : 8.001184535476396\n",
      "    log_marginal   : 1704.2944900224793\n",
      "    val_loss       : -1706.183369954427\n",
      "    val_ess        : 8.001184066136679\n",
      "    val_log_marginal: 1706.1833801269531\n",
      "Train Epoch: 16 [0/54000 (0%)] Loss: -1726.471191\n",
      "Train Epoch: 16 [11264/54000 (21%)] Loss: -1724.870850\n",
      "Train Epoch: 16 [22528/54000 (42%)] Loss: -1697.420898\n",
      "Train Epoch: 16 [33792/54000 (63%)] Loss: -1736.250244\n",
      "Train Epoch: 16 [45056/54000 (83%)] Loss: -1712.929199\n",
      "    epoch          : 16\n",
      "    loss           : -1711.2166368016656\n",
      "    ess            : 8.001184535476396\n",
      "    log_marginal   : 1711.2166379532723\n",
      "    val_loss       : -1719.2177327473958\n",
      "    val_ess        : 8.001184384028116\n",
      "    val_log_marginal: 1719.2177327473958\n",
      "Train Epoch: 17 [0/54000 (0%)] Loss: -1738.956299\n",
      "Train Epoch: 17 [11264/54000 (21%)] Loss: -1732.185425\n",
      "Train Epoch: 17 [22528/54000 (42%)] Loss: -1720.179443\n",
      "Train Epoch: 17 [33792/54000 (63%)] Loss: -1735.098145\n",
      "Train Epoch: 17 [45056/54000 (83%)] Loss: -1714.315674\n",
      "    epoch          : 17\n",
      "    loss           : -1719.7156579359523\n",
      "    ess            : 8.001183995660746\n",
      "    log_marginal   : 1719.7156579359523\n",
      "    val_loss       : -1730.8900960286458\n",
      "    val_ess        : 8.001184860865274\n",
      "    val_log_marginal: 1730.8900960286458\n",
      "Train Epoch: 18 [0/54000 (0%)] Loss: -1748.117676\n",
      "Train Epoch: 18 [11264/54000 (21%)] Loss: -1749.395752\n",
      "Train Epoch: 18 [22528/54000 (42%)] Loss: -1721.645752\n",
      "Train Epoch: 18 [33792/54000 (63%)] Loss: -1756.837891\n",
      "Train Epoch: 18 [45056/54000 (83%)] Loss: -1733.791992\n",
      "    epoch          : 18\n",
      "    loss           : -1734.0535543189858\n",
      "    ess            : 8.001184571464107\n",
      "    log_marginal   : 1734.0535543189858\n",
      "    val_loss       : -1734.6414082845051\n",
      "    val_ess        : 8.001185019810995\n",
      "    val_log_marginal: 1734.6414082845051\n",
      "Train Epoch: 19 [0/54000 (0%)] Loss: -1753.210327\n",
      "Train Epoch: 19 [11264/54000 (21%)] Loss: -1744.818970\n",
      "Train Epoch: 19 [22528/54000 (42%)] Loss: -1719.048584\n",
      "Train Epoch: 19 [33792/54000 (63%)] Loss: -1760.705322\n",
      "Train Epoch: 19 [45056/54000 (83%)] Loss: -1725.148804\n",
      "    epoch          : 19\n",
      "    loss           : -1732.1176942069576\n",
      "    ess            : 8.00118376174063\n",
      "    log_marginal   : 1732.1176919037441\n",
      "    val_loss       : -1739.3992106119792\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1739.3992106119792\n",
      "Train Epoch: 20 [0/54000 (0%)] Loss: -1757.439453\n",
      "Train Epoch: 20 [11264/54000 (21%)] Loss: -1739.859375\n",
      "Train Epoch: 20 [22528/54000 (42%)] Loss: -1722.300049\n",
      "Train Epoch: 20 [33792/54000 (63%)] Loss: -1758.532471\n",
      "Train Epoch: 20 [45056/54000 (83%)] Loss: -1716.852295\n",
      "    epoch          : 20\n",
      "    loss           : -1732.030493394384\n",
      "    ess            : 8.001183455845094\n",
      "    log_marginal   : 1732.030493394384\n",
      "    val_loss       : -1745.8949483235676\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1745.8949483235676\n",
      "Train Epoch: 21 [0/54000 (0%)] Loss: -1762.652100\n",
      "Train Epoch: 21 [11264/54000 (21%)] Loss: -1749.384277\n",
      "Train Epoch: 21 [22528/54000 (42%)] Loss: -1736.576904\n",
      "Train Epoch: 21 [33792/54000 (63%)] Loss: -1766.173584\n",
      "Train Epoch: 21 [45056/54000 (83%)] Loss: -1727.475464\n",
      "    epoch          : 21\n",
      "    loss           : -1741.2815874207695\n",
      "    ess            : 8.001183995660746\n",
      "    log_marginal   : 1741.281585117556\n",
      "    val_loss       : -1747.6231791178386\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1747.6231791178386\n",
      "Train Epoch: 22 [0/54000 (0%)] Loss: -1764.734131\n",
      "Train Epoch: 22 [11264/54000 (21%)] Loss: -1745.675293\n",
      "Train Epoch: 22 [22528/54000 (42%)] Loss: -1722.859497\n",
      "Train Epoch: 22 [33792/54000 (63%)] Loss: -1767.478516\n",
      "Train Epoch: 22 [45056/54000 (83%)] Loss: -1730.437256\n",
      "    epoch          : 22\n",
      "    loss           : -1739.7698940061173\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1739.7698940061173\n",
      "    val_loss       : -1747.1952718098958\n",
      "    val_ess        : 8.001181999842325\n",
      "    val_log_marginal: 1747.1952718098958\n",
      "Train Epoch: 23 [0/54000 (0%)] Loss: -1766.478271\n",
      "Train Epoch: 23 [11264/54000 (21%)] Loss: -1759.961914\n",
      "Train Epoch: 23 [22528/54000 (42%)] Loss: -1721.657959\n",
      "Train Epoch: 23 [33792/54000 (63%)] Loss: -1765.754639\n",
      "Train Epoch: 23 [45056/54000 (83%)] Loss: -1731.761719\n",
      "    epoch          : 23\n",
      "    loss           : -1742.2394708597435\n",
      "    ess            : 8.001183131955704\n",
      "    log_marginal   : 1742.2394708597435\n",
      "    val_loss       : -1745.607421875\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1745.607421875\n",
      "Train Epoch: 24 [0/54000 (0%)] Loss: -1759.957520\n",
      "Train Epoch: 24 [11264/54000 (21%)] Loss: -1755.360962\n",
      "Train Epoch: 24 [22528/54000 (42%)] Loss: -1737.265991\n",
      "Train Epoch: 24 [33792/54000 (63%)] Loss: -1777.604858\n",
      "Train Epoch: 24 [45056/54000 (83%)] Loss: -1739.196777\n",
      "    epoch          : 24\n",
      "    loss           : -1746.4906547114533\n",
      "    ess            : 8.001184157605442\n",
      "    log_marginal   : 1746.4906547114533\n",
      "    val_loss       : -1745.821533203125\n",
      "    val_ess        : 8.001184542973837\n",
      "    val_log_marginal: 1745.821533203125\n",
      "Train Epoch: 25 [0/54000 (0%)] Loss: -1761.070679\n",
      "Train Epoch: 25 [11264/54000 (21%)] Loss: -1751.881470\n",
      "Train Epoch: 25 [22528/54000 (42%)] Loss: -1745.671875\n",
      "Train Epoch: 25 [33792/54000 (63%)] Loss: -1779.927490\n",
      "Train Epoch: 25 [45056/54000 (83%)] Loss: -1708.801514\n",
      "    epoch          : 25\n",
      "    loss           : -1742.8043972951061\n",
      "    ess            : 8.001183797728341\n",
      "    log_marginal   : 1742.8043972951061\n",
      "    val_loss       : -1740.9737141927083\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1740.9737141927083\n",
      "Train Epoch: 26 [0/54000 (0%)] Loss: -1759.145264\n",
      "Train Epoch: 26 [11264/54000 (21%)] Loss: -1751.166992\n",
      "Train Epoch: 26 [22528/54000 (42%)] Loss: -1744.800781\n",
      "Train Epoch: 26 [33792/54000 (63%)] Loss: -1767.696777\n",
      "Train Epoch: 26 [45056/54000 (83%)] Loss: -1725.905518\n",
      "    epoch          : 26\n",
      "    loss           : -1743.9880152288472\n",
      "    ess            : 8.001183536817443\n",
      "    log_marginal   : 1743.988016380454\n",
      "    val_loss       : -1751.309834798177\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1751.309834798177\n",
      "Train Epoch: 27 [0/54000 (0%)] Loss: -1768.762939\n",
      "Train Epoch: 27 [11264/54000 (21%)] Loss: -1769.725342\n",
      "Train Epoch: 27 [22528/54000 (42%)] Loss: -1752.985596\n",
      "Train Epoch: 27 [33792/54000 (63%)] Loss: -1780.235229\n",
      "Train Epoch: 27 [45056/54000 (83%)] Loss: -1719.086914\n",
      "    epoch          : 27\n",
      "    loss           : -1752.7073629127358\n",
      "    ess            : 8.00118325791269\n",
      "    log_marginal   : 1752.707361761129\n",
      "    val_loss       : -1750.6354268391926\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1750.6354268391926\n",
      "Train Epoch: 28 [0/54000 (0%)] Loss: -1764.818359\n",
      "Train Epoch: 28 [11264/54000 (21%)] Loss: -1768.177002\n",
      "Train Epoch: 28 [22528/54000 (42%)] Loss: -1727.945435\n",
      "Train Epoch: 28 [33792/54000 (63%)] Loss: -1757.574707\n",
      "Train Epoch: 28 [45056/54000 (83%)] Loss: -1727.435181\n",
      "    epoch          : 28\n",
      "    loss           : -1744.6658682193397\n",
      "    ess            : 8.001184247574717\n",
      "    log_marginal   : 1744.6658682193397\n",
      "    val_loss       : -1752.7821756998699\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1752.7821655273438\n",
      "Train Epoch: 29 [0/54000 (0%)] Loss: -1767.672119\n",
      "Train Epoch: 29 [11264/54000 (21%)] Loss: -1774.289551\n",
      "Train Epoch: 29 [22528/54000 (42%)] Loss: -1734.295410\n",
      "Train Epoch: 29 [33792/54000 (63%)] Loss: -1781.207031\n",
      "Train Epoch: 29 [45056/54000 (83%)] Loss: -1745.662476\n",
      "    epoch          : 29\n",
      "    loss           : -1751.9070895213001\n",
      "    ess            : 8.001184256571644\n",
      "    log_marginal   : 1751.9070895213001\n",
      "    val_loss       : -1744.8135681152344\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1744.8135681152344\n",
      "Train Epoch: 30 [0/54000 (0%)] Loss: -1759.052490\n",
      "Train Epoch: 30 [11264/54000 (21%)] Loss: -1772.497314\n",
      "Train Epoch: 30 [22528/54000 (42%)] Loss: -1750.289429\n",
      "Train Epoch: 30 [33792/54000 (63%)] Loss: -1773.487793\n",
      "Train Epoch: 30 [45056/54000 (83%)] Loss: -1749.882324\n",
      "    epoch          : 30\n",
      "    loss           : -1755.041388745578\n",
      "    ess            : 8.001184895353497\n",
      "    log_marginal   : 1755.0413898971844\n",
      "    val_loss       : -1750.3635660807292\n",
      "    val_ess        : 8.001185178756714\n",
      "    val_log_marginal: 1750.3635660807292\n",
      "Train Epoch: 31 [0/54000 (0%)] Loss: -1766.322876\n",
      "Train Epoch: 31 [11264/54000 (21%)] Loss: -1779.508301\n",
      "Train Epoch: 31 [22528/54000 (42%)] Loss: -1749.753906\n",
      "Train Epoch: 31 [33792/54000 (63%)] Loss: -1785.069824\n",
      "Train Epoch: 31 [45056/54000 (83%)] Loss: -1735.608154\n",
      "    epoch          : 31\n",
      "    loss           : -1755.1247282208137\n",
      "    ess            : 8.001184346540919\n",
      "    log_marginal   : 1755.1247282208137\n",
      "    val_loss       : -1754.1703796386719\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1754.170389811198\n",
      "Train Epoch: 32 [0/54000 (0%)] Loss: -1770.675049\n",
      "Train Epoch: 32 [11264/54000 (21%)] Loss: -1783.293945\n",
      "Train Epoch: 32 [22528/54000 (42%)] Loss: -1748.352539\n",
      "Train Epoch: 32 [33792/54000 (63%)] Loss: -1787.441284\n",
      "Train Epoch: 32 [45056/54000 (83%)] Loss: -1735.224854\n",
      "    epoch          : 32\n",
      "    loss           : -1758.0796716078273\n",
      "    ess            : 8.001183779734486\n",
      "    log_marginal   : 1758.0796716078273\n",
      "    val_loss       : -1756.0084940592449\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1756.0084940592449\n",
      "Train Epoch: 33 [0/54000 (0%)] Loss: -1772.978271\n",
      "Train Epoch: 33 [11264/54000 (21%)] Loss: -1764.137329\n",
      "Train Epoch: 33 [22528/54000 (42%)] Loss: -1737.179810\n",
      "Train Epoch: 33 [33792/54000 (63%)] Loss: -1783.922852\n",
      "Train Epoch: 33 [45056/54000 (83%)] Loss: -1729.991699\n",
      "    epoch          : 33\n",
      "    loss           : -1748.9587206570607\n",
      "    ess            : 8.001184562467179\n",
      "    log_marginal   : 1748.958719505454\n",
      "    val_loss       : -1749.2159322102864\n",
      "    val_ess        : 8.001185894012451\n",
      "    val_log_marginal: 1749.2159322102864\n",
      "Train Epoch: 34 [0/54000 (0%)] Loss: -1768.690063\n",
      "Train Epoch: 34 [11264/54000 (21%)] Loss: -1770.185791\n",
      "Train Epoch: 34 [22528/54000 (42%)] Loss: -1744.844238\n",
      "Train Epoch: 34 [33792/54000 (63%)] Loss: -1785.409546\n",
      "Train Epoch: 34 [45056/54000 (83%)] Loss: -1745.918335\n",
      "    epoch          : 34\n",
      "    loss           : -1752.4180240271226\n",
      "    ess            : 8.00118394167918\n",
      "    log_marginal   : 1752.4180240271226\n",
      "    val_loss       : -1759.4063008626301\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1759.4063008626301\n",
      "Train Epoch: 35 [0/54000 (0%)] Loss: -1777.761353\n",
      "Train Epoch: 35 [11264/54000 (21%)] Loss: -1780.925293\n",
      "Train Epoch: 35 [22528/54000 (42%)] Loss: -1759.291748\n",
      "Train Epoch: 35 [33792/54000 (63%)] Loss: -1789.630249\n",
      "Train Epoch: 35 [45056/54000 (83%)] Loss: -1742.758789\n",
      "    epoch          : 35\n",
      "    loss           : -1762.90094915426\n",
      "    ess            : 8.001183500829733\n",
      "    log_marginal   : 1762.90094915426\n",
      "    val_loss       : -1764.3872375488281\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1764.3872375488281\n",
      "Train Epoch: 36 [0/54000 (0%)] Loss: -1779.624756\n",
      "Train Epoch: 36 [11264/54000 (21%)] Loss: -1780.018066\n",
      "Train Epoch: 36 [22528/54000 (42%)] Loss: -1739.064819\n",
      "Train Epoch: 36 [33792/54000 (63%)] Loss: -1777.513550\n",
      "Train Epoch: 36 [45056/54000 (83%)] Loss: -1756.405518\n",
      "    epoch          : 36\n",
      "    loss           : -1760.553797308004\n",
      "    ess            : 8.001184148608514\n",
      "    log_marginal   : 1760.553797308004\n",
      "    val_loss       : -1774.2925618489583\n",
      "    val_ess        : 8.001184066136679\n",
      "    val_log_marginal: 1774.2925618489583\n",
      "Train Epoch: 37 [0/54000 (0%)] Loss: -1788.653809\n",
      "Train Epoch: 37 [11264/54000 (21%)] Loss: -1787.256836\n",
      "Train Epoch: 37 [22528/54000 (42%)] Loss: -1756.397949\n",
      "Train Epoch: 37 [33792/54000 (63%)] Loss: -1781.969971\n",
      "Train Epoch: 37 [45056/54000 (83%)] Loss: -1760.548340\n",
      "    epoch          : 37\n",
      "    loss           : -1767.4264860333137\n",
      "    ess            : 8.0011823132353\n",
      "    log_marginal   : 1767.4264860333137\n",
      "    val_loss       : -1764.3626302083333\n",
      "    val_ess        : 8.001184622446695\n",
      "    val_log_marginal: 1764.3626302083333\n",
      "Train Epoch: 38 [0/54000 (0%)] Loss: -1777.770508\n",
      "Train Epoch: 38 [11264/54000 (21%)] Loss: -1779.381592\n",
      "Train Epoch: 38 [22528/54000 (42%)] Loss: -1765.723267\n",
      "Train Epoch: 38 [33792/54000 (63%)] Loss: -1786.211914\n",
      "Train Epoch: 38 [45056/54000 (83%)] Loss: -1731.540283\n",
      "    epoch          : 38\n",
      "    loss           : -1759.1586937094635\n",
      "    ess            : 8.001183023992574\n",
      "    log_marginal   : 1759.1586937094635\n",
      "    val_loss       : -1756.6942443847656\n",
      "    val_ess        : 8.001184622446695\n",
      "    val_log_marginal: 1756.6942443847656\n",
      "Train Epoch: 39 [0/54000 (0%)] Loss: -1771.002686\n",
      "Train Epoch: 39 [11264/54000 (21%)] Loss: -1747.463867\n",
      "Train Epoch: 39 [22528/54000 (42%)] Loss: -1738.472412\n",
      "Train Epoch: 39 [33792/54000 (63%)] Loss: -1744.606689\n",
      "Train Epoch: 39 [45056/54000 (83%)] Loss: -1741.372314\n",
      "    epoch          : 39\n",
      "    loss           : -1743.5602992795548\n",
      "    ess            : 8.001185354196801\n",
      "    log_marginal   : 1743.5603004311615\n",
      "    val_loss       : -1770.1754455566406\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1770.1754455566406\n",
      "Train Epoch: 40 [0/54000 (0%)] Loss: -1784.769775\n",
      "Train Epoch: 40 [11264/54000 (21%)] Loss: -1776.658447\n",
      "Train Epoch: 40 [22528/54000 (42%)] Loss: -1757.305664\n",
      "Train Epoch: 40 [33792/54000 (63%)] Loss: -1778.208374\n",
      "Train Epoch: 40 [45056/54000 (83%)] Loss: -1747.210205\n",
      "    epoch          : 40\n",
      "    loss           : -1761.046552550118\n",
      "    ess            : 8.001185039304337\n",
      "    log_marginal   : 1761.046552550118\n",
      "    val_loss       : -1768.1080220540364\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1768.1080220540364\n",
      "Train Epoch: 41 [0/54000 (0%)] Loss: -1784.318481\n",
      "Train Epoch: 41 [11264/54000 (21%)] Loss: -1778.213501\n",
      "Train Epoch: 41 [22528/54000 (42%)] Loss: -1754.809814\n",
      "Train Epoch: 41 [33792/54000 (63%)] Loss: -1763.943848\n",
      "Train Epoch: 41 [45056/54000 (83%)] Loss: -1749.928955\n",
      "    epoch          : 41\n",
      "    loss           : -1758.871288371536\n",
      "    ess            : 8.001184895353497\n",
      "    log_marginal   : 1758.8712872199292\n",
      "    val_loss       : -1767.8734232584636\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1767.8734130859375\n",
      "Train Epoch: 42 [0/54000 (0%)] Loss: -1782.492920\n",
      "Train Epoch: 42 [11264/54000 (21%)] Loss: -1784.836914\n",
      "Train Epoch: 42 [22528/54000 (42%)] Loss: -1770.300659\n",
      "Train Epoch: 42 [33792/54000 (63%)] Loss: -1785.048218\n",
      "Train Epoch: 42 [45056/54000 (83%)] Loss: -1752.815430\n",
      "    epoch          : 42\n",
      "    loss           : -1766.3530411630306\n",
      "    ess            : 8.00118492234428\n",
      "    log_marginal   : 1766.353040011424\n",
      "    val_loss       : -1762.1668395996094\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1762.1668192545574\n",
      "Train Epoch: 43 [0/54000 (0%)] Loss: -1773.403564\n",
      "Train Epoch: 43 [11264/54000 (21%)] Loss: -1771.395630\n",
      "Train Epoch: 43 [22528/54000 (42%)] Loss: -1758.388428\n",
      "Train Epoch: 43 [33792/54000 (63%)] Loss: -1773.798584\n",
      "Train Epoch: 43 [45056/54000 (83%)] Loss: -1759.398071\n",
      "    epoch          : 43\n",
      "    loss           : -1761.0624562389446\n",
      "    ess            : 8.001185471156859\n",
      "    log_marginal   : 1761.0624562389446\n",
      "    val_loss       : -1761.6478576660156\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1761.6478271484375\n",
      "Train Epoch: 44 [0/54000 (0%)] Loss: -1775.313843\n",
      "Train Epoch: 44 [11264/54000 (21%)] Loss: -1776.551758\n",
      "Train Epoch: 44 [22528/54000 (42%)] Loss: -1768.776001\n",
      "Train Epoch: 44 [33792/54000 (63%)] Loss: -1775.957275\n",
      "Train Epoch: 44 [45056/54000 (83%)] Loss: -1756.966187\n",
      "    epoch          : 44\n",
      "    loss           : -1763.88309003722\n",
      "    ess            : 8.001184625445672\n",
      "    log_marginal   : 1763.88309003722\n",
      "    val_loss       : -1765.1946207682292\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1765.1946207682292\n",
      "Train Epoch: 45 [0/54000 (0%)] Loss: -1781.052856\n",
      "Train Epoch: 45 [11264/54000 (21%)] Loss: -1758.711670\n",
      "Train Epoch: 45 [22528/54000 (42%)] Loss: -1766.350952\n",
      "Train Epoch: 45 [33792/54000 (63%)] Loss: -1761.400146\n",
      "Train Epoch: 45 [45056/54000 (83%)] Loss: -1755.685669\n",
      "    epoch          : 45\n",
      "    loss           : -1759.3286766196197\n",
      "    ess            : 8.00118531820909\n",
      "    log_marginal   : 1759.3286777712265\n",
      "    val_loss       : -1772.6352640787761\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1772.6352437337239\n",
      "Train Epoch: 46 [0/54000 (0%)] Loss: -1785.792480\n",
      "Train Epoch: 46 [11264/54000 (21%)] Loss: -1753.526611\n",
      "Train Epoch: 46 [22528/54000 (42%)] Loss: -1768.727539\n",
      "Train Epoch: 46 [33792/54000 (63%)] Loss: -1769.720947\n",
      "Train Epoch: 46 [45056/54000 (83%)] Loss: -1763.770752\n",
      "    epoch          : 46\n",
      "    loss           : -1763.5407853036556\n",
      "    ess            : 8.001184913347352\n",
      "    log_marginal   : 1763.5407853036556\n",
      "    val_loss       : -1767.7688802083333\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1767.7688802083333\n",
      "Train Epoch: 47 [0/54000 (0%)] Loss: -1782.294189\n",
      "Train Epoch: 47 [11264/54000 (21%)] Loss: -1765.317139\n",
      "Train Epoch: 47 [22528/54000 (42%)] Loss: -1774.577148\n",
      "Train Epoch: 47 [33792/54000 (63%)] Loss: -1790.735107\n",
      "Train Epoch: 47 [45056/54000 (83%)] Loss: -1766.862549\n",
      "    epoch          : 47\n",
      "    loss           : -1768.5462945902123\n",
      "    ess            : 8.001184463500977\n",
      "    log_marginal   : 1768.546295741819\n",
      "    val_loss       : -1773.7957967122395\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1773.7957763671875\n",
      "Train Epoch: 48 [0/54000 (0%)] Loss: -1791.571777\n",
      "Train Epoch: 48 [11264/54000 (21%)] Loss: -1781.234619\n",
      "Train Epoch: 48 [22528/54000 (42%)] Loss: -1760.295654\n",
      "Train Epoch: 48 [33792/54000 (63%)] Loss: -1786.879150\n",
      "Train Epoch: 48 [45056/54000 (83%)] Loss: -1767.630127\n",
      "    epoch          : 48\n",
      "    loss           : -1770.4499995393573\n",
      "    ess            : 8.001184913347352\n",
      "    log_marginal   : 1770.4499995393573\n",
      "    val_loss       : -1782.0296325683594\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1782.0296325683594\n",
      "Train Epoch: 49 [0/54000 (0%)] Loss: -1798.790161\n",
      "Train Epoch: 49 [11264/54000 (21%)] Loss: -1778.212402\n",
      "Train Epoch: 49 [22528/54000 (42%)] Loss: -1770.492920\n",
      "Train Epoch: 49 [33792/54000 (63%)] Loss: -1772.010254\n",
      "Train Epoch: 49 [45056/54000 (83%)] Loss: -1761.419434\n",
      "    epoch          : 49\n",
      "    loss           : -1766.3878542342277\n",
      "    ess            : 8.001184949335062\n",
      "    log_marginal   : 1766.3878542342277\n",
      "    val_loss       : -1762.0271708170574\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1762.0271708170574\n",
      "Train Epoch: 50 [0/54000 (0%)] Loss: -1778.739746\n",
      "Train Epoch: 50 [11264/54000 (21%)] Loss: -1767.910400\n",
      "Train Epoch: 50 [22528/54000 (42%)] Loss: -1764.806274\n",
      "Train Epoch: 50 [33792/54000 (63%)] Loss: -1782.429688\n",
      "Train Epoch: 50 [45056/54000 (83%)] Loss: -1760.178711\n",
      "    epoch          : 50\n",
      "    loss           : -1762.9677342828716\n",
      "    ess            : 8.001184877359643\n",
      "    log_marginal   : 1762.9677331312648\n",
      "    val_loss       : -1771.0170491536458\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1771.017069498698\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch50.pth ...\n",
      "Train Epoch: 51 [0/54000 (0%)] Loss: -1784.929932\n",
      "Train Epoch: 51 [11264/54000 (21%)] Loss: -1777.210083\n",
      "Train Epoch: 51 [22528/54000 (42%)] Loss: -1765.677490\n",
      "Train Epoch: 51 [33792/54000 (63%)] Loss: -1777.367188\n",
      "Train Epoch: 51 [45056/54000 (83%)] Loss: -1755.527100\n",
      "    epoch          : 51\n",
      "    loss           : -1764.0570310196786\n",
      "    ess            : 8.001185057298192\n",
      "    log_marginal   : 1764.0570321712853\n",
      "    val_loss       : -1757.8666890462239\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1757.8666890462239\n",
      "Train Epoch: 52 [0/54000 (0%)] Loss: -1775.312622\n",
      "Train Epoch: 52 [11264/54000 (21%)] Loss: -1783.299683\n",
      "Train Epoch: 52 [22528/54000 (42%)] Loss: -1772.337280\n",
      "Train Epoch: 52 [33792/54000 (63%)] Loss: -1792.494873\n",
      "Train Epoch: 52 [45056/54000 (83%)] Loss: -1768.656372\n",
      "    epoch          : 52\n",
      "    loss           : -1772.470574145047\n",
      "    ess            : 8.001184427513266\n",
      "    log_marginal   : 1772.470574145047\n",
      "    val_loss       : -1770.4810994466145\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1770.4810994466145\n",
      "Train Epoch: 53 [0/54000 (0%)] Loss: -1785.513916\n",
      "Train Epoch: 53 [11264/54000 (21%)] Loss: -1794.457397\n",
      "Train Epoch: 53 [22528/54000 (42%)] Loss: -1771.964722\n",
      "Train Epoch: 53 [33792/54000 (63%)] Loss: -1793.942261\n",
      "Train Epoch: 53 [45056/54000 (83%)] Loss: -1766.544312\n",
      "    epoch          : 53\n",
      "    loss           : -1776.334745587043\n",
      "    ess            : 8.00118383371605\n",
      "    log_marginal   : 1776.334745587043\n",
      "    val_loss       : -1778.7660624186199\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1778.7660624186199\n",
      "Train Epoch: 54 [0/54000 (0%)] Loss: -1791.973145\n",
      "Train Epoch: 54 [11264/54000 (21%)] Loss: -1788.023682\n",
      "Train Epoch: 54 [22528/54000 (42%)] Loss: -1765.291504\n",
      "Train Epoch: 54 [33792/54000 (63%)] Loss: -1794.603027\n",
      "Train Epoch: 54 [45056/54000 (83%)] Loss: -1769.106445\n",
      "    epoch          : 54\n",
      "    loss           : -1774.2657919829746\n",
      "    ess            : 8.00118343785124\n",
      "    log_marginal   : 1774.2657919829746\n",
      "    val_loss       : -1777.3936462402344\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1777.3936360677083\n",
      "Train Epoch: 55 [0/54000 (0%)] Loss: -1790.937500\n",
      "Train Epoch: 55 [11264/54000 (21%)] Loss: -1785.232544\n",
      "Train Epoch: 55 [22528/54000 (42%)] Loss: -1773.339722\n",
      "Train Epoch: 55 [33792/54000 (63%)] Loss: -1800.244385\n",
      "Train Epoch: 55 [45056/54000 (83%)] Loss: -1754.455811\n",
      "    epoch          : 55\n",
      "    loss           : -1774.7414988391804\n",
      "    ess            : 8.00118354581437\n",
      "    log_marginal   : 1774.7414988391804\n",
      "    val_loss       : -1780.9414469401042\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1780.9414672851562\n",
      "Train Epoch: 56 [0/54000 (0%)] Loss: -1790.849365\n",
      "Train Epoch: 56 [11264/54000 (21%)] Loss: -1797.321533\n",
      "Train Epoch: 56 [22528/54000 (42%)] Loss: -1775.522461\n",
      "Train Epoch: 56 [33792/54000 (63%)] Loss: -1792.980103\n",
      "Train Epoch: 56 [45056/54000 (83%)] Loss: -1759.763672\n",
      "    epoch          : 56\n",
      "    loss           : -1775.9907963590802\n",
      "    ess            : 8.001183905691471\n",
      "    log_marginal   : 1775.9907963590802\n",
      "    val_loss       : -1783.5867309570312\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1783.5867207845051\n",
      "Train Epoch: 57 [0/54000 (0%)] Loss: -1795.569580\n",
      "Train Epoch: 57 [11264/54000 (21%)] Loss: -1791.338745\n",
      "Train Epoch: 57 [22528/54000 (42%)] Loss: -1768.619751\n",
      "Train Epoch: 57 [33792/54000 (63%)] Loss: -1789.671997\n",
      "Train Epoch: 57 [45056/54000 (83%)] Loss: -1760.815308\n",
      "    epoch          : 57\n",
      "    loss           : -1773.8037420308815\n",
      "    ess            : 8.0011842745655\n",
      "    log_marginal   : 1773.8037420308815\n",
      "    val_loss       : -1777.8797607421875\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1777.8797607421875\n",
      "Train Epoch: 58 [0/54000 (0%)] Loss: -1789.685791\n",
      "Train Epoch: 58 [11264/54000 (21%)] Loss: -1774.980713\n",
      "Train Epoch: 58 [22528/54000 (42%)] Loss: -1759.875732\n",
      "Train Epoch: 58 [33792/54000 (63%)] Loss: -1784.186523\n",
      "Train Epoch: 58 [45056/54000 (83%)] Loss: -1752.244629\n",
      "    epoch          : 58\n",
      "    loss           : -1764.8491798256928\n",
      "    ess            : 8.001185084288975\n",
      "    log_marginal   : 1764.8491775224793\n",
      "    val_loss       : -1772.6653340657551\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1772.6653340657551\n",
      "Train Epoch: 59 [0/54000 (0%)] Loss: -1787.746826\n",
      "Train Epoch: 59 [11264/54000 (21%)] Loss: -1783.784180\n",
      "Train Epoch: 59 [22528/54000 (42%)] Loss: -1762.422363\n",
      "Train Epoch: 59 [33792/54000 (63%)] Loss: -1783.622314\n",
      "Train Epoch: 59 [45056/54000 (83%)] Loss: -1742.442139\n",
      "    epoch          : 59\n",
      "    loss           : -1764.2608181935436\n",
      "    ess            : 8.001185453163004\n",
      "    log_marginal   : 1764.2608181935436\n",
      "    val_loss       : -1778.3841552734375\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1778.3841552734375\n",
      "Train Epoch: 60 [0/54000 (0%)] Loss: -1790.148071\n",
      "Train Epoch: 60 [11264/54000 (21%)] Loss: -1791.501953\n",
      "Train Epoch: 60 [22528/54000 (42%)] Loss: -1780.395020\n",
      "Train Epoch: 60 [33792/54000 (63%)] Loss: -1795.809326\n",
      "Train Epoch: 60 [45056/54000 (83%)] Loss: -1760.628174\n",
      "    epoch          : 60\n",
      "    loss           : -1778.0198306677476\n",
      "    ess            : 8.001184823378077\n",
      "    log_marginal   : 1778.0198306677476\n",
      "    val_loss       : -1786.3836364746094\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1786.3836364746094\n",
      "Train Epoch: 61 [0/54000 (0%)] Loss: -1795.555542\n",
      "Train Epoch: 61 [11264/54000 (21%)] Loss: -1774.673096\n",
      "Train Epoch: 61 [22528/54000 (42%)] Loss: -1765.908691\n",
      "Train Epoch: 61 [33792/54000 (63%)] Loss: -1778.438843\n",
      "Train Epoch: 61 [45056/54000 (83%)] Loss: -1764.064697\n",
      "    epoch          : 61\n",
      "    loss           : -1769.1424030807782\n",
      "    ess            : 8.001185291218308\n",
      "    log_marginal   : 1769.1424030807782\n",
      "    val_loss       : -1784.325419108073\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1784.325419108073\n",
      "Train Epoch: 62 [0/54000 (0%)] Loss: -1797.129517\n",
      "Train Epoch: 62 [11264/54000 (21%)] Loss: -1770.054199\n",
      "Train Epoch: 62 [22528/54000 (42%)] Loss: -1753.308228\n",
      "Train Epoch: 62 [33792/54000 (63%)] Loss: -1776.191895\n",
      "Train Epoch: 62 [45056/54000 (83%)] Loss: -1755.809570\n",
      "    epoch          : 62\n",
      "    loss           : -1760.4079394070607\n",
      "    ess            : 8.001185894012451\n",
      "    log_marginal   : 1760.4079394070607\n",
      "    val_loss       : -1771.5606180826824\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1771.5606180826824\n",
      "Train Epoch: 63 [0/54000 (0%)] Loss: -1781.750244\n",
      "Train Epoch: 63 [11264/54000 (21%)] Loss: -1785.866577\n",
      "Train Epoch: 63 [22528/54000 (42%)] Loss: -1770.300049\n",
      "Train Epoch: 63 [33792/54000 (63%)] Loss: -1781.288818\n",
      "Train Epoch: 63 [45056/54000 (83%)] Loss: -1759.669189\n",
      "    epoch          : 63\n",
      "    loss           : -1767.8599980192364\n",
      "    ess            : 8.001185687083119\n",
      "    log_marginal   : 1767.8599980192364\n",
      "    val_loss       : -1780.6290690104167\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1780.6290588378906\n",
      "Train Epoch: 64 [0/54000 (0%)] Loss: -1791.714600\n",
      "Train Epoch: 64 [11264/54000 (21%)] Loss: -1795.317017\n",
      "Train Epoch: 64 [22528/54000 (42%)] Loss: -1781.794434\n",
      "Train Epoch: 64 [33792/54000 (63%)] Loss: -1796.566406\n",
      "Train Epoch: 64 [45056/54000 (83%)] Loss: -1776.162109\n",
      "    epoch          : 64\n",
      "    loss           : -1782.1137234669811\n",
      "    ess            : 8.001185489150712\n",
      "    log_marginal   : 1782.1137234669811\n",
      "    val_loss       : -1780.2756856282551\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1780.2756958007812\n",
      "Train Epoch: 65 [0/54000 (0%)] Loss: -1791.457031\n",
      "Train Epoch: 65 [11264/54000 (21%)] Loss: -1795.846802\n",
      "Train Epoch: 65 [22528/54000 (42%)] Loss: -1780.980103\n",
      "Train Epoch: 65 [33792/54000 (63%)] Loss: -1802.323608\n",
      "Train Epoch: 65 [45056/54000 (83%)] Loss: -1773.017578\n",
      "    epoch          : 65\n",
      "    loss           : -1780.435848595961\n",
      "    ess            : 8.001185363193727\n",
      "    log_marginal   : 1780.4358497475678\n",
      "    val_loss       : -1780.5932006835938\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1780.5932108561199\n",
      "Train Epoch: 66 [0/54000 (0%)] Loss: -1792.683228\n",
      "Train Epoch: 66 [11264/54000 (21%)] Loss: -1792.983398\n",
      "Train Epoch: 66 [22528/54000 (42%)] Loss: -1772.093994\n",
      "Train Epoch: 66 [33792/54000 (63%)] Loss: -1790.277222\n",
      "Train Epoch: 66 [45056/54000 (83%)] Loss: -1768.990234\n",
      "    epoch          : 66\n",
      "    loss           : -1775.9079037072524\n",
      "    ess            : 8.001185525138423\n",
      "    log_marginal   : 1775.9079037072524\n",
      "    val_loss       : -1777.0970967610676\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1777.0970967610676\n",
      "Train Epoch: 67 [0/54000 (0%)] Loss: -1790.448242\n",
      "Train Epoch: 67 [11264/54000 (21%)] Loss: -1789.540283\n",
      "Train Epoch: 67 [22528/54000 (42%)] Loss: -1765.767578\n",
      "Train Epoch: 67 [33792/54000 (63%)] Loss: -1790.595215\n",
      "Train Epoch: 67 [45056/54000 (83%)] Loss: -1772.757690\n",
      "    epoch          : 67\n",
      "    loss           : -1771.911790379938\n",
      "    ess            : 8.001185147267467\n",
      "    log_marginal   : 1771.911790379938\n",
      "    val_loss       : -1780.817891438802\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1780.817891438802\n",
      "Train Epoch: 68 [0/54000 (0%)] Loss: -1791.117188\n",
      "Train Epoch: 68 [11264/54000 (21%)] Loss: -1790.926025\n",
      "Train Epoch: 68 [22528/54000 (42%)] Loss: -1769.101074\n",
      "Train Epoch: 68 [33792/54000 (63%)] Loss: -1796.999268\n",
      "Train Epoch: 68 [45056/54000 (83%)] Loss: -1771.023438\n",
      "    epoch          : 68\n",
      "    loss           : -1772.626216096698\n",
      "    ess            : 8.001185183255178\n",
      "    log_marginal   : 1772.6262172483048\n",
      "    val_loss       : -1749.1834411621094\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1749.1834411621094\n",
      "Train Epoch: 69 [0/54000 (0%)] Loss: -1758.076416\n",
      "Train Epoch: 69 [11264/54000 (21%)] Loss: -1778.761475\n",
      "Train Epoch: 69 [22528/54000 (42%)] Loss: -1754.899414\n",
      "Train Epoch: 69 [33792/54000 (63%)] Loss: -1782.868652\n",
      "Train Epoch: 69 [45056/54000 (83%)] Loss: -1767.649170\n",
      "    epoch          : 69\n",
      "    loss           : -1765.1238506964917\n",
      "    ess            : 8.00118549814764\n",
      "    log_marginal   : 1765.1238518480984\n",
      "    val_loss       : -1773.5860188802083\n",
      "    val_ess        : 8.001185973485311\n",
      "    val_log_marginal: 1773.5860087076824\n",
      "Train Epoch: 70 [0/54000 (0%)] Loss: -1785.327148\n",
      "Train Epoch: 70 [11264/54000 (21%)] Loss: -1780.837402\n",
      "Train Epoch: 70 [22528/54000 (42%)] Loss: -1767.792725\n",
      "Train Epoch: 70 [33792/54000 (63%)] Loss: -1795.453003\n",
      "Train Epoch: 70 [45056/54000 (83%)] Loss: -1768.254150\n",
      "    epoch          : 70\n",
      "    loss           : -1773.5835191258843\n",
      "    ess            : 8.00118539018451\n",
      "    log_marginal   : 1773.5835191258843\n",
      "    val_loss       : -1769.8455098470051\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1769.8455098470051\n",
      "Train Epoch: 71 [0/54000 (0%)] Loss: -1784.185547\n",
      "Train Epoch: 71 [11264/54000 (21%)] Loss: -1790.726562\n",
      "Train Epoch: 71 [22528/54000 (42%)] Loss: -1770.932861\n",
      "Train Epoch: 71 [33792/54000 (63%)] Loss: -1801.811523\n",
      "Train Epoch: 71 [45056/54000 (83%)] Loss: -1771.142822\n",
      "    epoch          : 71\n",
      "    loss           : -1778.6144363115418\n",
      "    ess            : 8.001185201249033\n",
      "    log_marginal   : 1778.6144363115418\n",
      "    val_loss       : -1781.4400736490886\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1781.4400736490886\n",
      "Train Epoch: 72 [0/54000 (0%)] Loss: -1793.104858\n",
      "Train Epoch: 72 [11264/54000 (21%)] Loss: -1792.570312\n",
      "Train Epoch: 72 [22528/54000 (42%)] Loss: -1774.546265\n",
      "Train Epoch: 72 [33792/54000 (63%)] Loss: -1792.590088\n",
      "Train Epoch: 72 [45056/54000 (83%)] Loss: -1770.581421\n",
      "    epoch          : 72\n",
      "    loss           : -1778.0982804208431\n",
      "    ess            : 8.001185345199874\n",
      "    log_marginal   : 1778.0982804208431\n",
      "    val_loss       : -1780.1902872721355\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1780.1902974446614\n",
      "Train Epoch: 73 [0/54000 (0%)] Loss: -1791.491211\n",
      "Train Epoch: 73 [11264/54000 (21%)] Loss: -1796.752930\n",
      "Train Epoch: 73 [22528/54000 (42%)] Loss: -1773.719727\n",
      "Train Epoch: 73 [33792/54000 (63%)] Loss: -1794.412476\n",
      "Train Epoch: 73 [45056/54000 (83%)] Loss: -1771.875488\n",
      "    epoch          : 73\n",
      "    loss           : -1779.479318294885\n",
      "    ess            : 8.001185075292048\n",
      "    log_marginal   : 1779.479318294885\n",
      "    val_loss       : -1787.3100484212239\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1787.3100484212239\n",
      "Train Epoch: 74 [0/54000 (0%)] Loss: -1796.990234\n",
      "Train Epoch: 74 [11264/54000 (21%)] Loss: -1791.524536\n",
      "Train Epoch: 74 [22528/54000 (42%)] Loss: -1764.125244\n",
      "Train Epoch: 74 [33792/54000 (63%)] Loss: -1794.245361\n",
      "Train Epoch: 74 [45056/54000 (83%)] Loss: -1759.494385\n",
      "    epoch          : 74\n",
      "    loss           : -1772.4732504790684\n",
      "    ess            : 8.001185219242888\n",
      "    log_marginal   : 1772.4732504790684\n",
      "    val_loss       : -1777.0148111979167\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1777.0148111979167\n",
      "Train Epoch: 75 [0/54000 (0%)] Loss: -1788.247070\n",
      "Train Epoch: 75 [11264/54000 (21%)] Loss: -1791.467651\n",
      "Train Epoch: 75 [22528/54000 (42%)] Loss: -1775.315918\n",
      "Train Epoch: 75 [33792/54000 (63%)] Loss: -1799.976562\n",
      "Train Epoch: 75 [45056/54000 (83%)] Loss: -1772.960938\n",
      "    epoch          : 75\n",
      "    loss           : -1778.403577120799\n",
      "    ess            : 8.001185903009379\n",
      "    log_marginal   : 1778.4035759691922\n",
      "    val_loss       : -1787.7664794921875\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1787.7664794921875\n",
      "Train Epoch: 76 [0/54000 (0%)] Loss: -1800.284912\n",
      "Train Epoch: 76 [11264/54000 (21%)] Loss: -1798.476685\n",
      "Train Epoch: 76 [22528/54000 (42%)] Loss: -1783.504395\n",
      "Train Epoch: 76 [33792/54000 (63%)] Loss: -1797.275757\n",
      "Train Epoch: 76 [45056/54000 (83%)] Loss: -1764.517456\n",
      "    epoch          : 76\n",
      "    loss           : -1781.345967994546\n",
      "    ess            : 8.001185597113842\n",
      "    log_marginal   : 1781.345967994546\n",
      "    val_loss       : -1788.7366536458333\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1788.7366536458333\n",
      "Train Epoch: 77 [0/54000 (0%)] Loss: -1799.056885\n",
      "Train Epoch: 77 [11264/54000 (21%)] Loss: -1798.176025\n",
      "Train Epoch: 77 [22528/54000 (42%)] Loss: -1779.447754\n",
      "Train Epoch: 77 [33792/54000 (63%)] Loss: -1807.691284\n",
      "Train Epoch: 77 [45056/54000 (83%)] Loss: -1777.018555\n",
      "    epoch          : 77\n",
      "    loss           : -1785.3702254385319\n",
      "    ess            : 8.001185570123061\n",
      "    log_marginal   : 1785.3702254385319\n",
      "    val_loss       : -1793.275126139323\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1793.275126139323\n",
      "Train Epoch: 78 [0/54000 (0%)] Loss: -1802.884399\n",
      "Train Epoch: 78 [11264/54000 (21%)] Loss: -1797.520386\n",
      "Train Epoch: 78 [22528/54000 (42%)] Loss: -1771.635010\n",
      "Train Epoch: 78 [33792/54000 (63%)] Loss: -1801.366699\n",
      "Train Epoch: 78 [45056/54000 (83%)] Loss: -1763.688721\n",
      "    epoch          : 78\n",
      "    loss           : -1782.2175857256043\n",
      "    ess            : 8.001185435169148\n",
      "    log_marginal   : 1782.217586877211\n",
      "    val_loss       : -1786.7377217610676\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1786.7377217610676\n",
      "Train Epoch: 79 [0/54000 (0%)] Loss: -1797.410400\n",
      "Train Epoch: 79 [11264/54000 (21%)] Loss: -1800.537354\n",
      "Train Epoch: 79 [22528/54000 (42%)] Loss: -1776.968018\n",
      "Train Epoch: 79 [33792/54000 (63%)] Loss: -1797.273438\n",
      "Train Epoch: 79 [45056/54000 (83%)] Loss: -1767.591797\n",
      "    epoch          : 79\n",
      "    loss           : -1778.694981988871\n",
      "    ess            : 8.001184787390367\n",
      "    log_marginal   : 1778.694981988871\n",
      "    val_loss       : -1765.0008443196614\n",
      "    val_ess        : 8.001185894012451\n",
      "    val_log_marginal: 1765.0008443196614\n",
      "Train Epoch: 80 [0/54000 (0%)] Loss: -1776.645996\n",
      "Train Epoch: 80 [11264/54000 (21%)] Loss: -1779.949463\n",
      "Train Epoch: 80 [22528/54000 (42%)] Loss: -1751.682617\n",
      "Train Epoch: 80 [33792/54000 (63%)] Loss: -1783.546631\n",
      "Train Epoch: 80 [45056/54000 (83%)] Loss: -1749.331787\n",
      "    epoch          : 80\n",
      "    loss           : -1763.2478718307782\n",
      "    ess            : 8.001185417175293\n",
      "    log_marginal   : 1763.2478718307782\n",
      "    val_loss       : -1771.1335957845051\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1771.1336161295574\n",
      "Train Epoch: 81 [0/54000 (0%)] Loss: -1784.365723\n",
      "Train Epoch: 81 [11264/54000 (21%)] Loss: -1776.437744\n",
      "Train Epoch: 81 [22528/54000 (42%)] Loss: -1755.386108\n",
      "Train Epoch: 81 [33792/54000 (63%)] Loss: -1796.697632\n",
      "Train Epoch: 81 [45056/54000 (83%)] Loss: -1766.275146\n",
      "    epoch          : 81\n",
      "    loss           : -1768.7486146171138\n",
      "    ess            : 8.001185921003234\n",
      "    log_marginal   : 1768.7486146171138\n",
      "    val_loss       : -1777.3573608398438\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1777.3573608398438\n",
      "Train Epoch: 82 [0/54000 (0%)] Loss: -1788.419189\n",
      "Train Epoch: 82 [11264/54000 (21%)] Loss: -1774.067749\n",
      "Train Epoch: 82 [22528/54000 (42%)] Loss: -1772.732178\n",
      "Train Epoch: 82 [33792/54000 (63%)] Loss: -1797.103027\n",
      "Train Epoch: 82 [45056/54000 (83%)] Loss: -1768.337158\n",
      "    epoch          : 82\n",
      "    loss           : -1772.6936380638267\n",
      "    ess            : 8.00118593899709\n",
      "    log_marginal   : 1772.6936380638267\n",
      "    val_loss       : -1778.9741821289062\n",
      "    val_ess        : 8.001184622446695\n",
      "    val_log_marginal: 1778.9741821289062\n",
      "Train Epoch: 83 [0/54000 (0%)] Loss: -1788.625244\n",
      "Train Epoch: 83 [11264/54000 (21%)] Loss: -1790.473022\n",
      "Train Epoch: 83 [22528/54000 (42%)] Loss: -1782.626953\n",
      "Train Epoch: 83 [33792/54000 (63%)] Loss: -1808.352417\n",
      "Train Epoch: 83 [45056/54000 (83%)] Loss: -1771.436768\n",
      "    epoch          : 83\n",
      "    loss           : -1781.5757757222877\n",
      "    ess            : 8.001185363193727\n",
      "    log_marginal   : 1781.5757757222877\n",
      "    val_loss       : -1785.2478129069011\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1785.2478129069011\n",
      "Train Epoch: 84 [0/54000 (0%)] Loss: -1795.432129\n",
      "Train Epoch: 84 [11264/54000 (21%)] Loss: -1799.453369\n",
      "Train Epoch: 84 [22528/54000 (42%)] Loss: -1787.882446\n",
      "Train Epoch: 84 [33792/54000 (63%)] Loss: -1806.207275\n",
      "Train Epoch: 84 [45056/54000 (83%)] Loss: -1766.402100\n",
      "    epoch          : 84\n",
      "    loss           : -1784.1337015403892\n",
      "    ess            : 8.001185363193727\n",
      "    log_marginal   : 1784.1336992371757\n",
      "    val_loss       : -1790.3074849446614\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1790.3074849446614\n",
      "Train Epoch: 85 [0/54000 (0%)] Loss: -1799.034546\n",
      "Train Epoch: 85 [11264/54000 (21%)] Loss: -1791.391479\n",
      "Train Epoch: 85 [22528/54000 (42%)] Loss: -1782.137817\n",
      "Train Epoch: 85 [33792/54000 (63%)] Loss: -1791.597290\n",
      "Train Epoch: 85 [45056/54000 (83%)] Loss: -1754.818848\n",
      "    epoch          : 85\n",
      "    loss           : -1775.9102909879864\n",
      "    ess            : 8.001185471156859\n",
      "    log_marginal   : 1775.9102921395931\n",
      "    val_loss       : -1766.3978576660156\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1766.3978576660156\n",
      "Train Epoch: 86 [0/54000 (0%)] Loss: -1774.415649\n",
      "Train Epoch: 86 [11264/54000 (21%)] Loss: -1767.812500\n",
      "Train Epoch: 86 [22528/54000 (42%)] Loss: -1747.745361\n",
      "Train Epoch: 86 [33792/54000 (63%)] Loss: -1789.311768\n",
      "Train Epoch: 86 [45056/54000 (83%)] Loss: -1761.294189\n",
      "    epoch          : 86\n",
      "    loss           : -1767.2297800891804\n",
      "    ess            : 8.001185885015524\n",
      "    log_marginal   : 1767.2297800891804\n",
      "    val_loss       : -1781.071024576823\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1781.071024576823\n",
      "Train Epoch: 87 [0/54000 (0%)] Loss: -1790.714722\n",
      "Train Epoch: 87 [11264/54000 (21%)] Loss: -1773.669678\n",
      "Train Epoch: 87 [22528/54000 (42%)] Loss: -1767.928955\n",
      "Train Epoch: 87 [33792/54000 (63%)] Loss: -1799.568604\n",
      "Train Epoch: 87 [45056/54000 (83%)] Loss: -1774.604492\n",
      "    epoch          : 87\n",
      "    loss           : -1778.3197148161114\n",
      "    ess            : 8.001185444166076\n",
      "    log_marginal   : 1778.3197148161114\n",
      "    val_loss       : -1790.5833740234375\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1790.5833638509114\n",
      "Train Epoch: 88 [0/54000 (0%)] Loss: -1800.427002\n",
      "Train Epoch: 88 [11264/54000 (21%)] Loss: -1799.679199\n",
      "Train Epoch: 88 [22528/54000 (42%)] Loss: -1784.535522\n",
      "Train Epoch: 88 [33792/54000 (63%)] Loss: -1808.778687\n",
      "Train Epoch: 88 [45056/54000 (83%)] Loss: -1775.945190\n",
      "    epoch          : 88\n",
      "    loss           : -1788.186271235628\n",
      "    ess            : 8.001185183255178\n",
      "    log_marginal   : 1788.1862700840213\n",
      "    val_loss       : -1787.0372721354167\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1787.0372721354167\n",
      "Train Epoch: 89 [0/54000 (0%)] Loss: -1799.075439\n",
      "Train Epoch: 89 [11264/54000 (21%)] Loss: -1801.770752\n",
      "Train Epoch: 89 [22528/54000 (42%)] Loss: -1786.406494\n",
      "Train Epoch: 89 [33792/54000 (63%)] Loss: -1795.972900\n",
      "Train Epoch: 89 [45056/54000 (83%)] Loss: -1778.517822\n",
      "    epoch          : 89\n",
      "    loss           : -1786.937595583358\n",
      "    ess            : 8.001184985322773\n",
      "    log_marginal   : 1786.937595583358\n",
      "    val_loss       : -1787.213399251302\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1787.2134195963542\n",
      "Train Epoch: 90 [0/54000 (0%)] Loss: -1797.206543\n",
      "Train Epoch: 90 [11264/54000 (21%)] Loss: -1789.346069\n",
      "Train Epoch: 90 [22528/54000 (42%)] Loss: -1779.020264\n",
      "Train Epoch: 90 [33792/54000 (63%)] Loss: -1756.430176\n",
      "Train Epoch: 90 [45056/54000 (83%)] Loss: -1749.431152\n",
      "    epoch          : 90\n",
      "    loss           : -1761.5862380693543\n",
      "    ess            : 8.001185165261322\n",
      "    log_marginal   : 1761.5862380693543\n",
      "    val_loss       : -1744.3280131022136\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1744.3280131022136\n",
      "Train Epoch: 91 [0/54000 (0%)] Loss: -1762.527588\n",
      "Train Epoch: 91 [11264/54000 (21%)] Loss: -1766.925293\n",
      "Train Epoch: 91 [22528/54000 (42%)] Loss: -1763.754395\n",
      "Train Epoch: 91 [33792/54000 (63%)] Loss: -1783.387207\n",
      "Train Epoch: 91 [45056/54000 (83%)] Loss: -1768.432373\n",
      "    epoch          : 91\n",
      "    loss           : -1761.1945904425854\n",
      "    ess            : 8.001185552129206\n",
      "    log_marginal   : 1761.1945904425854\n",
      "    val_loss       : -1775.972147623698\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1775.97216796875\n",
      "Train Epoch: 92 [0/54000 (0%)] Loss: -1789.227295\n",
      "Train Epoch: 92 [11264/54000 (21%)] Loss: -1789.476196\n",
      "Train Epoch: 92 [22528/54000 (42%)] Loss: -1777.563965\n",
      "Train Epoch: 92 [33792/54000 (63%)] Loss: -1803.913208\n",
      "Train Epoch: 92 [45056/54000 (83%)] Loss: -1772.045410\n",
      "    epoch          : 92\n",
      "    loss           : -1777.941481104437\n",
      "    ess            : 8.00118560611077\n",
      "    log_marginal   : 1777.941481104437\n",
      "    val_loss       : -1776.2097981770833\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1776.2097981770833\n",
      "Train Epoch: 93 [0/54000 (0%)] Loss: -1791.409424\n",
      "Train Epoch: 93 [11264/54000 (21%)] Loss: -1786.438232\n",
      "Train Epoch: 93 [22528/54000 (42%)] Loss: -1782.664307\n",
      "Train Epoch: 93 [33792/54000 (63%)] Loss: -1800.269043\n",
      "Train Epoch: 93 [45056/54000 (83%)] Loss: -1780.151733\n",
      "    epoch          : 93\n",
      "    loss           : -1781.620042333063\n",
      "    ess            : 8.001185489150712\n",
      "    log_marginal   : 1781.620042333063\n",
      "    val_loss       : -1787.812764485677\n",
      "    val_ess        : 8.001184860865274\n",
      "    val_log_marginal: 1787.812764485677\n",
      "Train Epoch: 94 [0/54000 (0%)] Loss: -1800.992676\n",
      "Train Epoch: 94 [11264/54000 (21%)] Loss: -1803.196777\n",
      "Train Epoch: 94 [22528/54000 (42%)] Loss: -1786.439087\n",
      "Train Epoch: 94 [33792/54000 (63%)] Loss: -1806.854492\n",
      "Train Epoch: 94 [45056/54000 (83%)] Loss: -1760.343628\n",
      "    epoch          : 94\n",
      "    loss           : -1782.4766097158756\n",
      "    ess            : 8.001185327206018\n",
      "    log_marginal   : 1782.4766097158756\n",
      "    val_loss       : -1779.163798014323\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1779.1638081868489\n",
      "Train Epoch: 95 [0/54000 (0%)] Loss: -1791.367432\n",
      "Train Epoch: 95 [11264/54000 (21%)] Loss: -1798.872559\n",
      "Train Epoch: 95 [22528/54000 (42%)] Loss: -1772.876709\n",
      "Train Epoch: 95 [33792/54000 (63%)] Loss: -1793.587158\n",
      "Train Epoch: 95 [45056/54000 (83%)] Loss: -1767.804199\n",
      "    epoch          : 95\n",
      "    loss           : -1776.568855717497\n",
      "    ess            : 8.001185525138423\n",
      "    log_marginal   : 1776.568855717497\n",
      "    val_loss       : -1782.6941833496094\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1782.6941935221355\n",
      "Train Epoch: 96 [0/54000 (0%)] Loss: -1793.143677\n",
      "Train Epoch: 96 [11264/54000 (21%)] Loss: -1788.403564\n",
      "Train Epoch: 96 [22528/54000 (42%)] Loss: -1780.035522\n",
      "Train Epoch: 96 [33792/54000 (63%)] Loss: -1793.838989\n",
      "Train Epoch: 96 [45056/54000 (83%)] Loss: -1767.901123\n",
      "    epoch          : 96\n",
      "    loss           : -1778.753637925634\n",
      "    ess            : 8.001185300215235\n",
      "    log_marginal   : 1778.753637925634\n",
      "    val_loss       : -1780.1661682128906\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1780.1661682128906\n",
      "Train Epoch: 97 [0/54000 (0%)] Loss: -1791.966797\n",
      "Train Epoch: 97 [11264/54000 (21%)] Loss: -1779.344238\n",
      "Train Epoch: 97 [22528/54000 (42%)] Loss: -1773.868286\n",
      "Train Epoch: 97 [33792/54000 (63%)] Loss: -1802.585449\n",
      "Train Epoch: 97 [45056/54000 (83%)] Loss: -1779.132568\n",
      "    epoch          : 97\n",
      "    loss           : -1778.251407263414\n",
      "    ess            : 8.001185354196801\n",
      "    log_marginal   : 1778.2514084150207\n",
      "    val_loss       : -1790.1002095540364\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1790.1002095540364\n",
      "Train Epoch: 98 [0/54000 (0%)] Loss: -1801.505371\n",
      "Train Epoch: 98 [11264/54000 (21%)] Loss: -1790.921387\n",
      "Train Epoch: 98 [22528/54000 (42%)] Loss: -1788.610352\n",
      "Train Epoch: 98 [33792/54000 (63%)] Loss: -1797.025635\n",
      "Train Epoch: 98 [45056/54000 (83%)] Loss: -1774.170044\n",
      "    epoch          : 98\n",
      "    loss           : -1782.0829490805572\n",
      "    ess            : 8.001185417175293\n",
      "    log_marginal   : 1782.0829490805572\n",
      "    val_loss       : -1781.2149353027344\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1781.2149353027344\n",
      "Train Epoch: 99 [0/54000 (0%)] Loss: -1792.629761\n",
      "Train Epoch: 99 [11264/54000 (21%)] Loss: -1794.256592\n",
      "Train Epoch: 99 [22528/54000 (42%)] Loss: -1774.648315\n",
      "Train Epoch: 99 [33792/54000 (63%)] Loss: -1807.737549\n",
      "Train Epoch: 99 [45056/54000 (83%)] Loss: -1777.025879\n",
      "    epoch          : 99\n",
      "    loss           : -1782.8432306253685\n",
      "    ess            : 8.00118528222138\n",
      "    log_marginal   : 1782.8432306253685\n",
      "    val_loss       : -1779.0867614746094\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1779.0867614746094\n",
      "Train Epoch: 100 [0/54000 (0%)] Loss: -1795.120850\n",
      "Train Epoch: 100 [11264/54000 (21%)] Loss: -1765.149048\n",
      "Train Epoch: 100 [22528/54000 (42%)] Loss: -1763.828735\n",
      "Train Epoch: 100 [33792/54000 (63%)] Loss: -1792.817627\n",
      "Train Epoch: 100 [45056/54000 (83%)] Loss: -1767.536743\n",
      "    epoch          : 100\n",
      "    loss           : -1771.5030816995873\n",
      "    ess            : 8.001185543132278\n",
      "    log_marginal   : 1771.5030816995873\n",
      "    val_loss       : -1785.906717936198\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1785.906717936198\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch100.pth ...\n",
      "Train Epoch: 101 [0/54000 (0%)] Loss: -1797.291992\n",
      "Train Epoch: 101 [11264/54000 (21%)] Loss: -1777.402344\n",
      "Train Epoch: 101 [22528/54000 (42%)] Loss: -1774.289307\n",
      "Train Epoch: 101 [33792/54000 (63%)] Loss: -1798.139648\n",
      "Train Epoch: 101 [45056/54000 (83%)] Loss: -1773.232910\n",
      "    epoch          : 101\n",
      "    loss           : -1780.627503593013\n",
      "    ess            : 8.001185444166076\n",
      "    log_marginal   : 1780.627503593013\n",
      "    val_loss       : -1782.5949300130208\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1782.5949300130208\n",
      "Train Epoch: 102 [0/54000 (0%)] Loss: -1793.803467\n",
      "Train Epoch: 102 [11264/54000 (21%)] Loss: -1790.244873\n",
      "Train Epoch: 102 [22528/54000 (42%)] Loss: -1782.039795\n",
      "Train Epoch: 102 [33792/54000 (63%)] Loss: -1772.671387\n",
      "Train Epoch: 102 [45056/54000 (83%)] Loss: -1765.345703\n",
      "    epoch          : 102\n",
      "    loss           : -1775.7843915831368\n",
      "    ess            : 8.00118524623367\n",
      "    log_marginal   : 1775.7843927347435\n",
      "    val_loss       : -1778.8855692545574\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1778.8855590820312\n",
      "Train Epoch: 103 [0/54000 (0%)] Loss: -1789.925293\n",
      "Train Epoch: 103 [11264/54000 (21%)] Loss: -1785.452759\n",
      "Train Epoch: 103 [22528/54000 (42%)] Loss: -1773.199341\n",
      "Train Epoch: 103 [33792/54000 (63%)] Loss: -1770.277954\n",
      "Train Epoch: 103 [45056/54000 (83%)] Loss: -1759.621094\n",
      "    epoch          : 103\n",
      "    loss           : -1767.4631209463444\n",
      "    ess            : 8.001185804043176\n",
      "    log_marginal   : 1767.4631209463444\n",
      "    val_loss       : -1780.4833374023438\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1780.4833374023438\n",
      "Train Epoch: 104 [0/54000 (0%)] Loss: -1791.578003\n",
      "Train Epoch: 104 [11264/54000 (21%)] Loss: -1787.957031\n",
      "Train Epoch: 104 [22528/54000 (42%)] Loss: -1770.233887\n",
      "Train Epoch: 104 [33792/54000 (63%)] Loss: -1788.728516\n",
      "Train Epoch: 104 [45056/54000 (83%)] Loss: -1770.217041\n",
      "    epoch          : 104\n",
      "    loss           : -1774.2463309809846\n",
      "    ess            : 8.001185264227525\n",
      "    log_marginal   : 1774.2463309809846\n",
      "    val_loss       : -1792.3506673177083\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1792.3506673177083\n",
      "Train Epoch: 105 [0/54000 (0%)] Loss: -1802.176636\n",
      "Train Epoch: 105 [11264/54000 (21%)] Loss: -1801.462036\n",
      "Train Epoch: 105 [22528/54000 (42%)] Loss: -1784.054932\n",
      "Train Epoch: 105 [33792/54000 (63%)] Loss: -1798.924683\n",
      "Train Epoch: 105 [45056/54000 (83%)] Loss: -1774.677734\n",
      "    epoch          : 105\n",
      "    loss           : -1784.741177540905\n",
      "    ess            : 8.001185345199874\n",
      "    log_marginal   : 1784.7411763892983\n",
      "    val_loss       : -1785.1086832682292\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1785.1086832682292\n",
      "Train Epoch: 106 [0/54000 (0%)] Loss: -1796.307861\n",
      "Train Epoch: 106 [11264/54000 (21%)] Loss: -1804.697021\n",
      "Train Epoch: 106 [22528/54000 (42%)] Loss: -1784.722046\n",
      "Train Epoch: 106 [33792/54000 (63%)] Loss: -1802.284912\n",
      "Train Epoch: 106 [45056/54000 (83%)] Loss: -1774.363037\n",
      "    epoch          : 106\n",
      "    loss           : -1787.0384325711232\n",
      "    ess            : 8.001185003316627\n",
      "    log_marginal   : 1787.0384325711232\n",
      "    val_loss       : -1788.9990336100261\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1788.9990336100261\n",
      "Train Epoch: 107 [0/54000 (0%)] Loss: -1801.335205\n",
      "Train Epoch: 107 [11264/54000 (21%)] Loss: -1800.952759\n",
      "Train Epoch: 107 [22528/54000 (42%)] Loss: -1787.171875\n",
      "Train Epoch: 107 [33792/54000 (63%)] Loss: -1809.093262\n",
      "Train Epoch: 107 [45056/54000 (83%)] Loss: -1781.040771\n",
      "    epoch          : 107\n",
      "    loss           : -1789.1049436173348\n",
      "    ess            : 8.001185129273612\n",
      "    log_marginal   : 1789.104942465728\n",
      "    val_loss       : -1792.7609354654949\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1792.7609354654949\n",
      "Train Epoch: 108 [0/54000 (0%)] Loss: -1805.889893\n",
      "Train Epoch: 108 [11264/54000 (21%)] Loss: -1807.847168\n",
      "Train Epoch: 108 [22528/54000 (42%)] Loss: -1786.511230\n",
      "Train Epoch: 108 [33792/54000 (63%)] Loss: -1800.812988\n",
      "Train Epoch: 108 [45056/54000 (83%)] Loss: -1783.748413\n",
      "    epoch          : 108\n",
      "    loss           : -1788.2937046266952\n",
      "    ess            : 8.001185273224452\n",
      "    log_marginal   : 1788.2937046266952\n",
      "    val_loss       : -1792.5088399251301\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1792.5088297526042\n",
      "Train Epoch: 109 [0/54000 (0%)] Loss: -1803.607422\n",
      "Train Epoch: 109 [11264/54000 (21%)] Loss: -1802.323120\n",
      "Train Epoch: 109 [22528/54000 (42%)] Loss: -1787.180420\n",
      "Train Epoch: 109 [33792/54000 (63%)] Loss: -1802.713623\n",
      "Train Epoch: 109 [45056/54000 (83%)] Loss: -1780.542603\n",
      "    epoch          : 109\n",
      "    loss           : -1788.1638068433078\n",
      "    ess            : 8.001185435169148\n",
      "    log_marginal   : 1788.1638068433078\n",
      "    val_loss       : -1785.0472106933594\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1785.0472106933594\n",
      "Train Epoch: 110 [0/54000 (0%)] Loss: -1796.597412\n",
      "Train Epoch: 110 [11264/54000 (21%)] Loss: -1781.534912\n",
      "Train Epoch: 110 [22528/54000 (42%)] Loss: -1773.851685\n",
      "Train Epoch: 110 [33792/54000 (63%)] Loss: -1784.236816\n",
      "Train Epoch: 110 [45056/54000 (83%)] Loss: -1761.590332\n",
      "    epoch          : 110\n",
      "    loss           : -1776.2144245651532\n",
      "    ess            : 8.001185597113842\n",
      "    log_marginal   : 1776.2144245651532\n",
      "    val_loss       : -1781.984110514323\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1781.984110514323\n",
      "Train Epoch: 111 [0/54000 (0%)] Loss: -1793.449585\n",
      "Train Epoch: 111 [11264/54000 (21%)] Loss: -1792.644775\n",
      "Train Epoch: 111 [22528/54000 (42%)] Loss: -1778.751465\n",
      "Train Epoch: 111 [33792/54000 (63%)] Loss: -1789.479858\n",
      "Train Epoch: 111 [45056/54000 (83%)] Loss: -1766.086914\n",
      "    epoch          : 111\n",
      "    loss           : -1779.5081729529038\n",
      "    ess            : 8.001185471156859\n",
      "    log_marginal   : 1779.5081729529038\n",
      "    val_loss       : -1781.2442423502605\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1781.2442423502605\n",
      "Train Epoch: 112 [0/54000 (0%)] Loss: -1792.819336\n",
      "Train Epoch: 112 [11264/54000 (21%)] Loss: -1784.599365\n",
      "Train Epoch: 112 [22528/54000 (42%)] Loss: -1780.988892\n",
      "Train Epoch: 112 [33792/54000 (63%)] Loss: -1799.373535\n",
      "Train Epoch: 112 [45056/54000 (83%)] Loss: -1768.276611\n",
      "    epoch          : 112\n",
      "    loss           : -1781.208504154997\n",
      "    ess            : 8.001185489150712\n",
      "    log_marginal   : 1781.2085053066037\n",
      "    val_loss       : -1790.2769775390625\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1790.2769775390625\n",
      "Train Epoch: 113 [0/54000 (0%)] Loss: -1801.422974\n",
      "Train Epoch: 113 [11264/54000 (21%)] Loss: -1785.408447\n",
      "Train Epoch: 113 [22528/54000 (42%)] Loss: -1786.311646\n",
      "Train Epoch: 113 [33792/54000 (63%)] Loss: -1802.170898\n",
      "Train Epoch: 113 [45056/54000 (83%)] Loss: -1771.679443\n",
      "    epoch          : 113\n",
      "    loss           : -1784.69133945681\n",
      "    ess            : 8.001185525138423\n",
      "    log_marginal   : 1784.69133945681\n",
      "    val_loss       : -1791.1643880208333\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1791.1643981933594\n",
      "Train Epoch: 114 [0/54000 (0%)] Loss: -1801.516357\n",
      "Train Epoch: 114 [11264/54000 (21%)] Loss: -1793.597900\n",
      "Train Epoch: 114 [22528/54000 (42%)] Loss: -1778.541626\n",
      "Train Epoch: 114 [33792/54000 (63%)] Loss: -1805.845581\n",
      "Train Epoch: 114 [45056/54000 (83%)] Loss: -1773.813232\n",
      "    epoch          : 114\n",
      "    loss           : -1784.7271958836968\n",
      "    ess            : 8.001185417175293\n",
      "    log_marginal   : 1784.7271947320903\n",
      "    val_loss       : -1782.3949178059895\n",
      "    val_ess        : 8.001185894012451\n",
      "    val_log_marginal: 1782.3949279785156\n",
      "Train Epoch: 115 [0/54000 (0%)] Loss: -1793.259521\n",
      "Train Epoch: 115 [11264/54000 (21%)] Loss: -1782.540283\n",
      "Train Epoch: 115 [22528/54000 (42%)] Loss: -1739.032715\n",
      "Train Epoch: 115 [33792/54000 (63%)] Loss: -1782.581787\n",
      "Train Epoch: 115 [45056/54000 (83%)] Loss: -1741.648438\n",
      "    epoch          : 115\n",
      "    loss           : -1761.1689717994545\n",
      "    ess            : 8.001185444166076\n",
      "    log_marginal   : 1761.1689729510613\n",
      "    val_loss       : -1761.6063028971355\n",
      "    val_ess        : 8.001185655593872\n",
      "    val_log_marginal: 1761.6063028971355\n",
      "Train Epoch: 116 [0/54000 (0%)] Loss: -1769.566650\n",
      "Train Epoch: 116 [11264/54000 (21%)] Loss: -1771.451904\n",
      "Train Epoch: 116 [22528/54000 (42%)] Loss: -1739.387695\n",
      "Train Epoch: 116 [33792/54000 (63%)] Loss: -1788.455322\n",
      "Train Epoch: 116 [45056/54000 (83%)] Loss: -1770.383179\n",
      "    epoch          : 116\n",
      "    loss           : -1761.6402127247936\n",
      "    ess            : 8.001185723070828\n",
      "    log_marginal   : 1761.6402138764004\n",
      "    val_loss       : -1789.1418355305989\n",
      "    val_ess        : 8.001185973485311\n",
      "    val_log_marginal: 1789.1418558756511\n",
      "Train Epoch: 117 [0/54000 (0%)] Loss: -1798.035278\n",
      "Train Epoch: 117 [11264/54000 (21%)] Loss: -1790.826782\n",
      "Train Epoch: 117 [22528/54000 (42%)] Loss: -1769.402588\n",
      "Train Epoch: 117 [33792/54000 (63%)] Loss: -1803.314453\n",
      "Train Epoch: 117 [45056/54000 (83%)] Loss: -1769.849365\n",
      "    epoch          : 117\n",
      "    loss           : -1778.5951538085938\n",
      "    ess            : 8.001185489150712\n",
      "    log_marginal   : 1778.5951538085938\n",
      "    val_loss       : -1784.875264485677\n",
      "    val_ess        : 8.001185178756714\n",
      "    val_log_marginal: 1784.875264485677\n",
      "Train Epoch: 118 [0/54000 (0%)] Loss: -1794.989502\n",
      "Train Epoch: 118 [11264/54000 (21%)] Loss: -1793.393188\n",
      "Train Epoch: 118 [22528/54000 (42%)] Loss: -1767.620728\n",
      "Train Epoch: 118 [33792/54000 (63%)] Loss: -1807.896484\n",
      "Train Epoch: 118 [45056/54000 (83%)] Loss: -1777.027954\n",
      "    epoch          : 118\n",
      "    loss           : -1781.1593270931603\n",
      "    ess            : 8.00118596598787\n",
      "    log_marginal   : 1781.1593270931603\n",
      "    val_loss       : -1786.0738423665364\n",
      "    val_ess        : 8.00118581453959\n",
      "    val_log_marginal: 1786.0738423665364\n",
      "Train Epoch: 119 [0/54000 (0%)] Loss: -1798.638184\n",
      "Train Epoch: 119 [11264/54000 (21%)] Loss: -1783.909912\n",
      "Train Epoch: 119 [22528/54000 (42%)] Loss: -1769.925049\n",
      "Train Epoch: 119 [33792/54000 (63%)] Loss: -1788.269897\n",
      "Train Epoch: 119 [45056/54000 (83%)] Loss: -1754.016602\n",
      "    epoch          : 119\n",
      "    loss           : -1769.7021449826798\n",
      "    ess            : 8.001185687083119\n",
      "    log_marginal   : 1769.7021449826798\n",
      "    val_loss       : -1771.5259908040364\n",
      "    val_ess        : 8.00118613243103\n",
      "    val_log_marginal: 1771.5260009765625\n",
      "Train Epoch: 120 [0/54000 (0%)] Loss: -1783.428223\n",
      "Train Epoch: 120 [11264/54000 (21%)] Loss: -1783.849609\n",
      "Train Epoch: 120 [22528/54000 (42%)] Loss: -1777.652588\n",
      "Train Epoch: 120 [33792/54000 (63%)] Loss: -1790.320068\n",
      "Train Epoch: 120 [45056/54000 (83%)] Loss: -1767.437744\n",
      "    epoch          : 120\n",
      "    loss           : -1776.3072290960347\n",
      "    ess            : 8.001185804043176\n",
      "    log_marginal   : 1776.3072290960347\n",
      "    val_loss       : -1786.7657979329426\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1786.7657877604167\n",
      "Train Epoch: 121 [0/54000 (0%)] Loss: -1795.750000\n",
      "Train Epoch: 121 [11264/54000 (21%)] Loss: -1797.559570\n",
      "Train Epoch: 121 [22528/54000 (42%)] Loss: -1780.749512\n",
      "Train Epoch: 121 [33792/54000 (63%)] Loss: -1798.946533\n",
      "Train Epoch: 121 [45056/54000 (83%)] Loss: -1772.243408\n",
      "    epoch          : 121\n",
      "    loss           : -1783.6109941590507\n",
      "    ess            : 8.001185615107698\n",
      "    log_marginal   : 1783.6109964622642\n",
      "    val_loss       : -1790.1780700683594\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1790.1780700683594\n",
      "Train Epoch: 122 [0/54000 (0%)] Loss: -1801.338623\n",
      "Train Epoch: 122 [11264/54000 (21%)] Loss: -1802.700317\n",
      "Train Epoch: 122 [22528/54000 (42%)] Loss: -1789.541992\n",
      "Train Epoch: 122 [33792/54000 (63%)] Loss: -1805.418457\n",
      "Train Epoch: 122 [45056/54000 (83%)] Loss: -1779.174927\n",
      "    epoch          : 122\n",
      "    loss           : -1788.2725046985554\n",
      "    ess            : 8.001185453163004\n",
      "    log_marginal   : 1788.2725046985554\n",
      "    val_loss       : -1791.2759399414062\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1791.2759399414062\n",
      "Train Epoch: 123 [0/54000 (0%)] Loss: -1802.068481\n",
      "Train Epoch: 123 [11264/54000 (21%)] Loss: -1799.672119\n",
      "Train Epoch: 123 [22528/54000 (42%)] Loss: -1787.670288\n",
      "Train Epoch: 123 [33792/54000 (63%)] Loss: -1780.397705\n",
      "Train Epoch: 123 [45056/54000 (83%)] Loss: -1773.078735\n",
      "    epoch          : 123\n",
      "    loss           : -1782.8874822652565\n",
      "    ess            : 8.00118517425825\n",
      "    log_marginal   : 1782.8874811136498\n",
      "    val_loss       : -1786.5198465983074\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1786.5198465983074\n",
      "Train Epoch: 124 [0/54000 (0%)] Loss: -1794.869995\n",
      "Train Epoch: 124 [11264/54000 (21%)] Loss: -1795.476318\n",
      "Train Epoch: 124 [22528/54000 (42%)] Loss: -1782.277222\n",
      "Train Epoch: 124 [33792/54000 (63%)] Loss: -1767.058594\n",
      "Train Epoch: 124 [45056/54000 (83%)] Loss: -1767.888184\n",
      "    epoch          : 124\n",
      "    loss           : -1776.068611576872\n",
      "    ess            : 8.001185570123061\n",
      "    log_marginal   : 1776.068611576872\n",
      "    val_loss       : -1771.9974365234375\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1771.9974365234375\n",
      "Train Epoch: 125 [0/54000 (0%)] Loss: -1781.301392\n",
      "Train Epoch: 125 [11264/54000 (21%)] Loss: -1797.339355\n",
      "Train Epoch: 125 [22528/54000 (42%)] Loss: -1766.269165\n",
      "Train Epoch: 125 [33792/54000 (63%)] Loss: -1781.923584\n",
      "Train Epoch: 125 [45056/54000 (83%)] Loss: -1753.658447\n",
      "    epoch          : 125\n",
      "    loss           : -1770.7859140072228\n",
      "    ess            : 8.001185705076974\n",
      "    log_marginal   : 1770.7859140072228\n",
      "    val_loss       : -1759.2265218098958\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1759.2265218098958\n",
      "Train Epoch: 126 [0/54000 (0%)] Loss: -1767.931763\n",
      "Train Epoch: 126 [11264/54000 (21%)] Loss: -1784.423828\n",
      "Train Epoch: 126 [22528/54000 (42%)] Loss: -1757.656494\n",
      "Train Epoch: 126 [33792/54000 (63%)] Loss: -1792.036377\n",
      "Train Epoch: 126 [45056/54000 (83%)] Loss: -1759.770630\n",
      "    epoch          : 126\n",
      "    loss           : -1766.5050371278007\n",
      "    ess            : 8.001185921003234\n",
      "    log_marginal   : 1766.5050382794075\n",
      "    val_loss       : -1780.3751017252605\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1780.3751017252605\n",
      "Train Epoch: 127 [0/54000 (0%)] Loss: -1790.609375\n",
      "Train Epoch: 127 [11264/54000 (21%)] Loss: -1801.366455\n",
      "Train Epoch: 127 [22528/54000 (42%)] Loss: -1777.221436\n",
      "Train Epoch: 127 [33792/54000 (63%)] Loss: -1805.671387\n",
      "Train Epoch: 127 [45056/54000 (83%)] Loss: -1770.063843\n",
      "    epoch          : 127\n",
      "    loss           : -1780.7290499705189\n",
      "    ess            : 8.001185741064683\n",
      "    log_marginal   : 1780.7290499705189\n",
      "    val_loss       : -1783.8411051432292\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1783.8411051432292\n",
      "Train Epoch: 128 [0/54000 (0%)] Loss: -1793.064941\n",
      "Train Epoch: 128 [11264/54000 (21%)] Loss: -1802.218994\n",
      "Train Epoch: 128 [22528/54000 (42%)] Loss: -1780.982178\n",
      "Train Epoch: 128 [33792/54000 (63%)] Loss: -1804.528809\n",
      "Train Epoch: 128 [45056/54000 (83%)] Loss: -1770.903809\n",
      "    epoch          : 128\n",
      "    loss           : -1782.957407825398\n",
      "    ess            : 8.001185687083119\n",
      "    log_marginal   : 1782.957407825398\n",
      "    val_loss       : -1776.1529947916667\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1776.1529947916667\n",
      "Train Epoch: 129 [0/54000 (0%)] Loss: -1787.169922\n",
      "Train Epoch: 129 [11264/54000 (21%)] Loss: -1796.851807\n",
      "Train Epoch: 129 [22528/54000 (42%)] Loss: -1774.394653\n",
      "Train Epoch: 129 [33792/54000 (63%)] Loss: -1802.517700\n",
      "Train Epoch: 129 [45056/54000 (83%)] Loss: -1778.269775\n",
      "    epoch          : 129\n",
      "    loss           : -1781.910673321418\n",
      "    ess            : 8.001185462159931\n",
      "    log_marginal   : 1781.910673321418\n",
      "    val_loss       : -1782.747334798177\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1782.747334798177\n",
      "Train Epoch: 130 [0/54000 (0%)] Loss: -1795.302734\n",
      "Train Epoch: 130 [11264/54000 (21%)] Loss: -1786.220581\n",
      "Train Epoch: 130 [22528/54000 (42%)] Loss: -1760.636475\n",
      "Train Epoch: 130 [33792/54000 (63%)] Loss: -1790.702393\n",
      "Train Epoch: 130 [45056/54000 (83%)] Loss: -1768.761719\n",
      "    epoch          : 130\n",
      "    loss           : -1772.5623076816776\n",
      "    ess            : 8.001185696080046\n",
      "    log_marginal   : 1772.5623076816776\n",
      "    val_loss       : -1753.9353434244792\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1753.9353434244792\n",
      "Train Epoch: 131 [0/54000 (0%)] Loss: -1766.247925\n",
      "Train Epoch: 131 [11264/54000 (21%)] Loss: -1754.238037\n",
      "Train Epoch: 131 [22528/54000 (42%)] Loss: -1755.815674\n",
      "Train Epoch: 131 [33792/54000 (63%)] Loss: -1791.309570\n",
      "Train Epoch: 131 [45056/54000 (83%)] Loss: -1778.397461\n",
      "    epoch          : 131\n",
      "    loss           : -1763.2954527656987\n",
      "    ess            : 8.00118564209848\n",
      "    log_marginal   : 1763.295451614092\n",
      "    val_loss       : -1772.5975443522136\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1772.5975443522136\n",
      "Train Epoch: 132 [0/54000 (0%)] Loss: -1783.941406\n",
      "Train Epoch: 132 [11264/54000 (21%)] Loss: -1778.310059\n",
      "Train Epoch: 132 [22528/54000 (42%)] Loss: -1782.101318\n",
      "Train Epoch: 132 [33792/54000 (63%)] Loss: -1802.549438\n",
      "Train Epoch: 132 [45056/54000 (83%)] Loss: -1772.764771\n",
      "    epoch          : 132\n",
      "    loss           : -1779.7865807875148\n",
      "    ess            : 8.001185687083119\n",
      "    log_marginal   : 1779.7865807875148\n",
      "    val_loss       : -1783.8174438476562\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1783.8174438476562\n",
      "Train Epoch: 133 [0/54000 (0%)] Loss: -1793.698242\n",
      "Train Epoch: 133 [11264/54000 (21%)] Loss: -1796.930054\n",
      "Train Epoch: 133 [22528/54000 (42%)] Loss: -1784.067139\n",
      "Train Epoch: 133 [33792/54000 (63%)] Loss: -1800.859375\n",
      "Train Epoch: 133 [45056/54000 (83%)] Loss: -1776.976196\n",
      "    epoch          : 133\n",
      "    loss           : -1783.8515164357311\n",
      "    ess            : 8.001185435169148\n",
      "    log_marginal   : 1783.8515164357311\n",
      "    val_loss       : -1782.1329752604167\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1782.1329752604167\n",
      "Train Epoch: 134 [0/54000 (0%)] Loss: -1789.063965\n",
      "Train Epoch: 134 [11264/54000 (21%)] Loss: -1798.284180\n",
      "Train Epoch: 134 [22528/54000 (42%)] Loss: -1757.058838\n",
      "Train Epoch: 134 [33792/54000 (63%)] Loss: -1780.869141\n",
      "Train Epoch: 134 [45056/54000 (83%)] Loss: -1753.333130\n",
      "    epoch          : 134\n",
      "    loss           : -1768.367091916642\n",
      "    ess            : 8.001185903009379\n",
      "    log_marginal   : 1768.3670907650353\n",
      "    val_loss       : -1765.8585917154949\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1765.8585917154949\n",
      "Train Epoch: 135 [0/54000 (0%)] Loss: -1776.323486\n",
      "Train Epoch: 135 [11264/54000 (21%)] Loss: -1779.796631\n",
      "Train Epoch: 135 [22528/54000 (42%)] Loss: -1760.416992\n",
      "Train Epoch: 135 [33792/54000 (63%)] Loss: -1791.389282\n",
      "Train Epoch: 135 [45056/54000 (83%)] Loss: -1754.542725\n",
      "    epoch          : 135\n",
      "    loss           : -1766.5562398658608\n",
      "    ess            : 8.001185867021668\n",
      "    log_marginal   : 1766.5562398658608\n",
      "    val_loss       : -1774.9669698079426\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1774.9669698079426\n",
      "Train Epoch: 136 [0/54000 (0%)] Loss: -1785.761841\n",
      "Train Epoch: 136 [11264/54000 (21%)] Loss: -1794.649414\n",
      "Train Epoch: 136 [22528/54000 (42%)] Loss: -1772.178711\n",
      "Train Epoch: 136 [33792/54000 (63%)] Loss: -1802.062500\n",
      "Train Epoch: 136 [45056/54000 (83%)] Loss: -1773.535889\n",
      "    epoch          : 136\n",
      "    loss           : -1780.2636269623379\n",
      "    ess            : 8.001185669089264\n",
      "    log_marginal   : 1780.2636269623379\n",
      "    val_loss       : -1792.7396748860676\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1792.7396748860676\n",
      "Train Epoch: 137 [0/54000 (0%)] Loss: -1803.787354\n",
      "Train Epoch: 137 [11264/54000 (21%)] Loss: -1803.335083\n",
      "Train Epoch: 137 [22528/54000 (42%)] Loss: -1784.072021\n",
      "Train Epoch: 137 [33792/54000 (63%)] Loss: -1801.436523\n",
      "Train Epoch: 137 [45056/54000 (83%)] Loss: -1775.618896\n",
      "    epoch          : 137\n",
      "    loss           : -1786.2120038878243\n",
      "    ess            : 8.001185435169148\n",
      "    log_marginal   : 1786.2120038878243\n",
      "    val_loss       : -1790.9297281901042\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1790.9297485351562\n",
      "Train Epoch: 138 [0/54000 (0%)] Loss: -1800.348633\n",
      "Train Epoch: 138 [11264/54000 (21%)] Loss: -1803.327637\n",
      "Train Epoch: 138 [22528/54000 (42%)] Loss: -1785.866211\n",
      "Train Epoch: 138 [33792/54000 (63%)] Loss: -1807.036377\n",
      "Train Epoch: 138 [45056/54000 (83%)] Loss: -1769.155029\n",
      "    epoch          : 138\n",
      "    loss           : -1785.2216336232311\n",
      "    ess            : 8.001185327206018\n",
      "    log_marginal   : 1785.2216336232311\n",
      "    val_loss       : -1776.8362325032551\n",
      "    val_ess        : 8.001184225082397\n",
      "    val_log_marginal: 1776.8362426757812\n",
      "Train Epoch: 139 [0/54000 (0%)] Loss: -1790.822998\n",
      "Train Epoch: 139 [11264/54000 (21%)] Loss: -1802.534912\n",
      "Train Epoch: 139 [22528/54000 (42%)] Loss: -1784.354004\n",
      "Train Epoch: 139 [33792/54000 (63%)] Loss: -1809.781738\n",
      "Train Epoch: 139 [45056/54000 (83%)] Loss: -1779.643921\n",
      "    epoch          : 139\n",
      "    loss           : -1787.0198640643425\n",
      "    ess            : 8.001185507144568\n",
      "    log_marginal   : 1787.0198640643425\n",
      "    val_loss       : -1796.7158203125\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1796.7158203125\n",
      "Train Epoch: 140 [0/54000 (0%)] Loss: -1807.844604\n",
      "Train Epoch: 140 [11264/54000 (21%)] Loss: -1807.482178\n",
      "Train Epoch: 140 [22528/54000 (42%)] Loss: -1787.254150\n",
      "Train Epoch: 140 [33792/54000 (63%)] Loss: -1806.318237\n",
      "Train Epoch: 140 [45056/54000 (83%)] Loss: -1766.072876\n",
      "    epoch          : 140\n",
      "    loss           : -1788.412605717497\n",
      "    ess            : 8.001185219242888\n",
      "    log_marginal   : 1788.412605717497\n",
      "    val_loss       : -1789.3981831868489\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1789.398173014323\n",
      "Train Epoch: 141 [0/54000 (0%)] Loss: -1800.439209\n",
      "Train Epoch: 141 [11264/54000 (21%)] Loss: -1796.424194\n",
      "Train Epoch: 141 [22528/54000 (42%)] Loss: -1772.623047\n",
      "Train Epoch: 141 [33792/54000 (63%)] Loss: -1805.132324\n",
      "Train Epoch: 141 [45056/54000 (83%)] Loss: -1759.195557\n",
      "    epoch          : 141\n",
      "    loss           : -1777.6472893480984\n",
      "    ess            : 8.001185507144568\n",
      "    log_marginal   : 1777.6472904997052\n",
      "    val_loss       : -1770.9968363444011\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1770.9968363444011\n",
      "Train Epoch: 142 [0/54000 (0%)] Loss: -1782.896484\n",
      "Train Epoch: 142 [11264/54000 (21%)] Loss: -1784.765991\n",
      "Train Epoch: 142 [22528/54000 (42%)] Loss: -1782.730713\n",
      "Train Epoch: 142 [33792/54000 (63%)] Loss: -1808.055298\n",
      "Train Epoch: 142 [45056/54000 (83%)] Loss: -1774.214844\n",
      "    epoch          : 142\n",
      "    loss           : -1783.1971228257664\n",
      "    ess            : 8.001185363193727\n",
      "    log_marginal   : 1783.1971239773732\n",
      "    val_loss       : -1798.3402811686199\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1798.3402811686199\n",
      "Train Epoch: 143 [0/54000 (0%)] Loss: -1811.111084\n",
      "Train Epoch: 143 [11264/54000 (21%)] Loss: -1806.429688\n",
      "Train Epoch: 143 [22528/54000 (42%)] Loss: -1787.395020\n",
      "Train Epoch: 143 [33792/54000 (63%)] Loss: -1806.245728\n",
      "Train Epoch: 143 [45056/54000 (83%)] Loss: -1773.452393\n",
      "    epoch          : 143\n",
      "    loss           : -1789.7907749391952\n",
      "    ess            : 8.001185165261322\n",
      "    log_marginal   : 1789.7907749391952\n",
      "    val_loss       : -1792.7494303385417\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1792.7494303385417\n",
      "Train Epoch: 144 [0/54000 (0%)] Loss: -1805.468506\n",
      "Train Epoch: 144 [11264/54000 (21%)] Loss: -1799.198486\n",
      "Train Epoch: 144 [22528/54000 (42%)] Loss: -1775.464844\n",
      "Train Epoch: 144 [33792/54000 (63%)] Loss: -1797.801025\n",
      "Train Epoch: 144 [45056/54000 (83%)] Loss: -1770.763184\n",
      "    epoch          : 144\n",
      "    loss           : -1782.8906549417748\n",
      "    ess            : 8.001185300215235\n",
      "    log_marginal   : 1782.8906549417748\n",
      "    val_loss       : -1787.6582438151042\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1787.6582438151042\n",
      "Train Epoch: 145 [0/54000 (0%)] Loss: -1800.915283\n",
      "Train Epoch: 145 [11264/54000 (21%)] Loss: -1798.544067\n",
      "Train Epoch: 145 [22528/54000 (42%)] Loss: -1772.428955\n",
      "Train Epoch: 145 [33792/54000 (63%)] Loss: -1805.764404\n",
      "Train Epoch: 145 [45056/54000 (83%)] Loss: -1770.895630\n",
      "    epoch          : 145\n",
      "    loss           : -1783.1478720610996\n",
      "    ess            : 8.001185489150712\n",
      "    log_marginal   : 1783.1478720610996\n",
      "    val_loss       : -1793.2638651529949\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1793.2638549804688\n",
      "Train Epoch: 146 [0/54000 (0%)] Loss: -1806.062256\n",
      "Train Epoch: 146 [11264/54000 (21%)] Loss: -1803.897095\n",
      "Train Epoch: 146 [22528/54000 (42%)] Loss: -1790.887695\n",
      "Train Epoch: 146 [33792/54000 (63%)] Loss: -1817.719727\n",
      "Train Epoch: 146 [45056/54000 (83%)] Loss: -1782.556763\n",
      "    epoch          : 146\n",
      "    loss           : -1794.8727543668927\n",
      "    ess            : 8.001185255230597\n",
      "    log_marginal   : 1794.8727543668927\n",
      "    val_loss       : -1796.8414001464844\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1796.8414001464844\n",
      "Train Epoch: 147 [0/54000 (0%)] Loss: -1808.474854\n",
      "Train Epoch: 147 [11264/54000 (21%)] Loss: -1805.111450\n",
      "Train Epoch: 147 [22528/54000 (42%)] Loss: -1790.519531\n",
      "Train Epoch: 147 [33792/54000 (63%)] Loss: -1813.008057\n",
      "Train Epoch: 147 [45056/54000 (83%)] Loss: -1783.530762\n",
      "    epoch          : 147\n",
      "    loss           : -1793.6467722766804\n",
      "    ess            : 8.001185255230597\n",
      "    log_marginal   : 1793.6467722766804\n",
      "    val_loss       : -1791.7341918945312\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1791.7341817220051\n",
      "Train Epoch: 148 [0/54000 (0%)] Loss: -1806.324463\n",
      "Train Epoch: 148 [11264/54000 (21%)] Loss: -1801.825073\n",
      "Train Epoch: 148 [22528/54000 (42%)] Loss: -1769.385742\n",
      "Train Epoch: 148 [33792/54000 (63%)] Loss: -1796.683350\n",
      "Train Epoch: 148 [45056/54000 (83%)] Loss: -1763.512695\n",
      "    epoch          : 148\n",
      "    loss           : -1779.528063504201\n",
      "    ess            : 8.001185705076974\n",
      "    log_marginal   : 1779.5280646558078\n",
      "    val_loss       : -1770.3801981608074\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1770.3801981608074\n",
      "Train Epoch: 149 [0/54000 (0%)] Loss: -1788.149902\n",
      "Train Epoch: 149 [11264/54000 (21%)] Loss: -1775.090698\n",
      "Train Epoch: 149 [22528/54000 (42%)] Loss: -1744.669312\n",
      "Train Epoch: 149 [33792/54000 (63%)] Loss: -1789.141357\n",
      "Train Epoch: 149 [45056/54000 (83%)] Loss: -1732.361450\n",
      "    epoch          : 149\n",
      "    loss           : -1760.5366061228626\n",
      "    ess            : 8.001185714073902\n",
      "    log_marginal   : 1760.5366061228626\n",
      "    val_loss       : -1764.5020039876301\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1764.5020039876301\n",
      "Train Epoch: 150 [0/54000 (0%)] Loss: -1778.696777\n",
      "Train Epoch: 150 [11264/54000 (21%)] Loss: -1773.141968\n",
      "Train Epoch: 150 [22528/54000 (42%)] Loss: -1771.079590\n",
      "Train Epoch: 150 [33792/54000 (63%)] Loss: -1791.936035\n",
      "Train Epoch: 150 [45056/54000 (83%)] Loss: -1758.647949\n",
      "    epoch          : 150\n",
      "    loss           : -1770.748171248526\n",
      "    ess            : 8.001185597113842\n",
      "    log_marginal   : 1770.748171248526\n",
      "    val_loss       : -1784.3660176595051\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1784.3660176595051\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch150.pth ...\n",
      "Train Epoch: 151 [0/54000 (0%)] Loss: -1796.834717\n",
      "Train Epoch: 151 [11264/54000 (21%)] Loss: -1787.521484\n",
      "Train Epoch: 151 [22528/54000 (42%)] Loss: -1778.927002\n",
      "Train Epoch: 151 [33792/54000 (63%)] Loss: -1801.599609\n",
      "Train Epoch: 151 [45056/54000 (83%)] Loss: -1775.207642\n",
      "    epoch          : 151\n",
      "    loss           : -1784.3500469855542\n",
      "    ess            : 8.001185165261322\n",
      "    log_marginal   : 1784.3500469855542\n",
      "    val_loss       : -1794.980244954427\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1794.980244954427\n",
      "Train Epoch: 152 [0/54000 (0%)] Loss: -1806.388794\n",
      "Train Epoch: 152 [11264/54000 (21%)] Loss: -1796.102051\n",
      "Train Epoch: 152 [22528/54000 (42%)] Loss: -1781.220459\n",
      "Train Epoch: 152 [33792/54000 (63%)] Loss: -1805.770020\n",
      "Train Epoch: 152 [45056/54000 (83%)] Loss: -1774.531738\n",
      "    epoch          : 152\n",
      "    loss           : -1787.5654722969487\n",
      "    ess            : 8.001185147267467\n",
      "    log_marginal   : 1787.565471145342\n",
      "    val_loss       : -1791.7142130533855\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1791.7142130533855\n",
      "Train Epoch: 153 [0/54000 (0%)] Loss: -1803.275269\n",
      "Train Epoch: 153 [11264/54000 (21%)] Loss: -1794.833252\n",
      "Train Epoch: 153 [22528/54000 (42%)] Loss: -1778.948730\n",
      "Train Epoch: 153 [33792/54000 (63%)] Loss: -1814.023193\n",
      "Train Epoch: 153 [45056/54000 (83%)] Loss: -1776.463989\n",
      "    epoch          : 153\n",
      "    loss           : -1788.6131534216538\n",
      "    ess            : 8.001185327206018\n",
      "    log_marginal   : 1788.6131534216538\n",
      "    val_loss       : -1789.8441670735676\n",
      "    val_ess        : 8.001184860865274\n",
      "    val_log_marginal: 1789.8441670735676\n",
      "Train Epoch: 154 [0/54000 (0%)] Loss: -1799.791016\n",
      "Train Epoch: 154 [11264/54000 (21%)] Loss: -1800.072998\n",
      "Train Epoch: 154 [22528/54000 (42%)] Loss: -1785.572021\n",
      "Train Epoch: 154 [33792/54000 (63%)] Loss: -1812.958252\n",
      "Train Epoch: 154 [45056/54000 (83%)] Loss: -1783.046143\n",
      "    epoch          : 154\n",
      "    loss           : -1791.2057161151238\n",
      "    ess            : 8.001185048301265\n",
      "    log_marginal   : 1791.205714963517\n",
      "    val_loss       : -1795.5201009114583\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1795.5201009114583\n",
      "Train Epoch: 155 [0/54000 (0%)] Loss: -1807.243042\n",
      "Train Epoch: 155 [11264/54000 (21%)] Loss: -1807.188477\n",
      "Train Epoch: 155 [22528/54000 (42%)] Loss: -1780.895752\n",
      "Train Epoch: 155 [33792/54000 (63%)] Loss: -1806.424805\n",
      "Train Epoch: 155 [45056/54000 (83%)] Loss: -1780.822266\n",
      "    epoch          : 155\n",
      "    loss           : -1790.325034087559\n",
      "    ess            : 8.001185021310482\n",
      "    log_marginal   : 1790.325034087559\n",
      "    val_loss       : -1792.1405436197917\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1792.1405436197917\n",
      "Train Epoch: 156 [0/54000 (0%)] Loss: -1807.510376\n",
      "Train Epoch: 156 [11264/54000 (21%)] Loss: -1794.953369\n",
      "Train Epoch: 156 [22528/54000 (42%)] Loss: -1781.278076\n",
      "Train Epoch: 156 [33792/54000 (63%)] Loss: -1804.555908\n",
      "Train Epoch: 156 [45056/54000 (83%)] Loss: -1783.444214\n",
      "    epoch          : 156\n",
      "    loss           : -1786.4989002155808\n",
      "    ess            : 8.001185147267467\n",
      "    log_marginal   : 1786.4989002155808\n",
      "    val_loss       : -1788.3785196940105\n",
      "    val_ess        : 8.001184622446695\n",
      "    val_log_marginal: 1788.3785196940105\n",
      "Train Epoch: 157 [0/54000 (0%)] Loss: -1802.372803\n",
      "Train Epoch: 157 [11264/54000 (21%)] Loss: -1799.001831\n",
      "Train Epoch: 157 [22528/54000 (42%)] Loss: -1784.740479\n",
      "Train Epoch: 157 [33792/54000 (63%)] Loss: -1800.651611\n",
      "Train Epoch: 157 [45056/54000 (83%)] Loss: -1778.633911\n",
      "    epoch          : 157\n",
      "    loss           : -1786.0549972822082\n",
      "    ess            : 8.001185327206018\n",
      "    log_marginal   : 1786.0549949789947\n",
      "    val_loss       : -1783.4632161458333\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1783.4632161458333\n",
      "Train Epoch: 158 [0/54000 (0%)] Loss: -1794.514893\n",
      "Train Epoch: 158 [11264/54000 (21%)] Loss: -1803.697388\n",
      "Train Epoch: 158 [22528/54000 (42%)] Loss: -1788.787109\n",
      "Train Epoch: 158 [33792/54000 (63%)] Loss: -1814.109131\n",
      "Train Epoch: 158 [45056/54000 (83%)] Loss: -1789.925903\n",
      "    epoch          : 158\n",
      "    loss           : -1792.4269247954746\n",
      "    ess            : 8.001185012313554\n",
      "    log_marginal   : 1792.4269247954746\n",
      "    val_loss       : -1789.7356770833333\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1789.7356770833333\n",
      "Train Epoch: 159 [0/54000 (0%)] Loss: -1797.484131\n",
      "Train Epoch: 159 [11264/54000 (21%)] Loss: -1802.895752\n",
      "Train Epoch: 159 [22528/54000 (42%)] Loss: -1777.738525\n",
      "Train Epoch: 159 [33792/54000 (63%)] Loss: -1790.718872\n",
      "Train Epoch: 159 [45056/54000 (83%)] Loss: -1764.721069\n",
      "    epoch          : 159\n",
      "    loss           : -1778.0730279886498\n",
      "    ess            : 8.001185543132278\n",
      "    log_marginal   : 1778.0730279886498\n",
      "    val_loss       : -1762.1713358561199\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1762.1713053385417\n",
      "Train Epoch: 160 [0/54000 (0%)] Loss: -1775.137207\n",
      "Train Epoch: 160 [11264/54000 (21%)] Loss: -1770.822998\n",
      "Train Epoch: 160 [22528/54000 (42%)] Loss: -1746.751099\n",
      "Train Epoch: 160 [33792/54000 (63%)] Loss: -1789.777588\n",
      "Train Epoch: 160 [45056/54000 (83%)] Loss: -1768.390381\n",
      "    epoch          : 160\n",
      "    loss           : -1760.081223973688\n",
      "    ess            : 8.001185120276684\n",
      "    log_marginal   : 1760.081223973688\n",
      "    val_loss       : -1770.1555786132812\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1770.1555786132812\n",
      "Train Epoch: 161 [0/54000 (0%)] Loss: -1783.544434\n",
      "Train Epoch: 161 [11264/54000 (21%)] Loss: -1759.571533\n",
      "Train Epoch: 161 [22528/54000 (42%)] Loss: -1767.441162\n",
      "Train Epoch: 161 [33792/54000 (63%)] Loss: -1798.909668\n",
      "Train Epoch: 161 [45056/54000 (83%)] Loss: -1774.936523\n",
      "    epoch          : 161\n",
      "    loss           : -1770.465580778302\n",
      "    ess            : 8.001185669089264\n",
      "    log_marginal   : 1770.465580778302\n",
      "    val_loss       : -1780.731221516927\n",
      "    val_ess        : 8.001185973485311\n",
      "    val_log_marginal: 1780.731221516927\n",
      "Train Epoch: 162 [0/54000 (0%)] Loss: -1794.832031\n",
      "Train Epoch: 162 [11264/54000 (21%)] Loss: -1785.122314\n",
      "Train Epoch: 162 [22528/54000 (42%)] Loss: -1781.879395\n",
      "Train Epoch: 162 [33792/54000 (63%)] Loss: -1801.517822\n",
      "Train Epoch: 162 [45056/54000 (83%)] Loss: -1779.933228\n",
      "    epoch          : 162\n",
      "    loss           : -1782.254435989092\n",
      "    ess            : 8.001185759058538\n",
      "    log_marginal   : 1782.2544371406987\n",
      "    val_loss       : -1788.790283203125\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1788.790283203125\n",
      "Train Epoch: 163 [0/54000 (0%)] Loss: -1799.795898\n",
      "Train Epoch: 163 [11264/54000 (21%)] Loss: -1799.654785\n",
      "Train Epoch: 163 [22528/54000 (42%)] Loss: -1777.794800\n",
      "Train Epoch: 163 [33792/54000 (63%)] Loss: -1806.686035\n",
      "Train Epoch: 163 [45056/54000 (83%)] Loss: -1787.440063\n",
      "    epoch          : 163\n",
      "    loss           : -1789.5079794829746\n",
      "    ess            : 8.001185615107698\n",
      "    log_marginal   : 1789.5079806345814\n",
      "    val_loss       : -1794.6497192382812\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1794.6497192382812\n",
      "Train Epoch: 164 [0/54000 (0%)] Loss: -1808.111938\n",
      "Train Epoch: 164 [11264/54000 (21%)] Loss: -1804.455322\n",
      "Train Epoch: 164 [22528/54000 (42%)] Loss: -1781.325439\n",
      "Train Epoch: 164 [33792/54000 (63%)] Loss: -1812.513672\n",
      "Train Epoch: 164 [45056/54000 (83%)] Loss: -1782.702271\n",
      "    epoch          : 164\n",
      "    loss           : -1792.8742813974056\n",
      "    ess            : 8.001185471156859\n",
      "    log_marginal   : 1792.8742813974056\n",
      "    val_loss       : -1796.6937154134114\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1796.6937154134114\n",
      "Train Epoch: 165 [0/54000 (0%)] Loss: -1809.893799\n",
      "Train Epoch: 165 [11264/54000 (21%)] Loss: -1807.387451\n",
      "Train Epoch: 165 [22528/54000 (42%)] Loss: -1786.641357\n",
      "Train Epoch: 165 [33792/54000 (63%)] Loss: -1808.961060\n",
      "Train Epoch: 165 [45056/54000 (83%)] Loss: -1779.326660\n",
      "    epoch          : 165\n",
      "    loss           : -1792.740784843013\n",
      "    ess            : 8.001185381187582\n",
      "    log_marginal   : 1792.740784843013\n",
      "    val_loss       : -1793.4803059895833\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1793.4803059895833\n",
      "Train Epoch: 166 [0/54000 (0%)] Loss: -1807.066650\n",
      "Train Epoch: 166 [11264/54000 (21%)] Loss: -1797.474365\n",
      "Train Epoch: 166 [22528/54000 (42%)] Loss: -1784.523926\n",
      "Train Epoch: 166 [33792/54000 (63%)] Loss: -1811.945190\n",
      "Train Epoch: 166 [45056/54000 (83%)] Loss: -1782.023071\n",
      "    epoch          : 166\n",
      "    loss           : -1789.9906869564416\n",
      "    ess            : 8.001185021310482\n",
      "    log_marginal   : 1789.9906869564416\n",
      "    val_loss       : -1790.7542826334636\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1790.7542826334636\n",
      "Train Epoch: 167 [0/54000 (0%)] Loss: -1803.405640\n",
      "Train Epoch: 167 [11264/54000 (21%)] Loss: -1799.886719\n",
      "Train Epoch: 167 [22528/54000 (42%)] Loss: -1787.630371\n",
      "Train Epoch: 167 [33792/54000 (63%)] Loss: -1817.883545\n",
      "Train Epoch: 167 [45056/54000 (83%)] Loss: -1776.003662\n",
      "    epoch          : 167\n",
      "    loss           : -1791.1448295161408\n",
      "    ess            : 8.001184940338135\n",
      "    log_marginal   : 1791.1448283645343\n",
      "    val_loss       : -1789.3655192057292\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1789.3655192057292\n",
      "Train Epoch: 168 [0/54000 (0%)] Loss: -1800.068481\n",
      "Train Epoch: 168 [11264/54000 (21%)] Loss: -1797.965088\n",
      "Train Epoch: 168 [22528/54000 (42%)] Loss: -1786.110840\n",
      "Train Epoch: 168 [33792/54000 (63%)] Loss: -1811.946289\n",
      "Train Epoch: 168 [45056/54000 (83%)] Loss: -1777.975464\n",
      "    epoch          : 168\n",
      "    loss           : -1788.5828949550412\n",
      "    ess            : 8.001184931341207\n",
      "    log_marginal   : 1788.5828949550412\n",
      "    val_loss       : -1786.945332845052\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1786.945332845052\n",
      "Train Epoch: 169 [0/54000 (0%)] Loss: -1796.385498\n",
      "Train Epoch: 169 [11264/54000 (21%)] Loss: -1792.949463\n",
      "Train Epoch: 169 [22528/54000 (42%)] Loss: -1780.803955\n",
      "Train Epoch: 169 [33792/54000 (63%)] Loss: -1807.141113\n",
      "Train Epoch: 169 [45056/54000 (83%)] Loss: -1783.918213\n",
      "    epoch          : 169\n",
      "    loss           : -1787.7223810159935\n",
      "    ess            : 8.001185147267467\n",
      "    log_marginal   : 1787.7223810159935\n",
      "    val_loss       : -1790.3633219401042\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1790.3633219401042\n",
      "Train Epoch: 170 [0/54000 (0%)] Loss: -1799.274170\n",
      "Train Epoch: 170 [11264/54000 (21%)] Loss: -1801.062500\n",
      "Train Epoch: 170 [22528/54000 (42%)] Loss: -1765.125977\n",
      "Train Epoch: 170 [33792/54000 (63%)] Loss: -1785.819092\n",
      "Train Epoch: 170 [45056/54000 (83%)] Loss: -1768.526367\n",
      "    epoch          : 170\n",
      "    loss           : -1773.8396894346993\n",
      "    ess            : 8.001185255230597\n",
      "    log_marginal   : 1773.8396894346993\n",
      "    val_loss       : -1753.8987121582031\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1753.8987325032551\n",
      "Train Epoch: 171 [0/54000 (0%)] Loss: -1766.431519\n",
      "Train Epoch: 171 [11264/54000 (21%)] Loss: -1766.773682\n",
      "Train Epoch: 171 [22528/54000 (42%)] Loss: -1751.399414\n",
      "Train Epoch: 171 [33792/54000 (63%)] Loss: -1797.529053\n",
      "Train Epoch: 171 [45056/54000 (83%)] Loss: -1776.827515\n",
      "    epoch          : 171\n",
      "    loss           : -1767.4140164357311\n",
      "    ess            : 8.001185156264395\n",
      "    log_marginal   : 1767.4140152841244\n",
      "    val_loss       : -1771.1138102213542\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1771.1138102213542\n",
      "Train Epoch: 172 [0/54000 (0%)] Loss: -1782.119873\n",
      "Train Epoch: 172 [11264/54000 (21%)] Loss: -1792.326294\n",
      "Train Epoch: 172 [22528/54000 (42%)] Loss: -1769.825195\n",
      "Train Epoch: 172 [33792/54000 (63%)] Loss: -1814.582764\n",
      "Train Epoch: 172 [45056/54000 (83%)] Loss: -1777.928467\n",
      "    epoch          : 172\n",
      "    loss           : -1780.9101539467865\n",
      "    ess            : 8.001185273224452\n",
      "    log_marginal   : 1780.9101550983933\n",
      "    val_loss       : -1773.7089233398438\n",
      "    val_ess        : 8.001185496648153\n",
      "    val_log_marginal: 1773.7089233398438\n",
      "Train Epoch: 173 [0/54000 (0%)] Loss: -1785.750488\n",
      "Train Epoch: 173 [11264/54000 (21%)] Loss: -1803.941406\n",
      "Train Epoch: 173 [22528/54000 (42%)] Loss: -1783.856201\n",
      "Train Epoch: 173 [33792/54000 (63%)] Loss: -1802.048950\n",
      "Train Epoch: 173 [45056/54000 (83%)] Loss: -1776.364990\n",
      "    epoch          : 173\n",
      "    loss           : -1786.7102073813385\n",
      "    ess            : 8.001185084288975\n",
      "    log_marginal   : 1786.7102073813385\n",
      "    val_loss       : -1790.1161702473958\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1790.1161804199219\n",
      "Train Epoch: 174 [0/54000 (0%)] Loss: -1800.384521\n",
      "Train Epoch: 174 [11264/54000 (21%)] Loss: -1801.538574\n",
      "Train Epoch: 174 [22528/54000 (42%)] Loss: -1783.912964\n",
      "Train Epoch: 174 [33792/54000 (63%)] Loss: -1800.676270\n",
      "Train Epoch: 174 [45056/54000 (83%)] Loss: -1780.342041\n",
      "    epoch          : 174\n",
      "    loss           : -1787.978925596993\n",
      "    ess            : 8.001185345199874\n",
      "    log_marginal   : 1787.9789244453862\n",
      "    val_loss       : -1788.931884765625\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1788.931884765625\n",
      "Train Epoch: 175 [0/54000 (0%)] Loss: -1799.675903\n",
      "Train Epoch: 175 [11264/54000 (21%)] Loss: -1794.214478\n",
      "Train Epoch: 175 [22528/54000 (42%)] Loss: -1781.885010\n",
      "Train Epoch: 175 [33792/54000 (63%)] Loss: -1772.558105\n",
      "Train Epoch: 175 [45056/54000 (83%)] Loss: -1756.666138\n",
      "    epoch          : 175\n",
      "    loss           : -1772.5769849093456\n",
      "    ess            : 8.001185273224452\n",
      "    log_marginal   : 1772.5769849093456\n",
      "    val_loss       : -1753.8712972005208\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1753.8712972005208\n",
      "Train Epoch: 176 [0/54000 (0%)] Loss: -1767.452881\n",
      "Train Epoch: 176 [11264/54000 (21%)] Loss: -1768.797363\n",
      "Train Epoch: 176 [22528/54000 (42%)] Loss: -1746.022461\n",
      "Train Epoch: 176 [33792/54000 (63%)] Loss: -1770.476318\n",
      "Train Epoch: 176 [45056/54000 (83%)] Loss: -1772.327637\n",
      "    epoch          : 176\n",
      "    loss           : -1759.096857034935\n",
      "    ess            : 8.001185525138423\n",
      "    log_marginal   : 1759.096857034935\n",
      "    val_loss       : -1769.3199971516926\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1769.3200174967449\n",
      "Train Epoch: 177 [0/54000 (0%)] Loss: -1782.361206\n",
      "Train Epoch: 177 [11264/54000 (21%)] Loss: -1785.722290\n",
      "Train Epoch: 177 [22528/54000 (42%)] Loss: -1769.166260\n",
      "Train Epoch: 177 [33792/54000 (63%)] Loss: -1794.469238\n",
      "Train Epoch: 177 [45056/54000 (83%)] Loss: -1784.234131\n",
      "    epoch          : 177\n",
      "    loss           : -1778.9884332620873\n",
      "    ess            : 8.001185516141495\n",
      "    log_marginal   : 1778.9884321104805\n",
      "    val_loss       : -1789.7865498860676\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1789.7865397135417\n",
      "Train Epoch: 178 [0/54000 (0%)] Loss: -1801.452637\n",
      "Train Epoch: 178 [11264/54000 (21%)] Loss: -1804.316895\n",
      "Train Epoch: 178 [22528/54000 (42%)] Loss: -1782.295410\n",
      "Train Epoch: 178 [33792/54000 (63%)] Loss: -1808.465698\n",
      "Train Epoch: 178 [45056/54000 (83%)] Loss: -1789.346558\n",
      "    epoch          : 178\n",
      "    loss           : -1790.5504058262088\n",
      "    ess            : 8.001185705076974\n",
      "    log_marginal   : 1790.5504069778156\n",
      "    val_loss       : -1789.2721455891926\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1789.2721455891926\n",
      "Train Epoch: 179 [0/54000 (0%)] Loss: -1802.435059\n",
      "Train Epoch: 179 [11264/54000 (21%)] Loss: -1791.296997\n",
      "Train Epoch: 179 [22528/54000 (42%)] Loss: -1776.642578\n",
      "Train Epoch: 179 [33792/54000 (63%)] Loss: -1803.198975\n",
      "Train Epoch: 179 [45056/54000 (83%)] Loss: -1783.416504\n",
      "    epoch          : 179\n",
      "    loss           : -1784.0565484964623\n",
      "    ess            : 8.001185489150712\n",
      "    log_marginal   : 1784.0565484964623\n",
      "    val_loss       : -1774.8975830078125\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1774.8975728352864\n",
      "Train Epoch: 180 [0/54000 (0%)] Loss: -1787.145264\n",
      "Train Epoch: 180 [11264/54000 (21%)] Loss: -1799.127441\n",
      "Train Epoch: 180 [22528/54000 (42%)] Loss: -1782.959473\n",
      "Train Epoch: 180 [33792/54000 (63%)] Loss: -1812.563721\n",
      "Train Epoch: 180 [45056/54000 (83%)] Loss: -1792.053101\n",
      "    epoch          : 180\n",
      "    loss           : -1789.9937260465802\n",
      "    ess            : 8.001185363193727\n",
      "    log_marginal   : 1789.9937260465802\n",
      "    val_loss       : -1793.5400492350261\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1793.540059407552\n",
      "Train Epoch: 181 [0/54000 (0%)] Loss: -1805.895508\n",
      "Train Epoch: 181 [11264/54000 (21%)] Loss: -1802.953247\n",
      "Train Epoch: 181 [22528/54000 (42%)] Loss: -1790.607544\n",
      "Train Epoch: 181 [33792/54000 (63%)] Loss: -1809.936035\n",
      "Train Epoch: 181 [45056/54000 (83%)] Loss: -1786.671631\n",
      "    epoch          : 181\n",
      "    loss           : -1792.6008772940006\n",
      "    ess            : 8.001185813040104\n",
      "    log_marginal   : 1792.6008772940006\n",
      "    val_loss       : -1797.0140482584636\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1797.0140380859375\n",
      "Train Epoch: 182 [0/54000 (0%)] Loss: -1808.693359\n",
      "Train Epoch: 182 [11264/54000 (21%)] Loss: -1799.837280\n",
      "Train Epoch: 182 [22528/54000 (42%)] Loss: -1775.979004\n",
      "Train Epoch: 182 [33792/54000 (63%)] Loss: -1807.911865\n",
      "Train Epoch: 182 [45056/54000 (83%)] Loss: -1780.030273\n",
      "    epoch          : 182\n",
      "    loss           : -1788.3352511423939\n",
      "    ess            : 8.00118593899709\n",
      "    log_marginal   : 1788.3352511423939\n",
      "    val_loss       : -1790.5212300618489\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1790.5212300618489\n",
      "Train Epoch: 183 [0/54000 (0%)] Loss: -1801.853149\n",
      "Train Epoch: 183 [11264/54000 (21%)] Loss: -1798.205811\n",
      "Train Epoch: 183 [22528/54000 (42%)] Loss: -1779.013306\n",
      "Train Epoch: 183 [33792/54000 (63%)] Loss: -1804.921143\n",
      "Train Epoch: 183 [45056/54000 (83%)] Loss: -1778.191895\n",
      "    epoch          : 183\n",
      "    loss           : -1787.9516325176887\n",
      "    ess            : 8.001185795046249\n",
      "    log_marginal   : 1787.951631366082\n",
      "    val_loss       : -1791.878153483073\n",
      "    val_ess        : 8.001185973485311\n",
      "    val_log_marginal: 1791.878153483073\n",
      "Train Epoch: 184 [0/54000 (0%)] Loss: -1803.788818\n",
      "Train Epoch: 184 [11264/54000 (21%)] Loss: -1801.968384\n",
      "Train Epoch: 184 [22528/54000 (42%)] Loss: -1783.924561\n",
      "Train Epoch: 184 [33792/54000 (63%)] Loss: -1812.891357\n",
      "Train Epoch: 184 [45056/54000 (83%)] Loss: -1792.490723\n",
      "    epoch          : 184\n",
      "    loss           : -1793.4603985480542\n",
      "    ess            : 8.001185795046249\n",
      "    log_marginal   : 1793.4603985480542\n",
      "    val_loss       : -1799.8872985839844\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1799.8872985839844\n",
      "Train Epoch: 185 [0/54000 (0%)] Loss: -1809.260620\n",
      "Train Epoch: 185 [11264/54000 (21%)] Loss: -1808.880127\n",
      "Train Epoch: 185 [22528/54000 (42%)] Loss: -1791.222412\n",
      "Train Epoch: 185 [33792/54000 (63%)] Loss: -1817.316528\n",
      "Train Epoch: 185 [45056/54000 (83%)] Loss: -1781.414307\n",
      "    epoch          : 185\n",
      "    loss           : -1795.9134360259434\n",
      "    ess            : 8.001185363193727\n",
      "    log_marginal   : 1795.9134360259434\n",
      "    val_loss       : -1791.357157389323\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1791.357157389323\n",
      "Train Epoch: 186 [0/54000 (0%)] Loss: -1801.947998\n",
      "Train Epoch: 186 [11264/54000 (21%)] Loss: -1808.661987\n",
      "Train Epoch: 186 [22528/54000 (42%)] Loss: -1791.196045\n",
      "Train Epoch: 186 [33792/54000 (63%)] Loss: -1814.480103\n",
      "Train Epoch: 186 [45056/54000 (83%)] Loss: -1787.813721\n",
      "    epoch          : 186\n",
      "    loss           : -1795.3289564600532\n",
      "    ess            : 8.001185309212163\n",
      "    log_marginal   : 1795.3289564600532\n",
      "    val_loss       : -1794.7070821126301\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1794.7070821126301\n",
      "Train Epoch: 187 [0/54000 (0%)] Loss: -1806.556396\n",
      "Train Epoch: 187 [11264/54000 (21%)] Loss: -1805.244263\n",
      "Train Epoch: 187 [22528/54000 (42%)] Loss: -1787.660034\n",
      "Train Epoch: 187 [33792/54000 (63%)] Loss: -1810.413940\n",
      "Train Epoch: 187 [45056/54000 (83%)] Loss: -1779.414185\n",
      "    epoch          : 187\n",
      "    loss           : -1792.3609561560288\n",
      "    ess            : 8.001185237236744\n",
      "    log_marginal   : 1792.3609561560288\n",
      "    val_loss       : -1795.8257446289062\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1795.8257548014324\n",
      "Train Epoch: 188 [0/54000 (0%)] Loss: -1807.671143\n",
      "Train Epoch: 188 [11264/54000 (21%)] Loss: -1785.141724\n",
      "Train Epoch: 188 [22528/54000 (42%)] Loss: -1784.344116\n",
      "Train Epoch: 188 [33792/54000 (63%)] Loss: -1810.212158\n",
      "Train Epoch: 188 [45056/54000 (83%)] Loss: -1782.030029\n",
      "    epoch          : 188\n",
      "    loss           : -1788.3957865013267\n",
      "    ess            : 8.001185345199874\n",
      "    log_marginal   : 1788.3957876529334\n",
      "    val_loss       : -1795.1515808105469\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1795.151590983073\n",
      "Train Epoch: 189 [0/54000 (0%)] Loss: -1808.577881\n",
      "Train Epoch: 189 [11264/54000 (21%)] Loss: -1804.823486\n",
      "Train Epoch: 189 [22528/54000 (42%)] Loss: -1784.916992\n",
      "Train Epoch: 189 [33792/54000 (63%)] Loss: -1810.292725\n",
      "Train Epoch: 189 [45056/54000 (83%)] Loss: -1782.093750\n",
      "    epoch          : 189\n",
      "    loss           : -1792.4436012124115\n",
      "    ess            : 8.001185525138423\n",
      "    log_marginal   : 1792.4436000608048\n",
      "    val_loss       : -1787.3125101725261\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1787.3125101725261\n",
      "Train Epoch: 190 [0/54000 (0%)] Loss: -1799.518799\n",
      "Train Epoch: 190 [11264/54000 (21%)] Loss: -1786.627075\n",
      "Train Epoch: 190 [22528/54000 (42%)] Loss: -1759.023560\n",
      "Train Epoch: 190 [33792/54000 (63%)] Loss: -1786.070068\n",
      "Train Epoch: 190 [45056/54000 (83%)] Loss: -1776.819336\n",
      "    epoch          : 190\n",
      "    loss           : -1774.9343077461674\n",
      "    ess            : 8.00118564209848\n",
      "    log_marginal   : 1774.9343077461674\n",
      "    val_loss       : -1787.826904296875\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1787.826904296875\n",
      "Train Epoch: 191 [0/54000 (0%)] Loss: -1798.263428\n",
      "Train Epoch: 191 [11264/54000 (21%)] Loss: -1790.066406\n",
      "Train Epoch: 191 [22528/54000 (42%)] Loss: -1783.127930\n",
      "Train Epoch: 191 [33792/54000 (63%)] Loss: -1804.853271\n",
      "Train Epoch: 191 [45056/54000 (83%)] Loss: -1780.396973\n",
      "    epoch          : 191\n",
      "    loss           : -1784.8261546008991\n",
      "    ess            : 8.00118531820909\n",
      "    log_marginal   : 1784.8261534492924\n",
      "    val_loss       : -1786.5733235677083\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1786.5733235677083\n",
      "Train Epoch: 192 [0/54000 (0%)] Loss: -1798.375000\n",
      "Train Epoch: 192 [11264/54000 (21%)] Loss: -1793.609375\n",
      "Train Epoch: 192 [22528/54000 (42%)] Loss: -1783.367432\n",
      "Train Epoch: 192 [33792/54000 (63%)] Loss: -1810.167969\n",
      "Train Epoch: 192 [45056/54000 (83%)] Loss: -1781.150391\n",
      "    epoch          : 192\n",
      "    loss           : -1787.3906987028302\n",
      "    ess            : 8.001185525138423\n",
      "    log_marginal   : 1787.3906975512234\n",
      "    val_loss       : -1791.283223470052\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1791.283223470052\n",
      "Train Epoch: 193 [0/54000 (0%)] Loss: -1806.105957\n",
      "Train Epoch: 193 [11264/54000 (21%)] Loss: -1802.686768\n",
      "Train Epoch: 193 [22528/54000 (42%)] Loss: -1789.459229\n",
      "Train Epoch: 193 [33792/54000 (63%)] Loss: -1813.950073\n",
      "Train Epoch: 193 [45056/54000 (83%)] Loss: -1786.593506\n",
      "    epoch          : 193\n",
      "    loss           : -1792.5006068967423\n",
      "    ess            : 8.001185462159931\n",
      "    log_marginal   : 1792.5006068967423\n",
      "    val_loss       : -1795.6570434570312\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1795.6570434570312\n",
      "Train Epoch: 194 [0/54000 (0%)] Loss: -1809.496338\n",
      "Train Epoch: 194 [11264/54000 (21%)] Loss: -1809.150024\n",
      "Train Epoch: 194 [22528/54000 (42%)] Loss: -1789.172852\n",
      "Train Epoch: 194 [33792/54000 (63%)] Loss: -1804.615234\n",
      "Train Epoch: 194 [45056/54000 (83%)] Loss: -1780.843750\n",
      "    epoch          : 194\n",
      "    loss           : -1791.4117800154777\n",
      "    ess            : 8.001185165261322\n",
      "    log_marginal   : 1791.411778863871\n",
      "    val_loss       : -1795.9240214029949\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1795.9240214029949\n",
      "Train Epoch: 195 [0/54000 (0%)] Loss: -1809.638550\n",
      "Train Epoch: 195 [11264/54000 (21%)] Loss: -1799.708740\n",
      "Train Epoch: 195 [22528/54000 (42%)] Loss: -1784.159912\n",
      "Train Epoch: 195 [33792/54000 (63%)] Loss: -1805.850342\n",
      "Train Epoch: 195 [45056/54000 (83%)] Loss: -1788.601318\n",
      "    epoch          : 195\n",
      "    loss           : -1792.6960909861439\n",
      "    ess            : 8.00118474240573\n",
      "    log_marginal   : 1792.6960909861439\n",
      "    val_loss       : -1800.1433512369792\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1800.1433512369792\n",
      "Train Epoch: 196 [0/54000 (0%)] Loss: -1812.090820\n",
      "Train Epoch: 196 [11264/54000 (21%)] Loss: -1808.637329\n",
      "Train Epoch: 196 [22528/54000 (42%)] Loss: -1790.233032\n",
      "Train Epoch: 196 [33792/54000 (63%)] Loss: -1806.571899\n",
      "Train Epoch: 196 [45056/54000 (83%)] Loss: -1784.660645\n",
      "    epoch          : 196\n",
      "    loss           : -1792.4374850291126\n",
      "    ess            : 8.001184751402658\n",
      "    log_marginal   : 1792.4374861807194\n",
      "    val_loss       : -1773.2536214192708\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1773.2536214192708\n",
      "Train Epoch: 197 [0/54000 (0%)] Loss: -1787.633789\n",
      "Train Epoch: 197 [11264/54000 (21%)] Loss: -1749.350098\n",
      "Train Epoch: 197 [22528/54000 (42%)] Loss: -1759.925903\n",
      "Train Epoch: 197 [33792/54000 (63%)] Loss: -1759.652710\n",
      "Train Epoch: 197 [45056/54000 (83%)] Loss: -1740.438599\n",
      "    epoch          : 197\n",
      "    loss           : -1757.2230282189712\n",
      "    ess            : 8.001185588116916\n",
      "    log_marginal   : 1757.2230282189712\n",
      "    val_loss       : -1756.7794291178386\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1756.7794291178386\n",
      "Train Epoch: 198 [0/54000 (0%)] Loss: -1770.166626\n",
      "Train Epoch: 198 [11264/54000 (21%)] Loss: -1768.841797\n",
      "Train Epoch: 198 [22528/54000 (42%)] Loss: -1771.064209\n",
      "Train Epoch: 198 [33792/54000 (63%)] Loss: -1788.129028\n",
      "Train Epoch: 198 [45056/54000 (83%)] Loss: -1762.694702\n",
      "    epoch          : 198\n",
      "    loss           : -1767.8886937555278\n",
      "    ess            : 8.001185462159931\n",
      "    log_marginal   : 1767.8886937555278\n",
      "    val_loss       : -1771.499003092448\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1771.499003092448\n",
      "Train Epoch: 199 [0/54000 (0%)] Loss: -1780.867432\n",
      "Train Epoch: 199 [11264/54000 (21%)] Loss: -1791.668213\n",
      "Train Epoch: 199 [22528/54000 (42%)] Loss: -1792.174072\n",
      "Train Epoch: 199 [33792/54000 (63%)] Loss: -1806.286255\n",
      "Train Epoch: 199 [45056/54000 (83%)] Loss: -1772.799561\n",
      "    epoch          : 199\n",
      "    loss           : -1785.5375665628685\n",
      "    ess            : 8.001185417175293\n",
      "    log_marginal   : 1785.5375654112618\n",
      "    val_loss       : -1785.5346374511719\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1785.5346374511719\n",
      "Train Epoch: 200 [0/54000 (0%)] Loss: -1796.117432\n",
      "Train Epoch: 200 [11264/54000 (21%)] Loss: -1797.137939\n",
      "Train Epoch: 200 [22528/54000 (42%)] Loss: -1788.807495\n",
      "Train Epoch: 200 [33792/54000 (63%)] Loss: -1803.312012\n",
      "Train Epoch: 200 [45056/54000 (83%)] Loss: -1783.060547\n",
      "    epoch          : 200\n",
      "    loss           : -1787.532561680056\n",
      "    ess            : 8.001185489150712\n",
      "    log_marginal   : 1787.532561680056\n",
      "    val_loss       : -1791.8055826822917\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1791.8055623372395\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch200.pth ...\n",
      "Train Epoch: 201 [0/54000 (0%)] Loss: -1803.234375\n",
      "Train Epoch: 201 [11264/54000 (21%)] Loss: -1797.478760\n",
      "Train Epoch: 201 [22528/54000 (42%)] Loss: -1782.193604\n",
      "Train Epoch: 201 [33792/54000 (63%)] Loss: -1797.926270\n",
      "Train Epoch: 201 [45056/54000 (83%)] Loss: -1784.133545\n",
      "    epoch          : 201\n",
      "    loss           : -1788.2917872015034\n",
      "    ess            : 8.001185309212163\n",
      "    log_marginal   : 1788.2917872015034\n",
      "    val_loss       : -1795.2672017415364\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1795.2672017415364\n",
      "Train Epoch: 202 [0/54000 (0%)] Loss: -1807.453613\n",
      "Train Epoch: 202 [11264/54000 (21%)] Loss: -1808.105591\n",
      "Train Epoch: 202 [22528/54000 (42%)] Loss: -1785.987549\n",
      "Train Epoch: 202 [33792/54000 (63%)] Loss: -1794.720947\n",
      "Train Epoch: 202 [45056/54000 (83%)] Loss: -1776.965820\n",
      "    epoch          : 202\n",
      "    loss           : -1786.961430387677\n",
      "    ess            : 8.001185372190655\n",
      "    log_marginal   : 1786.9614280844635\n",
      "    val_loss       : -1790.2434794108074\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1790.2434794108074\n",
      "Train Epoch: 203 [0/54000 (0%)] Loss: -1802.288452\n",
      "Train Epoch: 203 [11264/54000 (21%)] Loss: -1802.016602\n",
      "Train Epoch: 203 [22528/54000 (42%)] Loss: -1777.137207\n",
      "Train Epoch: 203 [33792/54000 (63%)] Loss: -1801.352905\n",
      "Train Epoch: 203 [45056/54000 (83%)] Loss: -1783.388306\n",
      "    epoch          : 203\n",
      "    loss           : -1788.6254986457104\n",
      "    ess            : 8.001185183255178\n",
      "    log_marginal   : 1788.6254986457104\n",
      "    val_loss       : -1798.8708902994792\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1798.8708902994792\n",
      "Train Epoch: 204 [0/54000 (0%)] Loss: -1808.666504\n",
      "Train Epoch: 204 [11264/54000 (21%)] Loss: -1800.725342\n",
      "Train Epoch: 204 [22528/54000 (42%)] Loss: -1783.130981\n",
      "Train Epoch: 204 [33792/54000 (63%)] Loss: -1805.057617\n",
      "Train Epoch: 204 [45056/54000 (83%)] Loss: -1787.189941\n",
      "    epoch          : 204\n",
      "    loss           : -1790.2321063347583\n",
      "    ess            : 8.001185291218308\n",
      "    log_marginal   : 1790.2321063347583\n",
      "    val_loss       : -1800.7127482096355\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1800.7127482096355\n",
      "Train Epoch: 205 [0/54000 (0%)] Loss: -1811.423096\n",
      "Train Epoch: 205 [11264/54000 (21%)] Loss: -1807.897461\n",
      "Train Epoch: 205 [22528/54000 (42%)] Loss: -1791.659302\n",
      "Train Epoch: 205 [33792/54000 (63%)] Loss: -1811.899414\n",
      "Train Epoch: 205 [45056/54000 (83%)] Loss: -1789.540649\n",
      "    epoch          : 205\n",
      "    loss           : -1795.1532408516362\n",
      "    ess            : 8.001185039304337\n",
      "    log_marginal   : 1795.1532408516362\n",
      "    val_loss       : -1795.7101542154949\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1795.7101542154949\n",
      "Train Epoch: 206 [0/54000 (0%)] Loss: -1807.867188\n",
      "Train Epoch: 206 [11264/54000 (21%)] Loss: -1805.112061\n",
      "Train Epoch: 206 [22528/54000 (42%)] Loss: -1782.987793\n",
      "Train Epoch: 206 [33792/54000 (63%)] Loss: -1812.658081\n",
      "Train Epoch: 206 [45056/54000 (83%)] Loss: -1787.154785\n",
      "    epoch          : 206\n",
      "    loss           : -1789.9173215470223\n",
      "    ess            : 8.0011849943197\n",
      "    log_marginal   : 1789.917322698629\n",
      "    val_loss       : -1766.115946451823\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1766.115946451823\n",
      "Train Epoch: 207 [0/54000 (0%)] Loss: -1781.155151\n",
      "Train Epoch: 207 [11264/54000 (21%)] Loss: -1783.340820\n",
      "Train Epoch: 207 [22528/54000 (42%)] Loss: -1755.797974\n",
      "Train Epoch: 207 [33792/54000 (63%)] Loss: -1794.038574\n",
      "Train Epoch: 207 [45056/54000 (83%)] Loss: -1771.788818\n",
      "    epoch          : 207\n",
      "    loss           : -1771.2974692290684\n",
      "    ess            : 8.001185795046249\n",
      "    log_marginal   : 1771.2974703806751\n",
      "    val_loss       : -1779.0291035970051\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1779.0290832519531\n",
      "Train Epoch: 208 [0/54000 (0%)] Loss: -1790.087402\n",
      "Train Epoch: 208 [11264/54000 (21%)] Loss: -1793.397217\n",
      "Train Epoch: 208 [22528/54000 (42%)] Loss: -1759.514282\n",
      "Train Epoch: 208 [33792/54000 (63%)] Loss: -1776.051025\n",
      "Train Epoch: 208 [45056/54000 (83%)] Loss: -1759.679810\n",
      "    epoch          : 208\n",
      "    loss           : -1767.0276235904334\n",
      "    ess            : 8.001185363193727\n",
      "    log_marginal   : 1767.0276247420402\n",
      "    val_loss       : -1752.2374471028645\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1752.2374471028645\n",
      "Train Epoch: 209 [0/54000 (0%)] Loss: -1764.188965\n",
      "Train Epoch: 209 [11264/54000 (21%)] Loss: -1769.793457\n",
      "Train Epoch: 209 [22528/54000 (42%)] Loss: -1760.014526\n",
      "Train Epoch: 209 [33792/54000 (63%)] Loss: -1794.140869\n",
      "Train Epoch: 209 [45056/54000 (83%)] Loss: -1782.030029\n",
      "    epoch          : 209\n",
      "    loss           : -1770.0789023345371\n",
      "    ess            : 8.001185480153785\n",
      "    log_marginal   : 1770.0789023345371\n",
      "    val_loss       : -1779.4734598795574\n",
      "    val_ess        : 8.001185178756714\n",
      "    val_log_marginal: 1779.4734700520833\n",
      "Train Epoch: 210 [0/54000 (0%)] Loss: -1787.094727\n",
      "Train Epoch: 210 [11264/54000 (21%)] Loss: -1794.332031\n",
      "Train Epoch: 210 [22528/54000 (42%)] Loss: -1777.244263\n",
      "Train Epoch: 210 [33792/54000 (63%)] Loss: -1803.817627\n",
      "Train Epoch: 210 [45056/54000 (83%)] Loss: -1783.928467\n",
      "    epoch          : 210\n",
      "    loss           : -1784.4583486880897\n",
      "    ess            : 8.001185525138423\n",
      "    log_marginal   : 1784.4583498396964\n",
      "    val_loss       : -1788.6804300944011\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1788.6804300944011\n",
      "Train Epoch: 211 [0/54000 (0%)] Loss: -1799.398438\n",
      "Train Epoch: 211 [11264/54000 (21%)] Loss: -1806.433960\n",
      "Train Epoch: 211 [22528/54000 (42%)] Loss: -1784.237061\n",
      "Train Epoch: 211 [33792/54000 (63%)] Loss: -1810.516235\n",
      "Train Epoch: 211 [45056/54000 (83%)] Loss: -1792.447144\n",
      "    epoch          : 211\n",
      "    loss           : -1793.0796531821197\n",
      "    ess            : 8.00118539018451\n",
      "    log_marginal   : 1793.0796531821197\n",
      "    val_loss       : -1793.5355326334636\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1793.5355326334636\n",
      "Train Epoch: 212 [0/54000 (0%)] Loss: -1803.281372\n",
      "Train Epoch: 212 [11264/54000 (21%)] Loss: -1807.281738\n",
      "Train Epoch: 212 [22528/54000 (42%)] Loss: -1790.176880\n",
      "Train Epoch: 212 [33792/54000 (63%)] Loss: -1812.390991\n",
      "Train Epoch: 212 [45056/54000 (83%)] Loss: -1781.966797\n",
      "    epoch          : 212\n",
      "    loss           : -1792.6714558151532\n",
      "    ess            : 8.001185228239816\n",
      "    log_marginal   : 1792.6714558151532\n",
      "    val_loss       : -1789.5299377441406\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1789.5299377441406\n",
      "Train Epoch: 213 [0/54000 (0%)] Loss: -1797.411621\n",
      "Train Epoch: 213 [11264/54000 (21%)] Loss: -1801.473633\n",
      "Train Epoch: 213 [22528/54000 (42%)] Loss: -1783.190063\n",
      "Train Epoch: 213 [33792/54000 (63%)] Loss: -1809.518555\n",
      "Train Epoch: 213 [45056/54000 (83%)] Loss: -1788.565796\n",
      "    epoch          : 213\n",
      "    loss           : -1790.8659057617188\n",
      "    ess            : 8.001185111279758\n",
      "    log_marginal   : 1790.8659057617188\n",
      "    val_loss       : -1795.6422017415364\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1795.6422017415364\n",
      "Train Epoch: 214 [0/54000 (0%)] Loss: -1805.364624\n",
      "Train Epoch: 214 [11264/54000 (21%)] Loss: -1810.585571\n",
      "Train Epoch: 214 [22528/54000 (42%)] Loss: -1792.260498\n",
      "Train Epoch: 214 [33792/54000 (63%)] Loss: -1815.822021\n",
      "Train Epoch: 214 [45056/54000 (83%)] Loss: -1790.056641\n",
      "    epoch          : 214\n",
      "    loss           : -1797.6063094229069\n",
      "    ess            : 8.001184859365788\n",
      "    log_marginal   : 1797.6063094229069\n",
      "    val_loss       : -1800.6784261067708\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1800.6784261067708\n",
      "Train Epoch: 215 [0/54000 (0%)] Loss: -1812.745117\n",
      "Train Epoch: 215 [11264/54000 (21%)] Loss: -1810.444458\n",
      "Train Epoch: 215 [22528/54000 (42%)] Loss: -1782.859009\n",
      "Train Epoch: 215 [33792/54000 (63%)] Loss: -1808.255859\n",
      "Train Epoch: 215 [45056/54000 (83%)] Loss: -1790.510742\n",
      "    epoch          : 215\n",
      "    loss           : -1793.8440379016804\n",
      "    ess            : 8.001184805384222\n",
      "    log_marginal   : 1793.8440379016804\n",
      "    val_loss       : -1799.6165059407551\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1799.6165059407551\n",
      "Train Epoch: 216 [0/54000 (0%)] Loss: -1809.808105\n",
      "Train Epoch: 216 [11264/54000 (21%)] Loss: -1811.413086\n",
      "Train Epoch: 216 [22528/54000 (42%)] Loss: -1789.753662\n",
      "Train Epoch: 216 [33792/54000 (63%)] Loss: -1809.342041\n",
      "Train Epoch: 216 [45056/54000 (83%)] Loss: -1789.945801\n",
      "    epoch          : 216\n",
      "    loss           : -1795.9822882886203\n",
      "    ess            : 8.001184886356569\n",
      "    log_marginal   : 1795.9822882886203\n",
      "    val_loss       : -1799.8282368977864\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1799.8282368977864\n",
      "Train Epoch: 217 [0/54000 (0%)] Loss: -1811.902710\n",
      "Train Epoch: 217 [11264/54000 (21%)] Loss: -1812.087891\n",
      "Train Epoch: 217 [22528/54000 (42%)] Loss: -1790.861328\n",
      "Train Epoch: 217 [33792/54000 (63%)] Loss: -1814.174561\n",
      "Train Epoch: 217 [45056/54000 (83%)] Loss: -1791.546387\n",
      "    epoch          : 217\n",
      "    loss           : -1797.1645565392837\n",
      "    ess            : 8.001184454504049\n",
      "    log_marginal   : 1797.1645576908904\n",
      "    val_loss       : -1798.7996012369792\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1798.7996012369792\n",
      "Train Epoch: 218 [0/54000 (0%)] Loss: -1811.979004\n",
      "Train Epoch: 218 [11264/54000 (21%)] Loss: -1809.704346\n",
      "Train Epoch: 218 [22528/54000 (42%)] Loss: -1794.825684\n",
      "Train Epoch: 218 [33792/54000 (63%)] Loss: -1811.513306\n",
      "Train Epoch: 218 [45056/54000 (83%)] Loss: -1783.379150\n",
      "    epoch          : 218\n",
      "    loss           : -1795.3959707584022\n",
      "    ess            : 8.001184535476396\n",
      "    log_marginal   : 1795.3959707584022\n",
      "    val_loss       : -1796.6018371582031\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1796.6018371582031\n",
      "Train Epoch: 219 [0/54000 (0%)] Loss: -1807.529541\n",
      "Train Epoch: 219 [11264/54000 (21%)] Loss: -1807.599365\n",
      "Train Epoch: 219 [22528/54000 (42%)] Loss: -1785.090698\n",
      "Train Epoch: 219 [33792/54000 (63%)] Loss: -1811.778320\n",
      "Train Epoch: 219 [45056/54000 (83%)] Loss: -1787.968506\n",
      "    epoch          : 219\n",
      "    loss           : -1793.661530116819\n",
      "    ess            : 8.001185309212163\n",
      "    log_marginal   : 1793.6615289652123\n",
      "    val_loss       : -1796.1594848632812\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1796.1594848632812\n",
      "Train Epoch: 220 [0/54000 (0%)] Loss: -1806.794312\n",
      "Train Epoch: 220 [11264/54000 (21%)] Loss: -1808.041382\n",
      "Train Epoch: 220 [22528/54000 (42%)] Loss: -1787.944824\n",
      "Train Epoch: 220 [33792/54000 (63%)] Loss: -1809.779663\n",
      "Train Epoch: 220 [45056/54000 (83%)] Loss: -1787.122192\n",
      "    epoch          : 220\n",
      "    loss           : -1794.371168604437\n",
      "    ess            : 8.001184472497904\n",
      "    log_marginal   : 1794.371168604437\n",
      "    val_loss       : -1796.4734903971355\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1796.4734903971355\n",
      "Train Epoch: 221 [0/54000 (0%)] Loss: -1808.437500\n",
      "Train Epoch: 221 [11264/54000 (21%)] Loss: -1801.873291\n",
      "Train Epoch: 221 [22528/54000 (42%)] Loss: -1791.706787\n",
      "Train Epoch: 221 [33792/54000 (63%)] Loss: -1817.643066\n",
      "Train Epoch: 221 [45056/54000 (83%)] Loss: -1791.137207\n",
      "    epoch          : 221\n",
      "    loss           : -1795.781733674823\n",
      "    ess            : 8.001184499488687\n",
      "    log_marginal   : 1795.781733674823\n",
      "    val_loss       : -1797.9358927408855\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1797.9358927408855\n",
      "Train Epoch: 222 [0/54000 (0%)] Loss: -1810.137695\n",
      "Train Epoch: 222 [11264/54000 (21%)] Loss: -1809.950806\n",
      "Train Epoch: 222 [22528/54000 (42%)] Loss: -1800.194336\n",
      "Train Epoch: 222 [33792/54000 (63%)] Loss: -1808.027710\n",
      "Train Epoch: 222 [45056/54000 (83%)] Loss: -1789.417480\n",
      "    epoch          : 222\n",
      "    loss           : -1798.0314169829746\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1798.0314169829746\n",
      "    val_loss       : -1799.0798848470051\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1799.0798645019531\n",
      "Train Epoch: 223 [0/54000 (0%)] Loss: -1811.274414\n",
      "Train Epoch: 223 [11264/54000 (21%)] Loss: -1811.375732\n",
      "Train Epoch: 223 [22528/54000 (42%)] Loss: -1784.171509\n",
      "Train Epoch: 223 [33792/54000 (63%)] Loss: -1802.303467\n",
      "Train Epoch: 223 [45056/54000 (83%)] Loss: -1792.163330\n",
      "    epoch          : 223\n",
      "    loss           : -1793.2951878961528\n",
      "    ess            : 8.00118394167918\n",
      "    log_marginal   : 1793.2951878961528\n",
      "    val_loss       : -1795.208740234375\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1795.208740234375\n",
      "Train Epoch: 224 [0/54000 (0%)] Loss: -1808.894165\n",
      "Train Epoch: 224 [11264/54000 (21%)] Loss: -1807.938232\n",
      "Train Epoch: 224 [22528/54000 (42%)] Loss: -1788.583496\n",
      "Train Epoch: 224 [33792/54000 (63%)] Loss: -1819.577026\n",
      "Train Epoch: 224 [45056/54000 (83%)] Loss: -1792.190796\n",
      "    epoch          : 224\n",
      "    loss           : -1797.001018020342\n",
      "    ess            : 8.0011842745655\n",
      "    log_marginal   : 1797.0010168687352\n",
      "    val_loss       : -1790.4629007975261\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1790.4629007975261\n",
      "Train Epoch: 225 [0/54000 (0%)] Loss: -1802.542725\n",
      "Train Epoch: 225 [11264/54000 (21%)] Loss: -1806.649170\n",
      "Train Epoch: 225 [22528/54000 (42%)] Loss: -1792.648804\n",
      "Train Epoch: 225 [33792/54000 (63%)] Loss: -1815.614624\n",
      "Train Epoch: 225 [45056/54000 (83%)] Loss: -1787.830078\n",
      "    epoch          : 225\n",
      "    loss           : -1793.9323246793927\n",
      "    ess            : 8.001183707759065\n",
      "    log_marginal   : 1793.9323246793927\n",
      "    val_loss       : -1789.8710225423176\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1789.8710428873699\n",
      "Train Epoch: 226 [0/54000 (0%)] Loss: -1802.365723\n",
      "Train Epoch: 226 [11264/54000 (21%)] Loss: -1801.994385\n",
      "Train Epoch: 226 [22528/54000 (42%)] Loss: -1792.333984\n",
      "Train Epoch: 226 [33792/54000 (63%)] Loss: -1802.349365\n",
      "Train Epoch: 226 [45056/54000 (83%)] Loss: -1780.640869\n",
      "    epoch          : 226\n",
      "    loss           : -1789.989435159935\n",
      "    ess            : 8.001184022651529\n",
      "    log_marginal   : 1789.989435159935\n",
      "    val_loss       : -1791.82470703125\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1791.82470703125\n",
      "Train Epoch: 227 [0/54000 (0%)] Loss: -1805.057617\n",
      "Train Epoch: 227 [11264/54000 (21%)] Loss: -1798.200562\n",
      "Train Epoch: 227 [22528/54000 (42%)] Loss: -1780.030762\n",
      "Train Epoch: 227 [33792/54000 (63%)] Loss: -1793.964600\n",
      "Train Epoch: 227 [45056/54000 (83%)] Loss: -1778.961914\n",
      "    epoch          : 227\n",
      "    loss           : -1779.5626358895931\n",
      "    ess            : 8.001185075292048\n",
      "    log_marginal   : 1779.5626358895931\n",
      "    val_loss       : -1766.876953125\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1766.876932779948\n",
      "Train Epoch: 228 [0/54000 (0%)] Loss: -1776.828979\n",
      "Train Epoch: 228 [11264/54000 (21%)] Loss: -1792.458008\n",
      "Train Epoch: 228 [22528/54000 (42%)] Loss: -1763.672119\n",
      "Train Epoch: 228 [33792/54000 (63%)] Loss: -1794.979370\n",
      "Train Epoch: 228 [45056/54000 (83%)] Loss: -1774.307129\n",
      "    epoch          : 228\n",
      "    loss           : -1773.1057819870282\n",
      "    ess            : 8.001185336202946\n",
      "    log_marginal   : 1773.105783138635\n",
      "    val_loss       : -1789.512959798177\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1789.512959798177\n",
      "Train Epoch: 229 [0/54000 (0%)] Loss: -1799.336304\n",
      "Train Epoch: 229 [11264/54000 (21%)] Loss: -1808.458862\n",
      "Train Epoch: 229 [22528/54000 (42%)] Loss: -1789.226074\n",
      "Train Epoch: 229 [33792/54000 (63%)] Loss: -1812.146484\n",
      "Train Epoch: 229 [45056/54000 (83%)] Loss: -1788.419556\n",
      "    epoch          : 229\n",
      "    loss           : -1792.7716697836822\n",
      "    ess            : 8.001184148608514\n",
      "    log_marginal   : 1792.771670935289\n",
      "    val_loss       : -1801.2276306152344\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1801.2276306152344\n",
      "Train Epoch: 230 [0/54000 (0%)] Loss: -1811.473877\n",
      "Train Epoch: 230 [11264/54000 (21%)] Loss: -1813.850586\n",
      "Train Epoch: 230 [22528/54000 (42%)] Loss: -1789.222046\n",
      "Train Epoch: 230 [33792/54000 (63%)] Loss: -1813.446167\n",
      "Train Epoch: 230 [45056/54000 (83%)] Loss: -1789.357910\n",
      "    epoch          : 230\n",
      "    loss           : -1796.9561986383403\n",
      "    ess            : 8.001184139611587\n",
      "    log_marginal   : 1796.9561986383403\n",
      "    val_loss       : -1796.3209228515625\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1796.3209228515625\n",
      "Train Epoch: 231 [0/54000 (0%)] Loss: -1808.595581\n",
      "Train Epoch: 231 [11264/54000 (21%)] Loss: -1796.127197\n",
      "Train Epoch: 231 [22528/54000 (42%)] Loss: -1781.527100\n",
      "Train Epoch: 231 [33792/54000 (63%)] Loss: -1810.772949\n",
      "Train Epoch: 231 [45056/54000 (83%)] Loss: -1787.704712\n",
      "    epoch          : 231\n",
      "    loss           : -1789.6820920548348\n",
      "    ess            : 8.001183815722195\n",
      "    log_marginal   : 1789.6820920548348\n",
      "    val_loss       : -1793.4439392089844\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1793.4439493815105\n",
      "Train Epoch: 232 [0/54000 (0%)] Loss: -1807.679565\n",
      "Train Epoch: 232 [11264/54000 (21%)] Loss: -1812.610840\n",
      "Train Epoch: 232 [22528/54000 (42%)] Loss: -1791.540283\n",
      "Train Epoch: 232 [33792/54000 (63%)] Loss: -1816.903809\n",
      "Train Epoch: 232 [45056/54000 (83%)] Loss: -1788.451782\n",
      "    epoch          : 232\n",
      "    loss           : -1795.8944241505749\n",
      "    ess            : 8.001184121617731\n",
      "    log_marginal   : 1795.8944218473614\n",
      "    val_loss       : -1791.2480163574219\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1791.2480163574219\n",
      "Train Epoch: 233 [0/54000 (0%)] Loss: -1799.589111\n",
      "Train Epoch: 233 [11264/54000 (21%)] Loss: -1802.687744\n",
      "Train Epoch: 233 [22528/54000 (42%)] Loss: -1789.277588\n",
      "Train Epoch: 233 [33792/54000 (63%)] Loss: -1816.191650\n",
      "Train Epoch: 233 [45056/54000 (83%)] Loss: -1792.145996\n",
      "    epoch          : 233\n",
      "    loss           : -1794.573060233638\n",
      "    ess            : 8.001184355537847\n",
      "    log_marginal   : 1794.573060233638\n",
      "    val_loss       : -1798.3448079427083\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1798.3448079427083\n",
      "Train Epoch: 234 [0/54000 (0%)] Loss: -1808.730469\n",
      "Train Epoch: 234 [11264/54000 (21%)] Loss: -1810.647949\n",
      "Train Epoch: 234 [22528/54000 (42%)] Loss: -1788.272705\n",
      "Train Epoch: 234 [33792/54000 (63%)] Loss: -1815.177979\n",
      "Train Epoch: 234 [45056/54000 (83%)] Loss: -1783.388062\n",
      "    epoch          : 234\n",
      "    loss           : -1794.9401302697524\n",
      "    ess            : 8.001184355537847\n",
      "    log_marginal   : 1794.9401302697524\n",
      "    val_loss       : -1796.1830444335938\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1796.1830444335938\n",
      "Train Epoch: 235 [0/54000 (0%)] Loss: -1808.530273\n",
      "Train Epoch: 235 [11264/54000 (21%)] Loss: -1806.197266\n",
      "Train Epoch: 235 [22528/54000 (42%)] Loss: -1792.537354\n",
      "Train Epoch: 235 [33792/54000 (63%)] Loss: -1817.380615\n",
      "Train Epoch: 235 [45056/54000 (83%)] Loss: -1791.376953\n",
      "    epoch          : 235\n",
      "    loss           : -1797.2119774008697\n",
      "    ess            : 8.001183338885037\n",
      "    log_marginal   : 1797.2119774008697\n",
      "    val_loss       : -1802.9172973632812\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1802.9172973632812\n",
      "Train Epoch: 236 [0/54000 (0%)] Loss: -1815.934326\n",
      "Train Epoch: 236 [11264/54000 (21%)] Loss: -1812.328979\n",
      "Train Epoch: 236 [22528/54000 (42%)] Loss: -1795.355469\n",
      "Train Epoch: 236 [33792/54000 (63%)] Loss: -1818.015137\n",
      "Train Epoch: 236 [45056/54000 (83%)] Loss: -1790.491699\n",
      "    epoch          : 236\n",
      "    loss           : -1798.2361692032723\n",
      "    ess            : 8.001183995660746\n",
      "    log_marginal   : 1798.2361680516656\n",
      "    val_loss       : -1803.4471333821614\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1803.4471333821614\n",
      "Train Epoch: 237 [0/54000 (0%)] Loss: -1814.892700\n",
      "Train Epoch: 237 [11264/54000 (21%)] Loss: -1814.447632\n",
      "Train Epoch: 237 [22528/54000 (42%)] Loss: -1794.385498\n",
      "Train Epoch: 237 [33792/54000 (63%)] Loss: -1808.160278\n",
      "Train Epoch: 237 [45056/54000 (83%)] Loss: -1783.069092\n",
      "    epoch          : 237\n",
      "    loss           : -1794.9949801463001\n",
      "    ess            : 8.00118304198643\n",
      "    log_marginal   : 1794.9949778430866\n",
      "    val_loss       : -1794.427958170573\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1794.427978515625\n",
      "Train Epoch: 238 [0/54000 (0%)] Loss: -1807.438477\n",
      "Train Epoch: 238 [11264/54000 (21%)] Loss: -1800.625732\n",
      "Train Epoch: 238 [22528/54000 (42%)] Loss: -1780.983032\n",
      "Train Epoch: 238 [33792/54000 (63%)] Loss: -1812.190674\n",
      "Train Epoch: 238 [45056/54000 (83%)] Loss: -1792.217529\n",
      "    epoch          : 238\n",
      "    loss           : -1791.4650164910083\n",
      "    ess            : 8.001184445507121\n",
      "    log_marginal   : 1791.4650153394016\n",
      "    val_loss       : -1800.1145426432292\n",
      "    val_ess        : 8.001184860865274\n",
      "    val_log_marginal: 1800.1145528157551\n",
      "Train Epoch: 239 [0/54000 (0%)] Loss: -1812.672119\n",
      "Train Epoch: 239 [11264/54000 (21%)] Loss: -1808.282715\n",
      "Train Epoch: 239 [22528/54000 (42%)] Loss: -1794.930786\n",
      "Train Epoch: 239 [33792/54000 (63%)] Loss: -1774.634888\n",
      "Train Epoch: 239 [45056/54000 (83%)] Loss: -1764.477173\n",
      "    epoch          : 239\n",
      "    loss           : -1780.6011479215802\n",
      "    ess            : 8.001184400522485\n",
      "    log_marginal   : 1780.6011467699734\n",
      "    val_loss       : -1761.4323018391926\n",
      "    val_ess        : 8.00118374824524\n",
      "    val_log_marginal: 1761.4322814941406\n",
      "Train Epoch: 240 [0/54000 (0%)] Loss: -1775.464966\n",
      "Train Epoch: 240 [11264/54000 (21%)] Loss: -1781.468994\n",
      "Train Epoch: 240 [22528/54000 (42%)] Loss: -1752.382324\n",
      "Train Epoch: 240 [33792/54000 (63%)] Loss: -1795.100342\n",
      "Train Epoch: 240 [45056/54000 (83%)] Loss: -1784.587158\n",
      "    epoch          : 240\n",
      "    loss           : -1772.092599544885\n",
      "    ess            : 8.001185003316627\n",
      "    log_marginal   : 1772.092599544885\n",
      "    val_loss       : -1793.6922912597656\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1793.6922912597656\n",
      "Train Epoch: 241 [0/54000 (0%)] Loss: -1802.121704\n",
      "Train Epoch: 241 [11264/54000 (21%)] Loss: -1804.925293\n",
      "Train Epoch: 241 [22528/54000 (42%)] Loss: -1780.591064\n",
      "Train Epoch: 241 [33792/54000 (63%)] Loss: -1798.801514\n",
      "Train Epoch: 241 [45056/54000 (83%)] Loss: -1788.400391\n",
      "    epoch          : 241\n",
      "    loss           : -1789.0704391767395\n",
      "    ess            : 8.00118440951941\n",
      "    log_marginal   : 1789.0704391767395\n",
      "    val_loss       : -1796.5563659667969\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1796.5563456217449\n",
      "Train Epoch: 242 [0/54000 (0%)] Loss: -1806.876221\n",
      "Train Epoch: 242 [11264/54000 (21%)] Loss: -1806.809692\n",
      "Train Epoch: 242 [22528/54000 (42%)] Loss: -1786.841309\n",
      "Train Epoch: 242 [33792/54000 (63%)] Loss: -1812.913574\n",
      "Train Epoch: 242 [45056/54000 (83%)] Loss: -1778.555420\n",
      "    epoch          : 242\n",
      "    loss           : -1792.7318207362912\n",
      "    ess            : 8.001184067636165\n",
      "    log_marginal   : 1792.7318207362912\n",
      "    val_loss       : -1792.0291035970051\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1792.0291035970051\n",
      "Train Epoch: 243 [0/54000 (0%)] Loss: -1800.295166\n",
      "Train Epoch: 243 [11264/54000 (21%)] Loss: -1809.452393\n",
      "Train Epoch: 243 [22528/54000 (42%)] Loss: -1792.154785\n",
      "Train Epoch: 243 [33792/54000 (63%)] Loss: -1818.850708\n",
      "Train Epoch: 243 [45056/54000 (83%)] Loss: -1779.752441\n",
      "    epoch          : 243\n",
      "    loss           : -1794.4919790591834\n",
      "    ess            : 8.001184544473324\n",
      "    log_marginal   : 1794.4919790591834\n",
      "    val_loss       : -1792.9033711751301\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1792.9033508300781\n",
      "Train Epoch: 244 [0/54000 (0%)] Loss: -1802.442505\n",
      "Train Epoch: 244 [11264/54000 (21%)] Loss: -1811.002319\n",
      "Train Epoch: 244 [22528/54000 (42%)] Loss: -1789.350342\n",
      "Train Epoch: 244 [33792/54000 (63%)] Loss: -1816.181274\n",
      "Train Epoch: 244 [45056/54000 (83%)] Loss: -1789.266479\n",
      "    epoch          : 244\n",
      "    loss           : -1795.9139346716538\n",
      "    ess            : 8.001184823378077\n",
      "    log_marginal   : 1795.9139346716538\n",
      "    val_loss       : -1797.6180928548176\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1797.6180928548176\n",
      "Train Epoch: 245 [0/54000 (0%)] Loss: -1809.123047\n",
      "Train Epoch: 245 [11264/54000 (21%)] Loss: -1808.110840\n",
      "Train Epoch: 245 [22528/54000 (42%)] Loss: -1789.856689\n",
      "Train Epoch: 245 [33792/54000 (63%)] Loss: -1808.676147\n",
      "Train Epoch: 245 [45056/54000 (83%)] Loss: -1783.279297\n",
      "    epoch          : 245\n",
      "    loss           : -1791.9402281563237\n",
      "    ess            : 8.00118404964231\n",
      "    log_marginal   : 1791.9402281563237\n",
      "    val_loss       : -1791.678446451823\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1791.678446451823\n",
      "Train Epoch: 246 [0/54000 (0%)] Loss: -1801.991333\n",
      "Train Epoch: 246 [11264/54000 (21%)] Loss: -1805.233765\n",
      "Train Epoch: 246 [22528/54000 (42%)] Loss: -1786.444824\n",
      "Train Epoch: 246 [33792/54000 (63%)] Loss: -1809.505859\n",
      "Train Epoch: 246 [45056/54000 (83%)] Loss: -1777.223877\n",
      "    epoch          : 246\n",
      "    loss           : -1787.897899699661\n",
      "    ess            : 8.001184463500977\n",
      "    log_marginal   : 1787.897899699661\n",
      "    val_loss       : -1782.6390787760417\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1782.6390787760417\n",
      "Train Epoch: 247 [0/54000 (0%)] Loss: -1794.106567\n",
      "Train Epoch: 247 [11264/54000 (21%)] Loss: -1804.951904\n",
      "Train Epoch: 247 [22528/54000 (42%)] Loss: -1788.462402\n",
      "Train Epoch: 247 [33792/54000 (63%)] Loss: -1814.079590\n",
      "Train Epoch: 247 [45056/54000 (83%)] Loss: -1792.436279\n",
      "    epoch          : 247\n",
      "    loss           : -1794.0969779536408\n",
      "    ess            : 8.00118408563002\n",
      "    log_marginal   : 1794.0969768020343\n",
      "    val_loss       : -1801.580586751302\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1801.580586751302\n",
      "Train Epoch: 248 [0/54000 (0%)] Loss: -1812.318970\n",
      "Train Epoch: 248 [11264/54000 (21%)] Loss: -1810.066406\n",
      "Train Epoch: 248 [22528/54000 (42%)] Loss: -1783.427490\n",
      "Train Epoch: 248 [33792/54000 (63%)] Loss: -1804.221436\n",
      "Train Epoch: 248 [45056/54000 (83%)] Loss: -1762.494873\n",
      "    epoch          : 248\n",
      "    loss           : -1786.558718123526\n",
      "    ess            : 8.001184661433381\n",
      "    log_marginal   : 1786.558718123526\n",
      "    val_loss       : -1762.1427205403645\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1762.1427307128906\n",
      "Train Epoch: 249 [0/54000 (0%)] Loss: -1771.875122\n",
      "Train Epoch: 249 [11264/54000 (21%)] Loss: -1779.883301\n",
      "Train Epoch: 249 [22528/54000 (42%)] Loss: -1784.881226\n",
      "Train Epoch: 249 [33792/54000 (63%)] Loss: -1795.212402\n",
      "Train Epoch: 249 [45056/54000 (83%)] Loss: -1768.665039\n",
      "    epoch          : 249\n",
      "    loss           : -1776.1491157963592\n",
      "    ess            : 8.001185201249033\n",
      "    log_marginal   : 1776.1491157963592\n",
      "    val_loss       : -1771.9646809895833\n",
      "    val_ess        : 8.001185019810995\n",
      "    val_log_marginal: 1771.9646809895833\n",
      "Train Epoch: 250 [0/54000 (0%)] Loss: -1786.080811\n",
      "Train Epoch: 250 [11264/54000 (21%)] Loss: -1793.828857\n",
      "Train Epoch: 250 [22528/54000 (42%)] Loss: -1790.151489\n",
      "Train Epoch: 250 [33792/54000 (63%)] Loss: -1806.416260\n",
      "Train Epoch: 250 [45056/54000 (83%)] Loss: -1775.448730\n",
      "    epoch          : 250\n",
      "    loss           : -1784.0509252008403\n",
      "    ess            : 8.001184148608514\n",
      "    log_marginal   : 1784.0509252008403\n",
      "    val_loss       : -1777.1900227864583\n",
      "    val_ess        : 8.00118605295817\n",
      "    val_log_marginal: 1777.1900227864583\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch250.pth ...\n",
      "Train Epoch: 251 [0/54000 (0%)] Loss: -1790.828857\n",
      "Train Epoch: 251 [11264/54000 (21%)] Loss: -1803.890381\n",
      "Train Epoch: 251 [22528/54000 (42%)] Loss: -1793.758789\n",
      "Train Epoch: 251 [33792/54000 (63%)] Loss: -1815.304199\n",
      "Train Epoch: 251 [45056/54000 (83%)] Loss: -1785.209961\n",
      "    epoch          : 251\n",
      "    loss           : -1792.2301013874558\n",
      "    ess            : 8.001184670430309\n",
      "    log_marginal   : 1792.2301013874558\n",
      "    val_loss       : -1794.3666381835938\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1794.3666381835938\n",
      "Train Epoch: 252 [0/54000 (0%)] Loss: -1805.842529\n",
      "Train Epoch: 252 [11264/54000 (21%)] Loss: -1803.044678\n",
      "Train Epoch: 252 [22528/54000 (42%)] Loss: -1788.656738\n",
      "Train Epoch: 252 [33792/54000 (63%)] Loss: -1809.039429\n",
      "Train Epoch: 252 [45056/54000 (83%)] Loss: -1781.482666\n",
      "    epoch          : 252\n",
      "    loss           : -1791.3658159363945\n",
      "    ess            : 8.001184553470251\n",
      "    log_marginal   : 1791.3658159363945\n",
      "    val_loss       : -1788.6206156412761\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1788.6206156412761\n",
      "Train Epoch: 253 [0/54000 (0%)] Loss: -1800.565186\n",
      "Train Epoch: 253 [11264/54000 (21%)] Loss: -1806.458618\n",
      "Train Epoch: 253 [22528/54000 (42%)] Loss: -1790.764160\n",
      "Train Epoch: 253 [33792/54000 (63%)] Loss: -1810.998291\n",
      "Train Epoch: 253 [45056/54000 (83%)] Loss: -1783.106689\n",
      "    epoch          : 253\n",
      "    loss           : -1791.8319920953716\n",
      "    ess            : 8.001185219242888\n",
      "    log_marginal   : 1791.8319920953716\n",
      "    val_loss       : -1790.1999816894531\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1790.1999816894531\n",
      "Train Epoch: 254 [0/54000 (0%)] Loss: -1802.681885\n",
      "Train Epoch: 254 [11264/54000 (21%)] Loss: -1803.699951\n",
      "Train Epoch: 254 [22528/54000 (42%)] Loss: -1795.497559\n",
      "Train Epoch: 254 [33792/54000 (63%)] Loss: -1815.298340\n",
      "Train Epoch: 254 [45056/54000 (83%)] Loss: -1786.684570\n",
      "    epoch          : 254\n",
      "    loss           : -1794.6728285303657\n",
      "    ess            : 8.001184400522485\n",
      "    log_marginal   : 1794.672827378759\n",
      "    val_loss       : -1795.4011535644531\n",
      "    val_ess        : 8.001184622446695\n",
      "    val_log_marginal: 1795.4011535644531\n",
      "Train Epoch: 255 [0/54000 (0%)] Loss: -1808.228516\n",
      "Train Epoch: 255 [11264/54000 (21%)] Loss: -1805.452881\n",
      "Train Epoch: 255 [22528/54000 (42%)] Loss: -1787.786743\n",
      "Train Epoch: 255 [33792/54000 (63%)] Loss: -1813.442261\n",
      "Train Epoch: 255 [45056/54000 (83%)] Loss: -1787.156738\n",
      "    epoch          : 255\n",
      "    loss           : -1793.0758425154777\n",
      "    ess            : 8.001184625445672\n",
      "    log_marginal   : 1793.075841363871\n",
      "    val_loss       : -1795.7128194173176\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1795.7128092447917\n",
      "Train Epoch: 256 [0/54000 (0%)] Loss: -1808.667480\n",
      "Train Epoch: 256 [11264/54000 (21%)] Loss: -1803.839600\n",
      "Train Epoch: 256 [22528/54000 (42%)] Loss: -1786.701904\n",
      "Train Epoch: 256 [33792/54000 (63%)] Loss: -1812.427246\n",
      "Train Epoch: 256 [45056/54000 (83%)] Loss: -1791.431396\n",
      "    epoch          : 256\n",
      "    loss           : -1794.072551223467\n",
      "    ess            : 8.001184571464107\n",
      "    log_marginal   : 1794.072551223467\n",
      "    val_loss       : -1800.9676208496094\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1800.9676208496094\n",
      "Train Epoch: 257 [0/54000 (0%)] Loss: -1812.639893\n",
      "Train Epoch: 257 [11264/54000 (21%)] Loss: -1812.091064\n",
      "Train Epoch: 257 [22528/54000 (42%)] Loss: -1791.264160\n",
      "Train Epoch: 257 [33792/54000 (63%)] Loss: -1813.537354\n",
      "Train Epoch: 257 [45056/54000 (83%)] Loss: -1781.358765\n",
      "    epoch          : 257\n",
      "    loss           : -1795.324818737102\n",
      "    ess            : 8.001184562467179\n",
      "    log_marginal   : 1795.324818737102\n",
      "    val_loss       : -1798.6409708658855\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1798.6409708658855\n",
      "Train Epoch: 258 [0/54000 (0%)] Loss: -1809.934082\n",
      "Train Epoch: 258 [11264/54000 (21%)] Loss: -1807.543335\n",
      "Train Epoch: 258 [22528/54000 (42%)] Loss: -1776.118164\n",
      "Train Epoch: 258 [33792/54000 (63%)] Loss: -1785.345459\n",
      "Train Epoch: 258 [45056/54000 (83%)] Loss: -1757.223389\n",
      "    epoch          : 258\n",
      "    loss           : -1778.6411144328567\n",
      "    ess            : 8.001185237236744\n",
      "    log_marginal   : 1778.6411144328567\n",
      "    val_loss       : -1772.7603658040364\n",
      "    val_ess        : 8.001185258229574\n",
      "    val_log_marginal: 1772.7603658040364\n",
      "Train Epoch: 259 [0/54000 (0%)] Loss: -1786.180420\n",
      "Train Epoch: 259 [11264/54000 (21%)] Loss: -1776.591797\n",
      "Train Epoch: 259 [22528/54000 (42%)] Loss: -1782.139038\n",
      "Train Epoch: 259 [33792/54000 (63%)] Loss: -1787.465210\n",
      "Train Epoch: 259 [45056/54000 (83%)] Loss: -1778.317871\n",
      "    epoch          : 259\n",
      "    loss           : -1777.70549615824\n",
      "    ess            : 8.001184841371932\n",
      "    log_marginal   : 1777.70549615824\n",
      "    val_loss       : -1793.2252400716145\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1793.2252400716145\n",
      "Train Epoch: 260 [0/54000 (0%)] Loss: -1805.756714\n",
      "Train Epoch: 260 [11264/54000 (21%)] Loss: -1790.457031\n",
      "Train Epoch: 260 [22528/54000 (42%)] Loss: -1789.068359\n",
      "Train Epoch: 260 [33792/54000 (63%)] Loss: -1805.538696\n",
      "Train Epoch: 260 [45056/54000 (83%)] Loss: -1781.353638\n",
      "    epoch          : 260\n",
      "    loss           : -1788.8614179503243\n",
      "    ess            : 8.001184607451817\n",
      "    log_marginal   : 1788.861419101931\n",
      "    val_loss       : -1794.4973958333333\n",
      "    val_ess        : 8.001185337702433\n",
      "    val_log_marginal: 1794.4974161783855\n",
      "Train Epoch: 261 [0/54000 (0%)] Loss: -1808.615967\n",
      "Train Epoch: 261 [11264/54000 (21%)] Loss: -1805.346558\n",
      "Train Epoch: 261 [22528/54000 (42%)] Loss: -1792.554688\n",
      "Train Epoch: 261 [33792/54000 (63%)] Loss: -1810.091553\n",
      "Train Epoch: 261 [45056/54000 (83%)] Loss: -1784.727173\n",
      "    epoch          : 261\n",
      "    loss           : -1794.3609285174675\n",
      "    ess            : 8.001184319550136\n",
      "    log_marginal   : 1794.3609285174675\n",
      "    val_loss       : -1788.5179545084636\n",
      "    val_ess        : 8.001184622446695\n",
      "    val_log_marginal: 1788.5179545084636\n",
      "Train Epoch: 262 [0/54000 (0%)] Loss: -1801.415527\n",
      "Train Epoch: 262 [11264/54000 (21%)] Loss: -1806.313843\n",
      "Train Epoch: 262 [22528/54000 (42%)] Loss: -1781.518555\n",
      "Train Epoch: 262 [33792/54000 (63%)] Loss: -1811.949219\n",
      "Train Epoch: 262 [45056/54000 (83%)] Loss: -1790.960938\n",
      "    epoch          : 262\n",
      "    loss           : -1793.107393084832\n",
      "    ess            : 8.001184337543991\n",
      "    log_marginal   : 1793.1073942364387\n",
      "    val_loss       : -1793.9219563802083\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1793.9219665527344\n",
      "Train Epoch: 263 [0/54000 (0%)] Loss: -1806.894897\n",
      "Train Epoch: 263 [11264/54000 (21%)] Loss: -1805.331299\n",
      "Train Epoch: 263 [22528/54000 (42%)] Loss: -1785.663086\n",
      "Train Epoch: 263 [33792/54000 (63%)] Loss: -1813.619263\n",
      "Train Epoch: 263 [45056/54000 (83%)] Loss: -1787.025879\n",
      "    epoch          : 263\n",
      "    loss           : -1794.3558142320164\n",
      "    ess            : 8.001184823378077\n",
      "    log_marginal   : 1794.3558142320164\n",
      "    val_loss       : -1797.686279296875\n",
      "    val_ess        : 8.001185973485311\n",
      "    val_log_marginal: 1797.686258951823\n",
      "Train Epoch: 264 [0/54000 (0%)] Loss: -1809.900757\n",
      "Train Epoch: 264 [11264/54000 (21%)] Loss: -1805.014526\n",
      "Train Epoch: 264 [22528/54000 (42%)] Loss: -1785.975342\n",
      "Train Epoch: 264 [33792/54000 (63%)] Loss: -1795.434326\n",
      "Train Epoch: 264 [45056/54000 (83%)] Loss: -1779.338867\n",
      "    epoch          : 264\n",
      "    loss           : -1789.4894915886646\n",
      "    ess            : 8.001184607451817\n",
      "    log_marginal   : 1789.4894915886646\n",
      "    val_loss       : -1793.1372782389324\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1793.1372884114583\n",
      "Train Epoch: 265 [0/54000 (0%)] Loss: -1806.714355\n",
      "Train Epoch: 265 [11264/54000 (21%)] Loss: -1805.748901\n",
      "Train Epoch: 265 [22528/54000 (42%)] Loss: -1788.367676\n",
      "Train Epoch: 265 [33792/54000 (63%)] Loss: -1808.671875\n",
      "Train Epoch: 265 [45056/54000 (83%)] Loss: -1790.261841\n",
      "    epoch          : 265\n",
      "    loss           : -1793.1527226286114\n",
      "    ess            : 8.001185111279758\n",
      "    log_marginal   : 1793.1527226286114\n",
      "    val_loss       : -1791.2476908365886\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1791.2476908365886\n",
      "Train Epoch: 266 [0/54000 (0%)] Loss: -1799.046387\n",
      "Train Epoch: 266 [11264/54000 (21%)] Loss: -1805.517822\n",
      "Train Epoch: 266 [22528/54000 (42%)] Loss: -1790.195679\n",
      "Train Epoch: 266 [33792/54000 (63%)] Loss: -1816.884521\n",
      "Train Epoch: 266 [45056/54000 (83%)] Loss: -1791.126953\n",
      "    epoch          : 266\n",
      "    loss           : -1795.346895037957\n",
      "    ess            : 8.001184220583934\n",
      "    log_marginal   : 1795.346895037957\n",
      "    val_loss       : -1802.4407450358074\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1802.4407348632812\n",
      "Train Epoch: 267 [0/54000 (0%)] Loss: -1811.365479\n",
      "Train Epoch: 267 [11264/54000 (21%)] Loss: -1816.161865\n",
      "Train Epoch: 267 [22528/54000 (42%)] Loss: -1794.612305\n",
      "Train Epoch: 267 [33792/54000 (63%)] Loss: -1813.707764\n",
      "Train Epoch: 267 [45056/54000 (83%)] Loss: -1785.211060\n",
      "    epoch          : 267\n",
      "    loss           : -1796.5090873286408\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1796.5090873286408\n",
      "    val_loss       : -1781.2945251464844\n",
      "    val_ess        : 8.001184225082397\n",
      "    val_log_marginal: 1781.2945251464844\n",
      "Train Epoch: 268 [0/54000 (0%)] Loss: -1789.788696\n",
      "Train Epoch: 268 [11264/54000 (21%)] Loss: -1804.537354\n",
      "Train Epoch: 268 [22528/54000 (42%)] Loss: -1796.794678\n",
      "Train Epoch: 268 [33792/54000 (63%)] Loss: -1815.193237\n",
      "Train Epoch: 268 [45056/54000 (83%)] Loss: -1789.094360\n",
      "    epoch          : 268\n",
      "    loss           : -1794.6415485885907\n",
      "    ess            : 8.001184607451817\n",
      "    log_marginal   : 1794.6415485885907\n",
      "    val_loss       : -1791.7451171875\n",
      "    val_ess        : 8.001184542973837\n",
      "    val_log_marginal: 1791.7451171875\n",
      "Train Epoch: 269 [0/54000 (0%)] Loss: -1800.773315\n",
      "Train Epoch: 269 [11264/54000 (21%)] Loss: -1796.357422\n",
      "Train Epoch: 269 [22528/54000 (42%)] Loss: -1742.572388\n",
      "Train Epoch: 269 [33792/54000 (63%)] Loss: -1749.270508\n",
      "Train Epoch: 269 [45056/54000 (83%)] Loss: -1761.643677\n",
      "    epoch          : 269\n",
      "    loss           : -1760.7062896152713\n",
      "    ess            : 8.001184625445672\n",
      "    log_marginal   : 1760.7062896152713\n",
      "    val_loss       : -1779.5694274902344\n",
      "    val_ess        : 8.00118613243103\n",
      "    val_log_marginal: 1779.5694478352864\n",
      "Train Epoch: 270 [0/54000 (0%)] Loss: -1791.756836\n",
      "Train Epoch: 270 [11264/54000 (21%)] Loss: -1801.921265\n",
      "Train Epoch: 270 [22528/54000 (42%)] Loss: -1784.031006\n",
      "Train Epoch: 270 [33792/54000 (63%)] Loss: -1787.333008\n",
      "Train Epoch: 270 [45056/54000 (83%)] Loss: -1771.004150\n",
      "    epoch          : 270\n",
      "    loss           : -1782.947323205336\n",
      "    ess            : 8.00118459845489\n",
      "    log_marginal   : 1782.947323205336\n",
      "    val_loss       : -1793.0226440429688\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1793.0226440429688\n",
      "Train Epoch: 271 [0/54000 (0%)] Loss: -1805.401245\n",
      "Train Epoch: 271 [11264/54000 (21%)] Loss: -1807.531494\n",
      "Train Epoch: 271 [22528/54000 (42%)] Loss: -1786.345215\n",
      "Train Epoch: 271 [33792/54000 (63%)] Loss: -1795.713135\n",
      "Train Epoch: 271 [45056/54000 (83%)] Loss: -1783.885010\n",
      "    epoch          : 271\n",
      "    loss           : -1789.1878293595223\n",
      "    ess            : 8.00118408563002\n",
      "    log_marginal   : 1789.1878282079156\n",
      "    val_loss       : -1792.7107442220051\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1792.7107442220051\n",
      "Train Epoch: 272 [0/54000 (0%)] Loss: -1805.569336\n",
      "Train Epoch: 272 [11264/54000 (21%)] Loss: -1808.232422\n",
      "Train Epoch: 272 [22528/54000 (42%)] Loss: -1785.686035\n",
      "Train Epoch: 272 [33792/54000 (63%)] Loss: -1806.616943\n",
      "Train Epoch: 272 [45056/54000 (83%)] Loss: -1787.079346\n",
      "    epoch          : 272\n",
      "    loss           : -1792.648197965802\n",
      "    ess            : 8.001184535476396\n",
      "    log_marginal   : 1792.648197965802\n",
      "    val_loss       : -1782.336690266927\n",
      "    val_ess        : 8.001185894012451\n",
      "    val_log_marginal: 1782.336690266927\n",
      "Train Epoch: 273 [0/54000 (0%)] Loss: -1797.422852\n",
      "Train Epoch: 273 [11264/54000 (21%)] Loss: -1807.391357\n",
      "Train Epoch: 273 [22528/54000 (42%)] Loss: -1785.298828\n",
      "Train Epoch: 273 [33792/54000 (63%)] Loss: -1811.725342\n",
      "Train Epoch: 273 [45056/54000 (83%)] Loss: -1786.528076\n",
      "    epoch          : 273\n",
      "    loss           : -1792.378223347214\n",
      "    ess            : 8.0011846344426\n",
      "    log_marginal   : 1792.378223347214\n",
      "    val_loss       : -1791.5680745442708\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1791.5680541992188\n",
      "Train Epoch: 274 [0/54000 (0%)] Loss: -1805.398682\n",
      "Train Epoch: 274 [11264/54000 (21%)] Loss: -1810.602539\n",
      "Train Epoch: 274 [22528/54000 (42%)] Loss: -1796.610107\n",
      "Train Epoch: 274 [33792/54000 (63%)] Loss: -1802.072266\n",
      "Train Epoch: 274 [45056/54000 (83%)] Loss: -1778.036499\n",
      "    epoch          : 274\n",
      "    loss           : -1792.2272269770783\n",
      "    ess            : 8.001184229580861\n",
      "    log_marginal   : 1792.2272258254718\n",
      "    val_loss       : -1794.6952718098958\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1794.6952718098958\n",
      "Train Epoch: 275 [0/54000 (0%)] Loss: -1808.300781\n",
      "Train Epoch: 275 [11264/54000 (21%)] Loss: -1814.653320\n",
      "Train Epoch: 275 [22528/54000 (42%)] Loss: -1786.712646\n",
      "Train Epoch: 275 [33792/54000 (63%)] Loss: -1797.796143\n",
      "Train Epoch: 275 [45056/54000 (83%)] Loss: -1787.645264\n",
      "    epoch          : 275\n",
      "    loss           : -1792.5211884120724\n",
      "    ess            : 8.001185372190655\n",
      "    log_marginal   : 1792.5211884120724\n",
      "    val_loss       : -1796.2207539876301\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1796.2207539876301\n",
      "Train Epoch: 276 [0/54000 (0%)] Loss: -1809.215332\n",
      "Train Epoch: 276 [11264/54000 (21%)] Loss: -1811.395020\n",
      "Train Epoch: 276 [22528/54000 (42%)] Loss: -1790.316284\n",
      "Train Epoch: 276 [33792/54000 (63%)] Loss: -1803.039673\n",
      "Train Epoch: 276 [45056/54000 (83%)] Loss: -1783.445190\n",
      "    epoch          : 276\n",
      "    loss           : -1793.6940756743809\n",
      "    ess            : 8.001185273224452\n",
      "    log_marginal   : 1793.6940756743809\n",
      "    val_loss       : -1794.1300659179688\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1794.1300659179688\n",
      "Train Epoch: 277 [0/54000 (0%)] Loss: -1805.488770\n",
      "Train Epoch: 277 [11264/54000 (21%)] Loss: -1812.211426\n",
      "Train Epoch: 277 [22528/54000 (42%)] Loss: -1788.815430\n",
      "Train Epoch: 277 [33792/54000 (63%)] Loss: -1794.369141\n",
      "Train Epoch: 277 [45056/54000 (83%)] Loss: -1760.057861\n",
      "    epoch          : 277\n",
      "    loss           : -1784.7750152012088\n",
      "    ess            : 8.001185003316627\n",
      "    log_marginal   : 1784.775014049602\n",
      "    val_loss       : -1775.3709615071614\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1775.3709615071614\n",
      "Train Epoch: 278 [0/54000 (0%)] Loss: -1792.233643\n",
      "Train Epoch: 278 [11264/54000 (21%)] Loss: -1777.671387\n",
      "Train Epoch: 278 [22528/54000 (42%)] Loss: -1788.106079\n",
      "Train Epoch: 278 [33792/54000 (63%)] Loss: -1807.010742\n",
      "Train Epoch: 278 [45056/54000 (83%)] Loss: -1769.799561\n",
      "    epoch          : 278\n",
      "    loss           : -1780.2222267006928\n",
      "    ess            : 8.001185219242888\n",
      "    log_marginal   : 1780.2222267006928\n",
      "    val_loss       : -1788.2358805338542\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1788.2358805338542\n",
      "Train Epoch: 279 [0/54000 (0%)] Loss: -1801.181885\n",
      "Train Epoch: 279 [11264/54000 (21%)] Loss: -1783.934570\n",
      "Train Epoch: 279 [22528/54000 (42%)] Loss: -1789.740479\n",
      "Train Epoch: 279 [33792/54000 (63%)] Loss: -1817.691528\n",
      "Train Epoch: 279 [45056/54000 (83%)] Loss: -1787.628906\n",
      "    epoch          : 279\n",
      "    loss           : -1790.211243827388\n",
      "    ess            : 8.001184868362715\n",
      "    log_marginal   : 1790.2112426757812\n",
      "    val_loss       : -1799.6216634114583\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1799.6216634114583\n",
      "Train Epoch: 280 [0/54000 (0%)] Loss: -1811.111450\n",
      "Train Epoch: 280 [11264/54000 (21%)] Loss: -1791.008545\n",
      "Train Epoch: 280 [22528/54000 (42%)] Loss: -1792.391846\n",
      "Train Epoch: 280 [33792/54000 (63%)] Loss: -1814.770142\n",
      "Train Epoch: 280 [45056/54000 (83%)] Loss: -1784.339844\n",
      "    epoch          : 280\n",
      "    loss           : -1792.631343049823\n",
      "    ess            : 8.001184319550136\n",
      "    log_marginal   : 1792.631343049823\n",
      "    val_loss       : -1799.0845133463542\n",
      "    val_ess        : 8.00118613243103\n",
      "    val_log_marginal: 1799.0845133463542\n",
      "Train Epoch: 281 [0/54000 (0%)] Loss: -1810.300049\n",
      "Train Epoch: 281 [11264/54000 (21%)] Loss: -1801.366089\n",
      "Train Epoch: 281 [22528/54000 (42%)] Loss: -1802.379150\n",
      "Train Epoch: 281 [33792/54000 (63%)] Loss: -1812.058960\n",
      "Train Epoch: 281 [45056/54000 (83%)] Loss: -1786.339111\n",
      "    epoch          : 281\n",
      "    loss           : -1795.9185779499558\n",
      "    ess            : 8.00118440951941\n",
      "    log_marginal   : 1795.9185779499558\n",
      "    val_loss       : -1788.7569580078125\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1788.7569580078125\n",
      "Train Epoch: 282 [0/54000 (0%)] Loss: -1801.330078\n",
      "Train Epoch: 282 [11264/54000 (21%)] Loss: -1800.632568\n",
      "Train Epoch: 282 [22528/54000 (42%)] Loss: -1794.990234\n",
      "Train Epoch: 282 [33792/54000 (63%)] Loss: -1795.331787\n",
      "Train Epoch: 282 [45056/54000 (83%)] Loss: -1785.184814\n",
      "    epoch          : 282\n",
      "    loss           : -1790.5587492169075\n",
      "    ess            : 8.001184769396511\n",
      "    log_marginal   : 1790.5587503685142\n",
      "    val_loss       : -1797.6615397135417\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1797.6615498860676\n",
      "Train Epoch: 283 [0/54000 (0%)] Loss: -1807.092163\n",
      "Train Epoch: 283 [11264/54000 (21%)] Loss: -1807.940063\n",
      "Train Epoch: 283 [22528/54000 (42%)] Loss: -1784.253540\n",
      "Train Epoch: 283 [33792/54000 (63%)] Loss: -1801.070557\n",
      "Train Epoch: 283 [45056/54000 (83%)] Loss: -1784.507324\n",
      "    epoch          : 283\n",
      "    loss           : -1791.3942341354657\n",
      "    ess            : 8.001184175599295\n",
      "    log_marginal   : 1791.3942364386792\n",
      "    val_loss       : -1798.7602844238281\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1798.7603047688801\n",
      "Train Epoch: 284 [0/54000 (0%)] Loss: -1808.198730\n",
      "Train Epoch: 284 [11264/54000 (21%)] Loss: -1811.853271\n",
      "Train Epoch: 284 [22528/54000 (42%)] Loss: -1801.491455\n",
      "Train Epoch: 284 [33792/54000 (63%)] Loss: -1810.189331\n",
      "Train Epoch: 284 [45056/54000 (83%)] Loss: -1787.192505\n",
      "    epoch          : 284\n",
      "    loss           : -1796.0955856611145\n",
      "    ess            : 8.001184265568572\n",
      "    log_marginal   : 1796.0955856611145\n",
      "    val_loss       : -1794.9138081868489\n",
      "    val_ess        : 8.001185337702433\n",
      "    val_log_marginal: 1794.9138081868489\n",
      "Train Epoch: 285 [0/54000 (0%)] Loss: -1806.231201\n",
      "Train Epoch: 285 [11264/54000 (21%)] Loss: -1802.864014\n",
      "Train Epoch: 285 [22528/54000 (42%)] Loss: -1791.655273\n",
      "Train Epoch: 285 [33792/54000 (63%)] Loss: -1814.250610\n",
      "Train Epoch: 285 [45056/54000 (83%)] Loss: -1796.861084\n",
      "    epoch          : 285\n",
      "    loss           : -1796.295256992556\n",
      "    ess            : 8.00118372575292\n",
      "    log_marginal   : 1796.2952558409493\n",
      "    val_loss       : -1799.4655354817708\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1799.4655354817708\n",
      "Train Epoch: 286 [0/54000 (0%)] Loss: -1811.020386\n",
      "Train Epoch: 286 [11264/54000 (21%)] Loss: -1808.547119\n",
      "Train Epoch: 286 [22528/54000 (42%)] Loss: -1785.431885\n",
      "Train Epoch: 286 [33792/54000 (63%)] Loss: -1807.043335\n",
      "Train Epoch: 286 [45056/54000 (83%)] Loss: -1782.003174\n",
      "    epoch          : 286\n",
      "    loss           : -1790.8267131301593\n",
      "    ess            : 8.00118397766689\n",
      "    log_marginal   : 1790.8267131301593\n",
      "    val_loss       : -1789.1208089192708\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1789.1207987467449\n",
      "Train Epoch: 287 [0/54000 (0%)] Loss: -1803.421631\n",
      "Train Epoch: 287 [11264/54000 (21%)] Loss: -1765.463379\n",
      "Train Epoch: 287 [22528/54000 (42%)] Loss: -1758.921021\n",
      "Train Epoch: 287 [33792/54000 (63%)] Loss: -1782.197266\n",
      "Train Epoch: 287 [45056/54000 (83%)] Loss: -1779.068848\n",
      "    epoch          : 287\n",
      "    loss           : -1771.473594809478\n",
      "    ess            : 8.00118470641802\n",
      "    log_marginal   : 1771.473594809478\n",
      "    val_loss       : -1771.0743916829426\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1771.0743916829426\n",
      "Train Epoch: 288 [0/54000 (0%)] Loss: -1786.412476\n",
      "Train Epoch: 288 [11264/54000 (21%)] Loss: -1773.634033\n",
      "Train Epoch: 288 [22528/54000 (42%)] Loss: -1784.837402\n",
      "Train Epoch: 288 [33792/54000 (63%)] Loss: -1791.448486\n",
      "Train Epoch: 288 [45056/54000 (83%)] Loss: -1788.302734\n",
      "    epoch          : 288\n",
      "    loss           : -1779.023777223983\n",
      "    ess            : 8.001184544473324\n",
      "    log_marginal   : 1779.023777223983\n",
      "    val_loss       : -1792.3278401692708\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1792.3278401692708\n",
      "Train Epoch: 289 [0/54000 (0%)] Loss: -1802.091309\n",
      "Train Epoch: 289 [11264/54000 (21%)] Loss: -1799.787842\n",
      "Train Epoch: 289 [22528/54000 (42%)] Loss: -1779.525269\n",
      "Train Epoch: 289 [33792/54000 (63%)] Loss: -1781.282715\n",
      "Train Epoch: 289 [45056/54000 (83%)] Loss: -1784.067139\n",
      "    epoch          : 289\n",
      "    loss           : -1784.9238315798202\n",
      "    ess            : 8.00118440951941\n",
      "    log_marginal   : 1784.9238315798202\n",
      "    val_loss       : -1788.5493876139324\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1788.5493876139324\n",
      "Train Epoch: 290 [0/54000 (0%)] Loss: -1798.916626\n",
      "Train Epoch: 290 [11264/54000 (21%)] Loss: -1807.472168\n",
      "Train Epoch: 290 [22528/54000 (42%)] Loss: -1794.678223\n",
      "Train Epoch: 290 [33792/54000 (63%)] Loss: -1790.297241\n",
      "Train Epoch: 290 [45056/54000 (83%)] Loss: -1788.471436\n",
      "    epoch          : 290\n",
      "    loss           : -1791.8927796561763\n",
      "    ess            : 8.001184346540919\n",
      "    log_marginal   : 1791.8927796561763\n",
      "    val_loss       : -1793.9810994466145\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1793.9810994466145\n",
      "Train Epoch: 291 [0/54000 (0%)] Loss: -1804.507324\n",
      "Train Epoch: 291 [11264/54000 (21%)] Loss: -1809.030273\n",
      "Train Epoch: 291 [22528/54000 (42%)] Loss: -1787.020142\n",
      "Train Epoch: 291 [33792/54000 (63%)] Loss: -1792.342773\n",
      "Train Epoch: 291 [45056/54000 (83%)] Loss: -1768.149902\n",
      "    epoch          : 291\n",
      "    loss           : -1785.91817949403\n",
      "    ess            : 8.001184751402658\n",
      "    log_marginal   : 1785.91817949403\n",
      "    val_loss       : -1774.6219787597656\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1774.6219787597656\n",
      "Train Epoch: 292 [0/54000 (0%)] Loss: -1786.521484\n",
      "Train Epoch: 292 [11264/54000 (21%)] Loss: -1761.942749\n",
      "Train Epoch: 292 [22528/54000 (42%)] Loss: -1766.627808\n",
      "Train Epoch: 292 [33792/54000 (63%)] Loss: -1777.797607\n",
      "Train Epoch: 292 [45056/54000 (83%)] Loss: -1775.726318\n",
      "    epoch          : 292\n",
      "    loss           : -1767.4503876308224\n",
      "    ess            : 8.001184940338135\n",
      "    log_marginal   : 1767.4503864792157\n",
      "    val_loss       : -1793.2588704427083\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1793.2588704427083\n",
      "Train Epoch: 293 [0/54000 (0%)] Loss: -1803.788330\n",
      "Train Epoch: 293 [11264/54000 (21%)] Loss: -1786.133423\n",
      "Train Epoch: 293 [22528/54000 (42%)] Loss: -1789.024658\n",
      "Train Epoch: 293 [33792/54000 (63%)] Loss: -1796.854248\n",
      "Train Epoch: 293 [45056/54000 (83%)] Loss: -1788.540283\n",
      "    epoch          : 293\n",
      "    loss           : -1785.613463203862\n",
      "    ess            : 8.001184040645384\n",
      "    log_marginal   : 1785.6134643554688\n",
      "    val_loss       : -1798.9951985677083\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1798.9951985677083\n",
      "Train Epoch: 294 [0/54000 (0%)] Loss: -1809.297119\n",
      "Train Epoch: 294 [11264/54000 (21%)] Loss: -1801.630371\n",
      "Train Epoch: 294 [22528/54000 (42%)] Loss: -1790.784424\n",
      "Train Epoch: 294 [33792/54000 (63%)] Loss: -1809.695312\n",
      "Train Epoch: 294 [45056/54000 (83%)] Loss: -1790.900757\n",
      "    epoch          : 294\n",
      "    loss           : -1793.4333691866893\n",
      "    ess            : 8.001184364534774\n",
      "    log_marginal   : 1793.4333691866893\n",
      "    val_loss       : -1795.3399353027344\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1795.3399353027344\n",
      "Train Epoch: 295 [0/54000 (0%)] Loss: -1805.785889\n",
      "Train Epoch: 295 [11264/54000 (21%)] Loss: -1808.148438\n",
      "Train Epoch: 295 [22528/54000 (42%)] Loss: -1788.110107\n",
      "Train Epoch: 295 [33792/54000 (63%)] Loss: -1810.437256\n",
      "Train Epoch: 295 [45056/54000 (83%)] Loss: -1790.901855\n",
      "    epoch          : 295\n",
      "    loss           : -1794.473012096477\n",
      "    ess            : 8.001184823378077\n",
      "    log_marginal   : 1794.473012096477\n",
      "    val_loss       : -1798.0415140787761\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1798.041524251302\n",
      "Train Epoch: 296 [0/54000 (0%)] Loss: -1809.216064\n",
      "Train Epoch: 296 [11264/54000 (21%)] Loss: -1811.903198\n",
      "Train Epoch: 296 [22528/54000 (42%)] Loss: -1787.307251\n",
      "Train Epoch: 296 [33792/54000 (63%)] Loss: -1812.601440\n",
      "Train Epoch: 296 [45056/54000 (83%)] Loss: -1790.057861\n",
      "    epoch          : 296\n",
      "    loss           : -1795.9962008494251\n",
      "    ess            : 8.001184661433381\n",
      "    log_marginal   : 1795.9962008494251\n",
      "    val_loss       : -1788.265869140625\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1788.265869140625\n",
      "Train Epoch: 297 [0/54000 (0%)] Loss: -1799.475586\n",
      "Train Epoch: 297 [11264/54000 (21%)] Loss: -1803.291382\n",
      "Train Epoch: 297 [22528/54000 (42%)] Loss: -1787.531372\n",
      "Train Epoch: 297 [33792/54000 (63%)] Loss: -1810.218018\n",
      "Train Epoch: 297 [45056/54000 (83%)] Loss: -1781.218750\n",
      "    epoch          : 297\n",
      "    loss           : -1789.4811332270783\n",
      "    ess            : 8.00118485036886\n",
      "    log_marginal   : 1789.4811332270783\n",
      "    val_loss       : -1792.4082336425781\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1792.4082336425781\n",
      "Train Epoch: 298 [0/54000 (0%)] Loss: -1804.731689\n",
      "Train Epoch: 298 [11264/54000 (21%)] Loss: -1807.956543\n",
      "Train Epoch: 298 [22528/54000 (42%)] Loss: -1790.249512\n",
      "Train Epoch: 298 [33792/54000 (63%)] Loss: -1809.540283\n",
      "Train Epoch: 298 [45056/54000 (83%)] Loss: -1789.461060\n",
      "    epoch          : 298\n",
      "    loss           : -1794.9797846956073\n",
      "    ess            : 8.001184121617731\n",
      "    log_marginal   : 1794.979785847214\n",
      "    val_loss       : -1801.0343526204426\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1801.0343627929688\n",
      "Train Epoch: 299 [0/54000 (0%)] Loss: -1810.528076\n",
      "Train Epoch: 299 [11264/54000 (21%)] Loss: -1818.474365\n",
      "Train Epoch: 299 [22528/54000 (42%)] Loss: -1793.840942\n",
      "Train Epoch: 299 [33792/54000 (63%)] Loss: -1803.898438\n",
      "Train Epoch: 299 [45056/54000 (83%)] Loss: -1790.257202\n",
      "    epoch          : 299\n",
      "    loss           : -1795.2039138506043\n",
      "    ess            : 8.00118372575292\n",
      "    log_marginal   : 1795.203915002211\n",
      "    val_loss       : -1794.0101013183594\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1794.0101013183594\n",
      "Train Epoch: 300 [0/54000 (0%)] Loss: -1803.408081\n",
      "Train Epoch: 300 [11264/54000 (21%)] Loss: -1808.916016\n",
      "Train Epoch: 300 [22528/54000 (42%)] Loss: -1795.515137\n",
      "Train Epoch: 300 [33792/54000 (63%)] Loss: -1807.647461\n",
      "Train Epoch: 300 [45056/54000 (83%)] Loss: -1788.214600\n",
      "    epoch          : 300\n",
      "    loss           : -1795.2392278707252\n",
      "    ess            : 8.001184211587006\n",
      "    log_marginal   : 1795.2392278707252\n",
      "    val_loss       : -1796.3823343912761\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1796.3823343912761\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch300.pth ...\n",
      "Train Epoch: 301 [0/54000 (0%)] Loss: -1806.537109\n",
      "Train Epoch: 301 [11264/54000 (21%)] Loss: -1812.757568\n",
      "Train Epoch: 301 [22528/54000 (42%)] Loss: -1781.346802\n",
      "Train Epoch: 301 [33792/54000 (63%)] Loss: -1792.592773\n",
      "Train Epoch: 301 [45056/54000 (83%)] Loss: -1777.564697\n",
      "    epoch          : 301\n",
      "    loss           : -1788.800773188753\n",
      "    ess            : 8.001184211587006\n",
      "    log_marginal   : 1788.8007743403596\n",
      "    val_loss       : -1791.2260437011719\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1791.2260437011719\n",
      "Train Epoch: 302 [0/54000 (0%)] Loss: -1803.129150\n",
      "Train Epoch: 302 [11264/54000 (21%)] Loss: -1807.005615\n",
      "Train Epoch: 302 [22528/54000 (42%)] Loss: -1793.386475\n",
      "Train Epoch: 302 [33792/54000 (63%)] Loss: -1794.681519\n",
      "Train Epoch: 302 [45056/54000 (83%)] Loss: -1785.309082\n",
      "    epoch          : 302\n",
      "    loss           : -1791.2503385723762\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1791.2503385723762\n",
      "    val_loss       : -1793.763448079427\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1793.763448079427\n",
      "Train Epoch: 303 [0/54000 (0%)] Loss: -1802.646729\n",
      "Train Epoch: 303 [11264/54000 (21%)] Loss: -1811.116211\n",
      "Train Epoch: 303 [22528/54000 (42%)] Loss: -1793.312744\n",
      "Train Epoch: 303 [33792/54000 (63%)] Loss: -1799.679199\n",
      "Train Epoch: 303 [45056/54000 (83%)] Loss: -1784.934204\n",
      "    epoch          : 303\n",
      "    loss           : -1794.4346705022847\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1794.4346705022847\n",
      "    val_loss       : -1793.0370178222656\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1793.0370178222656\n",
      "Train Epoch: 304 [0/54000 (0%)] Loss: -1801.677490\n",
      "Train Epoch: 304 [11264/54000 (21%)] Loss: -1806.583252\n",
      "Train Epoch: 304 [22528/54000 (42%)] Loss: -1788.066406\n",
      "Train Epoch: 304 [33792/54000 (63%)] Loss: -1803.511353\n",
      "Train Epoch: 304 [45056/54000 (83%)] Loss: -1775.899414\n",
      "    epoch          : 304\n",
      "    loss           : -1789.586645738134\n",
      "    ess            : 8.001184292559353\n",
      "    log_marginal   : 1789.5866468897407\n",
      "    val_loss       : -1783.6934814453125\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1783.6934814453125\n",
      "Train Epoch: 305 [0/54000 (0%)] Loss: -1790.953125\n",
      "Train Epoch: 305 [11264/54000 (21%)] Loss: -1801.180176\n",
      "Train Epoch: 305 [22528/54000 (42%)] Loss: -1782.815430\n",
      "Train Epoch: 305 [33792/54000 (63%)] Loss: -1807.623535\n",
      "Train Epoch: 305 [45056/54000 (83%)] Loss: -1779.101685\n",
      "    epoch          : 305\n",
      "    loss           : -1789.2341746204304\n",
      "    ess            : 8.001183518823588\n",
      "    log_marginal   : 1789.2341734688237\n",
      "    val_loss       : -1788.1693623860676\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1788.1693929036458\n",
      "Train Epoch: 306 [0/54000 (0%)] Loss: -1798.788818\n",
      "Train Epoch: 306 [11264/54000 (21%)] Loss: -1805.270630\n",
      "Train Epoch: 306 [22528/54000 (42%)] Loss: -1786.757812\n",
      "Train Epoch: 306 [33792/54000 (63%)] Loss: -1812.433350\n",
      "Train Epoch: 306 [45056/54000 (83%)] Loss: -1774.295654\n",
      "    epoch          : 306\n",
      "    loss           : -1789.8903969818691\n",
      "    ess            : 8.001184004657674\n",
      "    log_marginal   : 1789.8903969818691\n",
      "    val_loss       : -1788.4224548339844\n",
      "    val_ess        : 8.001185178756714\n",
      "    val_log_marginal: 1788.4224548339844\n",
      "Train Epoch: 307 [0/54000 (0%)] Loss: -1799.527832\n",
      "Train Epoch: 307 [11264/54000 (21%)] Loss: -1811.724365\n",
      "Train Epoch: 307 [22528/54000 (42%)] Loss: -1797.573242\n",
      "Train Epoch: 307 [33792/54000 (63%)] Loss: -1820.182617\n",
      "Train Epoch: 307 [45056/54000 (83%)] Loss: -1786.703491\n",
      "    epoch          : 307\n",
      "    loss           : -1799.2962611936173\n",
      "    ess            : 8.001183347881964\n",
      "    log_marginal   : 1799.2962611936173\n",
      "    val_loss       : -1799.4218037923176\n",
      "    val_ess        : 8.001184860865274\n",
      "    val_log_marginal: 1799.4218037923176\n",
      "Train Epoch: 308 [0/54000 (0%)] Loss: -1810.239014\n",
      "Train Epoch: 308 [11264/54000 (21%)] Loss: -1810.024170\n",
      "Train Epoch: 308 [22528/54000 (42%)] Loss: -1798.126221\n",
      "Train Epoch: 308 [33792/54000 (63%)] Loss: -1796.632935\n",
      "Train Epoch: 308 [45056/54000 (83%)] Loss: -1772.172119\n",
      "    epoch          : 308\n",
      "    loss           : -1791.5369642725532\n",
      "    ess            : 8.001183176940343\n",
      "    log_marginal   : 1791.5369631209464\n",
      "    val_loss       : -1788.2077229817708\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1788.2077229817708\n",
      "Train Epoch: 309 [0/54000 (0%)] Loss: -1797.481323\n",
      "Train Epoch: 309 [11264/54000 (21%)] Loss: -1803.346436\n",
      "Train Epoch: 309 [22528/54000 (42%)] Loss: -1787.923706\n",
      "Train Epoch: 309 [33792/54000 (63%)] Loss: -1793.098877\n",
      "Train Epoch: 309 [45056/54000 (83%)] Loss: -1778.911865\n",
      "    epoch          : 309\n",
      "    loss           : -1787.0062820146668\n",
      "    ess            : 8.001183671771356\n",
      "    log_marginal   : 1787.00628086306\n",
      "    val_loss       : -1793.7055358886719\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1793.7055358886719\n",
      "Train Epoch: 310 [0/54000 (0%)] Loss: -1803.268799\n",
      "Train Epoch: 310 [11264/54000 (21%)] Loss: -1809.259399\n",
      "Train Epoch: 310 [22528/54000 (42%)] Loss: -1796.592163\n",
      "Train Epoch: 310 [33792/54000 (63%)] Loss: -1812.029785\n",
      "Train Epoch: 310 [45056/54000 (83%)] Loss: -1779.210693\n",
      "    epoch          : 310\n",
      "    loss           : -1794.840815706073\n",
      "    ess            : 8.001182394207648\n",
      "    log_marginal   : 1794.8408168576798\n",
      "    val_loss       : -1792.5308837890625\n",
      "    val_ess        : 8.001184860865274\n",
      "    val_log_marginal: 1792.5308837890625\n",
      "Train Epoch: 311 [0/54000 (0%)] Loss: -1802.687012\n",
      "Train Epoch: 311 [11264/54000 (21%)] Loss: -1813.429321\n",
      "Train Epoch: 311 [22528/54000 (42%)] Loss: -1793.410889\n",
      "Train Epoch: 311 [33792/54000 (63%)] Loss: -1805.324463\n",
      "Train Epoch: 311 [45056/54000 (83%)] Loss: -1783.642334\n",
      "    epoch          : 311\n",
      "    loss           : -1794.2127973448555\n",
      "    ess            : 8.001183050983357\n",
      "    log_marginal   : 1794.2127973448555\n",
      "    val_loss       : -1795.0085754394531\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1795.0085754394531\n",
      "Train Epoch: 312 [0/54000 (0%)] Loss: -1806.897583\n",
      "Train Epoch: 312 [11264/54000 (21%)] Loss: -1805.789185\n",
      "Train Epoch: 312 [22528/54000 (42%)] Loss: -1786.702881\n",
      "Train Epoch: 312 [33792/54000 (63%)] Loss: -1814.460205\n",
      "Train Epoch: 312 [45056/54000 (83%)] Loss: -1786.435791\n",
      "    epoch          : 312\n",
      "    loss           : -1794.1574350033166\n",
      "    ess            : 8.00118220527217\n",
      "    log_marginal   : 1794.1574350033166\n",
      "    val_loss       : -1788.0240681966145\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1788.0240580240886\n",
      "Train Epoch: 313 [0/54000 (0%)] Loss: -1800.786133\n",
      "Train Epoch: 313 [11264/54000 (21%)] Loss: -1811.348389\n",
      "Train Epoch: 313 [22528/54000 (42%)] Loss: -1791.108643\n",
      "Train Epoch: 313 [33792/54000 (63%)] Loss: -1812.896240\n",
      "Train Epoch: 313 [45056/54000 (83%)] Loss: -1795.983643\n",
      "    epoch          : 313\n",
      "    loss           : -1797.4703000626473\n",
      "    ess            : 8.001182682109329\n",
      "    log_marginal   : 1797.4703000626473\n",
      "    val_loss       : -1801.6126200358074\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1801.6126200358074\n",
      "Train Epoch: 314 [0/54000 (0%)] Loss: -1812.841309\n",
      "Train Epoch: 314 [11264/54000 (21%)] Loss: -1814.964478\n",
      "Train Epoch: 314 [22528/54000 (42%)] Loss: -1791.939209\n",
      "Train Epoch: 314 [33792/54000 (63%)] Loss: -1816.745972\n",
      "Train Epoch: 314 [45056/54000 (83%)] Loss: -1786.020020\n",
      "    epoch          : 314\n",
      "    loss           : -1798.7544002892837\n",
      "    ess            : 8.001183239918834\n",
      "    log_marginal   : 1798.754399137677\n",
      "    val_loss       : -1798.455078125\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1798.455078125\n",
      "Train Epoch: 315 [0/54000 (0%)] Loss: -1809.799805\n",
      "Train Epoch: 315 [11264/54000 (21%)] Loss: -1810.576660\n",
      "Train Epoch: 315 [22528/54000 (42%)] Loss: -1791.217773\n",
      "Train Epoch: 315 [33792/54000 (63%)] Loss: -1796.817749\n",
      "Train Epoch: 315 [45056/54000 (83%)] Loss: -1749.340332\n",
      "    epoch          : 315\n",
      "    loss           : -1787.9770979971256\n",
      "    ess            : 8.00118325791269\n",
      "    log_marginal   : 1787.9770979971256\n",
      "    val_loss       : -1791.9873962402344\n",
      "    val_ess        : 8.001185496648153\n",
      "    val_log_marginal: 1791.9873962402344\n",
      "Train Epoch: 316 [0/54000 (0%)] Loss: -1803.269531\n",
      "Train Epoch: 316 [11264/54000 (21%)] Loss: -1801.193359\n",
      "Train Epoch: 316 [22528/54000 (42%)] Loss: -1769.150757\n",
      "Train Epoch: 316 [33792/54000 (63%)] Loss: -1802.278931\n",
      "Train Epoch: 316 [45056/54000 (83%)] Loss: -1786.189209\n",
      "    epoch          : 316\n",
      "    loss           : -1789.7291662827977\n",
      "    ess            : 8.001184103623876\n",
      "    log_marginal   : 1789.7291662827977\n",
      "    val_loss       : -1807.5392659505208\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1807.5392659505208\n",
      "Train Epoch: 317 [0/54000 (0%)] Loss: -1818.555054\n",
      "Train Epoch: 317 [11264/54000 (21%)] Loss: -1807.825928\n",
      "Train Epoch: 317 [22528/54000 (42%)] Loss: -1786.493042\n",
      "Train Epoch: 317 [33792/54000 (63%)] Loss: -1809.859619\n",
      "Train Epoch: 317 [45056/54000 (83%)] Loss: -1792.479980\n",
      "    epoch          : 317\n",
      "    loss           : -1796.8722948758107\n",
      "    ess            : 8.001181962355128\n",
      "    log_marginal   : 1796.8722948758107\n",
      "    val_loss       : -1791.7051391601562\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1791.7051391601562\n",
      "Train Epoch: 318 [0/54000 (0%)] Loss: -1803.276245\n",
      "Train Epoch: 318 [11264/54000 (21%)] Loss: -1804.992432\n",
      "Train Epoch: 318 [22528/54000 (42%)] Loss: -1781.685303\n",
      "Train Epoch: 318 [33792/54000 (63%)] Loss: -1798.618896\n",
      "Train Epoch: 318 [45056/54000 (83%)] Loss: -1769.709961\n",
      "    epoch          : 318\n",
      "    loss           : -1787.77894908977\n",
      "    ess            : 8.00118343785124\n",
      "    log_marginal   : 1787.77894908977\n",
      "    val_loss       : -1781.1710103352864\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1781.1710205078125\n",
      "Train Epoch: 319 [0/54000 (0%)] Loss: -1794.667114\n",
      "Train Epoch: 319 [11264/54000 (21%)] Loss: -1800.011230\n",
      "Train Epoch: 319 [22528/54000 (42%)] Loss: -1780.260254\n",
      "Train Epoch: 319 [33792/54000 (63%)] Loss: -1785.666870\n",
      "Train Epoch: 319 [45056/54000 (83%)] Loss: -1771.433472\n",
      "    epoch          : 319\n",
      "    loss           : -1780.5525823629127\n",
      "    ess            : 8.001183068977213\n",
      "    log_marginal   : 1780.5525823629127\n",
      "    val_loss       : -1785.2524312337239\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1785.2524312337239\n",
      "Train Epoch: 320 [0/54000 (0%)] Loss: -1803.007202\n",
      "Train Epoch: 320 [11264/54000 (21%)] Loss: -1808.033936\n",
      "Train Epoch: 320 [22528/54000 (42%)] Loss: -1789.822876\n",
      "Train Epoch: 320 [33792/54000 (63%)] Loss: -1810.040039\n",
      "Train Epoch: 320 [45056/54000 (83%)] Loss: -1794.044189\n",
      "    epoch          : 320\n",
      "    loss           : -1794.246561302329\n",
      "    ess            : 8.0011832939004\n",
      "    log_marginal   : 1794.246561302329\n",
      "    val_loss       : -1796.7550659179688\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1796.7550659179688\n",
      "Train Epoch: 321 [0/54000 (0%)] Loss: -1808.123169\n",
      "Train Epoch: 321 [11264/54000 (21%)] Loss: -1801.749756\n",
      "Train Epoch: 321 [22528/54000 (42%)] Loss: -1795.293213\n",
      "Train Epoch: 321 [33792/54000 (63%)] Loss: -1809.168701\n",
      "Train Epoch: 321 [45056/54000 (83%)] Loss: -1787.190674\n",
      "    epoch          : 321\n",
      "    loss           : -1793.1361314305718\n",
      "    ess            : 8.00118343785124\n",
      "    log_marginal   : 1793.1361314305718\n",
      "    val_loss       : -1785.8386128743489\n",
      "    val_ess        : 8.001184542973837\n",
      "    val_log_marginal: 1785.838602701823\n",
      "Train Epoch: 322 [0/54000 (0%)] Loss: -1796.820190\n",
      "Train Epoch: 322 [11264/54000 (21%)] Loss: -1799.510010\n",
      "Train Epoch: 322 [22528/54000 (42%)] Loss: -1795.840576\n",
      "Train Epoch: 322 [33792/54000 (63%)] Loss: -1809.876343\n",
      "Train Epoch: 322 [45056/54000 (83%)] Loss: -1785.929688\n",
      "    epoch          : 322\n",
      "    loss           : -1793.8143091741597\n",
      "    ess            : 8.001184157605442\n",
      "    log_marginal   : 1793.8143091741597\n",
      "    val_loss       : -1795.581278483073\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1795.581298828125\n",
      "Train Epoch: 323 [0/54000 (0%)] Loss: -1806.651245\n",
      "Train Epoch: 323 [11264/54000 (21%)] Loss: -1810.537842\n",
      "Train Epoch: 323 [22528/54000 (42%)] Loss: -1783.868896\n",
      "Train Epoch: 323 [33792/54000 (63%)] Loss: -1792.204712\n",
      "Train Epoch: 323 [45056/54000 (83%)] Loss: -1758.365967\n",
      "    epoch          : 323\n",
      "    loss           : -1783.216958099941\n",
      "    ess            : 8.001184103623876\n",
      "    log_marginal   : 1783.2169592515477\n",
      "    val_loss       : -1788.5142110188801\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1788.5142110188801\n",
      "Train Epoch: 324 [0/54000 (0%)] Loss: -1802.710938\n",
      "Train Epoch: 324 [11264/54000 (21%)] Loss: -1756.177246\n",
      "Train Epoch: 324 [22528/54000 (42%)] Loss: -1773.613037\n",
      "Train Epoch: 324 [33792/54000 (63%)] Loss: -1781.721069\n",
      "Train Epoch: 324 [45056/54000 (83%)] Loss: -1775.819336\n",
      "    epoch          : 324\n",
      "    loss           : -1775.2918286593456\n",
      "    ess            : 8.001184985322773\n",
      "    log_marginal   : 1775.2918286593456\n",
      "    val_loss       : -1797.5637715657551\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1797.5637715657551\n",
      "Train Epoch: 325 [0/54000 (0%)] Loss: -1806.011230\n",
      "Train Epoch: 325 [11264/54000 (21%)] Loss: -1784.553467\n",
      "Train Epoch: 325 [22528/54000 (42%)] Loss: -1788.251465\n",
      "Train Epoch: 325 [33792/54000 (63%)] Loss: -1801.218018\n",
      "Train Epoch: 325 [45056/54000 (83%)] Loss: -1790.864746\n",
      "    epoch          : 325\n",
      "    loss           : -1790.1481588111733\n",
      "    ess            : 8.00118383371605\n",
      "    log_marginal   : 1790.1481588111733\n",
      "    val_loss       : -1799.6150004069011\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1799.6150004069011\n",
      "Train Epoch: 326 [0/54000 (0%)] Loss: -1809.484985\n",
      "Train Epoch: 326 [11264/54000 (21%)] Loss: -1785.128174\n",
      "Train Epoch: 326 [22528/54000 (42%)] Loss: -1775.555420\n",
      "Train Epoch: 326 [33792/54000 (63%)] Loss: -1803.348877\n",
      "Train Epoch: 326 [45056/54000 (83%)] Loss: -1790.372803\n",
      "    epoch          : 326\n",
      "    loss           : -1787.8849878850972\n",
      "    ess            : 8.001183842712978\n",
      "    log_marginal   : 1787.8849867334907\n",
      "    val_loss       : -1797.5380045572917\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1797.5380045572917\n",
      "Train Epoch: 327 [0/54000 (0%)] Loss: -1809.595093\n",
      "Train Epoch: 327 [11264/54000 (21%)] Loss: -1780.826050\n",
      "Train Epoch: 327 [22528/54000 (42%)] Loss: -1781.897705\n",
      "Train Epoch: 327 [33792/54000 (63%)] Loss: -1808.253052\n",
      "Train Epoch: 327 [45056/54000 (83%)] Loss: -1790.224854\n",
      "    epoch          : 327\n",
      "    loss           : -1788.7600742556015\n",
      "    ess            : 8.001184418516338\n",
      "    log_marginal   : 1788.7600742556015\n",
      "    val_loss       : -1797.5576782226562\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1797.5576782226562\n",
      "Train Epoch: 328 [0/54000 (0%)] Loss: -1809.923950\n",
      "Train Epoch: 328 [11264/54000 (21%)] Loss: -1794.309082\n",
      "Train Epoch: 328 [22528/54000 (42%)] Loss: -1787.796875\n",
      "Train Epoch: 328 [33792/54000 (63%)] Loss: -1816.662598\n",
      "Train Epoch: 328 [45056/54000 (83%)] Loss: -1790.951172\n",
      "    epoch          : 328\n",
      "    loss           : -1794.3177870264594\n",
      "    ess            : 8.001184013654601\n",
      "    log_marginal   : 1794.3177870264594\n",
      "    val_loss       : -1800.5451761881511\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1800.5451761881511\n",
      "Train Epoch: 329 [0/54000 (0%)] Loss: -1808.082764\n",
      "Train Epoch: 329 [11264/54000 (21%)] Loss: -1801.865234\n",
      "Train Epoch: 329 [22528/54000 (42%)] Loss: -1795.710693\n",
      "Train Epoch: 329 [33792/54000 (63%)] Loss: -1810.586914\n",
      "Train Epoch: 329 [45056/54000 (83%)] Loss: -1783.242920\n",
      "    epoch          : 329\n",
      "    loss           : -1793.580628593013\n",
      "    ess            : 8.001184265568572\n",
      "    log_marginal   : 1793.580628593013\n",
      "    val_loss       : -1797.3320007324219\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1797.3320007324219\n",
      "Train Epoch: 330 [0/54000 (0%)] Loss: -1807.392700\n",
      "Train Epoch: 330 [11264/54000 (21%)] Loss: -1797.911133\n",
      "Train Epoch: 330 [22528/54000 (42%)] Loss: -1795.427002\n",
      "Train Epoch: 330 [33792/54000 (63%)] Loss: -1802.094238\n",
      "Train Epoch: 330 [45056/54000 (83%)] Loss: -1781.530273\n",
      "    epoch          : 330\n",
      "    loss           : -1790.9775667010613\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1790.9775667010613\n",
      "    val_loss       : -1795.8138122558594\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1795.8138122558594\n",
      "Train Epoch: 331 [0/54000 (0%)] Loss: -1809.592285\n",
      "Train Epoch: 331 [11264/54000 (21%)] Loss: -1789.768311\n",
      "Train Epoch: 331 [22528/54000 (42%)] Loss: -1788.382202\n",
      "Train Epoch: 331 [33792/54000 (63%)] Loss: -1810.293823\n",
      "Train Epoch: 331 [45056/54000 (83%)] Loss: -1789.858765\n",
      "    epoch          : 331\n",
      "    loss           : -1792.2151673514888\n",
      "    ess            : 8.00118404964231\n",
      "    log_marginal   : 1792.2151673514888\n",
      "    val_loss       : -1800.994364420573\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1800.9943542480469\n",
      "Train Epoch: 332 [0/54000 (0%)] Loss: -1812.697754\n",
      "Train Epoch: 332 [11264/54000 (21%)] Loss: -1802.052734\n",
      "Train Epoch: 332 [22528/54000 (42%)] Loss: -1799.718506\n",
      "Train Epoch: 332 [33792/54000 (63%)] Loss: -1812.753174\n",
      "Train Epoch: 332 [45056/54000 (83%)] Loss: -1792.113892\n",
      "    epoch          : 332\n",
      "    loss           : -1798.4921610130455\n",
      "    ess            : 8.00118404964231\n",
      "    log_marginal   : 1798.4921610130455\n",
      "    val_loss       : -1799.1485087076824\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1799.1485087076824\n",
      "Train Epoch: 333 [0/54000 (0%)] Loss: -1812.192993\n",
      "Train Epoch: 333 [11264/54000 (21%)] Loss: -1801.570068\n",
      "Train Epoch: 333 [22528/54000 (42%)] Loss: -1789.936768\n",
      "Train Epoch: 333 [33792/54000 (63%)] Loss: -1803.246582\n",
      "Train Epoch: 333 [45056/54000 (83%)] Loss: -1785.302002\n",
      "    epoch          : 333\n",
      "    loss           : -1791.3784064526828\n",
      "    ess            : 8.001184121617731\n",
      "    log_marginal   : 1791.3784087558963\n",
      "    val_loss       : -1790.4200948079426\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1790.4200948079426\n",
      "Train Epoch: 334 [0/54000 (0%)] Loss: -1804.433105\n",
      "Train Epoch: 334 [11264/54000 (21%)] Loss: -1804.418579\n",
      "Train Epoch: 334 [22528/54000 (42%)] Loss: -1790.997803\n",
      "Train Epoch: 334 [33792/54000 (63%)] Loss: -1805.535156\n",
      "Train Epoch: 334 [45056/54000 (83%)] Loss: -1798.070679\n",
      "    epoch          : 334\n",
      "    loss           : -1795.5711220795254\n",
      "    ess            : 8.001184355537847\n",
      "    log_marginal   : 1795.5711220795254\n",
      "    val_loss       : -1803.5062357584636\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1803.5062357584636\n",
      "Train Epoch: 335 [0/54000 (0%)] Loss: -1814.026123\n",
      "Train Epoch: 335 [11264/54000 (21%)] Loss: -1806.126709\n",
      "Train Epoch: 335 [22528/54000 (42%)] Loss: -1789.466919\n",
      "Train Epoch: 335 [33792/54000 (63%)] Loss: -1796.813477\n",
      "Train Epoch: 335 [45056/54000 (83%)] Loss: -1784.091064\n",
      "    epoch          : 335\n",
      "    loss           : -1793.0192283774322\n",
      "    ess            : 8.00118397766689\n",
      "    log_marginal   : 1793.0192283774322\n",
      "    val_loss       : -1797.0052998860676\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1797.0053100585938\n",
      "Train Epoch: 336 [0/54000 (0%)] Loss: -1808.291260\n",
      "Train Epoch: 336 [11264/54000 (21%)] Loss: -1808.582153\n",
      "Train Epoch: 336 [22528/54000 (42%)] Loss: -1791.414795\n",
      "Train Epoch: 336 [33792/54000 (63%)] Loss: -1804.958984\n",
      "Train Epoch: 336 [45056/54000 (83%)] Loss: -1774.777466\n",
      "    epoch          : 336\n",
      "    loss           : -1791.2471209831958\n",
      "    ess            : 8.00118408563002\n",
      "    log_marginal   : 1791.2471209831958\n",
      "    val_loss       : -1771.8326009114583\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1771.8326009114583\n",
      "Train Epoch: 337 [0/54000 (0%)] Loss: -1788.075928\n",
      "Train Epoch: 337 [11264/54000 (21%)] Loss: -1805.704712\n",
      "Train Epoch: 337 [22528/54000 (42%)] Loss: -1776.842529\n",
      "Train Epoch: 337 [33792/54000 (63%)] Loss: -1803.756836\n",
      "Train Epoch: 337 [45056/54000 (83%)] Loss: -1776.691772\n",
      "    epoch          : 337\n",
      "    loss           : -1786.2168740326504\n",
      "    ess            : 8.001184292559353\n",
      "    log_marginal   : 1786.2168728810436\n",
      "    val_loss       : -1791.1819763183594\n",
      "    val_ess        : 8.001185337702433\n",
      "    val_log_marginal: 1791.1819763183594\n",
      "Train Epoch: 338 [0/54000 (0%)] Loss: -1801.133057\n",
      "Train Epoch: 338 [11264/54000 (21%)] Loss: -1810.324829\n",
      "Train Epoch: 338 [22528/54000 (42%)] Loss: -1791.679199\n",
      "Train Epoch: 338 [33792/54000 (63%)] Loss: -1811.083008\n",
      "Train Epoch: 338 [45056/54000 (83%)] Loss: -1792.102295\n",
      "    epoch          : 338\n",
      "    loss           : -1798.6596253593013\n",
      "    ess            : 8.001183887697616\n",
      "    log_marginal   : 1798.6596253593013\n",
      "    val_loss       : -1802.2635803222656\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1802.2635803222656\n",
      "Train Epoch: 339 [0/54000 (0%)] Loss: -1812.045410\n",
      "Train Epoch: 339 [11264/54000 (21%)] Loss: -1814.277832\n",
      "Train Epoch: 339 [22528/54000 (42%)] Loss: -1792.266602\n",
      "Train Epoch: 339 [33792/54000 (63%)] Loss: -1809.125977\n",
      "Train Epoch: 339 [45056/54000 (83%)] Loss: -1783.562500\n",
      "    epoch          : 339\n",
      "    loss           : -1795.4640099867336\n",
      "    ess            : 8.001184823378077\n",
      "    log_marginal   : 1795.4640099867336\n",
      "    val_loss       : -1786.2876993815105\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1786.2877095540364\n",
      "Train Epoch: 340 [0/54000 (0%)] Loss: -1797.349976\n",
      "Train Epoch: 340 [11264/54000 (21%)] Loss: -1800.021362\n",
      "Train Epoch: 340 [22528/54000 (42%)] Loss: -1787.471191\n",
      "Train Epoch: 340 [33792/54000 (63%)] Loss: -1806.182007\n",
      "Train Epoch: 340 [45056/54000 (83%)] Loss: -1788.230591\n",
      "    epoch          : 340\n",
      "    loss           : -1792.6889176278744\n",
      "    ess            : 8.0011842745655\n",
      "    log_marginal   : 1792.6889176278744\n",
      "    val_loss       : -1794.0750834147136\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1794.0750935872395\n",
      "Train Epoch: 341 [0/54000 (0%)] Loss: -1807.120728\n",
      "Train Epoch: 341 [11264/54000 (21%)] Loss: -1800.428589\n",
      "Train Epoch: 341 [22528/54000 (42%)] Loss: -1790.193970\n",
      "Train Epoch: 341 [33792/54000 (63%)] Loss: -1802.031860\n",
      "Train Epoch: 341 [45056/54000 (83%)] Loss: -1789.767578\n",
      "    epoch          : 341\n",
      "    loss           : -1793.5651199052918\n",
      "    ess            : 8.001182988004864\n",
      "    log_marginal   : 1793.5651199052918\n",
      "    val_loss       : -1796.3081868489583\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1796.3081868489583\n",
      "Train Epoch: 342 [0/54000 (0%)] Loss: -1807.554199\n",
      "Train Epoch: 342 [11264/54000 (21%)] Loss: -1808.305176\n",
      "Train Epoch: 342 [22528/54000 (42%)] Loss: -1751.893311\n",
      "Train Epoch: 342 [33792/54000 (63%)] Loss: -1776.016357\n",
      "Train Epoch: 342 [45056/54000 (83%)] Loss: -1768.541504\n",
      "    epoch          : 342\n",
      "    loss           : -1778.094300468013\n",
      "    ess            : 8.001184265568572\n",
      "    log_marginal   : 1778.094300468013\n",
      "    val_loss       : -1789.8812764485676\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1789.8812764485676\n",
      "Train Epoch: 343 [0/54000 (0%)] Loss: -1801.168335\n",
      "Train Epoch: 343 [11264/54000 (21%)] Loss: -1785.017578\n",
      "Train Epoch: 343 [22528/54000 (42%)] Loss: -1767.248291\n",
      "Train Epoch: 343 [33792/54000 (63%)] Loss: -1801.695801\n",
      "Train Epoch: 343 [45056/54000 (83%)] Loss: -1784.821045\n",
      "    epoch          : 343\n",
      "    loss           : -1784.263216990345\n",
      "    ess            : 8.001184364534774\n",
      "    log_marginal   : 1784.263216990345\n",
      "    val_loss       : -1803.6588439941406\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1803.6588338216145\n",
      "Train Epoch: 344 [0/54000 (0%)] Loss: -1814.000000\n",
      "Train Epoch: 344 [11264/54000 (21%)] Loss: -1797.293457\n",
      "Train Epoch: 344 [22528/54000 (42%)] Loss: -1785.440063\n",
      "Train Epoch: 344 [33792/54000 (63%)] Loss: -1810.017334\n",
      "Train Epoch: 344 [45056/54000 (83%)] Loss: -1791.072388\n",
      "    epoch          : 344\n",
      "    loss           : -1795.4092361162293\n",
      "    ess            : 8.00118350982666\n",
      "    log_marginal   : 1795.4092349646226\n",
      "    val_loss       : -1802.1642659505208\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1802.1642659505208\n",
      "Train Epoch: 345 [0/54000 (0%)] Loss: -1815.337158\n",
      "Train Epoch: 345 [11264/54000 (21%)] Loss: -1804.406738\n",
      "Train Epoch: 345 [22528/54000 (42%)] Loss: -1779.658936\n",
      "Train Epoch: 345 [33792/54000 (63%)] Loss: -1804.124268\n",
      "Train Epoch: 345 [45056/54000 (83%)] Loss: -1783.325439\n",
      "    epoch          : 345\n",
      "    loss           : -1792.1155257315006\n",
      "    ess            : 8.001183905691471\n",
      "    log_marginal   : 1792.1155268831073\n",
      "    val_loss       : -1794.6523742675781\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1794.6523742675781\n",
      "Train Epoch: 346 [0/54000 (0%)] Loss: -1804.611694\n",
      "Train Epoch: 346 [11264/54000 (21%)] Loss: -1782.229492\n",
      "Train Epoch: 346 [22528/54000 (42%)] Loss: -1738.739258\n",
      "Train Epoch: 346 [33792/54000 (63%)] Loss: -1761.284912\n",
      "Train Epoch: 346 [45056/54000 (83%)] Loss: -1751.002563\n",
      "    epoch          : 346\n",
      "    loss           : -1762.8664044074292\n",
      "    ess            : 8.001184445507121\n",
      "    log_marginal   : 1762.8664044074292\n",
      "    val_loss       : -1763.1373494466145\n",
      "    val_ess        : 8.001185258229574\n",
      "    val_log_marginal: 1763.1373494466145\n",
      "Train Epoch: 347 [0/54000 (0%)] Loss: -1774.797119\n",
      "Train Epoch: 347 [11264/54000 (21%)] Loss: -1786.062500\n",
      "Train Epoch: 347 [22528/54000 (42%)] Loss: -1780.439331\n",
      "Train Epoch: 347 [33792/54000 (63%)] Loss: -1793.326904\n",
      "Train Epoch: 347 [45056/54000 (83%)] Loss: -1784.130127\n",
      "    epoch          : 347\n",
      "    loss           : -1783.0062474664653\n",
      "    ess            : 8.001184499488687\n",
      "    log_marginal   : 1783.0062486180718\n",
      "    val_loss       : -1780.7551778157551\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1780.7551778157551\n",
      "Train Epoch: 348 [0/54000 (0%)] Loss: -1791.531738\n",
      "Train Epoch: 348 [11264/54000 (21%)] Loss: -1800.665771\n",
      "Train Epoch: 348 [22528/54000 (42%)] Loss: -1781.300293\n",
      "Train Epoch: 348 [33792/54000 (63%)] Loss: -1806.194458\n",
      "Train Epoch: 348 [45056/54000 (83%)] Loss: -1792.611450\n",
      "    epoch          : 348\n",
      "    loss           : -1792.553446067954\n",
      "    ess            : 8.001183887697616\n",
      "    log_marginal   : 1792.553446067954\n",
      "    val_loss       : -1798.6388244628906\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1798.6388244628906\n",
      "Train Epoch: 349 [0/54000 (0%)] Loss: -1809.140137\n",
      "Train Epoch: 349 [11264/54000 (21%)] Loss: -1809.701172\n",
      "Train Epoch: 349 [22528/54000 (42%)] Loss: -1787.733643\n",
      "Train Epoch: 349 [33792/54000 (63%)] Loss: -1814.606567\n",
      "Train Epoch: 349 [45056/54000 (83%)] Loss: -1791.465088\n",
      "    epoch          : 349\n",
      "    loss           : -1797.8587531323703\n",
      "    ess            : 8.001183923685327\n",
      "    log_marginal   : 1797.8587531323703\n",
      "    val_loss       : -1797.1194966634114\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1797.1194966634114\n",
      "Train Epoch: 350 [0/54000 (0%)] Loss: -1806.270508\n",
      "Train Epoch: 350 [11264/54000 (21%)] Loss: -1801.647949\n",
      "Train Epoch: 350 [22528/54000 (42%)] Loss: -1783.006470\n",
      "Train Epoch: 350 [33792/54000 (63%)] Loss: -1812.507324\n",
      "Train Epoch: 350 [45056/54000 (83%)] Loss: -1783.854126\n",
      "    epoch          : 350\n",
      "    loss           : -1792.9731698665978\n",
      "    ess            : 8.001183959673035\n",
      "    log_marginal   : 1792.973168714991\n",
      "    val_loss       : -1791.6737569173176\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1791.6737569173176\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch350.pth ...\n",
      "Train Epoch: 351 [0/54000 (0%)] Loss: -1799.410645\n",
      "Train Epoch: 351 [11264/54000 (21%)] Loss: -1802.801392\n",
      "Train Epoch: 351 [22528/54000 (42%)] Loss: -1789.219727\n",
      "Train Epoch: 351 [33792/54000 (63%)] Loss: -1817.591064\n",
      "Train Epoch: 351 [45056/54000 (83%)] Loss: -1790.671143\n",
      "    epoch          : 351\n",
      "    loss           : -1795.4101919498084\n",
      "    ess            : 8.001183779734486\n",
      "    log_marginal   : 1795.4101919498084\n",
      "    val_loss       : -1796.652079264323\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1796.6520690917969\n",
      "Train Epoch: 352 [0/54000 (0%)] Loss: -1805.467896\n",
      "Train Epoch: 352 [11264/54000 (21%)] Loss: -1807.368774\n",
      "Train Epoch: 352 [22528/54000 (42%)] Loss: -1785.178711\n",
      "Train Epoch: 352 [33792/54000 (63%)] Loss: -1805.433350\n",
      "Train Epoch: 352 [45056/54000 (83%)] Loss: -1784.705566\n",
      "    epoch          : 352\n",
      "    loss           : -1793.1028050836528\n",
      "    ess            : 8.001184139611587\n",
      "    log_marginal   : 1793.1028050836528\n",
      "    val_loss       : -1797.3349711100261\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1797.3349711100261\n",
      "Train Epoch: 353 [0/54000 (0%)] Loss: -1806.744873\n",
      "Train Epoch: 353 [11264/54000 (21%)] Loss: -1798.343262\n",
      "Train Epoch: 353 [22528/54000 (42%)] Loss: -1780.540283\n",
      "Train Epoch: 353 [33792/54000 (63%)] Loss: -1803.162842\n",
      "Train Epoch: 353 [45056/54000 (83%)] Loss: -1770.835571\n",
      "    epoch          : 353\n",
      "    loss           : -1783.4010424344044\n",
      "    ess            : 8.001184625445672\n",
      "    log_marginal   : 1783.4010424344044\n",
      "    val_loss       : -1770.3478291829426\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1770.3478088378906\n",
      "Train Epoch: 354 [0/54000 (0%)] Loss: -1784.356201\n",
      "Train Epoch: 354 [11264/54000 (21%)] Loss: -1794.355469\n",
      "Train Epoch: 354 [22528/54000 (42%)] Loss: -1776.104248\n",
      "Train Epoch: 354 [33792/54000 (63%)] Loss: -1807.975708\n",
      "Train Epoch: 354 [45056/54000 (83%)] Loss: -1779.588745\n",
      "    epoch          : 354\n",
      "    loss           : -1784.297098411704\n",
      "    ess            : 8.001184625445672\n",
      "    log_marginal   : 1784.297098411704\n",
      "    val_loss       : -1784.6951090494792\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1784.6951090494792\n",
      "Train Epoch: 355 [0/54000 (0%)] Loss: -1795.127563\n",
      "Train Epoch: 355 [11264/54000 (21%)] Loss: -1809.966064\n",
      "Train Epoch: 355 [22528/54000 (42%)] Loss: -1789.941040\n",
      "Train Epoch: 355 [33792/54000 (63%)] Loss: -1817.184326\n",
      "Train Epoch: 355 [45056/54000 (83%)] Loss: -1790.563477\n",
      "    epoch          : 355\n",
      "    loss           : -1796.1741333007812\n",
      "    ess            : 8.00118350982666\n",
      "    log_marginal   : 1796.1741333007812\n",
      "    val_loss       : -1791.611836751302\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1791.611836751302\n",
      "Train Epoch: 356 [0/54000 (0%)] Loss: -1801.776367\n",
      "Train Epoch: 356 [11264/54000 (21%)] Loss: -1811.131104\n",
      "Train Epoch: 356 [22528/54000 (42%)] Loss: -1785.107178\n",
      "Train Epoch: 356 [33792/54000 (63%)] Loss: -1813.521729\n",
      "Train Epoch: 356 [45056/54000 (83%)] Loss: -1779.797363\n",
      "    epoch          : 356\n",
      "    loss           : -1793.1586879514298\n",
      "    ess            : 8.001184463500977\n",
      "    log_marginal   : 1793.1586879514298\n",
      "    val_loss       : -1791.390116373698\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1791.3901265462239\n",
      "Train Epoch: 357 [0/54000 (0%)] Loss: -1798.708496\n",
      "Train Epoch: 357 [11264/54000 (21%)] Loss: -1806.877197\n",
      "Train Epoch: 357 [22528/54000 (42%)] Loss: -1780.957886\n",
      "Train Epoch: 357 [33792/54000 (63%)] Loss: -1808.435669\n",
      "Train Epoch: 357 [45056/54000 (83%)] Loss: -1790.907227\n",
      "    epoch          : 357\n",
      "    loss           : -1792.5926709445018\n",
      "    ess            : 8.001183851709905\n",
      "    log_marginal   : 1792.592669792895\n",
      "    val_loss       : -1802.9886169433594\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1802.9885965983074\n",
      "Train Epoch: 358 [0/54000 (0%)] Loss: -1812.104248\n",
      "Train Epoch: 358 [11264/54000 (21%)] Loss: -1816.525879\n",
      "Train Epoch: 358 [22528/54000 (42%)] Loss: -1794.943970\n",
      "Train Epoch: 358 [33792/54000 (63%)] Loss: -1808.388062\n",
      "Train Epoch: 358 [45056/54000 (83%)] Loss: -1788.716187\n",
      "    epoch          : 358\n",
      "    loss           : -1798.2565745227741\n",
      "    ess            : 8.001183572805152\n",
      "    log_marginal   : 1798.2565745227741\n",
      "    val_loss       : -1794.4288635253906\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1794.4288533528645\n",
      "Train Epoch: 359 [0/54000 (0%)] Loss: -1805.398804\n",
      "Train Epoch: 359 [11264/54000 (21%)] Loss: -1790.228882\n",
      "Train Epoch: 359 [22528/54000 (42%)] Loss: -1778.386475\n",
      "Train Epoch: 359 [33792/54000 (63%)] Loss: -1819.604126\n",
      "Train Epoch: 359 [45056/54000 (83%)] Loss: -1795.648560\n",
      "    epoch          : 359\n",
      "    loss           : -1791.649236715065\n",
      "    ess            : 8.001184346540919\n",
      "    log_marginal   : 1791.649236715065\n",
      "    val_loss       : -1801.2838134765625\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1801.2838236490886\n",
      "Train Epoch: 360 [0/54000 (0%)] Loss: -1813.012451\n",
      "Train Epoch: 360 [11264/54000 (21%)] Loss: -1802.574707\n",
      "Train Epoch: 360 [22528/54000 (42%)] Loss: -1786.341431\n",
      "Train Epoch: 360 [33792/54000 (63%)] Loss: -1795.102295\n",
      "Train Epoch: 360 [45056/54000 (83%)] Loss: -1774.677856\n",
      "    epoch          : 360\n",
      "    loss           : -1788.1937209795105\n",
      "    ess            : 8.001183563808226\n",
      "    log_marginal   : 1788.1937209795105\n",
      "    val_loss       : -1796.8473612467449\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1796.8473612467449\n",
      "Train Epoch: 361 [0/54000 (0%)] Loss: -1807.123779\n",
      "Train Epoch: 361 [11264/54000 (21%)] Loss: -1803.156982\n",
      "Train Epoch: 361 [22528/54000 (42%)] Loss: -1775.225342\n",
      "Train Epoch: 361 [33792/54000 (63%)] Loss: -1810.168823\n",
      "Train Epoch: 361 [45056/54000 (83%)] Loss: -1760.886475\n",
      "    epoch          : 361\n",
      "    loss           : -1787.9750792305424\n",
      "    ess            : 8.001184949335062\n",
      "    log_marginal   : 1787.9750792305424\n",
      "    val_loss       : -1797.0422465006511\n",
      "    val_ess        : 8.001183271408081\n",
      "    val_log_marginal: 1797.0422465006511\n",
      "Train Epoch: 362 [0/54000 (0%)] Loss: -1804.254150\n",
      "Train Epoch: 362 [11264/54000 (21%)] Loss: -1806.390869\n",
      "Train Epoch: 362 [22528/54000 (42%)] Loss: -1788.121582\n",
      "Train Epoch: 362 [33792/54000 (63%)] Loss: -1813.163574\n",
      "Train Epoch: 362 [45056/54000 (83%)] Loss: -1793.256714\n",
      "    epoch          : 362\n",
      "    loss           : -1797.0171117242778\n",
      "    ess            : 8.001184040645384\n",
      "    log_marginal   : 1797.017110572671\n",
      "    val_loss       : -1807.999267578125\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1807.999247233073\n",
      "Train Epoch: 363 [0/54000 (0%)] Loss: -1815.313843\n",
      "Train Epoch: 363 [11264/54000 (21%)] Loss: -1815.574951\n",
      "Train Epoch: 363 [22528/54000 (42%)] Loss: -1791.886719\n",
      "Train Epoch: 363 [33792/54000 (63%)] Loss: -1808.198975\n",
      "Train Epoch: 363 [45056/54000 (83%)] Loss: -1781.952881\n",
      "    epoch          : 363\n",
      "    loss           : -1796.6439416273586\n",
      "    ess            : 8.00118336587582\n",
      "    log_marginal   : 1796.6439416273586\n",
      "    val_loss       : -1798.6074523925781\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1798.6074625651042\n",
      "Train Epoch: 364 [0/54000 (0%)] Loss: -1807.999756\n",
      "Train Epoch: 364 [11264/54000 (21%)] Loss: -1809.818604\n",
      "Train Epoch: 364 [22528/54000 (42%)] Loss: -1784.419678\n",
      "Train Epoch: 364 [33792/54000 (63%)] Loss: -1804.269287\n",
      "Train Epoch: 364 [45056/54000 (83%)] Loss: -1781.310791\n",
      "    epoch          : 364\n",
      "    loss           : -1790.543101184773\n",
      "    ess            : 8.001183554811298\n",
      "    log_marginal   : 1790.543101184773\n",
      "    val_loss       : -1788.0142110188801\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1788.0142110188801\n",
      "Train Epoch: 365 [0/54000 (0%)] Loss: -1798.224365\n",
      "Train Epoch: 365 [11264/54000 (21%)] Loss: -1795.616821\n",
      "Train Epoch: 365 [22528/54000 (42%)] Loss: -1775.588867\n",
      "Train Epoch: 365 [33792/54000 (63%)] Loss: -1802.715454\n",
      "Train Epoch: 365 [45056/54000 (83%)] Loss: -1783.117676\n",
      "    epoch          : 365\n",
      "    loss           : -1785.0949960384728\n",
      "    ess            : 8.001183779734486\n",
      "    log_marginal   : 1785.0949960384728\n",
      "    val_loss       : -1792.8719685872395\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1792.8719685872395\n",
      "Train Epoch: 366 [0/54000 (0%)] Loss: -1801.631592\n",
      "Train Epoch: 366 [11264/54000 (21%)] Loss: -1802.241943\n",
      "Train Epoch: 366 [22528/54000 (42%)] Loss: -1784.815552\n",
      "Train Epoch: 366 [33792/54000 (63%)] Loss: -1809.797119\n",
      "Train Epoch: 366 [45056/54000 (83%)] Loss: -1786.001221\n",
      "    epoch          : 366\n",
      "    loss           : -1791.8993979400059\n",
      "    ess            : 8.00118404964231\n",
      "    log_marginal   : 1791.8993979400059\n",
      "    val_loss       : -1801.9239705403645\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1801.9239705403645\n",
      "Train Epoch: 367 [0/54000 (0%)] Loss: -1811.699097\n",
      "Train Epoch: 367 [11264/54000 (21%)] Loss: -1811.382080\n",
      "Train Epoch: 367 [22528/54000 (42%)] Loss: -1776.493896\n",
      "Train Epoch: 367 [33792/54000 (63%)] Loss: -1774.623047\n",
      "Train Epoch: 367 [45056/54000 (83%)] Loss: -1762.742432\n",
      "    epoch          : 367\n",
      "    loss           : -1782.8898419074292\n",
      "    ess            : 8.001184445507121\n",
      "    log_marginal   : 1782.8898419074292\n",
      "    val_loss       : -1792.582275390625\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1792.5822652180989\n",
      "Train Epoch: 368 [0/54000 (0%)] Loss: -1802.083252\n",
      "Train Epoch: 368 [11264/54000 (21%)] Loss: -1807.046997\n",
      "Train Epoch: 368 [22528/54000 (42%)] Loss: -1791.491455\n",
      "Train Epoch: 368 [33792/54000 (63%)] Loss: -1788.981567\n",
      "Train Epoch: 368 [45056/54000 (83%)] Loss: -1787.533936\n",
      "    epoch          : 368\n",
      "    loss           : -1791.6723494619694\n",
      "    ess            : 8.001184013654601\n",
      "    log_marginal   : 1791.6723494619694\n",
      "    val_loss       : -1799.7225748697917\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1799.7225748697917\n",
      "Train Epoch: 369 [0/54000 (0%)] Loss: -1809.410156\n",
      "Train Epoch: 369 [11264/54000 (21%)] Loss: -1812.000977\n",
      "Train Epoch: 369 [22528/54000 (42%)] Loss: -1788.420898\n",
      "Train Epoch: 369 [33792/54000 (63%)] Loss: -1801.374512\n",
      "Train Epoch: 369 [45056/54000 (83%)] Loss: -1787.949585\n",
      "    epoch          : 369\n",
      "    loss           : -1794.3051320201946\n",
      "    ess            : 8.001183887697616\n",
      "    log_marginal   : 1794.3051320201946\n",
      "    val_loss       : -1796.2572224934895\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1796.2572224934895\n",
      "Train Epoch: 370 [0/54000 (0%)] Loss: -1806.497314\n",
      "Train Epoch: 370 [11264/54000 (21%)] Loss: -1806.510010\n",
      "Train Epoch: 370 [22528/54000 (42%)] Loss: -1783.293457\n",
      "Train Epoch: 370 [33792/54000 (63%)] Loss: -1805.870361\n",
      "Train Epoch: 370 [45056/54000 (83%)] Loss: -1783.292969\n",
      "    epoch          : 370\n",
      "    loss           : -1792.3146776883107\n",
      "    ess            : 8.00118408563002\n",
      "    log_marginal   : 1792.3146788399174\n",
      "    val_loss       : -1795.5710754394531\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1795.5710754394531\n",
      "Train Epoch: 371 [0/54000 (0%)] Loss: -1804.955566\n",
      "Train Epoch: 371 [11264/54000 (21%)] Loss: -1813.125732\n",
      "Train Epoch: 371 [22528/54000 (42%)] Loss: -1794.123535\n",
      "Train Epoch: 371 [33792/54000 (63%)] Loss: -1815.288452\n",
      "Train Epoch: 371 [45056/54000 (83%)] Loss: -1792.228271\n",
      "    epoch          : 371\n",
      "    loss           : -1798.98653886903\n",
      "    ess            : 8.001183788731414\n",
      "    log_marginal   : 1798.9865400206368\n",
      "    val_loss       : -1804.4951985677083\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1804.4951985677083\n",
      "Train Epoch: 372 [0/54000 (0%)] Loss: -1815.946533\n",
      "Train Epoch: 372 [11264/54000 (21%)] Loss: -1814.999756\n",
      "Train Epoch: 372 [22528/54000 (42%)] Loss: -1789.144165\n",
      "Train Epoch: 372 [33792/54000 (63%)] Loss: -1807.708130\n",
      "Train Epoch: 372 [45056/54000 (83%)] Loss: -1792.472656\n",
      "    epoch          : 372\n",
      "    loss           : -1797.5041446325913\n",
      "    ess            : 8.001183959673035\n",
      "    log_marginal   : 1797.5041446325913\n",
      "    val_loss       : -1798.5147705078125\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1798.5147705078125\n",
      "Train Epoch: 373 [0/54000 (0%)] Loss: -1806.121216\n",
      "Train Epoch: 373 [11264/54000 (21%)] Loss: -1813.325195\n",
      "Train Epoch: 373 [22528/54000 (42%)] Loss: -1795.767090\n",
      "Train Epoch: 373 [33792/54000 (63%)] Loss: -1815.308838\n",
      "Train Epoch: 373 [45056/54000 (83%)] Loss: -1780.365479\n",
      "    epoch          : 373\n",
      "    loss           : -1796.6296824329304\n",
      "    ess            : 8.001183995660746\n",
      "    log_marginal   : 1796.6296835845371\n",
      "    val_loss       : -1794.103739420573\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1794.1037190755208\n",
      "Train Epoch: 374 [0/54000 (0%)] Loss: -1801.005127\n",
      "Train Epoch: 374 [11264/54000 (21%)] Loss: -1807.122314\n",
      "Train Epoch: 374 [22528/54000 (42%)] Loss: -1792.266846\n",
      "Train Epoch: 374 [33792/54000 (63%)] Loss: -1815.378784\n",
      "Train Epoch: 374 [45056/54000 (83%)] Loss: -1796.953003\n",
      "    epoch          : 374\n",
      "    loss           : -1797.3320174307194\n",
      "    ess            : 8.001184175599295\n",
      "    log_marginal   : 1797.3320174307194\n",
      "    val_loss       : -1805.9097290039062\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1805.9097290039062\n",
      "Train Epoch: 375 [0/54000 (0%)] Loss: -1814.231689\n",
      "Train Epoch: 375 [11264/54000 (21%)] Loss: -1816.464600\n",
      "Train Epoch: 375 [22528/54000 (42%)] Loss: -1795.272827\n",
      "Train Epoch: 375 [33792/54000 (63%)] Loss: -1804.828613\n",
      "Train Epoch: 375 [45056/54000 (83%)] Loss: -1787.456787\n",
      "    epoch          : 375\n",
      "    loss           : -1798.6523886626621\n",
      "    ess            : 8.001182889038661\n",
      "    log_marginal   : 1798.6523886626621\n",
      "    val_loss       : -1803.063456217448\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1803.063456217448\n",
      "Train Epoch: 376 [0/54000 (0%)] Loss: -1812.511230\n",
      "Train Epoch: 376 [11264/54000 (21%)] Loss: -1813.791260\n",
      "Train Epoch: 376 [22528/54000 (42%)] Loss: -1795.710693\n",
      "Train Epoch: 376 [33792/54000 (63%)] Loss: -1812.942871\n",
      "Train Epoch: 376 [45056/54000 (83%)] Loss: -1786.579590\n",
      "    epoch          : 376\n",
      "    loss           : -1797.8673625442218\n",
      "    ess            : 8.001183842712978\n",
      "    log_marginal   : 1797.867364847435\n",
      "    val_loss       : -1767.4371236165364\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1767.4371134440105\n",
      "Train Epoch: 377 [0/54000 (0%)] Loss: -1781.394531\n",
      "Train Epoch: 377 [11264/54000 (21%)] Loss: -1806.904297\n",
      "Train Epoch: 377 [22528/54000 (42%)] Loss: -1780.918213\n",
      "Train Epoch: 377 [33792/54000 (63%)] Loss: -1812.851929\n",
      "Train Epoch: 377 [45056/54000 (83%)] Loss: -1787.819458\n",
      "    epoch          : 377\n",
      "    loss           : -1790.2844042508107\n",
      "    ess            : 8.00118459845489\n",
      "    log_marginal   : 1790.2844054024174\n",
      "    val_loss       : -1798.9422403971355\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1798.9422403971355\n",
      "Train Epoch: 378 [0/54000 (0%)] Loss: -1811.405273\n",
      "Train Epoch: 378 [11264/54000 (21%)] Loss: -1815.953247\n",
      "Train Epoch: 378 [22528/54000 (42%)] Loss: -1798.009033\n",
      "Train Epoch: 378 [33792/54000 (63%)] Loss: -1819.305176\n",
      "Train Epoch: 378 [45056/54000 (83%)] Loss: -1790.942383\n",
      "    epoch          : 378\n",
      "    loss           : -1799.9425509470814\n",
      "    ess            : 8.001183221924979\n",
      "    log_marginal   : 1799.9425509470814\n",
      "    val_loss       : -1788.5704956054688\n",
      "    val_ess        : 8.001183350880941\n",
      "    val_log_marginal: 1788.5704956054688\n",
      "Train Epoch: 379 [0/54000 (0%)] Loss: -1800.362793\n",
      "Train Epoch: 379 [11264/54000 (21%)] Loss: -1798.896729\n",
      "Train Epoch: 379 [22528/54000 (42%)] Loss: -1755.285400\n",
      "Train Epoch: 379 [33792/54000 (63%)] Loss: -1748.198486\n",
      "Train Epoch: 379 [45056/54000 (83%)] Loss: -1758.678955\n",
      "    epoch          : 379\n",
      "    loss           : -1766.8886361751916\n",
      "    ess            : 8.00118404964231\n",
      "    log_marginal   : 1766.8886361751916\n",
      "    val_loss       : -1785.3358052571614\n",
      "    val_ess        : 8.001185258229574\n",
      "    val_log_marginal: 1785.3358052571614\n",
      "Train Epoch: 380 [0/54000 (0%)] Loss: -1794.151611\n",
      "Train Epoch: 380 [11264/54000 (21%)] Loss: -1805.188843\n",
      "Train Epoch: 380 [22528/54000 (42%)] Loss: -1781.594727\n",
      "Train Epoch: 380 [33792/54000 (63%)] Loss: -1784.292725\n",
      "Train Epoch: 380 [45056/54000 (83%)] Loss: -1773.874512\n",
      "    epoch          : 380\n",
      "    loss           : -1783.371122540168\n",
      "    ess            : 8.00118419359315\n",
      "    log_marginal   : 1783.371122540168\n",
      "    val_loss       : -1786.7038167317708\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1786.7038167317708\n",
      "Train Epoch: 381 [0/54000 (0%)] Loss: -1798.824463\n",
      "Train Epoch: 381 [11264/54000 (21%)] Loss: -1808.211426\n",
      "Train Epoch: 381 [22528/54000 (42%)] Loss: -1782.558350\n",
      "Train Epoch: 381 [33792/54000 (63%)] Loss: -1798.102539\n",
      "Train Epoch: 381 [45056/54000 (83%)] Loss: -1786.336670\n",
      "    epoch          : 381\n",
      "    loss           : -1790.7932946547023\n",
      "    ess            : 8.001184130614659\n",
      "    log_marginal   : 1790.7932946547023\n",
      "    val_loss       : -1799.0193888346355\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1799.0193888346355\n",
      "Train Epoch: 382 [0/54000 (0%)] Loss: -1809.840576\n",
      "Train Epoch: 382 [11264/54000 (21%)] Loss: -1810.726562\n",
      "Train Epoch: 382 [22528/54000 (42%)] Loss: -1784.372559\n",
      "Train Epoch: 382 [33792/54000 (63%)] Loss: -1804.867554\n",
      "Train Epoch: 382 [45056/54000 (83%)] Loss: -1784.212524\n",
      "    epoch          : 382\n",
      "    loss           : -1794.4763448463295\n",
      "    ess            : 8.001182664115474\n",
      "    log_marginal   : 1794.4763448463295\n",
      "    val_loss       : -1796.67919921875\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1796.679178873698\n",
      "Train Epoch: 383 [0/54000 (0%)] Loss: -1808.890381\n",
      "Train Epoch: 383 [11264/54000 (21%)] Loss: -1806.816040\n",
      "Train Epoch: 383 [22528/54000 (42%)] Loss: -1788.429932\n",
      "Train Epoch: 383 [33792/54000 (63%)] Loss: -1809.079468\n",
      "Train Epoch: 383 [45056/54000 (83%)] Loss: -1780.724976\n",
      "    epoch          : 383\n",
      "    loss           : -1793.3394867519162\n",
      "    ess            : 8.001183059980285\n",
      "    log_marginal   : 1793.3394856003094\n",
      "    val_loss       : -1797.7421976725261\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1797.7421875\n",
      "Train Epoch: 384 [0/54000 (0%)] Loss: -1807.383545\n",
      "Train Epoch: 384 [11264/54000 (21%)] Loss: -1807.761230\n",
      "Train Epoch: 384 [22528/54000 (42%)] Loss: -1781.059082\n",
      "Train Epoch: 384 [33792/54000 (63%)] Loss: -1806.584106\n",
      "Train Epoch: 384 [45056/54000 (83%)] Loss: -1787.108032\n",
      "    epoch          : 384\n",
      "    loss           : -1794.6039048680718\n",
      "    ess            : 8.001183959673035\n",
      "    log_marginal   : 1794.6039048680718\n",
      "    val_loss       : -1801.7261759440105\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1801.7261555989583\n",
      "Train Epoch: 385 [0/54000 (0%)] Loss: -1812.038940\n",
      "Train Epoch: 385 [11264/54000 (21%)] Loss: -1806.836304\n",
      "Train Epoch: 385 [22528/54000 (42%)] Loss: -1790.540527\n",
      "Train Epoch: 385 [33792/54000 (63%)] Loss: -1814.026001\n",
      "Train Epoch: 385 [45056/54000 (83%)] Loss: -1776.097656\n",
      "    epoch          : 385\n",
      "    loss           : -1794.162238354953\n",
      "    ess            : 8.001182808066314\n",
      "    log_marginal   : 1794.1622372033462\n",
      "    val_loss       : -1790.2822265625\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1790.2822265625\n",
      "Train Epoch: 386 [0/54000 (0%)] Loss: -1802.124023\n",
      "Train Epoch: 386 [11264/54000 (21%)] Loss: -1815.181641\n",
      "Train Epoch: 386 [22528/54000 (42%)] Loss: -1791.216064\n",
      "Train Epoch: 386 [33792/54000 (63%)] Loss: -1815.173584\n",
      "Train Epoch: 386 [45056/54000 (83%)] Loss: -1785.143555\n",
      "    epoch          : 386\n",
      "    loss           : -1797.5562985978036\n",
      "    ess            : 8.00118318593727\n",
      "    log_marginal   : 1797.5562997494103\n",
      "    val_loss       : -1800.3193461100261\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1800.3193461100261\n",
      "Train Epoch: 387 [0/54000 (0%)] Loss: -1811.776611\n",
      "Train Epoch: 387 [11264/54000 (21%)] Loss: -1813.466797\n",
      "Train Epoch: 387 [22528/54000 (42%)] Loss: -1790.204834\n",
      "Train Epoch: 387 [33792/54000 (63%)] Loss: -1813.464844\n",
      "Train Epoch: 387 [45056/54000 (83%)] Loss: -1785.869995\n",
      "    epoch          : 387\n",
      "    loss           : -1797.1661031471108\n",
      "    ess            : 8.00118261013391\n",
      "    log_marginal   : 1797.1661031471108\n",
      "    val_loss       : -1804.1450093587239\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1804.1450093587239\n",
      "Train Epoch: 388 [0/54000 (0%)] Loss: -1816.678467\n",
      "Train Epoch: 388 [11264/54000 (21%)] Loss: -1817.889648\n",
      "Train Epoch: 388 [22528/54000 (42%)] Loss: -1795.816650\n",
      "Train Epoch: 388 [33792/54000 (63%)] Loss: -1807.060303\n",
      "Train Epoch: 388 [45056/54000 (83%)] Loss: -1778.994751\n",
      "    epoch          : 388\n",
      "    loss           : -1798.8627273271668\n",
      "    ess            : 8.00118271809704\n",
      "    log_marginal   : 1798.8627273271668\n",
      "    val_loss       : -1799.3113810221355\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1799.3113810221355\n",
      "Train Epoch: 389 [0/54000 (0%)] Loss: -1810.468262\n",
      "Train Epoch: 389 [11264/54000 (21%)] Loss: -1812.445557\n",
      "Train Epoch: 389 [22528/54000 (42%)] Loss: -1785.497559\n",
      "Train Epoch: 389 [33792/54000 (63%)] Loss: -1805.128906\n",
      "Train Epoch: 389 [45056/54000 (83%)] Loss: -1777.173950\n",
      "    epoch          : 389\n",
      "    loss           : -1791.4150137271522\n",
      "    ess            : 8.001183275906545\n",
      "    log_marginal   : 1791.4150137271522\n",
      "    val_loss       : -1782.9774271647136\n",
      "    val_ess        : 8.001184701919556\n",
      "    val_log_marginal: 1782.9774271647136\n",
      "Train Epoch: 390 [0/54000 (0%)] Loss: -1794.212158\n",
      "Train Epoch: 390 [11264/54000 (21%)] Loss: -1798.880371\n",
      "Train Epoch: 390 [22528/54000 (42%)] Loss: -1770.873047\n",
      "Train Epoch: 390 [33792/54000 (63%)] Loss: -1799.716064\n",
      "Train Epoch: 390 [45056/54000 (83%)] Loss: -1768.696533\n",
      "    epoch          : 390\n",
      "    loss           : -1781.53034023069\n",
      "    ess            : 8.001184697421092\n",
      "    log_marginal   : 1781.53034023069\n",
      "    val_loss       : -1783.6923116048176\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1783.6923116048176\n",
      "Train Epoch: 391 [0/54000 (0%)] Loss: -1797.432983\n",
      "Train Epoch: 391 [11264/54000 (21%)] Loss: -1790.739502\n",
      "Train Epoch: 391 [22528/54000 (42%)] Loss: -1777.986572\n",
      "Train Epoch: 391 [33792/54000 (63%)] Loss: -1808.125732\n",
      "Train Epoch: 391 [45056/54000 (83%)] Loss: -1779.705566\n",
      "    epoch          : 391\n",
      "    loss           : -1784.0962892928214\n",
      "    ess            : 8.001184499488687\n",
      "    log_marginal   : 1784.0962904444282\n",
      "    val_loss       : -1792.1653137207031\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1792.1653137207031\n",
      "Train Epoch: 392 [0/54000 (0%)] Loss: -1803.872559\n",
      "Train Epoch: 392 [11264/54000 (21%)] Loss: -1806.300293\n",
      "Train Epoch: 392 [22528/54000 (42%)] Loss: -1789.591431\n",
      "Train Epoch: 392 [33792/54000 (63%)] Loss: -1813.054199\n",
      "Train Epoch: 392 [45056/54000 (83%)] Loss: -1780.236694\n",
      "    epoch          : 392\n",
      "    loss           : -1792.0585787791126\n",
      "    ess            : 8.001183347881964\n",
      "    log_marginal   : 1792.0585787791126\n",
      "    val_loss       : -1791.8918558756511\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1791.8918558756511\n",
      "Train Epoch: 393 [0/54000 (0%)] Loss: -1803.543701\n",
      "Train Epoch: 393 [11264/54000 (21%)] Loss: -1786.129639\n",
      "Train Epoch: 393 [22528/54000 (42%)] Loss: -1781.015991\n",
      "Train Epoch: 393 [33792/54000 (63%)] Loss: -1810.020630\n",
      "Train Epoch: 393 [45056/54000 (83%)] Loss: -1785.667725\n",
      "    epoch          : 393\n",
      "    loss           : -1787.6479054576946\n",
      "    ess            : 8.001183428854313\n",
      "    log_marginal   : 1787.6479054576946\n",
      "    val_loss       : -1800.2567749023438\n",
      "    val_ess        : 8.001183112462362\n",
      "    val_log_marginal: 1800.2567749023438\n",
      "Train Epoch: 394 [0/54000 (0%)] Loss: -1813.470703\n",
      "Train Epoch: 394 [11264/54000 (21%)] Loss: -1805.912109\n",
      "Train Epoch: 394 [22528/54000 (42%)] Loss: -1792.471802\n",
      "Train Epoch: 394 [33792/54000 (63%)] Loss: -1819.157104\n",
      "Train Epoch: 394 [45056/54000 (83%)] Loss: -1788.830078\n",
      "    epoch          : 394\n",
      "    loss           : -1797.6833956736439\n",
      "    ess            : 8.001182880041734\n",
      "    log_marginal   : 1797.6833956736439\n",
      "    val_loss       : -1795.767110188802\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1795.767110188802\n",
      "Train Epoch: 395 [0/54000 (0%)] Loss: -1807.493164\n",
      "Train Epoch: 395 [11264/54000 (21%)] Loss: -1807.488770\n",
      "Train Epoch: 395 [22528/54000 (42%)] Loss: -1792.775757\n",
      "Train Epoch: 395 [33792/54000 (63%)] Loss: -1816.925049\n",
      "Train Epoch: 395 [45056/54000 (83%)] Loss: -1783.552490\n",
      "    epoch          : 395\n",
      "    loss           : -1795.6385348338001\n",
      "    ess            : 8.001183131955704\n",
      "    log_marginal   : 1795.6385336821934\n",
      "    val_loss       : -1791.708475748698\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1791.708475748698\n",
      "Train Epoch: 396 [0/54000 (0%)] Loss: -1804.522217\n",
      "Train Epoch: 396 [11264/54000 (21%)] Loss: -1802.793457\n",
      "Train Epoch: 396 [22528/54000 (42%)] Loss: -1779.724609\n",
      "Train Epoch: 396 [33792/54000 (63%)] Loss: -1797.983643\n",
      "Train Epoch: 396 [45056/54000 (83%)] Loss: -1774.928223\n",
      "    epoch          : 396\n",
      "    loss           : -1784.2824603386646\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1784.2824603386646\n",
      "    val_loss       : -1793.6439921061199\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1793.6439921061199\n",
      "Train Epoch: 397 [0/54000 (0%)] Loss: -1803.151611\n",
      "Train Epoch: 397 [11264/54000 (21%)] Loss: -1792.654785\n",
      "Train Epoch: 397 [22528/54000 (42%)] Loss: -1777.205811\n",
      "Train Epoch: 397 [33792/54000 (63%)] Loss: -1802.750977\n",
      "Train Epoch: 397 [45056/54000 (83%)] Loss: -1777.481689\n",
      "    epoch          : 397\n",
      "    loss           : -1783.451813319944\n",
      "    ess            : 8.00118325791269\n",
      "    log_marginal   : 1783.451813319944\n",
      "    val_loss       : -1799.2670084635417\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1799.2669779459636\n",
      "Train Epoch: 398 [0/54000 (0%)] Loss: -1810.502686\n",
      "Train Epoch: 398 [11264/54000 (21%)] Loss: -1810.389893\n",
      "Train Epoch: 398 [22528/54000 (42%)] Loss: -1799.825195\n",
      "Train Epoch: 398 [33792/54000 (63%)] Loss: -1803.439697\n",
      "Train Epoch: 398 [45056/54000 (83%)] Loss: -1779.829346\n",
      "    epoch          : 398\n",
      "    loss           : -1793.7702901588295\n",
      "    ess            : 8.001182547155416\n",
      "    log_marginal   : 1793.7702901588295\n",
      "    val_loss       : -1793.8725891113281\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1793.8725891113281\n",
      "Train Epoch: 399 [0/54000 (0%)] Loss: -1804.953369\n",
      "Train Epoch: 399 [11264/54000 (21%)] Loss: -1798.436279\n",
      "Train Epoch: 399 [22528/54000 (42%)] Loss: -1788.023193\n",
      "Train Epoch: 399 [33792/54000 (63%)] Loss: -1797.114258\n",
      "Train Epoch: 399 [45056/54000 (83%)] Loss: -1779.320801\n",
      "    epoch          : 399\n",
      "    loss           : -1785.0184568009286\n",
      "    ess            : 8.001183500829733\n",
      "    log_marginal   : 1785.0184602557488\n",
      "    val_loss       : -1789.2059427897136\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1789.2059427897136\n",
      "Train Epoch: 400 [0/54000 (0%)] Loss: -1801.952393\n",
      "Train Epoch: 400 [11264/54000 (21%)] Loss: -1786.902954\n",
      "Train Epoch: 400 [22528/54000 (42%)] Loss: -1788.787476\n",
      "Train Epoch: 400 [33792/54000 (63%)] Loss: -1808.694092\n",
      "Train Epoch: 400 [45056/54000 (83%)] Loss: -1786.133179\n",
      "    epoch          : 400\n",
      "    loss           : -1788.3604644199588\n",
      "    ess            : 8.001183248915762\n",
      "    log_marginal   : 1788.3604655715656\n",
      "    val_loss       : -1793.269795735677\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1793.269795735677\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch400.pth ...\n",
      "Train Epoch: 401 [0/54000 (0%)] Loss: -1804.063721\n",
      "Train Epoch: 401 [11264/54000 (21%)] Loss: -1787.645264\n",
      "Train Epoch: 401 [22528/54000 (42%)] Loss: -1788.028809\n",
      "Train Epoch: 401 [33792/54000 (63%)] Loss: -1812.810547\n",
      "Train Epoch: 401 [45056/54000 (83%)] Loss: -1792.290283\n",
      "    epoch          : 401\n",
      "    loss           : -1792.5944962411556\n",
      "    ess            : 8.0011829340233\n",
      "    log_marginal   : 1792.5944962411556\n",
      "    val_loss       : -1802.6520284016926\n",
      "    val_ess        : 8.0011834303538\n",
      "    val_log_marginal: 1802.6520284016926\n",
      "Train Epoch: 402 [0/54000 (0%)] Loss: -1815.284668\n",
      "Train Epoch: 402 [11264/54000 (21%)] Loss: -1804.753662\n",
      "Train Epoch: 402 [22528/54000 (42%)] Loss: -1799.705078\n",
      "Train Epoch: 402 [33792/54000 (63%)] Loss: -1814.494385\n",
      "Train Epoch: 402 [45056/54000 (83%)] Loss: -1783.437256\n",
      "    epoch          : 402\n",
      "    loss           : -1798.0970505048645\n",
      "    ess            : 8.001181089653159\n",
      "    log_marginal   : 1798.0970505048645\n",
      "    val_loss       : -1804.4955546061199\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1804.4955546061199\n",
      "Train Epoch: 403 [0/54000 (0%)] Loss: -1814.609985\n",
      "Train Epoch: 403 [11264/54000 (21%)] Loss: -1805.836914\n",
      "Train Epoch: 403 [22528/54000 (42%)] Loss: -1797.567383\n",
      "Train Epoch: 403 [33792/54000 (63%)] Loss: -1814.736450\n",
      "Train Epoch: 403 [45056/54000 (83%)] Loss: -1788.627930\n",
      "    epoch          : 403\n",
      "    loss           : -1798.9461877211086\n",
      "    ess            : 8.001182988004864\n",
      "    log_marginal   : 1798.9461877211086\n",
      "    val_loss       : -1802.7439066569011\n",
      "    val_ess        : 8.001181920369467\n",
      "    val_log_marginal: 1802.7439066569011\n",
      "Train Epoch: 404 [0/54000 (0%)] Loss: -1814.734131\n",
      "Train Epoch: 404 [11264/54000 (21%)] Loss: -1803.785645\n",
      "Train Epoch: 404 [22528/54000 (42%)] Loss: -1792.684082\n",
      "Train Epoch: 404 [33792/54000 (63%)] Loss: -1812.857422\n",
      "Train Epoch: 404 [45056/54000 (83%)] Loss: -1793.651001\n",
      "    epoch          : 404\n",
      "    loss           : -1797.8404863465507\n",
      "    ess            : 8.00118202533362\n",
      "    log_marginal   : 1797.8404863465507\n",
      "    val_loss       : -1800.1511128743489\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1800.151123046875\n",
      "Train Epoch: 405 [0/54000 (0%)] Loss: -1811.351929\n",
      "Train Epoch: 405 [11264/54000 (21%)] Loss: -1811.241211\n",
      "Train Epoch: 405 [22528/54000 (42%)] Loss: -1799.550171\n",
      "Train Epoch: 405 [33792/54000 (63%)] Loss: -1813.030029\n",
      "Train Epoch: 405 [45056/54000 (83%)] Loss: -1774.455322\n",
      "    epoch          : 405\n",
      "    loss           : -1793.2350959058078\n",
      "    ess            : 8.001182682109329\n",
      "    log_marginal   : 1793.2350959058078\n",
      "    val_loss       : -1770.7878926595051\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1770.7878926595051\n",
      "Train Epoch: 406 [0/54000 (0%)] Loss: -1789.777588\n",
      "Train Epoch: 406 [11264/54000 (21%)] Loss: -1809.637207\n",
      "Train Epoch: 406 [22528/54000 (42%)] Loss: -1774.349121\n",
      "Train Epoch: 406 [33792/54000 (63%)] Loss: -1804.854248\n",
      "Train Epoch: 406 [45056/54000 (83%)] Loss: -1779.642822\n",
      "    epoch          : 406\n",
      "    loss           : -1785.5507467017983\n",
      "    ess            : 8.001182475179997\n",
      "    log_marginal   : 1785.550747853405\n",
      "    val_loss       : -1785.472391764323\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1785.4723714192708\n",
      "Train Epoch: 407 [0/54000 (0%)] Loss: -1796.291504\n",
      "Train Epoch: 407 [11264/54000 (21%)] Loss: -1807.595215\n",
      "Train Epoch: 407 [22528/54000 (42%)] Loss: -1777.049316\n",
      "Train Epoch: 407 [33792/54000 (63%)] Loss: -1810.230225\n",
      "Train Epoch: 407 [45056/54000 (83%)] Loss: -1787.086426\n",
      "    epoch          : 407\n",
      "    loss           : -1790.9444856463738\n",
      "    ess            : 8.001182889038661\n",
      "    log_marginal   : 1790.9444856463738\n",
      "    val_loss       : -1791.5523986816406\n",
      "    val_ess        : 8.00118096669515\n",
      "    val_log_marginal: 1791.5523986816406\n",
      "Train Epoch: 408 [0/54000 (0%)] Loss: -1805.396362\n",
      "Train Epoch: 408 [11264/54000 (21%)] Loss: -1808.718994\n",
      "Train Epoch: 408 [22528/54000 (42%)] Loss: -1788.595825\n",
      "Train Epoch: 408 [33792/54000 (63%)] Loss: -1814.655273\n",
      "Train Epoch: 408 [45056/54000 (83%)] Loss: -1788.474121\n",
      "    epoch          : 408\n",
      "    loss           : -1797.3472497328273\n",
      "    ess            : 8.001181539499536\n",
      "    log_marginal   : 1797.347250884434\n",
      "    val_loss       : -1795.4176330566406\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1795.4176330566406\n",
      "Train Epoch: 409 [0/54000 (0%)] Loss: -1805.181396\n",
      "Train Epoch: 409 [11264/54000 (21%)] Loss: -1807.712158\n",
      "Train Epoch: 409 [22528/54000 (42%)] Loss: -1791.971558\n",
      "Train Epoch: 409 [33792/54000 (63%)] Loss: -1810.184204\n",
      "Train Epoch: 409 [45056/54000 (83%)] Loss: -1778.797607\n",
      "    epoch          : 409\n",
      "    loss           : -1792.1020703585643\n",
      "    ess            : 8.001183086971068\n",
      "    log_marginal   : 1792.1020703585643\n",
      "    val_loss       : -1779.0399169921875\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1779.0399271647136\n",
      "Train Epoch: 410 [0/54000 (0%)] Loss: -1794.293701\n",
      "Train Epoch: 410 [11264/54000 (21%)] Loss: -1795.259521\n",
      "Train Epoch: 410 [22528/54000 (42%)] Loss: -1771.790894\n",
      "Train Epoch: 410 [33792/54000 (63%)] Loss: -1784.436523\n",
      "Train Epoch: 410 [45056/54000 (83%)] Loss: -1778.882812\n",
      "    epoch          : 410\n",
      "    loss           : -1778.3034783129422\n",
      "    ess            : 8.00118343785124\n",
      "    log_marginal   : 1778.3034783129422\n",
      "    val_loss       : -1795.174540201823\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1795.1745300292969\n",
      "Train Epoch: 411 [0/54000 (0%)] Loss: -1806.068848\n",
      "Train Epoch: 411 [11264/54000 (21%)] Loss: -1805.122925\n",
      "Train Epoch: 411 [22528/54000 (42%)] Loss: -1780.999023\n",
      "Train Epoch: 411 [33792/54000 (63%)] Loss: -1795.536743\n",
      "Train Epoch: 411 [45056/54000 (83%)] Loss: -1791.337769\n",
      "    epoch          : 411\n",
      "    loss           : -1790.0062474664653\n",
      "    ess            : 8.001183518823588\n",
      "    log_marginal   : 1790.0062474664653\n",
      "    val_loss       : -1797.8411865234375\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1797.8411865234375\n",
      "Train Epoch: 412 [0/54000 (0%)] Loss: -1810.422241\n",
      "Train Epoch: 412 [11264/54000 (21%)] Loss: -1812.763428\n",
      "Train Epoch: 412 [22528/54000 (42%)] Loss: -1798.801880\n",
      "Train Epoch: 412 [33792/54000 (63%)] Loss: -1812.789795\n",
      "Train Epoch: 412 [45056/54000 (83%)] Loss: -1794.211548\n",
      "    epoch          : 412\n",
      "    loss           : -1798.4868762897995\n",
      "    ess            : 8.00118361778979\n",
      "    log_marginal   : 1798.4868762897995\n",
      "    val_loss       : -1801.4345601399739\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1801.4345601399739\n",
      "Train Epoch: 413 [0/54000 (0%)] Loss: -1813.460815\n",
      "Train Epoch: 413 [11264/54000 (21%)] Loss: -1813.721680\n",
      "Train Epoch: 413 [22528/54000 (42%)] Loss: -1790.479492\n",
      "Train Epoch: 413 [33792/54000 (63%)] Loss: -1805.670898\n",
      "Train Epoch: 413 [45056/54000 (83%)] Loss: -1789.473389\n",
      "    epoch          : 413\n",
      "    loss           : -1794.5538871333283\n",
      "    ess            : 8.001184013654601\n",
      "    log_marginal   : 1794.5538871333283\n",
      "    val_loss       : -1797.2848612467449\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1797.2848714192708\n",
      "Train Epoch: 414 [0/54000 (0%)] Loss: -1808.192871\n",
      "Train Epoch: 414 [11264/54000 (21%)] Loss: -1811.471191\n",
      "Train Epoch: 414 [22528/54000 (42%)] Loss: -1788.690063\n",
      "Train Epoch: 414 [33792/54000 (63%)] Loss: -1816.865234\n",
      "Train Epoch: 414 [45056/54000 (83%)] Loss: -1793.939697\n",
      "    epoch          : 414\n",
      "    loss           : -1798.598889620799\n",
      "    ess            : 8.001182628127763\n",
      "    log_marginal   : 1798.598889620799\n",
      "    val_loss       : -1803.1683654785156\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1803.1683654785156\n",
      "Train Epoch: 415 [0/54000 (0%)] Loss: -1813.555908\n",
      "Train Epoch: 415 [11264/54000 (21%)] Loss: -1806.656982\n",
      "Train Epoch: 415 [22528/54000 (42%)] Loss: -1790.851318\n",
      "Train Epoch: 415 [33792/54000 (63%)] Loss: -1814.036865\n",
      "Train Epoch: 415 [45056/54000 (83%)] Loss: -1783.159790\n",
      "    epoch          : 415\n",
      "    loss           : -1795.8544944907135\n",
      "    ess            : 8.001183815722195\n",
      "    log_marginal   : 1795.8544944907135\n",
      "    val_loss       : -1801.6599527994792\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1801.6599527994792\n",
      "Train Epoch: 416 [0/54000 (0%)] Loss: -1813.647705\n",
      "Train Epoch: 416 [11264/54000 (21%)] Loss: -1811.391602\n",
      "Train Epoch: 416 [22528/54000 (42%)] Loss: -1802.161987\n",
      "Train Epoch: 416 [33792/54000 (63%)] Loss: -1812.232300\n",
      "Train Epoch: 416 [45056/54000 (83%)] Loss: -1789.697510\n",
      "    epoch          : 416\n",
      "    loss           : -1798.8104466852153\n",
      "    ess            : 8.001183950676108\n",
      "    log_marginal   : 1798.8104466852153\n",
      "    val_loss       : -1801.7159729003906\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1801.7159932454426\n",
      "Train Epoch: 417 [0/54000 (0%)] Loss: -1815.348389\n",
      "Train Epoch: 417 [11264/54000 (21%)] Loss: -1811.691772\n",
      "Train Epoch: 417 [22528/54000 (42%)] Loss: -1798.303955\n",
      "Train Epoch: 417 [33792/54000 (63%)] Loss: -1812.580688\n",
      "Train Epoch: 417 [45056/54000 (83%)] Loss: -1790.392212\n",
      "    epoch          : 417\n",
      "    loss           : -1798.052217303582\n",
      "    ess            : 8.001183095967994\n",
      "    log_marginal   : 1798.0522161519752\n",
      "    val_loss       : -1802.6522115071614\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1802.6522115071614\n",
      "Train Epoch: 418 [0/54000 (0%)] Loss: -1815.231079\n",
      "Train Epoch: 418 [11264/54000 (21%)] Loss: -1812.304810\n",
      "Train Epoch: 418 [22528/54000 (42%)] Loss: -1796.427734\n",
      "Train Epoch: 418 [33792/54000 (63%)] Loss: -1815.783691\n",
      "Train Epoch: 418 [45056/54000 (83%)] Loss: -1787.024170\n",
      "    epoch          : 418\n",
      "    loss           : -1796.5912199200325\n",
      "    ess            : 8.001183275906545\n",
      "    log_marginal   : 1796.5912210716392\n",
      "    val_loss       : -1786.4001770019531\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1786.4001770019531\n",
      "Train Epoch: 419 [0/54000 (0%)] Loss: -1800.299683\n",
      "Train Epoch: 419 [11264/54000 (21%)] Loss: -1808.570557\n",
      "Train Epoch: 419 [22528/54000 (42%)] Loss: -1793.391479\n",
      "Train Epoch: 419 [33792/54000 (63%)] Loss: -1814.380615\n",
      "Train Epoch: 419 [45056/54000 (83%)] Loss: -1795.158569\n",
      "    epoch          : 419\n",
      "    loss           : -1796.0421626252948\n",
      "    ess            : 8.001183986663818\n",
      "    log_marginal   : 1796.0421626252948\n",
      "    val_loss       : -1799.3701477050781\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1799.370137532552\n",
      "Train Epoch: 420 [0/54000 (0%)] Loss: -1812.518921\n",
      "Train Epoch: 420 [11264/54000 (21%)] Loss: -1809.476318\n",
      "Train Epoch: 420 [22528/54000 (42%)] Loss: -1790.213867\n",
      "Train Epoch: 420 [33792/54000 (63%)] Loss: -1795.722900\n",
      "Train Epoch: 420 [45056/54000 (83%)] Loss: -1757.911987\n",
      "    epoch          : 420\n",
      "    loss           : -1785.3258805184994\n",
      "    ess            : 8.001183905691471\n",
      "    log_marginal   : 1785.3258805184994\n",
      "    val_loss       : -1785.488505045573\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1785.488505045573\n",
      "Train Epoch: 421 [0/54000 (0%)] Loss: -1798.819824\n",
      "Train Epoch: 421 [11264/54000 (21%)] Loss: -1793.962769\n",
      "Train Epoch: 421 [22528/54000 (42%)] Loss: -1786.054443\n",
      "Train Epoch: 421 [33792/54000 (63%)] Loss: -1803.118286\n",
      "Train Epoch: 421 [45056/54000 (83%)] Loss: -1772.683838\n",
      "    epoch          : 421\n",
      "    loss           : -1784.1708823150059\n",
      "    ess            : 8.001184202590078\n",
      "    log_marginal   : 1784.1708823150059\n",
      "    val_loss       : -1796.9033508300781\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1796.9033304850261\n",
      "Train Epoch: 422 [0/54000 (0%)] Loss: -1809.422363\n",
      "Train Epoch: 422 [11264/54000 (21%)] Loss: -1814.221558\n",
      "Train Epoch: 422 [22528/54000 (42%)] Loss: -1796.897339\n",
      "Train Epoch: 422 [33792/54000 (63%)] Loss: -1803.786743\n",
      "Train Epoch: 422 [45056/54000 (83%)] Loss: -1783.583496\n",
      "    epoch          : 422\n",
      "    loss           : -1793.7162982292896\n",
      "    ess            : 8.001182556152344\n",
      "    log_marginal   : 1793.7162970776828\n",
      "    val_loss       : -1799.3990783691406\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1799.3990783691406\n",
      "Train Epoch: 423 [0/54000 (0%)] Loss: -1811.776733\n",
      "Train Epoch: 423 [11264/54000 (21%)] Loss: -1806.656982\n",
      "Train Epoch: 423 [22528/54000 (42%)] Loss: -1797.397461\n",
      "Train Epoch: 423 [33792/54000 (63%)] Loss: -1818.796021\n",
      "Train Epoch: 423 [45056/54000 (83%)] Loss: -1790.493530\n",
      "    epoch          : 423\n",
      "    loss           : -1797.7088761239681\n",
      "    ess            : 8.001182799069387\n",
      "    log_marginal   : 1797.7088772755749\n",
      "    val_loss       : -1799.8309122721355\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1799.8309326171875\n",
      "Train Epoch: 424 [0/54000 (0%)] Loss: -1811.633301\n",
      "Train Epoch: 424 [11264/54000 (21%)] Loss: -1810.301025\n",
      "Train Epoch: 424 [22528/54000 (42%)] Loss: -1792.427368\n",
      "Train Epoch: 424 [33792/54000 (63%)] Loss: -1810.572266\n",
      "Train Epoch: 424 [45056/54000 (83%)] Loss: -1793.750488\n",
      "    epoch          : 424\n",
      "    loss           : -1797.6263128316627\n",
      "    ess            : 8.001183167943415\n",
      "    log_marginal   : 1797.6263128316627\n",
      "    val_loss       : -1800.4327799479167\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1800.4327799479167\n",
      "Train Epoch: 425 [0/54000 (0%)] Loss: -1813.790527\n",
      "Train Epoch: 425 [11264/54000 (21%)] Loss: -1803.519531\n",
      "Train Epoch: 425 [22528/54000 (42%)] Loss: -1779.218140\n",
      "Train Epoch: 425 [33792/54000 (63%)] Loss: -1793.064941\n",
      "Train Epoch: 425 [45056/54000 (83%)] Loss: -1787.620850\n",
      "    epoch          : 425\n",
      "    loss           : -1789.1907958984375\n",
      "    ess            : 8.001182574146199\n",
      "    log_marginal   : 1789.1907958984375\n",
      "    val_loss       : -1787.499287923177\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1787.499287923177\n",
      "Train Epoch: 426 [0/54000 (0%)] Loss: -1800.369141\n",
      "Train Epoch: 426 [11264/54000 (21%)] Loss: -1798.697388\n",
      "Train Epoch: 426 [22528/54000 (42%)] Loss: -1782.779663\n",
      "Train Epoch: 426 [33792/54000 (63%)] Loss: -1801.319580\n",
      "Train Epoch: 426 [45056/54000 (83%)] Loss: -1784.277588\n",
      "    epoch          : 426\n",
      "    loss           : -1787.530538307046\n",
      "    ess            : 8.001183239918834\n",
      "    log_marginal   : 1787.530538307046\n",
      "    val_loss       : -1790.2977600097656\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1790.2977600097656\n",
      "Train Epoch: 427 [0/54000 (0%)] Loss: -1801.414307\n",
      "Train Epoch: 427 [11264/54000 (21%)] Loss: -1800.398926\n",
      "Train Epoch: 427 [22528/54000 (42%)] Loss: -1783.727295\n",
      "Train Epoch: 427 [33792/54000 (63%)] Loss: -1809.160645\n",
      "Train Epoch: 427 [45056/54000 (83%)] Loss: -1789.629395\n",
      "    epoch          : 427\n",
      "    loss           : -1791.6696961600826\n",
      "    ess            : 8.00118358180208\n",
      "    log_marginal   : 1791.6696961600826\n",
      "    val_loss       : -1796.6458231608074\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1796.6458231608074\n",
      "Train Epoch: 428 [0/54000 (0%)] Loss: -1807.223022\n",
      "Train Epoch: 428 [11264/54000 (21%)] Loss: -1808.559082\n",
      "Train Epoch: 428 [22528/54000 (42%)] Loss: -1781.557129\n",
      "Train Epoch: 428 [33792/54000 (63%)] Loss: -1814.631592\n",
      "Train Epoch: 428 [45056/54000 (83%)] Loss: -1783.251465\n",
      "    epoch          : 428\n",
      "    loss           : -1792.623179309773\n",
      "    ess            : 8.0011829340233\n",
      "    log_marginal   : 1792.623179309773\n",
      "    val_loss       : -1791.7377115885417\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1791.7377115885417\n",
      "Train Epoch: 429 [0/54000 (0%)] Loss: -1802.074707\n",
      "Train Epoch: 429 [11264/54000 (21%)] Loss: -1807.425049\n",
      "Train Epoch: 429 [22528/54000 (42%)] Loss: -1791.264160\n",
      "Train Epoch: 429 [33792/54000 (63%)] Loss: -1820.674561\n",
      "Train Epoch: 429 [45056/54000 (83%)] Loss: -1790.287354\n",
      "    epoch          : 429\n",
      "    loss           : -1796.2345385281544\n",
      "    ess            : 8.001183986663818\n",
      "    log_marginal   : 1796.2345385281544\n",
      "    val_loss       : -1799.0447998046875\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1799.0447794596355\n",
      "Train Epoch: 430 [0/54000 (0%)] Loss: -1809.015137\n",
      "Train Epoch: 430 [11264/54000 (21%)] Loss: -1811.088501\n",
      "Train Epoch: 430 [22528/54000 (42%)] Loss: -1796.996216\n",
      "Train Epoch: 430 [33792/54000 (63%)] Loss: -1819.327148\n",
      "Train Epoch: 430 [45056/54000 (83%)] Loss: -1790.153687\n",
      "    epoch          : 430\n",
      "    loss           : -1799.2783421930278\n",
      "    ess            : 8.001183347881964\n",
      "    log_marginal   : 1799.2783421930278\n",
      "    val_loss       : -1802.187520345052\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1802.187520345052\n",
      "Train Epoch: 431 [0/54000 (0%)] Loss: -1813.107178\n",
      "Train Epoch: 431 [11264/54000 (21%)] Loss: -1815.313477\n",
      "Train Epoch: 431 [22528/54000 (42%)] Loss: -1792.184204\n",
      "Train Epoch: 431 [33792/54000 (63%)] Loss: -1816.077515\n",
      "Train Epoch: 431 [45056/54000 (83%)] Loss: -1778.716797\n",
      "    epoch          : 431\n",
      "    loss           : -1796.044537238355\n",
      "    ess            : 8.001183779734486\n",
      "    log_marginal   : 1796.044537238355\n",
      "    val_loss       : -1794.3304850260417\n",
      "    val_ess        : 8.001185337702433\n",
      "    val_log_marginal: 1794.3304748535156\n",
      "Train Epoch: 432 [0/54000 (0%)] Loss: -1807.237305\n",
      "Train Epoch: 432 [11264/54000 (21%)] Loss: -1806.508057\n",
      "Train Epoch: 432 [22528/54000 (42%)] Loss: -1796.388916\n",
      "Train Epoch: 432 [33792/54000 (63%)] Loss: -1811.713379\n",
      "Train Epoch: 432 [45056/54000 (83%)] Loss: -1790.812988\n",
      "    epoch          : 432\n",
      "    loss           : -1795.0449518167748\n",
      "    ess            : 8.001183455845094\n",
      "    log_marginal   : 1795.0449518167748\n",
      "    val_loss       : -1800.5407307942708\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1800.5407307942708\n",
      "Train Epoch: 433 [0/54000 (0%)] Loss: -1811.133301\n",
      "Train Epoch: 433 [11264/54000 (21%)] Loss: -1808.376221\n",
      "Train Epoch: 433 [22528/54000 (42%)] Loss: -1798.209839\n",
      "Train Epoch: 433 [33792/54000 (63%)] Loss: -1822.246582\n",
      "Train Epoch: 433 [45056/54000 (83%)] Loss: -1794.749268\n",
      "    epoch          : 433\n",
      "    loss           : -1800.8195996554393\n",
      "    ess            : 8.001182268250663\n",
      "    log_marginal   : 1800.8195996554393\n",
      "    val_loss       : -1802.3426411946614\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1802.3426411946614\n",
      "Train Epoch: 434 [0/54000 (0%)] Loss: -1813.572510\n",
      "Train Epoch: 434 [11264/54000 (21%)] Loss: -1808.044556\n",
      "Train Epoch: 434 [22528/54000 (42%)] Loss: -1789.097778\n",
      "Train Epoch: 434 [33792/54000 (63%)] Loss: -1813.201172\n",
      "Train Epoch: 434 [45056/54000 (83%)] Loss: -1785.722046\n",
      "    epoch          : 434\n",
      "    loss           : -1793.7339178121315\n",
      "    ess            : 8.001183095967994\n",
      "    log_marginal   : 1793.7339178121315\n",
      "    val_loss       : -1800.7182108561199\n",
      "    val_ess        : 8.001182874043783\n",
      "    val_log_marginal: 1800.7182210286458\n",
      "Train Epoch: 435 [0/54000 (0%)] Loss: -1811.923706\n",
      "Train Epoch: 435 [11264/54000 (21%)] Loss: -1804.808350\n",
      "Train Epoch: 435 [22528/54000 (42%)] Loss: -1776.909668\n",
      "Train Epoch: 435 [33792/54000 (63%)] Loss: -1798.361938\n",
      "Train Epoch: 435 [45056/54000 (83%)] Loss: -1771.714355\n",
      "    epoch          : 435\n",
      "    loss           : -1782.2665900464328\n",
      "    ess            : 8.001184175599295\n",
      "    log_marginal   : 1782.2665900464328\n",
      "    val_loss       : -1782.0534261067708\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1782.0534261067708\n",
      "Train Epoch: 436 [0/54000 (0%)] Loss: -1791.516724\n",
      "Train Epoch: 436 [11264/54000 (21%)] Loss: -1792.053467\n",
      "Train Epoch: 436 [22528/54000 (42%)] Loss: -1769.911865\n",
      "Train Epoch: 436 [33792/54000 (63%)] Loss: -1810.743042\n",
      "Train Epoch: 436 [45056/54000 (83%)] Loss: -1782.587891\n",
      "    epoch          : 436\n",
      "    loss           : -1784.0883144162735\n",
      "    ess            : 8.001184148608514\n",
      "    log_marginal   : 1784.0883144162735\n",
      "    val_loss       : -1796.2585042317708\n",
      "    val_ess        : 8.001184701919556\n",
      "    val_log_marginal: 1796.2585042317708\n",
      "Train Epoch: 437 [0/54000 (0%)] Loss: -1807.706055\n",
      "Train Epoch: 437 [11264/54000 (21%)] Loss: -1806.634033\n",
      "Train Epoch: 437 [22528/54000 (42%)] Loss: -1787.395020\n",
      "Train Epoch: 437 [33792/54000 (63%)] Loss: -1814.909302\n",
      "Train Epoch: 437 [45056/54000 (83%)] Loss: -1788.176270\n",
      "    epoch          : 437\n",
      "    loss           : -1796.2968162680572\n",
      "    ess            : 8.001182799069387\n",
      "    log_marginal   : 1796.2968162680572\n",
      "    val_loss       : -1802.9127400716145\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1802.9127400716145\n",
      "Train Epoch: 438 [0/54000 (0%)] Loss: -1813.374146\n",
      "Train Epoch: 438 [11264/54000 (21%)] Loss: -1809.411865\n",
      "Train Epoch: 438 [22528/54000 (42%)] Loss: -1795.844604\n",
      "Train Epoch: 438 [33792/54000 (63%)] Loss: -1818.789917\n",
      "Train Epoch: 438 [45056/54000 (83%)] Loss: -1794.262451\n",
      "    epoch          : 438\n",
      "    loss           : -1799.8373873728626\n",
      "    ess            : 8.001182952017155\n",
      "    log_marginal   : 1799.8373873728626\n",
      "    val_loss       : -1802.226318359375\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1802.226298014323\n",
      "Train Epoch: 439 [0/54000 (0%)] Loss: -1812.344482\n",
      "Train Epoch: 439 [11264/54000 (21%)] Loss: -1806.073730\n",
      "Train Epoch: 439 [22528/54000 (42%)] Loss: -1790.644653\n",
      "Train Epoch: 439 [33792/54000 (63%)] Loss: -1792.557617\n",
      "Train Epoch: 439 [45056/54000 (83%)] Loss: -1777.628418\n",
      "    epoch          : 439\n",
      "    loss           : -1789.2176456091538\n",
      "    ess            : 8.0011836537775\n",
      "    log_marginal   : 1789.2176456091538\n",
      "    val_loss       : -1788.6295674641926\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1788.6295674641926\n",
      "Train Epoch: 440 [0/54000 (0%)] Loss: -1798.910889\n",
      "Train Epoch: 440 [11264/54000 (21%)] Loss: -1793.400879\n",
      "Train Epoch: 440 [22528/54000 (42%)] Loss: -1792.788330\n",
      "Train Epoch: 440 [33792/54000 (63%)] Loss: -1816.504272\n",
      "Train Epoch: 440 [45056/54000 (83%)] Loss: -1790.010986\n",
      "    epoch          : 440\n",
      "    loss           : -1793.1230077203716\n",
      "    ess            : 8.001183023992574\n",
      "    log_marginal   : 1793.1230077203716\n",
      "    val_loss       : -1787.8595377604167\n",
      "    val_ess        : 8.00118358929952\n",
      "    val_log_marginal: 1787.8595377604167\n",
      "Train Epoch: 441 [0/54000 (0%)] Loss: -1798.403809\n",
      "Train Epoch: 441 [11264/54000 (21%)] Loss: -1800.730713\n",
      "Train Epoch: 441 [22528/54000 (42%)] Loss: -1796.114502\n",
      "Train Epoch: 441 [33792/54000 (63%)] Loss: -1816.194336\n",
      "Train Epoch: 441 [45056/54000 (83%)] Loss: -1788.970947\n",
      "    epoch          : 441\n",
      "    loss           : -1796.292745338296\n",
      "    ess            : 8.001182727093967\n",
      "    log_marginal   : 1796.292745338296\n",
      "    val_loss       : -1799.8546346028645\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1799.8546346028645\n",
      "Train Epoch: 442 [0/54000 (0%)] Loss: -1812.119873\n",
      "Train Epoch: 442 [11264/54000 (21%)] Loss: -1813.868164\n",
      "Train Epoch: 442 [22528/54000 (42%)] Loss: -1801.296631\n",
      "Train Epoch: 442 [33792/54000 (63%)] Loss: -1822.124512\n",
      "Train Epoch: 442 [45056/54000 (83%)] Loss: -1787.245117\n",
      "    epoch          : 442\n",
      "    loss           : -1802.5900003685142\n",
      "    ess            : 8.001181764422723\n",
      "    log_marginal   : 1802.5900003685142\n",
      "    val_loss       : -1801.6624348958333\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1801.6624348958333\n",
      "Train Epoch: 443 [0/54000 (0%)] Loss: -1810.525391\n",
      "Train Epoch: 443 [11264/54000 (21%)] Loss: -1804.019653\n",
      "Train Epoch: 443 [22528/54000 (42%)] Loss: -1768.299561\n",
      "Train Epoch: 443 [33792/54000 (63%)] Loss: -1790.181274\n",
      "Train Epoch: 443 [45056/54000 (83%)] Loss: -1781.217041\n",
      "    epoch          : 443\n",
      "    loss           : -1784.1679169276974\n",
      "    ess            : 8.001183635783645\n",
      "    log_marginal   : 1784.1679169276974\n",
      "    val_loss       : -1787.2772013346355\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1787.2772013346355\n",
      "Train Epoch: 444 [0/54000 (0%)] Loss: -1799.318604\n",
      "Train Epoch: 444 [11264/54000 (21%)] Loss: -1797.223145\n",
      "Train Epoch: 444 [22528/54000 (42%)] Loss: -1782.281860\n",
      "Train Epoch: 444 [33792/54000 (63%)] Loss: -1812.148071\n",
      "Train Epoch: 444 [45056/54000 (83%)] Loss: -1790.676758\n",
      "    epoch          : 444\n",
      "    loss           : -1791.2538221827094\n",
      "    ess            : 8.001182862047878\n",
      "    log_marginal   : 1791.2538221827094\n",
      "    val_loss       : -1785.2166849772136\n",
      "    val_ess        : 8.0011834303538\n",
      "    val_log_marginal: 1785.2166849772136\n",
      "Train Epoch: 445 [0/54000 (0%)] Loss: -1797.990723\n",
      "Train Epoch: 445 [11264/54000 (21%)] Loss: -1806.066895\n",
      "Train Epoch: 445 [22528/54000 (42%)] Loss: -1792.164795\n",
      "Train Epoch: 445 [33792/54000 (63%)] Loss: -1810.624512\n",
      "Train Epoch: 445 [45056/54000 (83%)] Loss: -1783.859619\n",
      "    epoch          : 445\n",
      "    loss           : -1792.572000755454\n",
      "    ess            : 8.001182628127763\n",
      "    log_marginal   : 1792.572000755454\n",
      "    val_loss       : -1792.357157389323\n",
      "    val_ess        : 8.001184622446695\n",
      "    val_log_marginal: 1792.357157389323\n",
      "Train Epoch: 446 [0/54000 (0%)] Loss: -1802.443970\n",
      "Train Epoch: 446 [11264/54000 (21%)] Loss: -1812.743896\n",
      "Train Epoch: 446 [22528/54000 (42%)] Loss: -1795.281250\n",
      "Train Epoch: 446 [33792/54000 (63%)] Loss: -1801.494629\n",
      "Train Epoch: 446 [45056/54000 (83%)] Loss: -1775.978271\n",
      "    epoch          : 446\n",
      "    loss           : -1791.2539154628537\n",
      "    ess            : 8.001183095967994\n",
      "    log_marginal   : 1791.2539154628537\n",
      "    val_loss       : -1788.1140238444011\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1788.1140441894531\n",
      "Train Epoch: 447 [0/54000 (0%)] Loss: -1800.428223\n",
      "Train Epoch: 447 [11264/54000 (21%)] Loss: -1801.644775\n",
      "Train Epoch: 447 [22528/54000 (42%)] Loss: -1791.247681\n",
      "Train Epoch: 447 [33792/54000 (63%)] Loss: -1813.788574\n",
      "Train Epoch: 447 [45056/54000 (83%)] Loss: -1776.500854\n",
      "    epoch          : 447\n",
      "    loss           : -1790.2583445423054\n",
      "    ess            : 8.001183023992574\n",
      "    log_marginal   : 1790.2583445423054\n",
      "    val_loss       : -1785.4220377604167\n",
      "    val_ess        : 8.001184542973837\n",
      "    val_log_marginal: 1785.4220479329426\n",
      "Train Epoch: 448 [0/54000 (0%)] Loss: -1794.829224\n",
      "Train Epoch: 448 [11264/54000 (21%)] Loss: -1806.102295\n",
      "Train Epoch: 448 [22528/54000 (42%)] Loss: -1781.407471\n",
      "Train Epoch: 448 [33792/54000 (63%)] Loss: -1807.824585\n",
      "Train Epoch: 448 [45056/54000 (83%)] Loss: -1782.743652\n",
      "    epoch          : 448\n",
      "    loss           : -1789.9599724535672\n",
      "    ess            : 8.001183212928051\n",
      "    log_marginal   : 1789.9599724535672\n",
      "    val_loss       : -1791.3021341959636\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1791.3021341959636\n",
      "Train Epoch: 449 [0/54000 (0%)] Loss: -1803.193359\n",
      "Train Epoch: 449 [11264/54000 (21%)] Loss: -1811.670654\n",
      "Train Epoch: 449 [22528/54000 (42%)] Loss: -1791.623535\n",
      "Train Epoch: 449 [33792/54000 (63%)] Loss: -1812.164185\n",
      "Train Epoch: 449 [45056/54000 (83%)] Loss: -1792.702881\n",
      "    epoch          : 449\n",
      "    loss           : -1796.902458910672\n",
      "    ess            : 8.001183239918834\n",
      "    log_marginal   : 1796.902458910672\n",
      "    val_loss       : -1801.878397623698\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1801.87841796875\n",
      "Train Epoch: 450 [0/54000 (0%)] Loss: -1813.278076\n",
      "Train Epoch: 450 [11264/54000 (21%)] Loss: -1811.836548\n",
      "Train Epoch: 450 [22528/54000 (42%)] Loss: -1796.348267\n",
      "Train Epoch: 450 [33792/54000 (63%)] Loss: -1813.298828\n",
      "Train Epoch: 450 [45056/54000 (83%)] Loss: -1793.412354\n",
      "    epoch          : 450\n",
      "    loss           : -1797.7598796340656\n",
      "    ess            : 8.001182259253735\n",
      "    log_marginal   : 1797.7598796340656\n",
      "    val_loss       : -1797.8570963541667\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1797.8571166992188\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch450.pth ...\n",
      "Train Epoch: 451 [0/54000 (0%)] Loss: -1810.507568\n",
      "Train Epoch: 451 [11264/54000 (21%)] Loss: -1796.549316\n",
      "Train Epoch: 451 [22528/54000 (42%)] Loss: -1782.846313\n",
      "Train Epoch: 451 [33792/54000 (63%)] Loss: -1790.939819\n",
      "Train Epoch: 451 [45056/54000 (83%)] Loss: -1780.065552\n",
      "    epoch          : 451\n",
      "    loss           : -1784.4026316516804\n",
      "    ess            : 8.001183905691471\n",
      "    log_marginal   : 1784.4026316516804\n",
      "    val_loss       : -1771.0671081542969\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1771.0671081542969\n",
      "Train Epoch: 452 [0/54000 (0%)] Loss: -1785.298950\n",
      "Train Epoch: 452 [11264/54000 (21%)] Loss: -1798.972656\n",
      "Train Epoch: 452 [22528/54000 (42%)] Loss: -1753.480591\n",
      "Train Epoch: 452 [33792/54000 (63%)] Loss: -1781.485718\n",
      "Train Epoch: 452 [45056/54000 (83%)] Loss: -1765.897705\n",
      "    epoch          : 452\n",
      "    loss           : -1768.4686267780808\n",
      "    ess            : 8.001184616448745\n",
      "    log_marginal   : 1768.4686267780808\n",
      "    val_loss       : -1787.9856363932292\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1787.985616048177\n",
      "Train Epoch: 453 [0/54000 (0%)] Loss: -1798.711548\n",
      "Train Epoch: 453 [11264/54000 (21%)] Loss: -1799.156494\n",
      "Train Epoch: 453 [22528/54000 (42%)] Loss: -1783.229980\n",
      "Train Epoch: 453 [33792/54000 (63%)] Loss: -1801.676025\n",
      "Train Epoch: 453 [45056/54000 (83%)] Loss: -1784.819580\n",
      "    epoch          : 453\n",
      "    loss           : -1786.011503399543\n",
      "    ess            : 8.001184985322773\n",
      "    log_marginal   : 1786.0115022479363\n",
      "    val_loss       : -1797.2309163411458\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1797.2309163411458\n",
      "Train Epoch: 454 [0/54000 (0%)] Loss: -1808.246826\n",
      "Train Epoch: 454 [11264/54000 (21%)] Loss: -1806.021118\n",
      "Train Epoch: 454 [22528/54000 (42%)] Loss: -1793.143555\n",
      "Train Epoch: 454 [33792/54000 (63%)] Loss: -1809.336060\n",
      "Train Epoch: 454 [45056/54000 (83%)] Loss: -1789.645386\n",
      "    epoch          : 454\n",
      "    loss           : -1794.1710262658462\n",
      "    ess            : 8.001183995660746\n",
      "    log_marginal   : 1794.1710251142395\n",
      "    val_loss       : -1798.5044657389324\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1798.5044657389324\n",
      "Train Epoch: 455 [0/54000 (0%)] Loss: -1808.252930\n",
      "Train Epoch: 455 [11264/54000 (21%)] Loss: -1808.480591\n",
      "Train Epoch: 455 [22528/54000 (42%)] Loss: -1788.563232\n",
      "Train Epoch: 455 [33792/54000 (63%)] Loss: -1810.175293\n",
      "Train Epoch: 455 [45056/54000 (83%)] Loss: -1788.933594\n",
      "    epoch          : 455\n",
      "    loss           : -1796.2050193930572\n",
      "    ess            : 8.001184499488687\n",
      "    log_marginal   : 1796.2050193930572\n",
      "    val_loss       : -1799.2540283203125\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1799.2540283203125\n",
      "Train Epoch: 456 [0/54000 (0%)] Loss: -1806.895264\n",
      "Train Epoch: 456 [11264/54000 (21%)] Loss: -1808.843628\n",
      "Train Epoch: 456 [22528/54000 (42%)] Loss: -1784.291016\n",
      "Train Epoch: 456 [33792/54000 (63%)] Loss: -1807.124023\n",
      "Train Epoch: 456 [45056/54000 (83%)] Loss: -1789.737183\n",
      "    epoch          : 456\n",
      "    loss           : -1792.0034824587265\n",
      "    ess            : 8.001184238577789\n",
      "    log_marginal   : 1792.0034824587265\n",
      "    val_loss       : -1796.1947123209636\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1796.1947123209636\n",
      "Train Epoch: 457 [0/54000 (0%)] Loss: -1806.143311\n",
      "Train Epoch: 457 [11264/54000 (21%)] Loss: -1809.391968\n",
      "Train Epoch: 457 [22528/54000 (42%)] Loss: -1792.531372\n",
      "Train Epoch: 457 [33792/54000 (63%)] Loss: -1811.361816\n",
      "Train Epoch: 457 [45056/54000 (83%)] Loss: -1781.074463\n",
      "    epoch          : 457\n",
      "    loss           : -1792.3463963922466\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1792.3463963922466\n",
      "    val_loss       : -1789.5523173014324\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1789.5523173014324\n",
      "Train Epoch: 458 [0/54000 (0%)] Loss: -1798.761719\n",
      "Train Epoch: 458 [11264/54000 (21%)] Loss: -1808.538818\n",
      "Train Epoch: 458 [22528/54000 (42%)] Loss: -1778.316650\n",
      "Train Epoch: 458 [33792/54000 (63%)] Loss: -1800.221191\n",
      "Train Epoch: 458 [45056/54000 (83%)] Loss: -1792.293335\n",
      "    epoch          : 458\n",
      "    loss           : -1789.6488405623527\n",
      "    ess            : 8.001184157605442\n",
      "    log_marginal   : 1789.6488405623527\n",
      "    val_loss       : -1796.1450500488281\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1796.1450500488281\n",
      "Train Epoch: 459 [0/54000 (0%)] Loss: -1804.917847\n",
      "Train Epoch: 459 [11264/54000 (21%)] Loss: -1806.952637\n",
      "Train Epoch: 459 [22528/54000 (42%)] Loss: -1777.305664\n",
      "Train Epoch: 459 [33792/54000 (63%)] Loss: -1801.137085\n",
      "Train Epoch: 459 [45056/54000 (83%)] Loss: -1786.141724\n",
      "    epoch          : 459\n",
      "    loss           : -1788.9472310767983\n",
      "    ess            : 8.001184877359643\n",
      "    log_marginal   : 1788.9472310767983\n",
      "    val_loss       : -1801.2087809244792\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1801.2087809244792\n",
      "Train Epoch: 460 [0/54000 (0%)] Loss: -1810.587891\n",
      "Train Epoch: 460 [11264/54000 (21%)] Loss: -1809.135498\n",
      "Train Epoch: 460 [22528/54000 (42%)] Loss: -1790.056030\n",
      "Train Epoch: 460 [33792/54000 (63%)] Loss: -1812.486816\n",
      "Train Epoch: 460 [45056/54000 (83%)] Loss: -1787.947754\n",
      "    epoch          : 460\n",
      "    loss           : -1795.2304238373379\n",
      "    ess            : 8.001184067636165\n",
      "    log_marginal   : 1795.2304226857311\n",
      "    val_loss       : -1801.8419799804688\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1801.8419799804688\n",
      "Train Epoch: 461 [0/54000 (0%)] Loss: -1810.018311\n",
      "Train Epoch: 461 [11264/54000 (21%)] Loss: -1807.473633\n",
      "Train Epoch: 461 [22528/54000 (42%)] Loss: -1795.563721\n",
      "Train Epoch: 461 [33792/54000 (63%)] Loss: -1815.158569\n",
      "Train Epoch: 461 [45056/54000 (83%)] Loss: -1790.937866\n",
      "    epoch          : 461\n",
      "    loss           : -1797.4022343473614\n",
      "    ess            : 8.001184373531702\n",
      "    log_marginal   : 1797.4022343473614\n",
      "    val_loss       : -1800.1182657877605\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1800.1182657877605\n",
      "Train Epoch: 462 [0/54000 (0%)] Loss: -1810.327637\n",
      "Train Epoch: 462 [11264/54000 (21%)] Loss: -1803.468994\n",
      "Train Epoch: 462 [22528/54000 (42%)] Loss: -1800.136230\n",
      "Train Epoch: 462 [33792/54000 (63%)] Loss: -1804.084839\n",
      "Train Epoch: 462 [45056/54000 (83%)] Loss: -1784.463745\n",
      "    epoch          : 462\n",
      "    loss           : -1794.5950213738208\n",
      "    ess            : 8.001184517482542\n",
      "    log_marginal   : 1794.5950225254276\n",
      "    val_loss       : -1794.3169555664062\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1794.3169555664062\n",
      "Train Epoch: 463 [0/54000 (0%)] Loss: -1802.857056\n",
      "Train Epoch: 463 [11264/54000 (21%)] Loss: -1801.668457\n",
      "Train Epoch: 463 [22528/54000 (42%)] Loss: -1789.475342\n",
      "Train Epoch: 463 [33792/54000 (63%)] Loss: -1810.650879\n",
      "Train Epoch: 463 [45056/54000 (83%)] Loss: -1794.925049\n",
      "    epoch          : 463\n",
      "    loss           : -1794.8303372365124\n",
      "    ess            : 8.001184526479468\n",
      "    log_marginal   : 1794.8303383881191\n",
      "    val_loss       : -1806.6080423990886\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1806.6080423990886\n",
      "Train Epoch: 464 [0/54000 (0%)] Loss: -1816.719360\n",
      "Train Epoch: 464 [11264/54000 (21%)] Loss: -1809.819824\n",
      "Train Epoch: 464 [22528/54000 (42%)] Loss: -1793.777100\n",
      "Train Epoch: 464 [33792/54000 (63%)] Loss: -1796.194458\n",
      "Train Epoch: 464 [45056/54000 (83%)] Loss: -1793.919189\n",
      "    epoch          : 464\n",
      "    loss           : -1796.4472149543042\n",
      "    ess            : 8.001183347881964\n",
      "    log_marginal   : 1796.4472149543042\n",
      "    val_loss       : -1805.8085530598958\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1805.8085327148438\n",
      "Train Epoch: 465 [0/54000 (0%)] Loss: -1817.588867\n",
      "Train Epoch: 465 [11264/54000 (21%)] Loss: -1812.719360\n",
      "Train Epoch: 465 [22528/54000 (42%)] Loss: -1797.174805\n",
      "Train Epoch: 465 [33792/54000 (63%)] Loss: -1812.331543\n",
      "Train Epoch: 465 [45056/54000 (83%)] Loss: -1793.597656\n",
      "    epoch          : 465\n",
      "    loss           : -1798.9275627855984\n",
      "    ess            : 8.00118307797414\n",
      "    log_marginal   : 1798.9275639372052\n",
      "    val_loss       : -1786.3583882649739\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1786.3583882649739\n",
      "Train Epoch: 466 [0/54000 (0%)] Loss: -1799.616455\n",
      "Train Epoch: 466 [11264/54000 (21%)] Loss: -1810.737549\n",
      "Train Epoch: 466 [22528/54000 (42%)] Loss: -1791.676025\n",
      "Train Epoch: 466 [33792/54000 (63%)] Loss: -1809.510742\n",
      "Train Epoch: 466 [45056/54000 (83%)] Loss: -1797.339111\n",
      "    epoch          : 466\n",
      "    loss           : -1797.5675866468898\n",
      "    ess            : 8.001184445507121\n",
      "    log_marginal   : 1797.5675877984966\n",
      "    val_loss       : -1806.7076416015625\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1806.7076416015625\n",
      "Train Epoch: 467 [0/54000 (0%)] Loss: -1818.459961\n",
      "Train Epoch: 467 [11264/54000 (21%)] Loss: -1819.838135\n",
      "Train Epoch: 467 [22528/54000 (42%)] Loss: -1797.458496\n",
      "Train Epoch: 467 [33792/54000 (63%)] Loss: -1806.362793\n",
      "Train Epoch: 467 [45056/54000 (83%)] Loss: -1790.655029\n",
      "    epoch          : 467\n",
      "    loss           : -1798.848321878685\n",
      "    ess            : 8.001183635783645\n",
      "    log_marginal   : 1798.848321878685\n",
      "    val_loss       : -1789.758524576823\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1789.758524576823\n",
      "Train Epoch: 468 [0/54000 (0%)] Loss: -1804.906250\n",
      "Train Epoch: 468 [11264/54000 (21%)] Loss: -1789.230469\n",
      "Train Epoch: 468 [22528/54000 (42%)] Loss: -1765.949219\n",
      "Train Epoch: 468 [33792/54000 (63%)] Loss: -1791.666260\n",
      "Train Epoch: 468 [45056/54000 (83%)] Loss: -1775.357056\n",
      "    epoch          : 468\n",
      "    loss           : -1776.9375322449882\n",
      "    ess            : 8.001185489150712\n",
      "    log_marginal   : 1776.9375322449882\n",
      "    val_loss       : -1783.9946390787761\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1783.9946390787761\n",
      "Train Epoch: 469 [0/54000 (0%)] Loss: -1795.048706\n",
      "Train Epoch: 469 [11264/54000 (21%)] Loss: -1798.571777\n",
      "Train Epoch: 469 [22528/54000 (42%)] Loss: -1778.445801\n",
      "Train Epoch: 469 [33792/54000 (63%)] Loss: -1796.821899\n",
      "Train Epoch: 469 [45056/54000 (83%)] Loss: -1778.343140\n",
      "    epoch          : 469\n",
      "    loss           : -1785.5256485849056\n",
      "    ess            : 8.001184985322773\n",
      "    log_marginal   : 1785.5256485849056\n",
      "    val_loss       : -1793.6738993326824\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1793.6739095052083\n",
      "Train Epoch: 470 [0/54000 (0%)] Loss: -1807.418945\n",
      "Train Epoch: 470 [11264/54000 (21%)] Loss: -1807.647827\n",
      "Train Epoch: 470 [22528/54000 (42%)] Loss: -1793.214111\n",
      "Train Epoch: 470 [33792/54000 (63%)] Loss: -1807.189209\n",
      "Train Epoch: 470 [45056/54000 (83%)] Loss: -1787.557739\n",
      "    epoch          : 470\n",
      "    loss           : -1794.2305378464032\n",
      "    ess            : 8.001184913347352\n",
      "    log_marginal   : 1794.2305378464032\n",
      "    val_loss       : -1800.6192016601562\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1800.6192220052083\n",
      "Train Epoch: 471 [0/54000 (0%)] Loss: -1812.205322\n",
      "Train Epoch: 471 [11264/54000 (21%)] Loss: -1809.886719\n",
      "Train Epoch: 471 [22528/54000 (42%)] Loss: -1793.796875\n",
      "Train Epoch: 471 [33792/54000 (63%)] Loss: -1804.989502\n",
      "Train Epoch: 471 [45056/54000 (83%)] Loss: -1789.569824\n",
      "    epoch          : 471\n",
      "    loss           : -1795.6692988557636\n",
      "    ess            : 8.001184859365788\n",
      "    log_marginal   : 1795.6692988557636\n",
      "    val_loss       : -1804.3201497395833\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1804.3201395670574\n",
      "Train Epoch: 472 [0/54000 (0%)] Loss: -1814.711670\n",
      "Train Epoch: 472 [11264/54000 (21%)] Loss: -1812.181641\n",
      "Train Epoch: 472 [22528/54000 (42%)] Loss: -1797.776855\n",
      "Train Epoch: 472 [33792/54000 (63%)] Loss: -1814.273926\n",
      "Train Epoch: 472 [45056/54000 (83%)] Loss: -1794.312744\n",
      "    epoch          : 472\n",
      "    loss           : -1800.0554233766952\n",
      "    ess            : 8.001184103623876\n",
      "    log_marginal   : 1800.0554233766952\n",
      "    val_loss       : -1801.0561828613281\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1801.0561828613281\n",
      "Train Epoch: 473 [0/54000 (0%)] Loss: -1814.226562\n",
      "Train Epoch: 473 [11264/54000 (21%)] Loss: -1811.626465\n",
      "Train Epoch: 473 [22528/54000 (42%)] Loss: -1793.897583\n",
      "Train Epoch: 473 [33792/54000 (63%)] Loss: -1813.607422\n",
      "Train Epoch: 473 [45056/54000 (83%)] Loss: -1790.901123\n",
      "    epoch          : 473\n",
      "    loss           : -1797.8728925596993\n",
      "    ess            : 8.001184931341207\n",
      "    log_marginal   : 1797.872893711306\n",
      "    val_loss       : -1796.1228942871094\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1796.1228942871094\n",
      "Train Epoch: 474 [0/54000 (0%)] Loss: -1807.393799\n",
      "Train Epoch: 474 [11264/54000 (21%)] Loss: -1808.989380\n",
      "Train Epoch: 474 [22528/54000 (42%)] Loss: -1795.623535\n",
      "Train Epoch: 474 [33792/54000 (63%)] Loss: -1815.349243\n",
      "Train Epoch: 474 [45056/54000 (83%)] Loss: -1793.619385\n",
      "    epoch          : 474\n",
      "    loss           : -1798.1746883752212\n",
      "    ess            : 8.001184679427237\n",
      "    log_marginal   : 1798.1746883752212\n",
      "    val_loss       : -1801.3134155273438\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1801.3134155273438\n",
      "Train Epoch: 475 [0/54000 (0%)] Loss: -1811.425659\n",
      "Train Epoch: 475 [11264/54000 (21%)] Loss: -1812.956055\n",
      "Train Epoch: 475 [22528/54000 (42%)] Loss: -1795.200195\n",
      "Train Epoch: 475 [33792/54000 (63%)] Loss: -1813.938965\n",
      "Train Epoch: 475 [45056/54000 (83%)] Loss: -1796.251465\n",
      "    epoch          : 475\n",
      "    loss           : -1799.0707662330483\n",
      "    ess            : 8.001183563808226\n",
      "    log_marginal   : 1799.0707650814416\n",
      "    val_loss       : -1803.5734252929688\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1803.5734252929688\n",
      "Train Epoch: 476 [0/54000 (0%)] Loss: -1816.419922\n",
      "Train Epoch: 476 [11264/54000 (21%)] Loss: -1815.735596\n",
      "Train Epoch: 476 [22528/54000 (42%)] Loss: -1797.725952\n",
      "Train Epoch: 476 [33792/54000 (63%)] Loss: -1821.424805\n",
      "Train Epoch: 476 [45056/54000 (83%)] Loss: -1788.988525\n",
      "    epoch          : 476\n",
      "    loss           : -1801.3940867298054\n",
      "    ess            : 8.001183518823588\n",
      "    log_marginal   : 1801.3940878814121\n",
      "    val_loss       : -1798.6212056477864\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1798.6212056477864\n",
      "Train Epoch: 477 [0/54000 (0%)] Loss: -1811.657471\n",
      "Train Epoch: 477 [11264/54000 (21%)] Loss: -1805.701904\n",
      "Train Epoch: 477 [22528/54000 (42%)] Loss: -1785.627563\n",
      "Train Epoch: 477 [33792/54000 (63%)] Loss: -1801.696533\n",
      "Train Epoch: 477 [45056/54000 (83%)] Loss: -1788.966309\n",
      "    epoch          : 477\n",
      "    loss           : -1792.4665746149028\n",
      "    ess            : 8.0011846344426\n",
      "    log_marginal   : 1792.4665746149028\n",
      "    val_loss       : -1804.1102600097656\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1804.1102701822917\n",
      "Train Epoch: 478 [0/54000 (0%)] Loss: -1815.374512\n",
      "Train Epoch: 478 [11264/54000 (21%)] Loss: -1811.343506\n",
      "Train Epoch: 478 [22528/54000 (42%)] Loss: -1792.829346\n",
      "Train Epoch: 478 [33792/54000 (63%)] Loss: -1809.960449\n",
      "Train Epoch: 478 [45056/54000 (83%)] Loss: -1793.443604\n",
      "    epoch          : 478\n",
      "    loss           : -1796.5296331441627\n",
      "    ess            : 8.001183995660746\n",
      "    log_marginal   : 1796.5296331441627\n",
      "    val_loss       : -1801.4527893066406\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1801.4527689615886\n",
      "Train Epoch: 479 [0/54000 (0%)] Loss: -1811.446533\n",
      "Train Epoch: 479 [11264/54000 (21%)] Loss: -1810.909180\n",
      "Train Epoch: 479 [22528/54000 (42%)] Loss: -1798.538330\n",
      "Train Epoch: 479 [33792/54000 (63%)] Loss: -1815.056641\n",
      "Train Epoch: 479 [45056/54000 (83%)] Loss: -1792.705078\n",
      "    epoch          : 479\n",
      "    loss           : -1799.5098830888855\n",
      "    ess            : 8.001184202590078\n",
      "    log_marginal   : 1799.5098830888855\n",
      "    val_loss       : -1803.9761250813801\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1803.9761250813801\n",
      "Train Epoch: 480 [0/54000 (0%)] Loss: -1816.610352\n",
      "Train Epoch: 480 [11264/54000 (21%)] Loss: -1809.422852\n",
      "Train Epoch: 480 [22528/54000 (42%)] Loss: -1791.145020\n",
      "Train Epoch: 480 [33792/54000 (63%)] Loss: -1805.936279\n",
      "Train Epoch: 480 [45056/54000 (83%)] Loss: -1789.601074\n",
      "    epoch          : 480\n",
      "    loss           : -1795.5870119490714\n",
      "    ess            : 8.001183626786718\n",
      "    log_marginal   : 1795.5870119490714\n",
      "    val_loss       : -1794.7411193847656\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1794.7411193847656\n",
      "Train Epoch: 481 [0/54000 (0%)] Loss: -1808.407227\n",
      "Train Epoch: 481 [11264/54000 (21%)] Loss: -1805.318237\n",
      "Train Epoch: 481 [22528/54000 (42%)] Loss: -1789.823486\n",
      "Train Epoch: 481 [33792/54000 (63%)] Loss: -1817.203125\n",
      "Train Epoch: 481 [45056/54000 (83%)] Loss: -1787.438232\n",
      "    epoch          : 481\n",
      "    loss           : -1795.4653827019458\n",
      "    ess            : 8.00118394167918\n",
      "    log_marginal   : 1795.465381550339\n",
      "    val_loss       : -1793.2638651529949\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1793.2638651529949\n",
      "Train Epoch: 482 [0/54000 (0%)] Loss: -1806.264648\n",
      "Train Epoch: 482 [11264/54000 (21%)] Loss: -1812.091309\n",
      "Train Epoch: 482 [22528/54000 (42%)] Loss: -1796.692627\n",
      "Train Epoch: 482 [33792/54000 (63%)] Loss: -1815.176514\n",
      "Train Epoch: 482 [45056/54000 (83%)] Loss: -1795.803955\n",
      "    epoch          : 482\n",
      "    loss           : -1798.94293788694\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1798.94293788694\n",
      "    val_loss       : -1801.8150939941406\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1801.8150939941406\n",
      "Train Epoch: 483 [0/54000 (0%)] Loss: -1811.127197\n",
      "Train Epoch: 483 [11264/54000 (21%)] Loss: -1817.982544\n",
      "Train Epoch: 483 [22528/54000 (42%)] Loss: -1801.660278\n",
      "Train Epoch: 483 [33792/54000 (63%)] Loss: -1821.963135\n",
      "Train Epoch: 483 [45056/54000 (83%)] Loss: -1796.454224\n",
      "    epoch          : 483\n",
      "    loss           : -1803.5948705133403\n",
      "    ess            : 8.00118372575292\n",
      "    log_marginal   : 1803.5948705133403\n",
      "    val_loss       : -1802.0962015787761\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1802.0962015787761\n",
      "Train Epoch: 484 [0/54000 (0%)] Loss: -1810.665283\n",
      "Train Epoch: 484 [11264/54000 (21%)] Loss: -1814.179443\n",
      "Train Epoch: 484 [22528/54000 (42%)] Loss: -1795.335938\n",
      "Train Epoch: 484 [33792/54000 (63%)] Loss: -1777.565063\n",
      "Train Epoch: 484 [45056/54000 (83%)] Loss: -1754.423340\n",
      "    epoch          : 484\n",
      "    loss           : -1785.5867839309406\n",
      "    ess            : 8.00118430155628\n",
      "    log_marginal   : 1785.586785082547\n",
      "    val_loss       : -1788.6644388834636\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1788.6644185384114\n",
      "Train Epoch: 485 [0/54000 (0%)] Loss: -1800.590942\n",
      "Train Epoch: 485 [11264/54000 (21%)] Loss: -1802.074341\n",
      "Train Epoch: 485 [22528/54000 (42%)] Loss: -1789.314209\n",
      "Train Epoch: 485 [33792/54000 (63%)] Loss: -1801.817139\n",
      "Train Epoch: 485 [45056/54000 (83%)] Loss: -1786.806274\n",
      "    epoch          : 485\n",
      "    loss           : -1791.1507821712853\n",
      "    ess            : 8.001184229580861\n",
      "    log_marginal   : 1791.150783322892\n",
      "    val_loss       : -1803.7662150065105\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1803.7662150065105\n",
      "Train Epoch: 486 [0/54000 (0%)] Loss: -1816.384521\n",
      "Train Epoch: 486 [11264/54000 (21%)] Loss: -1812.674683\n",
      "Train Epoch: 486 [22528/54000 (42%)] Loss: -1797.898315\n",
      "Train Epoch: 486 [33792/54000 (63%)] Loss: -1814.637207\n",
      "Train Epoch: 486 [45056/54000 (83%)] Loss: -1795.297119\n",
      "    epoch          : 486\n",
      "    loss           : -1800.3435507720371\n",
      "    ess            : 8.0011823132353\n",
      "    log_marginal   : 1800.3435507720371\n",
      "    val_loss       : -1801.9554036458333\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1801.9553934733074\n",
      "Train Epoch: 487 [0/54000 (0%)] Loss: -1814.452881\n",
      "Train Epoch: 487 [11264/54000 (21%)] Loss: -1810.102661\n",
      "Train Epoch: 487 [22528/54000 (42%)] Loss: -1793.035645\n",
      "Train Epoch: 487 [33792/54000 (63%)] Loss: -1808.052002\n",
      "Train Epoch: 487 [45056/54000 (83%)] Loss: -1791.232422\n",
      "    epoch          : 487\n",
      "    loss           : -1795.4276998267983\n",
      "    ess            : 8.001182835057097\n",
      "    log_marginal   : 1795.4276998267983\n",
      "    val_loss       : -1799.4750467936199\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1799.4750467936199\n",
      "Train Epoch: 488 [0/54000 (0%)] Loss: -1812.679443\n",
      "Train Epoch: 488 [11264/54000 (21%)] Loss: -1814.378418\n",
      "Train Epoch: 488 [22528/54000 (42%)] Loss: -1801.951050\n",
      "Train Epoch: 488 [33792/54000 (63%)] Loss: -1812.993164\n",
      "Train Epoch: 488 [45056/54000 (83%)] Loss: -1791.826172\n",
      "    epoch          : 488\n",
      "    loss           : -1798.5692702959168\n",
      "    ess            : 8.00118261013391\n",
      "    log_marginal   : 1798.56926914431\n",
      "    val_loss       : -1797.2742716471355\n",
      "    val_ess        : 8.001182953516642\n",
      "    val_log_marginal: 1797.2742716471355\n",
      "Train Epoch: 489 [0/54000 (0%)] Loss: -1805.595459\n",
      "Train Epoch: 489 [11264/54000 (21%)] Loss: -1807.041992\n",
      "Train Epoch: 489 [22528/54000 (42%)] Loss: -1795.941895\n",
      "Train Epoch: 489 [33792/54000 (63%)] Loss: -1810.739624\n",
      "Train Epoch: 489 [45056/54000 (83%)] Loss: -1791.875000\n",
      "    epoch          : 489\n",
      "    loss           : -1796.888207777491\n",
      "    ess            : 8.001183023992574\n",
      "    log_marginal   : 1796.888207777491\n",
      "    val_loss       : -1797.8499145507812\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1797.8499145507812\n",
      "Train Epoch: 490 [0/54000 (0%)] Loss: -1811.327393\n",
      "Train Epoch: 490 [11264/54000 (21%)] Loss: -1815.476807\n",
      "Train Epoch: 490 [22528/54000 (42%)] Loss: -1807.177490\n",
      "Train Epoch: 490 [33792/54000 (63%)] Loss: -1820.272705\n",
      "Train Epoch: 490 [45056/54000 (83%)] Loss: -1797.127808\n",
      "    epoch          : 490\n",
      "    loss           : -1801.2458380933078\n",
      "    ess            : 8.00118206132133\n",
      "    log_marginal   : 1801.2458380933078\n",
      "    val_loss       : -1794.2798868815105\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1794.2798868815105\n",
      "Train Epoch: 491 [0/54000 (0%)] Loss: -1809.114258\n",
      "Train Epoch: 491 [11264/54000 (21%)] Loss: -1815.074707\n",
      "Train Epoch: 491 [22528/54000 (42%)] Loss: -1802.705688\n",
      "Train Epoch: 491 [33792/54000 (63%)] Loss: -1791.934814\n",
      "Train Epoch: 491 [45056/54000 (83%)] Loss: -1780.411621\n",
      "    epoch          : 491\n",
      "    loss           : -1791.794040895858\n",
      "    ess            : 8.001182835057097\n",
      "    log_marginal   : 1791.7940420474647\n",
      "    val_loss       : -1785.8465474446614\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1785.8465474446614\n",
      "Train Epoch: 492 [0/54000 (0%)] Loss: -1800.020264\n",
      "Train Epoch: 492 [11264/54000 (21%)] Loss: -1804.780518\n",
      "Train Epoch: 492 [22528/54000 (42%)] Loss: -1784.268555\n",
      "Train Epoch: 492 [33792/54000 (63%)] Loss: -1793.976685\n",
      "Train Epoch: 492 [45056/54000 (83%)] Loss: -1786.999878\n",
      "    epoch          : 492\n",
      "    loss           : -1789.106349729142\n",
      "    ess            : 8.00118325791269\n",
      "    log_marginal   : 1789.106349729142\n",
      "    val_loss       : -1797.2962646484375\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1797.2962646484375\n",
      "Train Epoch: 493 [0/54000 (0%)] Loss: -1808.789917\n",
      "Train Epoch: 493 [11264/54000 (21%)] Loss: -1810.988892\n",
      "Train Epoch: 493 [22528/54000 (42%)] Loss: -1790.634033\n",
      "Train Epoch: 493 [33792/54000 (63%)] Loss: -1804.037598\n",
      "Train Epoch: 493 [45056/54000 (83%)] Loss: -1794.824707\n",
      "    epoch          : 493\n",
      "    loss           : -1794.6446982329746\n",
      "    ess            : 8.001183527820515\n",
      "    log_marginal   : 1794.6446982329746\n",
      "    val_loss       : -1799.3022766113281\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1799.3022867838542\n",
      "Train Epoch: 494 [0/54000 (0%)] Loss: -1810.560547\n",
      "Train Epoch: 494 [11264/54000 (21%)] Loss: -1816.279907\n",
      "Train Epoch: 494 [22528/54000 (42%)] Loss: -1799.399414\n",
      "Train Epoch: 494 [33792/54000 (63%)] Loss: -1814.607544\n",
      "Train Epoch: 494 [45056/54000 (83%)] Loss: -1801.925537\n",
      "    epoch          : 494\n",
      "    loss           : -1800.7976580925708\n",
      "    ess            : 8.00118318593727\n",
      "    log_marginal   : 1800.7976580925708\n",
      "    val_loss       : -1801.8817443847656\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1801.8817443847656\n",
      "Train Epoch: 495 [0/54000 (0%)] Loss: -1812.676025\n",
      "Train Epoch: 495 [11264/54000 (21%)] Loss: -1806.055908\n",
      "Train Epoch: 495 [22528/54000 (42%)] Loss: -1793.400391\n",
      "Train Epoch: 495 [33792/54000 (63%)] Loss: -1810.299805\n",
      "Train Epoch: 495 [45056/54000 (83%)] Loss: -1787.108154\n",
      "    epoch          : 495\n",
      "    loss           : -1793.722453567217\n",
      "    ess            : 8.001183167943415\n",
      "    log_marginal   : 1793.722453567217\n",
      "    val_loss       : -1792.5369059244792\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1792.5369059244792\n",
      "Train Epoch: 496 [0/54000 (0%)] Loss: -1806.100830\n",
      "Train Epoch: 496 [11264/54000 (21%)] Loss: -1807.567993\n",
      "Train Epoch: 496 [22528/54000 (42%)] Loss: -1789.217163\n",
      "Train Epoch: 496 [33792/54000 (63%)] Loss: -1810.906006\n",
      "Train Epoch: 496 [45056/54000 (83%)] Loss: -1796.603882\n",
      "    epoch          : 496\n",
      "    loss           : -1797.3366054318985\n",
      "    ess            : 8.00118263712469\n",
      "    log_marginal   : 1797.3366054318985\n",
      "    val_loss       : -1805.7954915364583\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1805.7954915364583\n",
      "Train Epoch: 497 [0/54000 (0%)] Loss: -1817.301514\n",
      "Train Epoch: 497 [11264/54000 (21%)] Loss: -1812.918457\n",
      "Train Epoch: 497 [22528/54000 (42%)] Loss: -1788.586792\n",
      "Train Epoch: 497 [33792/54000 (63%)] Loss: -1813.347656\n",
      "Train Epoch: 497 [45056/54000 (83%)] Loss: -1794.330566\n",
      "    epoch          : 497\n",
      "    loss           : -1799.5605077203716\n",
      "    ess            : 8.001181548496461\n",
      "    log_marginal   : 1799.560508871978\n",
      "    val_loss       : -1802.3798726399739\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1802.3798726399739\n",
      "Train Epoch: 498 [0/54000 (0%)] Loss: -1813.929321\n",
      "Train Epoch: 498 [11264/54000 (21%)] Loss: -1811.109497\n",
      "Train Epoch: 498 [22528/54000 (42%)] Loss: -1791.770020\n",
      "Train Epoch: 498 [33792/54000 (63%)] Loss: -1777.675537\n",
      "Train Epoch: 498 [45056/54000 (83%)] Loss: -1776.087646\n",
      "    epoch          : 498\n",
      "    loss           : -1785.8035105579304\n",
      "    ess            : 8.001182808066314\n",
      "    log_marginal   : 1785.8035094063237\n",
      "    val_loss       : -1791.1676432291667\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1791.1676635742188\n",
      "Train Epoch: 499 [0/54000 (0%)] Loss: -1803.229126\n",
      "Train Epoch: 499 [11264/54000 (21%)] Loss: -1783.088135\n",
      "Train Epoch: 499 [22528/54000 (42%)] Loss: -1765.221313\n",
      "Train Epoch: 499 [33792/54000 (63%)] Loss: -1772.950684\n",
      "Train Epoch: 499 [45056/54000 (83%)] Loss: -1780.621338\n",
      "    epoch          : 499\n",
      "    loss           : -1776.153205151828\n",
      "    ess            : 8.001184769396511\n",
      "    log_marginal   : 1776.1532040002212\n",
      "    val_loss       : -1801.4243265787761\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1801.4243469238281\n",
      "Train Epoch: 500 [0/54000 (0%)] Loss: -1811.697144\n",
      "Train Epoch: 500 [11264/54000 (21%)] Loss: -1793.311768\n",
      "Train Epoch: 500 [22528/54000 (42%)] Loss: -1786.025391\n",
      "Train Epoch: 500 [33792/54000 (63%)] Loss: -1793.572998\n",
      "Train Epoch: 500 [45056/54000 (83%)] Loss: -1794.768555\n",
      "    epoch          : 500\n",
      "    loss           : -1788.8892142817658\n",
      "    ess            : 8.001183968669963\n",
      "    log_marginal   : 1788.8892142817658\n",
      "    val_loss       : -1805.1731974283855\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1805.1731974283855\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch500.pth ...\n",
      "Train Epoch: 501 [0/54000 (0%)] Loss: -1816.614746\n",
      "Train Epoch: 501 [11264/54000 (21%)] Loss: -1804.897705\n",
      "Train Epoch: 501 [22528/54000 (42%)] Loss: -1791.584595\n",
      "Train Epoch: 501 [33792/54000 (63%)] Loss: -1803.427002\n",
      "Train Epoch: 501 [45056/54000 (83%)] Loss: -1790.911011\n",
      "    epoch          : 501\n",
      "    loss           : -1792.9263754790684\n",
      "    ess            : 8.001183644780573\n",
      "    log_marginal   : 1792.9263754790684\n",
      "    val_loss       : -1791.8974100748699\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1791.8974202473958\n",
      "Train Epoch: 502 [0/54000 (0%)] Loss: -1801.349121\n",
      "Train Epoch: 502 [11264/54000 (21%)] Loss: -1796.395752\n",
      "Train Epoch: 502 [22528/54000 (42%)] Loss: -1797.039307\n",
      "Train Epoch: 502 [33792/54000 (63%)] Loss: -1816.755005\n",
      "Train Epoch: 502 [45056/54000 (83%)] Loss: -1785.984375\n",
      "    epoch          : 502\n",
      "    loss           : -1794.4798054245282\n",
      "    ess            : 8.001183311894255\n",
      "    log_marginal   : 1794.4798054245282\n",
      "    val_loss       : -1793.218282063802\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1793.218282063802\n",
      "Train Epoch: 503 [0/54000 (0%)] Loss: -1803.098999\n",
      "Train Epoch: 503 [11264/54000 (21%)] Loss: -1805.222534\n",
      "Train Epoch: 503 [22528/54000 (42%)] Loss: -1799.597168\n",
      "Train Epoch: 503 [33792/54000 (63%)] Loss: -1815.889893\n",
      "Train Epoch: 503 [45056/54000 (83%)] Loss: -1795.344849\n",
      "    epoch          : 503\n",
      "    loss           : -1798.71296087301\n",
      "    ess            : 8.001183428854313\n",
      "    log_marginal   : 1798.71296087301\n",
      "    val_loss       : -1804.3093363444011\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1804.3093363444011\n",
      "Train Epoch: 504 [0/54000 (0%)] Loss: -1815.616455\n",
      "Train Epoch: 504 [11264/54000 (21%)] Loss: -1815.732666\n",
      "Train Epoch: 504 [22528/54000 (42%)] Loss: -1792.887817\n",
      "Train Epoch: 504 [33792/54000 (63%)] Loss: -1802.006592\n",
      "Train Epoch: 504 [45056/54000 (83%)] Loss: -1782.632812\n",
      "    epoch          : 504\n",
      "    loss           : -1794.9410158553214\n",
      "    ess            : 8.00118354581437\n",
      "    log_marginal   : 1794.941013552108\n",
      "    val_loss       : -1798.3677164713542\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1798.3677266438801\n",
      "Train Epoch: 505 [0/54000 (0%)] Loss: -1809.842773\n",
      "Train Epoch: 505 [11264/54000 (21%)] Loss: -1816.217041\n",
      "Train Epoch: 505 [22528/54000 (42%)] Loss: -1796.408447\n",
      "Train Epoch: 505 [33792/54000 (63%)] Loss: -1812.071777\n",
      "Train Epoch: 505 [45056/54000 (83%)] Loss: -1782.121094\n",
      "    epoch          : 505\n",
      "    loss           : -1795.806144282503\n",
      "    ess            : 8.001182556152344\n",
      "    log_marginal   : 1795.806144282503\n",
      "    val_loss       : -1788.8041483561199\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1788.8041483561199\n",
      "Train Epoch: 506 [0/54000 (0%)] Loss: -1801.258057\n",
      "Train Epoch: 506 [11264/54000 (21%)] Loss: -1813.909912\n",
      "Train Epoch: 506 [22528/54000 (42%)] Loss: -1786.366211\n",
      "Train Epoch: 506 [33792/54000 (63%)] Loss: -1816.736206\n",
      "Train Epoch: 506 [45056/54000 (83%)] Loss: -1796.560425\n",
      "    epoch          : 506\n",
      "    loss           : -1797.6841799178214\n",
      "    ess            : 8.001182286244518\n",
      "    log_marginal   : 1797.684177614608\n",
      "    val_loss       : -1809.8489888509114\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1809.8489888509114\n",
      "Train Epoch: 507 [0/54000 (0%)] Loss: -1822.390869\n",
      "Train Epoch: 507 [11264/54000 (21%)] Loss: -1821.541870\n",
      "Train Epoch: 507 [22528/54000 (42%)] Loss: -1788.960449\n",
      "Train Epoch: 507 [33792/54000 (63%)] Loss: -1812.999634\n",
      "Train Epoch: 507 [45056/54000 (83%)] Loss: -1789.361328\n",
      "    epoch          : 507\n",
      "    loss           : -1801.3690024321934\n",
      "    ess            : 8.00118238521072\n",
      "    log_marginal   : 1801.3690024321934\n",
      "    val_loss       : -1803.5921020507812\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1803.5921020507812\n",
      "Train Epoch: 508 [0/54000 (0%)] Loss: -1817.355469\n",
      "Train Epoch: 508 [11264/54000 (21%)] Loss: -1811.562500\n",
      "Train Epoch: 508 [22528/54000 (42%)] Loss: -1791.421143\n",
      "Train Epoch: 508 [33792/54000 (63%)] Loss: -1819.366089\n",
      "Train Epoch: 508 [45056/54000 (83%)] Loss: -1797.375000\n",
      "    epoch          : 508\n",
      "    loss           : -1800.517147424086\n",
      "    ess            : 8.001181926367417\n",
      "    log_marginal   : 1800.5171462724793\n",
      "    val_loss       : -1798.0731506347656\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1798.0731506347656\n",
      "Train Epoch: 509 [0/54000 (0%)] Loss: -1809.996704\n",
      "Train Epoch: 509 [11264/54000 (21%)] Loss: -1797.737549\n",
      "Train Epoch: 509 [22528/54000 (42%)] Loss: -1792.151855\n",
      "Train Epoch: 509 [33792/54000 (63%)] Loss: -1815.353149\n",
      "Train Epoch: 509 [45056/54000 (83%)] Loss: -1785.904541\n",
      "    epoch          : 509\n",
      "    loss           : -1793.8158995430424\n",
      "    ess            : 8.001181323573274\n",
      "    log_marginal   : 1793.8158995430424\n",
      "    val_loss       : -1803.8063659667969\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1803.8063659667969\n",
      "Train Epoch: 510 [0/54000 (0%)] Loss: -1814.350342\n",
      "Train Epoch: 510 [11264/54000 (21%)] Loss: -1815.499268\n",
      "Train Epoch: 510 [22528/54000 (42%)] Loss: -1799.037598\n",
      "Train Epoch: 510 [33792/54000 (63%)] Loss: -1814.320923\n",
      "Train Epoch: 510 [45056/54000 (83%)] Loss: -1767.500977\n",
      "    epoch          : 510\n",
      "    loss           : -1792.9319584684552\n",
      "    ess            : 8.00118318593727\n",
      "    log_marginal   : 1792.9319584684552\n",
      "    val_loss       : -1772.2825826009114\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1772.2825724283855\n",
      "Train Epoch: 511 [0/54000 (0%)] Loss: -1787.946045\n",
      "Train Epoch: 511 [11264/54000 (21%)] Loss: -1781.358887\n",
      "Train Epoch: 511 [22528/54000 (42%)] Loss: -1781.229126\n",
      "Train Epoch: 511 [33792/54000 (63%)] Loss: -1799.665039\n",
      "Train Epoch: 511 [45056/54000 (83%)] Loss: -1766.818848\n",
      "    epoch          : 511\n",
      "    loss           : -1778.4296114939564\n",
      "    ess            : 8.001184355537847\n",
      "    log_marginal   : 1778.4296114939564\n",
      "    val_loss       : -1790.9754231770833\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1790.9754028320312\n",
      "Train Epoch: 512 [0/54000 (0%)] Loss: -1800.175415\n",
      "Train Epoch: 512 [11264/54000 (21%)] Loss: -1799.334473\n",
      "Train Epoch: 512 [22528/54000 (42%)] Loss: -1796.843262\n",
      "Train Epoch: 512 [33792/54000 (63%)] Loss: -1813.142822\n",
      "Train Epoch: 512 [45056/54000 (83%)] Loss: -1781.693359\n",
      "    epoch          : 512\n",
      "    loss           : -1792.5673632351857\n",
      "    ess            : 8.001183374872747\n",
      "    log_marginal   : 1792.5673632351857\n",
      "    val_loss       : -1795.4371439615886\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1795.4371337890625\n",
      "Train Epoch: 513 [0/54000 (0%)] Loss: -1810.145020\n",
      "Train Epoch: 513 [11264/54000 (21%)] Loss: -1806.721680\n",
      "Train Epoch: 513 [22528/54000 (42%)] Loss: -1798.939941\n",
      "Train Epoch: 513 [33792/54000 (63%)] Loss: -1815.609009\n",
      "Train Epoch: 513 [45056/54000 (83%)] Loss: -1781.556152\n",
      "    epoch          : 513\n",
      "    loss           : -1794.2516548588592\n",
      "    ess            : 8.001182898035589\n",
      "    log_marginal   : 1794.2516537072524\n",
      "    val_loss       : -1787.6193237304688\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1787.6193237304688\n",
      "Train Epoch: 514 [0/54000 (0%)] Loss: -1803.460449\n",
      "Train Epoch: 514 [11264/54000 (21%)] Loss: -1799.518677\n",
      "Train Epoch: 514 [22528/54000 (42%)] Loss: -1800.287598\n",
      "Train Epoch: 514 [33792/54000 (63%)] Loss: -1813.530762\n",
      "Train Epoch: 514 [45056/54000 (83%)] Loss: -1788.699951\n",
      "    epoch          : 514\n",
      "    loss           : -1793.8626029536408\n",
      "    ess            : 8.001183176940343\n",
      "    log_marginal   : 1793.8626029536408\n",
      "    val_loss       : -1796.1999409993489\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1796.1999409993489\n",
      "Train Epoch: 515 [0/54000 (0%)] Loss: -1807.157593\n",
      "Train Epoch: 515 [11264/54000 (21%)] Loss: -1803.791748\n",
      "Train Epoch: 515 [22528/54000 (42%)] Loss: -1795.930298\n",
      "Train Epoch: 515 [33792/54000 (63%)] Loss: -1812.420898\n",
      "Train Epoch: 515 [45056/54000 (83%)] Loss: -1789.067261\n",
      "    epoch          : 515\n",
      "    loss           : -1794.6292678545105\n",
      "    ess            : 8.001182457186141\n",
      "    log_marginal   : 1794.6292678545105\n",
      "    val_loss       : -1799.6459147135417\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1799.6459147135417\n",
      "Train Epoch: 516 [0/54000 (0%)] Loss: -1810.540283\n",
      "Train Epoch: 516 [11264/54000 (21%)] Loss: -1806.388550\n",
      "Train Epoch: 516 [22528/54000 (42%)] Loss: -1776.979248\n",
      "Train Epoch: 516 [33792/54000 (63%)] Loss: -1778.644531\n",
      "Train Epoch: 516 [45056/54000 (83%)] Loss: -1775.564209\n",
      "    epoch          : 516\n",
      "    loss           : -1781.9239640145931\n",
      "    ess            : 8.001184238577789\n",
      "    log_marginal   : 1781.9239640145931\n",
      "    val_loss       : -1792.2662150065105\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1792.2662150065105\n",
      "Train Epoch: 517 [0/54000 (0%)] Loss: -1804.601074\n",
      "Train Epoch: 517 [11264/54000 (21%)] Loss: -1802.074219\n",
      "Train Epoch: 517 [22528/54000 (42%)] Loss: -1791.384766\n",
      "Train Epoch: 517 [33792/54000 (63%)] Loss: -1799.745850\n",
      "Train Epoch: 517 [45056/54000 (83%)] Loss: -1788.311035\n",
      "    epoch          : 517\n",
      "    loss           : -1790.0652845850532\n",
      "    ess            : 8.001183392866603\n",
      "    log_marginal   : 1790.0652845850532\n",
      "    val_loss       : -1797.8099263509114\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1797.8099263509114\n",
      "Train Epoch: 518 [0/54000 (0%)] Loss: -1809.225708\n",
      "Train Epoch: 518 [11264/54000 (21%)] Loss: -1805.806763\n",
      "Train Epoch: 518 [22528/54000 (42%)] Loss: -1791.239990\n",
      "Train Epoch: 518 [33792/54000 (63%)] Loss: -1798.783936\n",
      "Train Epoch: 518 [45056/54000 (83%)] Loss: -1791.375732\n",
      "    epoch          : 518\n",
      "    loss           : -1793.232157005454\n",
      "    ess            : 8.001183095967994\n",
      "    log_marginal   : 1793.2321581570607\n",
      "    val_loss       : -1803.1667785644531\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1803.1667785644531\n",
      "Train Epoch: 519 [0/54000 (0%)] Loss: -1815.930664\n",
      "Train Epoch: 519 [11264/54000 (21%)] Loss: -1809.032349\n",
      "Train Epoch: 519 [22528/54000 (42%)] Loss: -1800.048950\n",
      "Train Epoch: 519 [33792/54000 (63%)] Loss: -1811.652466\n",
      "Train Epoch: 519 [45056/54000 (83%)] Loss: -1792.018311\n",
      "    epoch          : 519\n",
      "    loss           : -1799.9333185159935\n",
      "    ess            : 8.001182511167706\n",
      "    log_marginal   : 1799.9333185159935\n",
      "    val_loss       : -1806.2552693684895\n",
      "    val_ess        : 8.001182317733765\n",
      "    val_log_marginal: 1806.2552693684895\n",
      "Train Epoch: 520 [0/54000 (0%)] Loss: -1818.444580\n",
      "Train Epoch: 520 [11264/54000 (21%)] Loss: -1812.780151\n",
      "Train Epoch: 520 [22528/54000 (42%)] Loss: -1806.344482\n",
      "Train Epoch: 520 [33792/54000 (63%)] Loss: -1814.563477\n",
      "Train Epoch: 520 [45056/54000 (83%)] Loss: -1795.369141\n",
      "    epoch          : 520\n",
      "    loss           : -1802.3344507757222\n",
      "    ess            : 8.00118336587582\n",
      "    log_marginal   : 1802.3344507757222\n",
      "    val_loss       : -1800.3276977539062\n",
      "    val_ess        : 8.0011834303538\n",
      "    val_log_marginal: 1800.3276977539062\n",
      "Train Epoch: 521 [0/54000 (0%)] Loss: -1811.230469\n",
      "Train Epoch: 521 [11264/54000 (21%)] Loss: -1807.730347\n",
      "Train Epoch: 521 [22528/54000 (42%)] Loss: -1790.764526\n",
      "Train Epoch: 521 [33792/54000 (63%)] Loss: -1807.277588\n",
      "Train Epoch: 521 [45056/54000 (83%)] Loss: -1780.265259\n",
      "    epoch          : 521\n",
      "    loss           : -1791.8350968270931\n",
      "    ess            : 8.001181863388926\n",
      "    log_marginal   : 1791.8350968270931\n",
      "    val_loss       : -1797.1157328287761\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1797.115743001302\n",
      "Train Epoch: 522 [0/54000 (0%)] Loss: -1808.372681\n",
      "Train Epoch: 522 [11264/54000 (21%)] Loss: -1803.038574\n",
      "Train Epoch: 522 [22528/54000 (42%)] Loss: -1793.257080\n",
      "Train Epoch: 522 [33792/54000 (63%)] Loss: -1803.786377\n",
      "Train Epoch: 522 [45056/54000 (83%)] Loss: -1781.051270\n",
      "    epoch          : 522\n",
      "    loss           : -1791.0827095463592\n",
      "    ess            : 8.001182079315186\n",
      "    log_marginal   : 1791.0827095463592\n",
      "    val_loss       : -1794.382303873698\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1794.382303873698\n",
      "Train Epoch: 523 [0/54000 (0%)] Loss: -1809.743408\n",
      "Train Epoch: 523 [11264/54000 (21%)] Loss: -1815.916626\n",
      "Train Epoch: 523 [22528/54000 (42%)] Loss: -1798.708008\n",
      "Train Epoch: 523 [33792/54000 (63%)] Loss: -1791.387329\n",
      "Train Epoch: 523 [45056/54000 (83%)] Loss: -1776.614258\n",
      "    epoch          : 523\n",
      "    loss           : -1788.6128931585347\n",
      "    ess            : 8.001182790072459\n",
      "    log_marginal   : 1788.6128931585347\n",
      "    val_loss       : -1776.8111775716145\n",
      "    val_ess        : 8.00118613243103\n",
      "    val_log_marginal: 1776.8111775716145\n",
      "Train Epoch: 524 [0/54000 (0%)] Loss: -1788.300903\n",
      "Train Epoch: 524 [11264/54000 (21%)] Loss: -1780.165039\n",
      "Train Epoch: 524 [22528/54000 (42%)] Loss: -1783.701660\n",
      "Train Epoch: 524 [33792/54000 (63%)] Loss: -1796.250244\n",
      "Train Epoch: 524 [45056/54000 (83%)] Loss: -1792.615479\n",
      "    epoch          : 524\n",
      "    loss           : -1783.2620423514888\n",
      "    ess            : 8.001184769396511\n",
      "    log_marginal   : 1783.2620423514888\n",
      "    val_loss       : -1796.3766479492188\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1796.3766479492188\n",
      "Train Epoch: 525 [0/54000 (0%)] Loss: -1807.230469\n",
      "Train Epoch: 525 [11264/54000 (21%)] Loss: -1802.831299\n",
      "Train Epoch: 525 [22528/54000 (42%)] Loss: -1793.737549\n",
      "Train Epoch: 525 [33792/54000 (63%)] Loss: -1799.292236\n",
      "Train Epoch: 525 [45056/54000 (83%)] Loss: -1790.082520\n",
      "    epoch          : 525\n",
      "    loss           : -1792.1090594597583\n",
      "    ess            : 8.001183743746775\n",
      "    log_marginal   : 1792.1090594597583\n",
      "    val_loss       : -1792.5151672363281\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1792.5151672363281\n",
      "Train Epoch: 526 [0/54000 (0%)] Loss: -1804.138062\n",
      "Train Epoch: 526 [11264/54000 (21%)] Loss: -1805.690918\n",
      "Train Epoch: 526 [22528/54000 (42%)] Loss: -1790.488403\n",
      "Train Epoch: 526 [33792/54000 (63%)] Loss: -1806.697510\n",
      "Train Epoch: 526 [45056/54000 (83%)] Loss: -1796.105957\n",
      "    epoch          : 526\n",
      "    loss           : -1794.9514298349056\n",
      "    ess            : 8.001183905691471\n",
      "    log_marginal   : 1794.9514298349056\n",
      "    val_loss       : -1798.8399658203125\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1798.8399454752605\n",
      "Train Epoch: 527 [0/54000 (0%)] Loss: -1811.625244\n",
      "Train Epoch: 527 [11264/54000 (21%)] Loss: -1812.447144\n",
      "Train Epoch: 527 [22528/54000 (42%)] Loss: -1796.957153\n",
      "Train Epoch: 527 [33792/54000 (63%)] Loss: -1813.097900\n",
      "Train Epoch: 527 [45056/54000 (83%)] Loss: -1796.796997\n",
      "    epoch          : 527\n",
      "    loss           : -1799.4771636387088\n",
      "    ess            : 8.001182979007936\n",
      "    log_marginal   : 1799.4771636387088\n",
      "    val_loss       : -1802.1367289225261\n",
      "    val_ess        : 8.001184225082397\n",
      "    val_log_marginal: 1802.1367289225261\n",
      "Train Epoch: 528 [0/54000 (0%)] Loss: -1813.317383\n",
      "Train Epoch: 528 [11264/54000 (21%)] Loss: -1814.488525\n",
      "Train Epoch: 528 [22528/54000 (42%)] Loss: -1794.337280\n",
      "Train Epoch: 528 [33792/54000 (63%)] Loss: -1812.506836\n",
      "Train Epoch: 528 [45056/54000 (83%)] Loss: -1793.671875\n",
      "    epoch          : 528\n",
      "    loss           : -1798.7191104529038\n",
      "    ess            : 8.001182988004864\n",
      "    log_marginal   : 1798.7191104529038\n",
      "    val_loss       : -1800.1798299153645\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1800.1798502604167\n",
      "Train Epoch: 529 [0/54000 (0%)] Loss: -1811.704590\n",
      "Train Epoch: 529 [11264/54000 (21%)] Loss: -1810.523071\n",
      "Train Epoch: 529 [22528/54000 (42%)] Loss: -1797.463379\n",
      "Train Epoch: 529 [33792/54000 (63%)] Loss: -1817.477417\n",
      "Train Epoch: 529 [45056/54000 (83%)] Loss: -1787.354980\n",
      "    epoch          : 529\n",
      "    loss           : -1796.4659274119251\n",
      "    ess            : 8.001183347881964\n",
      "    log_marginal   : 1796.4659274119251\n",
      "    val_loss       : -1797.8821716308594\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1797.8821716308594\n",
      "Train Epoch: 530 [0/54000 (0%)] Loss: -1808.972168\n",
      "Train Epoch: 530 [11264/54000 (21%)] Loss: -1812.322510\n",
      "Train Epoch: 530 [22528/54000 (42%)] Loss: -1796.586060\n",
      "Train Epoch: 530 [33792/54000 (63%)] Loss: -1817.906982\n",
      "Train Epoch: 530 [45056/54000 (83%)] Loss: -1791.453125\n",
      "    epoch          : 530\n",
      "    loss           : -1798.8809065908756\n",
      "    ess            : 8.001183347881964\n",
      "    log_marginal   : 1798.8809065908756\n",
      "    val_loss       : -1801.1567891438801\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1801.1567891438801\n",
      "Train Epoch: 531 [0/54000 (0%)] Loss: -1813.147705\n",
      "Train Epoch: 531 [11264/54000 (21%)] Loss: -1816.264648\n",
      "Train Epoch: 531 [22528/54000 (42%)] Loss: -1796.568604\n",
      "Train Epoch: 531 [33792/54000 (63%)] Loss: -1817.935425\n",
      "Train Epoch: 531 [45056/54000 (83%)] Loss: -1793.544678\n",
      "    epoch          : 531\n",
      "    loss           : -1799.7525634765625\n",
      "    ess            : 8.001183014995647\n",
      "    log_marginal   : 1799.7525634765625\n",
      "    val_loss       : -1804.5628051757812\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1804.5627950032551\n",
      "Train Epoch: 532 [0/54000 (0%)] Loss: -1815.332764\n",
      "Train Epoch: 532 [11264/54000 (21%)] Loss: -1814.743164\n",
      "Train Epoch: 532 [22528/54000 (42%)] Loss: -1797.288208\n",
      "Train Epoch: 532 [33792/54000 (63%)] Loss: -1811.943848\n",
      "Train Epoch: 532 [45056/54000 (83%)] Loss: -1790.246094\n",
      "    epoch          : 532\n",
      "    loss           : -1797.2414401072376\n",
      "    ess            : 8.001182547155416\n",
      "    log_marginal   : 1797.2414401072376\n",
      "    val_loss       : -1780.9601236979167\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1780.9601236979167\n",
      "Train Epoch: 533 [0/54000 (0%)] Loss: -1792.964722\n",
      "Train Epoch: 533 [11264/54000 (21%)] Loss: -1797.856079\n",
      "Train Epoch: 533 [22528/54000 (42%)] Loss: -1766.215088\n",
      "Train Epoch: 533 [33792/54000 (63%)] Loss: -1809.882568\n",
      "Train Epoch: 533 [45056/54000 (83%)] Loss: -1758.961182\n",
      "    epoch          : 533\n",
      "    loss           : -1779.3146166531544\n",
      "    ess            : 8.001183410860458\n",
      "    log_marginal   : 1779.3146166531544\n",
      "    val_loss       : -1786.5641377766926\n",
      "    val_ess        : 8.001185576121012\n",
      "    val_log_marginal: 1786.5641581217449\n",
      "Train Epoch: 534 [0/54000 (0%)] Loss: -1797.786621\n",
      "Train Epoch: 534 [11264/54000 (21%)] Loss: -1805.684692\n",
      "Train Epoch: 534 [22528/54000 (42%)] Loss: -1790.830322\n",
      "Train Epoch: 534 [33792/54000 (63%)] Loss: -1818.249146\n",
      "Train Epoch: 534 [45056/54000 (83%)] Loss: -1765.879883\n",
      "    epoch          : 534\n",
      "    loss           : -1790.540361512382\n",
      "    ess            : 8.001183491832805\n",
      "    log_marginal   : 1790.5403626639888\n",
      "    val_loss       : -1792.1323649088542\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1792.1323649088542\n",
      "Train Epoch: 535 [0/54000 (0%)] Loss: -1803.876709\n",
      "Train Epoch: 535 [11264/54000 (21%)] Loss: -1814.772827\n",
      "Train Epoch: 535 [22528/54000 (42%)] Loss: -1785.753662\n",
      "Train Epoch: 535 [33792/54000 (63%)] Loss: -1819.283691\n",
      "Train Epoch: 535 [45056/54000 (83%)] Loss: -1789.566162\n",
      "    epoch          : 535\n",
      "    loss           : -1797.843030245799\n",
      "    ess            : 8.00118274508782\n",
      "    log_marginal   : 1797.8430313974056\n",
      "    val_loss       : -1802.5802714029949\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1802.5802510579426\n",
      "Train Epoch: 536 [0/54000 (0%)] Loss: -1816.749634\n",
      "Train Epoch: 536 [11264/54000 (21%)] Loss: -1818.352051\n",
      "Train Epoch: 536 [22528/54000 (42%)] Loss: -1796.837402\n",
      "Train Epoch: 536 [33792/54000 (63%)] Loss: -1824.089478\n",
      "Train Epoch: 536 [45056/54000 (83%)] Loss: -1794.480225\n",
      "    epoch          : 536\n",
      "    loss           : -1803.500165831368\n",
      "    ess            : 8.001182988004864\n",
      "    log_marginal   : 1803.500165831368\n",
      "    val_loss       : -1802.0980021158855\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1802.0980021158855\n",
      "Train Epoch: 537 [0/54000 (0%)] Loss: -1816.163818\n",
      "Train Epoch: 537 [11264/54000 (21%)] Loss: -1812.734619\n",
      "Train Epoch: 537 [22528/54000 (42%)] Loss: -1799.250732\n",
      "Train Epoch: 537 [33792/54000 (63%)] Loss: -1816.698730\n",
      "Train Epoch: 537 [45056/54000 (83%)] Loss: -1791.324951\n",
      "    epoch          : 537\n",
      "    loss           : -1799.1599305350826\n",
      "    ess            : 8.001183707759065\n",
      "    log_marginal   : 1799.1599316866893\n",
      "    val_loss       : -1800.2254842122395\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1800.2254842122395\n",
      "Train Epoch: 538 [0/54000 (0%)] Loss: -1813.647461\n",
      "Train Epoch: 538 [11264/54000 (21%)] Loss: -1811.489746\n",
      "Train Epoch: 538 [22528/54000 (42%)] Loss: -1789.092651\n",
      "Train Epoch: 538 [33792/54000 (63%)] Loss: -1815.814209\n",
      "Train Epoch: 538 [45056/54000 (83%)] Loss: -1790.610474\n",
      "    epoch          : 538\n",
      "    loss           : -1798.4032362452094\n",
      "    ess            : 8.001183320891183\n",
      "    log_marginal   : 1798.4032362452094\n",
      "    val_loss       : -1802.5462544759114\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1802.5462544759114\n",
      "Train Epoch: 539 [0/54000 (0%)] Loss: -1816.692383\n",
      "Train Epoch: 539 [11264/54000 (21%)] Loss: -1808.746216\n",
      "Train Epoch: 539 [22528/54000 (42%)] Loss: -1793.032349\n",
      "Train Epoch: 539 [33792/54000 (63%)] Loss: -1805.388916\n",
      "Train Epoch: 539 [45056/54000 (83%)] Loss: -1789.682373\n",
      "    epoch          : 539\n",
      "    loss           : -1796.6707095739976\n",
      "    ess            : 8.001183194934198\n",
      "    log_marginal   : 1796.6707095739976\n",
      "    val_loss       : -1800.7547098795574\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1800.7546895345051\n",
      "Train Epoch: 540 [0/54000 (0%)] Loss: -1812.172119\n",
      "Train Epoch: 540 [11264/54000 (21%)] Loss: -1805.830078\n",
      "Train Epoch: 540 [22528/54000 (42%)] Loss: -1775.671875\n",
      "Train Epoch: 540 [33792/54000 (63%)] Loss: -1804.389404\n",
      "Train Epoch: 540 [45056/54000 (83%)] Loss: -1781.944946\n",
      "    epoch          : 540\n",
      "    loss           : -1787.5153463111733\n",
      "    ess            : 8.001182808066314\n",
      "    log_marginal   : 1787.5153463111733\n",
      "    val_loss       : -1795.9580688476562\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1795.9580688476562\n",
      "Train Epoch: 541 [0/54000 (0%)] Loss: -1807.173096\n",
      "Train Epoch: 541 [11264/54000 (21%)] Loss: -1810.498901\n",
      "Train Epoch: 541 [22528/54000 (42%)] Loss: -1804.872070\n",
      "Train Epoch: 541 [33792/54000 (63%)] Loss: -1819.878784\n",
      "Train Epoch: 541 [45056/54000 (83%)] Loss: -1796.906250\n",
      "    epoch          : 541\n",
      "    loss           : -1801.211111392615\n",
      "    ess            : 8.001182763081676\n",
      "    log_marginal   : 1801.211111392615\n",
      "    val_loss       : -1799.0387064615886\n",
      "    val_ess        : 8.001182715098063\n",
      "    val_log_marginal: 1799.0387064615886\n",
      "Train Epoch: 542 [0/54000 (0%)] Loss: -1809.093750\n",
      "Train Epoch: 542 [11264/54000 (21%)] Loss: -1811.418945\n",
      "Train Epoch: 542 [22528/54000 (42%)] Loss: -1796.862305\n",
      "Train Epoch: 542 [33792/54000 (63%)] Loss: -1820.192749\n",
      "Train Epoch: 542 [45056/54000 (83%)] Loss: -1797.348633\n",
      "    epoch          : 542\n",
      "    loss           : -1801.2809033663768\n",
      "    ess            : 8.001181755425796\n",
      "    log_marginal   : 1801.2809033663768\n",
      "    val_loss       : -1796.8153991699219\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1796.8153991699219\n",
      "Train Epoch: 543 [0/54000 (0%)] Loss: -1806.122192\n",
      "Train Epoch: 543 [11264/54000 (21%)] Loss: -1808.322754\n",
      "Train Epoch: 543 [22528/54000 (42%)] Loss: -1784.973145\n",
      "Train Epoch: 543 [33792/54000 (63%)] Loss: -1790.406982\n",
      "Train Epoch: 543 [45056/54000 (83%)] Loss: -1760.257568\n",
      "    epoch          : 543\n",
      "    loss           : -1781.7756163399174\n",
      "    ess            : 8.001182925026372\n",
      "    log_marginal   : 1781.7756174915241\n",
      "    val_loss       : -1758.3377888997395\n",
      "    val_ess        : 8.00118621190389\n",
      "    val_log_marginal: 1758.3377888997395\n",
      "Train Epoch: 544 [0/54000 (0%)] Loss: -1764.783081\n",
      "Train Epoch: 544 [11264/54000 (21%)] Loss: -1783.789185\n",
      "Train Epoch: 544 [22528/54000 (42%)] Loss: -1764.074219\n",
      "Train Epoch: 544 [33792/54000 (63%)] Loss: -1806.557251\n",
      "Train Epoch: 544 [45056/54000 (83%)] Loss: -1765.981323\n",
      "    epoch          : 544\n",
      "    loss           : -1775.3424636552918\n",
      "    ess            : 8.001183707759065\n",
      "    log_marginal   : 1775.3424636552918\n",
      "    val_loss       : -1780.9182840983074\n",
      "    val_ess        : 8.001185417175293\n",
      "    val_log_marginal: 1780.9182840983074\n",
      "Train Epoch: 545 [0/54000 (0%)] Loss: -1791.801636\n",
      "Train Epoch: 545 [11264/54000 (21%)] Loss: -1794.085083\n",
      "Train Epoch: 545 [22528/54000 (42%)] Loss: -1788.135010\n",
      "Train Epoch: 545 [33792/54000 (63%)] Loss: -1814.082764\n",
      "Train Epoch: 545 [45056/54000 (83%)] Loss: -1780.749512\n",
      "    epoch          : 545\n",
      "    loss           : -1787.9274222895783\n",
      "    ess            : 8.001182673112401\n",
      "    log_marginal   : 1787.9274222895783\n",
      "    val_loss       : -1782.7651977539062\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1782.7651977539062\n",
      "Train Epoch: 546 [0/54000 (0%)] Loss: -1794.182129\n",
      "Train Epoch: 546 [11264/54000 (21%)] Loss: -1803.360229\n",
      "Train Epoch: 546 [22528/54000 (42%)] Loss: -1787.667236\n",
      "Train Epoch: 546 [33792/54000 (63%)] Loss: -1817.801758\n",
      "Train Epoch: 546 [45056/54000 (83%)] Loss: -1793.358154\n",
      "    epoch          : 546\n",
      "    loss           : -1794.5547922962116\n",
      "    ess            : 8.001182196275243\n",
      "    log_marginal   : 1794.5547922962116\n",
      "    val_loss       : -1803.5866597493489\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1803.5866597493489\n",
      "Train Epoch: 547 [0/54000 (0%)] Loss: -1814.604980\n",
      "Train Epoch: 547 [11264/54000 (21%)] Loss: -1815.912598\n",
      "Train Epoch: 547 [22528/54000 (42%)] Loss: -1793.946411\n",
      "Train Epoch: 547 [33792/54000 (63%)] Loss: -1819.081299\n",
      "Train Epoch: 547 [45056/54000 (83%)] Loss: -1790.517456\n",
      "    epoch          : 547\n",
      "    loss           : -1800.2253878611439\n",
      "    ess            : 8.001182268250663\n",
      "    log_marginal   : 1800.2253878611439\n",
      "    val_loss       : -1799.0545247395833\n",
      "    val_ess        : 8.001184225082397\n",
      "    val_log_marginal: 1799.0545247395833\n",
      "Train Epoch: 548 [0/54000 (0%)] Loss: -1809.430054\n",
      "Train Epoch: 548 [11264/54000 (21%)] Loss: -1809.693604\n",
      "Train Epoch: 548 [22528/54000 (42%)] Loss: -1799.413940\n",
      "Train Epoch: 548 [33792/54000 (63%)] Loss: -1814.524536\n",
      "Train Epoch: 548 [45056/54000 (83%)] Loss: -1787.348145\n",
      "    epoch          : 548\n",
      "    loss           : -1797.0921331441627\n",
      "    ess            : 8.001182520164633\n",
      "    log_marginal   : 1797.0921331441627\n",
      "    val_loss       : -1795.0640665690105\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1795.0640665690105\n",
      "Train Epoch: 549 [0/54000 (0%)] Loss: -1805.257324\n",
      "Train Epoch: 549 [11264/54000 (21%)] Loss: -1806.878906\n",
      "Train Epoch: 549 [22528/54000 (42%)] Loss: -1797.512695\n",
      "Train Epoch: 549 [33792/54000 (63%)] Loss: -1820.582031\n",
      "Train Epoch: 549 [45056/54000 (83%)] Loss: -1792.810059\n",
      "    epoch          : 549\n",
      "    loss           : -1799.9626867906102\n",
      "    ess            : 8.001181188619361\n",
      "    log_marginal   : 1799.9626867906102\n",
      "    val_loss       : -1805.71728515625\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1805.717264811198\n",
      "Train Epoch: 550 [0/54000 (0%)] Loss: -1813.880371\n",
      "Train Epoch: 550 [11264/54000 (21%)] Loss: -1810.294434\n",
      "Train Epoch: 550 [22528/54000 (42%)] Loss: -1792.170776\n",
      "Train Epoch: 550 [33792/54000 (63%)] Loss: -1797.254883\n",
      "Train Epoch: 550 [45056/54000 (83%)] Loss: -1776.443115\n",
      "    epoch          : 550\n",
      "    loss           : -1790.4559176463001\n",
      "    ess            : 8.001181827401215\n",
      "    log_marginal   : 1790.4559176463001\n",
      "    val_loss       : -1795.9941711425781\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1795.9941914876301\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch550.pth ...\n",
      "Train Epoch: 551 [0/54000 (0%)] Loss: -1806.036377\n",
      "Train Epoch: 551 [11264/54000 (21%)] Loss: -1810.277100\n",
      "Train Epoch: 551 [22528/54000 (42%)] Loss: -1785.794189\n",
      "Train Epoch: 551 [33792/54000 (63%)] Loss: -1806.975098\n",
      "Train Epoch: 551 [45056/54000 (83%)] Loss: -1785.674561\n",
      "    epoch          : 551\n",
      "    loss           : -1791.864051674897\n",
      "    ess            : 8.001182862047878\n",
      "    log_marginal   : 1791.864051674897\n",
      "    val_loss       : -1794.3965454101562\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1794.3965250651042\n",
      "Train Epoch: 552 [0/54000 (0%)] Loss: -1803.131958\n",
      "Train Epoch: 552 [11264/54000 (21%)] Loss: -1796.245361\n",
      "Train Epoch: 552 [22528/54000 (42%)] Loss: -1783.193237\n",
      "Train Epoch: 552 [33792/54000 (63%)] Loss: -1800.727905\n",
      "Train Epoch: 552 [45056/54000 (83%)] Loss: -1788.077637\n",
      "    epoch          : 552\n",
      "    loss           : -1786.5696940871906\n",
      "    ess            : 8.001183239918834\n",
      "    log_marginal   : 1786.5696940871906\n",
      "    val_loss       : -1795.174051920573\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1795.174051920573\n",
      "Train Epoch: 553 [0/54000 (0%)] Loss: -1803.245117\n",
      "Train Epoch: 553 [11264/54000 (21%)] Loss: -1800.708374\n",
      "Train Epoch: 553 [22528/54000 (42%)] Loss: -1788.647949\n",
      "Train Epoch: 553 [33792/54000 (63%)] Loss: -1816.735474\n",
      "Train Epoch: 553 [45056/54000 (83%)] Loss: -1798.327637\n",
      "    epoch          : 553\n",
      "    loss           : -1794.959576300855\n",
      "    ess            : 8.001182484176924\n",
      "    log_marginal   : 1794.9595774524616\n",
      "    val_loss       : -1800.7483622233074\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1800.7483622233074\n",
      "Train Epoch: 554 [0/54000 (0%)] Loss: -1810.044434\n",
      "Train Epoch: 554 [11264/54000 (21%)] Loss: -1805.362061\n",
      "Train Epoch: 554 [22528/54000 (42%)] Loss: -1791.234741\n",
      "Train Epoch: 554 [33792/54000 (63%)] Loss: -1817.306641\n",
      "Train Epoch: 554 [45056/54000 (83%)] Loss: -1793.696899\n",
      "    epoch          : 554\n",
      "    loss           : -1796.9935383346844\n",
      "    ess            : 8.00118206132133\n",
      "    log_marginal   : 1796.9935383346844\n",
      "    val_loss       : -1800.0731608072917\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1800.0731709798176\n",
      "Train Epoch: 555 [0/54000 (0%)] Loss: -1810.836426\n",
      "Train Epoch: 555 [11264/54000 (21%)] Loss: -1816.328369\n",
      "Train Epoch: 555 [22528/54000 (42%)] Loss: -1805.986572\n",
      "Train Epoch: 555 [33792/54000 (63%)] Loss: -1814.066162\n",
      "Train Epoch: 555 [45056/54000 (83%)] Loss: -1788.781006\n",
      "    epoch          : 555\n",
      "    loss           : -1799.5186237839032\n",
      "    ess            : 8.001182016336694\n",
      "    log_marginal   : 1799.5186237839032\n",
      "    val_loss       : -1799.4465942382812\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1799.4465942382812\n",
      "Train Epoch: 556 [0/54000 (0%)] Loss: -1812.225830\n",
      "Train Epoch: 556 [11264/54000 (21%)] Loss: -1814.194946\n",
      "Train Epoch: 556 [22528/54000 (42%)] Loss: -1798.103516\n",
      "Train Epoch: 556 [33792/54000 (63%)] Loss: -1812.140625\n",
      "Train Epoch: 556 [45056/54000 (83%)] Loss: -1792.278564\n",
      "    epoch          : 556\n",
      "    loss           : -1799.3686696178509\n",
      "    ess            : 8.001182232262954\n",
      "    log_marginal   : 1799.3686684662441\n",
      "    val_loss       : -1804.0452779134114\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1804.0452779134114\n",
      "Train Epoch: 557 [0/54000 (0%)] Loss: -1814.558350\n",
      "Train Epoch: 557 [11264/54000 (21%)] Loss: -1817.507568\n",
      "Train Epoch: 557 [22528/54000 (42%)] Loss: -1799.786377\n",
      "Train Epoch: 557 [33792/54000 (63%)] Loss: -1807.123657\n",
      "Train Epoch: 557 [45056/54000 (83%)] Loss: -1791.977051\n",
      "    epoch          : 557\n",
      "    loss           : -1798.9325043300412\n",
      "    ess            : 8.001181287585565\n",
      "    log_marginal   : 1798.9325043300412\n",
      "    val_loss       : -1801.9741719563801\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1801.9741719563801\n",
      "Train Epoch: 558 [0/54000 (0%)] Loss: -1812.013672\n",
      "Train Epoch: 558 [11264/54000 (21%)] Loss: -1811.195557\n",
      "Train Epoch: 558 [22528/54000 (42%)] Loss: -1793.940186\n",
      "Train Epoch: 558 [33792/54000 (63%)] Loss: -1816.523071\n",
      "Train Epoch: 558 [45056/54000 (83%)] Loss: -1793.806885\n",
      "    epoch          : 558\n",
      "    loss           : -1799.2082450434846\n",
      "    ess            : 8.001182448189214\n",
      "    log_marginal   : 1799.2082450434846\n",
      "    val_loss       : -1808.505126953125\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1808.505126953125\n",
      "Train Epoch: 559 [0/54000 (0%)] Loss: -1819.279785\n",
      "Train Epoch: 559 [11264/54000 (21%)] Loss: -1819.135498\n",
      "Train Epoch: 559 [22528/54000 (42%)] Loss: -1794.235352\n",
      "Train Epoch: 559 [33792/54000 (63%)] Loss: -1807.595093\n",
      "Train Epoch: 559 [45056/54000 (83%)] Loss: -1796.235107\n",
      "    epoch          : 559\n",
      "    loss           : -1799.6827853220814\n",
      "    ess            : 8.001181863388926\n",
      "    log_marginal   : 1799.6827853220814\n",
      "    val_loss       : -1797.981913248698\n",
      "    val_ess        : 8.00118056933085\n",
      "    val_log_marginal: 1797.9819234212239\n",
      "Train Epoch: 560 [0/54000 (0%)] Loss: -1809.022583\n",
      "Train Epoch: 560 [11264/54000 (21%)] Loss: -1812.174316\n",
      "Train Epoch: 560 [22528/54000 (42%)] Loss: -1798.970337\n",
      "Train Epoch: 560 [33792/54000 (63%)] Loss: -1822.300781\n",
      "Train Epoch: 560 [45056/54000 (83%)] Loss: -1797.101929\n",
      "    epoch          : 560\n",
      "    loss           : -1802.12214056051\n",
      "    ess            : 8.001182358219939\n",
      "    log_marginal   : 1802.12214056051\n",
      "    val_loss       : -1803.6884155273438\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1803.6884155273438\n",
      "Train Epoch: 561 [0/54000 (0%)] Loss: -1810.395020\n",
      "Train Epoch: 561 [11264/54000 (21%)] Loss: -1805.391235\n",
      "Train Epoch: 561 [22528/54000 (42%)] Loss: -1793.151855\n",
      "Train Epoch: 561 [33792/54000 (63%)] Loss: -1800.011475\n",
      "Train Epoch: 561 [45056/54000 (83%)] Loss: -1787.563965\n",
      "    epoch          : 561\n",
      "    loss           : -1791.8928533590065\n",
      "    ess            : 8.00118238521072\n",
      "    log_marginal   : 1791.8928533590065\n",
      "    val_loss       : -1794.0859069824219\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1794.0859069824219\n",
      "Train Epoch: 562 [0/54000 (0%)] Loss: -1803.137695\n",
      "Train Epoch: 562 [11264/54000 (21%)] Loss: -1792.878174\n",
      "Train Epoch: 562 [22528/54000 (42%)] Loss: -1776.790894\n",
      "Train Epoch: 562 [33792/54000 (63%)] Loss: -1811.031494\n",
      "Train Epoch: 562 [45056/54000 (83%)] Loss: -1795.930176\n",
      "    epoch          : 562\n",
      "    loss           : -1789.5429457178657\n",
      "    ess            : 8.001183824719122\n",
      "    log_marginal   : 1789.5429457178657\n",
      "    val_loss       : -1803.5465799967449\n",
      "    val_ess        : 8.001183986663818\n",
      "    val_log_marginal: 1803.5465799967449\n",
      "Train Epoch: 563 [0/54000 (0%)] Loss: -1812.853638\n",
      "Train Epoch: 563 [11264/54000 (21%)] Loss: -1802.927246\n",
      "Train Epoch: 563 [22528/54000 (42%)] Loss: -1784.481689\n",
      "Train Epoch: 563 [33792/54000 (63%)] Loss: -1810.423706\n",
      "Train Epoch: 563 [45056/54000 (83%)] Loss: -1786.895508\n",
      "    epoch          : 563\n",
      "    loss           : -1792.922276910746\n",
      "    ess            : 8.001183050983357\n",
      "    log_marginal   : 1792.922276910746\n",
      "    val_loss       : -1798.4971110026042\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1798.4971211751301\n",
      "Train Epoch: 564 [0/54000 (0%)] Loss: -1811.106812\n",
      "Train Epoch: 564 [11264/54000 (21%)] Loss: -1809.914062\n",
      "Train Epoch: 564 [22528/54000 (42%)] Loss: -1792.862183\n",
      "Train Epoch: 564 [33792/54000 (63%)] Loss: -1815.409912\n",
      "Train Epoch: 564 [45056/54000 (83%)] Loss: -1794.898682\n",
      "    epoch          : 564\n",
      "    loss           : -1797.9073209942512\n",
      "    ess            : 8.001182952017155\n",
      "    log_marginal   : 1797.9073209942512\n",
      "    val_loss       : -1802.8943481445312\n",
      "    val_ess        : 8.0011834303538\n",
      "    val_log_marginal: 1802.8943379720051\n",
      "Train Epoch: 565 [0/54000 (0%)] Loss: -1814.866577\n",
      "Train Epoch: 565 [11264/54000 (21%)] Loss: -1810.454468\n",
      "Train Epoch: 565 [22528/54000 (42%)] Loss: -1787.975830\n",
      "Train Epoch: 565 [33792/54000 (63%)] Loss: -1810.245605\n",
      "Train Epoch: 565 [45056/54000 (83%)] Loss: -1792.213867\n",
      "    epoch          : 565\n",
      "    loss           : -1795.9050097195607\n",
      "    ess            : 8.001182898035589\n",
      "    log_marginal   : 1795.9050097195607\n",
      "    val_loss       : -1805.9201965332031\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1805.9201965332031\n",
      "Train Epoch: 566 [0/54000 (0%)] Loss: -1816.546875\n",
      "Train Epoch: 566 [11264/54000 (21%)] Loss: -1817.580566\n",
      "Train Epoch: 566 [22528/54000 (42%)] Loss: -1795.882568\n",
      "Train Epoch: 566 [33792/54000 (63%)] Loss: -1815.461914\n",
      "Train Epoch: 566 [45056/54000 (83%)] Loss: -1793.285400\n",
      "    epoch          : 566\n",
      "    loss           : -1800.8558268996906\n",
      "    ess            : 8.001182115302896\n",
      "    log_marginal   : 1800.855828051297\n",
      "    val_loss       : -1802.3670450846355\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1802.3670450846355\n",
      "Train Epoch: 567 [0/54000 (0%)] Loss: -1813.433350\n",
      "Train Epoch: 567 [11264/54000 (21%)] Loss: -1812.605713\n",
      "Train Epoch: 567 [22528/54000 (42%)] Loss: -1795.299927\n",
      "Train Epoch: 567 [33792/54000 (63%)] Loss: -1818.654907\n",
      "Train Epoch: 567 [45056/54000 (83%)] Loss: -1789.931152\n",
      "    epoch          : 567\n",
      "    loss           : -1798.8370269199588\n",
      "    ess            : 8.001182106305968\n",
      "    log_marginal   : 1798.8370269199588\n",
      "    val_loss       : -1794.2273966471355\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1794.2273966471355\n",
      "Train Epoch: 568 [0/54000 (0%)] Loss: -1804.479248\n",
      "Train Epoch: 568 [11264/54000 (21%)] Loss: -1801.439453\n",
      "Train Epoch: 568 [22528/54000 (42%)] Loss: -1785.538330\n",
      "Train Epoch: 568 [33792/54000 (63%)] Loss: -1802.690918\n",
      "Train Epoch: 568 [45056/54000 (83%)] Loss: -1789.699219\n",
      "    epoch          : 568\n",
      "    loss           : -1790.362714659493\n",
      "    ess            : 8.001183779734486\n",
      "    log_marginal   : 1790.362714659493\n",
      "    val_loss       : -1798.6910807291667\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1798.6910807291667\n",
      "Train Epoch: 569 [0/54000 (0%)] Loss: -1810.049316\n",
      "Train Epoch: 569 [11264/54000 (21%)] Loss: -1798.804688\n",
      "Train Epoch: 569 [22528/54000 (42%)] Loss: -1789.350952\n",
      "Train Epoch: 569 [33792/54000 (63%)] Loss: -1806.254639\n",
      "Train Epoch: 569 [45056/54000 (83%)] Loss: -1784.724854\n",
      "    epoch          : 569\n",
      "    loss           : -1788.048352511424\n",
      "    ess            : 8.001183995660746\n",
      "    log_marginal   : 1788.048352511424\n",
      "    val_loss       : -1779.3287150065105\n",
      "    val_ess        : 8.001184384028116\n",
      "    val_log_marginal: 1779.3287150065105\n",
      "Train Epoch: 570 [0/54000 (0%)] Loss: -1789.500610\n",
      "Train Epoch: 570 [11264/54000 (21%)] Loss: -1800.229736\n",
      "Train Epoch: 570 [22528/54000 (42%)] Loss: -1788.965088\n",
      "Train Epoch: 570 [33792/54000 (63%)] Loss: -1801.071289\n",
      "Train Epoch: 570 [45056/54000 (83%)] Loss: -1786.519043\n",
      "    epoch          : 570\n",
      "    loss           : -1786.4235206460053\n",
      "    ess            : 8.001183167943415\n",
      "    log_marginal   : 1786.4235206460053\n",
      "    val_loss       : -1789.1839701334636\n",
      "    val_ess        : 8.00118358929952\n",
      "    val_log_marginal: 1789.1839701334636\n",
      "Train Epoch: 571 [0/54000 (0%)] Loss: -1797.704834\n",
      "Train Epoch: 571 [11264/54000 (21%)] Loss: -1801.515015\n",
      "Train Epoch: 571 [22528/54000 (42%)] Loss: -1793.778320\n",
      "Train Epoch: 571 [33792/54000 (63%)] Loss: -1808.459473\n",
      "Train Epoch: 571 [45056/54000 (83%)] Loss: -1790.210693\n",
      "    epoch          : 571\n",
      "    loss           : -1792.830317659198\n",
      "    ess            : 8.001183554811298\n",
      "    log_marginal   : 1792.830317659198\n",
      "    val_loss       : -1794.30615234375\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1794.30615234375\n",
      "Train Epoch: 572 [0/54000 (0%)] Loss: -1803.869873\n",
      "Train Epoch: 572 [11264/54000 (21%)] Loss: -1781.730225\n",
      "Train Epoch: 572 [22528/54000 (42%)] Loss: -1782.186279\n",
      "Train Epoch: 572 [33792/54000 (63%)] Loss: -1807.279785\n",
      "Train Epoch: 572 [45056/54000 (83%)] Loss: -1784.912842\n",
      "    epoch          : 572\n",
      "    loss           : -1784.9948074052918\n",
      "    ess            : 8.001184184596223\n",
      "    log_marginal   : 1784.9948074052918\n",
      "    val_loss       : -1792.9483032226562\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1792.9483032226562\n",
      "Train Epoch: 573 [0/54000 (0%)] Loss: -1806.782959\n",
      "Train Epoch: 573 [11264/54000 (21%)] Loss: -1814.195801\n",
      "Train Epoch: 573 [22528/54000 (42%)] Loss: -1803.754272\n",
      "Train Epoch: 573 [33792/54000 (63%)] Loss: -1820.529297\n",
      "Train Epoch: 573 [45056/54000 (83%)] Loss: -1792.793579\n",
      "    epoch          : 573\n",
      "    loss           : -1799.7825789541569\n",
      "    ess            : 8.001182754084748\n",
      "    log_marginal   : 1799.7825778025501\n",
      "    val_loss       : -1801.7712707519531\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1801.7712707519531\n",
      "Train Epoch: 574 [0/54000 (0%)] Loss: -1813.212158\n",
      "Train Epoch: 574 [11264/54000 (21%)] Loss: -1808.183105\n",
      "Train Epoch: 574 [22528/54000 (42%)] Loss: -1796.356201\n",
      "Train Epoch: 574 [33792/54000 (63%)] Loss: -1820.072021\n",
      "Train Epoch: 574 [45056/54000 (83%)] Loss: -1803.548462\n",
      "    epoch          : 574\n",
      "    loss           : -1802.4139830391362\n",
      "    ess            : 8.001182304238373\n",
      "    log_marginal   : 1802.4139830391362\n",
      "    val_loss       : -1804.0447184244792\n",
      "    val_ess        : 8.001182158788046\n",
      "    val_log_marginal: 1804.0447184244792\n",
      "Train Epoch: 575 [0/54000 (0%)] Loss: -1815.011719\n",
      "Train Epoch: 575 [11264/54000 (21%)] Loss: -1808.797363\n",
      "Train Epoch: 575 [22528/54000 (42%)] Loss: -1793.103149\n",
      "Train Epoch: 575 [33792/54000 (63%)] Loss: -1812.060059\n",
      "Train Epoch: 575 [45056/54000 (83%)] Loss: -1795.637451\n",
      "    epoch          : 575\n",
      "    loss           : -1798.5777357569282\n",
      "    ess            : 8.001182115302896\n",
      "    log_marginal   : 1798.5777357569282\n",
      "    val_loss       : -1800.359375\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1800.359375\n",
      "Train Epoch: 576 [0/54000 (0%)] Loss: -1814.712891\n",
      "Train Epoch: 576 [11264/54000 (21%)] Loss: -1799.432373\n",
      "Train Epoch: 576 [22528/54000 (42%)] Loss: -1789.048340\n",
      "Train Epoch: 576 [33792/54000 (63%)] Loss: -1812.434692\n",
      "Train Epoch: 576 [45056/54000 (83%)] Loss: -1791.056274\n",
      "    epoch          : 576\n",
      "    loss           : -1796.2120821970814\n",
      "    ess            : 8.001182943020227\n",
      "    log_marginal   : 1796.2120821970814\n",
      "    val_loss       : -1798.8479614257812\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1798.8479410807292\n",
      "Train Epoch: 577 [0/54000 (0%)] Loss: -1813.134766\n",
      "Train Epoch: 577 [11264/54000 (21%)] Loss: -1804.633789\n",
      "Train Epoch: 577 [22528/54000 (42%)] Loss: -1799.151245\n",
      "Train Epoch: 577 [33792/54000 (63%)] Loss: -1814.920166\n",
      "Train Epoch: 577 [45056/54000 (83%)] Loss: -1791.133179\n",
      "    epoch          : 577\n",
      "    loss           : -1797.1612042121167\n",
      "    ess            : 8.001182214269098\n",
      "    log_marginal   : 1797.1612042121167\n",
      "    val_loss       : -1799.0489705403645\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1799.0489501953125\n",
      "Train Epoch: 578 [0/54000 (0%)] Loss: -1808.478271\n",
      "Train Epoch: 578 [11264/54000 (21%)] Loss: -1807.111206\n",
      "Train Epoch: 578 [22528/54000 (42%)] Loss: -1793.184937\n",
      "Train Epoch: 578 [33792/54000 (63%)] Loss: -1804.506714\n",
      "Train Epoch: 578 [45056/54000 (83%)] Loss: -1784.819702\n",
      "    epoch          : 578\n",
      "    loss           : -1792.577670115345\n",
      "    ess            : 8.00118206132133\n",
      "    log_marginal   : 1792.5776712669517\n",
      "    val_loss       : -1787.2097269694011\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1787.2097269694011\n",
      "Train Epoch: 579 [0/54000 (0%)] Loss: -1798.609131\n",
      "Train Epoch: 579 [11264/54000 (21%)] Loss: -1802.381104\n",
      "Train Epoch: 579 [22528/54000 (42%)] Loss: -1798.093506\n",
      "Train Epoch: 579 [33792/54000 (63%)] Loss: -1805.541382\n",
      "Train Epoch: 579 [45056/54000 (83%)] Loss: -1788.884155\n",
      "    epoch          : 579\n",
      "    loss           : -1791.0943557451355\n",
      "    ess            : 8.001183734749848\n",
      "    log_marginal   : 1791.0943545935288\n",
      "    val_loss       : -1793.036641438802\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1793.036641438802\n",
      "Train Epoch: 580 [0/54000 (0%)] Loss: -1805.688721\n",
      "Train Epoch: 580 [11264/54000 (21%)] Loss: -1790.325806\n",
      "Train Epoch: 580 [22528/54000 (42%)] Loss: -1789.014160\n",
      "Train Epoch: 580 [33792/54000 (63%)] Loss: -1815.732178\n",
      "Train Epoch: 580 [45056/54000 (83%)] Loss: -1800.238281\n",
      "    epoch          : 580\n",
      "    loss           : -1795.744260392099\n",
      "    ess            : 8.001183680768284\n",
      "    log_marginal   : 1795.744260392099\n",
      "    val_loss       : -1805.0655314127605\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1805.0655314127605\n",
      "Train Epoch: 581 [0/54000 (0%)] Loss: -1816.837891\n",
      "Train Epoch: 581 [11264/54000 (21%)] Loss: -1804.921143\n",
      "Train Epoch: 581 [22528/54000 (42%)] Loss: -1794.775757\n",
      "Train Epoch: 581 [33792/54000 (63%)] Loss: -1810.755737\n",
      "Train Epoch: 581 [45056/54000 (83%)] Loss: -1796.491821\n",
      "    epoch          : 581\n",
      "    loss           : -1799.6407677992336\n",
      "    ess            : 8.001182583143127\n",
      "    log_marginal   : 1799.6407677992336\n",
      "    val_loss       : -1800.304931640625\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1800.304911295573\n",
      "Train Epoch: 582 [0/54000 (0%)] Loss: -1812.325439\n",
      "Train Epoch: 582 [11264/54000 (21%)] Loss: -1801.873291\n",
      "Train Epoch: 582 [22528/54000 (42%)] Loss: -1790.666016\n",
      "Train Epoch: 582 [33792/54000 (63%)] Loss: -1801.631226\n",
      "Train Epoch: 582 [45056/54000 (83%)] Loss: -1778.355469\n",
      "    epoch          : 582\n",
      "    loss           : -1789.428843372273\n",
      "    ess            : 8.001183671771356\n",
      "    log_marginal   : 1789.428843372273\n",
      "    val_loss       : -1784.6454569498699\n",
      "    val_ess        : 8.001184701919556\n",
      "    val_log_marginal: 1784.6454569498699\n",
      "Train Epoch: 583 [0/54000 (0%)] Loss: -1794.745361\n",
      "Train Epoch: 583 [11264/54000 (21%)] Loss: -1791.108643\n",
      "Train Epoch: 583 [22528/54000 (42%)] Loss: -1777.906494\n",
      "Train Epoch: 583 [33792/54000 (63%)] Loss: -1771.512939\n",
      "Train Epoch: 583 [45056/54000 (83%)] Loss: -1780.579834\n",
      "    epoch          : 583\n",
      "    loss           : -1776.066257692733\n",
      "    ess            : 8.001184832375005\n",
      "    log_marginal   : 1776.066257692733\n",
      "    val_loss       : -1777.4066975911458\n",
      "    val_ess        : 8.001185178756714\n",
      "    val_log_marginal: 1777.4066975911458\n",
      "Train Epoch: 584 [0/54000 (0%)] Loss: -1788.623047\n",
      "Train Epoch: 584 [11264/54000 (21%)] Loss: -1797.151733\n",
      "Train Epoch: 584 [22528/54000 (42%)] Loss: -1783.402100\n",
      "Train Epoch: 584 [33792/54000 (63%)] Loss: -1786.430664\n",
      "Train Epoch: 584 [45056/54000 (83%)] Loss: -1785.805664\n",
      "    epoch          : 584\n",
      "    loss           : -1782.3755884710347\n",
      "    ess            : 8.001184418516338\n",
      "    log_marginal   : 1782.3755907742482\n",
      "    val_loss       : -1784.5634358723958\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1784.5634358723958\n",
      "Train Epoch: 585 [0/54000 (0%)] Loss: -1798.412842\n",
      "Train Epoch: 585 [11264/54000 (21%)] Loss: -1799.237061\n",
      "Train Epoch: 585 [22528/54000 (42%)] Loss: -1783.993896\n",
      "Train Epoch: 585 [33792/54000 (63%)] Loss: -1801.544067\n",
      "Train Epoch: 585 [45056/54000 (83%)] Loss: -1792.568604\n",
      "    epoch          : 585\n",
      "    loss           : -1787.9310510023586\n",
      "    ess            : 8.001183023992574\n",
      "    log_marginal   : 1787.9310510023586\n",
      "    val_loss       : -1796.9068400065105\n",
      "    val_ess        : 8.001184622446695\n",
      "    val_log_marginal: 1796.9068400065105\n",
      "Train Epoch: 586 [0/54000 (0%)] Loss: -1809.333374\n",
      "Train Epoch: 586 [11264/54000 (21%)] Loss: -1806.176758\n",
      "Train Epoch: 586 [22528/54000 (42%)] Loss: -1798.069580\n",
      "Train Epoch: 586 [33792/54000 (63%)] Loss: -1812.388062\n",
      "Train Epoch: 586 [45056/54000 (83%)] Loss: -1783.915283\n",
      "    epoch          : 586\n",
      "    loss           : -1795.480162422612\n",
      "    ess            : 8.001181800410432\n",
      "    log_marginal   : 1795.480162422612\n",
      "    val_loss       : -1793.1067810058594\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1793.1067810058594\n",
      "Train Epoch: 587 [0/54000 (0%)] Loss: -1804.797119\n",
      "Train Epoch: 587 [11264/54000 (21%)] Loss: -1807.754395\n",
      "Train Epoch: 587 [22528/54000 (42%)] Loss: -1795.303711\n",
      "Train Epoch: 587 [33792/54000 (63%)] Loss: -1814.987305\n",
      "Train Epoch: 587 [45056/54000 (83%)] Loss: -1789.836914\n",
      "    epoch          : 587\n",
      "    loss           : -1796.6815864994842\n",
      "    ess            : 8.001182430195358\n",
      "    log_marginal   : 1796.6815864994842\n",
      "    val_loss       : -1804.5623677571614\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1804.5623575846355\n",
      "Train Epoch: 588 [0/54000 (0%)] Loss: -1816.526855\n",
      "Train Epoch: 588 [11264/54000 (21%)] Loss: -1812.888916\n",
      "Train Epoch: 588 [22528/54000 (42%)] Loss: -1795.290527\n",
      "Train Epoch: 588 [33792/54000 (63%)] Loss: -1815.071655\n",
      "Train Epoch: 588 [45056/54000 (83%)] Loss: -1795.235107\n",
      "    epoch          : 588\n",
      "    loss           : -1799.9099316866893\n",
      "    ess            : 8.001182034330547\n",
      "    log_marginal   : 1799.9099316866893\n",
      "    val_loss       : -1803.9496561686199\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1803.9496561686199\n",
      "Train Epoch: 589 [0/54000 (0%)] Loss: -1813.398926\n",
      "Train Epoch: 589 [11264/54000 (21%)] Loss: -1814.876709\n",
      "Train Epoch: 589 [22528/54000 (42%)] Loss: -1805.818237\n",
      "Train Epoch: 589 [33792/54000 (63%)] Loss: -1818.770508\n",
      "Train Epoch: 589 [45056/54000 (83%)] Loss: -1792.824219\n",
      "    epoch          : 589\n",
      "    loss           : -1801.84807773806\n",
      "    ess            : 8.001180810748407\n",
      "    log_marginal   : 1801.84807773806\n",
      "    val_loss       : -1798.2625223795574\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1798.2625223795574\n",
      "Train Epoch: 590 [0/54000 (0%)] Loss: -1807.838135\n",
      "Train Epoch: 590 [11264/54000 (21%)] Loss: -1814.620117\n",
      "Train Epoch: 590 [22528/54000 (42%)] Loss: -1795.851685\n",
      "Train Epoch: 590 [33792/54000 (63%)] Loss: -1814.401978\n",
      "Train Epoch: 590 [45056/54000 (83%)] Loss: -1795.016846\n",
      "    epoch          : 590\n",
      "    loss           : -1800.5955142614976\n",
      "    ess            : 8.001181440533331\n",
      "    log_marginal   : 1800.5955142614976\n",
      "    val_loss       : -1805.5973714192708\n",
      "    val_ess        : 8.001180410385132\n",
      "    val_log_marginal: 1805.5973815917969\n",
      "Train Epoch: 591 [0/54000 (0%)] Loss: -1817.752808\n",
      "Train Epoch: 591 [11264/54000 (21%)] Loss: -1817.424072\n",
      "Train Epoch: 591 [22528/54000 (42%)] Loss: -1798.422607\n",
      "Train Epoch: 591 [33792/54000 (63%)] Loss: -1811.248291\n",
      "Train Epoch: 591 [45056/54000 (83%)] Loss: -1790.800049\n",
      "    epoch          : 591\n",
      "    loss           : -1800.5672699550412\n",
      "    ess            : 8.001180162969625\n",
      "    log_marginal   : 1800.5672699550412\n",
      "    val_loss       : -1802.7877502441406\n",
      "    val_ess        : 8.001180171966553\n",
      "    val_log_marginal: 1802.7877807617188\n",
      "Train Epoch: 592 [0/54000 (0%)] Loss: -1812.359741\n",
      "Train Epoch: 592 [11264/54000 (21%)] Loss: -1812.545288\n",
      "Train Epoch: 592 [22528/54000 (42%)] Loss: -1800.443115\n",
      "Train Epoch: 592 [33792/54000 (63%)] Loss: -1818.988281\n",
      "Train Epoch: 592 [45056/54000 (83%)] Loss: -1793.903809\n",
      "    epoch          : 592\n",
      "    loss           : -1802.898458228921\n",
      "    ess            : 8.001181035671594\n",
      "    log_marginal   : 1802.8984570773143\n",
      "    val_loss       : -1805.6173909505208\n",
      "    val_ess        : 8.001181681950888\n",
      "    val_log_marginal: 1805.6173909505208\n",
      "Train Epoch: 593 [0/54000 (0%)] Loss: -1814.877686\n",
      "Train Epoch: 593 [11264/54000 (21%)] Loss: -1817.546265\n",
      "Train Epoch: 593 [22528/54000 (42%)] Loss: -1789.640137\n",
      "Train Epoch: 593 [33792/54000 (63%)] Loss: -1814.245117\n",
      "Train Epoch: 593 [45056/54000 (83%)] Loss: -1793.991699\n",
      "    epoch          : 593\n",
      "    loss           : -1798.979372420401\n",
      "    ess            : 8.001181458527187\n",
      "    log_marginal   : 1798.9793712687942\n",
      "    val_loss       : -1795.5934244791667\n",
      "    val_ess        : 8.001184542973837\n",
      "    val_log_marginal: 1795.5934244791667\n",
      "Train Epoch: 594 [0/54000 (0%)] Loss: -1806.194824\n",
      "Train Epoch: 594 [11264/54000 (21%)] Loss: -1806.282227\n",
      "Train Epoch: 594 [22528/54000 (42%)] Loss: -1796.328857\n",
      "Train Epoch: 594 [33792/54000 (63%)] Loss: -1815.676025\n",
      "Train Epoch: 594 [45056/54000 (83%)] Loss: -1793.301025\n",
      "    epoch          : 594\n",
      "    loss           : -1796.3731850678066\n",
      "    ess            : 8.001183311894255\n",
      "    log_marginal   : 1796.3731850678066\n",
      "    val_loss       : -1796.3575846354167\n",
      "    val_ess        : 8.001180410385132\n",
      "    val_log_marginal: 1796.3575948079426\n",
      "Train Epoch: 595 [0/54000 (0%)] Loss: -1804.496094\n",
      "Train Epoch: 595 [11264/54000 (21%)] Loss: -1815.625977\n",
      "Train Epoch: 595 [22528/54000 (42%)] Loss: -1797.960571\n",
      "Train Epoch: 595 [33792/54000 (63%)] Loss: -1814.348633\n",
      "Train Epoch: 595 [45056/54000 (83%)] Loss: -1796.833252\n",
      "    epoch          : 595\n",
      "    loss           : -1800.952686237839\n",
      "    ess            : 8.001182070318258\n",
      "    log_marginal   : 1800.952686237839\n",
      "    val_loss       : -1808.0775858561199\n",
      "    val_ess        : 8.001181523005167\n",
      "    val_log_marginal: 1808.0775858561199\n",
      "Train Epoch: 596 [0/54000 (0%)] Loss: -1819.500610\n",
      "Train Epoch: 596 [11264/54000 (21%)] Loss: -1821.019531\n",
      "Train Epoch: 596 [22528/54000 (42%)] Loss: -1800.914429\n",
      "Train Epoch: 596 [33792/54000 (63%)] Loss: -1814.894409\n",
      "Train Epoch: 596 [45056/54000 (83%)] Loss: -1788.035522\n",
      "    epoch          : 596\n",
      "    loss           : -1801.8826904296875\n",
      "    ess            : 8.001181422539478\n",
      "    log_marginal   : 1801.8826904296875\n",
      "    val_loss       : -1788.2046813964844\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1788.2046813964844\n",
      "Train Epoch: 597 [0/54000 (0%)] Loss: -1799.917603\n",
      "Train Epoch: 597 [11264/54000 (21%)] Loss: -1791.301270\n",
      "Train Epoch: 597 [22528/54000 (42%)] Loss: -1771.964355\n",
      "Train Epoch: 597 [33792/54000 (63%)] Loss: -1805.105957\n",
      "Train Epoch: 597 [45056/54000 (83%)] Loss: -1781.304443\n",
      "    epoch          : 597\n",
      "    loss           : -1783.6427566240418\n",
      "    ess            : 8.00118361778979\n",
      "    log_marginal   : 1783.642755472435\n",
      "    val_loss       : -1795.2237040201824\n",
      "    val_ess        : 8.001184225082397\n",
      "    val_log_marginal: 1795.2237243652344\n",
      "Train Epoch: 598 [0/54000 (0%)] Loss: -1803.776001\n",
      "Train Epoch: 598 [11264/54000 (21%)] Loss: -1796.752197\n",
      "Train Epoch: 598 [22528/54000 (42%)] Loss: -1775.887329\n",
      "Train Epoch: 598 [33792/54000 (63%)] Loss: -1804.175415\n",
      "Train Epoch: 598 [45056/54000 (83%)] Loss: -1768.267090\n",
      "    epoch          : 598\n",
      "    loss           : -1782.3228230026532\n",
      "    ess            : 8.001182808066314\n",
      "    log_marginal   : 1782.3228230026532\n",
      "    val_loss       : -1789.1482645670574\n",
      "    val_ess        : 8.001185496648153\n",
      "    val_log_marginal: 1789.1482645670574\n",
      "Train Epoch: 599 [0/54000 (0%)] Loss: -1803.323730\n",
      "Train Epoch: 599 [11264/54000 (21%)] Loss: -1806.699219\n",
      "Train Epoch: 599 [22528/54000 (42%)] Loss: -1793.466919\n",
      "Train Epoch: 599 [33792/54000 (63%)] Loss: -1813.568115\n",
      "Train Epoch: 599 [45056/54000 (83%)] Loss: -1782.970581\n",
      "    epoch          : 599\n",
      "    loss           : -1794.5523232514004\n",
      "    ess            : 8.001181332570201\n",
      "    log_marginal   : 1794.5523232514004\n",
      "    val_loss       : -1801.5897725423176\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1801.5897928873699\n",
      "Train Epoch: 600 [0/54000 (0%)] Loss: -1812.464844\n",
      "Train Epoch: 600 [11264/54000 (21%)] Loss: -1817.871216\n",
      "Train Epoch: 600 [22528/54000 (42%)] Loss: -1802.987061\n",
      "Train Epoch: 600 [33792/54000 (63%)] Loss: -1818.732666\n",
      "Train Epoch: 600 [45056/54000 (83%)] Loss: -1797.820557\n",
      "    epoch          : 600\n",
      "    loss           : -1803.6863599093456\n",
      "    ess            : 8.00117982108638\n",
      "    log_marginal   : 1803.6863599093456\n",
      "    val_loss       : -1805.9052734375\n",
      "    val_ess        : 8.001181443532309\n",
      "    val_log_marginal: 1805.9052836100261\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch600.pth ...\n",
      "Train Epoch: 601 [0/54000 (0%)] Loss: -1817.549805\n",
      "Train Epoch: 601 [11264/54000 (21%)] Loss: -1811.544189\n",
      "Train Epoch: 601 [22528/54000 (42%)] Loss: -1796.149170\n",
      "Train Epoch: 601 [33792/54000 (63%)] Loss: -1818.751587\n",
      "Train Epoch: 601 [45056/54000 (83%)] Loss: -1797.302368\n",
      "    epoch          : 601\n",
      "    loss           : -1801.672438135687\n",
      "    ess            : 8.001181962355128\n",
      "    log_marginal   : 1801.672438135687\n",
      "    val_loss       : -1805.2097473144531\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1805.2097473144531\n",
      "Train Epoch: 602 [0/54000 (0%)] Loss: -1818.199463\n",
      "Train Epoch: 602 [11264/54000 (21%)] Loss: -1805.712769\n",
      "Train Epoch: 602 [22528/54000 (42%)] Loss: -1793.238525\n",
      "Train Epoch: 602 [33792/54000 (63%)] Loss: -1816.823853\n",
      "Train Epoch: 602 [45056/54000 (83%)] Loss: -1793.170776\n",
      "    epoch          : 602\n",
      "    loss           : -1798.1153426260319\n",
      "    ess            : 8.001181818404287\n",
      "    log_marginal   : 1798.1153426260319\n",
      "    val_loss       : -1801.5989278157551\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1801.5989278157551\n",
      "Train Epoch: 603 [0/54000 (0%)] Loss: -1812.673584\n",
      "Train Epoch: 603 [11264/54000 (21%)] Loss: -1809.692749\n",
      "Train Epoch: 603 [22528/54000 (42%)] Loss: -1789.518555\n",
      "Train Epoch: 603 [33792/54000 (63%)] Loss: -1814.866211\n",
      "Train Epoch: 603 [45056/54000 (83%)] Loss: -1793.174683\n",
      "    epoch          : 603\n",
      "    loss           : -1797.5892748562794\n",
      "    ess            : 8.001181674453447\n",
      "    log_marginal   : 1797.5892748562794\n",
      "    val_loss       : -1800.5830688476562\n",
      "    val_ess        : 8.001181999842325\n",
      "    val_log_marginal: 1800.5830688476562\n",
      "Train Epoch: 604 [0/54000 (0%)] Loss: -1814.622559\n",
      "Train Epoch: 604 [11264/54000 (21%)] Loss: -1814.826416\n",
      "Train Epoch: 604 [22528/54000 (42%)] Loss: -1796.586914\n",
      "Train Epoch: 604 [33792/54000 (63%)] Loss: -1803.642944\n",
      "Train Epoch: 604 [45056/54000 (83%)] Loss: -1792.620850\n",
      "    epoch          : 604\n",
      "    loss           : -1797.9489135742188\n",
      "    ess            : 8.001180972693101\n",
      "    log_marginal   : 1797.948912422612\n",
      "    val_loss       : -1796.4601135253906\n",
      "    val_ess        : 8.001181443532309\n",
      "    val_log_marginal: 1796.4601135253906\n",
      "Train Epoch: 605 [0/54000 (0%)] Loss: -1808.703979\n",
      "Train Epoch: 605 [11264/54000 (21%)] Loss: -1814.187012\n",
      "Train Epoch: 605 [22528/54000 (42%)] Loss: -1794.628906\n",
      "Train Epoch: 605 [33792/54000 (63%)] Loss: -1814.486328\n",
      "Train Epoch: 605 [45056/54000 (83%)] Loss: -1783.839600\n",
      "    epoch          : 605\n",
      "    loss           : -1796.8660117095371\n",
      "    ess            : 8.00118105366545\n",
      "    log_marginal   : 1796.8660105579304\n",
      "    val_loss       : -1794.0894673665364\n",
      "    val_ess        : 8.001182079315186\n",
      "    val_log_marginal: 1794.0894673665364\n",
      "Train Epoch: 606 [0/54000 (0%)] Loss: -1805.574707\n",
      "Train Epoch: 606 [11264/54000 (21%)] Loss: -1808.397583\n",
      "Train Epoch: 606 [22528/54000 (42%)] Loss: -1781.505493\n",
      "Train Epoch: 606 [33792/54000 (63%)] Loss: -1815.165771\n",
      "Train Epoch: 606 [45056/54000 (83%)] Loss: -1794.474487\n",
      "    epoch          : 606\n",
      "    loss           : -1794.851206653523\n",
      "    ess            : 8.001181566490317\n",
      "    log_marginal   : 1794.851206653523\n",
      "    val_loss       : -1799.478983561198\n",
      "    val_ess        : 8.001180728276571\n",
      "    val_log_marginal: 1799.47900390625\n",
      "Train Epoch: 607 [0/54000 (0%)] Loss: -1812.958862\n",
      "Train Epoch: 607 [11264/54000 (21%)] Loss: -1809.514404\n",
      "Train Epoch: 607 [22528/54000 (42%)] Loss: -1788.880615\n",
      "Train Epoch: 607 [33792/54000 (63%)] Loss: -1814.014404\n",
      "Train Epoch: 607 [45056/54000 (83%)] Loss: -1790.971313\n",
      "    epoch          : 607\n",
      "    loss           : -1798.0028767135907\n",
      "    ess            : 8.00117967713554\n",
      "    log_marginal   : 1798.0028767135907\n",
      "    val_loss       : -1803.1081848144531\n",
      "    val_ess        : 8.001178900400797\n",
      "    val_log_marginal: 1803.1081848144531\n",
      "Train Epoch: 608 [0/54000 (0%)] Loss: -1815.546387\n",
      "Train Epoch: 608 [11264/54000 (21%)] Loss: -1812.405762\n",
      "Train Epoch: 608 [22528/54000 (42%)] Loss: -1798.110352\n",
      "Train Epoch: 608 [33792/54000 (63%)] Loss: -1813.059570\n",
      "Train Epoch: 608 [45056/54000 (83%)] Loss: -1779.832764\n",
      "    epoch          : 608\n",
      "    loss           : -1796.6944752819134\n",
      "    ess            : 8.001181098650086\n",
      "    log_marginal   : 1796.6944752819134\n",
      "    val_loss       : -1793.3626403808594\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1793.3626403808594\n",
      "Train Epoch: 609 [0/54000 (0%)] Loss: -1806.208496\n",
      "Train Epoch: 609 [11264/54000 (21%)] Loss: -1796.272705\n",
      "Train Epoch: 609 [22528/54000 (42%)] Loss: -1782.140259\n",
      "Train Epoch: 609 [33792/54000 (63%)] Loss: -1813.827026\n",
      "Train Epoch: 609 [45056/54000 (83%)] Loss: -1790.095215\n",
      "    epoch          : 609\n",
      "    loss           : -1790.774091612618\n",
      "    ess            : 8.001184175599295\n",
      "    log_marginal   : 1790.774091612618\n",
      "    val_loss       : -1795.9300231933594\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1795.9300231933594\n",
      "Train Epoch: 610 [0/54000 (0%)] Loss: -1809.513184\n",
      "Train Epoch: 610 [11264/54000 (21%)] Loss: -1803.940063\n",
      "Train Epoch: 610 [22528/54000 (42%)] Loss: -1790.809937\n",
      "Train Epoch: 610 [33792/54000 (63%)] Loss: -1809.791138\n",
      "Train Epoch: 610 [45056/54000 (83%)] Loss: -1795.877441\n",
      "    epoch          : 610\n",
      "    loss           : -1795.0453306953862\n",
      "    ess            : 8.001183212928051\n",
      "    log_marginal   : 1795.0453306953862\n",
      "    val_loss       : -1805.724365234375\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1805.724365234375\n",
      "Train Epoch: 611 [0/54000 (0%)] Loss: -1819.925781\n",
      "Train Epoch: 611 [11264/54000 (21%)] Loss: -1814.707031\n",
      "Train Epoch: 611 [22528/54000 (42%)] Loss: -1798.404541\n",
      "Train Epoch: 611 [33792/54000 (63%)] Loss: -1818.819092\n",
      "Train Epoch: 611 [45056/54000 (83%)] Loss: -1798.188965\n",
      "    epoch          : 611\n",
      "    loss           : -1802.6852013929836\n",
      "    ess            : 8.001181035671594\n",
      "    log_marginal   : 1802.6852013929836\n",
      "    val_loss       : -1806.7561543782551\n",
      "    val_ess        : 8.001181046168009\n",
      "    val_log_marginal: 1806.7561543782551\n",
      "Train Epoch: 612 [0/54000 (0%)] Loss: -1817.999512\n",
      "Train Epoch: 612 [11264/54000 (21%)] Loss: -1817.905273\n",
      "Train Epoch: 612 [22528/54000 (42%)] Loss: -1800.195312\n",
      "Train Epoch: 612 [33792/54000 (63%)] Loss: -1816.556885\n",
      "Train Epoch: 612 [45056/54000 (83%)] Loss: -1799.283691\n",
      "    epoch          : 612\n",
      "    loss           : -1803.8913885152565\n",
      "    ess            : 8.001181305579419\n",
      "    log_marginal   : 1803.8913896668632\n",
      "    val_loss       : -1805.7639261881511\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1805.7639261881511\n",
      "Train Epoch: 613 [0/54000 (0%)] Loss: -1814.881714\n",
      "Train Epoch: 613 [11264/54000 (21%)] Loss: -1820.717285\n",
      "Train Epoch: 613 [22528/54000 (42%)] Loss: -1795.561279\n",
      "Train Epoch: 613 [33792/54000 (63%)] Loss: -1806.576538\n",
      "Train Epoch: 613 [45056/54000 (83%)] Loss: -1790.098145\n",
      "    epoch          : 613\n",
      "    loss           : -1799.7650687739533\n",
      "    ess            : 8.001180873726899\n",
      "    log_marginal   : 1799.76506992556\n",
      "    val_loss       : -1802.7995096842449\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1802.7995096842449\n",
      "Train Epoch: 614 [0/54000 (0%)] Loss: -1813.804443\n",
      "Train Epoch: 614 [11264/54000 (21%)] Loss: -1813.430908\n",
      "Train Epoch: 614 [22528/54000 (42%)] Loss: -1796.079834\n",
      "Train Epoch: 614 [33792/54000 (63%)] Loss: -1821.186890\n",
      "Train Epoch: 614 [45056/54000 (83%)] Loss: -1801.191895\n",
      "    epoch          : 614\n",
      "    loss           : -1802.9031475714917\n",
      "    ess            : 8.001182088312113\n",
      "    log_marginal   : 1802.9031475714917\n",
      "    val_loss       : -1809.8816630045574\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1809.8816630045574\n",
      "Train Epoch: 615 [0/54000 (0%)] Loss: -1822.055176\n",
      "Train Epoch: 615 [11264/54000 (21%)] Loss: -1816.827637\n",
      "Train Epoch: 615 [22528/54000 (42%)] Loss: -1796.932373\n",
      "Train Epoch: 615 [33792/54000 (63%)] Loss: -1815.341309\n",
      "Train Epoch: 615 [45056/54000 (83%)] Loss: -1795.526733\n",
      "    epoch          : 615\n",
      "    loss           : -1802.7598646631782\n",
      "    ess            : 8.001181143634724\n",
      "    log_marginal   : 1802.7598658147847\n",
      "    val_loss       : -1802.1362406412761\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1802.1362406412761\n",
      "Train Epoch: 616 [0/54000 (0%)] Loss: -1810.900146\n",
      "Train Epoch: 616 [11264/54000 (21%)] Loss: -1790.730347\n",
      "Train Epoch: 616 [22528/54000 (42%)] Loss: -1767.792236\n",
      "Train Epoch: 616 [33792/54000 (63%)] Loss: -1781.846191\n",
      "Train Epoch: 616 [45056/54000 (83%)] Loss: -1768.956543\n",
      "    epoch          : 616\n",
      "    loss           : -1771.9687569096404\n",
      "    ess            : 8.001183482835877\n",
      "    log_marginal   : 1771.9687569096404\n",
      "    val_loss       : -1770.3053792317708\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1770.3053792317708\n",
      "Train Epoch: 617 [0/54000 (0%)] Loss: -1777.423340\n",
      "Train Epoch: 617 [11264/54000 (21%)] Loss: -1797.614502\n",
      "Train Epoch: 617 [22528/54000 (42%)] Loss: -1783.875488\n",
      "Train Epoch: 617 [33792/54000 (63%)] Loss: -1808.820312\n",
      "Train Epoch: 617 [45056/54000 (83%)] Loss: -1787.668579\n",
      "    epoch          : 617\n",
      "    loss           : -1785.0618481905956\n",
      "    ess            : 8.001183734749848\n",
      "    log_marginal   : 1785.0618481905956\n",
      "    val_loss       : -1789.1837158203125\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1789.1837158203125\n",
      "Train Epoch: 618 [0/54000 (0%)] Loss: -1796.834717\n",
      "Train Epoch: 618 [11264/54000 (21%)] Loss: -1808.634888\n",
      "Train Epoch: 618 [22528/54000 (42%)] Loss: -1797.734253\n",
      "Train Epoch: 618 [33792/54000 (63%)] Loss: -1816.881104\n",
      "Train Epoch: 618 [45056/54000 (83%)] Loss: -1797.392090\n",
      "    epoch          : 618\n",
      "    loss           : -1797.851637354437\n",
      "    ess            : 8.001181764422723\n",
      "    log_marginal   : 1797.851637354437\n",
      "    val_loss       : -1804.4287414550781\n",
      "    val_ess        : 8.001182079315186\n",
      "    val_log_marginal: 1804.4287414550781\n",
      "Train Epoch: 619 [0/54000 (0%)] Loss: -1812.495361\n",
      "Train Epoch: 619 [11264/54000 (21%)] Loss: -1816.512695\n",
      "Train Epoch: 619 [22528/54000 (42%)] Loss: -1803.982422\n",
      "Train Epoch: 619 [33792/54000 (63%)] Loss: -1815.249756\n",
      "Train Epoch: 619 [45056/54000 (83%)] Loss: -1792.985352\n",
      "    epoch          : 619\n",
      "    loss           : -1801.6198557727741\n",
      "    ess            : 8.0011823132353\n",
      "    log_marginal   : 1801.6198546211674\n",
      "    val_loss       : -1804.2008768717449\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1804.2008768717449\n",
      "Train Epoch: 620 [0/54000 (0%)] Loss: -1813.851318\n",
      "Train Epoch: 620 [11264/54000 (21%)] Loss: -1816.530151\n",
      "Train Epoch: 620 [22528/54000 (42%)] Loss: -1790.288086\n",
      "Train Epoch: 620 [33792/54000 (63%)] Loss: -1817.792969\n",
      "Train Epoch: 620 [45056/54000 (83%)] Loss: -1781.011841\n",
      "    epoch          : 620\n",
      "    loss           : -1797.5277951798348\n",
      "    ess            : 8.001182952017155\n",
      "    log_marginal   : 1797.5277951798348\n",
      "    val_loss       : -1789.8948059082031\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1789.8947855631511\n",
      "Train Epoch: 621 [0/54000 (0%)] Loss: -1799.842773\n",
      "Train Epoch: 621 [11264/54000 (21%)] Loss: -1804.569336\n",
      "Train Epoch: 621 [22528/54000 (42%)] Loss: -1776.627197\n",
      "Train Epoch: 621 [33792/54000 (63%)] Loss: -1808.280518\n",
      "Train Epoch: 621 [45056/54000 (83%)] Loss: -1794.528809\n",
      "    epoch          : 621\n",
      "    loss           : -1792.9003215285968\n",
      "    ess            : 8.001183320891183\n",
      "    log_marginal   : 1792.9003215285968\n",
      "    val_loss       : -1802.4248453776042\n",
      "    val_ess        : 8.001183986663818\n",
      "    val_log_marginal: 1802.4248453776042\n",
      "Train Epoch: 622 [0/54000 (0%)] Loss: -1814.929443\n",
      "Train Epoch: 622 [11264/54000 (21%)] Loss: -1812.702881\n",
      "Train Epoch: 622 [22528/54000 (42%)] Loss: -1798.305176\n",
      "Train Epoch: 622 [33792/54000 (63%)] Loss: -1821.714355\n",
      "Train Epoch: 622 [45056/54000 (83%)] Loss: -1800.942627\n",
      "    epoch          : 622\n",
      "    loss           : -1804.8305030678803\n",
      "    ess            : 8.001180540840581\n",
      "    log_marginal   : 1804.8305030678803\n",
      "    val_loss       : -1811.0694478352864\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1811.0694376627605\n",
      "Train Epoch: 623 [0/54000 (0%)] Loss: -1821.361084\n",
      "Train Epoch: 623 [11264/54000 (21%)] Loss: -1818.789062\n",
      "Train Epoch: 623 [22528/54000 (42%)] Loss: -1800.968506\n",
      "Train Epoch: 623 [33792/54000 (63%)] Loss: -1822.968018\n",
      "Train Epoch: 623 [45056/54000 (83%)] Loss: -1796.210205\n",
      "    epoch          : 623\n",
      "    loss           : -1805.2473340304393\n",
      "    ess            : 8.001181089653159\n",
      "    log_marginal   : 1805.2473340304393\n",
      "    val_loss       : -1805.0683492024739\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1805.0683695475261\n",
      "Train Epoch: 624 [0/54000 (0%)] Loss: -1818.186401\n",
      "Train Epoch: 624 [11264/54000 (21%)] Loss: -1808.470947\n",
      "Train Epoch: 624 [22528/54000 (42%)] Loss: -1800.861328\n",
      "Train Epoch: 624 [33792/54000 (63%)] Loss: -1820.439453\n",
      "Train Epoch: 624 [45056/54000 (83%)] Loss: -1792.880371\n",
      "    epoch          : 624\n",
      "    loss           : -1800.957768278302\n",
      "    ess            : 8.001181188619361\n",
      "    log_marginal   : 1800.957768278302\n",
      "    val_loss       : -1802.0613911946614\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1802.0613911946614\n",
      "Train Epoch: 625 [0/54000 (0%)] Loss: -1814.701416\n",
      "Train Epoch: 625 [11264/54000 (21%)] Loss: -1812.221436\n",
      "Train Epoch: 625 [22528/54000 (42%)] Loss: -1802.560547\n",
      "Train Epoch: 625 [33792/54000 (63%)] Loss: -1820.046143\n",
      "Train Epoch: 625 [45056/54000 (83%)] Loss: -1799.936279\n",
      "    epoch          : 625\n",
      "    loss           : -1803.7110135060436\n",
      "    ess            : 8.001180774760696\n",
      "    log_marginal   : 1803.7110135060436\n",
      "    val_loss       : -1806.9744466145833\n",
      "    val_ess        : 8.001180410385132\n",
      "    val_log_marginal: 1806.9744466145833\n",
      "Train Epoch: 626 [0/54000 (0%)] Loss: -1819.837036\n",
      "Train Epoch: 626 [11264/54000 (21%)] Loss: -1814.156982\n",
      "Train Epoch: 626 [22528/54000 (42%)] Loss: -1794.002930\n",
      "Train Epoch: 626 [33792/54000 (63%)] Loss: -1809.675781\n",
      "Train Epoch: 626 [45056/54000 (83%)] Loss: -1795.797607\n",
      "    epoch          : 626\n",
      "    loss           : -1799.9237820607311\n",
      "    ess            : 8.00118144953026\n",
      "    log_marginal   : 1799.9237820607311\n",
      "    val_loss       : -1803.6754760742188\n",
      "    val_ess        : 8.001181364059448\n",
      "    val_log_marginal: 1803.6754659016926\n",
      "Train Epoch: 627 [0/54000 (0%)] Loss: -1816.056396\n",
      "Train Epoch: 627 [11264/54000 (21%)] Loss: -1816.882568\n",
      "Train Epoch: 627 [22528/54000 (42%)] Loss: -1797.902344\n",
      "Train Epoch: 627 [33792/54000 (63%)] Loss: -1799.180420\n",
      "Train Epoch: 627 [45056/54000 (83%)] Loss: -1791.621582\n",
      "    epoch          : 627\n",
      "    loss           : -1798.260129532724\n",
      "    ess            : 8.001181332570201\n",
      "    log_marginal   : 1798.260129532724\n",
      "    val_loss       : -1798.5788269042969\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1798.5788167317708\n",
      "Train Epoch: 628 [0/54000 (0%)] Loss: -1810.732178\n",
      "Train Epoch: 628 [11264/54000 (21%)] Loss: -1811.357056\n",
      "Train Epoch: 628 [22528/54000 (42%)] Loss: -1785.664307\n",
      "Train Epoch: 628 [33792/54000 (63%)] Loss: -1814.281494\n",
      "Train Epoch: 628 [45056/54000 (83%)] Loss: -1800.520874\n",
      "    epoch          : 628\n",
      "    loss           : -1798.473988658977\n",
      "    ess            : 8.00118173743194\n",
      "    log_marginal   : 1798.473988658977\n",
      "    val_loss       : -1801.3319091796875\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1801.3319295247395\n",
      "Train Epoch: 629 [0/54000 (0%)] Loss: -1810.877563\n",
      "Train Epoch: 629 [11264/54000 (21%)] Loss: -1814.229004\n",
      "Train Epoch: 629 [22528/54000 (42%)] Loss: -1789.111816\n",
      "Train Epoch: 629 [33792/54000 (63%)] Loss: -1819.744751\n",
      "Train Epoch: 629 [45056/54000 (83%)] Loss: -1800.358398\n",
      "    epoch          : 629\n",
      "    loss           : -1801.4532136737175\n",
      "    ess            : 8.00118202533362\n",
      "    log_marginal   : 1801.4532136737175\n",
      "    val_loss       : -1805.2437540690105\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1805.2437642415364\n",
      "Train Epoch: 630 [0/54000 (0%)] Loss: -1813.000122\n",
      "Train Epoch: 630 [11264/54000 (21%)] Loss: -1815.137695\n",
      "Train Epoch: 630 [22528/54000 (42%)] Loss: -1795.796143\n",
      "Train Epoch: 630 [33792/54000 (63%)] Loss: -1817.753418\n",
      "Train Epoch: 630 [45056/54000 (83%)] Loss: -1794.015381\n",
      "    epoch          : 630\n",
      "    loss           : -1800.5131029812794\n",
      "    ess            : 8.001180765763769\n",
      "    log_marginal   : 1800.5131029812794\n",
      "    val_loss       : -1797.7859598795574\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1797.7859598795574\n",
      "Train Epoch: 631 [0/54000 (0%)] Loss: -1808.016357\n",
      "Train Epoch: 631 [11264/54000 (21%)] Loss: -1810.403320\n",
      "Train Epoch: 631 [22528/54000 (42%)] Loss: -1797.627441\n",
      "Train Epoch: 631 [33792/54000 (63%)] Loss: -1815.549438\n",
      "Train Epoch: 631 [45056/54000 (83%)] Loss: -1788.436523\n",
      "    epoch          : 631\n",
      "    loss           : -1797.8877713185436\n",
      "    ess            : 8.00118148551797\n",
      "    log_marginal   : 1797.8877724701504\n",
      "    val_loss       : -1798.8987731933594\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1798.8987731933594\n",
      "Train Epoch: 632 [0/54000 (0%)] Loss: -1811.520264\n",
      "Train Epoch: 632 [11264/54000 (21%)] Loss: -1812.237793\n",
      "Train Epoch: 632 [22528/54000 (42%)] Loss: -1796.612549\n",
      "Train Epoch: 632 [33792/54000 (63%)] Loss: -1815.559937\n",
      "Train Epoch: 632 [45056/54000 (83%)] Loss: -1787.092529\n",
      "    epoch          : 632\n",
      "    loss           : -1799.631658590065\n",
      "    ess            : 8.001181368557912\n",
      "    log_marginal   : 1799.631658590065\n",
      "    val_loss       : -1808.357421875\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1808.357421875\n",
      "Train Epoch: 633 [0/54000 (0%)] Loss: -1818.570312\n",
      "Train Epoch: 633 [11264/54000 (21%)] Loss: -1821.102051\n",
      "Train Epoch: 633 [22528/54000 (42%)] Loss: -1803.024536\n",
      "Train Epoch: 633 [33792/54000 (63%)] Loss: -1822.277100\n",
      "Train Epoch: 633 [45056/54000 (83%)] Loss: -1792.001953\n",
      "    epoch          : 633\n",
      "    loss           : -1804.7113647460938\n",
      "    ess            : 8.00117978509867\n",
      "    log_marginal   : 1804.7113647460938\n",
      "    val_loss       : -1794.9791259765625\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1794.9791259765625\n",
      "Train Epoch: 634 [0/54000 (0%)] Loss: -1807.664429\n",
      "Train Epoch: 634 [11264/54000 (21%)] Loss: -1781.130859\n",
      "Train Epoch: 634 [22528/54000 (42%)] Loss: -1763.213867\n",
      "Train Epoch: 634 [33792/54000 (63%)] Loss: -1781.156250\n",
      "Train Epoch: 634 [45056/54000 (83%)] Loss: -1776.388672\n",
      "    epoch          : 634\n",
      "    loss           : -1774.375517071418\n",
      "    ess            : 8.001184337543991\n",
      "    log_marginal   : 1774.3755182230248\n",
      "    val_loss       : -1795.7046915690105\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1795.7046813964844\n",
      "Train Epoch: 635 [0/54000 (0%)] Loss: -1805.713257\n",
      "Train Epoch: 635 [11264/54000 (21%)] Loss: -1796.310425\n",
      "Train Epoch: 635 [22528/54000 (42%)] Loss: -1779.394287\n",
      "Train Epoch: 635 [33792/54000 (63%)] Loss: -1795.669312\n",
      "Train Epoch: 635 [45056/54000 (83%)] Loss: -1789.282471\n",
      "    epoch          : 635\n",
      "    loss           : -1788.3768644512825\n",
      "    ess            : 8.001183338885037\n",
      "    log_marginal   : 1788.3768644512825\n",
      "    val_loss       : -1801.5936381022136\n",
      "    val_ess        : 8.001181999842325\n",
      "    val_log_marginal: 1801.5936381022136\n",
      "Train Epoch: 636 [0/54000 (0%)] Loss: -1813.634766\n",
      "Train Epoch: 636 [11264/54000 (21%)] Loss: -1807.267090\n",
      "Train Epoch: 636 [22528/54000 (42%)] Loss: -1796.752441\n",
      "Train Epoch: 636 [33792/54000 (63%)] Loss: -1813.178467\n",
      "Train Epoch: 636 [45056/54000 (83%)] Loss: -1788.623047\n",
      "    epoch          : 636\n",
      "    loss           : -1796.8085626566185\n",
      "    ess            : 8.001181539499536\n",
      "    log_marginal   : 1796.8085638082252\n",
      "    val_loss       : -1796.4981994628906\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1796.4981994628906\n",
      "Train Epoch: 637 [0/54000 (0%)] Loss: -1807.622070\n",
      "Train Epoch: 637 [11264/54000 (21%)] Loss: -1807.971680\n",
      "Train Epoch: 637 [22528/54000 (42%)] Loss: -1799.323730\n",
      "Train Epoch: 637 [33792/54000 (63%)] Loss: -1814.035400\n",
      "Train Epoch: 637 [45056/54000 (83%)] Loss: -1800.320312\n",
      "    epoch          : 637\n",
      "    loss           : -1800.8348872346698\n",
      "    ess            : 8.001182583143127\n",
      "    log_marginal   : 1800.8348872346698\n",
      "    val_loss       : -1798.2407836914062\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1798.2407836914062\n",
      "Train Epoch: 638 [0/54000 (0%)] Loss: -1809.734131\n",
      "Train Epoch: 638 [11264/54000 (21%)] Loss: -1801.169922\n",
      "Train Epoch: 638 [22528/54000 (42%)] Loss: -1792.791260\n",
      "Train Epoch: 638 [33792/54000 (63%)] Loss: -1812.898926\n",
      "Train Epoch: 638 [45056/54000 (83%)] Loss: -1795.824341\n",
      "    epoch          : 638\n",
      "    loss           : -1798.2479628077094\n",
      "    ess            : 8.001183158946487\n",
      "    log_marginal   : 1798.247963959316\n",
      "    val_loss       : -1806.3014322916667\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1806.3014322916667\n",
      "Train Epoch: 639 [0/54000 (0%)] Loss: -1820.498779\n",
      "Train Epoch: 639 [11264/54000 (21%)] Loss: -1817.392090\n",
      "Train Epoch: 639 [22528/54000 (42%)] Loss: -1801.411865\n",
      "Train Epoch: 639 [33792/54000 (63%)] Loss: -1816.569214\n",
      "Train Epoch: 639 [45056/54000 (83%)] Loss: -1793.910522\n",
      "    epoch          : 639\n",
      "    loss           : -1802.897105091023\n",
      "    ess            : 8.00118162946881\n",
      "    log_marginal   : 1802.897105091023\n",
      "    val_loss       : -1800.087137858073\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1800.087137858073\n",
      "Train Epoch: 640 [0/54000 (0%)] Loss: -1812.938232\n",
      "Train Epoch: 640 [11264/54000 (21%)] Loss: -1816.438110\n",
      "Train Epoch: 640 [22528/54000 (42%)] Loss: -1803.173096\n",
      "Train Epoch: 640 [33792/54000 (63%)] Loss: -1823.724609\n",
      "Train Epoch: 640 [45056/54000 (83%)] Loss: -1801.397339\n",
      "    epoch          : 640\n",
      "    loss           : -1806.2177930148143\n",
      "    ess            : 8.00118090971461\n",
      "    log_marginal   : 1806.2177930148143\n",
      "    val_loss       : -1807.9795532226562\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1807.9795532226562\n",
      "Train Epoch: 641 [0/54000 (0%)] Loss: -1816.303345\n",
      "Train Epoch: 641 [11264/54000 (21%)] Loss: -1811.711914\n",
      "Train Epoch: 641 [22528/54000 (42%)] Loss: -1793.682983\n",
      "Train Epoch: 641 [33792/54000 (63%)] Loss: -1818.437866\n",
      "Train Epoch: 641 [45056/54000 (83%)] Loss: -1793.258911\n",
      "    epoch          : 641\n",
      "    loss           : -1799.7539235241009\n",
      "    ess            : 8.001182430195358\n",
      "    log_marginal   : 1799.7539246757076\n",
      "    val_loss       : -1806.1543070475261\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1806.1543070475261\n",
      "Train Epoch: 642 [0/54000 (0%)] Loss: -1817.307251\n",
      "Train Epoch: 642 [11264/54000 (21%)] Loss: -1819.210205\n",
      "Train Epoch: 642 [22528/54000 (42%)] Loss: -1808.272095\n",
      "Train Epoch: 642 [33792/54000 (63%)] Loss: -1802.830688\n",
      "Train Epoch: 642 [45056/54000 (83%)] Loss: -1787.515137\n",
      "    epoch          : 642\n",
      "    loss           : -1800.9434077424823\n",
      "    ess            : 8.001180873726899\n",
      "    log_marginal   : 1800.9434065908756\n",
      "    val_loss       : -1800.1726481119792\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1800.1726481119792\n",
      "Train Epoch: 643 [0/54000 (0%)] Loss: -1810.432617\n",
      "Train Epoch: 643 [11264/54000 (21%)] Loss: -1814.288208\n",
      "Train Epoch: 643 [22528/54000 (42%)] Loss: -1805.049316\n",
      "Train Epoch: 643 [33792/54000 (63%)] Loss: -1820.805542\n",
      "Train Epoch: 643 [45056/54000 (83%)] Loss: -1802.242432\n",
      "    epoch          : 643\n",
      "    loss           : -1805.4994691093013\n",
      "    ess            : 8.00118144953026\n",
      "    log_marginal   : 1805.4994691093013\n",
      "    val_loss       : -1808.83837890625\n",
      "    val_ess        : 8.001181046168009\n",
      "    val_log_marginal: 1808.8383890787761\n",
      "Train Epoch: 644 [0/54000 (0%)] Loss: -1820.581055\n",
      "Train Epoch: 644 [11264/54000 (21%)] Loss: -1816.465332\n",
      "Train Epoch: 644 [22528/54000 (42%)] Loss: -1795.921997\n",
      "Train Epoch: 644 [33792/54000 (63%)] Loss: -1810.511963\n",
      "Train Epoch: 644 [45056/54000 (83%)] Loss: -1794.867065\n",
      "    epoch          : 644\n",
      "    loss           : -1800.0605526330337\n",
      "    ess            : 8.00118126959171\n",
      "    log_marginal   : 1800.0605537846404\n",
      "    val_loss       : -1805.7467244466145\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1805.7467244466145\n",
      "Train Epoch: 645 [0/54000 (0%)] Loss: -1817.216187\n",
      "Train Epoch: 645 [11264/54000 (21%)] Loss: -1816.410156\n",
      "Train Epoch: 645 [22528/54000 (42%)] Loss: -1804.235474\n",
      "Train Epoch: 645 [33792/54000 (63%)] Loss: -1823.068481\n",
      "Train Epoch: 645 [45056/54000 (83%)] Loss: -1790.744263\n",
      "    epoch          : 645\n",
      "    loss           : -1802.5214532816185\n",
      "    ess            : 8.001179776101742\n",
      "    log_marginal   : 1802.5214532816185\n",
      "    val_loss       : -1793.3622741699219\n",
      "    val_ess        : 8.001182158788046\n",
      "    val_log_marginal: 1793.3622741699219\n",
      "Train Epoch: 646 [0/54000 (0%)] Loss: -1807.615723\n",
      "Train Epoch: 646 [11264/54000 (21%)] Loss: -1810.553833\n",
      "Train Epoch: 646 [22528/54000 (42%)] Loss: -1803.585449\n",
      "Train Epoch: 646 [33792/54000 (63%)] Loss: -1822.761719\n",
      "Train Epoch: 646 [45056/54000 (83%)] Loss: -1799.895020\n",
      "    epoch          : 646\n",
      "    loss           : -1802.6911436836674\n",
      "    ess            : 8.001179974034148\n",
      "    log_marginal   : 1802.6911448352741\n",
      "    val_loss       : -1802.5935668945312\n",
      "    val_ess        : 8.001182079315186\n",
      "    val_log_marginal: 1802.5935668945312\n",
      "Train Epoch: 647 [0/54000 (0%)] Loss: -1815.752197\n",
      "Train Epoch: 647 [11264/54000 (21%)] Loss: -1813.622314\n",
      "Train Epoch: 647 [22528/54000 (42%)] Loss: -1803.951904\n",
      "Train Epoch: 647 [33792/54000 (63%)] Loss: -1807.274658\n",
      "Train Epoch: 647 [45056/54000 (83%)] Loss: -1786.163696\n",
      "    epoch          : 647\n",
      "    loss           : -1797.798666900059\n",
      "    ess            : 8.001181098650086\n",
      "    log_marginal   : 1797.798666900059\n",
      "    val_loss       : -1799.4738667805989\n",
      "    val_ess        : 8.001185735066732\n",
      "    val_log_marginal: 1799.4738667805989\n",
      "Train Epoch: 648 [0/54000 (0%)] Loss: -1806.035156\n",
      "Train Epoch: 648 [11264/54000 (21%)] Loss: -1801.916748\n",
      "Train Epoch: 648 [22528/54000 (42%)] Loss: -1795.868896\n",
      "Train Epoch: 648 [33792/54000 (63%)] Loss: -1816.902954\n",
      "Train Epoch: 648 [45056/54000 (83%)] Loss: -1800.573730\n",
      "    epoch          : 648\n",
      "    loss           : -1799.4598192898732\n",
      "    ess            : 8.001181782416577\n",
      "    log_marginal   : 1799.4598192898732\n",
      "    val_loss       : -1807.1233825683594\n",
      "    val_ess        : 8.001181920369467\n",
      "    val_log_marginal: 1807.1233825683594\n",
      "Train Epoch: 649 [0/54000 (0%)] Loss: -1815.442871\n",
      "Train Epoch: 649 [11264/54000 (21%)] Loss: -1809.573730\n",
      "Train Epoch: 649 [22528/54000 (42%)] Loss: -1794.395264\n",
      "Train Epoch: 649 [33792/54000 (63%)] Loss: -1807.970703\n",
      "Train Epoch: 649 [45056/54000 (83%)] Loss: -1797.457764\n",
      "    epoch          : 649\n",
      "    loss           : -1798.4007533811173\n",
      "    ess            : 8.001179875067944\n",
      "    log_marginal   : 1798.4007533811173\n",
      "    val_loss       : -1799.9136759440105\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1799.9136962890625\n",
      "Train Epoch: 650 [0/54000 (0%)] Loss: -1809.053589\n",
      "Train Epoch: 650 [11264/54000 (21%)] Loss: -1799.092896\n",
      "Train Epoch: 650 [22528/54000 (42%)] Loss: -1785.217896\n",
      "Train Epoch: 650 [33792/54000 (63%)] Loss: -1786.265991\n",
      "Train Epoch: 650 [45056/54000 (83%)] Loss: -1774.273682\n",
      "    epoch          : 650\n",
      "    loss           : -1783.4831370227741\n",
      "    ess            : 8.001183221924979\n",
      "    log_marginal   : 1783.4831393259876\n",
      "    val_loss       : -1788.0118713378906\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1788.0118713378906\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch650.pth ...\n",
      "Train Epoch: 651 [0/54000 (0%)] Loss: -1801.491943\n",
      "Train Epoch: 651 [11264/54000 (21%)] Loss: -1804.914551\n",
      "Train Epoch: 651 [22528/54000 (42%)] Loss: -1777.853760\n",
      "Train Epoch: 651 [33792/54000 (63%)] Loss: -1808.458008\n",
      "Train Epoch: 651 [45056/54000 (83%)] Loss: -1781.379517\n",
      "    epoch          : 651\n",
      "    loss           : -1789.298100309552\n",
      "    ess            : 8.001182196275243\n",
      "    log_marginal   : 1789.298100309552\n",
      "    val_loss       : -1790.8662821451824\n",
      "    val_ess        : 8.001182874043783\n",
      "    val_log_marginal: 1790.8662719726562\n",
      "Train Epoch: 652 [0/54000 (0%)] Loss: -1802.782837\n",
      "Train Epoch: 652 [11264/54000 (21%)] Loss: -1809.921509\n",
      "Train Epoch: 652 [22528/54000 (42%)] Loss: -1784.549316\n",
      "Train Epoch: 652 [33792/54000 (63%)] Loss: -1813.405029\n",
      "Train Epoch: 652 [45056/54000 (83%)] Loss: -1799.190430\n",
      "    epoch          : 652\n",
      "    loss           : -1796.8617288841392\n",
      "    ess            : 8.001181908373562\n",
      "    log_marginal   : 1796.8617277325325\n",
      "    val_loss       : -1808.7424011230469\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1808.7424011230469\n",
      "Train Epoch: 653 [0/54000 (0%)] Loss: -1820.820801\n",
      "Train Epoch: 653 [11264/54000 (21%)] Loss: -1815.759277\n",
      "Train Epoch: 653 [22528/54000 (42%)] Loss: -1793.882080\n",
      "Train Epoch: 653 [33792/54000 (63%)] Loss: -1786.913330\n",
      "Train Epoch: 653 [45056/54000 (83%)] Loss: -1785.101074\n",
      "    epoch          : 653\n",
      "    loss           : -1791.383061247052\n",
      "    ess            : 8.001182250256809\n",
      "    log_marginal   : 1791.3830623986587\n",
      "    val_loss       : -1786.5612386067708\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1786.5612386067708\n",
      "Train Epoch: 654 [0/54000 (0%)] Loss: -1796.648682\n",
      "Train Epoch: 654 [11264/54000 (21%)] Loss: -1800.483032\n",
      "Train Epoch: 654 [22528/54000 (42%)] Loss: -1787.178467\n",
      "Train Epoch: 654 [33792/54000 (63%)] Loss: -1802.645508\n",
      "Train Epoch: 654 [45056/54000 (83%)] Loss: -1791.726562\n",
      "    epoch          : 654\n",
      "    loss           : -1789.939229713296\n",
      "    ess            : 8.001183122958777\n",
      "    log_marginal   : 1789.9392285616893\n",
      "    val_loss       : -1792.5279947916667\n",
      "    val_ess        : 8.001184066136679\n",
      "    val_log_marginal: 1792.5280049641926\n",
      "Train Epoch: 655 [0/54000 (0%)] Loss: -1804.072876\n",
      "Train Epoch: 655 [11264/54000 (21%)] Loss: -1793.741943\n",
      "Train Epoch: 655 [22528/54000 (42%)] Loss: -1790.907471\n",
      "Train Epoch: 655 [33792/54000 (63%)] Loss: -1809.940918\n",
      "Train Epoch: 655 [45056/54000 (83%)] Loss: -1788.140137\n",
      "    epoch          : 655\n",
      "    loss           : -1791.0106765459168\n",
      "    ess            : 8.00118191737049\n",
      "    log_marginal   : 1791.0106765459168\n",
      "    val_loss       : -1797.654296875\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1797.654296875\n",
      "Train Epoch: 656 [0/54000 (0%)] Loss: -1808.686279\n",
      "Train Epoch: 656 [11264/54000 (21%)] Loss: -1810.293579\n",
      "Train Epoch: 656 [22528/54000 (42%)] Loss: -1800.017456\n",
      "Train Epoch: 656 [33792/54000 (63%)] Loss: -1811.678345\n",
      "Train Epoch: 656 [45056/54000 (83%)] Loss: -1792.676025\n",
      "    epoch          : 656\n",
      "    loss           : -1798.7861224480396\n",
      "    ess            : 8.001181215610144\n",
      "    log_marginal   : 1798.7861224480396\n",
      "    val_loss       : -1803.7823588053386\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1803.7823588053386\n",
      "Train Epoch: 657 [0/54000 (0%)] Loss: -1814.948242\n",
      "Train Epoch: 657 [11264/54000 (21%)] Loss: -1813.601807\n",
      "Train Epoch: 657 [22528/54000 (42%)] Loss: -1805.257812\n",
      "Train Epoch: 657 [33792/54000 (63%)] Loss: -1819.391357\n",
      "Train Epoch: 657 [45056/54000 (83%)] Loss: -1797.729736\n",
      "    epoch          : 657\n",
      "    loss           : -1803.6303031489533\n",
      "    ess            : 8.001181026674667\n",
      "    log_marginal   : 1803.6303031489533\n",
      "    val_loss       : -1801.557840983073\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1801.557840983073\n",
      "Train Epoch: 658 [0/54000 (0%)] Loss: -1814.256348\n",
      "Train Epoch: 658 [11264/54000 (21%)] Loss: -1812.611328\n",
      "Train Epoch: 658 [22528/54000 (42%)] Loss: -1800.850098\n",
      "Train Epoch: 658 [33792/54000 (63%)] Loss: -1822.021240\n",
      "Train Epoch: 658 [45056/54000 (83%)] Loss: -1794.025513\n",
      "    epoch          : 658\n",
      "    loss           : -1800.1045935288914\n",
      "    ess            : 8.00118014497577\n",
      "    log_marginal   : 1800.104595832105\n",
      "    val_loss       : -1798.2228291829426\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1798.2228190104167\n",
      "Train Epoch: 659 [0/54000 (0%)] Loss: -1812.852051\n",
      "Train Epoch: 659 [11264/54000 (21%)] Loss: -1810.132202\n",
      "Train Epoch: 659 [22528/54000 (42%)] Loss: -1801.842651\n",
      "Train Epoch: 659 [33792/54000 (63%)] Loss: -1821.304443\n",
      "Train Epoch: 659 [45056/54000 (83%)] Loss: -1798.060669\n",
      "    epoch          : 659\n",
      "    loss           : -1802.1530174399322\n",
      "    ess            : 8.001180495855943\n",
      "    log_marginal   : 1802.1530174399322\n",
      "    val_loss       : -1805.7210795084636\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1805.7210591634114\n",
      "Train Epoch: 660 [0/54000 (0%)] Loss: -1820.795776\n",
      "Train Epoch: 660 [11264/54000 (21%)] Loss: -1809.734009\n",
      "Train Epoch: 660 [22528/54000 (42%)] Loss: -1800.138672\n",
      "Train Epoch: 660 [33792/54000 (63%)] Loss: -1818.896240\n",
      "Train Epoch: 660 [45056/54000 (83%)] Loss: -1796.457153\n",
      "    epoch          : 660\n",
      "    loss           : -1801.113860508181\n",
      "    ess            : 8.001180010021857\n",
      "    log_marginal   : 1801.113860508181\n",
      "    val_loss       : -1805.6671752929688\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1805.6671752929688\n",
      "Train Epoch: 661 [0/54000 (0%)] Loss: -1819.325684\n",
      "Train Epoch: 661 [11264/54000 (21%)] Loss: -1808.852173\n",
      "Train Epoch: 661 [22528/54000 (42%)] Loss: -1791.119385\n",
      "Train Epoch: 661 [33792/54000 (63%)] Loss: -1814.654907\n",
      "Train Epoch: 661 [45056/54000 (83%)] Loss: -1787.683228\n",
      "    epoch          : 661\n",
      "    loss           : -1797.3116938752948\n",
      "    ess            : 8.001180387892813\n",
      "    log_marginal   : 1797.3116938752948\n",
      "    val_loss       : -1799.4782613118489\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1799.4782613118489\n",
      "Train Epoch: 662 [0/54000 (0%)] Loss: -1812.208618\n",
      "Train Epoch: 662 [11264/54000 (21%)] Loss: -1805.581055\n",
      "Train Epoch: 662 [22528/54000 (42%)] Loss: -1791.189819\n",
      "Train Epoch: 662 [33792/54000 (63%)] Loss: -1810.869019\n",
      "Train Epoch: 662 [45056/54000 (83%)] Loss: -1783.081055\n",
      "    epoch          : 662\n",
      "    loss           : -1795.1956199789947\n",
      "    ess            : 8.001181962355128\n",
      "    log_marginal   : 1795.195618827388\n",
      "    val_loss       : -1801.4634908040364\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1801.4634704589844\n",
      "Train Epoch: 663 [0/54000 (0%)] Loss: -1815.070801\n",
      "Train Epoch: 663 [11264/54000 (21%)] Loss: -1806.097900\n",
      "Train Epoch: 663 [22528/54000 (42%)] Loss: -1802.424927\n",
      "Train Epoch: 663 [33792/54000 (63%)] Loss: -1821.031250\n",
      "Train Epoch: 663 [45056/54000 (83%)] Loss: -1793.362183\n",
      "    epoch          : 663\n",
      "    loss           : -1802.9129408350532\n",
      "    ess            : 8.001180324914321\n",
      "    log_marginal   : 1802.9129396834464\n",
      "    val_loss       : -1809.3663736979167\n",
      "    val_ess        : 8.001179615656534\n",
      "    val_log_marginal: 1809.3663736979167\n",
      "Train Epoch: 664 [0/54000 (0%)] Loss: -1823.479858\n",
      "Train Epoch: 664 [11264/54000 (21%)] Loss: -1807.293579\n",
      "Train Epoch: 664 [22528/54000 (42%)] Loss: -1796.663696\n",
      "Train Epoch: 664 [33792/54000 (63%)] Loss: -1806.888184\n",
      "Train Epoch: 664 [45056/54000 (83%)] Loss: -1778.095459\n",
      "    epoch          : 664\n",
      "    loss           : -1794.844755352668\n",
      "    ess            : 8.001181683450374\n",
      "    log_marginal   : 1794.844755352668\n",
      "    val_loss       : -1790.4049987792969\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1790.4049784342449\n",
      "Train Epoch: 665 [0/54000 (0%)] Loss: -1807.866699\n",
      "Train Epoch: 665 [11264/54000 (21%)] Loss: -1779.911621\n",
      "Train Epoch: 665 [22528/54000 (42%)] Loss: -1777.164551\n",
      "Train Epoch: 665 [33792/54000 (63%)] Loss: -1801.898682\n",
      "Train Epoch: 665 [45056/54000 (83%)] Loss: -1789.500244\n",
      "    epoch          : 665\n",
      "    loss           : -1785.1913452148438\n",
      "    ess            : 8.001183527820515\n",
      "    log_marginal   : 1785.1913452148438\n",
      "    val_loss       : -1802.0540364583333\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1802.0540262858074\n",
      "Train Epoch: 666 [0/54000 (0%)] Loss: -1815.155518\n",
      "Train Epoch: 666 [11264/54000 (21%)] Loss: -1794.894165\n",
      "Train Epoch: 666 [22528/54000 (42%)] Loss: -1791.629761\n",
      "Train Epoch: 666 [33792/54000 (63%)] Loss: -1815.149658\n",
      "Train Epoch: 666 [45056/54000 (83%)] Loss: -1788.665283\n",
      "    epoch          : 666\n",
      "    loss           : -1794.8245227741745\n",
      "    ess            : 8.00118072077913\n",
      "    log_marginal   : 1794.8245227741745\n",
      "    val_loss       : -1799.3261311848958\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1799.3261108398438\n",
      "Train Epoch: 667 [0/54000 (0%)] Loss: -1811.772461\n",
      "Train Epoch: 667 [11264/54000 (21%)] Loss: -1792.151367\n",
      "Train Epoch: 667 [22528/54000 (42%)] Loss: -1790.907227\n",
      "Train Epoch: 667 [33792/54000 (63%)] Loss: -1814.941650\n",
      "Train Epoch: 667 [45056/54000 (83%)] Loss: -1795.133545\n",
      "    epoch          : 667\n",
      "    loss           : -1794.077024063974\n",
      "    ess            : 8.001181854391998\n",
      "    log_marginal   : 1794.077024063974\n",
      "    val_loss       : -1806.0847880045574\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1806.0847981770833\n",
      "Train Epoch: 668 [0/54000 (0%)] Loss: -1815.892334\n",
      "Train Epoch: 668 [11264/54000 (21%)] Loss: -1806.269897\n",
      "Train Epoch: 668 [22528/54000 (42%)] Loss: -1792.690674\n",
      "Train Epoch: 668 [33792/54000 (63%)] Loss: -1811.840942\n",
      "Train Epoch: 668 [45056/54000 (83%)] Loss: -1791.799561\n",
      "    epoch          : 668\n",
      "    loss           : -1797.2020597637825\n",
      "    ess            : 8.001181143634724\n",
      "    log_marginal   : 1797.2020597637825\n",
      "    val_loss       : -1804.5632731119792\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1804.5632731119792\n",
      "Train Epoch: 669 [0/54000 (0%)] Loss: -1815.593994\n",
      "Train Epoch: 669 [11264/54000 (21%)] Loss: -1810.195801\n",
      "Train Epoch: 669 [22528/54000 (42%)] Loss: -1798.755859\n",
      "Train Epoch: 669 [33792/54000 (63%)] Loss: -1821.656006\n",
      "Train Epoch: 669 [45056/54000 (83%)] Loss: -1798.833496\n",
      "    epoch          : 669\n",
      "    loss           : -1801.6640314066185\n",
      "    ess            : 8.00117992904951\n",
      "    log_marginal   : 1801.6640314066185\n",
      "    val_loss       : -1803.6546325683594\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1803.6546325683594\n",
      "Train Epoch: 670 [0/54000 (0%)] Loss: -1813.395508\n",
      "Train Epoch: 670 [11264/54000 (21%)] Loss: -1811.024048\n",
      "Train Epoch: 670 [22528/54000 (42%)] Loss: -1794.412598\n",
      "Train Epoch: 670 [33792/54000 (63%)] Loss: -1813.714600\n",
      "Train Epoch: 670 [45056/54000 (83%)] Loss: -1789.502686\n",
      "    epoch          : 670\n",
      "    loss           : -1797.7899837853774\n",
      "    ess            : 8.001181134637797\n",
      "    log_marginal   : 1797.7899837853774\n",
      "    val_loss       : -1801.3770548502605\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1801.3770446777344\n",
      "Train Epoch: 671 [0/54000 (0%)] Loss: -1814.444214\n",
      "Train Epoch: 671 [11264/54000 (21%)] Loss: -1804.907593\n",
      "Train Epoch: 671 [22528/54000 (42%)] Loss: -1787.392334\n",
      "Train Epoch: 671 [33792/54000 (63%)] Loss: -1804.698975\n",
      "Train Epoch: 671 [45056/54000 (83%)] Loss: -1791.779785\n",
      "    epoch          : 671\n",
      "    loss           : -1794.2280284953567\n",
      "    ess            : 8.00118007300035\n",
      "    log_marginal   : 1794.2280284953567\n",
      "    val_loss       : -1801.363037109375\n",
      "    val_ess        : 8.001182158788046\n",
      "    val_log_marginal: 1801.363037109375\n",
      "Train Epoch: 672 [0/54000 (0%)] Loss: -1814.364136\n",
      "Train Epoch: 672 [11264/54000 (21%)] Loss: -1811.359253\n",
      "Train Epoch: 672 [22528/54000 (42%)] Loss: -1804.626587\n",
      "Train Epoch: 672 [33792/54000 (63%)] Loss: -1820.996094\n",
      "Train Epoch: 672 [45056/54000 (83%)] Loss: -1798.664429\n",
      "    epoch          : 672\n",
      "    loss           : -1803.9036727041569\n",
      "    ess            : 8.001180630809856\n",
      "    log_marginal   : 1803.9036727041569\n",
      "    val_loss       : -1804.6739603678386\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1804.6739705403645\n",
      "Train Epoch: 673 [0/54000 (0%)] Loss: -1819.819580\n",
      "Train Epoch: 673 [11264/54000 (21%)] Loss: -1818.027222\n",
      "Train Epoch: 673 [22528/54000 (42%)] Loss: -1797.579712\n",
      "Train Epoch: 673 [33792/54000 (63%)] Loss: -1808.092041\n",
      "Train Epoch: 673 [45056/54000 (83%)] Loss: -1792.344360\n",
      "    epoch          : 673\n",
      "    loss           : -1799.9137619306457\n",
      "    ess            : 8.001180468865162\n",
      "    log_marginal   : 1799.9137619306457\n",
      "    val_loss       : -1796.0238444010417\n",
      "    val_ess        : 8.001183350880941\n",
      "    val_log_marginal: 1796.0238444010417\n",
      "Train Epoch: 674 [0/54000 (0%)] Loss: -1808.788086\n",
      "Train Epoch: 674 [11264/54000 (21%)] Loss: -1802.441284\n",
      "Train Epoch: 674 [22528/54000 (42%)] Loss: -1779.866211\n",
      "Train Epoch: 674 [33792/54000 (63%)] Loss: -1804.742554\n",
      "Train Epoch: 674 [45056/54000 (83%)] Loss: -1785.316162\n",
      "    epoch          : 674\n",
      "    loss           : -1788.9026385613208\n",
      "    ess            : 8.001181467524114\n",
      "    log_marginal   : 1788.9026397129276\n",
      "    val_loss       : -1784.9536844889324\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1784.9536946614583\n",
      "Train Epoch: 675 [0/54000 (0%)] Loss: -1797.471436\n",
      "Train Epoch: 675 [11264/54000 (21%)] Loss: -1797.151489\n",
      "Train Epoch: 675 [22528/54000 (42%)] Loss: -1783.547607\n",
      "Train Epoch: 675 [33792/54000 (63%)] Loss: -1810.264893\n",
      "Train Epoch: 675 [45056/54000 (83%)] Loss: -1789.150146\n",
      "    epoch          : 675\n",
      "    loss           : -1792.158777776754\n",
      "    ess            : 8.001182376213794\n",
      "    log_marginal   : 1792.1587766251473\n",
      "    val_loss       : -1806.6605529785156\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1806.6605529785156\n",
      "Train Epoch: 676 [0/54000 (0%)] Loss: -1817.995361\n",
      "Train Epoch: 676 [11264/54000 (21%)] Loss: -1809.985107\n",
      "Train Epoch: 676 [22528/54000 (42%)] Loss: -1800.610474\n",
      "Train Epoch: 676 [33792/54000 (63%)] Loss: -1819.866455\n",
      "Train Epoch: 676 [45056/54000 (83%)] Loss: -1797.770020\n",
      "    epoch          : 676\n",
      "    loss           : -1804.4303358545844\n",
      "    ess            : 8.001180441874379\n",
      "    log_marginal   : 1804.4303358545844\n",
      "    val_loss       : -1807.0348815917969\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1807.034891764323\n",
      "Train Epoch: 677 [0/54000 (0%)] Loss: -1819.120361\n",
      "Train Epoch: 677 [11264/54000 (21%)] Loss: -1808.360107\n",
      "Train Epoch: 677 [22528/54000 (42%)] Loss: -1801.320801\n",
      "Train Epoch: 677 [33792/54000 (63%)] Loss: -1816.058105\n",
      "Train Epoch: 677 [45056/54000 (83%)] Loss: -1787.957520\n",
      "    epoch          : 677\n",
      "    loss           : -1798.8776659695607\n",
      "    ess            : 8.001181539499536\n",
      "    log_marginal   : 1798.8776659695607\n",
      "    val_loss       : -1802.5024312337239\n",
      "    val_ess        : 8.001181046168009\n",
      "    val_log_marginal: 1802.5024515787761\n",
      "Train Epoch: 678 [0/54000 (0%)] Loss: -1813.348877\n",
      "Train Epoch: 678 [11264/54000 (21%)] Loss: -1804.682739\n",
      "Train Epoch: 678 [22528/54000 (42%)] Loss: -1794.746826\n",
      "Train Epoch: 678 [33792/54000 (63%)] Loss: -1815.274414\n",
      "Train Epoch: 678 [45056/54000 (83%)] Loss: -1786.311279\n",
      "    epoch          : 678\n",
      "    loss           : -1796.8345417526532\n",
      "    ess            : 8.001180927708464\n",
      "    log_marginal   : 1796.8345417526532\n",
      "    val_loss       : -1799.5197041829426\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1799.5197041829426\n",
      "Train Epoch: 679 [0/54000 (0%)] Loss: -1813.982666\n",
      "Train Epoch: 679 [11264/54000 (21%)] Loss: -1811.848022\n",
      "Train Epoch: 679 [22528/54000 (42%)] Loss: -1800.343506\n",
      "Train Epoch: 679 [33792/54000 (63%)] Loss: -1814.728760\n",
      "Train Epoch: 679 [45056/54000 (83%)] Loss: -1792.434326\n",
      "    epoch          : 679\n",
      "    loss           : -1800.380706211306\n",
      "    ess            : 8.00118036090203\n",
      "    log_marginal   : 1800.3807050596993\n",
      "    val_loss       : -1806.878926595052\n",
      "    val_ess        : 8.001179536183676\n",
      "    val_log_marginal: 1806.878926595052\n",
      "Train Epoch: 680 [0/54000 (0%)] Loss: -1821.433350\n",
      "Train Epoch: 680 [11264/54000 (21%)] Loss: -1819.026855\n",
      "Train Epoch: 680 [22528/54000 (42%)] Loss: -1791.117188\n",
      "Train Epoch: 680 [33792/54000 (63%)] Loss: -1796.458862\n",
      "Train Epoch: 680 [45056/54000 (83%)] Loss: -1767.500488\n",
      "    epoch          : 680\n",
      "    loss           : -1790.463172768647\n",
      "    ess            : 8.001180747769913\n",
      "    log_marginal   : 1790.4631739202534\n",
      "    val_loss       : -1782.049072265625\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1782.0490620930989\n",
      "Train Epoch: 681 [0/54000 (0%)] Loss: -1796.869263\n",
      "Train Epoch: 681 [11264/54000 (21%)] Loss: -1807.796631\n",
      "Train Epoch: 681 [22528/54000 (42%)] Loss: -1774.238770\n",
      "Train Epoch: 681 [33792/54000 (63%)] Loss: -1783.388184\n",
      "Train Epoch: 681 [45056/54000 (83%)] Loss: -1766.334351\n",
      "    epoch          : 681\n",
      "    loss           : -1778.2121052292157\n",
      "    ess            : 8.001184076633093\n",
      "    log_marginal   : 1778.2121075324292\n",
      "    val_loss       : -1794.2902526855469\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1794.2902526855469\n",
      "Train Epoch: 682 [0/54000 (0%)] Loss: -1804.614868\n",
      "Train Epoch: 682 [11264/54000 (21%)] Loss: -1815.001831\n",
      "Train Epoch: 682 [22528/54000 (42%)] Loss: -1791.451660\n",
      "Train Epoch: 682 [33792/54000 (63%)] Loss: -1802.669434\n",
      "Train Epoch: 682 [45056/54000 (83%)] Loss: -1784.677002\n",
      "    epoch          : 682\n",
      "    loss           : -1793.1119131412147\n",
      "    ess            : 8.001182538158488\n",
      "    log_marginal   : 1793.1119131412147\n",
      "    val_loss       : -1799.9109903971355\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1799.9109903971355\n",
      "Train Epoch: 683 [0/54000 (0%)] Loss: -1811.722290\n",
      "Train Epoch: 683 [11264/54000 (21%)] Loss: -1818.468872\n",
      "Train Epoch: 683 [22528/54000 (42%)] Loss: -1794.653198\n",
      "Train Epoch: 683 [33792/54000 (63%)] Loss: -1811.147217\n",
      "Train Epoch: 683 [45056/54000 (83%)] Loss: -1796.329590\n",
      "    epoch          : 683\n",
      "    loss           : -1798.1650989460495\n",
      "    ess            : 8.0011823132353\n",
      "    log_marginal   : 1798.1650989460495\n",
      "    val_loss       : -1806.5881652832031\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1806.5881652832031\n",
      "Train Epoch: 684 [0/54000 (0%)] Loss: -1819.695435\n",
      "Train Epoch: 684 [11264/54000 (21%)] Loss: -1815.147705\n",
      "Train Epoch: 684 [22528/54000 (42%)] Loss: -1794.755737\n",
      "Train Epoch: 684 [33792/54000 (63%)] Loss: -1815.150391\n",
      "Train Epoch: 684 [45056/54000 (83%)] Loss: -1795.097656\n",
      "    epoch          : 684\n",
      "    loss           : -1799.5289721219044\n",
      "    ess            : 8.001182574146199\n",
      "    log_marginal   : 1799.5289721219044\n",
      "    val_loss       : -1803.3015034993489\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1803.3015034993489\n",
      "Train Epoch: 685 [0/54000 (0%)] Loss: -1817.457397\n",
      "Train Epoch: 685 [11264/54000 (21%)] Loss: -1806.932129\n",
      "Train Epoch: 685 [22528/54000 (42%)] Loss: -1793.386719\n",
      "Train Epoch: 685 [33792/54000 (63%)] Loss: -1813.787598\n",
      "Train Epoch: 685 [45056/54000 (83%)] Loss: -1792.513672\n",
      "    epoch          : 685\n",
      "    loss           : -1797.589152785967\n",
      "    ess            : 8.001182808066314\n",
      "    log_marginal   : 1797.5891539375737\n",
      "    val_loss       : -1800.4582112630208\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1800.4582214355469\n",
      "Train Epoch: 686 [0/54000 (0%)] Loss: -1811.892090\n",
      "Train Epoch: 686 [11264/54000 (21%)] Loss: -1815.968262\n",
      "Train Epoch: 686 [22528/54000 (42%)] Loss: -1793.004150\n",
      "Train Epoch: 686 [33792/54000 (63%)] Loss: -1800.584961\n",
      "Train Epoch: 686 [45056/54000 (83%)] Loss: -1789.269043\n",
      "    epoch          : 686\n",
      "    loss           : -1795.9874359706662\n",
      "    ess            : 8.001181404545623\n",
      "    log_marginal   : 1795.9874359706662\n",
      "    val_loss       : -1797.0776672363281\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1797.0776672363281\n",
      "Train Epoch: 687 [0/54000 (0%)] Loss: -1810.085938\n",
      "Train Epoch: 687 [11264/54000 (21%)] Loss: -1813.046753\n",
      "Train Epoch: 687 [22528/54000 (42%)] Loss: -1799.982910\n",
      "Train Epoch: 687 [33792/54000 (63%)] Loss: -1820.711182\n",
      "Train Epoch: 687 [45056/54000 (83%)] Loss: -1799.259033\n",
      "    epoch          : 687\n",
      "    loss           : -1802.2347170271964\n",
      "    ess            : 8.001181980348983\n",
      "    log_marginal   : 1802.2347181788032\n",
      "    val_loss       : -1802.5805358886719\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1802.5805358886719\n",
      "Train Epoch: 688 [0/54000 (0%)] Loss: -1814.042480\n",
      "Train Epoch: 688 [11264/54000 (21%)] Loss: -1811.276733\n",
      "Train Epoch: 688 [22528/54000 (42%)] Loss: -1797.152100\n",
      "Train Epoch: 688 [33792/54000 (63%)] Loss: -1817.946045\n",
      "Train Epoch: 688 [45056/54000 (83%)] Loss: -1795.033203\n",
      "    epoch          : 688\n",
      "    loss           : -1800.7834979363208\n",
      "    ess            : 8.001180882723826\n",
      "    log_marginal   : 1800.7834979363208\n",
      "    val_loss       : -1797.4792175292969\n",
      "    val_ess        : 8.001182794570923\n",
      "    val_log_marginal: 1797.4792378743489\n",
      "Train Epoch: 689 [0/54000 (0%)] Loss: -1810.572998\n",
      "Train Epoch: 689 [11264/54000 (21%)] Loss: -1808.772705\n",
      "Train Epoch: 689 [22528/54000 (42%)] Loss: -1799.094971\n",
      "Train Epoch: 689 [33792/54000 (63%)] Loss: -1818.378174\n",
      "Train Epoch: 689 [45056/54000 (83%)] Loss: -1796.835205\n",
      "    epoch          : 689\n",
      "    loss           : -1799.7986058649028\n",
      "    ess            : 8.001181863388926\n",
      "    log_marginal   : 1799.7986058649028\n",
      "    val_loss       : -1781.7037150065105\n",
      "    val_ess        : 8.001181523005167\n",
      "    val_log_marginal: 1781.7037150065105\n",
      "Train Epoch: 690 [0/54000 (0%)] Loss: -1798.060181\n",
      "Train Epoch: 690 [11264/54000 (21%)] Loss: -1810.509888\n",
      "Train Epoch: 690 [22528/54000 (42%)] Loss: -1792.324829\n",
      "Train Epoch: 690 [33792/54000 (63%)] Loss: -1812.121094\n",
      "Train Epoch: 690 [45056/54000 (83%)] Loss: -1796.115112\n",
      "    epoch          : 690\n",
      "    loss           : -1797.0537166955337\n",
      "    ess            : 8.001182034330547\n",
      "    log_marginal   : 1797.0537166955337\n",
      "    val_loss       : -1803.0436503092449\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1803.0436197916667\n",
      "Train Epoch: 691 [0/54000 (0%)] Loss: -1817.460327\n",
      "Train Epoch: 691 [11264/54000 (21%)] Loss: -1817.752319\n",
      "Train Epoch: 691 [22528/54000 (42%)] Loss: -1805.301392\n",
      "Train Epoch: 691 [33792/54000 (63%)] Loss: -1820.194580\n",
      "Train Epoch: 691 [45056/54000 (83%)] Loss: -1790.722168\n",
      "    epoch          : 691\n",
      "    loss           : -1803.1497238447082\n",
      "    ess            : 8.001180261935827\n",
      "    log_marginal   : 1803.1497238447082\n",
      "    val_loss       : -1800.6899108886719\n",
      "    val_ess        : 8.001180728276571\n",
      "    val_log_marginal: 1800.6899007161458\n",
      "Train Epoch: 692 [0/54000 (0%)] Loss: -1814.041504\n",
      "Train Epoch: 692 [11264/54000 (21%)] Loss: -1817.270020\n",
      "Train Epoch: 692 [22528/54000 (42%)] Loss: -1795.810181\n",
      "Train Epoch: 692 [33792/54000 (63%)] Loss: -1813.908447\n",
      "Train Epoch: 692 [45056/54000 (83%)] Loss: -1789.382324\n",
      "    epoch          : 692\n",
      "    loss           : -1798.998013478405\n",
      "    ess            : 8.001179830083307\n",
      "    log_marginal   : 1798.998013478405\n",
      "    val_loss       : -1800.620849609375\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1800.620849609375\n",
      "Train Epoch: 693 [0/54000 (0%)] Loss: -1811.039673\n",
      "Train Epoch: 693 [11264/54000 (21%)] Loss: -1814.153564\n",
      "Train Epoch: 693 [22528/54000 (42%)] Loss: -1795.713501\n",
      "Train Epoch: 693 [33792/54000 (63%)] Loss: -1807.885498\n",
      "Train Epoch: 693 [45056/54000 (83%)] Loss: -1787.710938\n",
      "    epoch          : 693\n",
      "    loss           : -1797.5896675541717\n",
      "    ess            : 8.00118112564087\n",
      "    log_marginal   : 1797.5896675541717\n",
      "    val_loss       : -1799.3233642578125\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1799.3233439127605\n",
      "Train Epoch: 694 [0/54000 (0%)] Loss: -1811.079834\n",
      "Train Epoch: 694 [11264/54000 (21%)] Loss: -1811.791016\n",
      "Train Epoch: 694 [22528/54000 (42%)] Loss: -1802.202393\n",
      "Train Epoch: 694 [33792/54000 (63%)] Loss: -1817.747681\n",
      "Train Epoch: 694 [45056/54000 (83%)] Loss: -1797.564575\n",
      "    epoch          : 694\n",
      "    loss           : -1802.9353545566776\n",
      "    ess            : 8.001180567831364\n",
      "    log_marginal   : 1802.9353545566776\n",
      "    val_loss       : -1808.3427836100261\n",
      "    val_ess        : 8.001180092493692\n",
      "    val_log_marginal: 1808.3427836100261\n",
      "Train Epoch: 695 [0/54000 (0%)] Loss: -1818.775391\n",
      "Train Epoch: 695 [11264/54000 (21%)] Loss: -1820.202393\n",
      "Train Epoch: 695 [22528/54000 (42%)] Loss: -1798.707764\n",
      "Train Epoch: 695 [33792/54000 (63%)] Loss: -1800.860596\n",
      "Train Epoch: 695 [45056/54000 (83%)] Loss: -1794.953613\n",
      "    epoch          : 695\n",
      "    loss           : -1800.4831566000885\n",
      "    ess            : 8.001180900717682\n",
      "    log_marginal   : 1800.4831566000885\n",
      "    val_loss       : -1801.5407613118489\n",
      "    val_ess        : 8.00118088722229\n",
      "    val_log_marginal: 1801.540751139323\n",
      "Train Epoch: 696 [0/54000 (0%)] Loss: -1811.442627\n",
      "Train Epoch: 696 [11264/54000 (21%)] Loss: -1812.364136\n",
      "Train Epoch: 696 [22528/54000 (42%)] Loss: -1792.909912\n",
      "Train Epoch: 696 [33792/54000 (63%)] Loss: -1810.104248\n",
      "Train Epoch: 696 [45056/54000 (83%)] Loss: -1793.343750\n",
      "    epoch          : 696\n",
      "    loss           : -1798.8384883088886\n",
      "    ess            : 8.00118007300035\n",
      "    log_marginal   : 1798.8384883088886\n",
      "    val_loss       : -1801.6709696451824\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1801.6709696451824\n",
      "Train Epoch: 697 [0/54000 (0%)] Loss: -1811.092773\n",
      "Train Epoch: 697 [11264/54000 (21%)] Loss: -1812.479736\n",
      "Train Epoch: 697 [22528/54000 (42%)] Loss: -1788.238281\n",
      "Train Epoch: 697 [33792/54000 (63%)] Loss: -1815.566162\n",
      "Train Epoch: 697 [45056/54000 (83%)] Loss: -1793.451294\n",
      "    epoch          : 697\n",
      "    loss           : -1797.763025823629\n",
      "    ess            : 8.001180900717682\n",
      "    log_marginal   : 1797.763025823629\n",
      "    val_loss       : -1800.6500142415364\n",
      "    val_ess        : 8.001181046168009\n",
      "    val_log_marginal: 1800.6500142415364\n",
      "Train Epoch: 698 [0/54000 (0%)] Loss: -1812.866821\n",
      "Train Epoch: 698 [11264/54000 (21%)] Loss: -1814.528076\n",
      "Train Epoch: 698 [22528/54000 (42%)] Loss: -1804.644653\n",
      "Train Epoch: 698 [33792/54000 (63%)] Loss: -1823.124878\n",
      "Train Epoch: 698 [45056/54000 (83%)] Loss: -1797.171265\n",
      "    epoch          : 698\n",
      "    loss           : -1804.2358029923348\n",
      "    ess            : 8.001179173307598\n",
      "    log_marginal   : 1804.2358029923348\n",
      "    val_loss       : -1805.7171020507812\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1805.7170817057292\n",
      "Train Epoch: 699 [0/54000 (0%)] Loss: -1817.543213\n",
      "Train Epoch: 699 [11264/54000 (21%)] Loss: -1814.157471\n",
      "Train Epoch: 699 [22528/54000 (42%)] Loss: -1803.681519\n",
      "Train Epoch: 699 [33792/54000 (63%)] Loss: -1820.222046\n",
      "Train Epoch: 699 [45056/54000 (83%)] Loss: -1800.897217\n",
      "    epoch          : 699\n",
      "    loss           : -1804.7564132978332\n",
      "    ess            : 8.001178930390555\n",
      "    log_marginal   : 1804.7564132978332\n",
      "    val_loss       : -1805.3265380859375\n",
      "    val_ess        : 8.001177867253622\n",
      "    val_log_marginal: 1805.3265380859375\n",
      "Train Epoch: 700 [0/54000 (0%)] Loss: -1816.395752\n",
      "Train Epoch: 700 [11264/54000 (21%)] Loss: -1816.494751\n",
      "Train Epoch: 700 [22528/54000 (42%)] Loss: -1803.610107\n",
      "Train Epoch: 700 [33792/54000 (63%)] Loss: -1812.936035\n",
      "Train Epoch: 700 [45056/54000 (83%)] Loss: -1792.396484\n",
      "    epoch          : 700\n",
      "    loss           : -1802.765061864313\n",
      "    ess            : 8.001178894402846\n",
      "    log_marginal   : 1802.7650607127064\n",
      "    val_loss       : -1800.9060872395833\n",
      "    val_ess        : 8.001182953516642\n",
      "    val_log_marginal: 1800.9060872395833\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch700.pth ...\n",
      "Train Epoch: 701 [0/54000 (0%)] Loss: -1811.081543\n",
      "Train Epoch: 701 [11264/54000 (21%)] Loss: -1815.907349\n",
      "Train Epoch: 701 [22528/54000 (42%)] Loss: -1800.210938\n",
      "Train Epoch: 701 [33792/54000 (63%)] Loss: -1818.859131\n",
      "Train Epoch: 701 [45056/54000 (83%)] Loss: -1802.444214\n",
      "    epoch          : 701\n",
      "    loss           : -1804.391435731132\n",
      "    ess            : 8.001180522846726\n",
      "    log_marginal   : 1804.391435731132\n",
      "    val_loss       : -1807.5293782552083\n",
      "    val_ess        : 8.001181999842325\n",
      "    val_log_marginal: 1807.5293782552083\n",
      "Train Epoch: 702 [0/54000 (0%)] Loss: -1817.734497\n",
      "Train Epoch: 702 [11264/54000 (21%)] Loss: -1808.572021\n",
      "Train Epoch: 702 [22528/54000 (42%)] Loss: -1781.042603\n",
      "Train Epoch: 702 [33792/54000 (63%)] Loss: -1795.088501\n",
      "Train Epoch: 702 [45056/54000 (83%)] Loss: -1759.277832\n",
      "    epoch          : 702\n",
      "    loss           : -1784.847399441701\n",
      "    ess            : 8.001181197616289\n",
      "    log_marginal   : 1784.847399441701\n",
      "    val_loss       : -1764.6405843098958\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1764.6405843098958\n",
      "Train Epoch: 703 [0/54000 (0%)] Loss: -1776.524902\n",
      "Train Epoch: 703 [11264/54000 (21%)] Loss: -1790.706787\n",
      "Train Epoch: 703 [22528/54000 (42%)] Loss: -1789.617432\n",
      "Train Epoch: 703 [33792/54000 (63%)] Loss: -1806.646973\n",
      "Train Epoch: 703 [45056/54000 (83%)] Loss: -1783.306641\n",
      "    epoch          : 703\n",
      "    loss           : -1783.3641610775353\n",
      "    ess            : 8.00118340186353\n",
      "    log_marginal   : 1783.3641610775353\n",
      "    val_loss       : -1786.5187174479167\n",
      "    val_ess        : 8.001182953516642\n",
      "    val_log_marginal: 1786.5187174479167\n",
      "Train Epoch: 704 [0/54000 (0%)] Loss: -1800.215454\n",
      "Train Epoch: 704 [11264/54000 (21%)] Loss: -1803.644287\n",
      "Train Epoch: 704 [22528/54000 (42%)] Loss: -1793.384766\n",
      "Train Epoch: 704 [33792/54000 (63%)] Loss: -1809.716553\n",
      "Train Epoch: 704 [45056/54000 (83%)] Loss: -1791.447998\n",
      "    epoch          : 704\n",
      "    loss           : -1793.3869824679393\n",
      "    ess            : 8.001182133296751\n",
      "    log_marginal   : 1793.3869813163326\n",
      "    val_loss       : -1798.7853088378906\n",
      "    val_ess        : 8.001182079315186\n",
      "    val_log_marginal: 1798.7852884928386\n",
      "Train Epoch: 705 [0/54000 (0%)] Loss: -1810.513184\n",
      "Train Epoch: 705 [11264/54000 (21%)] Loss: -1810.011230\n",
      "Train Epoch: 705 [22528/54000 (42%)] Loss: -1797.093262\n",
      "Train Epoch: 705 [33792/54000 (63%)] Loss: -1813.615234\n",
      "Train Epoch: 705 [45056/54000 (83%)] Loss: -1788.884521\n",
      "    epoch          : 705\n",
      "    loss           : -1797.0661114386792\n",
      "    ess            : 8.0011815934811\n",
      "    log_marginal   : 1797.0661114386792\n",
      "    val_loss       : -1797.4011942545574\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1797.4011942545574\n",
      "Train Epoch: 706 [0/54000 (0%)] Loss: -1809.413574\n",
      "Train Epoch: 706 [11264/54000 (21%)] Loss: -1800.191406\n",
      "Train Epoch: 706 [22528/54000 (42%)] Loss: -1794.346924\n",
      "Train Epoch: 706 [33792/54000 (63%)] Loss: -1811.684570\n",
      "Train Epoch: 706 [45056/54000 (83%)] Loss: -1790.691040\n",
      "    epoch          : 706\n",
      "    loss           : -1794.4892520544663\n",
      "    ess            : 8.001183167943415\n",
      "    log_marginal   : 1794.4892520544663\n",
      "    val_loss       : -1794.3834228515625\n",
      "    val_ess        : 8.001184940338135\n",
      "    val_log_marginal: 1794.3834228515625\n",
      "Train Epoch: 707 [0/54000 (0%)] Loss: -1805.419189\n",
      "Train Epoch: 707 [11264/54000 (21%)] Loss: -1808.388062\n",
      "Train Epoch: 707 [22528/54000 (42%)] Loss: -1796.801514\n",
      "Train Epoch: 707 [33792/54000 (63%)] Loss: -1815.842285\n",
      "Train Epoch: 707 [45056/54000 (83%)] Loss: -1793.401367\n",
      "    epoch          : 707\n",
      "    loss           : -1798.907023879717\n",
      "    ess            : 8.001181296582493\n",
      "    log_marginal   : 1798.9070227281102\n",
      "    val_loss       : -1802.9290262858074\n",
      "    val_ess        : 8.001182874043783\n",
      "    val_log_marginal: 1802.9290262858074\n",
      "Train Epoch: 708 [0/54000 (0%)] Loss: -1815.263428\n",
      "Train Epoch: 708 [11264/54000 (21%)] Loss: -1815.831055\n",
      "Train Epoch: 708 [22528/54000 (42%)] Loss: -1806.384033\n",
      "Train Epoch: 708 [33792/54000 (63%)] Loss: -1821.803467\n",
      "Train Epoch: 708 [45056/54000 (83%)] Loss: -1793.426514\n",
      "    epoch          : 708\n",
      "    loss           : -1802.5743557911999\n",
      "    ess            : 8.00118050485287\n",
      "    log_marginal   : 1802.5743557911999\n",
      "    val_loss       : -1797.9224853515625\n",
      "    val_ess        : 8.001181681950888\n",
      "    val_log_marginal: 1797.9224853515625\n",
      "Train Epoch: 709 [0/54000 (0%)] Loss: -1809.316040\n",
      "Train Epoch: 709 [11264/54000 (21%)] Loss: -1806.165894\n",
      "Train Epoch: 709 [22528/54000 (42%)] Loss: -1795.347412\n",
      "Train Epoch: 709 [33792/54000 (63%)] Loss: -1813.192627\n",
      "Train Epoch: 709 [45056/54000 (83%)] Loss: -1796.991943\n",
      "    epoch          : 709\n",
      "    loss           : -1797.4681891675266\n",
      "    ess            : 8.00118058582522\n",
      "    log_marginal   : 1797.4681891675266\n",
      "    val_loss       : -1801.1853332519531\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1801.1853332519531\n",
      "Train Epoch: 710 [0/54000 (0%)] Loss: -1810.905029\n",
      "Train Epoch: 710 [11264/54000 (21%)] Loss: -1815.665283\n",
      "Train Epoch: 710 [22528/54000 (42%)] Loss: -1803.071533\n",
      "Train Epoch: 710 [33792/54000 (63%)] Loss: -1818.779663\n",
      "Train Epoch: 710 [45056/54000 (83%)] Loss: -1784.266846\n",
      "    epoch          : 710\n",
      "    loss           : -1799.0902606316333\n",
      "    ess            : 8.001181008680812\n",
      "    log_marginal   : 1799.0902629348468\n",
      "    val_loss       : -1792.4010111490886\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1792.4010314941406\n",
      "Train Epoch: 711 [0/54000 (0%)] Loss: -1805.615723\n",
      "Train Epoch: 711 [11264/54000 (21%)] Loss: -1808.414062\n",
      "Train Epoch: 711 [22528/54000 (42%)] Loss: -1796.579224\n",
      "Train Epoch: 711 [33792/54000 (63%)] Loss: -1817.611694\n",
      "Train Epoch: 711 [45056/54000 (83%)] Loss: -1798.692139\n",
      "    epoch          : 711\n",
      "    loss           : -1799.4565913362323\n",
      "    ess            : 8.00118082874226\n",
      "    log_marginal   : 1799.4565936394458\n",
      "    val_loss       : -1801.6850280761719\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1801.6850280761719\n",
      "Train Epoch: 712 [0/54000 (0%)] Loss: -1815.214111\n",
      "Train Epoch: 712 [11264/54000 (21%)] Loss: -1809.773682\n",
      "Train Epoch: 712 [22528/54000 (42%)] Loss: -1800.728516\n",
      "Train Epoch: 712 [33792/54000 (63%)] Loss: -1818.543335\n",
      "Train Epoch: 712 [45056/54000 (83%)] Loss: -1787.968140\n",
      "    epoch          : 712\n",
      "    loss           : -1799.2139028873084\n",
      "    ess            : 8.001180774760696\n",
      "    log_marginal   : 1799.2139028873084\n",
      "    val_loss       : -1792.9757181803386\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1792.9757080078125\n",
      "Train Epoch: 713 [0/54000 (0%)] Loss: -1805.785156\n",
      "Train Epoch: 713 [11264/54000 (21%)] Loss: -1804.771606\n",
      "Train Epoch: 713 [22528/54000 (42%)] Loss: -1798.144287\n",
      "Train Epoch: 713 [33792/54000 (63%)] Loss: -1817.690063\n",
      "Train Epoch: 713 [45056/54000 (83%)] Loss: -1792.345825\n",
      "    epoch          : 713\n",
      "    loss           : -1797.3565662312058\n",
      "    ess            : 8.00118014497577\n",
      "    log_marginal   : 1797.3565673828125\n",
      "    val_loss       : -1794.5235290527344\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1794.5235290527344\n",
      "Train Epoch: 714 [0/54000 (0%)] Loss: -1802.791504\n",
      "Train Epoch: 714 [11264/54000 (21%)] Loss: -1807.651611\n",
      "Train Epoch: 714 [22528/54000 (42%)] Loss: -1798.389893\n",
      "Train Epoch: 714 [33792/54000 (63%)] Loss: -1818.515137\n",
      "Train Epoch: 714 [45056/54000 (83%)] Loss: -1793.069702\n",
      "    epoch          : 714\n",
      "    loss           : -1799.5367708026238\n",
      "    ess            : 8.001179830083307\n",
      "    log_marginal   : 1799.5367708026238\n",
      "    val_loss       : -1806.3225199381511\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1806.3225199381511\n",
      "Train Epoch: 715 [0/54000 (0%)] Loss: -1817.546143\n",
      "Train Epoch: 715 [11264/54000 (21%)] Loss: -1818.941650\n",
      "Train Epoch: 715 [22528/54000 (42%)] Loss: -1805.000366\n",
      "Train Epoch: 715 [33792/54000 (63%)] Loss: -1816.196411\n",
      "Train Epoch: 715 [45056/54000 (83%)] Loss: -1785.979736\n",
      "    epoch          : 715\n",
      "    loss           : -1801.5680265606575\n",
      "    ess            : 8.001180198957336\n",
      "    log_marginal   : 1801.5680265606575\n",
      "    val_loss       : -1800.2253824869792\n",
      "    val_ess        : 8.001181046168009\n",
      "    val_log_marginal: 1800.2253723144531\n",
      "Train Epoch: 716 [0/54000 (0%)] Loss: -1810.491943\n",
      "Train Epoch: 716 [11264/54000 (21%)] Loss: -1814.431152\n",
      "Train Epoch: 716 [22528/54000 (42%)] Loss: -1801.402710\n",
      "Train Epoch: 716 [33792/54000 (63%)] Loss: -1816.134521\n",
      "Train Epoch: 716 [45056/54000 (83%)] Loss: -1792.591553\n",
      "    epoch          : 716\n",
      "    loss           : -1800.9926251105542\n",
      "    ess            : 8.001181494514897\n",
      "    log_marginal   : 1800.9926251105542\n",
      "    val_loss       : -1801.5583394368489\n",
      "    val_ess        : 8.001181523005167\n",
      "    val_log_marginal: 1801.5583394368489\n",
      "Train Epoch: 717 [0/54000 (0%)] Loss: -1812.784302\n",
      "Train Epoch: 717 [11264/54000 (21%)] Loss: -1807.330933\n",
      "Train Epoch: 717 [22528/54000 (42%)] Loss: -1789.222168\n",
      "Train Epoch: 717 [33792/54000 (63%)] Loss: -1810.463135\n",
      "Train Epoch: 717 [45056/54000 (83%)] Loss: -1786.588623\n",
      "    epoch          : 717\n",
      "    loss           : -1794.515939388635\n",
      "    ess            : 8.001180531843653\n",
      "    log_marginal   : 1794.515939388635\n",
      "    val_loss       : -1799.3925069173176\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1799.3925069173176\n",
      "Train Epoch: 718 [0/54000 (0%)] Loss: -1812.799683\n",
      "Train Epoch: 718 [11264/54000 (21%)] Loss: -1812.225586\n",
      "Train Epoch: 718 [22528/54000 (42%)] Loss: -1798.318359\n",
      "Train Epoch: 718 [33792/54000 (63%)] Loss: -1806.633423\n",
      "Train Epoch: 718 [45056/54000 (83%)] Loss: -1779.667480\n",
      "    epoch          : 718\n",
      "    loss           : -1794.2597932635613\n",
      "    ess            : 8.001182088312113\n",
      "    log_marginal   : 1794.2597921119545\n",
      "    val_loss       : -1786.6243184407551\n",
      "    val_ess        : 8.001185337702433\n",
      "    val_log_marginal: 1786.6243184407551\n",
      "Train Epoch: 719 [0/54000 (0%)] Loss: -1797.086426\n",
      "Train Epoch: 719 [11264/54000 (21%)] Loss: -1797.020386\n",
      "Train Epoch: 719 [22528/54000 (42%)] Loss: -1792.618652\n",
      "Train Epoch: 719 [33792/54000 (63%)] Loss: -1799.981689\n",
      "Train Epoch: 719 [45056/54000 (83%)] Loss: -1779.606934\n",
      "    epoch          : 719\n",
      "    loss           : -1788.5754981850678\n",
      "    ess            : 8.001181818404287\n",
      "    log_marginal   : 1788.5754993366745\n",
      "    val_loss       : -1802.1479797363281\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1802.147969563802\n",
      "Train Epoch: 720 [0/54000 (0%)] Loss: -1809.535889\n",
      "Train Epoch: 720 [11264/54000 (21%)] Loss: -1812.970215\n",
      "Train Epoch: 720 [22528/54000 (42%)] Loss: -1792.887451\n",
      "Train Epoch: 720 [33792/54000 (63%)] Loss: -1807.980469\n",
      "Train Epoch: 720 [45056/54000 (83%)] Loss: -1787.710205\n",
      "    epoch          : 720\n",
      "    loss           : -1796.286439139888\n",
      "    ess            : 8.001180324914321\n",
      "    log_marginal   : 1796.286439139888\n",
      "    val_loss       : -1802.2279256184895\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1802.2279256184895\n",
      "Train Epoch: 721 [0/54000 (0%)] Loss: -1811.688721\n",
      "Train Epoch: 721 [11264/54000 (21%)] Loss: -1820.161133\n",
      "Train Epoch: 721 [22528/54000 (42%)] Loss: -1803.115112\n",
      "Train Epoch: 721 [33792/54000 (63%)] Loss: -1818.479248\n",
      "Train Epoch: 721 [45056/54000 (83%)] Loss: -1788.806396\n",
      "    epoch          : 721\n",
      "    loss           : -1802.373431511645\n",
      "    ess            : 8.00118018096348\n",
      "    log_marginal   : 1802.373431511645\n",
      "    val_loss       : -1799.8651123046875\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1799.8651123046875\n",
      "Train Epoch: 722 [0/54000 (0%)] Loss: -1810.829712\n",
      "Train Epoch: 722 [11264/54000 (21%)] Loss: -1813.764648\n",
      "Train Epoch: 722 [22528/54000 (42%)] Loss: -1804.015747\n",
      "Train Epoch: 722 [33792/54000 (63%)] Loss: -1814.512695\n",
      "Train Epoch: 722 [45056/54000 (83%)] Loss: -1786.792603\n",
      "    epoch          : 722\n",
      "    loss           : -1799.3181670566776\n",
      "    ess            : 8.00117971312325\n",
      "    log_marginal   : 1799.3181670566776\n",
      "    val_loss       : -1796.0266723632812\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1796.0266621907551\n",
      "Train Epoch: 723 [0/54000 (0%)] Loss: -1810.588135\n",
      "Train Epoch: 723 [11264/54000 (21%)] Loss: -1812.879395\n",
      "Train Epoch: 723 [22528/54000 (42%)] Loss: -1802.907471\n",
      "Train Epoch: 723 [33792/54000 (63%)] Loss: -1821.663086\n",
      "Train Epoch: 723 [45056/54000 (83%)] Loss: -1794.794067\n",
      "    epoch          : 723\n",
      "    loss           : -1801.4767720924233\n",
      "    ess            : 8.00117935324615\n",
      "    log_marginal   : 1801.476768637603\n",
      "    val_loss       : -1799.409159342448\n",
      "    val_ess        : 8.001181046168009\n",
      "    val_log_marginal: 1799.409159342448\n",
      "Train Epoch: 724 [0/54000 (0%)] Loss: -1809.786987\n",
      "Train Epoch: 724 [11264/54000 (21%)] Loss: -1819.362427\n",
      "Train Epoch: 724 [22528/54000 (42%)] Loss: -1796.818115\n",
      "Train Epoch: 724 [33792/54000 (63%)] Loss: -1813.666260\n",
      "Train Epoch: 724 [45056/54000 (83%)] Loss: -1790.590210\n",
      "    epoch          : 724\n",
      "    loss           : -1798.9367226654629\n",
      "    ess            : 8.001179083338323\n",
      "    log_marginal   : 1798.9367238170696\n",
      "    val_loss       : -1799.054423014323\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1799.054423014323\n",
      "Train Epoch: 725 [0/54000 (0%)] Loss: -1811.773438\n",
      "Train Epoch: 725 [11264/54000 (21%)] Loss: -1813.691406\n",
      "Train Epoch: 725 [22528/54000 (42%)] Loss: -1802.641846\n",
      "Train Epoch: 725 [33792/54000 (63%)] Loss: -1820.549072\n",
      "Train Epoch: 725 [45056/54000 (83%)] Loss: -1799.790527\n",
      "    epoch          : 725\n",
      "    loss           : -1803.2493723743366\n",
      "    ess            : 8.001178687473512\n",
      "    log_marginal   : 1803.2493723743366\n",
      "    val_loss       : -1804.7537434895833\n",
      "    val_ess        : 8.001180489857992\n",
      "    val_log_marginal: 1804.7537638346355\n",
      "Train Epoch: 726 [0/54000 (0%)] Loss: -1814.944946\n",
      "Train Epoch: 726 [11264/54000 (21%)] Loss: -1818.937866\n",
      "Train Epoch: 726 [22528/54000 (42%)] Loss: -1792.820435\n",
      "Train Epoch: 726 [33792/54000 (63%)] Loss: -1773.694946\n",
      "Train Epoch: 726 [45056/54000 (83%)] Loss: -1792.445068\n",
      "    epoch          : 726\n",
      "    loss           : -1791.3638409308667\n",
      "    ess            : 8.00118028892661\n",
      "    log_marginal   : 1791.3638409308667\n",
      "    val_loss       : -1793.9095967610676\n",
      "    val_ess        : 8.001184225082397\n",
      "    val_log_marginal: 1793.9095967610676\n",
      "Train Epoch: 727 [0/54000 (0%)] Loss: -1802.931152\n",
      "Train Epoch: 727 [11264/54000 (21%)] Loss: -1805.337158\n",
      "Train Epoch: 727 [22528/54000 (42%)] Loss: -1747.555420\n",
      "Train Epoch: 727 [33792/54000 (63%)] Loss: -1782.269165\n",
      "Train Epoch: 727 [45056/54000 (83%)] Loss: -1774.625977\n",
      "    epoch          : 727\n",
      "    loss           : -1775.7614515772407\n",
      "    ess            : 8.001183059980285\n",
      "    log_marginal   : 1775.7614515772407\n",
      "    val_loss       : -1793.4999898274739\n",
      "    val_ess        : 8.00118637084961\n",
      "    val_log_marginal: 1793.4999898274739\n",
      "Train Epoch: 728 [0/54000 (0%)] Loss: -1802.002563\n",
      "Train Epoch: 728 [11264/54000 (21%)] Loss: -1811.840210\n",
      "Train Epoch: 728 [22528/54000 (42%)] Loss: -1785.173828\n",
      "Train Epoch: 728 [33792/54000 (63%)] Loss: -1801.041382\n",
      "Train Epoch: 728 [45056/54000 (83%)] Loss: -1781.764160\n",
      "    epoch          : 728\n",
      "    loss           : -1789.8088125552772\n",
      "    ess            : 8.001180711782203\n",
      "    log_marginal   : 1789.8088125552772\n",
      "    val_loss       : -1800.810770670573\n",
      "    val_ess        : 8.00118088722229\n",
      "    val_log_marginal: 1800.8107604980469\n",
      "Train Epoch: 729 [0/54000 (0%)] Loss: -1810.165771\n",
      "Train Epoch: 729 [11264/54000 (21%)] Loss: -1814.443237\n",
      "Train Epoch: 729 [22528/54000 (42%)] Loss: -1796.100708\n",
      "Train Epoch: 729 [33792/54000 (63%)] Loss: -1813.979980\n",
      "Train Epoch: 729 [45056/54000 (83%)] Loss: -1796.177490\n",
      "    epoch          : 729\n",
      "    loss           : -1799.1439289596844\n",
      "    ess            : 8.001180315917393\n",
      "    log_marginal   : 1799.1439289596844\n",
      "    val_loss       : -1807.2450866699219\n",
      "    val_ess        : 8.00118358929952\n",
      "    val_log_marginal: 1807.2450866699219\n",
      "Train Epoch: 730 [0/54000 (0%)] Loss: -1816.213867\n",
      "Train Epoch: 730 [11264/54000 (21%)] Loss: -1812.128906\n",
      "Train Epoch: 730 [22528/54000 (42%)] Loss: -1794.899048\n",
      "Train Epoch: 730 [33792/54000 (63%)] Loss: -1809.861328\n",
      "Train Epoch: 730 [45056/54000 (83%)] Loss: -1792.285522\n",
      "    epoch          : 730\n",
      "    loss           : -1799.4008535709022\n",
      "    ess            : 8.001181980348983\n",
      "    log_marginal   : 1799.4008535709022\n",
      "    val_loss       : -1803.1634318033855\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1803.1634318033855\n",
      "Train Epoch: 731 [0/54000 (0%)] Loss: -1811.457031\n",
      "Train Epoch: 731 [11264/54000 (21%)] Loss: -1813.037598\n",
      "Train Epoch: 731 [22528/54000 (42%)] Loss: -1795.008301\n",
      "Train Epoch: 731 [33792/54000 (63%)] Loss: -1814.081177\n",
      "Train Epoch: 731 [45056/54000 (83%)] Loss: -1798.456299\n",
      "    epoch          : 731\n",
      "    loss           : -1800.62179277528\n",
      "    ess            : 8.001181494514897\n",
      "    log_marginal   : 1800.62179277528\n",
      "    val_loss       : -1807.9069519042969\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1807.906962076823\n",
      "Train Epoch: 732 [0/54000 (0%)] Loss: -1817.514282\n",
      "Train Epoch: 732 [11264/54000 (21%)] Loss: -1809.152832\n",
      "Train Epoch: 732 [22528/54000 (42%)] Loss: -1781.850830\n",
      "Train Epoch: 732 [33792/54000 (63%)] Loss: -1808.134155\n",
      "Train Epoch: 732 [45056/54000 (83%)] Loss: -1792.820801\n",
      "    epoch          : 732\n",
      "    loss           : -1794.8282090672906\n",
      "    ess            : 8.001180540840581\n",
      "    log_marginal   : 1794.8282090672906\n",
      "    val_loss       : -1805.4702555338542\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1805.4702555338542\n",
      "Train Epoch: 733 [0/54000 (0%)] Loss: -1816.540649\n",
      "Train Epoch: 733 [11264/54000 (21%)] Loss: -1818.900879\n",
      "Train Epoch: 733 [22528/54000 (42%)] Loss: -1803.346802\n",
      "Train Epoch: 733 [33792/54000 (63%)] Loss: -1818.644897\n",
      "Train Epoch: 733 [45056/54000 (83%)] Loss: -1796.432983\n",
      "    epoch          : 733\n",
      "    loss           : -1803.8530584371315\n",
      "    ess            : 8.001181188619361\n",
      "    log_marginal   : 1803.8530584371315\n",
      "    val_loss       : -1807.6325988769531\n",
      "    val_ess        : 8.001180410385132\n",
      "    val_log_marginal: 1807.6325988769531\n",
      "Train Epoch: 734 [0/54000 (0%)] Loss: -1816.722534\n",
      "Train Epoch: 734 [11264/54000 (21%)] Loss: -1813.714844\n",
      "Train Epoch: 734 [22528/54000 (42%)] Loss: -1799.054932\n",
      "Train Epoch: 734 [33792/54000 (63%)] Loss: -1809.072998\n",
      "Train Epoch: 734 [45056/54000 (83%)] Loss: -1786.853271\n",
      "    epoch          : 734\n",
      "    loss           : -1796.917877773069\n",
      "    ess            : 8.00118018096348\n",
      "    log_marginal   : 1796.917877773069\n",
      "    val_loss       : -1792.9413146972656\n",
      "    val_ess        : 8.001180330912272\n",
      "    val_log_marginal: 1792.9413146972656\n",
      "Train Epoch: 735 [0/54000 (0%)] Loss: -1802.415283\n",
      "Train Epoch: 735 [11264/54000 (21%)] Loss: -1806.578979\n",
      "Train Epoch: 735 [22528/54000 (42%)] Loss: -1800.106689\n",
      "Train Epoch: 735 [33792/54000 (63%)] Loss: -1818.235596\n",
      "Train Epoch: 735 [45056/54000 (83%)] Loss: -1779.344849\n",
      "    epoch          : 735\n",
      "    loss           : -1794.6968913528156\n",
      "    ess            : 8.001179812089452\n",
      "    log_marginal   : 1794.6968913528156\n",
      "    val_loss       : -1792.7322082519531\n",
      "    val_ess        : 8.00118088722229\n",
      "    val_log_marginal: 1792.7322082519531\n",
      "Train Epoch: 736 [0/54000 (0%)] Loss: -1805.021484\n",
      "Train Epoch: 736 [11264/54000 (21%)] Loss: -1812.986084\n",
      "Train Epoch: 736 [22528/54000 (42%)] Loss: -1801.803711\n",
      "Train Epoch: 736 [33792/54000 (63%)] Loss: -1816.824463\n",
      "Train Epoch: 736 [45056/54000 (83%)] Loss: -1798.794922\n",
      "    epoch          : 736\n",
      "    loss           : -1800.3545244324882\n",
      "    ess            : 8.001180450871306\n",
      "    log_marginal   : 1800.3545232808815\n",
      "    val_loss       : -1807.027099609375\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1807.0270894368489\n",
      "Train Epoch: 737 [0/54000 (0%)] Loss: -1818.489014\n",
      "Train Epoch: 737 [11264/54000 (21%)] Loss: -1818.848877\n",
      "Train Epoch: 737 [22528/54000 (42%)] Loss: -1802.430542\n",
      "Train Epoch: 737 [33792/54000 (63%)] Loss: -1816.344238\n",
      "Train Epoch: 737 [45056/54000 (83%)] Loss: -1788.888916\n",
      "    epoch          : 737\n",
      "    loss           : -1802.0102320257222\n",
      "    ess            : 8.001180765763769\n",
      "    log_marginal   : 1802.0102320257222\n",
      "    val_loss       : -1802.2410888671875\n",
      "    val_ess        : 8.001180251439413\n",
      "    val_log_marginal: 1802.2410888671875\n",
      "Train Epoch: 738 [0/54000 (0%)] Loss: -1814.159180\n",
      "Train Epoch: 738 [11264/54000 (21%)] Loss: -1808.759888\n",
      "Train Epoch: 738 [22528/54000 (42%)] Loss: -1789.742676\n",
      "Train Epoch: 738 [33792/54000 (63%)] Loss: -1815.018555\n",
      "Train Epoch: 738 [45056/54000 (83%)] Loss: -1789.376343\n",
      "    epoch          : 738\n",
      "    loss           : -1797.9781194722877\n",
      "    ess            : 8.001180189960408\n",
      "    log_marginal   : 1797.9781194722877\n",
      "    val_loss       : -1807.0806681315105\n",
      "    val_ess        : 8.001179774602255\n",
      "    val_log_marginal: 1807.0806884765625\n",
      "Train Epoch: 739 [0/54000 (0%)] Loss: -1818.470703\n",
      "Train Epoch: 739 [11264/54000 (21%)] Loss: -1816.255737\n",
      "Train Epoch: 739 [22528/54000 (42%)] Loss: -1799.247070\n",
      "Train Epoch: 739 [33792/54000 (63%)] Loss: -1818.967407\n",
      "Train Epoch: 739 [45056/54000 (83%)] Loss: -1789.824707\n",
      "    epoch          : 739\n",
      "    loss           : -1801.732201918116\n",
      "    ess            : 8.001179335252294\n",
      "    log_marginal   : 1801.732201918116\n",
      "    val_loss       : -1803.8927408854167\n",
      "    val_ess        : 8.001178900400797\n",
      "    val_log_marginal: 1803.8927307128906\n",
      "Train Epoch: 740 [0/54000 (0%)] Loss: -1814.892700\n",
      "Train Epoch: 740 [11264/54000 (21%)] Loss: -1815.479370\n",
      "Train Epoch: 740 [22528/54000 (42%)] Loss: -1805.437866\n",
      "Train Epoch: 740 [33792/54000 (63%)] Loss: -1823.616699\n",
      "Train Epoch: 740 [45056/54000 (83%)] Loss: -1796.578003\n",
      "    epoch          : 740\n",
      "    loss           : -1805.0823928545105\n",
      "    ess            : 8.001179083338323\n",
      "    log_marginal   : 1805.0823928545105\n",
      "    val_loss       : -1805.4882202148438\n",
      "    val_ess        : 8.001179854075113\n",
      "    val_log_marginal: 1805.4882100423176\n",
      "Train Epoch: 741 [0/54000 (0%)] Loss: -1817.336426\n",
      "Train Epoch: 741 [11264/54000 (21%)] Loss: -1814.410889\n",
      "Train Epoch: 741 [22528/54000 (42%)] Loss: -1801.801025\n",
      "Train Epoch: 741 [33792/54000 (63%)] Loss: -1812.465820\n",
      "Train Epoch: 741 [45056/54000 (83%)] Loss: -1776.893555\n",
      "    epoch          : 741\n",
      "    loss           : -1798.4452399487766\n",
      "    ess            : 8.001179371240005\n",
      "    log_marginal   : 1798.445237645563\n",
      "    val_loss       : -1797.387430826823\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1797.387430826823\n",
      "Train Epoch: 742 [0/54000 (0%)] Loss: -1808.512817\n",
      "Train Epoch: 742 [11264/54000 (21%)] Loss: -1810.449707\n",
      "Train Epoch: 742 [22528/54000 (42%)] Loss: -1800.732544\n",
      "Train Epoch: 742 [33792/54000 (63%)] Loss: -1822.529663\n",
      "Train Epoch: 742 [45056/54000 (83%)] Loss: -1790.215454\n",
      "    epoch          : 742\n",
      "    loss           : -1801.337464530513\n",
      "    ess            : 8.001179587166265\n",
      "    log_marginal   : 1801.337464530513\n",
      "    val_loss       : -1800.0387369791667\n",
      "    val_ess        : 8.001180251439413\n",
      "    val_log_marginal: 1800.0387471516926\n",
      "Train Epoch: 743 [0/54000 (0%)] Loss: -1812.366943\n",
      "Train Epoch: 743 [11264/54000 (21%)] Loss: -1812.529297\n",
      "Train Epoch: 743 [22528/54000 (42%)] Loss: -1796.558594\n",
      "Train Epoch: 743 [33792/54000 (63%)] Loss: -1816.087280\n",
      "Train Epoch: 743 [45056/54000 (83%)] Loss: -1794.509766\n",
      "    epoch          : 743\n",
      "    loss           : -1799.9718017578125\n",
      "    ess            : 8.001180028015712\n",
      "    log_marginal   : 1799.9718017578125\n",
      "    val_loss       : -1808.0476175944011\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1808.0476175944011\n",
      "Train Epoch: 744 [0/54000 (0%)] Loss: -1821.175049\n",
      "Train Epoch: 744 [11264/54000 (21%)] Loss: -1821.331665\n",
      "Train Epoch: 744 [22528/54000 (42%)] Loss: -1804.603027\n",
      "Train Epoch: 744 [33792/54000 (63%)] Loss: -1821.535645\n",
      "Train Epoch: 744 [45056/54000 (83%)] Loss: -1795.934326\n",
      "    epoch          : 744\n",
      "    loss           : -1805.1811293116157\n",
      "    ess            : 8.001179047350613\n",
      "    log_marginal   : 1805.1811304632222\n",
      "    val_loss       : -1802.8386739095051\n",
      "    val_ess        : 8.001178503036499\n",
      "    val_log_marginal: 1802.8386739095051\n",
      "Train Epoch: 745 [0/54000 (0%)] Loss: -1815.734497\n",
      "Train Epoch: 745 [11264/54000 (21%)] Loss: -1813.120605\n",
      "Train Epoch: 745 [22528/54000 (42%)] Loss: -1791.818237\n",
      "Train Epoch: 745 [33792/54000 (63%)] Loss: -1809.827148\n",
      "Train Epoch: 745 [45056/54000 (83%)] Loss: -1784.420654\n",
      "    epoch          : 745\n",
      "    loss           : -1796.2567265348614\n",
      "    ess            : 8.001179407227713\n",
      "    log_marginal   : 1796.2567265348614\n",
      "    val_loss       : -1797.9418131510417\n",
      "    val_ess        : 8.001184463500977\n",
      "    val_log_marginal: 1797.9418131510417\n",
      "Train Epoch: 746 [0/54000 (0%)] Loss: -1811.427368\n",
      "Train Epoch: 746 [11264/54000 (21%)] Loss: -1814.793213\n",
      "Train Epoch: 746 [22528/54000 (42%)] Loss: -1803.733398\n",
      "Train Epoch: 746 [33792/54000 (63%)] Loss: -1809.700928\n",
      "Train Epoch: 746 [45056/54000 (83%)] Loss: -1784.067871\n",
      "    epoch          : 746\n",
      "    loss           : -1798.3177732071786\n",
      "    ess            : 8.001179902058727\n",
      "    log_marginal   : 1798.3177732071786\n",
      "    val_loss       : -1798.9947408040364\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1798.9947408040364\n",
      "Train Epoch: 747 [0/54000 (0%)] Loss: -1810.693115\n",
      "Train Epoch: 747 [11264/54000 (21%)] Loss: -1810.172119\n",
      "Train Epoch: 747 [22528/54000 (42%)] Loss: -1797.268066\n",
      "Train Epoch: 747 [33792/54000 (63%)] Loss: -1822.307495\n",
      "Train Epoch: 747 [45056/54000 (83%)] Loss: -1799.329346\n",
      "    epoch          : 747\n",
      "    loss           : -1802.314788242556\n",
      "    ess            : 8.001180684791422\n",
      "    log_marginal   : 1802.314788242556\n",
      "    val_loss       : -1806.5360310872395\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1806.5360310872395\n",
      "Train Epoch: 748 [0/54000 (0%)] Loss: -1816.804810\n",
      "Train Epoch: 748 [11264/54000 (21%)] Loss: -1814.613281\n",
      "Train Epoch: 748 [22528/54000 (42%)] Loss: -1793.986328\n",
      "Train Epoch: 748 [33792/54000 (63%)] Loss: -1814.678589\n",
      "Train Epoch: 748 [45056/54000 (83%)] Loss: -1790.901611\n",
      "    epoch          : 748\n",
      "    loss           : -1799.675454193691\n",
      "    ess            : 8.001179956040293\n",
      "    log_marginal   : 1799.6754553452977\n",
      "    val_loss       : -1805.0646870930989\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1805.0646870930989\n",
      "Train Epoch: 749 [0/54000 (0%)] Loss: -1816.221313\n",
      "Train Epoch: 749 [11264/54000 (21%)] Loss: -1819.652588\n",
      "Train Epoch: 749 [22528/54000 (42%)] Loss: -1803.369629\n",
      "Train Epoch: 749 [33792/54000 (63%)] Loss: -1820.586426\n",
      "Train Epoch: 749 [45056/54000 (83%)] Loss: -1793.048828\n",
      "    epoch          : 749\n",
      "    loss           : -1803.821963904039\n",
      "    ess            : 8.001179767104814\n",
      "    log_marginal   : 1803.821963904039\n",
      "    val_loss       : -1797.6400756835938\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1797.6400756835938\n",
      "Train Epoch: 750 [0/54000 (0%)] Loss: -1810.917847\n",
      "Train Epoch: 750 [11264/54000 (21%)] Loss: -1806.426270\n",
      "Train Epoch: 750 [22528/54000 (42%)] Loss: -1796.157227\n",
      "Train Epoch: 750 [33792/54000 (63%)] Loss: -1818.124268\n",
      "Train Epoch: 750 [45056/54000 (83%)] Loss: -1793.353027\n",
      "    epoch          : 750\n",
      "    loss           : -1798.7507519991893\n",
      "    ess            : 8.001180711782203\n",
      "    log_marginal   : 1798.7507519991893\n",
      "    val_loss       : -1806.7577107747395\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1806.7577107747395\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch750.pth ...\n",
      "Train Epoch: 751 [0/54000 (0%)] Loss: -1819.652466\n",
      "Train Epoch: 751 [11264/54000 (21%)] Loss: -1817.208496\n",
      "Train Epoch: 751 [22528/54000 (42%)] Loss: -1800.266113\n",
      "Train Epoch: 751 [33792/54000 (63%)] Loss: -1811.105103\n",
      "Train Epoch: 751 [45056/54000 (83%)] Loss: -1790.221802\n",
      "    epoch          : 751\n",
      "    loss           : -1800.8847287735848\n",
      "    ess            : 8.001179623153975\n",
      "    log_marginal   : 1800.8847287735848\n",
      "    val_loss       : -1789.7218017578125\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1789.7218017578125\n",
      "Train Epoch: 752 [0/54000 (0%)] Loss: -1802.308594\n",
      "Train Epoch: 752 [11264/54000 (21%)] Loss: -1797.889893\n",
      "Train Epoch: 752 [22528/54000 (42%)] Loss: -1769.206299\n",
      "Train Epoch: 752 [33792/54000 (63%)] Loss: -1803.727417\n",
      "Train Epoch: 752 [45056/54000 (83%)] Loss: -1781.117798\n",
      "    epoch          : 752\n",
      "    loss           : -1784.9445443783166\n",
      "    ess            : 8.001182898035589\n",
      "    log_marginal   : 1784.9445443783166\n",
      "    val_loss       : -1798.1336263020833\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1798.1336161295574\n",
      "Train Epoch: 753 [0/54000 (0%)] Loss: -1812.412964\n",
      "Train Epoch: 753 [11264/54000 (21%)] Loss: -1808.324951\n",
      "Train Epoch: 753 [22528/54000 (42%)] Loss: -1785.916992\n",
      "Train Epoch: 753 [33792/54000 (63%)] Loss: -1811.653809\n",
      "Train Epoch: 753 [45056/54000 (83%)] Loss: -1784.866455\n",
      "    epoch          : 753\n",
      "    loss           : -1793.5621487599499\n",
      "    ess            : 8.0011829340233\n",
      "    log_marginal   : 1793.5621476083431\n",
      "    val_loss       : -1801.7437845865886\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1801.7437845865886\n",
      "Train Epoch: 754 [0/54000 (0%)] Loss: -1813.066162\n",
      "Train Epoch: 754 [11264/54000 (21%)] Loss: -1806.801880\n",
      "Train Epoch: 754 [22528/54000 (42%)] Loss: -1792.200562\n",
      "Train Epoch: 754 [33792/54000 (63%)] Loss: -1813.041382\n",
      "Train Epoch: 754 [45056/54000 (83%)] Loss: -1786.829102\n",
      "    epoch          : 754\n",
      "    loss           : -1796.140534023069\n",
      "    ess            : 8.001182259253735\n",
      "    log_marginal   : 1796.140534023069\n",
      "    val_loss       : -1795.868876139323\n",
      "    val_ess        : 8.001183350880941\n",
      "    val_log_marginal: 1795.868876139323\n",
      "Train Epoch: 755 [0/54000 (0%)] Loss: -1807.925537\n",
      "Train Epoch: 755 [11264/54000 (21%)] Loss: -1800.426758\n",
      "Train Epoch: 755 [22528/54000 (42%)] Loss: -1794.218262\n",
      "Train Epoch: 755 [33792/54000 (63%)] Loss: -1814.333008\n",
      "Train Epoch: 755 [45056/54000 (83%)] Loss: -1796.946411\n",
      "    epoch          : 755\n",
      "    loss           : -1797.2507796377506\n",
      "    ess            : 8.001181305579419\n",
      "    log_marginal   : 1797.2507796377506\n",
      "    val_loss       : -1804.8652852376301\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1804.8652852376301\n",
      "Train Epoch: 756 [0/54000 (0%)] Loss: -1817.194092\n",
      "Train Epoch: 756 [11264/54000 (21%)] Loss: -1810.223877\n",
      "Train Epoch: 756 [22528/54000 (42%)] Loss: -1792.476929\n",
      "Train Epoch: 756 [33792/54000 (63%)] Loss: -1813.075439\n",
      "Train Epoch: 756 [45056/54000 (83%)] Loss: -1791.578125\n",
      "    epoch          : 756\n",
      "    loss           : -1798.2468687813237\n",
      "    ess            : 8.001179668138612\n",
      "    log_marginal   : 1798.2468687813237\n",
      "    val_loss       : -1802.2765401204426\n",
      "    val_ess        : 8.001182158788046\n",
      "    val_log_marginal: 1802.2765401204426\n",
      "Train Epoch: 757 [0/54000 (0%)] Loss: -1816.268555\n",
      "Train Epoch: 757 [11264/54000 (21%)] Loss: -1812.855713\n",
      "Train Epoch: 757 [22528/54000 (42%)] Loss: -1801.385864\n",
      "Train Epoch: 757 [33792/54000 (63%)] Loss: -1813.374023\n",
      "Train Epoch: 757 [45056/54000 (83%)] Loss: -1794.275879\n",
      "    epoch          : 757\n",
      "    loss           : -1800.4762630822524\n",
      "    ess            : 8.001181350564057\n",
      "    log_marginal   : 1800.4762630822524\n",
      "    val_loss       : -1802.9398701985676\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1802.9398701985676\n",
      "Train Epoch: 758 [0/54000 (0%)] Loss: -1814.685303\n",
      "Train Epoch: 758 [11264/54000 (21%)] Loss: -1807.953613\n",
      "Train Epoch: 758 [22528/54000 (42%)] Loss: -1797.117188\n",
      "Train Epoch: 758 [33792/54000 (63%)] Loss: -1812.717407\n",
      "Train Epoch: 758 [45056/54000 (83%)] Loss: -1787.437988\n",
      "    epoch          : 758\n",
      "    loss           : -1797.8994854621167\n",
      "    ess            : 8.001180046009567\n",
      "    log_marginal   : 1797.8994854621167\n",
      "    val_loss       : -1800.9960835774739\n",
      "    val_ess        : 8.001182874043783\n",
      "    val_log_marginal: 1800.996073404948\n",
      "Train Epoch: 759 [0/54000 (0%)] Loss: -1812.696289\n",
      "Train Epoch: 759 [11264/54000 (21%)] Loss: -1817.591309\n",
      "Train Epoch: 759 [22528/54000 (42%)] Loss: -1801.659424\n",
      "Train Epoch: 759 [33792/54000 (63%)] Loss: -1815.842285\n",
      "Train Epoch: 759 [45056/54000 (83%)] Loss: -1784.684082\n",
      "    epoch          : 759\n",
      "    loss           : -1800.988756863576\n",
      "    ess            : 8.00118000102493\n",
      "    log_marginal   : 1800.988756863576\n",
      "    val_loss       : -1803.0627950032551\n",
      "    val_ess        : 8.001180410385132\n",
      "    val_log_marginal: 1803.0627950032551\n",
      "Train Epoch: 760 [0/54000 (0%)] Loss: -1814.441406\n",
      "Train Epoch: 760 [11264/54000 (21%)] Loss: -1818.596191\n",
      "Train Epoch: 760 [22528/54000 (42%)] Loss: -1800.938599\n",
      "Train Epoch: 760 [33792/54000 (63%)] Loss: -1818.083496\n",
      "Train Epoch: 760 [45056/54000 (83%)] Loss: -1792.503662\n",
      "    epoch          : 760\n",
      "    loss           : -1802.233034529776\n",
      "    ess            : 8.00118144953026\n",
      "    log_marginal   : 1802.2330356813827\n",
      "    val_loss       : -1808.6131286621094\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1808.6131083170574\n",
      "Train Epoch: 761 [0/54000 (0%)] Loss: -1819.927002\n",
      "Train Epoch: 761 [11264/54000 (21%)] Loss: -1819.004028\n",
      "Train Epoch: 761 [22528/54000 (42%)] Loss: -1801.320312\n",
      "Train Epoch: 761 [33792/54000 (63%)] Loss: -1813.458984\n",
      "Train Epoch: 761 [45056/54000 (83%)] Loss: -1793.171021\n",
      "    epoch          : 761\n",
      "    loss           : -1800.8025501179245\n",
      "    ess            : 8.001180963696173\n",
      "    log_marginal   : 1800.8025501179245\n",
      "    val_loss       : -1805.0033162434895\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1805.0032958984375\n",
      "Train Epoch: 762 [0/54000 (0%)] Loss: -1818.658691\n",
      "Train Epoch: 762 [11264/54000 (21%)] Loss: -1815.437134\n",
      "Train Epoch: 762 [22528/54000 (42%)] Loss: -1798.808594\n",
      "Train Epoch: 762 [33792/54000 (63%)] Loss: -1818.950439\n",
      "Train Epoch: 762 [45056/54000 (83%)] Loss: -1796.287231\n",
      "    epoch          : 762\n",
      "    loss           : -1802.0159716336232\n",
      "    ess            : 8.00118028892661\n",
      "    log_marginal   : 1802.0159716336232\n",
      "    val_loss       : -1806.6183369954426\n",
      "    val_ess        : 8.001180092493692\n",
      "    val_log_marginal: 1806.6183369954426\n",
      "Train Epoch: 763 [0/54000 (0%)] Loss: -1820.815918\n",
      "Train Epoch: 763 [11264/54000 (21%)] Loss: -1814.988037\n",
      "Train Epoch: 763 [22528/54000 (42%)] Loss: -1796.480225\n",
      "Train Epoch: 763 [33792/54000 (63%)] Loss: -1819.440552\n",
      "Train Epoch: 763 [45056/54000 (83%)] Loss: -1793.690918\n",
      "    epoch          : 763\n",
      "    loss           : -1801.6025321528596\n",
      "    ess            : 8.00117873245815\n",
      "    log_marginal   : 1801.6025321528596\n",
      "    val_loss       : -1805.9520365397136\n",
      "    val_ess        : 8.001181046168009\n",
      "    val_log_marginal: 1805.9520365397136\n",
      "Train Epoch: 764 [0/54000 (0%)] Loss: -1819.068359\n",
      "Train Epoch: 764 [11264/54000 (21%)] Loss: -1817.448730\n",
      "Train Epoch: 764 [22528/54000 (42%)] Loss: -1803.490234\n",
      "Train Epoch: 764 [33792/54000 (63%)] Loss: -1817.622803\n",
      "Train Epoch: 764 [45056/54000 (83%)] Loss: -1788.516602\n",
      "    epoch          : 764\n",
      "    loss           : -1802.6179751989976\n",
      "    ess            : 8.001179128322962\n",
      "    log_marginal   : 1802.6179740473908\n",
      "    val_loss       : -1802.3850402832031\n",
      "    val_ess        : 8.001179456710815\n",
      "    val_log_marginal: 1802.3850402832031\n",
      "Train Epoch: 765 [0/54000 (0%)] Loss: -1815.346191\n",
      "Train Epoch: 765 [11264/54000 (21%)] Loss: -1814.366699\n",
      "Train Epoch: 765 [22528/54000 (42%)] Loss: -1802.165161\n",
      "Train Epoch: 765 [33792/54000 (63%)] Loss: -1814.918579\n",
      "Train Epoch: 765 [45056/54000 (83%)] Loss: -1791.556641\n",
      "    epoch          : 765\n",
      "    loss           : -1801.5169343768425\n",
      "    ess            : 8.001178633491948\n",
      "    log_marginal   : 1801.5169343768425\n",
      "    val_loss       : -1805.6078999837239\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1805.6078999837239\n",
      "Train Epoch: 766 [0/54000 (0%)] Loss: -1818.799561\n",
      "Train Epoch: 766 [11264/54000 (21%)] Loss: -1817.482422\n",
      "Train Epoch: 766 [22528/54000 (42%)] Loss: -1797.779663\n",
      "Train Epoch: 766 [33792/54000 (63%)] Loss: -1811.376465\n",
      "Train Epoch: 766 [45056/54000 (83%)] Loss: -1787.500977\n",
      "    epoch          : 766\n",
      "    loss           : -1799.2988373378537\n",
      "    ess            : 8.001178255620992\n",
      "    log_marginal   : 1799.2988373378537\n",
      "    val_loss       : -1800.2290852864583\n",
      "    val_ess        : 8.001176834106445\n",
      "    val_log_marginal: 1800.2290852864583\n",
      "Train Epoch: 767 [0/54000 (0%)] Loss: -1812.042480\n",
      "Train Epoch: 767 [11264/54000 (21%)] Loss: -1815.957275\n",
      "Train Epoch: 767 [22528/54000 (42%)] Loss: -1801.714111\n",
      "Train Epoch: 767 [33792/54000 (63%)] Loss: -1821.718018\n",
      "Train Epoch: 767 [45056/54000 (83%)] Loss: -1797.915283\n",
      "    epoch          : 767\n",
      "    loss           : -1802.742655052329\n",
      "    ess            : 8.001178930390555\n",
      "    log_marginal   : 1802.7426539007222\n",
      "    val_loss       : -1806.8428446451824\n",
      "    val_ess        : 8.001180013020834\n",
      "    val_log_marginal: 1806.8428446451824\n",
      "Train Epoch: 768 [0/54000 (0%)] Loss: -1818.993408\n",
      "Train Epoch: 768 [11264/54000 (21%)] Loss: -1813.943726\n",
      "Train Epoch: 768 [22528/54000 (42%)] Loss: -1797.776978\n",
      "Train Epoch: 768 [33792/54000 (63%)] Loss: -1817.320923\n",
      "Train Epoch: 768 [45056/54000 (83%)] Loss: -1794.235840\n",
      "    epoch          : 768\n",
      "    loss           : -1800.1789078622494\n",
      "    ess            : 8.001179434218496\n",
      "    log_marginal   : 1800.1789078622494\n",
      "    val_loss       : -1801.4794311523438\n",
      "    val_ess        : 8.001179615656534\n",
      "    val_log_marginal: 1801.4794311523438\n",
      "Train Epoch: 769 [0/54000 (0%)] Loss: -1812.865967\n",
      "Train Epoch: 769 [11264/54000 (21%)] Loss: -1818.583984\n",
      "Train Epoch: 769 [22528/54000 (42%)] Loss: -1805.239258\n",
      "Train Epoch: 769 [33792/54000 (63%)] Loss: -1822.428711\n",
      "Train Epoch: 769 [45056/54000 (83%)] Loss: -1796.175049\n",
      "    epoch          : 769\n",
      "    loss           : -1804.5333447726268\n",
      "    ess            : 8.00117826461792\n",
      "    log_marginal   : 1804.5333447726268\n",
      "    val_loss       : -1802.4244588216145\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1802.4244384765625\n",
      "Train Epoch: 770 [0/54000 (0%)] Loss: -1814.091797\n",
      "Train Epoch: 770 [11264/54000 (21%)] Loss: -1817.829834\n",
      "Train Epoch: 770 [22528/54000 (42%)] Loss: -1798.481567\n",
      "Train Epoch: 770 [33792/54000 (63%)] Loss: -1813.923828\n",
      "Train Epoch: 770 [45056/54000 (83%)] Loss: -1796.364990\n",
      "    epoch          : 770\n",
      "    loss           : -1801.5873862212559\n",
      "    ess            : 8.001179875067944\n",
      "    log_marginal   : 1801.5873850696491\n",
      "    val_loss       : -1806.4693298339844\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1806.4693298339844\n",
      "Train Epoch: 771 [0/54000 (0%)] Loss: -1817.414062\n",
      "Train Epoch: 771 [11264/54000 (21%)] Loss: -1820.427246\n",
      "Train Epoch: 771 [22528/54000 (42%)] Loss: -1800.845703\n",
      "Train Epoch: 771 [33792/54000 (63%)] Loss: -1802.072998\n",
      "Train Epoch: 771 [45056/54000 (83%)] Loss: -1792.296265\n",
      "    epoch          : 771\n",
      "    loss           : -1799.331059293927\n",
      "    ess            : 8.00117884042128\n",
      "    log_marginal   : 1799.331059293927\n",
      "    val_loss       : -1803.639872233073\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1803.6398824055989\n",
      "Train Epoch: 772 [0/54000 (0%)] Loss: -1816.301392\n",
      "Train Epoch: 772 [11264/54000 (21%)] Loss: -1810.813477\n",
      "Train Epoch: 772 [22528/54000 (42%)] Loss: -1797.625000\n",
      "Train Epoch: 772 [33792/54000 (63%)] Loss: -1818.398560\n",
      "Train Epoch: 772 [45056/54000 (83%)] Loss: -1801.410767\n",
      "    epoch          : 772\n",
      "    loss           : -1801.7150360683224\n",
      "    ess            : 8.001178363584122\n",
      "    log_marginal   : 1801.7150360683224\n",
      "    val_loss       : -1804.249755859375\n",
      "    val_ess        : 8.001179615656534\n",
      "    val_log_marginal: 1804.249735514323\n",
      "Train Epoch: 773 [0/54000 (0%)] Loss: -1815.816040\n",
      "Train Epoch: 773 [11264/54000 (21%)] Loss: -1802.715088\n",
      "Train Epoch: 773 [22528/54000 (42%)] Loss: -1792.945923\n",
      "Train Epoch: 773 [33792/54000 (63%)] Loss: -1816.129639\n",
      "Train Epoch: 773 [45056/54000 (83%)] Loss: -1792.026001\n",
      "    epoch          : 773\n",
      "    loss           : -1797.7702106979657\n",
      "    ess            : 8.001180324914321\n",
      "    log_marginal   : 1797.7702106979657\n",
      "    val_loss       : -1809.1856587727864\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1809.1856689453125\n",
      "Train Epoch: 774 [0/54000 (0%)] Loss: -1819.854370\n",
      "Train Epoch: 774 [11264/54000 (21%)] Loss: -1818.830078\n",
      "Train Epoch: 774 [22528/54000 (42%)] Loss: -1808.126465\n",
      "Train Epoch: 774 [33792/54000 (63%)] Loss: -1821.086670\n",
      "Train Epoch: 774 [45056/54000 (83%)] Loss: -1788.861816\n",
      "    epoch          : 774\n",
      "    loss           : -1804.9698601488797\n",
      "    ess            : 8.001178318599486\n",
      "    log_marginal   : 1804.969858997273\n",
      "    val_loss       : -1800.4790954589844\n",
      "    val_ess        : 8.001180251439413\n",
      "    val_log_marginal: 1800.4790954589844\n",
      "Train Epoch: 775 [0/54000 (0%)] Loss: -1813.176514\n",
      "Train Epoch: 775 [11264/54000 (21%)] Loss: -1814.162354\n",
      "Train Epoch: 775 [22528/54000 (42%)] Loss: -1802.133545\n",
      "Train Epoch: 775 [33792/54000 (63%)] Loss: -1815.152588\n",
      "Train Epoch: 775 [45056/54000 (83%)] Loss: -1793.695435\n",
      "    epoch          : 775\n",
      "    loss           : -1802.0676810786408\n",
      "    ess            : 8.001179128322962\n",
      "    log_marginal   : 1802.0676810786408\n",
      "    val_loss       : -1808.7161560058594\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1808.7161560058594\n",
      "Train Epoch: 776 [0/54000 (0%)] Loss: -1820.419434\n",
      "Train Epoch: 776 [11264/54000 (21%)] Loss: -1812.318481\n",
      "Train Epoch: 776 [22528/54000 (42%)] Loss: -1793.490601\n",
      "Train Epoch: 776 [33792/54000 (63%)] Loss: -1812.983643\n",
      "Train Epoch: 776 [45056/54000 (83%)] Loss: -1790.797607\n",
      "    epoch          : 776\n",
      "    loss           : -1798.875864856648\n",
      "    ess            : 8.001178003707022\n",
      "    log_marginal   : 1798.875864856648\n",
      "    val_loss       : -1802.3785807291667\n",
      "    val_ess        : 8.001180489857992\n",
      "    val_log_marginal: 1802.3785807291667\n",
      "Train Epoch: 777 [0/54000 (0%)] Loss: -1813.089111\n",
      "Train Epoch: 777 [11264/54000 (21%)] Loss: -1816.300293\n",
      "Train Epoch: 777 [22528/54000 (42%)] Loss: -1804.359619\n",
      "Train Epoch: 777 [33792/54000 (63%)] Loss: -1820.761108\n",
      "Train Epoch: 777 [45056/54000 (83%)] Loss: -1796.525391\n",
      "    epoch          : 777\n",
      "    loss           : -1803.505466677108\n",
      "    ess            : 8.001177850759253\n",
      "    log_marginal   : 1803.5054678287147\n",
      "    val_loss       : -1802.4432983398438\n",
      "    val_ess        : 8.001177867253622\n",
      "    val_log_marginal: 1802.4432983398438\n",
      "Train Epoch: 778 [0/54000 (0%)] Loss: -1814.451416\n",
      "Train Epoch: 778 [11264/54000 (21%)] Loss: -1808.494629\n",
      "Train Epoch: 778 [22528/54000 (42%)] Loss: -1768.164795\n",
      "Train Epoch: 778 [33792/54000 (63%)] Loss: -1774.618896\n",
      "Train Epoch: 778 [45056/54000 (83%)] Loss: -1761.644043\n",
      "    epoch          : 778\n",
      "    loss           : -1777.4325169977153\n",
      "    ess            : 8.001180810748407\n",
      "    log_marginal   : 1777.4325169977153\n",
      "    val_loss       : -1780.0153401692708\n",
      "    val_ess        : 8.001185099283854\n",
      "    val_log_marginal: 1780.0153401692708\n",
      "Train Epoch: 779 [0/54000 (0%)] Loss: -1790.898682\n",
      "Train Epoch: 779 [11264/54000 (21%)] Loss: -1805.728760\n",
      "Train Epoch: 779 [22528/54000 (42%)] Loss: -1787.443726\n",
      "Train Epoch: 779 [33792/54000 (63%)] Loss: -1806.663574\n",
      "Train Epoch: 779 [45056/54000 (83%)] Loss: -1777.340332\n",
      "    epoch          : 779\n",
      "    loss           : -1787.6095085863797\n",
      "    ess            : 8.001182961014083\n",
      "    log_marginal   : 1787.609507434773\n",
      "    val_loss       : -1792.7244974772136\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1792.7244974772136\n",
      "Train Epoch: 780 [0/54000 (0%)] Loss: -1803.112183\n",
      "Train Epoch: 780 [11264/54000 (21%)] Loss: -1811.411377\n",
      "Train Epoch: 780 [22528/54000 (42%)] Loss: -1793.117920\n",
      "Train Epoch: 780 [33792/54000 (63%)] Loss: -1808.333740\n",
      "Train Epoch: 780 [45056/54000 (83%)] Loss: -1790.113892\n",
      "    epoch          : 780\n",
      "    loss           : -1795.5623376234523\n",
      "    ess            : 8.001181323573274\n",
      "    log_marginal   : 1795.562338775059\n",
      "    val_loss       : -1798.9327596028645\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1798.9327494303386\n",
      "Train Epoch: 781 [0/54000 (0%)] Loss: -1805.707642\n",
      "Train Epoch: 781 [11264/54000 (21%)] Loss: -1811.656250\n",
      "Train Epoch: 781 [22528/54000 (42%)] Loss: -1797.617188\n",
      "Train Epoch: 781 [33792/54000 (63%)] Loss: -1813.634888\n",
      "Train Epoch: 781 [45056/54000 (83%)] Loss: -1795.810303\n",
      "    epoch          : 781\n",
      "    loss           : -1799.7299954396374\n",
      "    ess            : 8.001180162969625\n",
      "    log_marginal   : 1799.7299954396374\n",
      "    val_loss       : -1805.9397888183594\n",
      "    val_ess        : 8.001181602478027\n",
      "    val_log_marginal: 1805.9397786458333\n",
      "Train Epoch: 782 [0/54000 (0%)] Loss: -1816.021973\n",
      "Train Epoch: 782 [11264/54000 (21%)] Loss: -1816.718018\n",
      "Train Epoch: 782 [22528/54000 (42%)] Loss: -1799.495239\n",
      "Train Epoch: 782 [33792/54000 (63%)] Loss: -1817.596924\n",
      "Train Epoch: 782 [45056/54000 (83%)] Loss: -1799.464355\n",
      "    epoch          : 782\n",
      "    loss           : -1803.5203396779186\n",
      "    ess            : 8.00117869647044\n",
      "    log_marginal   : 1803.5203396779186\n",
      "    val_loss       : -1806.1483764648438\n",
      "    val_ess        : 8.001179854075113\n",
      "    val_log_marginal: 1806.1483764648438\n",
      "Train Epoch: 783 [0/54000 (0%)] Loss: -1818.128418\n",
      "Train Epoch: 783 [11264/54000 (21%)] Loss: -1813.994141\n",
      "Train Epoch: 783 [22528/54000 (42%)] Loss: -1796.124878\n",
      "Train Epoch: 783 [33792/54000 (63%)] Loss: -1814.872314\n",
      "Train Epoch: 783 [45056/54000 (83%)] Loss: -1793.930176\n",
      "    epoch          : 783\n",
      "    loss           : -1800.8893144715507\n",
      "    ess            : 8.001180270932755\n",
      "    log_marginal   : 1800.8893144715507\n",
      "    val_loss       : -1798.8104146321614\n",
      "    val_ess        : 8.001181602478027\n",
      "    val_log_marginal: 1798.8104146321614\n",
      "Train Epoch: 784 [0/54000 (0%)] Loss: -1807.495605\n",
      "Train Epoch: 784 [11264/54000 (21%)] Loss: -1807.797363\n",
      "Train Epoch: 784 [22528/54000 (42%)] Loss: -1795.037109\n",
      "Train Epoch: 784 [33792/54000 (63%)] Loss: -1813.124146\n",
      "Train Epoch: 784 [45056/54000 (83%)] Loss: -1790.924683\n",
      "    epoch          : 784\n",
      "    loss           : -1797.8303049915241\n",
      "    ess            : 8.00117985707409\n",
      "    log_marginal   : 1797.8303038399174\n",
      "    val_loss       : -1794.4035542805989\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1794.4035542805989\n",
      "Train Epoch: 785 [0/54000 (0%)] Loss: -1805.815674\n",
      "Train Epoch: 785 [11264/54000 (21%)] Loss: -1807.637939\n",
      "Train Epoch: 785 [22528/54000 (42%)] Loss: -1794.379150\n",
      "Train Epoch: 785 [33792/54000 (63%)] Loss: -1815.269165\n",
      "Train Epoch: 785 [45056/54000 (83%)] Loss: -1791.503418\n",
      "    epoch          : 785\n",
      "    loss           : -1796.589521300118\n",
      "    ess            : 8.001179488200062\n",
      "    log_marginal   : 1796.589521300118\n",
      "    val_loss       : -1803.1119689941406\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1803.1119689941406\n",
      "Train Epoch: 786 [0/54000 (0%)] Loss: -1813.577148\n",
      "Train Epoch: 786 [11264/54000 (21%)] Loss: -1816.266602\n",
      "Train Epoch: 786 [22528/54000 (42%)] Loss: -1793.730713\n",
      "Train Epoch: 786 [33792/54000 (63%)] Loss: -1810.235229\n",
      "Train Epoch: 786 [45056/54000 (83%)] Loss: -1792.270752\n",
      "    epoch          : 786\n",
      "    loss           : -1797.7249801923645\n",
      "    ess            : 8.001180207954263\n",
      "    log_marginal   : 1797.7249801923645\n",
      "    val_loss       : -1802.2173665364583\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1802.2173665364583\n",
      "Train Epoch: 787 [0/54000 (0%)] Loss: -1812.623169\n",
      "Train Epoch: 787 [11264/54000 (21%)] Loss: -1815.316406\n",
      "Train Epoch: 787 [22528/54000 (42%)] Loss: -1805.318848\n",
      "Train Epoch: 787 [33792/54000 (63%)] Loss: -1825.992920\n",
      "Train Epoch: 787 [45056/54000 (83%)] Loss: -1796.150391\n",
      "    epoch          : 787\n",
      "    loss           : -1803.8757934570312\n",
      "    ess            : 8.001179119326034\n",
      "    log_marginal   : 1803.875794608638\n",
      "    val_loss       : -1798.4461975097656\n",
      "    val_ess        : 8.001180489857992\n",
      "    val_log_marginal: 1798.4461975097656\n",
      "Train Epoch: 788 [0/54000 (0%)] Loss: -1810.854492\n",
      "Train Epoch: 788 [11264/54000 (21%)] Loss: -1812.134888\n",
      "Train Epoch: 788 [22528/54000 (42%)] Loss: -1798.085693\n",
      "Train Epoch: 788 [33792/54000 (63%)] Loss: -1814.254028\n",
      "Train Epoch: 788 [45056/54000 (83%)] Loss: -1801.390625\n",
      "    epoch          : 788\n",
      "    loss           : -1801.0958390145931\n",
      "    ess            : 8.001179506193917\n",
      "    log_marginal   : 1801.0958390145931\n",
      "    val_loss       : -1806.8299153645833\n",
      "    val_ess        : 8.001181046168009\n",
      "    val_log_marginal: 1806.8299153645833\n",
      "Train Epoch: 789 [0/54000 (0%)] Loss: -1816.989502\n",
      "Train Epoch: 789 [11264/54000 (21%)] Loss: -1818.323975\n",
      "Train Epoch: 789 [22528/54000 (42%)] Loss: -1798.094971\n",
      "Train Epoch: 789 [33792/54000 (63%)] Loss: -1818.904297\n",
      "Train Epoch: 789 [45056/54000 (83%)] Loss: -1797.802490\n",
      "    epoch          : 789\n",
      "    loss           : -1803.103386645047\n",
      "    ess            : 8.001179434218496\n",
      "    log_marginal   : 1803.103386645047\n",
      "    val_loss       : -1800.3610941569011\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1800.361104329427\n",
      "Train Epoch: 790 [0/54000 (0%)] Loss: -1811.753540\n",
      "Train Epoch: 790 [11264/54000 (21%)] Loss: -1817.792480\n",
      "Train Epoch: 790 [22528/54000 (42%)] Loss: -1798.233887\n",
      "Train Epoch: 790 [33792/54000 (63%)] Loss: -1819.159180\n",
      "Train Epoch: 790 [45056/54000 (83%)] Loss: -1799.609619\n",
      "    epoch          : 790\n",
      "    loss           : -1802.7817267651828\n",
      "    ess            : 8.001179470206207\n",
      "    log_marginal   : 1802.7817267651828\n",
      "    val_loss       : -1807.9531656901042\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1807.9531555175781\n",
      "Train Epoch: 791 [0/54000 (0%)] Loss: -1821.500488\n",
      "Train Epoch: 791 [11264/54000 (21%)] Loss: -1820.362549\n",
      "Train Epoch: 791 [22528/54000 (42%)] Loss: -1799.910889\n",
      "Train Epoch: 791 [33792/54000 (63%)] Loss: -1814.881104\n",
      "Train Epoch: 791 [45056/54000 (83%)] Loss: -1799.108643\n",
      "    epoch          : 791\n",
      "    loss           : -1803.298497613871\n",
      "    ess            : 8.001178957381338\n",
      "    log_marginal   : 1803.298497613871\n",
      "    val_loss       : -1804.79345703125\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1804.7934468587239\n",
      "Train Epoch: 792 [0/54000 (0%)] Loss: -1816.920288\n",
      "Train Epoch: 792 [11264/54000 (21%)] Loss: -1818.000244\n",
      "Train Epoch: 792 [22528/54000 (42%)] Loss: -1802.258789\n",
      "Train Epoch: 792 [33792/54000 (63%)] Loss: -1820.441406\n",
      "Train Epoch: 792 [45056/54000 (83%)] Loss: -1800.901245\n",
      "    epoch          : 792\n",
      "    loss           : -1804.7129228699882\n",
      "    ess            : 8.001179488200062\n",
      "    log_marginal   : 1804.7129228699882\n",
      "    val_loss       : -1808.9437662760417\n",
      "    val_ess        : 8.001181046168009\n",
      "    val_log_marginal: 1808.9437662760417\n",
      "Train Epoch: 793 [0/54000 (0%)] Loss: -1822.007812\n",
      "Train Epoch: 793 [11264/54000 (21%)] Loss: -1809.619629\n",
      "Train Epoch: 793 [22528/54000 (42%)] Loss: -1796.388184\n",
      "Train Epoch: 793 [33792/54000 (63%)] Loss: -1815.779297\n",
      "Train Epoch: 793 [45056/54000 (83%)] Loss: -1793.412476\n",
      "    epoch          : 793\n",
      "    loss           : -1799.1550661482902\n",
      "    ess            : 8.001180855733043\n",
      "    log_marginal   : 1799.1550661482902\n",
      "    val_loss       : -1804.3208719889324\n",
      "    val_ess        : 8.0011838277181\n",
      "    val_log_marginal: 1804.3208719889324\n",
      "Train Epoch: 794 [0/54000 (0%)] Loss: -1815.294922\n",
      "Train Epoch: 794 [11264/54000 (21%)] Loss: -1817.421387\n",
      "Train Epoch: 794 [22528/54000 (42%)] Loss: -1804.183594\n",
      "Train Epoch: 794 [33792/54000 (63%)] Loss: -1814.296387\n",
      "Train Epoch: 794 [45056/54000 (83%)] Loss: -1794.032104\n",
      "    epoch          : 794\n",
      "    loss           : -1801.799187426297\n",
      "    ess            : 8.001179416224641\n",
      "    log_marginal   : 1801.799187426297\n",
      "    val_loss       : -1803.4036560058594\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1803.4036356608074\n",
      "Train Epoch: 795 [0/54000 (0%)] Loss: -1812.792725\n",
      "Train Epoch: 795 [11264/54000 (21%)] Loss: -1812.987793\n",
      "Train Epoch: 795 [22528/54000 (42%)] Loss: -1803.588745\n",
      "Train Epoch: 795 [33792/54000 (63%)] Loss: -1821.818359\n",
      "Train Epoch: 795 [45056/54000 (83%)] Loss: -1795.299805\n",
      "    epoch          : 795\n",
      "    loss           : -1803.1170688845077\n",
      "    ess            : 8.00117985707409\n",
      "    log_marginal   : 1803.1170688845077\n",
      "    val_loss       : -1804.3433329264324\n",
      "    val_ess        : 8.001179774602255\n",
      "    val_log_marginal: 1804.3433430989583\n",
      "Train Epoch: 796 [0/54000 (0%)] Loss: -1815.705200\n",
      "Train Epoch: 796 [11264/54000 (21%)] Loss: -1807.858032\n",
      "Train Epoch: 796 [22528/54000 (42%)] Loss: -1798.000732\n",
      "Train Epoch: 796 [33792/54000 (63%)] Loss: -1816.688232\n",
      "Train Epoch: 796 [45056/54000 (83%)] Loss: -1794.867432\n",
      "    epoch          : 796\n",
      "    loss           : -1799.4980618458874\n",
      "    ess            : 8.001178876408991\n",
      "    log_marginal   : 1799.4980618458874\n",
      "    val_loss       : -1804.3089497884114\n",
      "    val_ess        : 8.001181920369467\n",
      "    val_log_marginal: 1804.3089497884114\n",
      "Train Epoch: 797 [0/54000 (0%)] Loss: -1815.396362\n",
      "Train Epoch: 797 [11264/54000 (21%)] Loss: -1818.426025\n",
      "Train Epoch: 797 [22528/54000 (42%)] Loss: -1805.009399\n",
      "Train Epoch: 797 [33792/54000 (63%)] Loss: -1811.950928\n",
      "Train Epoch: 797 [45056/54000 (83%)] Loss: -1792.918945\n",
      "    epoch          : 797\n",
      "    loss           : -1801.4874267578125\n",
      "    ess            : 8.001179488200062\n",
      "    log_marginal   : 1801.4874267578125\n",
      "    val_loss       : -1803.1986389160156\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1803.1986389160156\n",
      "Train Epoch: 798 [0/54000 (0%)] Loss: -1813.373291\n",
      "Train Epoch: 798 [11264/54000 (21%)] Loss: -1813.942871\n",
      "Train Epoch: 798 [22528/54000 (42%)] Loss: -1802.673462\n",
      "Train Epoch: 798 [33792/54000 (63%)] Loss: -1818.126953\n",
      "Train Epoch: 798 [45056/54000 (83%)] Loss: -1793.273315\n",
      "    epoch          : 798\n",
      "    loss           : -1803.4445029204746\n",
      "    ess            : 8.00117858850731\n",
      "    log_marginal   : 1803.4445029204746\n",
      "    val_loss       : -1806.9997049967449\n",
      "    val_ess        : 8.001178979873657\n",
      "    val_log_marginal: 1806.9997151692708\n",
      "Train Epoch: 799 [0/54000 (0%)] Loss: -1817.571411\n",
      "Train Epoch: 799 [11264/54000 (21%)] Loss: -1818.485107\n",
      "Train Epoch: 799 [22528/54000 (42%)] Loss: -1803.244995\n",
      "Train Epoch: 799 [33792/54000 (63%)] Loss: -1811.764038\n",
      "Train Epoch: 799 [45056/54000 (83%)] Loss: -1788.763184\n",
      "    epoch          : 799\n",
      "    loss           : -1802.1531487230984\n",
      "    ess            : 8.001178543522673\n",
      "    log_marginal   : 1802.1531487230984\n",
      "    val_loss       : -1803.1441141764324\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1803.1441141764324\n",
      "Train Epoch: 800 [0/54000 (0%)] Loss: -1814.664551\n",
      "Train Epoch: 800 [11264/54000 (21%)] Loss: -1814.595215\n",
      "Train Epoch: 800 [22528/54000 (42%)] Loss: -1794.609131\n",
      "Train Epoch: 800 [33792/54000 (63%)] Loss: -1817.048828\n",
      "Train Epoch: 800 [45056/54000 (83%)] Loss: -1792.519043\n",
      "    epoch          : 800\n",
      "    loss           : -1799.260580962559\n",
      "    ess            : 8.001180882723826\n",
      "    log_marginal   : 1799.260580962559\n",
      "    val_loss       : -1803.0768025716145\n",
      "    val_ess        : 8.001180251439413\n",
      "    val_log_marginal: 1803.0768025716145\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch800.pth ...\n",
      "Train Epoch: 801 [0/54000 (0%)] Loss: -1814.368408\n",
      "Train Epoch: 801 [11264/54000 (21%)] Loss: -1816.335693\n",
      "Train Epoch: 801 [22528/54000 (42%)] Loss: -1790.521240\n",
      "Train Epoch: 801 [33792/54000 (63%)] Loss: -1815.034912\n",
      "Train Epoch: 801 [45056/54000 (83%)] Loss: -1794.822388\n",
      "    epoch          : 801\n",
      "    loss           : -1798.4782392393868\n",
      "    ess            : 8.001178435559543\n",
      "    log_marginal   : 1798.47823808778\n",
      "    val_loss       : -1800.9442952473958\n",
      "    val_ess        : 8.00117818514506\n",
      "    val_log_marginal: 1800.9442952473958\n",
      "Train Epoch: 802 [0/54000 (0%)] Loss: -1812.817993\n",
      "Train Epoch: 802 [11264/54000 (21%)] Loss: -1806.941406\n",
      "Train Epoch: 802 [22528/54000 (42%)] Loss: -1793.792358\n",
      "Train Epoch: 802 [33792/54000 (63%)] Loss: -1817.834717\n",
      "Train Epoch: 802 [45056/54000 (83%)] Loss: -1789.428711\n",
      "    epoch          : 802\n",
      "    loss           : -1797.8001144697082\n",
      "    ess            : 8.001177607842212\n",
      "    log_marginal   : 1797.8001144697082\n",
      "    val_loss       : -1797.539815266927\n",
      "    val_ess        : 8.001176595687866\n",
      "    val_log_marginal: 1797.539815266927\n",
      "Train Epoch: 803 [0/54000 (0%)] Loss: -1810.045288\n",
      "Train Epoch: 803 [11264/54000 (21%)] Loss: -1814.454224\n",
      "Train Epoch: 803 [22528/54000 (42%)] Loss: -1769.247437\n",
      "Train Epoch: 803 [33792/54000 (63%)] Loss: -1795.673828\n",
      "Train Epoch: 803 [45056/54000 (83%)] Loss: -1780.087646\n",
      "    epoch          : 803\n",
      "    loss           : -1786.624888294148\n",
      "    ess            : 8.001179416224641\n",
      "    log_marginal   : 1786.624888294148\n",
      "    val_loss       : -1793.2884419759114\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1793.2884114583333\n",
      "Train Epoch: 804 [0/54000 (0%)] Loss: -1804.261963\n",
      "Train Epoch: 804 [11264/54000 (21%)] Loss: -1807.457886\n",
      "Train Epoch: 804 [22528/54000 (42%)] Loss: -1790.891602\n",
      "Train Epoch: 804 [33792/54000 (63%)] Loss: -1812.121948\n",
      "Train Epoch: 804 [45056/54000 (83%)] Loss: -1788.763184\n",
      "    epoch          : 804\n",
      "    loss           : -1794.5115252800708\n",
      "    ess            : 8.001178894402846\n",
      "    log_marginal   : 1794.511524128464\n",
      "    val_loss       : -1800.736348470052\n",
      "    val_ess        : 8.001177151997885\n",
      "    val_log_marginal: 1800.736348470052\n",
      "Train Epoch: 805 [0/54000 (0%)] Loss: -1812.130737\n",
      "Train Epoch: 805 [11264/54000 (21%)] Loss: -1814.997192\n",
      "Train Epoch: 805 [22528/54000 (42%)] Loss: -1797.912476\n",
      "Train Epoch: 805 [33792/54000 (63%)] Loss: -1818.786377\n",
      "Train Epoch: 805 [45056/54000 (83%)] Loss: -1792.493774\n",
      "    epoch          : 805\n",
      "    loss           : -1799.2178747788914\n",
      "    ess            : 8.001177598845285\n",
      "    log_marginal   : 1799.2178747788914\n",
      "    val_loss       : -1797.528055826823\n",
      "    val_ess        : 8.001176198323568\n",
      "    val_log_marginal: 1797.528055826823\n",
      "Train Epoch: 806 [0/54000 (0%)] Loss: -1809.315674\n",
      "Train Epoch: 806 [11264/54000 (21%)] Loss: -1804.238403\n",
      "Train Epoch: 806 [22528/54000 (42%)] Loss: -1785.288818\n",
      "Train Epoch: 806 [33792/54000 (63%)] Loss: -1813.389160\n",
      "Train Epoch: 806 [45056/54000 (83%)] Loss: -1791.167725\n",
      "    epoch          : 806\n",
      "    loss           : -1793.9186746849205\n",
      "    ess            : 8.001181323573274\n",
      "    log_marginal   : 1793.9186746849205\n",
      "    val_loss       : -1802.0204467773438\n",
      "    val_ess        : 8.001182794570923\n",
      "    val_log_marginal: 1802.0204569498699\n",
      "Train Epoch: 807 [0/54000 (0%)] Loss: -1817.188843\n",
      "Train Epoch: 807 [11264/54000 (21%)] Loss: -1820.081665\n",
      "Train Epoch: 807 [22528/54000 (42%)] Loss: -1802.252319\n",
      "Train Epoch: 807 [33792/54000 (63%)] Loss: -1821.688721\n",
      "Train Epoch: 807 [45056/54000 (83%)] Loss: -1790.023560\n",
      "    epoch          : 807\n",
      "    loss           : -1803.1515572026092\n",
      "    ess            : 8.001179596163192\n",
      "    log_marginal   : 1803.1515595058224\n",
      "    val_loss       : -1800.5941772460938\n",
      "    val_ess        : 8.001182874043783\n",
      "    val_log_marginal: 1800.5941772460938\n",
      "Train Epoch: 808 [0/54000 (0%)] Loss: -1813.881104\n",
      "Train Epoch: 808 [11264/54000 (21%)] Loss: -1817.510742\n",
      "Train Epoch: 808 [22528/54000 (42%)] Loss: -1795.028442\n",
      "Train Epoch: 808 [33792/54000 (63%)] Loss: -1816.784424\n",
      "Train Epoch: 808 [45056/54000 (83%)] Loss: -1782.244507\n",
      "    epoch          : 808\n",
      "    loss           : -1798.1860201853626\n",
      "    ess            : 8.001179623153975\n",
      "    log_marginal   : 1798.1860201853626\n",
      "    val_loss       : -1799.3801167805989\n",
      "    val_ess        : 8.001181681950888\n",
      "    val_log_marginal: 1799.3801167805989\n",
      "Train Epoch: 809 [0/54000 (0%)] Loss: -1812.856201\n",
      "Train Epoch: 809 [11264/54000 (21%)] Loss: -1814.375000\n",
      "Train Epoch: 809 [22528/54000 (42%)] Loss: -1796.399658\n",
      "Train Epoch: 809 [33792/54000 (63%)] Loss: -1817.680908\n",
      "Train Epoch: 809 [45056/54000 (83%)] Loss: -1788.092285\n",
      "    epoch          : 809\n",
      "    loss           : -1799.045612839033\n",
      "    ess            : 8.001180010021857\n",
      "    log_marginal   : 1799.0456116874263\n",
      "    val_loss       : -1802.3349914550781\n",
      "    val_ess        : 8.001180092493692\n",
      "    val_log_marginal: 1802.3349914550781\n",
      "Train Epoch: 810 [0/54000 (0%)] Loss: -1810.174683\n",
      "Train Epoch: 810 [11264/54000 (21%)] Loss: -1808.752686\n",
      "Train Epoch: 810 [22528/54000 (42%)] Loss: -1793.472168\n",
      "Train Epoch: 810 [33792/54000 (63%)] Loss: -1816.007935\n",
      "Train Epoch: 810 [45056/54000 (83%)] Loss: -1793.575195\n",
      "    epoch          : 810\n",
      "    loss           : -1798.1294601728332\n",
      "    ess            : 8.00117996503722\n",
      "    log_marginal   : 1798.1294601728332\n",
      "    val_loss       : -1805.7638651529949\n",
      "    val_ess        : 8.001179377237955\n",
      "    val_log_marginal: 1805.7638651529949\n",
      "Train Epoch: 811 [0/54000 (0%)] Loss: -1816.480225\n",
      "Train Epoch: 811 [11264/54000 (21%)] Loss: -1813.047974\n",
      "Train Epoch: 811 [22528/54000 (42%)] Loss: -1796.240234\n",
      "Train Epoch: 811 [33792/54000 (63%)] Loss: -1809.846924\n",
      "Train Epoch: 811 [45056/54000 (83%)] Loss: -1787.001709\n",
      "    epoch          : 811\n",
      "    loss           : -1797.340049887603\n",
      "    ess            : 8.001180135978842\n",
      "    log_marginal   : 1797.3400510392098\n",
      "    val_loss       : -1797.1422627766926\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1797.1422627766926\n",
      "Train Epoch: 812 [0/54000 (0%)] Loss: -1810.585815\n",
      "Train Epoch: 812 [11264/54000 (21%)] Loss: -1817.287354\n",
      "Train Epoch: 812 [22528/54000 (42%)] Loss: -1801.842896\n",
      "Train Epoch: 812 [33792/54000 (63%)] Loss: -1824.318604\n",
      "Train Epoch: 812 [45056/54000 (83%)] Loss: -1789.313843\n",
      "    epoch          : 812\n",
      "    loss           : -1801.5277882701946\n",
      "    ess            : 8.00117946120928\n",
      "    log_marginal   : 1801.5277871185879\n",
      "    val_loss       : -1795.1298217773438\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1795.1298217773438\n",
      "Train Epoch: 813 [0/54000 (0%)] Loss: -1810.133789\n",
      "Train Epoch: 813 [11264/54000 (21%)] Loss: -1819.226562\n",
      "Train Epoch: 813 [22528/54000 (42%)] Loss: -1795.469360\n",
      "Train Epoch: 813 [33792/54000 (63%)] Loss: -1823.281738\n",
      "Train Epoch: 813 [45056/54000 (83%)] Loss: -1797.949097\n",
      "    epoch          : 813\n",
      "    loss           : -1802.8039919295402\n",
      "    ess            : 8.001180055006495\n",
      "    log_marginal   : 1802.803993081147\n",
      "    val_loss       : -1807.9041748046875\n",
      "    val_ess        : 8.001180013020834\n",
      "    val_log_marginal: 1807.9041544596355\n",
      "Train Epoch: 814 [0/54000 (0%)] Loss: -1821.939209\n",
      "Train Epoch: 814 [11264/54000 (21%)] Loss: -1822.385498\n",
      "Train Epoch: 814 [22528/54000 (42%)] Loss: -1804.512451\n",
      "Train Epoch: 814 [33792/54000 (63%)] Loss: -1816.270508\n",
      "Train Epoch: 814 [45056/54000 (83%)] Loss: -1786.081787\n",
      "    epoch          : 814\n",
      "    loss           : -1800.8396249447228\n",
      "    ess            : 8.001179335252294\n",
      "    log_marginal   : 1800.8396249447228\n",
      "    val_loss       : -1784.1517130533855\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1784.1517130533855\n",
      "Train Epoch: 815 [0/54000 (0%)] Loss: -1800.229858\n",
      "Train Epoch: 815 [11264/54000 (21%)] Loss: -1803.984619\n",
      "Train Epoch: 815 [22528/54000 (42%)] Loss: -1766.940308\n",
      "Train Epoch: 815 [33792/54000 (63%)] Loss: -1798.582031\n",
      "Train Epoch: 815 [45056/54000 (83%)] Loss: -1779.633789\n",
      "    epoch          : 815\n",
      "    loss           : -1780.4783256098908\n",
      "    ess            : 8.001183320891183\n",
      "    log_marginal   : 1780.4783256098908\n",
      "    val_loss       : -1798.4913228352864\n",
      "    val_ess        : 8.001184781392416\n",
      "    val_log_marginal: 1798.4913228352864\n",
      "Train Epoch: 816 [0/54000 (0%)] Loss: -1813.528564\n",
      "Train Epoch: 816 [11264/54000 (21%)] Loss: -1817.604980\n",
      "Train Epoch: 816 [22528/54000 (42%)] Loss: -1790.638062\n",
      "Train Epoch: 816 [33792/54000 (63%)] Loss: -1812.116333\n",
      "Train Epoch: 816 [45056/54000 (83%)] Loss: -1783.745605\n",
      "    epoch          : 816\n",
      "    loss           : -1793.7150567972435\n",
      "    ess            : 8.00118180940736\n",
      "    log_marginal   : 1793.7150579488502\n",
      "    val_loss       : -1794.7572123209636\n",
      "    val_ess        : 8.001184145609537\n",
      "    val_log_marginal: 1794.7572123209636\n",
      "Train Epoch: 817 [0/54000 (0%)] Loss: -1807.104614\n",
      "Train Epoch: 817 [11264/54000 (21%)] Loss: -1808.889648\n",
      "Train Epoch: 817 [22528/54000 (42%)] Loss: -1786.657715\n",
      "Train Epoch: 817 [33792/54000 (63%)] Loss: -1809.538574\n",
      "Train Epoch: 817 [45056/54000 (83%)] Loss: -1790.461426\n",
      "    epoch          : 817\n",
      "    loss           : -1793.7847819778156\n",
      "    ess            : 8.00118220527217\n",
      "    log_marginal   : 1793.7847819778156\n",
      "    val_loss       : -1804.8998413085938\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1804.8998413085938\n",
      "Train Epoch: 818 [0/54000 (0%)] Loss: -1816.934570\n",
      "Train Epoch: 818 [11264/54000 (21%)] Loss: -1818.739990\n",
      "Train Epoch: 818 [22528/54000 (42%)] Loss: -1797.129517\n",
      "Train Epoch: 818 [33792/54000 (63%)] Loss: -1824.338745\n",
      "Train Epoch: 818 [45056/54000 (83%)] Loss: -1793.753662\n",
      "    epoch          : 818\n",
      "    loss           : -1803.5763526772553\n",
      "    ess            : 8.001180702785277\n",
      "    log_marginal   : 1803.5763526772553\n",
      "    val_loss       : -1805.321797688802\n",
      "    val_ess        : 8.001180251439413\n",
      "    val_log_marginal: 1805.321797688802\n",
      "Train Epoch: 819 [0/54000 (0%)] Loss: -1818.347412\n",
      "Train Epoch: 819 [11264/54000 (21%)] Loss: -1816.723145\n",
      "Train Epoch: 819 [22528/54000 (42%)] Loss: -1794.215576\n",
      "Train Epoch: 819 [33792/54000 (63%)] Loss: -1823.044189\n",
      "Train Epoch: 819 [45056/54000 (83%)] Loss: -1793.795898\n",
      "    epoch          : 819\n",
      "    loss           : -1802.108795741819\n",
      "    ess            : 8.001179326255366\n",
      "    log_marginal   : 1802.108795741819\n",
      "    val_loss       : -1806.0211588541667\n",
      "    val_ess        : 8.001180013020834\n",
      "    val_log_marginal: 1806.0211588541667\n",
      "Train Epoch: 820 [0/54000 (0%)] Loss: -1819.924683\n",
      "Train Epoch: 820 [11264/54000 (21%)] Loss: -1815.964600\n",
      "Train Epoch: 820 [22528/54000 (42%)] Loss: -1797.154297\n",
      "Train Epoch: 820 [33792/54000 (63%)] Loss: -1816.623535\n",
      "Train Epoch: 820 [45056/54000 (83%)] Loss: -1792.486816\n",
      "    epoch          : 820\n",
      "    loss           : -1801.197216105911\n",
      "    ess            : 8.001181170625507\n",
      "    log_marginal   : 1801.197216105911\n",
      "    val_loss       : -1807.6151936848958\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1807.6151936848958\n",
      "Train Epoch: 821 [0/54000 (0%)] Loss: -1820.617676\n",
      "Train Epoch: 821 [11264/54000 (21%)] Loss: -1822.006836\n",
      "Train Epoch: 821 [22528/54000 (42%)] Loss: -1804.609131\n",
      "Train Epoch: 821 [33792/54000 (63%)] Loss: -1824.716553\n",
      "Train Epoch: 821 [45056/54000 (83%)] Loss: -1795.321777\n",
      "    epoch          : 821\n",
      "    loss           : -1805.904698785746\n",
      "    ess            : 8.001179038353687\n",
      "    log_marginal   : 1805.904698785746\n",
      "    val_loss       : -1806.425801595052\n",
      "    val_ess        : 8.001181920369467\n",
      "    val_log_marginal: 1806.425801595052\n",
      "Train Epoch: 822 [0/54000 (0%)] Loss: -1819.220947\n",
      "Train Epoch: 822 [11264/54000 (21%)] Loss: -1820.550537\n",
      "Train Epoch: 822 [22528/54000 (42%)] Loss: -1801.372681\n",
      "Train Epoch: 822 [33792/54000 (63%)] Loss: -1822.236328\n",
      "Train Epoch: 822 [45056/54000 (83%)] Loss: -1799.166382\n",
      "    epoch          : 822\n",
      "    loss           : -1805.5415730026532\n",
      "    ess            : 8.001180108988061\n",
      "    log_marginal   : 1805.5415730026532\n",
      "    val_loss       : -1802.2608337402344\n",
      "    val_ess        : 8.00118096669515\n",
      "    val_log_marginal: 1802.2608337402344\n",
      "Train Epoch: 823 [0/54000 (0%)] Loss: -1815.141602\n",
      "Train Epoch: 823 [11264/54000 (21%)] Loss: -1811.459106\n",
      "Train Epoch: 823 [22528/54000 (42%)] Loss: -1791.893311\n",
      "Train Epoch: 823 [33792/54000 (63%)] Loss: -1808.876465\n",
      "Train Epoch: 823 [45056/54000 (83%)] Loss: -1787.050537\n",
      "    epoch          : 823\n",
      "    loss           : -1795.531623120578\n",
      "    ess            : 8.001181422539478\n",
      "    log_marginal   : 1795.531623120578\n",
      "    val_loss       : -1797.1566263834636\n",
      "    val_ess        : 8.00118056933085\n",
      "    val_log_marginal: 1797.1566467285156\n",
      "Train Epoch: 824 [0/54000 (0%)] Loss: -1812.935547\n",
      "Train Epoch: 824 [11264/54000 (21%)] Loss: -1818.072754\n",
      "Train Epoch: 824 [22528/54000 (42%)] Loss: -1803.741943\n",
      "Train Epoch: 824 [33792/54000 (63%)] Loss: -1820.921265\n",
      "Train Epoch: 824 [45056/54000 (83%)] Loss: -1793.450317\n",
      "    epoch          : 824\n",
      "    loss           : -1802.1386833910672\n",
      "    ess            : 8.00118090971461\n",
      "    log_marginal   : 1802.1386833910672\n",
      "    val_loss       : -1797.749735514323\n",
      "    val_ess        : 8.001179615656534\n",
      "    val_log_marginal: 1797.7497456868489\n",
      "Train Epoch: 825 [0/54000 (0%)] Loss: -1809.432861\n",
      "Train Epoch: 825 [11264/54000 (21%)] Loss: -1811.732178\n",
      "Train Epoch: 825 [22528/54000 (42%)] Loss: -1800.368896\n",
      "Train Epoch: 825 [33792/54000 (63%)] Loss: -1820.464355\n",
      "Train Epoch: 825 [45056/54000 (83%)] Loss: -1795.784668\n",
      "    epoch          : 825\n",
      "    loss           : -1800.9894259470814\n",
      "    ess            : 8.001179992028003\n",
      "    log_marginal   : 1800.989427098688\n",
      "    val_loss       : -1803.3030192057292\n",
      "    val_ess        : 8.001179377237955\n",
      "    val_log_marginal: 1803.3030192057292\n",
      "Train Epoch: 826 [0/54000 (0%)] Loss: -1814.833008\n",
      "Train Epoch: 826 [11264/54000 (21%)] Loss: -1814.378784\n",
      "Train Epoch: 826 [22528/54000 (42%)] Loss: -1794.234497\n",
      "Train Epoch: 826 [33792/54000 (63%)] Loss: -1806.267944\n",
      "Train Epoch: 826 [45056/54000 (83%)] Loss: -1785.017578\n",
      "    epoch          : 826\n",
      "    loss           : -1795.6738315798202\n",
      "    ess            : 8.001179848077163\n",
      "    log_marginal   : 1795.6738315798202\n",
      "    val_loss       : -1794.2328186035156\n",
      "    val_ess        : 8.00118319193522\n",
      "    val_log_marginal: 1794.2328186035156\n",
      "Train Epoch: 827 [0/54000 (0%)] Loss: -1806.470703\n",
      "Train Epoch: 827 [11264/54000 (21%)] Loss: -1807.705322\n",
      "Train Epoch: 827 [22528/54000 (42%)] Loss: -1793.829834\n",
      "Train Epoch: 827 [33792/54000 (63%)] Loss: -1819.638428\n",
      "Train Epoch: 827 [45056/54000 (83%)] Loss: -1800.677734\n",
      "    epoch          : 827\n",
      "    loss           : -1800.1218399911556\n",
      "    ess            : 8.00118014497577\n",
      "    log_marginal   : 1800.121838839549\n",
      "    val_loss       : -1808.6671346028645\n",
      "    val_ess        : 8.001176675160727\n",
      "    val_log_marginal: 1808.6671346028645\n",
      "Train Epoch: 828 [0/54000 (0%)] Loss: -1821.077759\n",
      "Train Epoch: 828 [11264/54000 (21%)] Loss: -1814.018311\n",
      "Train Epoch: 828 [22528/54000 (42%)] Loss: -1793.991333\n",
      "Train Epoch: 828 [33792/54000 (63%)] Loss: -1817.168945\n",
      "Train Epoch: 828 [45056/54000 (83%)] Loss: -1797.067871\n",
      "    epoch          : 828\n",
      "    loss           : -1801.1085320238797\n",
      "    ess            : 8.001177679817632\n",
      "    log_marginal   : 1801.1085320238797\n",
      "    val_loss       : -1802.0562845865886\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1802.0562845865886\n",
      "Train Epoch: 829 [0/54000 (0%)] Loss: -1811.843262\n",
      "Train Epoch: 829 [11264/54000 (21%)] Loss: -1814.714722\n",
      "Train Epoch: 829 [22528/54000 (42%)] Loss: -1808.260864\n",
      "Train Epoch: 829 [33792/54000 (63%)] Loss: -1828.743652\n",
      "Train Epoch: 829 [45056/54000 (83%)] Loss: -1795.936768\n",
      "    epoch          : 829\n",
      "    loss           : -1805.2437456238945\n",
      "    ess            : 8.001178705467368\n",
      "    log_marginal   : 1805.2437456238945\n",
      "    val_loss       : -1788.1424255371094\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1788.1424051920574\n",
      "Train Epoch: 830 [0/54000 (0%)] Loss: -1803.097656\n",
      "Train Epoch: 830 [11264/54000 (21%)] Loss: -1812.726929\n",
      "Train Epoch: 830 [22528/54000 (42%)] Loss: -1800.946533\n",
      "Train Epoch: 830 [33792/54000 (63%)] Loss: -1823.570801\n",
      "Train Epoch: 830 [45056/54000 (83%)] Loss: -1795.139404\n",
      "    epoch          : 830\n",
      "    loss           : -1800.999561237839\n",
      "    ess            : 8.001180019018785\n",
      "    log_marginal   : 1800.9995600862323\n",
      "    val_loss       : -1802.6937052408855\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1802.6937052408855\n",
      "Train Epoch: 831 [0/54000 (0%)] Loss: -1815.872803\n",
      "Train Epoch: 831 [11264/54000 (21%)] Loss: -1820.854858\n",
      "Train Epoch: 831 [22528/54000 (42%)] Loss: -1802.936279\n",
      "Train Epoch: 831 [33792/54000 (63%)] Loss: -1819.630493\n",
      "Train Epoch: 831 [45056/54000 (83%)] Loss: -1794.536255\n",
      "    epoch          : 831\n",
      "    loss           : -1802.6283039596844\n",
      "    ess            : 8.001178471547252\n",
      "    log_marginal   : 1802.6283039596844\n",
      "    val_loss       : -1802.1085917154949\n",
      "    val_ess        : 8.001178979873657\n",
      "    val_log_marginal: 1802.1086018880208\n",
      "Train Epoch: 832 [0/54000 (0%)] Loss: -1812.859131\n",
      "Train Epoch: 832 [11264/54000 (21%)] Loss: -1816.628296\n",
      "Train Epoch: 832 [22528/54000 (42%)] Loss: -1797.642944\n",
      "Train Epoch: 832 [33792/54000 (63%)] Loss: -1820.422363\n",
      "Train Epoch: 832 [45056/54000 (83%)] Loss: -1795.000366\n",
      "    epoch          : 832\n",
      "    loss           : -1801.911492113797\n",
      "    ess            : 8.001177742796123\n",
      "    log_marginal   : 1801.911492113797\n",
      "    val_loss       : -1804.1369730631511\n",
      "    val_ess        : 8.001179377237955\n",
      "    val_log_marginal: 1804.1369730631511\n",
      "Train Epoch: 833 [0/54000 (0%)] Loss: -1819.109985\n",
      "Train Epoch: 833 [11264/54000 (21%)] Loss: -1806.104614\n",
      "Train Epoch: 833 [22528/54000 (42%)] Loss: -1794.076660\n",
      "Train Epoch: 833 [33792/54000 (63%)] Loss: -1818.937500\n",
      "Train Epoch: 833 [45056/54000 (83%)] Loss: -1793.339844\n",
      "    epoch          : 833\n",
      "    loss           : -1798.4211483361587\n",
      "    ess            : 8.001178363584122\n",
      "    log_marginal   : 1798.4211483361587\n",
      "    val_loss       : -1802.1663513183594\n",
      "    val_ess        : 8.001181602478027\n",
      "    val_log_marginal: 1802.1663513183594\n",
      "Train Epoch: 834 [0/54000 (0%)] Loss: -1815.903076\n",
      "Train Epoch: 834 [11264/54000 (21%)] Loss: -1807.933105\n",
      "Train Epoch: 834 [22528/54000 (42%)] Loss: -1805.951172\n",
      "Train Epoch: 834 [33792/54000 (63%)] Loss: -1825.650879\n",
      "Train Epoch: 834 [45056/54000 (83%)] Loss: -1790.830322\n",
      "    epoch          : 834\n",
      "    loss           : -1801.906532143647\n",
      "    ess            : 8.00117826461792\n",
      "    log_marginal   : 1801.906532143647\n",
      "    val_loss       : -1798.9675191243489\n",
      "    val_ess        : 8.001180251439413\n",
      "    val_log_marginal: 1798.9674987792969\n",
      "Train Epoch: 835 [0/54000 (0%)] Loss: -1813.338379\n",
      "Train Epoch: 835 [11264/54000 (21%)] Loss: -1808.925781\n",
      "Train Epoch: 835 [22528/54000 (42%)] Loss: -1799.652344\n",
      "Train Epoch: 835 [33792/54000 (63%)] Loss: -1815.347534\n",
      "Train Epoch: 835 [45056/54000 (83%)] Loss: -1789.630127\n",
      "    epoch          : 835\n",
      "    loss           : -1798.5674415444428\n",
      "    ess            : 8.00117804869166\n",
      "    log_marginal   : 1798.5674415444428\n",
      "    val_loss       : -1803.4265441894531\n",
      "    val_ess        : 8.001178979873657\n",
      "    val_log_marginal: 1803.4265441894531\n",
      "Train Epoch: 836 [0/54000 (0%)] Loss: -1816.950684\n",
      "Train Epoch: 836 [11264/54000 (21%)] Loss: -1814.483398\n",
      "Train Epoch: 836 [22528/54000 (42%)] Loss: -1803.113525\n",
      "Train Epoch: 836 [33792/54000 (63%)] Loss: -1824.626587\n",
      "Train Epoch: 836 [45056/54000 (83%)] Loss: -1784.708740\n",
      "    epoch          : 836\n",
      "    loss           : -1801.6668620559406\n",
      "    ess            : 8.00117758085143\n",
      "    log_marginal   : 1801.6668620559406\n",
      "    val_loss       : -1794.6327616373699\n",
      "    val_ess        : 8.001179456710815\n",
      "    val_log_marginal: 1794.632792154948\n",
      "Train Epoch: 837 [0/54000 (0%)] Loss: -1810.767822\n",
      "Train Epoch: 837 [11264/54000 (21%)] Loss: -1812.197388\n",
      "Train Epoch: 837 [22528/54000 (42%)] Loss: -1799.165039\n",
      "Train Epoch: 837 [33792/54000 (63%)] Loss: -1815.765747\n",
      "Train Epoch: 837 [45056/54000 (83%)] Loss: -1799.042725\n",
      "    epoch          : 837\n",
      "    loss           : -1800.8686926499852\n",
      "    ess            : 8.001179272273802\n",
      "    log_marginal   : 1800.8686914983784\n",
      "    val_loss       : -1810.4116312662761\n",
      "    val_ess        : 8.001176516215006\n",
      "    val_log_marginal: 1810.4116312662761\n",
      "Train Epoch: 838 [0/54000 (0%)] Loss: -1824.715820\n",
      "Train Epoch: 838 [11264/54000 (21%)] Loss: -1819.088745\n",
      "Train Epoch: 838 [22528/54000 (42%)] Loss: -1802.601562\n",
      "Train Epoch: 838 [33792/54000 (63%)] Loss: -1813.435303\n",
      "Train Epoch: 838 [45056/54000 (83%)] Loss: -1795.012085\n",
      "    epoch          : 838\n",
      "    loss           : -1802.486704700398\n",
      "    ess            : 8.00117848054418\n",
      "    log_marginal   : 1802.486704700398\n",
      "    val_loss       : -1800.7141621907551\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1800.7141621907551\n",
      "Train Epoch: 839 [0/54000 (0%)] Loss: -1812.646240\n",
      "Train Epoch: 839 [11264/54000 (21%)] Loss: -1816.118408\n",
      "Train Epoch: 839 [22528/54000 (42%)] Loss: -1800.481201\n",
      "Train Epoch: 839 [33792/54000 (63%)] Loss: -1819.079590\n",
      "Train Epoch: 839 [45056/54000 (83%)] Loss: -1798.614502\n",
      "    epoch          : 839\n",
      "    loss           : -1802.5930003040241\n",
      "    ess            : 8.001179920052582\n",
      "    log_marginal   : 1802.5930003040241\n",
      "    val_loss       : -1799.5088195800781\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1799.5088195800781\n",
      "Train Epoch: 840 [0/54000 (0%)] Loss: -1812.210205\n",
      "Train Epoch: 840 [11264/54000 (21%)] Loss: -1815.480957\n",
      "Train Epoch: 840 [22528/54000 (42%)] Loss: -1796.417969\n",
      "Train Epoch: 840 [33792/54000 (63%)] Loss: -1815.661377\n",
      "Train Epoch: 840 [45056/54000 (83%)] Loss: -1798.551514\n",
      "    epoch          : 840\n",
      "    loss           : -1800.5412954654334\n",
      "    ess            : 8.001179866071018\n",
      "    log_marginal   : 1800.5412954654334\n",
      "    val_loss       : -1804.2144063313801\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1804.2143961588542\n",
      "Train Epoch: 841 [0/54000 (0%)] Loss: -1817.980713\n",
      "Train Epoch: 841 [11264/54000 (21%)] Loss: -1820.296143\n",
      "Train Epoch: 841 [22528/54000 (42%)] Loss: -1805.461670\n",
      "Train Epoch: 841 [33792/54000 (63%)] Loss: -1816.375977\n",
      "Train Epoch: 841 [45056/54000 (83%)] Loss: -1793.609253\n",
      "    epoch          : 841\n",
      "    loss           : -1803.4495423514888\n",
      "    ess            : 8.001178201639428\n",
      "    log_marginal   : 1803.4495435030956\n",
      "    val_loss       : -1801.968770345052\n",
      "    val_ess        : 8.001180489857992\n",
      "    val_log_marginal: 1801.9687601725261\n",
      "Train Epoch: 842 [0/54000 (0%)] Loss: -1815.648071\n",
      "Train Epoch: 842 [11264/54000 (21%)] Loss: -1814.075317\n",
      "Train Epoch: 842 [22528/54000 (42%)] Loss: -1784.455566\n",
      "Train Epoch: 842 [33792/54000 (63%)] Loss: -1794.215088\n",
      "Train Epoch: 842 [45056/54000 (83%)] Loss: -1778.833008\n",
      "    epoch          : 842\n",
      "    loss           : -1789.6044921875\n",
      "    ess            : 8.001180999683884\n",
      "    log_marginal   : 1789.6044933391067\n",
      "    val_loss       : -1786.4796752929688\n",
      "    val_ess        : 8.001183350880941\n",
      "    val_log_marginal: 1786.4796752929688\n",
      "Train Epoch: 843 [0/54000 (0%)] Loss: -1801.255371\n",
      "Train Epoch: 843 [11264/54000 (21%)] Loss: -1805.572998\n",
      "Train Epoch: 843 [22528/54000 (42%)] Loss: -1793.970215\n",
      "Train Epoch: 843 [33792/54000 (63%)] Loss: -1813.712280\n",
      "Train Epoch: 843 [45056/54000 (83%)] Loss: -1791.026367\n",
      "    epoch          : 843\n",
      "    loss           : -1794.9665584924087\n",
      "    ess            : 8.001179920052582\n",
      "    log_marginal   : 1794.9665584924087\n",
      "    val_loss       : -1794.6076558430989\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1794.6076761881511\n",
      "Train Epoch: 844 [0/54000 (0%)] Loss: -1810.556641\n",
      "Train Epoch: 844 [11264/54000 (21%)] Loss: -1812.960083\n",
      "Train Epoch: 844 [22528/54000 (42%)] Loss: -1798.664062\n",
      "Train Epoch: 844 [33792/54000 (63%)] Loss: -1808.959839\n",
      "Train Epoch: 844 [45056/54000 (83%)] Loss: -1792.377075\n",
      "    epoch          : 844\n",
      "    loss           : -1796.7120038878243\n",
      "    ess            : 8.001180594822145\n",
      "    log_marginal   : 1796.7120038878243\n",
      "    val_loss       : -1798.3504130045574\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1798.3503926595051\n",
      "Train Epoch: 845 [0/54000 (0%)] Loss: -1812.026123\n",
      "Train Epoch: 845 [11264/54000 (21%)] Loss: -1810.680420\n",
      "Train Epoch: 845 [22528/54000 (42%)] Loss: -1796.756836\n",
      "Train Epoch: 845 [33792/54000 (63%)] Loss: -1812.687622\n",
      "Train Epoch: 845 [45056/54000 (83%)] Loss: -1793.965820\n",
      "    epoch          : 845\n",
      "    loss           : -1798.6796621646522\n",
      "    ess            : 8.00117894838441\n",
      "    log_marginal   : 1798.6796621646522\n",
      "    val_loss       : -1799.6732991536458\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1799.6732991536458\n",
      "Train Epoch: 846 [0/54000 (0%)] Loss: -1809.708740\n",
      "Train Epoch: 846 [11264/54000 (21%)] Loss: -1820.805054\n",
      "Train Epoch: 846 [22528/54000 (42%)] Loss: -1805.086914\n",
      "Train Epoch: 846 [33792/54000 (63%)] Loss: -1816.625732\n",
      "Train Epoch: 846 [45056/54000 (83%)] Loss: -1794.862793\n",
      "    epoch          : 846\n",
      "    loss           : -1803.344855542453\n",
      "    ess            : 8.001179434218496\n",
      "    log_marginal   : 1803.344855542453\n",
      "    val_loss       : -1800.5555318196614\n",
      "    val_ess        : 8.001178503036499\n",
      "    val_log_marginal: 1800.5555318196614\n",
      "Train Epoch: 847 [0/54000 (0%)] Loss: -1811.952881\n",
      "Train Epoch: 847 [11264/54000 (21%)] Loss: -1815.502563\n",
      "Train Epoch: 847 [22528/54000 (42%)] Loss: -1801.190430\n",
      "Train Epoch: 847 [33792/54000 (63%)] Loss: -1818.116211\n",
      "Train Epoch: 847 [45056/54000 (83%)] Loss: -1801.829102\n",
      "    epoch          : 847\n",
      "    loss           : -1803.460688752948\n",
      "    ess            : 8.001180243941972\n",
      "    log_marginal   : 1803.4606899045548\n",
      "    val_loss       : -1801.025899251302\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1801.025899251302\n",
      "Train Epoch: 848 [0/54000 (0%)] Loss: -1815.041992\n",
      "Train Epoch: 848 [11264/54000 (21%)] Loss: -1807.465820\n",
      "Train Epoch: 848 [22528/54000 (42%)] Loss: -1795.927490\n",
      "Train Epoch: 848 [33792/54000 (63%)] Loss: -1813.116943\n",
      "Train Epoch: 848 [45056/54000 (83%)] Loss: -1795.295288\n",
      "    epoch          : 848\n",
      "    loss           : -1798.5622535561615\n",
      "    ess            : 8.001180108988061\n",
      "    log_marginal   : 1798.5622535561615\n",
      "    val_loss       : -1800.7867024739583\n",
      "    val_ess        : 8.00118096669515\n",
      "    val_log_marginal: 1800.7867228190105\n",
      "Train Epoch: 849 [0/54000 (0%)] Loss: -1811.886353\n",
      "Train Epoch: 849 [11264/54000 (21%)] Loss: -1804.860962\n",
      "Train Epoch: 849 [22528/54000 (42%)] Loss: -1803.542725\n",
      "Train Epoch: 849 [33792/54000 (63%)] Loss: -1820.930176\n",
      "Train Epoch: 849 [45056/54000 (83%)] Loss: -1789.857788\n",
      "    epoch          : 849\n",
      "    loss           : -1799.8407730966244\n",
      "    ess            : 8.001179326255366\n",
      "    log_marginal   : 1799.8407719450177\n",
      "    val_loss       : -1792.0825907389324\n",
      "    val_ess        : 8.001177469889322\n",
      "    val_log_marginal: 1792.0825907389324\n",
      "Train Epoch: 850 [0/54000 (0%)] Loss: -1805.225830\n",
      "Train Epoch: 850 [11264/54000 (21%)] Loss: -1812.462280\n",
      "Train Epoch: 850 [22528/54000 (42%)] Loss: -1797.695679\n",
      "Train Epoch: 850 [33792/54000 (63%)] Loss: -1817.422485\n",
      "Train Epoch: 850 [45056/54000 (83%)] Loss: -1797.446289\n",
      "    epoch          : 850\n",
      "    loss           : -1800.8582072707843\n",
      "    ess            : 8.001177985713166\n",
      "    log_marginal   : 1800.8582072707843\n",
      "    val_loss       : -1808.8353881835938\n",
      "    val_ess        : 8.00118096669515\n",
      "    val_log_marginal: 1808.8353881835938\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch850.pth ...\n",
      "Train Epoch: 851 [0/54000 (0%)] Loss: -1821.175049\n",
      "Train Epoch: 851 [11264/54000 (21%)] Loss: -1814.563721\n",
      "Train Epoch: 851 [22528/54000 (42%)] Loss: -1799.703491\n",
      "Train Epoch: 851 [33792/54000 (63%)] Loss: -1805.977783\n",
      "Train Epoch: 851 [45056/54000 (83%)] Loss: -1782.104126\n",
      "    epoch          : 851\n",
      "    loss           : -1794.9631151883107\n",
      "    ess            : 8.001180099991133\n",
      "    log_marginal   : 1794.9631151883107\n",
      "    val_loss       : -1773.0846659342449\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1773.0846659342449\n",
      "Train Epoch: 852 [0/54000 (0%)] Loss: -1785.822876\n",
      "Train Epoch: 852 [11264/54000 (21%)] Loss: -1790.023315\n",
      "Train Epoch: 852 [22528/54000 (42%)] Loss: -1765.739990\n",
      "Train Epoch: 852 [33792/54000 (63%)] Loss: -1805.296265\n",
      "Train Epoch: 852 [45056/54000 (83%)] Loss: -1793.657959\n",
      "    epoch          : 852\n",
      "    loss           : -1783.534465285967\n",
      "    ess            : 8.00118336587582\n",
      "    log_marginal   : 1783.534465285967\n",
      "    val_loss       : -1789.6086730957031\n",
      "    val_ess        : 8.001181681950888\n",
      "    val_log_marginal: 1789.6086730957031\n",
      "Train Epoch: 853 [0/54000 (0%)] Loss: -1801.677124\n",
      "Train Epoch: 853 [11264/54000 (21%)] Loss: -1798.818481\n",
      "Train Epoch: 853 [22528/54000 (42%)] Loss: -1783.375000\n",
      "Train Epoch: 853 [33792/54000 (63%)] Loss: -1815.315918\n",
      "Train Epoch: 853 [45056/54000 (83%)] Loss: -1796.396851\n",
      "    epoch          : 853\n",
      "    loss           : -1794.5768973872346\n",
      "    ess            : 8.00117960516012\n",
      "    log_marginal   : 1794.576896235628\n",
      "    val_loss       : -1802.0841979980469\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1802.0841979980469\n",
      "Train Epoch: 854 [0/54000 (0%)] Loss: -1815.089111\n",
      "Train Epoch: 854 [11264/54000 (21%)] Loss: -1808.422241\n",
      "Train Epoch: 854 [22528/54000 (42%)] Loss: -1789.682129\n",
      "Train Epoch: 854 [33792/54000 (63%)] Loss: -1817.109253\n",
      "Train Epoch: 854 [45056/54000 (83%)] Loss: -1791.726318\n",
      "    epoch          : 854\n",
      "    loss           : -1797.651686182562\n",
      "    ess            : 8.00118080175148\n",
      "    log_marginal   : 1797.651686182562\n",
      "    val_loss       : -1796.3189697265625\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1796.3189798990886\n",
      "Train Epoch: 855 [0/54000 (0%)] Loss: -1807.727051\n",
      "Train Epoch: 855 [11264/54000 (21%)] Loss: -1805.161011\n",
      "Train Epoch: 855 [22528/54000 (42%)] Loss: -1794.899292\n",
      "Train Epoch: 855 [33792/54000 (63%)] Loss: -1812.959595\n",
      "Train Epoch: 855 [45056/54000 (83%)] Loss: -1788.869263\n",
      "    epoch          : 855\n",
      "    loss           : -1795.9957551776238\n",
      "    ess            : 8.001180846736116\n",
      "    log_marginal   : 1795.995754026017\n",
      "    val_loss       : -1792.206563313802\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1792.206563313802\n",
      "Train Epoch: 856 [0/54000 (0%)] Loss: -1804.169678\n",
      "Train Epoch: 856 [11264/54000 (21%)] Loss: -1811.790405\n",
      "Train Epoch: 856 [22528/54000 (42%)] Loss: -1800.642578\n",
      "Train Epoch: 856 [33792/54000 (63%)] Loss: -1822.329224\n",
      "Train Epoch: 856 [45056/54000 (83%)] Loss: -1789.808960\n",
      "    epoch          : 856\n",
      "    loss           : -1801.0760670787884\n",
      "    ess            : 8.001179758107886\n",
      "    log_marginal   : 1801.076068230395\n",
      "    val_loss       : -1796.6280008951824\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1796.6280008951824\n",
      "Train Epoch: 857 [0/54000 (0%)] Loss: -1808.367188\n",
      "Train Epoch: 857 [11264/54000 (21%)] Loss: -1815.229980\n",
      "Train Epoch: 857 [22528/54000 (42%)] Loss: -1803.019775\n",
      "Train Epoch: 857 [33792/54000 (63%)] Loss: -1824.010986\n",
      "Train Epoch: 857 [45056/54000 (83%)] Loss: -1796.530273\n",
      "    epoch          : 857\n",
      "    loss           : -1803.676848789431\n",
      "    ess            : 8.00118072077913\n",
      "    log_marginal   : 1803.676848789431\n",
      "    val_loss       : -1798.144775390625\n",
      "    val_ess        : 8.001184304555258\n",
      "    val_log_marginal: 1798.144775390625\n",
      "Train Epoch: 858 [0/54000 (0%)] Loss: -1812.934082\n",
      "Train Epoch: 858 [11264/54000 (21%)] Loss: -1811.031250\n",
      "Train Epoch: 858 [22528/54000 (42%)] Loss: -1795.976440\n",
      "Train Epoch: 858 [33792/54000 (63%)] Loss: -1814.261108\n",
      "Train Epoch: 858 [45056/54000 (83%)] Loss: -1790.007080\n",
      "    epoch          : 858\n",
      "    loss           : -1798.3351866524174\n",
      "    ess            : 8.00118105366545\n",
      "    log_marginal   : 1798.3351866524174\n",
      "    val_loss       : -1796.4123942057292\n",
      "    val_ess        : 8.001182874043783\n",
      "    val_log_marginal: 1796.4123942057292\n",
      "Train Epoch: 859 [0/54000 (0%)] Loss: -1812.243408\n",
      "Train Epoch: 859 [11264/54000 (21%)] Loss: -1809.814331\n",
      "Train Epoch: 859 [22528/54000 (42%)] Loss: -1798.314697\n",
      "Train Epoch: 859 [33792/54000 (63%)] Loss: -1814.671509\n",
      "Train Epoch: 859 [45056/54000 (83%)] Loss: -1798.847534\n",
      "    epoch          : 859\n",
      "    loss           : -1801.2756082786705\n",
      "    ess            : 8.001179830083307\n",
      "    log_marginal   : 1801.2756082786705\n",
      "    val_loss       : -1801.4912719726562\n",
      "    val_ess        : 8.001180092493692\n",
      "    val_log_marginal: 1801.4912719726562\n",
      "Train Epoch: 860 [0/54000 (0%)] Loss: -1814.222900\n",
      "Train Epoch: 860 [11264/54000 (21%)] Loss: -1809.985474\n",
      "Train Epoch: 860 [22528/54000 (42%)] Loss: -1797.835693\n",
      "Train Epoch: 860 [33792/54000 (63%)] Loss: -1817.055420\n",
      "Train Epoch: 860 [45056/54000 (83%)] Loss: -1796.783325\n",
      "    epoch          : 860\n",
      "    loss           : -1801.9144148916569\n",
      "    ess            : 8.001178129664007\n",
      "    log_marginal   : 1801.9144160432636\n",
      "    val_loss       : -1805.2099914550781\n",
      "    val_ess        : 8.00118096669515\n",
      "    val_log_marginal: 1805.2099914550781\n",
      "Train Epoch: 861 [0/54000 (0%)] Loss: -1819.490479\n",
      "Train Epoch: 861 [11264/54000 (21%)] Loss: -1815.164673\n",
      "Train Epoch: 861 [22528/54000 (42%)] Loss: -1802.779541\n",
      "Train Epoch: 861 [33792/54000 (63%)] Loss: -1806.909912\n",
      "Train Epoch: 861 [45056/54000 (83%)] Loss: -1793.453125\n",
      "    epoch          : 861\n",
      "    loss           : -1800.0906084168632\n",
      "    ess            : 8.001179704126322\n",
      "    log_marginal   : 1800.0906084168632\n",
      "    val_loss       : -1799.6589864095051\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1799.6589965820312\n",
      "Train Epoch: 862 [0/54000 (0%)] Loss: -1812.791992\n",
      "Train Epoch: 862 [11264/54000 (21%)] Loss: -1815.317383\n",
      "Train Epoch: 862 [22528/54000 (42%)] Loss: -1803.724487\n",
      "Train Epoch: 862 [33792/54000 (63%)] Loss: -1815.706543\n",
      "Train Epoch: 862 [45056/54000 (83%)] Loss: -1799.005737\n",
      "    epoch          : 862\n",
      "    loss           : -1802.3763508346844\n",
      "    ess            : 8.00117985707409\n",
      "    log_marginal   : 1802.3763508346844\n",
      "    val_loss       : -1803.5700378417969\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1803.5700378417969\n",
      "Train Epoch: 863 [0/54000 (0%)] Loss: -1816.257080\n",
      "Train Epoch: 863 [11264/54000 (21%)] Loss: -1818.861572\n",
      "Train Epoch: 863 [22528/54000 (42%)] Loss: -1804.737305\n",
      "Train Epoch: 863 [33792/54000 (63%)] Loss: -1822.460693\n",
      "Train Epoch: 863 [45056/54000 (83%)] Loss: -1796.294678\n",
      "    epoch          : 863\n",
      "    loss           : -1804.8522027933373\n",
      "    ess            : 8.001180019018785\n",
      "    log_marginal   : 1804.8522027933373\n",
      "    val_loss       : -1797.3392740885417\n",
      "    val_ess        : 8.001180251439413\n",
      "    val_log_marginal: 1797.3392842610676\n",
      "Train Epoch: 864 [0/54000 (0%)] Loss: -1812.050781\n",
      "Train Epoch: 864 [11264/54000 (21%)] Loss: -1813.131714\n",
      "Train Epoch: 864 [22528/54000 (42%)] Loss: -1799.496338\n",
      "Train Epoch: 864 [33792/54000 (63%)] Loss: -1814.685547\n",
      "Train Epoch: 864 [45056/54000 (83%)] Loss: -1799.341797\n",
      "    epoch          : 864\n",
      "    loss           : -1801.8524319630749\n",
      "    ess            : 8.001180540840581\n",
      "    log_marginal   : 1801.8524319630749\n",
      "    val_loss       : -1805.7319946289062\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1805.7319946289062\n",
      "Train Epoch: 865 [0/54000 (0%)] Loss: -1820.756348\n",
      "Train Epoch: 865 [11264/54000 (21%)] Loss: -1811.218262\n",
      "Train Epoch: 865 [22528/54000 (42%)] Loss: -1797.811279\n",
      "Train Epoch: 865 [33792/54000 (63%)] Loss: -1817.186035\n",
      "Train Epoch: 865 [45056/54000 (83%)] Loss: -1792.753174\n",
      "    epoch          : 865\n",
      "    loss           : -1801.0580617076946\n",
      "    ess            : 8.00118014497577\n",
      "    log_marginal   : 1801.0580617076946\n",
      "    val_loss       : -1802.1427612304688\n",
      "    val_ess        : 8.001180728276571\n",
      "    val_log_marginal: 1802.1427612304688\n",
      "Train Epoch: 866 [0/54000 (0%)] Loss: -1817.456665\n",
      "Train Epoch: 866 [11264/54000 (21%)] Loss: -1816.330811\n",
      "Train Epoch: 866 [22528/54000 (42%)] Loss: -1798.242065\n",
      "Train Epoch: 866 [33792/54000 (63%)] Loss: -1817.443604\n",
      "Train Epoch: 866 [45056/54000 (83%)] Loss: -1794.957031\n",
      "    epoch          : 866\n",
      "    loss           : -1804.0227200490124\n",
      "    ess            : 8.001178885405919\n",
      "    log_marginal   : 1804.0227212006191\n",
      "    val_loss       : -1804.5052185058594\n",
      "    val_ess        : 8.001182158788046\n",
      "    val_log_marginal: 1804.5052185058594\n",
      "Train Epoch: 867 [0/54000 (0%)] Loss: -1819.901489\n",
      "Train Epoch: 867 [11264/54000 (21%)] Loss: -1813.588379\n",
      "Train Epoch: 867 [22528/54000 (42%)] Loss: -1794.506714\n",
      "Train Epoch: 867 [33792/54000 (63%)] Loss: -1817.206299\n",
      "Train Epoch: 867 [45056/54000 (83%)] Loss: -1797.636963\n",
      "    epoch          : 867\n",
      "    loss           : -1802.112677808078\n",
      "    ess            : 8.001179236286092\n",
      "    log_marginal   : 1802.112677808078\n",
      "    val_loss       : -1806.7736002604167\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1806.7736002604167\n",
      "Train Epoch: 868 [0/54000 (0%)] Loss: -1820.182861\n",
      "Train Epoch: 868 [11264/54000 (21%)] Loss: -1818.252930\n",
      "Train Epoch: 868 [22528/54000 (42%)] Loss: -1804.472412\n",
      "Train Epoch: 868 [33792/54000 (63%)] Loss: -1817.368408\n",
      "Train Epoch: 868 [45056/54000 (83%)] Loss: -1795.060547\n",
      "    epoch          : 868\n",
      "    loss           : -1803.1587340156987\n",
      "    ess            : 8.00118028892661\n",
      "    log_marginal   : 1803.1587340156987\n",
      "    val_loss       : -1800.6483561197917\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1800.6483561197917\n",
      "Train Epoch: 869 [0/54000 (0%)] Loss: -1813.222534\n",
      "Train Epoch: 869 [11264/54000 (21%)] Loss: -1813.809692\n",
      "Train Epoch: 869 [22528/54000 (42%)] Loss: -1794.302979\n",
      "Train Epoch: 869 [33792/54000 (63%)] Loss: -1816.211914\n",
      "Train Epoch: 869 [45056/54000 (83%)] Loss: -1793.760132\n",
      "    epoch          : 869\n",
      "    loss           : -1799.477406627727\n",
      "    ess            : 8.001180711782203\n",
      "    log_marginal   : 1799.477406627727\n",
      "    val_loss       : -1803.3954976399739\n",
      "    val_ess        : 8.001180410385132\n",
      "    val_log_marginal: 1803.3954976399739\n",
      "Train Epoch: 870 [0/54000 (0%)] Loss: -1817.165771\n",
      "Train Epoch: 870 [11264/54000 (21%)] Loss: -1819.564453\n",
      "Train Epoch: 870 [22528/54000 (42%)] Loss: -1797.041016\n",
      "Train Epoch: 870 [33792/54000 (63%)] Loss: -1820.807373\n",
      "Train Epoch: 870 [45056/54000 (83%)] Loss: -1799.119019\n",
      "    epoch          : 870\n",
      "    loss           : -1803.5667494288032\n",
      "    ess            : 8.00117869647044\n",
      "    log_marginal   : 1803.5667494288032\n",
      "    val_loss       : -1806.9763285319011\n",
      "    val_ess        : 8.001179615656534\n",
      "    val_log_marginal: 1806.976318359375\n",
      "Train Epoch: 871 [0/54000 (0%)] Loss: -1818.410400\n",
      "Train Epoch: 871 [11264/54000 (21%)] Loss: -1817.089600\n",
      "Train Epoch: 871 [22528/54000 (42%)] Loss: -1796.899048\n",
      "Train Epoch: 871 [33792/54000 (63%)] Loss: -1784.105103\n",
      "Train Epoch: 871 [45056/54000 (83%)] Loss: -1764.766846\n",
      "    epoch          : 871\n",
      "    loss           : -1785.6600203604069\n",
      "    ess            : 8.001179299264583\n",
      "    log_marginal   : 1785.6600180571934\n",
      "    val_loss       : -1766.7020975748699\n",
      "    val_ess        : 8.001185258229574\n",
      "    val_log_marginal: 1766.7020874023438\n",
      "Train Epoch: 872 [0/54000 (0%)] Loss: -1779.759766\n",
      "Train Epoch: 872 [11264/54000 (21%)] Loss: -1799.619873\n",
      "Train Epoch: 872 [22528/54000 (42%)] Loss: -1788.535156\n",
      "Train Epoch: 872 [33792/54000 (63%)] Loss: -1799.400391\n",
      "Train Epoch: 872 [45056/54000 (83%)] Loss: -1779.178223\n",
      "    epoch          : 872\n",
      "    loss           : -1784.7604243440448\n",
      "    ess            : 8.00118191737049\n",
      "    log_marginal   : 1784.760423192438\n",
      "    val_loss       : -1789.8054606119792\n",
      "    val_ess        : 8.001181920369467\n",
      "    val_log_marginal: 1789.8054606119792\n",
      "Train Epoch: 873 [0/54000 (0%)] Loss: -1804.391235\n",
      "Train Epoch: 873 [11264/54000 (21%)] Loss: -1815.941406\n",
      "Train Epoch: 873 [22528/54000 (42%)] Loss: -1800.850586\n",
      "Train Epoch: 873 [33792/54000 (63%)] Loss: -1813.267334\n",
      "Train Epoch: 873 [45056/54000 (83%)] Loss: -1790.228271\n",
      "    epoch          : 873\n",
      "    loss           : -1797.7384643554688\n",
      "    ess            : 8.001178102673224\n",
      "    log_marginal   : 1797.7384620522553\n",
      "    val_loss       : -1799.4717305501301\n",
      "    val_ess        : 8.001178503036499\n",
      "    val_log_marginal: 1799.4717305501301\n",
      "Train Epoch: 874 [0/54000 (0%)] Loss: -1812.651611\n",
      "Train Epoch: 874 [11264/54000 (21%)] Loss: -1816.475342\n",
      "Train Epoch: 874 [22528/54000 (42%)] Loss: -1800.323853\n",
      "Train Epoch: 874 [33792/54000 (63%)] Loss: -1813.088013\n",
      "Train Epoch: 874 [45056/54000 (83%)] Loss: -1792.020142\n",
      "    epoch          : 874\n",
      "    loss           : -1799.8306228349793\n",
      "    ess            : 8.001180675794494\n",
      "    log_marginal   : 1799.8306228349793\n",
      "    val_loss       : -1801.791768391927\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1801.7917582194011\n",
      "Train Epoch: 875 [0/54000 (0%)] Loss: -1813.607178\n",
      "Train Epoch: 875 [11264/54000 (21%)] Loss: -1815.231201\n",
      "Train Epoch: 875 [22528/54000 (42%)] Loss: -1800.410645\n",
      "Train Epoch: 875 [33792/54000 (63%)] Loss: -1812.010742\n",
      "Train Epoch: 875 [45056/54000 (83%)] Loss: -1791.987427\n",
      "    epoch          : 875\n",
      "    loss           : -1799.6441189747936\n",
      "    ess            : 8.001179290267656\n",
      "    log_marginal   : 1799.6441189747936\n",
      "    val_loss       : -1803.715352376302\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1803.715352376302\n",
      "Train Epoch: 876 [0/54000 (0%)] Loss: -1818.431152\n",
      "Train Epoch: 876 [11264/54000 (21%)] Loss: -1817.040161\n",
      "Train Epoch: 876 [22528/54000 (42%)] Loss: -1805.311401\n",
      "Train Epoch: 876 [33792/54000 (63%)] Loss: -1822.152100\n",
      "Train Epoch: 876 [45056/54000 (83%)] Loss: -1794.152954\n",
      "    epoch          : 876\n",
      "    loss           : -1803.665911980395\n",
      "    ess            : 8.001178651485803\n",
      "    log_marginal   : 1803.665911980395\n",
      "    val_loss       : -1803.0936787923176\n",
      "    val_ess        : 8.001177231470743\n",
      "    val_log_marginal: 1803.0936787923176\n",
      "Train Epoch: 877 [0/54000 (0%)] Loss: -1815.909668\n",
      "Train Epoch: 877 [11264/54000 (21%)] Loss: -1813.246704\n",
      "Train Epoch: 877 [22528/54000 (42%)] Loss: -1793.788086\n",
      "Train Epoch: 877 [33792/54000 (63%)] Loss: -1815.889893\n",
      "Train Epoch: 877 [45056/54000 (83%)] Loss: -1795.226196\n",
      "    epoch          : 877\n",
      "    loss           : -1799.5667229418484\n",
      "    ess            : 8.001178237627137\n",
      "    log_marginal   : 1799.5667229418484\n",
      "    val_loss       : -1805.8052978515625\n",
      "    val_ess        : 8.001176993052164\n",
      "    val_log_marginal: 1805.8052978515625\n",
      "Train Epoch: 878 [0/54000 (0%)] Loss: -1817.625732\n",
      "Train Epoch: 878 [11264/54000 (21%)] Loss: -1813.253174\n",
      "Train Epoch: 878 [22528/54000 (42%)] Loss: -1802.936890\n",
      "Train Epoch: 878 [33792/54000 (63%)] Loss: -1815.242554\n",
      "Train Epoch: 878 [45056/54000 (83%)] Loss: -1793.422119\n",
      "    epoch          : 878\n",
      "    loss           : -1801.5074405310288\n",
      "    ess            : 8.001178237627137\n",
      "    log_marginal   : 1801.5074405310288\n",
      "    val_loss       : -1803.2438252766926\n",
      "    val_ess        : 8.001177708307901\n",
      "    val_log_marginal: 1803.2438354492188\n",
      "Train Epoch: 879 [0/54000 (0%)] Loss: -1816.291016\n",
      "Train Epoch: 879 [11264/54000 (21%)] Loss: -1807.390869\n",
      "Train Epoch: 879 [22528/54000 (42%)] Loss: -1794.991333\n",
      "Train Epoch: 879 [33792/54000 (63%)] Loss: -1815.805054\n",
      "Train Epoch: 879 [45056/54000 (83%)] Loss: -1789.242432\n",
      "    epoch          : 879\n",
      "    loss           : -1797.856424583579\n",
      "    ess            : 8.001178273614848\n",
      "    log_marginal   : 1797.856424583579\n",
      "    val_loss       : -1803.8219604492188\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1803.8219604492188\n",
      "Train Epoch: 880 [0/54000 (0%)] Loss: -1817.490845\n",
      "Train Epoch: 880 [11264/54000 (21%)] Loss: -1815.905029\n",
      "Train Epoch: 880 [22528/54000 (42%)] Loss: -1808.674805\n",
      "Train Epoch: 880 [33792/54000 (63%)] Loss: -1822.119873\n",
      "Train Epoch: 880 [45056/54000 (83%)] Loss: -1784.523315\n",
      "    epoch          : 880\n",
      "    loss           : -1802.3212579691185\n",
      "    ess            : 8.001180028015712\n",
      "    log_marginal   : 1802.3212568175118\n",
      "    val_loss       : -1795.7606608072917\n",
      "    val_ess        : 8.001180171966553\n",
      "    val_log_marginal: 1795.7606608072917\n",
      "Train Epoch: 881 [0/54000 (0%)] Loss: -1809.437622\n",
      "Train Epoch: 881 [11264/54000 (21%)] Loss: -1807.807617\n",
      "Train Epoch: 881 [22528/54000 (42%)] Loss: -1799.668213\n",
      "Train Epoch: 881 [33792/54000 (63%)] Loss: -1822.121094\n",
      "Train Epoch: 881 [45056/54000 (83%)] Loss: -1802.614136\n",
      "    epoch          : 881\n",
      "    loss           : -1802.0133309994103\n",
      "    ess            : 8.001179830083307\n",
      "    log_marginal   : 1802.013332151017\n",
      "    val_loss       : -1810.20654296875\n",
      "    val_ess        : 8.001181681950888\n",
      "    val_log_marginal: 1810.20654296875\n",
      "Train Epoch: 882 [0/54000 (0%)] Loss: -1822.406372\n",
      "Train Epoch: 882 [11264/54000 (21%)] Loss: -1807.647583\n",
      "Train Epoch: 882 [22528/54000 (42%)] Loss: -1799.225830\n",
      "Train Epoch: 882 [33792/54000 (63%)] Loss: -1817.336426\n",
      "Train Epoch: 882 [45056/54000 (83%)] Loss: -1791.456299\n",
      "    epoch          : 882\n",
      "    loss           : -1801.0472700011055\n",
      "    ess            : 8.001179308261511\n",
      "    log_marginal   : 1801.0472700011055\n",
      "    val_loss       : -1803.5965270996094\n",
      "    val_ess        : 8.001178423563639\n",
      "    val_log_marginal: 1803.5965372721355\n",
      "Train Epoch: 883 [0/54000 (0%)] Loss: -1816.892090\n",
      "Train Epoch: 883 [11264/54000 (21%)] Loss: -1816.258667\n",
      "Train Epoch: 883 [22528/54000 (42%)] Loss: -1803.258057\n",
      "Train Epoch: 883 [33792/54000 (63%)] Loss: -1823.910645\n",
      "Train Epoch: 883 [45056/54000 (83%)] Loss: -1796.251953\n",
      "    epoch          : 883\n",
      "    loss           : -1804.8908000442218\n",
      "    ess            : 8.001179047350613\n",
      "    log_marginal   : 1804.8908000442218\n",
      "    val_loss       : -1798.658935546875\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1798.658935546875\n",
      "Train Epoch: 884 [0/54000 (0%)] Loss: -1810.878662\n",
      "Train Epoch: 884 [11264/54000 (21%)] Loss: -1809.753296\n",
      "Train Epoch: 884 [22528/54000 (42%)] Loss: -1797.054810\n",
      "Train Epoch: 884 [33792/54000 (63%)] Loss: -1812.799683\n",
      "Train Epoch: 884 [45056/54000 (83%)] Loss: -1787.253784\n",
      "    epoch          : 884\n",
      "    loss           : -1796.970289698187\n",
      "    ess            : 8.00117935324615\n",
      "    log_marginal   : 1796.970289698187\n",
      "    val_loss       : -1798.3414204915364\n",
      "    val_ess        : 8.001183032989502\n",
      "    val_log_marginal: 1798.3414204915364\n",
      "Train Epoch: 885 [0/54000 (0%)] Loss: -1810.130127\n",
      "Train Epoch: 885 [11264/54000 (21%)] Loss: -1817.011230\n",
      "Train Epoch: 885 [22528/54000 (42%)] Loss: -1793.100098\n",
      "Train Epoch: 885 [33792/54000 (63%)] Loss: -1801.480347\n",
      "Train Epoch: 885 [45056/54000 (83%)] Loss: -1788.780151\n",
      "    epoch          : 885\n",
      "    loss           : -1795.3702807156544\n",
      "    ess            : 8.001180522846726\n",
      "    log_marginal   : 1795.3702807156544\n",
      "    val_loss       : -1797.7079671223958\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1797.7079671223958\n",
      "Train Epoch: 886 [0/54000 (0%)] Loss: -1811.552490\n",
      "Train Epoch: 886 [11264/54000 (21%)] Loss: -1817.304932\n",
      "Train Epoch: 886 [22528/54000 (42%)] Loss: -1804.678223\n",
      "Train Epoch: 886 [33792/54000 (63%)] Loss: -1825.927002\n",
      "Train Epoch: 886 [45056/54000 (83%)] Loss: -1802.478760\n",
      "    epoch          : 886\n",
      "    loss           : -1805.3793772571491\n",
      "    ess            : 8.001178687473512\n",
      "    log_marginal   : 1805.3793795603626\n",
      "    val_loss       : -1803.7511596679688\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1803.7511596679688\n",
      "Train Epoch: 887 [0/54000 (0%)] Loss: -1816.155151\n",
      "Train Epoch: 887 [11264/54000 (21%)] Loss: -1814.443115\n",
      "Train Epoch: 887 [22528/54000 (42%)] Loss: -1797.862427\n",
      "Train Epoch: 887 [33792/54000 (63%)] Loss: -1820.941650\n",
      "Train Epoch: 887 [45056/54000 (83%)] Loss: -1801.032593\n",
      "    epoch          : 887\n",
      "    loss           : -1802.5850150630158\n",
      "    ess            : 8.001178075682443\n",
      "    log_marginal   : 1802.5850139114093\n",
      "    val_loss       : -1795.822530110677\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1795.822530110677\n",
      "Train Epoch: 888 [0/54000 (0%)] Loss: -1805.823975\n",
      "Train Epoch: 888 [11264/54000 (21%)] Loss: -1808.059937\n",
      "Train Epoch: 888 [22528/54000 (42%)] Loss: -1795.109863\n",
      "Train Epoch: 888 [33792/54000 (63%)] Loss: -1823.065796\n",
      "Train Epoch: 888 [45056/54000 (83%)] Loss: -1802.086670\n",
      "    epoch          : 888\n",
      "    loss           : -1799.375153163694\n",
      "    ess            : 8.001179992028003\n",
      "    log_marginal   : 1799.3751543153007\n",
      "    val_loss       : -1779.3333943684895\n",
      "    val_ess        : 8.001180171966553\n",
      "    val_log_marginal: 1779.3333943684895\n",
      "Train Epoch: 889 [0/54000 (0%)] Loss: -1795.316650\n",
      "Train Epoch: 889 [11264/54000 (21%)] Loss: -1804.655762\n",
      "Train Epoch: 889 [22528/54000 (42%)] Loss: -1792.697266\n",
      "Train Epoch: 889 [33792/54000 (63%)] Loss: -1816.832764\n",
      "Train Epoch: 889 [45056/54000 (83%)] Loss: -1791.185791\n",
      "    epoch          : 889\n",
      "    loss           : -1795.0115402509582\n",
      "    ess            : 8.001179218292236\n",
      "    log_marginal   : 1795.0115425541717\n",
      "    val_loss       : -1803.5999043782551\n",
      "    val_ess        : 8.00118096669515\n",
      "    val_log_marginal: 1803.5999043782551\n",
      "Train Epoch: 890 [0/54000 (0%)] Loss: -1817.781006\n",
      "Train Epoch: 890 [11264/54000 (21%)] Loss: -1818.274414\n",
      "Train Epoch: 890 [22528/54000 (42%)] Loss: -1801.207031\n",
      "Train Epoch: 890 [33792/54000 (63%)] Loss: -1823.542480\n",
      "Train Epoch: 890 [45056/54000 (83%)] Loss: -1791.825195\n",
      "    epoch          : 890\n",
      "    loss           : -1803.1709410469487\n",
      "    ess            : 8.001178651485803\n",
      "    log_marginal   : 1803.1709421985554\n",
      "    val_loss       : -1801.8689575195312\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1801.8689371744792\n",
      "Train Epoch: 891 [0/54000 (0%)] Loss: -1815.128174\n",
      "Train Epoch: 891 [11264/54000 (21%)] Loss: -1821.737793\n",
      "Train Epoch: 891 [22528/54000 (42%)] Loss: -1803.683105\n",
      "Train Epoch: 891 [33792/54000 (63%)] Loss: -1821.969971\n",
      "Train Epoch: 891 [45056/54000 (83%)] Loss: -1784.502686\n",
      "    epoch          : 891\n",
      "    loss           : -1803.5306880159198\n",
      "    ess            : 8.001178390574905\n",
      "    log_marginal   : 1803.5306891675266\n",
      "    val_loss       : -1800.947245279948\n",
      "    val_ess        : 8.001179774602255\n",
      "    val_log_marginal: 1800.9472249348958\n",
      "Train Epoch: 892 [0/54000 (0%)] Loss: -1814.065430\n",
      "Train Epoch: 892 [11264/54000 (21%)] Loss: -1821.101685\n",
      "Train Epoch: 892 [22528/54000 (42%)] Loss: -1803.436523\n",
      "Train Epoch: 892 [33792/54000 (63%)] Loss: -1819.333252\n",
      "Train Epoch: 892 [45056/54000 (83%)] Loss: -1788.471436\n",
      "    epoch          : 892\n",
      "    loss           : -1801.8093365363354\n",
      "    ess            : 8.001179128322962\n",
      "    log_marginal   : 1801.8093365363354\n",
      "    val_loss       : -1792.8057657877605\n",
      "    val_ess        : 8.001181920369467\n",
      "    val_log_marginal: 1792.8057657877605\n",
      "Train Epoch: 893 [0/54000 (0%)] Loss: -1807.065430\n",
      "Train Epoch: 893 [11264/54000 (21%)] Loss: -1807.941895\n",
      "Train Epoch: 893 [22528/54000 (42%)] Loss: -1772.968018\n",
      "Train Epoch: 893 [33792/54000 (63%)] Loss: -1792.895508\n",
      "Train Epoch: 893 [45056/54000 (83%)] Loss: -1780.248779\n",
      "    epoch          : 893\n",
      "    loss           : -1785.0643402675412\n",
      "    ess            : 8.001181557493389\n",
      "    log_marginal   : 1785.064341419148\n",
      "    val_loss       : -1791.9028422037761\n",
      "    val_ess        : 8.00118350982666\n",
      "    val_log_marginal: 1791.9028422037761\n",
      "Train Epoch: 894 [0/54000 (0%)] Loss: -1802.708618\n",
      "Train Epoch: 894 [11264/54000 (21%)] Loss: -1806.027832\n",
      "Train Epoch: 894 [22528/54000 (42%)] Loss: -1788.368042\n",
      "Train Epoch: 894 [33792/54000 (63%)] Loss: -1812.039429\n",
      "Train Epoch: 894 [45056/54000 (83%)] Loss: -1794.803223\n",
      "    epoch          : 894\n",
      "    loss           : -1795.1314547556751\n",
      "    ess            : 8.001179911055655\n",
      "    log_marginal   : 1795.1314536040684\n",
      "    val_loss       : -1798.3519388834636\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1798.3519694010417\n",
      "Train Epoch: 895 [0/54000 (0%)] Loss: -1808.561768\n",
      "Train Epoch: 895 [11264/54000 (21%)] Loss: -1813.869141\n",
      "Train Epoch: 895 [22528/54000 (42%)] Loss: -1795.034180\n",
      "Train Epoch: 895 [33792/54000 (63%)] Loss: -1798.316772\n",
      "Train Epoch: 895 [45056/54000 (83%)] Loss: -1779.235107\n",
      "    epoch          : 895\n",
      "    loss           : -1790.9734485554245\n",
      "    ess            : 8.001180576828292\n",
      "    log_marginal   : 1790.9734497070312\n",
      "    val_loss       : -1786.6654968261719\n",
      "    val_ess        : 8.001182874043783\n",
      "    val_log_marginal: 1786.6654968261719\n",
      "Train Epoch: 896 [0/54000 (0%)] Loss: -1802.275146\n",
      "Train Epoch: 896 [11264/54000 (21%)] Loss: -1802.388184\n",
      "Train Epoch: 896 [22528/54000 (42%)] Loss: -1788.143311\n",
      "Train Epoch: 896 [33792/54000 (63%)] Loss: -1813.048340\n",
      "Train Epoch: 896 [45056/54000 (83%)] Loss: -1783.415283\n",
      "    epoch          : 896\n",
      "    loss           : -1793.1026162201504\n",
      "    ess            : 8.001181143634724\n",
      "    log_marginal   : 1793.1026150685436\n",
      "    val_loss       : -1796.5764567057292\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1796.5764567057292\n",
      "Train Epoch: 897 [0/54000 (0%)] Loss: -1808.253540\n",
      "Train Epoch: 897 [11264/54000 (21%)] Loss: -1807.903809\n",
      "Train Epoch: 897 [22528/54000 (42%)] Loss: -1789.735840\n",
      "Train Epoch: 897 [33792/54000 (63%)] Loss: -1813.367554\n",
      "Train Epoch: 897 [45056/54000 (83%)] Loss: -1795.038574\n",
      "    epoch          : 897\n",
      "    loss           : -1798.6235201853626\n",
      "    ess            : 8.001178723461223\n",
      "    log_marginal   : 1798.6235201853626\n",
      "    val_loss       : -1805.0410766601562\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1805.0410766601562\n",
      "Train Epoch: 898 [0/54000 (0%)] Loss: -1814.793945\n",
      "Train Epoch: 898 [11264/54000 (21%)] Loss: -1815.383179\n",
      "Train Epoch: 898 [22528/54000 (42%)] Loss: -1798.130371\n",
      "Train Epoch: 898 [33792/54000 (63%)] Loss: -1812.177368\n",
      "Train Epoch: 898 [45056/54000 (83%)] Loss: -1787.701172\n",
      "    epoch          : 898\n",
      "    loss           : -1799.4666368016656\n",
      "    ess            : 8.001180432877451\n",
      "    log_marginal   : 1799.4666368016656\n",
      "    val_loss       : -1798.3473002115886\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1798.3473002115886\n",
      "Train Epoch: 899 [0/54000 (0%)] Loss: -1810.123901\n",
      "Train Epoch: 899 [11264/54000 (21%)] Loss: -1811.944336\n",
      "Train Epoch: 899 [22528/54000 (42%)] Loss: -1795.008301\n",
      "Train Epoch: 899 [33792/54000 (63%)] Loss: -1809.427490\n",
      "Train Epoch: 899 [45056/54000 (83%)] Loss: -1792.638184\n",
      "    epoch          : 899\n",
      "    loss           : -1798.058391067217\n",
      "    ess            : 8.001181008680812\n",
      "    log_marginal   : 1798.0583922188237\n",
      "    val_loss       : -1804.5577697753906\n",
      "    val_ess        : 8.001181920369467\n",
      "    val_log_marginal: 1804.5577799479167\n",
      "Train Epoch: 900 [0/54000 (0%)] Loss: -1815.805298\n",
      "Train Epoch: 900 [11264/54000 (21%)] Loss: -1817.119385\n",
      "Train Epoch: 900 [22528/54000 (42%)] Loss: -1792.714233\n",
      "Train Epoch: 900 [33792/54000 (63%)] Loss: -1802.451416\n",
      "Train Epoch: 900 [45056/54000 (83%)] Loss: -1781.894165\n",
      "    epoch          : 900\n",
      "    loss           : -1795.1334216999558\n",
      "    ess            : 8.001180522846726\n",
      "    log_marginal   : 1795.1334216999558\n",
      "    val_loss       : -1799.5946655273438\n",
      "    val_ess        : 8.001180013020834\n",
      "    val_log_marginal: 1799.5946756998699\n",
      "Saving checkpoint: saved/models/Mnist_Ppc/0208_133044/checkpoint-epoch900.pth ...\n",
      "Train Epoch: 901 [0/54000 (0%)] Loss: -1812.354980\n",
      "Train Epoch: 901 [11264/54000 (21%)] Loss: -1815.853516\n",
      "Train Epoch: 901 [22528/54000 (42%)] Loss: -1797.959717\n",
      "Train Epoch: 901 [33792/54000 (63%)] Loss: -1814.343262\n",
      "Train Epoch: 901 [45056/54000 (83%)] Loss: -1795.914795\n",
      "    epoch          : 901\n",
      "    loss           : -1801.3881974130306\n",
      "    ess            : 8.001179146316817\n",
      "    log_marginal   : 1801.3881985646374\n",
      "    val_loss       : -1805.8438313802083\n",
      "    val_ess        : 8.001179218292236\n",
      "    val_log_marginal: 1805.8438313802083\n",
      "Train Epoch: 902 [0/54000 (0%)] Loss: -1819.318115\n",
      "Train Epoch: 902 [11264/54000 (21%)] Loss: -1815.431519\n",
      "Train Epoch: 902 [22528/54000 (42%)] Loss: -1797.145020\n",
      "Train Epoch: 902 [33792/54000 (63%)] Loss: -1813.736206\n",
      "Train Epoch: 902 [45056/54000 (83%)] Loss: -1793.548096\n",
      "    epoch          : 902\n",
      "    loss           : -1800.650266251474\n",
      "    ess            : 8.001178876408991\n",
      "    log_marginal   : 1800.650266251474\n",
      "    val_loss       : -1801.1038106282551\n",
      "    val_ess        : 8.001182556152344\n",
      "    val_log_marginal: 1801.1037902832031\n",
      "Train Epoch: 903 [0/54000 (0%)] Loss: -1813.319458\n",
      "Train Epoch: 903 [11264/54000 (21%)] Loss: -1817.558472\n",
      "Train Epoch: 903 [22528/54000 (42%)] Loss: -1801.226318\n",
      "Train Epoch: 903 [33792/54000 (63%)] Loss: -1808.854248\n",
      "Train Epoch: 903 [45056/54000 (83%)] Loss: -1784.766724\n",
      "    epoch          : 903\n",
      "    loss           : -1798.8559259378685\n",
      "    ess            : 8.001178651485803\n",
      "    log_marginal   : 1798.8559247862618\n",
      "    val_loss       : -1794.1464945475261\n",
      "    val_ess        : 8.001179138819376\n",
      "    val_log_marginal: 1794.1464945475261\n",
      "Train Epoch: 904 [0/54000 (0%)] Loss: -1806.503662\n",
      "Train Epoch: 904 [11264/54000 (21%)] Loss: -1815.763916\n",
      "Train Epoch: 904 [22528/54000 (42%)] Loss: -1800.656250\n",
      "Train Epoch: 904 [33792/54000 (63%)] Loss: -1812.321899\n",
      "Train Epoch: 904 [45056/54000 (83%)] Loss: -1795.635010\n",
      "    epoch          : 904\n",
      "    loss           : -1800.9212865289653\n",
      "    ess            : 8.001179740114033\n",
      "    log_marginal   : 1800.9212865289653\n",
      "    val_loss       : -1805.2319946289062\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1805.2319946289062\n",
      "Train Epoch: 905 [0/54000 (0%)] Loss: -1817.904053\n",
      "Train Epoch: 905 [11264/54000 (21%)] Loss: -1817.419312\n",
      "Train Epoch: 905 [22528/54000 (42%)] Loss: -1800.603882\n",
      "Train Epoch: 905 [33792/54000 (63%)] Loss: -1789.776855\n",
      "Train Epoch: 905 [45056/54000 (83%)] Loss: -1778.806519\n",
      "    epoch          : 905\n",
      "    loss           : -1791.9911499023438\n",
      "    ess            : 8.001179200298381\n",
      "    log_marginal   : 1791.9911499023438\n",
      "    val_loss       : -1783.8317565917969\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1783.8317565917969\n",
      "Train Epoch: 906 [0/54000 (0%)] Loss: -1797.286255\n",
      "Train Epoch: 906 [11264/54000 (21%)] Loss: -1806.469360\n",
      "Train Epoch: 906 [22528/54000 (42%)] Loss: -1786.168213\n",
      "Train Epoch: 906 [33792/54000 (63%)] Loss: -1798.203857\n",
      "Train Epoch: 906 [45056/54000 (83%)] Loss: -1788.996582\n",
      "    epoch          : 906\n",
      "    loss           : -1788.6983918963738\n",
      "    ess            : 8.001181539499536\n",
      "    log_marginal   : 1788.6983895931603\n",
      "    val_loss       : -1795.4595743815105\n",
      "    val_ess        : 8.001179377237955\n",
      "    val_log_marginal: 1795.4595642089844\n",
      "Train Epoch: 907 [0/54000 (0%)] Loss: -1810.309570\n",
      "Train Epoch: 907 [11264/54000 (21%)] Loss: -1811.787842\n",
      "Train Epoch: 907 [22528/54000 (42%)] Loss: -1792.206909\n",
      "Train Epoch: 907 [33792/54000 (63%)] Loss: -1810.686768\n",
      "Train Epoch: 907 [45056/54000 (83%)] Loss: -1800.385498\n",
      "    epoch          : 907\n",
      "    loss           : -1797.39006992556\n",
      "    ess            : 8.00117749987908\n",
      "    log_marginal   : 1797.39006992556\n",
      "    val_loss       : -1802.9216003417969\n",
      "    val_ess        : 8.001178979873657\n",
      "    val_log_marginal: 1802.9216003417969\n",
      "Train Epoch: 908 [0/54000 (0%)] Loss: -1816.578369\n",
      "Train Epoch: 908 [11264/54000 (21%)] Loss: -1816.087891\n",
      "Train Epoch: 908 [22528/54000 (42%)] Loss: -1803.145020\n",
      "Train Epoch: 908 [33792/54000 (63%)] Loss: -1818.555664\n",
      "Train Epoch: 908 [45056/54000 (83%)] Loss: -1793.111938\n",
      "    epoch          : 908\n",
      "    loss           : -1801.5440731408462\n",
      "    ess            : 8.001178741455078\n",
      "    log_marginal   : 1801.5440731408462\n",
      "    val_loss       : -1794.3746948242188\n",
      "    val_ess        : 8.00118374824524\n",
      "    val_log_marginal: 1794.3747049967449\n",
      "Train Epoch: 909 [0/54000 (0%)] Loss: -1803.455933\n",
      "Train Epoch: 909 [11264/54000 (21%)] Loss: -1808.246826\n",
      "Train Epoch: 909 [22528/54000 (42%)] Loss: -1792.017822\n",
      "Train Epoch: 909 [33792/54000 (63%)] Loss: -1814.865723\n",
      "Train Epoch: 909 [45056/54000 (83%)] Loss: -1796.863770\n",
      "    epoch          : 909\n",
      "    loss           : -1797.4504359983048\n",
      "    ess            : 8.001180954699246\n",
      "    log_marginal   : 1797.4504359983048\n",
      "    val_loss       : -1795.6854044596355\n",
      "    val_ess        : 8.00118112564087\n",
      "    val_log_marginal: 1795.6854044596355\n",
      "Train Epoch: 910 [0/54000 (0%)] Loss: -1809.911133\n",
      "Train Epoch: 910 [11264/54000 (21%)] Loss: -1812.325684\n",
      "Train Epoch: 910 [22528/54000 (42%)] Loss: -1800.855225\n",
      "Train Epoch: 910 [33792/54000 (63%)] Loss: -1818.549072\n",
      "Train Epoch: 910 [45056/54000 (83%)] Loss: -1793.578125\n",
      "    epoch          : 910\n",
      "    loss           : -1801.1481162017246\n",
      "    ess            : 8.001179488200062\n",
      "    log_marginal   : 1801.1481162017246\n",
      "    val_loss       : -1803.4748840332031\n",
      "    val_ess        : 8.001180489857992\n",
      "    val_log_marginal: 1803.474873860677\n",
      "Train Epoch: 911 [0/54000 (0%)] Loss: -1814.241211\n",
      "Train Epoch: 911 [11264/54000 (21%)] Loss: -1818.176147\n",
      "Train Epoch: 911 [22528/54000 (42%)] Loss: -1803.881714\n",
      "Train Epoch: 911 [33792/54000 (63%)] Loss: -1822.961670\n",
      "Train Epoch: 911 [45056/54000 (83%)] Loss: -1801.041870\n",
      "    epoch          : 911\n",
      "    loss           : -1807.1012999336674\n",
      "    ess            : 8.00117844455647\n",
      "    log_marginal   : 1807.1012999336674\n",
      "    val_loss       : -1807.0695393880208\n",
      "    val_ess        : 8.00117794672648\n",
      "    val_log_marginal: 1807.069559733073\n",
      "Train Epoch: 912 [0/54000 (0%)] Loss: -1817.973267\n",
      "Train Epoch: 912 [11264/54000 (21%)] Loss: -1818.704346\n",
      "Train Epoch: 912 [22528/54000 (42%)] Loss: -1800.741821\n",
      "Train Epoch: 912 [33792/54000 (63%)] Loss: -1813.971924\n",
      "Train Epoch: 912 [45056/54000 (83%)] Loss: -1789.859619\n",
      "    epoch          : 912\n",
      "    loss           : -1801.0975721827094\n",
      "    ess            : 8.001180603819073\n",
      "    log_marginal   : 1801.0975721827094\n",
      "    val_loss       : -1800.9737447102864\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1800.9737447102864\n",
      "Train Epoch: 913 [0/54000 (0%)] Loss: -1814.338867\n",
      "Train Epoch: 913 [11264/54000 (21%)] Loss: -1810.986694\n",
      "Train Epoch: 913 [22528/54000 (42%)] Loss: -1801.104980\n",
      "Train Epoch: 913 [33792/54000 (63%)] Loss: -1815.697021\n",
      "Train Epoch: 913 [45056/54000 (83%)] Loss: -1795.314087\n",
      "    epoch          : 913\n",
      "    loss           : -1801.3854669534935\n",
      "    ess            : 8.001179668138612\n",
      "    log_marginal   : 1801.3854669534935\n",
      "    val_loss       : -1802.8877970377605\n",
      "    val_ess        : 8.001180013020834\n",
      "    val_log_marginal: 1802.8877970377605\n",
      "Train Epoch: 914 [0/54000 (0%)] Loss: -1815.254639\n",
      "Train Epoch: 914 [11264/54000 (21%)] Loss: -1816.717651\n",
      "Train Epoch: 914 [22528/54000 (42%)] Loss: -1798.846069\n",
      "Train Epoch: 914 [33792/54000 (63%)] Loss: -1821.249023\n",
      "Train Epoch: 914 [45056/54000 (83%)] Loss: -1802.708496\n",
      "    epoch          : 914\n",
      "    loss           : -1805.311925348246\n",
      "    ess            : 8.001178552519601\n",
      "    log_marginal   : 1805.3119276514594\n",
      "    val_loss       : -1810.2853698730469\n",
      "    val_ess        : 8.001179138819376\n",
      "    val_log_marginal: 1810.2853495279949\n",
      "Train Epoch: 915 [0/54000 (0%)] Loss: -1821.627686\n",
      "Train Epoch: 915 [11264/54000 (21%)] Loss: -1817.493530\n",
      "Train Epoch: 915 [22528/54000 (42%)] Loss: -1795.872314\n",
      "Train Epoch: 915 [33792/54000 (63%)] Loss: -1817.244629\n",
      "Train Epoch: 915 [45056/54000 (83%)] Loss: -1794.726807\n",
      "    epoch          : 915\n",
      "    loss           : -1803.1023548054245\n",
      "    ess            : 8.001179155313745\n",
      "    log_marginal   : 1803.1023548054245\n",
      "    val_loss       : -1803.1607767740886\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1803.1607666015625\n",
      "Train Epoch: 916 [0/54000 (0%)] Loss: -1816.716553\n",
      "Train Epoch: 916 [11264/54000 (21%)] Loss: -1818.279053\n",
      "Train Epoch: 916 [22528/54000 (42%)] Loss: -1801.451172\n",
      "Train Epoch: 916 [33792/54000 (63%)] Loss: -1824.060547\n",
      "Train Epoch: 916 [45056/54000 (83%)] Loss: -1788.265381\n",
      "    epoch          : 916\n",
      "    loss           : -1801.0926421543338\n",
      "    ess            : 8.001179011362904\n",
      "    log_marginal   : 1801.0926433059406\n",
      "    val_loss       : -1793.5321350097656\n",
      "    val_ess        : 8.001179695129395\n",
      "    val_log_marginal: 1793.5321553548176\n",
      "Train Epoch: 917 [0/54000 (0%)] Loss: -1807.737305\n",
      "Train Epoch: 917 [11264/54000 (21%)] Loss: -1807.308350\n",
      "Train Epoch: 917 [22528/54000 (42%)] Loss: -1791.087646\n",
      "Train Epoch: 917 [33792/54000 (63%)] Loss: -1811.783691\n",
      "Train Epoch: 917 [45056/54000 (83%)] Loss: -1793.354980\n",
      "    epoch          : 917\n",
      "    loss           : -1794.5015880656692\n",
      "    ess            : 8.001180019018785\n",
      "    log_marginal   : 1794.5015880656692\n",
      "    val_loss       : -1803.2992451985676\n",
      "    val_ess        : 8.001180171966553\n",
      "    val_log_marginal: 1803.2992350260417\n",
      "Train Epoch: 918 [0/54000 (0%)] Loss: -1815.477905\n",
      "Train Epoch: 918 [11264/54000 (21%)] Loss: -1821.768799\n",
      "Train Epoch: 918 [22528/54000 (42%)] Loss: -1805.899658\n",
      "Train Epoch: 918 [33792/54000 (63%)] Loss: -1814.893555\n",
      "Train Epoch: 918 [45056/54000 (83%)] Loss: -1785.203369\n",
      "    epoch          : 918\n",
      "    loss           : -1801.1850182875148\n",
      "    ess            : 8.00117978509867\n",
      "    log_marginal   : 1801.1850194391216\n",
      "    val_loss       : -1799.7841389973958\n",
      "    val_ess        : 8.001181523005167\n",
      "    val_log_marginal: 1799.7841288248699\n",
      "Train Epoch: 919 [0/54000 (0%)] Loss: -1813.041748\n",
      "Train Epoch: 919 [11264/54000 (21%)] Loss: -1816.194336\n",
      "Train Epoch: 919 [22528/54000 (42%)] Loss: -1800.382935\n",
      "Train Epoch: 919 [33792/54000 (63%)] Loss: -1822.064331\n",
      "Train Epoch: 919 [45056/54000 (83%)] Loss: -1801.418945\n",
      "    epoch          : 919\n",
      "    loss           : -1803.4769966557342\n",
      "    ess            : 8.001180297923538\n",
      "    log_marginal   : 1803.4769966557342\n",
      "    val_loss       : -1811.8220825195312\n",
      "    val_ess        : 8.001181761423746\n",
      "    val_log_marginal: 1811.8220825195312\n",
      "Train Epoch: 920 [0/54000 (0%)] Loss: -1824.256592\n",
      "Train Epoch: 920 [11264/54000 (21%)] Loss: -1819.390869\n",
      "Train Epoch: 920 [22528/54000 (42%)] Loss: -1797.326050\n",
      "Train Epoch: 920 [33792/54000 (63%)] Loss: -1815.111084\n",
      "Train Epoch: 920 [45056/54000 (83%)] Loss: -1796.266602\n",
      "    epoch          : 920\n",
      "    loss           : -1802.9033652251621\n",
      "    ess            : 8.001178912396702\n",
      "    log_marginal   : 1802.9033652251621\n",
      "    val_loss       : -1806.2908732096355\n",
      "    val_ess        : 8.001180013020834\n",
      "    val_log_marginal: 1806.2908630371094\n",
      "Train Epoch: 921 [0/54000 (0%)] Loss: -1817.552979\n",
      "Train Epoch: 921 [11264/54000 (21%)] Loss: -1816.009399\n",
      "Train Epoch: 921 [22528/54000 (42%)] Loss: -1798.914551\n",
      "Train Epoch: 921 [33792/54000 (63%)] Loss: -1821.939087\n",
      "Train Epoch: 921 [45056/54000 (83%)] Loss: -1795.737793\n",
      "    epoch          : 921\n",
      "    loss           : -1800.9654575563827\n",
      "    ess            : 8.00117894838441\n",
      "    log_marginal   : 1800.9654587079895\n",
      "    val_loss       : -1785.4958089192708\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1785.4958089192708\n",
      "Train Epoch: 922 [0/54000 (0%)] Loss: -1799.869385\n",
      "Train Epoch: 922 [11264/54000 (21%)] Loss: -1813.907471\n",
      "Train Epoch: 922 [22528/54000 (42%)] Loss: -1799.194092\n",
      "Train Epoch: 922 [33792/54000 (63%)] Loss: -1813.661987\n",
      "Train Epoch: 922 [45056/54000 (83%)] Loss: -1791.913574\n",
      "    epoch          : 922\n",
      "    loss           : -1798.0938720703125\n",
      "    ess            : 8.001179524187771\n",
      "    log_marginal   : 1798.0938720703125\n",
      "    val_loss       : -1801.6686299641926\n",
      "    val_ess        : 8.001180489857992\n",
      "    val_log_marginal: 1801.6686299641926\n",
      "Train Epoch: 923 [0/54000 (0%)] Loss: -1814.992432\n",
      "Train Epoch: 923 [11264/54000 (21%)] Loss: -1817.169434\n",
      "Train Epoch: 923 [22528/54000 (42%)] Loss: -1801.313232\n",
      "Train Epoch: 923 [33792/54000 (63%)] Loss: -1816.501709\n",
      "Train Epoch: 923 [45056/54000 (83%)] Loss: -1790.778076\n",
      "    epoch          : 923\n",
      "    loss           : -1800.7911031471108\n",
      "    ess            : 8.00117837258105\n",
      "    log_marginal   : 1800.791101995504\n",
      "    val_loss       : -1801.2215270996094\n",
      "    val_ess        : 8.001179138819376\n",
      "    val_log_marginal: 1801.2215270996094\n",
      "Train Epoch: 924 [0/54000 (0%)] Loss: -1813.059082\n",
      "Train Epoch: 924 [11264/54000 (21%)] Loss: -1819.732300\n",
      "Train Epoch: 924 [22528/54000 (42%)] Loss: -1801.560669\n",
      "Train Epoch: 924 [33792/54000 (63%)] Loss: -1817.268555\n",
      "Train Epoch: 924 [45056/54000 (83%)] Loss: -1795.718506\n",
      "    epoch          : 924\n",
      "    loss           : -1802.0395231426887\n",
      "    ess            : 8.001176798118735\n",
      "    log_marginal   : 1802.0395231426887\n",
      "    val_loss       : -1792.8568013509114\n",
      "    val_ess        : 8.001180648803711\n",
      "    val_log_marginal: 1792.8567911783855\n",
      "Train Epoch: 925 [0/54000 (0%)] Loss: -1805.300049\n",
      "Train Epoch: 925 [11264/54000 (21%)] Loss: -1810.848633\n",
      "Train Epoch: 925 [22528/54000 (42%)] Loss: -1799.341064\n",
      "Train Epoch: 925 [33792/54000 (63%)] Loss: -1816.975708\n",
      "Train Epoch: 925 [45056/54000 (83%)] Loss: -1790.573975\n",
      "    epoch          : 925\n",
      "    loss           : -1797.4270192272259\n",
      "    ess            : 8.00117902935676\n",
      "    log_marginal   : 1797.4270192272259\n",
      "    val_loss       : -1800.119120279948\n",
      "    val_ess        : 8.001182238260904\n",
      "    val_log_marginal: 1800.119120279948\n",
      "Train Epoch: 926 [0/54000 (0%)] Loss: -1810.394409\n",
      "Train Epoch: 926 [11264/54000 (21%)] Loss: -1821.088867\n",
      "Train Epoch: 926 [22528/54000 (42%)] Loss: -1807.161621\n",
      "Train Epoch: 926 [33792/54000 (63%)] Loss: -1820.576294\n",
      "Train Epoch: 926 [45056/54000 (83%)] Loss: -1790.364136\n",
      "    epoch          : 926\n",
      "    loss           : -1803.3164949237175\n",
      "    ess            : 8.001179839080235\n",
      "    log_marginal   : 1803.3164949237175\n",
      "    val_loss       : -1797.5760803222656\n",
      "    val_ess        : 8.00117858250936\n",
      "    val_log_marginal: 1797.5760803222656\n",
      "Train Epoch: 927 [0/54000 (0%)] Loss: -1810.123657\n",
      "Train Epoch: 927 [11264/54000 (21%)] Loss: -1815.767212\n",
      "Train Epoch: 927 [22528/54000 (42%)] Loss: -1797.694580\n",
      "Train Epoch: 927 [33792/54000 (63%)] Loss: -1813.790405\n",
      "Train Epoch: 927 [45056/54000 (83%)] Loss: -1784.354248\n",
      "    epoch          : 927\n",
      "    loss           : -1798.1200319686027\n",
      "    ess            : 8.001179083338323\n",
      "    log_marginal   : 1798.1200319686027\n",
      "    val_loss       : -1793.5919291178386\n",
      "    val_ess        : 8.001182397206625\n",
      "    val_log_marginal: 1793.5919291178386\n",
      "Train Epoch: 928 [0/54000 (0%)] Loss: -1807.652588\n",
      "Train Epoch: 928 [11264/54000 (21%)] Loss: -1817.177368\n",
      "Train Epoch: 928 [22528/54000 (42%)] Loss: -1803.099487\n",
      "Train Epoch: 928 [33792/54000 (63%)] Loss: -1809.895752\n",
      "Train Epoch: 928 [45056/54000 (83%)] Loss: -1780.689209\n",
      "    epoch          : 928\n",
      "    loss           : -1798.4196915536556\n",
      "    ess            : 8.001178489541108\n",
      "    log_marginal   : 1798.4196915536556\n",
      "    val_loss       : -1795.8151957194011\n",
      "    val_ess        : 8.001178900400797\n",
      "    val_log_marginal: 1795.8151957194011\n",
      "Train Epoch: 929 [0/54000 (0%)] Loss: -1809.252930\n",
      "Train Epoch: 929 [11264/54000 (21%)] Loss: -1813.308105\n",
      "Train Epoch: 929 [22528/54000 (42%)] Loss: -1800.301514\n",
      "Train Epoch: 929 [33792/54000 (63%)] Loss: -1818.319580\n",
      "Train Epoch: 929 [45056/54000 (83%)] Loss: -1791.409668\n",
      "    epoch          : 929\n",
      "    loss           : -1799.638336757444\n",
      "    ess            : 8.001180648803711\n",
      "    log_marginal   : 1799.638336757444\n",
      "    val_loss       : -1797.0209554036458\n",
      "    val_ess        : 8.001182079315186\n",
      "    val_log_marginal: 1797.0209452311199\n",
      "Train Epoch: 930 [0/54000 (0%)] Loss: -1807.418213\n",
      "Train Epoch: 930 [11264/54000 (21%)] Loss: -1813.589111\n",
      "Train Epoch: 930 [22528/54000 (42%)] Loss: -1795.563477\n",
      "Train Epoch: 930 [33792/54000 (63%)] Loss: -1779.033447\n",
      "Train Epoch: 930 [45056/54000 (83%)] Loss: -1768.976440\n",
      "    epoch          : 930\n",
      "    loss           : -1784.8380910045696\n",
      "    ess            : 8.001180747769913\n",
      "    log_marginal   : 1784.8380910045696\n",
      "    val_loss       : -1784.0727132161458\n",
      "    val_ess        : 8.001183986663818\n",
      "    val_log_marginal: 1784.0727030436199\n",
      "Train Epoch: 931 [0/54000 (0%)] Loss: -1799.470093\n",
      "Train Epoch: 931 [11264/54000 (21%)] Loss: -1809.467163\n",
      "Train Epoch: 931 [22528/54000 (42%)] Loss: -1793.645386\n",
      "Train Epoch: 931 [33792/54000 (63%)] Loss: -1812.407227\n",
      "Train Epoch: 931 [45056/54000 (83%)] Loss: -1793.746704\n",
      "    epoch          : 931\n",
      "    loss           : -1794.1307672464623\n",
      "    ess            : 8.001181530502608\n",
      "    log_marginal   : 1794.1307672464623\n",
      "    val_loss       : -1800.6442057291667\n",
      "    val_ess        : 8.001182079315186\n",
      "    val_log_marginal: 1800.6442057291667\n",
      "Train Epoch: 932 [0/54000 (0%)] Loss: -1812.428955\n",
      "Train Epoch: 932 [11264/54000 (21%)] Loss: -1820.313477\n",
      "Train Epoch: 932 [22528/54000 (42%)] Loss: -1798.723877\n",
      "Train Epoch: 932 [33792/54000 (63%)] Loss: -1821.882935\n",
      "Train Epoch: 932 [45056/54000 (83%)] Loss: -1800.611572\n",
      "    epoch          : 932\n",
      "    loss           : -1802.1449999539357\n",
      "    ess            : 8.001177733799196\n",
      "    log_marginal   : 1802.1449999539357\n",
      "    val_loss       : -1801.7577006022136\n",
      "    val_ess        : 8.001181284586588\n",
      "    val_log_marginal: 1801.7577006022136\n",
      "Train Epoch: 933 [0/54000 (0%)] Loss: -1815.544678\n",
      "Train Epoch: 933 [11264/54000 (21%)] Loss: -1816.386719\n",
      "Train Epoch: 933 [22528/54000 (42%)] Loss: -1801.542480\n",
      "Train Epoch: 933 [33792/54000 (63%)] Loss: -1816.593506\n",
      "Train Epoch: 933 [45056/54000 (83%)] Loss: -1789.905762\n",
      "    epoch          : 933\n",
      "    loss           : -1800.946330520342\n",
      "    ess            : 8.001179101332179\n",
      "    log_marginal   : 1800.9463316719487\n",
      "    val_loss       : -1801.8494974772136\n",
      "    val_ess        : 8.001183668772379\n",
      "    val_log_marginal: 1801.8494974772136\n",
      "Train Epoch: 934 [0/54000 (0%)] Loss: -1816.433594\n",
      "Train Epoch: 934 [11264/54000 (21%)] Loss: -1817.041992\n",
      "Train Epoch: 934 [22528/54000 (42%)] Loss: -1804.237793\n",
      "Train Epoch: 934 [33792/54000 (63%)] Loss: -1818.516113\n",
      "Train Epoch: 934 [45056/54000 (83%)] Loss: -1786.469727\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5b900-0121-4cf6-91b6-2c9b0b12716f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.model.eval()\n",
    "trainer.cpu()\n",
    "trainer.train_particles.cpu()\n",
    "trainer.valid_particles.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b487d4-288a-40d7-8f4d-c79e2e15385e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ppc] *",
   "language": "python",
   "name": "conda-env-ppc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
